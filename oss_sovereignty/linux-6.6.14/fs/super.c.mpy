{
  "module_name": "super.c",
  "hash_id": "d4991fd28bfa3330ada6f44aa1de2d4cdcab00506e0e6744dd90e721c36043a2",
  "original_prompt": "Ingested from linux-6.6.14/fs/super.c",
  "human_readable_source": "\n \n\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/blkdev.h>\n#include <linux/mount.h>\n#include <linux/security.h>\n#include <linux/writeback.h>\t\t \n#include <linux/idr.h>\n#include <linux/mutex.h>\n#include <linux/backing-dev.h>\n#include <linux/rculist_bl.h>\n#include <linux/fscrypt.h>\n#include <linux/fsnotify.h>\n#include <linux/lockdep.h>\n#include <linux/user_namespace.h>\n#include <linux/fs_context.h>\n#include <uapi/linux/mount.h>\n#include \"internal.h\"\n\nstatic int thaw_super_locked(struct super_block *sb, enum freeze_holder who);\n\nstatic LIST_HEAD(super_blocks);\nstatic DEFINE_SPINLOCK(sb_lock);\n\nstatic char *sb_writers_name[SB_FREEZE_LEVELS] = {\n\t\"sb_writers\",\n\t\"sb_pagefaults\",\n\t\"sb_internal\",\n};\n\nstatic inline void __super_lock(struct super_block *sb, bool excl)\n{\n\tif (excl)\n\t\tdown_write(&sb->s_umount);\n\telse\n\t\tdown_read(&sb->s_umount);\n}\n\nstatic inline void super_unlock(struct super_block *sb, bool excl)\n{\n\tif (excl)\n\t\tup_write(&sb->s_umount);\n\telse\n\t\tup_read(&sb->s_umount);\n}\n\nstatic inline void __super_lock_excl(struct super_block *sb)\n{\n\t__super_lock(sb, true);\n}\n\nstatic inline void super_unlock_excl(struct super_block *sb)\n{\n\tsuper_unlock(sb, true);\n}\n\nstatic inline void super_unlock_shared(struct super_block *sb)\n{\n\tsuper_unlock(sb, false);\n}\n\nstatic inline bool wait_born(struct super_block *sb)\n{\n\tunsigned int flags;\n\n\t \n\tflags = smp_load_acquire(&sb->s_flags);\n\treturn flags & (SB_BORN | SB_DYING);\n}\n\n \nstatic __must_check bool super_lock(struct super_block *sb, bool excl)\n{\n\n\tlockdep_assert_not_held(&sb->s_umount);\n\nrelock:\n\t__super_lock(sb, excl);\n\n\t \n\tif (sb->s_flags & SB_DYING)\n\t\treturn false;\n\n\t \n\tif (sb->s_flags & SB_BORN)\n\t\treturn true;\n\n\tsuper_unlock(sb, excl);\n\n\t \n\twait_var_event(&sb->s_flags, wait_born(sb));\n\n\t \n\tgoto relock;\n}\n\n \nstatic inline bool super_lock_shared(struct super_block *sb)\n{\n\treturn super_lock(sb, false);\n}\n\n \nstatic inline bool super_lock_excl(struct super_block *sb)\n{\n\treturn super_lock(sb, true);\n}\n\n \n#define SUPER_WAKE_FLAGS (SB_BORN | SB_DYING | SB_DEAD)\nstatic void super_wake(struct super_block *sb, unsigned int flag)\n{\n\tWARN_ON_ONCE((flag & ~SUPER_WAKE_FLAGS));\n\tWARN_ON_ONCE(hweight32(flag & SUPER_WAKE_FLAGS) > 1);\n\n\t \n\tsmp_store_release(&sb->s_flags, sb->s_flags | flag);\n\t \n\tsmp_mb();\n\twake_up_var(&sb->s_flags);\n}\n\n \nstatic unsigned long super_cache_scan(struct shrinker *shrink,\n\t\t\t\t      struct shrink_control *sc)\n{\n\tstruct super_block *sb;\n\tlong\tfs_objects = 0;\n\tlong\ttotal_objects;\n\tlong\tfreed = 0;\n\tlong\tdentries;\n\tlong\tinodes;\n\n\tsb = container_of(shrink, struct super_block, s_shrink);\n\n\t \n\tif (!(sc->gfp_mask & __GFP_FS))\n\t\treturn SHRINK_STOP;\n\n\tif (!super_trylock_shared(sb))\n\t\treturn SHRINK_STOP;\n\n\tif (sb->s_op->nr_cached_objects)\n\t\tfs_objects = sb->s_op->nr_cached_objects(sb, sc);\n\n\tinodes = list_lru_shrink_count(&sb->s_inode_lru, sc);\n\tdentries = list_lru_shrink_count(&sb->s_dentry_lru, sc);\n\ttotal_objects = dentries + inodes + fs_objects + 1;\n\tif (!total_objects)\n\t\ttotal_objects = 1;\n\n\t \n\tdentries = mult_frac(sc->nr_to_scan, dentries, total_objects);\n\tinodes = mult_frac(sc->nr_to_scan, inodes, total_objects);\n\tfs_objects = mult_frac(sc->nr_to_scan, fs_objects, total_objects);\n\n\t \n\tsc->nr_to_scan = dentries + 1;\n\tfreed = prune_dcache_sb(sb, sc);\n\tsc->nr_to_scan = inodes + 1;\n\tfreed += prune_icache_sb(sb, sc);\n\n\tif (fs_objects) {\n\t\tsc->nr_to_scan = fs_objects + 1;\n\t\tfreed += sb->s_op->free_cached_objects(sb, sc);\n\t}\n\n\tsuper_unlock_shared(sb);\n\treturn freed;\n}\n\nstatic unsigned long super_cache_count(struct shrinker *shrink,\n\t\t\t\t       struct shrink_control *sc)\n{\n\tstruct super_block *sb;\n\tlong\ttotal_objects = 0;\n\n\tsb = container_of(shrink, struct super_block, s_shrink);\n\n\t \n\tif (!(sb->s_flags & SB_BORN))\n\t\treturn 0;\n\tsmp_rmb();\n\n\tif (sb->s_op && sb->s_op->nr_cached_objects)\n\t\ttotal_objects = sb->s_op->nr_cached_objects(sb, sc);\n\n\ttotal_objects += list_lru_shrink_count(&sb->s_dentry_lru, sc);\n\ttotal_objects += list_lru_shrink_count(&sb->s_inode_lru, sc);\n\n\tif (!total_objects)\n\t\treturn SHRINK_EMPTY;\n\n\ttotal_objects = vfs_pressure_ratio(total_objects);\n\treturn total_objects;\n}\n\nstatic void destroy_super_work(struct work_struct *work)\n{\n\tstruct super_block *s = container_of(work, struct super_block,\n\t\t\t\t\t\t\tdestroy_work);\n\tint i;\n\n\tfor (i = 0; i < SB_FREEZE_LEVELS; i++)\n\t\tpercpu_free_rwsem(&s->s_writers.rw_sem[i]);\n\tkfree(s);\n}\n\nstatic void destroy_super_rcu(struct rcu_head *head)\n{\n\tstruct super_block *s = container_of(head, struct super_block, rcu);\n\tINIT_WORK(&s->destroy_work, destroy_super_work);\n\tschedule_work(&s->destroy_work);\n}\n\n \nstatic void destroy_unused_super(struct super_block *s)\n{\n\tif (!s)\n\t\treturn;\n\tsuper_unlock_excl(s);\n\tlist_lru_destroy(&s->s_dentry_lru);\n\tlist_lru_destroy(&s->s_inode_lru);\n\tsecurity_sb_free(s);\n\tput_user_ns(s->s_user_ns);\n\tkfree(s->s_subtype);\n\tfree_prealloced_shrinker(&s->s_shrink);\n\t \n\tdestroy_super_work(&s->destroy_work);\n}\n\n \nstatic struct super_block *alloc_super(struct file_system_type *type, int flags,\n\t\t\t\t       struct user_namespace *user_ns)\n{\n\tstruct super_block *s = kzalloc(sizeof(struct super_block),  GFP_USER);\n\tstatic const struct super_operations default_op;\n\tint i;\n\n\tif (!s)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&s->s_mounts);\n\ts->s_user_ns = get_user_ns(user_ns);\n\tinit_rwsem(&s->s_umount);\n\tlockdep_set_class(&s->s_umount, &type->s_umount_key);\n\t \n\tdown_write_nested(&s->s_umount, SINGLE_DEPTH_NESTING);\n\n\tif (security_sb_alloc(s))\n\t\tgoto fail;\n\n\tfor (i = 0; i < SB_FREEZE_LEVELS; i++) {\n\t\tif (__percpu_init_rwsem(&s->s_writers.rw_sem[i],\n\t\t\t\t\tsb_writers_name[i],\n\t\t\t\t\t&type->s_writers_key[i]))\n\t\t\tgoto fail;\n\t}\n\ts->s_bdi = &noop_backing_dev_info;\n\ts->s_flags = flags;\n\tif (s->s_user_ns != &init_user_ns)\n\t\ts->s_iflags |= SB_I_NODEV;\n\tINIT_HLIST_NODE(&s->s_instances);\n\tINIT_HLIST_BL_HEAD(&s->s_roots);\n\tmutex_init(&s->s_sync_lock);\n\tINIT_LIST_HEAD(&s->s_inodes);\n\tspin_lock_init(&s->s_inode_list_lock);\n\tINIT_LIST_HEAD(&s->s_inodes_wb);\n\tspin_lock_init(&s->s_inode_wblist_lock);\n\n\ts->s_count = 1;\n\tatomic_set(&s->s_active, 1);\n\tmutex_init(&s->s_vfs_rename_mutex);\n\tlockdep_set_class(&s->s_vfs_rename_mutex, &type->s_vfs_rename_key);\n\tinit_rwsem(&s->s_dquot.dqio_sem);\n\ts->s_maxbytes = MAX_NON_LFS;\n\ts->s_op = &default_op;\n\ts->s_time_gran = 1000000000;\n\ts->s_time_min = TIME64_MIN;\n\ts->s_time_max = TIME64_MAX;\n\n\ts->s_shrink.seeks = DEFAULT_SEEKS;\n\ts->s_shrink.scan_objects = super_cache_scan;\n\ts->s_shrink.count_objects = super_cache_count;\n\ts->s_shrink.batch = 1024;\n\ts->s_shrink.flags = SHRINKER_NUMA_AWARE | SHRINKER_MEMCG_AWARE;\n\tif (prealloc_shrinker(&s->s_shrink, \"sb-%s\", type->name))\n\t\tgoto fail;\n\tif (list_lru_init_memcg(&s->s_dentry_lru, &s->s_shrink))\n\t\tgoto fail;\n\tif (list_lru_init_memcg(&s->s_inode_lru, &s->s_shrink))\n\t\tgoto fail;\n\treturn s;\n\nfail:\n\tdestroy_unused_super(s);\n\treturn NULL;\n}\n\n \n\n \nstatic void __put_super(struct super_block *s)\n{\n\tif (!--s->s_count) {\n\t\tlist_del_init(&s->s_list);\n\t\tWARN_ON(s->s_dentry_lru.node);\n\t\tWARN_ON(s->s_inode_lru.node);\n\t\tWARN_ON(!list_empty(&s->s_mounts));\n\t\tsecurity_sb_free(s);\n\t\tput_user_ns(s->s_user_ns);\n\t\tkfree(s->s_subtype);\n\t\tcall_rcu(&s->rcu, destroy_super_rcu);\n\t}\n}\n\n \nvoid put_super(struct super_block *sb)\n{\n\tspin_lock(&sb_lock);\n\t__put_super(sb);\n\tspin_unlock(&sb_lock);\n}\n\nstatic void kill_super_notify(struct super_block *sb)\n{\n\tlockdep_assert_not_held(&sb->s_umount);\n\n\t \n\tif (sb->s_flags & SB_DEAD)\n\t\treturn;\n\n\t \n\tspin_lock(&sb_lock);\n\thlist_del_init(&sb->s_instances);\n\tspin_unlock(&sb_lock);\n\n\t \n\tsuper_wake(sb, SB_DEAD);\n}\n\n \nvoid deactivate_locked_super(struct super_block *s)\n{\n\tstruct file_system_type *fs = s->s_type;\n\tif (atomic_dec_and_test(&s->s_active)) {\n\t\tunregister_shrinker(&s->s_shrink);\n\t\tfs->kill_sb(s);\n\n\t\tkill_super_notify(s);\n\n\t\t \n\t\tlist_lru_destroy(&s->s_dentry_lru);\n\t\tlist_lru_destroy(&s->s_inode_lru);\n\n\t\tput_filesystem(fs);\n\t\tput_super(s);\n\t} else {\n\t\tsuper_unlock_excl(s);\n\t}\n}\n\nEXPORT_SYMBOL(deactivate_locked_super);\n\n \nvoid deactivate_super(struct super_block *s)\n{\n\tif (!atomic_add_unless(&s->s_active, -1, 1)) {\n\t\t__super_lock_excl(s);\n\t\tdeactivate_locked_super(s);\n\t}\n}\n\nEXPORT_SYMBOL(deactivate_super);\n\n \nstatic int grab_super(struct super_block *s) __releases(sb_lock)\n{\n\tbool born;\n\n\ts->s_count++;\n\tspin_unlock(&sb_lock);\n\tborn = super_lock_excl(s);\n\tif (born && atomic_inc_not_zero(&s->s_active)) {\n\t\tput_super(s);\n\t\treturn 1;\n\t}\n\tsuper_unlock_excl(s);\n\tput_super(s);\n\treturn 0;\n}\n\nstatic inline bool wait_dead(struct super_block *sb)\n{\n\tunsigned int flags;\n\n\t \n\tflags = smp_load_acquire(&sb->s_flags);\n\treturn flags & SB_DEAD;\n}\n\n \nstatic bool grab_super_dead(struct super_block *sb)\n{\n\n\tsb->s_count++;\n\tif (grab_super(sb)) {\n\t\tput_super(sb);\n\t\tlockdep_assert_held(&sb->s_umount);\n\t\treturn true;\n\t}\n\twait_var_event(&sb->s_flags, wait_dead(sb));\n\tlockdep_assert_not_held(&sb->s_umount);\n\tput_super(sb);\n\treturn false;\n}\n\n \nbool super_trylock_shared(struct super_block *sb)\n{\n\tif (down_read_trylock(&sb->s_umount)) {\n\t\tif (!(sb->s_flags & SB_DYING) && sb->s_root &&\n\t\t    (sb->s_flags & SB_BORN))\n\t\t\treturn true;\n\t\tsuper_unlock_shared(sb);\n\t}\n\n\treturn false;\n}\n\n \nvoid retire_super(struct super_block *sb)\n{\n\tWARN_ON(!sb->s_bdev);\n\t__super_lock_excl(sb);\n\tif (sb->s_iflags & SB_I_PERSB_BDI) {\n\t\tbdi_unregister(sb->s_bdi);\n\t\tsb->s_iflags &= ~SB_I_PERSB_BDI;\n\t}\n\tsb->s_iflags |= SB_I_RETIRED;\n\tsuper_unlock_excl(sb);\n}\nEXPORT_SYMBOL(retire_super);\n\n \nvoid generic_shutdown_super(struct super_block *sb)\n{\n\tconst struct super_operations *sop = sb->s_op;\n\n\tif (sb->s_root) {\n\t\tshrink_dcache_for_umount(sb);\n\t\tsync_filesystem(sb);\n\t\tsb->s_flags &= ~SB_ACTIVE;\n\n\t\tcgroup_writeback_umount();\n\n\t\t \n\t\tevict_inodes(sb);\n\n\t\t \n\t\tfsnotify_sb_delete(sb);\n\t\tsecurity_sb_delete(sb);\n\n\t\t \n\t\tfscrypt_destroy_keyring(sb);\n\n\t\tif (sb->s_dio_done_wq) {\n\t\t\tdestroy_workqueue(sb->s_dio_done_wq);\n\t\t\tsb->s_dio_done_wq = NULL;\n\t\t}\n\n\t\tif (sop->put_super)\n\t\t\tsop->put_super(sb);\n\n\t\tif (CHECK_DATA_CORRUPTION(!list_empty(&sb->s_inodes),\n\t\t\t\t\"VFS: Busy inodes after unmount of %s (%s)\",\n\t\t\t\tsb->s_id, sb->s_type->name)) {\n\t\t\t \n\t\t\tstruct inode *inode;\n\n\t\t\tspin_lock(&sb->s_inode_list_lock);\n\t\t\tlist_for_each_entry(inode, &sb->s_inodes, i_sb_list) {\n\t\t\t\tinode->i_op = VFS_PTR_POISON;\n\t\t\t\tinode->i_sb = VFS_PTR_POISON;\n\t\t\t\tinode->i_mapping = VFS_PTR_POISON;\n\t\t\t}\n\t\t\tspin_unlock(&sb->s_inode_list_lock);\n\t\t}\n\t}\n\t \n\tsuper_wake(sb, SB_DYING);\n\tsuper_unlock_excl(sb);\n\tif (sb->s_bdi != &noop_backing_dev_info) {\n\t\tif (sb->s_iflags & SB_I_PERSB_BDI)\n\t\t\tbdi_unregister(sb->s_bdi);\n\t\tbdi_put(sb->s_bdi);\n\t\tsb->s_bdi = &noop_backing_dev_info;\n\t}\n}\n\nEXPORT_SYMBOL(generic_shutdown_super);\n\nbool mount_capable(struct fs_context *fc)\n{\n\tif (!(fc->fs_type->fs_flags & FS_USERNS_MOUNT))\n\t\treturn capable(CAP_SYS_ADMIN);\n\telse\n\t\treturn ns_capable(fc->user_ns, CAP_SYS_ADMIN);\n}\n\n \nstruct super_block *sget_fc(struct fs_context *fc,\n\t\t\t    int (*test)(struct super_block *, struct fs_context *),\n\t\t\t    int (*set)(struct super_block *, struct fs_context *))\n{\n\tstruct super_block *s = NULL;\n\tstruct super_block *old;\n\tstruct user_namespace *user_ns = fc->global ? &init_user_ns : fc->user_ns;\n\tint err;\n\nretry:\n\tspin_lock(&sb_lock);\n\tif (test) {\n\t\thlist_for_each_entry(old, &fc->fs_type->fs_supers, s_instances) {\n\t\t\tif (test(old, fc))\n\t\t\t\tgoto share_extant_sb;\n\t\t}\n\t}\n\tif (!s) {\n\t\tspin_unlock(&sb_lock);\n\t\ts = alloc_super(fc->fs_type, fc->sb_flags, user_ns);\n\t\tif (!s)\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\tgoto retry;\n\t}\n\n\ts->s_fs_info = fc->s_fs_info;\n\terr = set(s, fc);\n\tif (err) {\n\t\ts->s_fs_info = NULL;\n\t\tspin_unlock(&sb_lock);\n\t\tdestroy_unused_super(s);\n\t\treturn ERR_PTR(err);\n\t}\n\tfc->s_fs_info = NULL;\n\ts->s_type = fc->fs_type;\n\ts->s_iflags |= fc->s_iflags;\n\tstrscpy(s->s_id, s->s_type->name, sizeof(s->s_id));\n\t \n\tlist_add_tail(&s->s_list, &super_blocks);\n\thlist_add_head(&s->s_instances, &s->s_type->fs_supers);\n\tspin_unlock(&sb_lock);\n\tget_filesystem(s->s_type);\n\tregister_shrinker_prepared(&s->s_shrink);\n\treturn s;\n\nshare_extant_sb:\n\tif (user_ns != old->s_user_ns || fc->exclusive) {\n\t\tspin_unlock(&sb_lock);\n\t\tdestroy_unused_super(s);\n\t\tif (fc->exclusive)\n\t\t\twarnfc(fc, \"reusing existing filesystem not allowed\");\n\t\telse\n\t\t\twarnfc(fc, \"reusing existing filesystem in another namespace not allowed\");\n\t\treturn ERR_PTR(-EBUSY);\n\t}\n\tif (!grab_super_dead(old))\n\t\tgoto retry;\n\tdestroy_unused_super(s);\n\treturn old;\n}\nEXPORT_SYMBOL(sget_fc);\n\n \nstruct super_block *sget(struct file_system_type *type,\n\t\t\tint (*test)(struct super_block *,void *),\n\t\t\tint (*set)(struct super_block *,void *),\n\t\t\tint flags,\n\t\t\tvoid *data)\n{\n\tstruct user_namespace *user_ns = current_user_ns();\n\tstruct super_block *s = NULL;\n\tstruct super_block *old;\n\tint err;\n\n\t \n\tif (flags & SB_SUBMOUNT)\n\t\tuser_ns = &init_user_ns;\n\nretry:\n\tspin_lock(&sb_lock);\n\tif (test) {\n\t\thlist_for_each_entry(old, &type->fs_supers, s_instances) {\n\t\t\tif (!test(old, data))\n\t\t\t\tcontinue;\n\t\t\tif (user_ns != old->s_user_ns) {\n\t\t\t\tspin_unlock(&sb_lock);\n\t\t\t\tdestroy_unused_super(s);\n\t\t\t\treturn ERR_PTR(-EBUSY);\n\t\t\t}\n\t\t\tif (!grab_super_dead(old))\n\t\t\t\tgoto retry;\n\t\t\tdestroy_unused_super(s);\n\t\t\treturn old;\n\t\t}\n\t}\n\tif (!s) {\n\t\tspin_unlock(&sb_lock);\n\t\ts = alloc_super(type, (flags & ~SB_SUBMOUNT), user_ns);\n\t\tif (!s)\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\tgoto retry;\n\t}\n\n\terr = set(s, data);\n\tif (err) {\n\t\tspin_unlock(&sb_lock);\n\t\tdestroy_unused_super(s);\n\t\treturn ERR_PTR(err);\n\t}\n\ts->s_type = type;\n\tstrscpy(s->s_id, type->name, sizeof(s->s_id));\n\tlist_add_tail(&s->s_list, &super_blocks);\n\thlist_add_head(&s->s_instances, &type->fs_supers);\n\tspin_unlock(&sb_lock);\n\tget_filesystem(type);\n\tregister_shrinker_prepared(&s->s_shrink);\n\treturn s;\n}\nEXPORT_SYMBOL(sget);\n\nvoid drop_super(struct super_block *sb)\n{\n\tsuper_unlock_shared(sb);\n\tput_super(sb);\n}\n\nEXPORT_SYMBOL(drop_super);\n\nvoid drop_super_exclusive(struct super_block *sb)\n{\n\tsuper_unlock_excl(sb);\n\tput_super(sb);\n}\nEXPORT_SYMBOL(drop_super_exclusive);\n\nstatic void __iterate_supers(void (*f)(struct super_block *))\n{\n\tstruct super_block *sb, *p = NULL;\n\n\tspin_lock(&sb_lock);\n\tlist_for_each_entry(sb, &super_blocks, s_list) {\n\t\t \n\t\tif (smp_load_acquire(&sb->s_flags) & SB_DYING)\n\t\t\tcontinue;\n\t\tsb->s_count++;\n\t\tspin_unlock(&sb_lock);\n\n\t\tf(sb);\n\n\t\tspin_lock(&sb_lock);\n\t\tif (p)\n\t\t\t__put_super(p);\n\t\tp = sb;\n\t}\n\tif (p)\n\t\t__put_super(p);\n\tspin_unlock(&sb_lock);\n}\n \nvoid iterate_supers(void (*f)(struct super_block *, void *), void *arg)\n{\n\tstruct super_block *sb, *p = NULL;\n\n\tspin_lock(&sb_lock);\n\tlist_for_each_entry(sb, &super_blocks, s_list) {\n\t\tbool born;\n\n\t\tsb->s_count++;\n\t\tspin_unlock(&sb_lock);\n\n\t\tborn = super_lock_shared(sb);\n\t\tif (born && sb->s_root)\n\t\t\tf(sb, arg);\n\t\tsuper_unlock_shared(sb);\n\n\t\tspin_lock(&sb_lock);\n\t\tif (p)\n\t\t\t__put_super(p);\n\t\tp = sb;\n\t}\n\tif (p)\n\t\t__put_super(p);\n\tspin_unlock(&sb_lock);\n}\n\n \nvoid iterate_supers_type(struct file_system_type *type,\n\tvoid (*f)(struct super_block *, void *), void *arg)\n{\n\tstruct super_block *sb, *p = NULL;\n\n\tspin_lock(&sb_lock);\n\thlist_for_each_entry(sb, &type->fs_supers, s_instances) {\n\t\tbool born;\n\n\t\tsb->s_count++;\n\t\tspin_unlock(&sb_lock);\n\n\t\tborn = super_lock_shared(sb);\n\t\tif (born && sb->s_root)\n\t\t\tf(sb, arg);\n\t\tsuper_unlock_shared(sb);\n\n\t\tspin_lock(&sb_lock);\n\t\tif (p)\n\t\t\t__put_super(p);\n\t\tp = sb;\n\t}\n\tif (p)\n\t\t__put_super(p);\n\tspin_unlock(&sb_lock);\n}\n\nEXPORT_SYMBOL(iterate_supers_type);\n\n \nstruct super_block *get_active_super(struct block_device *bdev)\n{\n\tstruct super_block *sb;\n\n\tif (!bdev)\n\t\treturn NULL;\n\n\tspin_lock(&sb_lock);\n\tlist_for_each_entry(sb, &super_blocks, s_list) {\n\t\tif (sb->s_bdev == bdev) {\n\t\t\tif (!grab_super(sb))\n\t\t\t\treturn NULL;\n\t\t\tsuper_unlock_excl(sb);\n\t\t\treturn sb;\n\t\t}\n\t}\n\tspin_unlock(&sb_lock);\n\treturn NULL;\n}\n\nstruct super_block *user_get_super(dev_t dev, bool excl)\n{\n\tstruct super_block *sb;\n\n\tspin_lock(&sb_lock);\n\tlist_for_each_entry(sb, &super_blocks, s_list) {\n\t\tif (sb->s_dev ==  dev) {\n\t\t\tbool born;\n\n\t\t\tsb->s_count++;\n\t\t\tspin_unlock(&sb_lock);\n\t\t\t \n\t\t\tborn = super_lock(sb, excl);\n\t\t\tif (born && sb->s_root)\n\t\t\t\treturn sb;\n\t\t\tsuper_unlock(sb, excl);\n\t\t\t \n\t\t\tspin_lock(&sb_lock);\n\t\t\t__put_super(sb);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&sb_lock);\n\treturn NULL;\n}\n\n \nint reconfigure_super(struct fs_context *fc)\n{\n\tstruct super_block *sb = fc->root->d_sb;\n\tint retval;\n\tbool remount_ro = false;\n\tbool remount_rw = false;\n\tbool force = fc->sb_flags & SB_FORCE;\n\n\tif (fc->sb_flags_mask & ~MS_RMT_MASK)\n\t\treturn -EINVAL;\n\tif (sb->s_writers.frozen != SB_UNFROZEN)\n\t\treturn -EBUSY;\n\n\tretval = security_sb_remount(sb, fc->security);\n\tif (retval)\n\t\treturn retval;\n\n\tif (fc->sb_flags_mask & SB_RDONLY) {\n#ifdef CONFIG_BLOCK\n\t\tif (!(fc->sb_flags & SB_RDONLY) && sb->s_bdev &&\n\t\t    bdev_read_only(sb->s_bdev))\n\t\t\treturn -EACCES;\n#endif\n\t\tremount_rw = !(fc->sb_flags & SB_RDONLY) && sb_rdonly(sb);\n\t\tremount_ro = (fc->sb_flags & SB_RDONLY) && !sb_rdonly(sb);\n\t}\n\n\tif (remount_ro) {\n\t\tif (!hlist_empty(&sb->s_pins)) {\n\t\t\tsuper_unlock_excl(sb);\n\t\t\tgroup_pin_kill(&sb->s_pins);\n\t\t\t__super_lock_excl(sb);\n\t\t\tif (!sb->s_root)\n\t\t\t\treturn 0;\n\t\t\tif (sb->s_writers.frozen != SB_UNFROZEN)\n\t\t\t\treturn -EBUSY;\n\t\t\tremount_ro = !sb_rdonly(sb);\n\t\t}\n\t}\n\tshrink_dcache_sb(sb);\n\n\t \n\tif (remount_ro) {\n\t\tif (force) {\n\t\t\tsb_start_ro_state_change(sb);\n\t\t} else {\n\t\t\tretval = sb_prepare_remount_readonly(sb);\n\t\t\tif (retval)\n\t\t\t\treturn retval;\n\t\t}\n\t} else if (remount_rw) {\n\t\t \n\t\tsb_start_ro_state_change(sb);\n\t}\n\n\tif (fc->ops->reconfigure) {\n\t\tretval = fc->ops->reconfigure(fc);\n\t\tif (retval) {\n\t\t\tif (!force)\n\t\t\t\tgoto cancel_readonly;\n\t\t\t \n\t\t\tWARN(1, \"forced remount of a %s fs returned %i\\n\",\n\t\t\t     sb->s_type->name, retval);\n\t\t}\n\t}\n\n\tWRITE_ONCE(sb->s_flags, ((sb->s_flags & ~fc->sb_flags_mask) |\n\t\t\t\t (fc->sb_flags & fc->sb_flags_mask)));\n\tsb_end_ro_state_change(sb);\n\n\t \n\tif (remount_ro && sb->s_bdev)\n\t\tinvalidate_bdev(sb->s_bdev);\n\treturn 0;\n\ncancel_readonly:\n\tsb_end_ro_state_change(sb);\n\treturn retval;\n}\n\nstatic void do_emergency_remount_callback(struct super_block *sb)\n{\n\tbool born = super_lock_excl(sb);\n\n\tif (born && sb->s_root && sb->s_bdev && !sb_rdonly(sb)) {\n\t\tstruct fs_context *fc;\n\n\t\tfc = fs_context_for_reconfigure(sb->s_root,\n\t\t\t\t\tSB_RDONLY | SB_FORCE, SB_RDONLY);\n\t\tif (!IS_ERR(fc)) {\n\t\t\tif (parse_monolithic_mount_data(fc, NULL) == 0)\n\t\t\t\t(void)reconfigure_super(fc);\n\t\t\tput_fs_context(fc);\n\t\t}\n\t}\n\tsuper_unlock_excl(sb);\n}\n\nstatic void do_emergency_remount(struct work_struct *work)\n{\n\t__iterate_supers(do_emergency_remount_callback);\n\tkfree(work);\n\tprintk(\"Emergency Remount complete\\n\");\n}\n\nvoid emergency_remount(void)\n{\n\tstruct work_struct *work;\n\n\twork = kmalloc(sizeof(*work), GFP_ATOMIC);\n\tif (work) {\n\t\tINIT_WORK(work, do_emergency_remount);\n\t\tschedule_work(work);\n\t}\n}\n\nstatic void do_thaw_all_callback(struct super_block *sb)\n{\n\tbool born = super_lock_excl(sb);\n\n\tif (born && sb->s_root) {\n\t\tif (IS_ENABLED(CONFIG_BLOCK))\n\t\t\twhile (sb->s_bdev && !thaw_bdev(sb->s_bdev))\n\t\t\t\tpr_warn(\"Emergency Thaw on %pg\\n\", sb->s_bdev);\n\t\tthaw_super_locked(sb, FREEZE_HOLDER_USERSPACE);\n\t} else {\n\t\tsuper_unlock_excl(sb);\n\t}\n}\n\nstatic void do_thaw_all(struct work_struct *work)\n{\n\t__iterate_supers(do_thaw_all_callback);\n\tkfree(work);\n\tprintk(KERN_WARNING \"Emergency Thaw complete\\n\");\n}\n\n \nvoid emergency_thaw_all(void)\n{\n\tstruct work_struct *work;\n\n\twork = kmalloc(sizeof(*work), GFP_ATOMIC);\n\tif (work) {\n\t\tINIT_WORK(work, do_thaw_all);\n\t\tschedule_work(work);\n\t}\n}\n\nstatic DEFINE_IDA(unnamed_dev_ida);\n\n \nint get_anon_bdev(dev_t *p)\n{\n\tint dev;\n\n\t \n\tdev = ida_alloc_range(&unnamed_dev_ida, 1, (1 << MINORBITS) - 1,\n\t\t\tGFP_ATOMIC);\n\tif (dev == -ENOSPC)\n\t\tdev = -EMFILE;\n\tif (dev < 0)\n\t\treturn dev;\n\n\t*p = MKDEV(0, dev);\n\treturn 0;\n}\nEXPORT_SYMBOL(get_anon_bdev);\n\nvoid free_anon_bdev(dev_t dev)\n{\n\tida_free(&unnamed_dev_ida, MINOR(dev));\n}\nEXPORT_SYMBOL(free_anon_bdev);\n\nint set_anon_super(struct super_block *s, void *data)\n{\n\treturn get_anon_bdev(&s->s_dev);\n}\nEXPORT_SYMBOL(set_anon_super);\n\nvoid kill_anon_super(struct super_block *sb)\n{\n\tdev_t dev = sb->s_dev;\n\tgeneric_shutdown_super(sb);\n\tkill_super_notify(sb);\n\tfree_anon_bdev(dev);\n}\nEXPORT_SYMBOL(kill_anon_super);\n\nvoid kill_litter_super(struct super_block *sb)\n{\n\tif (sb->s_root)\n\t\td_genocide(sb->s_root);\n\tkill_anon_super(sb);\n}\nEXPORT_SYMBOL(kill_litter_super);\n\nint set_anon_super_fc(struct super_block *sb, struct fs_context *fc)\n{\n\treturn set_anon_super(sb, NULL);\n}\nEXPORT_SYMBOL(set_anon_super_fc);\n\nstatic int test_keyed_super(struct super_block *sb, struct fs_context *fc)\n{\n\treturn sb->s_fs_info == fc->s_fs_info;\n}\n\nstatic int test_single_super(struct super_block *s, struct fs_context *fc)\n{\n\treturn 1;\n}\n\nstatic int vfs_get_super(struct fs_context *fc,\n\t\tint (*test)(struct super_block *, struct fs_context *),\n\t\tint (*fill_super)(struct super_block *sb,\n\t\t\t\t  struct fs_context *fc))\n{\n\tstruct super_block *sb;\n\tint err;\n\n\tsb = sget_fc(fc, test, set_anon_super_fc);\n\tif (IS_ERR(sb))\n\t\treturn PTR_ERR(sb);\n\n\tif (!sb->s_root) {\n\t\terr = fill_super(sb, fc);\n\t\tif (err)\n\t\t\tgoto error;\n\n\t\tsb->s_flags |= SB_ACTIVE;\n\t}\n\n\tfc->root = dget(sb->s_root);\n\treturn 0;\n\nerror:\n\tdeactivate_locked_super(sb);\n\treturn err;\n}\n\nint get_tree_nodev(struct fs_context *fc,\n\t\t  int (*fill_super)(struct super_block *sb,\n\t\t\t\t    struct fs_context *fc))\n{\n\treturn vfs_get_super(fc, NULL, fill_super);\n}\nEXPORT_SYMBOL(get_tree_nodev);\n\nint get_tree_single(struct fs_context *fc,\n\t\t  int (*fill_super)(struct super_block *sb,\n\t\t\t\t    struct fs_context *fc))\n{\n\treturn vfs_get_super(fc, test_single_super, fill_super);\n}\nEXPORT_SYMBOL(get_tree_single);\n\nint get_tree_keyed(struct fs_context *fc,\n\t\t  int (*fill_super)(struct super_block *sb,\n\t\t\t\t    struct fs_context *fc),\n\t\tvoid *key)\n{\n\tfc->s_fs_info = key;\n\treturn vfs_get_super(fc, test_keyed_super, fill_super);\n}\nEXPORT_SYMBOL(get_tree_keyed);\n\nstatic int set_bdev_super(struct super_block *s, void *data)\n{\n\ts->s_dev = *(dev_t *)data;\n\treturn 0;\n}\n\nstatic int super_s_dev_set(struct super_block *s, struct fs_context *fc)\n{\n\treturn set_bdev_super(s, fc->sget_key);\n}\n\nstatic int super_s_dev_test(struct super_block *s, struct fs_context *fc)\n{\n\treturn !(s->s_iflags & SB_I_RETIRED) &&\n\t\ts->s_dev == *(dev_t *)fc->sget_key;\n}\n\n \nstruct super_block *sget_dev(struct fs_context *fc, dev_t dev)\n{\n\tfc->sget_key = &dev;\n\treturn sget_fc(fc, super_s_dev_test, super_s_dev_set);\n}\nEXPORT_SYMBOL(sget_dev);\n\n#ifdef CONFIG_BLOCK\n \nstatic bool super_lock_shared_active(struct super_block *sb)\n{\n\tbool born = super_lock_shared(sb);\n\n\tif (!born || !sb->s_root || !(sb->s_flags & SB_ACTIVE)) {\n\t\tsuper_unlock_shared(sb);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic void fs_bdev_mark_dead(struct block_device *bdev, bool surprise)\n{\n\tstruct super_block *sb = bdev->bd_holder;\n\n\t \n\tlockdep_assert_held(&bdev->bd_holder_lock);\n\n\tif (!super_lock_shared_active(sb))\n\t\treturn;\n\n\tif (!surprise)\n\t\tsync_filesystem(sb);\n\tshrink_dcache_sb(sb);\n\tinvalidate_inodes(sb);\n\tif (sb->s_op->shutdown)\n\t\tsb->s_op->shutdown(sb);\n\n\tsuper_unlock_shared(sb);\n}\n\nstatic void fs_bdev_sync(struct block_device *bdev)\n{\n\tstruct super_block *sb = bdev->bd_holder;\n\n\tlockdep_assert_held(&bdev->bd_holder_lock);\n\n\tif (!super_lock_shared_active(sb))\n\t\treturn;\n\tsync_filesystem(sb);\n\tsuper_unlock_shared(sb);\n}\n\nconst struct blk_holder_ops fs_holder_ops = {\n\t.mark_dead\t\t= fs_bdev_mark_dead,\n\t.sync\t\t\t= fs_bdev_sync,\n};\nEXPORT_SYMBOL_GPL(fs_holder_ops);\n\nint setup_bdev_super(struct super_block *sb, int sb_flags,\n\t\tstruct fs_context *fc)\n{\n\tblk_mode_t mode = sb_open_mode(sb_flags);\n\tstruct block_device *bdev;\n\n\tbdev = blkdev_get_by_dev(sb->s_dev, mode, sb, &fs_holder_ops);\n\tif (IS_ERR(bdev)) {\n\t\tif (fc)\n\t\t\terrorf(fc, \"%s: Can't open blockdev\", fc->source);\n\t\treturn PTR_ERR(bdev);\n\t}\n\n\t \n\tif ((mode & BLK_OPEN_WRITE) && bdev_read_only(bdev)) {\n\t\tblkdev_put(bdev, sb);\n\t\treturn -EACCES;\n\t}\n\n\t \n\tmutex_lock(&bdev->bd_fsfreeze_mutex);\n\tif (bdev->bd_fsfreeze_count > 0) {\n\t\tmutex_unlock(&bdev->bd_fsfreeze_mutex);\n\t\tif (fc)\n\t\t\twarnf(fc, \"%pg: Can't mount, blockdev is frozen\", bdev);\n\t\tblkdev_put(bdev, sb);\n\t\treturn -EBUSY;\n\t}\n\tspin_lock(&sb_lock);\n\tsb->s_bdev = bdev;\n\tsb->s_bdi = bdi_get(bdev->bd_disk->bdi);\n\tif (bdev_stable_writes(bdev))\n\t\tsb->s_iflags |= SB_I_STABLE_WRITES;\n\tspin_unlock(&sb_lock);\n\tmutex_unlock(&bdev->bd_fsfreeze_mutex);\n\n\tsnprintf(sb->s_id, sizeof(sb->s_id), \"%pg\", bdev);\n\tshrinker_debugfs_rename(&sb->s_shrink, \"sb-%s:%s\", sb->s_type->name,\n\t\t\t\tsb->s_id);\n\tsb_set_blocksize(sb, block_size(bdev));\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(setup_bdev_super);\n\n \nint get_tree_bdev(struct fs_context *fc,\n\t\tint (*fill_super)(struct super_block *,\n\t\t\t\t  struct fs_context *))\n{\n\tstruct super_block *s;\n\tint error = 0;\n\tdev_t dev;\n\n\tif (!fc->source)\n\t\treturn invalf(fc, \"No source specified\");\n\n\terror = lookup_bdev(fc->source, &dev);\n\tif (error) {\n\t\terrorf(fc, \"%s: Can't lookup blockdev\", fc->source);\n\t\treturn error;\n\t}\n\n\tfc->sb_flags |= SB_NOSEC;\n\ts = sget_dev(fc, dev);\n\tif (IS_ERR(s))\n\t\treturn PTR_ERR(s);\n\n\tif (s->s_root) {\n\t\t \n\t\tif ((fc->sb_flags ^ s->s_flags) & SB_RDONLY) {\n\t\t\twarnf(fc, \"%pg: Can't mount, would change RO state\", s->s_bdev);\n\t\t\tdeactivate_locked_super(s);\n\t\t\treturn -EBUSY;\n\t\t}\n\t} else {\n\t\t \n\t\tsuper_unlock_excl(s);\n\t\terror = setup_bdev_super(s, fc->sb_flags, fc);\n\t\t__super_lock_excl(s);\n\t\tif (!error)\n\t\t\terror = fill_super(s, fc);\n\t\tif (error) {\n\t\t\tdeactivate_locked_super(s);\n\t\t\treturn error;\n\t\t}\n\t\ts->s_flags |= SB_ACTIVE;\n\t}\n\n\tBUG_ON(fc->root);\n\tfc->root = dget(s->s_root);\n\treturn 0;\n}\nEXPORT_SYMBOL(get_tree_bdev);\n\nstatic int test_bdev_super(struct super_block *s, void *data)\n{\n\treturn !(s->s_iflags & SB_I_RETIRED) && s->s_dev == *(dev_t *)data;\n}\n\nstruct dentry *mount_bdev(struct file_system_type *fs_type,\n\tint flags, const char *dev_name, void *data,\n\tint (*fill_super)(struct super_block *, void *, int))\n{\n\tstruct super_block *s;\n\tint error;\n\tdev_t dev;\n\n\terror = lookup_bdev(dev_name, &dev);\n\tif (error)\n\t\treturn ERR_PTR(error);\n\n\tflags |= SB_NOSEC;\n\ts = sget(fs_type, test_bdev_super, set_bdev_super, flags, &dev);\n\tif (IS_ERR(s))\n\t\treturn ERR_CAST(s);\n\n\tif (s->s_root) {\n\t\tif ((flags ^ s->s_flags) & SB_RDONLY) {\n\t\t\tdeactivate_locked_super(s);\n\t\t\treturn ERR_PTR(-EBUSY);\n\t\t}\n\t} else {\n\t\t \n\t\tsuper_unlock_excl(s);\n\t\terror = setup_bdev_super(s, flags, NULL);\n\t\t__super_lock_excl(s);\n\t\tif (!error)\n\t\t\terror = fill_super(s, data, flags & SB_SILENT ? 1 : 0);\n\t\tif (error) {\n\t\t\tdeactivate_locked_super(s);\n\t\t\treturn ERR_PTR(error);\n\t\t}\n\n\t\ts->s_flags |= SB_ACTIVE;\n\t}\n\n\treturn dget(s->s_root);\n}\nEXPORT_SYMBOL(mount_bdev);\n\nvoid kill_block_super(struct super_block *sb)\n{\n\tstruct block_device *bdev = sb->s_bdev;\n\n\tgeneric_shutdown_super(sb);\n\tif (bdev) {\n\t\tsync_blockdev(bdev);\n\t\tblkdev_put(bdev, sb);\n\t}\n}\n\nEXPORT_SYMBOL(kill_block_super);\n#endif\n\nstruct dentry *mount_nodev(struct file_system_type *fs_type,\n\tint flags, void *data,\n\tint (*fill_super)(struct super_block *, void *, int))\n{\n\tint error;\n\tstruct super_block *s = sget(fs_type, NULL, set_anon_super, flags, NULL);\n\n\tif (IS_ERR(s))\n\t\treturn ERR_CAST(s);\n\n\terror = fill_super(s, data, flags & SB_SILENT ? 1 : 0);\n\tif (error) {\n\t\tdeactivate_locked_super(s);\n\t\treturn ERR_PTR(error);\n\t}\n\ts->s_flags |= SB_ACTIVE;\n\treturn dget(s->s_root);\n}\nEXPORT_SYMBOL(mount_nodev);\n\nint reconfigure_single(struct super_block *s,\n\t\t       int flags, void *data)\n{\n\tstruct fs_context *fc;\n\tint ret;\n\n\t \n\tfc = fs_context_for_reconfigure(s->s_root, flags, MS_RMT_MASK);\n\tif (IS_ERR(fc))\n\t\treturn PTR_ERR(fc);\n\n\tret = parse_monolithic_mount_data(fc, data);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = reconfigure_super(fc);\nout:\n\tput_fs_context(fc);\n\treturn ret;\n}\n\nstatic int compare_single(struct super_block *s, void *p)\n{\n\treturn 1;\n}\n\nstruct dentry *mount_single(struct file_system_type *fs_type,\n\tint flags, void *data,\n\tint (*fill_super)(struct super_block *, void *, int))\n{\n\tstruct super_block *s;\n\tint error;\n\n\ts = sget(fs_type, compare_single, set_anon_super, flags, NULL);\n\tif (IS_ERR(s))\n\t\treturn ERR_CAST(s);\n\tif (!s->s_root) {\n\t\terror = fill_super(s, data, flags & SB_SILENT ? 1 : 0);\n\t\tif (!error)\n\t\t\ts->s_flags |= SB_ACTIVE;\n\t} else {\n\t\terror = reconfigure_single(s, flags, data);\n\t}\n\tif (unlikely(error)) {\n\t\tdeactivate_locked_super(s);\n\t\treturn ERR_PTR(error);\n\t}\n\treturn dget(s->s_root);\n}\nEXPORT_SYMBOL(mount_single);\n\n \nint vfs_get_tree(struct fs_context *fc)\n{\n\tstruct super_block *sb;\n\tint error;\n\n\tif (fc->root)\n\t\treturn -EBUSY;\n\n\t \n\terror = fc->ops->get_tree(fc);\n\tif (error < 0)\n\t\treturn error;\n\n\tif (!fc->root) {\n\t\tpr_err(\"Filesystem %s get_tree() didn't set fc->root\\n\",\n\t\t       fc->fs_type->name);\n\t\t \n\t\tBUG();\n\t}\n\n\tsb = fc->root->d_sb;\n\tWARN_ON(!sb->s_bdi);\n\n\t \n\tsuper_wake(sb, SB_BORN);\n\n\terror = security_sb_set_mnt_opts(sb, fc->security, 0, NULL);\n\tif (unlikely(error)) {\n\t\tfc_drop_locked(fc);\n\t\treturn error;\n\t}\n\n\t \n\tWARN((sb->s_maxbytes < 0), \"%s set sb->s_maxbytes to \"\n\t\t\"negative value (%lld)\\n\", fc->fs_type->name, sb->s_maxbytes);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(vfs_get_tree);\n\n \nint super_setup_bdi_name(struct super_block *sb, char *fmt, ...)\n{\n\tstruct backing_dev_info *bdi;\n\tint err;\n\tva_list args;\n\n\tbdi = bdi_alloc(NUMA_NO_NODE);\n\tif (!bdi)\n\t\treturn -ENOMEM;\n\n\tva_start(args, fmt);\n\terr = bdi_register_va(bdi, fmt, args);\n\tva_end(args);\n\tif (err) {\n\t\tbdi_put(bdi);\n\t\treturn err;\n\t}\n\tWARN_ON(sb->s_bdi != &noop_backing_dev_info);\n\tsb->s_bdi = bdi;\n\tsb->s_iflags |= SB_I_PERSB_BDI;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(super_setup_bdi_name);\n\n \nint super_setup_bdi(struct super_block *sb)\n{\n\tstatic atomic_long_t bdi_seq = ATOMIC_LONG_INIT(0);\n\n\treturn super_setup_bdi_name(sb, \"%.28s-%ld\", sb->s_type->name,\n\t\t\t\t    atomic_long_inc_return(&bdi_seq));\n}\nEXPORT_SYMBOL(super_setup_bdi);\n\n \nstatic void sb_wait_write(struct super_block *sb, int level)\n{\n\tpercpu_down_write(sb->s_writers.rw_sem + level-1);\n}\n\n \nstatic void lockdep_sb_freeze_release(struct super_block *sb)\n{\n\tint level;\n\n\tfor (level = SB_FREEZE_LEVELS - 1; level >= 0; level--)\n\t\tpercpu_rwsem_release(sb->s_writers.rw_sem + level, 0, _THIS_IP_);\n}\n\n \nstatic void lockdep_sb_freeze_acquire(struct super_block *sb)\n{\n\tint level;\n\n\tfor (level = 0; level < SB_FREEZE_LEVELS; ++level)\n\t\tpercpu_rwsem_acquire(sb->s_writers.rw_sem + level, 0, _THIS_IP_);\n}\n\nstatic void sb_freeze_unlock(struct super_block *sb, int level)\n{\n\tfor (level--; level >= 0; level--)\n\t\tpercpu_up_write(sb->s_writers.rw_sem + level);\n}\n\nstatic int wait_for_partially_frozen(struct super_block *sb)\n{\n\tint ret = 0;\n\n\tdo {\n\t\tunsigned short old = sb->s_writers.frozen;\n\n\t\tup_write(&sb->s_umount);\n\t\tret = wait_var_event_killable(&sb->s_writers.frozen,\n\t\t\t\t\t       sb->s_writers.frozen != old);\n\t\tdown_write(&sb->s_umount);\n\t} while (ret == 0 &&\n\t\t sb->s_writers.frozen != SB_UNFROZEN &&\n\t\t sb->s_writers.frozen != SB_FREEZE_COMPLETE);\n\n\treturn ret;\n}\n\n \nint freeze_super(struct super_block *sb, enum freeze_holder who)\n{\n\tint ret;\n\n\tatomic_inc(&sb->s_active);\n\tif (!super_lock_excl(sb))\n\t\tWARN(1, \"Dying superblock while freezing!\");\n\nretry:\n\tif (sb->s_writers.frozen == SB_FREEZE_COMPLETE) {\n\t\tif (sb->s_writers.freeze_holders & who) {\n\t\t\tdeactivate_locked_super(sb);\n\t\t\treturn -EBUSY;\n\t\t}\n\n\t\tWARN_ON(sb->s_writers.freeze_holders == 0);\n\n\t\t \n\t\tsb->s_writers.freeze_holders |= who;\n\t\tsuper_unlock_excl(sb);\n\t\treturn 0;\n\t}\n\n\tif (sb->s_writers.frozen != SB_UNFROZEN) {\n\t\tret = wait_for_partially_frozen(sb);\n\t\tif (ret) {\n\t\t\tdeactivate_locked_super(sb);\n\t\t\treturn ret;\n\t\t}\n\n\t\tgoto retry;\n\t}\n\n\tif (!(sb->s_flags & SB_BORN)) {\n\t\tsuper_unlock_excl(sb);\n\t\treturn 0;\t \n\t}\n\n\tif (sb_rdonly(sb)) {\n\t\t \n\t\tsb->s_writers.freeze_holders |= who;\n\t\tsb->s_writers.frozen = SB_FREEZE_COMPLETE;\n\t\twake_up_var(&sb->s_writers.frozen);\n\t\tsuper_unlock_excl(sb);\n\t\treturn 0;\n\t}\n\n\tsb->s_writers.frozen = SB_FREEZE_WRITE;\n\t \n\tsuper_unlock_excl(sb);\n\tsb_wait_write(sb, SB_FREEZE_WRITE);\n\tif (!super_lock_excl(sb))\n\t\tWARN(1, \"Dying superblock while freezing!\");\n\n\t \n\tsb->s_writers.frozen = SB_FREEZE_PAGEFAULT;\n\tsb_wait_write(sb, SB_FREEZE_PAGEFAULT);\n\n\t \n\tret = sync_filesystem(sb);\n\tif (ret) {\n\t\tsb->s_writers.frozen = SB_UNFROZEN;\n\t\tsb_freeze_unlock(sb, SB_FREEZE_PAGEFAULT);\n\t\twake_up_var(&sb->s_writers.frozen);\n\t\tdeactivate_locked_super(sb);\n\t\treturn ret;\n\t}\n\n\t \n\tsb->s_writers.frozen = SB_FREEZE_FS;\n\tsb_wait_write(sb, SB_FREEZE_FS);\n\n\tif (sb->s_op->freeze_fs) {\n\t\tret = sb->s_op->freeze_fs(sb);\n\t\tif (ret) {\n\t\t\tprintk(KERN_ERR\n\t\t\t\t\"VFS:Filesystem freeze failed\\n\");\n\t\t\tsb->s_writers.frozen = SB_UNFROZEN;\n\t\t\tsb_freeze_unlock(sb, SB_FREEZE_FS);\n\t\t\twake_up_var(&sb->s_writers.frozen);\n\t\t\tdeactivate_locked_super(sb);\n\t\t\treturn ret;\n\t\t}\n\t}\n\t \n\tsb->s_writers.freeze_holders |= who;\n\tsb->s_writers.frozen = SB_FREEZE_COMPLETE;\n\twake_up_var(&sb->s_writers.frozen);\n\tlockdep_sb_freeze_release(sb);\n\tsuper_unlock_excl(sb);\n\treturn 0;\n}\nEXPORT_SYMBOL(freeze_super);\n\n \nstatic int thaw_super_locked(struct super_block *sb, enum freeze_holder who)\n{\n\tint error;\n\n\tif (sb->s_writers.frozen == SB_FREEZE_COMPLETE) {\n\t\tif (!(sb->s_writers.freeze_holders & who)) {\n\t\t\tsuper_unlock_excl(sb);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (sb->s_writers.freeze_holders & ~who) {\n\t\t\tsb->s_writers.freeze_holders &= ~who;\n\t\t\tdeactivate_locked_super(sb);\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tsuper_unlock_excl(sb);\n\t\treturn -EINVAL;\n\t}\n\n\tif (sb_rdonly(sb)) {\n\t\tsb->s_writers.freeze_holders &= ~who;\n\t\tsb->s_writers.frozen = SB_UNFROZEN;\n\t\twake_up_var(&sb->s_writers.frozen);\n\t\tgoto out;\n\t}\n\n\tlockdep_sb_freeze_acquire(sb);\n\n\tif (sb->s_op->unfreeze_fs) {\n\t\terror = sb->s_op->unfreeze_fs(sb);\n\t\tif (error) {\n\t\t\tprintk(KERN_ERR \"VFS:Filesystem thaw failed\\n\");\n\t\t\tlockdep_sb_freeze_release(sb);\n\t\t\tsuper_unlock_excl(sb);\n\t\t\treturn error;\n\t\t}\n\t}\n\n\tsb->s_writers.freeze_holders &= ~who;\n\tsb->s_writers.frozen = SB_UNFROZEN;\n\twake_up_var(&sb->s_writers.frozen);\n\tsb_freeze_unlock(sb, SB_FREEZE_FS);\nout:\n\tdeactivate_locked_super(sb);\n\treturn 0;\n}\n\n \nint thaw_super(struct super_block *sb, enum freeze_holder who)\n{\n\tif (!super_lock_excl(sb))\n\t\tWARN(1, \"Dying superblock while thawing!\");\n\treturn thaw_super_locked(sb, who);\n}\nEXPORT_SYMBOL(thaw_super);\n\n \nint sb_init_dio_done_wq(struct super_block *sb)\n{\n\tstruct workqueue_struct *old;\n\tstruct workqueue_struct *wq = alloc_workqueue(\"dio/%s\",\n\t\t\t\t\t\t      WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t\t      sb->s_id);\n\tif (!wq)\n\t\treturn -ENOMEM;\n\t \n\told = cmpxchg(&sb->s_dio_done_wq, NULL, wq);\n\t \n\tif (old)\n\t\tdestroy_workqueue(wq);\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}