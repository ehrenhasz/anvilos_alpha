{
  "module_name": "pagelist.c",
  "hash_id": "e3681164e3dce9ebff0be4919ac664511c2bdea9e9b53f87c303550a8b3da243",
  "original_prompt": "Ingested from linux-6.6.14/fs/nfs/pagelist.c",
  "human_readable_source": "\n \n\n#include <linux/slab.h>\n#include <linux/file.h>\n#include <linux/sched.h>\n#include <linux/sunrpc/clnt.h>\n#include <linux/nfs.h>\n#include <linux/nfs3.h>\n#include <linux/nfs4.h>\n#include <linux/nfs_fs.h>\n#include <linux/nfs_page.h>\n#include <linux/nfs_mount.h>\n#include <linux/export.h>\n#include <linux/filelock.h>\n\n#include \"internal.h\"\n#include \"pnfs.h\"\n#include \"nfstrace.h\"\n#include \"fscache.h\"\n\n#define NFSDBG_FACILITY\t\tNFSDBG_PAGECACHE\n\nstatic struct kmem_cache *nfs_page_cachep;\nstatic const struct rpc_call_ops nfs_pgio_common_ops;\n\nstruct nfs_page_iter_page {\n\tconst struct nfs_page *req;\n\tsize_t count;\n};\n\nstatic void nfs_page_iter_page_init(struct nfs_page_iter_page *i,\n\t\t\t\t    const struct nfs_page *req)\n{\n\ti->req = req;\n\ti->count = 0;\n}\n\nstatic void nfs_page_iter_page_advance(struct nfs_page_iter_page *i, size_t sz)\n{\n\tconst struct nfs_page *req = i->req;\n\tsize_t tmp = i->count + sz;\n\n\ti->count = (tmp < req->wb_bytes) ? tmp : req->wb_bytes;\n}\n\nstatic struct page *nfs_page_iter_page_get(struct nfs_page_iter_page *i)\n{\n\tconst struct nfs_page *req = i->req;\n\tstruct page *page;\n\n\tif (i->count != req->wb_bytes) {\n\t\tsize_t base = i->count + req->wb_pgbase;\n\t\tsize_t len = PAGE_SIZE - offset_in_page(base);\n\n\t\tpage = nfs_page_to_page(req, base);\n\t\tnfs_page_iter_page_advance(i, len);\n\t\treturn page;\n\t}\n\treturn NULL;\n}\n\nstatic struct nfs_pgio_mirror *\nnfs_pgio_get_mirror(struct nfs_pageio_descriptor *desc, u32 idx)\n{\n\tif (desc->pg_ops->pg_get_mirror)\n\t\treturn desc->pg_ops->pg_get_mirror(desc, idx);\n\treturn &desc->pg_mirrors[0];\n}\n\nstruct nfs_pgio_mirror *\nnfs_pgio_current_mirror(struct nfs_pageio_descriptor *desc)\n{\n\treturn nfs_pgio_get_mirror(desc, desc->pg_mirror_idx);\n}\nEXPORT_SYMBOL_GPL(nfs_pgio_current_mirror);\n\nstatic u32\nnfs_pgio_set_current_mirror(struct nfs_pageio_descriptor *desc, u32 idx)\n{\n\tif (desc->pg_ops->pg_set_mirror)\n\t\treturn desc->pg_ops->pg_set_mirror(desc, idx);\n\treturn desc->pg_mirror_idx;\n}\n\nvoid nfs_pgheader_init(struct nfs_pageio_descriptor *desc,\n\t\t       struct nfs_pgio_header *hdr,\n\t\t       void (*release)(struct nfs_pgio_header *hdr))\n{\n\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\n\n\thdr->req = nfs_list_entry(mirror->pg_list.next);\n\thdr->inode = desc->pg_inode;\n\thdr->cred = nfs_req_openctx(hdr->req)->cred;\n\thdr->io_start = req_offset(hdr->req);\n\thdr->good_bytes = mirror->pg_count;\n\thdr->io_completion = desc->pg_io_completion;\n\thdr->dreq = desc->pg_dreq;\n\tnfs_netfs_set_pgio_header(hdr, desc);\n\thdr->release = release;\n\thdr->completion_ops = desc->pg_completion_ops;\n\tif (hdr->completion_ops->init_hdr)\n\t\thdr->completion_ops->init_hdr(hdr);\n\n\thdr->pgio_mirror_idx = desc->pg_mirror_idx;\n}\nEXPORT_SYMBOL_GPL(nfs_pgheader_init);\n\nvoid nfs_set_pgio_error(struct nfs_pgio_header *hdr, int error, loff_t pos)\n{\n\tunsigned int new = pos - hdr->io_start;\n\n\ttrace_nfs_pgio_error(hdr, error, pos);\n\tif (hdr->good_bytes > new) {\n\t\thdr->good_bytes = new;\n\t\tclear_bit(NFS_IOHDR_EOF, &hdr->flags);\n\t\tif (!test_and_set_bit(NFS_IOHDR_ERROR, &hdr->flags))\n\t\t\thdr->error = error;\n\t}\n}\n\nstatic inline struct nfs_page *nfs_page_alloc(void)\n{\n\tstruct nfs_page *p =\n\t\tkmem_cache_zalloc(nfs_page_cachep, nfs_io_gfp_mask());\n\tif (p)\n\t\tINIT_LIST_HEAD(&p->wb_list);\n\treturn p;\n}\n\nstatic inline void\nnfs_page_free(struct nfs_page *p)\n{\n\tkmem_cache_free(nfs_page_cachep, p);\n}\n\n \nint\nnfs_iocounter_wait(struct nfs_lock_context *l_ctx)\n{\n\treturn wait_var_event_killable(&l_ctx->io_count,\n\t\t\t\t       !atomic_read(&l_ctx->io_count));\n}\n\n \nbool\nnfs_async_iocounter_wait(struct rpc_task *task, struct nfs_lock_context *l_ctx)\n{\n\tstruct inode *inode = d_inode(l_ctx->open_context->dentry);\n\tbool ret = false;\n\n\tif (atomic_read(&l_ctx->io_count) > 0) {\n\t\trpc_sleep_on(&NFS_SERVER(inode)->uoc_rpcwaitq, task, NULL);\n\t\tret = true;\n\t}\n\n\tif (atomic_read(&l_ctx->io_count) == 0) {\n\t\trpc_wake_up_queued_task(&NFS_SERVER(inode)->uoc_rpcwaitq, task);\n\t\tret = false;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(nfs_async_iocounter_wait);\n\n \nstruct nfs_page *\nnfs_page_group_lock_head(struct nfs_page *req)\n{\n\tstruct nfs_page *head = req->wb_head;\n\n\twhile (!nfs_lock_request(head)) {\n\t\tint ret = nfs_wait_on_request(head);\n\t\tif (ret < 0)\n\t\t\treturn ERR_PTR(ret);\n\t}\n\tif (head != req)\n\t\tkref_get(&head->wb_kref);\n\treturn head;\n}\n\n \nstatic void\nnfs_unroll_locks(struct nfs_page *head, struct nfs_page *req)\n{\n\tstruct nfs_page *tmp;\n\n\t \n\tfor (tmp = head->wb_this_page ; tmp != req; tmp = tmp->wb_this_page) {\n\t\tif (!kref_read(&tmp->wb_kref))\n\t\t\tcontinue;\n\t\tnfs_unlock_and_release_request(tmp);\n\t}\n}\n\n \nstatic int\nnfs_page_group_lock_subreq(struct nfs_page *head, struct nfs_page *subreq)\n{\n\tint ret;\n\n\tif (!kref_get_unless_zero(&subreq->wb_kref))\n\t\treturn 0;\n\twhile (!nfs_lock_request(subreq)) {\n\t\tnfs_page_group_unlock(head);\n\t\tret = nfs_wait_on_request(subreq);\n\t\tif (!ret)\n\t\t\tret = nfs_page_group_lock(head);\n\t\tif (ret < 0) {\n\t\t\tnfs_unroll_locks(head, subreq);\n\t\t\tnfs_release_request(subreq);\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nint nfs_page_group_lock_subrequests(struct nfs_page *head)\n{\n\tstruct nfs_page *subreq;\n\tint ret;\n\n\tret = nfs_page_group_lock(head);\n\tif (ret < 0)\n\t\treturn ret;\n\t \n\tfor (subreq = head->wb_this_page; subreq != head;\n\t\t\tsubreq = subreq->wb_this_page) {\n\t\tret = nfs_page_group_lock_subreq(head, subreq);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tnfs_page_group_unlock(head);\n\treturn 0;\n}\n\n \nint\nnfs_page_set_headlock(struct nfs_page *req)\n{\n\tif (!test_and_set_bit(PG_HEADLOCK, &req->wb_flags))\n\t\treturn 0;\n\n\tset_bit(PG_CONTENDED1, &req->wb_flags);\n\tsmp_mb__after_atomic();\n\treturn wait_on_bit_lock(&req->wb_flags, PG_HEADLOCK,\n\t\t\t\tTASK_UNINTERRUPTIBLE);\n}\n\n \nvoid\nnfs_page_clear_headlock(struct nfs_page *req)\n{\n\tclear_bit_unlock(PG_HEADLOCK, &req->wb_flags);\n\tsmp_mb__after_atomic();\n\tif (!test_bit(PG_CONTENDED1, &req->wb_flags))\n\t\treturn;\n\twake_up_bit(&req->wb_flags, PG_HEADLOCK);\n}\n\n \nint\nnfs_page_group_lock(struct nfs_page *req)\n{\n\tint ret;\n\n\tret = nfs_page_set_headlock(req);\n\tif (ret || req->wb_head == req)\n\t\treturn ret;\n\treturn nfs_page_set_headlock(req->wb_head);\n}\n\n \nvoid\nnfs_page_group_unlock(struct nfs_page *req)\n{\n\tif (req != req->wb_head)\n\t\tnfs_page_clear_headlock(req->wb_head);\n\tnfs_page_clear_headlock(req);\n}\n\n \nstatic bool\nnfs_page_group_sync_on_bit_locked(struct nfs_page *req, unsigned int bit)\n{\n\tstruct nfs_page *head = req->wb_head;\n\tstruct nfs_page *tmp;\n\n\tWARN_ON_ONCE(!test_bit(PG_HEADLOCK, &head->wb_flags));\n\tWARN_ON_ONCE(test_and_set_bit(bit, &req->wb_flags));\n\n\ttmp = req->wb_this_page;\n\twhile (tmp != req) {\n\t\tif (!test_bit(bit, &tmp->wb_flags))\n\t\t\treturn false;\n\t\ttmp = tmp->wb_this_page;\n\t}\n\n\t \n\ttmp = req;\n\tdo {\n\t\tclear_bit(bit, &tmp->wb_flags);\n\t\ttmp = tmp->wb_this_page;\n\t} while (tmp != req);\n\n\treturn true;\n}\n\n \nbool nfs_page_group_sync_on_bit(struct nfs_page *req, unsigned int bit)\n{\n\tbool ret;\n\n\tnfs_page_group_lock(req);\n\tret = nfs_page_group_sync_on_bit_locked(req, bit);\n\tnfs_page_group_unlock(req);\n\n\treturn ret;\n}\n\n \nstatic inline void\nnfs_page_group_init(struct nfs_page *req, struct nfs_page *prev)\n{\n\tstruct inode *inode;\n\tWARN_ON_ONCE(prev == req);\n\n\tif (!prev) {\n\t\t \n\t\treq->wb_head = req;\n\t\treq->wb_this_page = req;\n\t} else {\n\t\t \n\t\tWARN_ON_ONCE(prev->wb_this_page != prev->wb_head);\n\t\tWARN_ON_ONCE(!test_bit(PG_HEADLOCK, &prev->wb_head->wb_flags));\n\t\treq->wb_head = prev->wb_head;\n\t\treq->wb_this_page = prev->wb_this_page;\n\t\tprev->wb_this_page = req;\n\n\t\t \n\t\tkref_get(&req->wb_head->wb_kref);\n\n\t\t \n\t\tif (test_bit(PG_INODE_REF, &prev->wb_head->wb_flags)) {\n\t\t\tinode = nfs_page_to_inode(req);\n\t\t\tset_bit(PG_INODE_REF, &req->wb_flags);\n\t\t\tkref_get(&req->wb_kref);\n\t\t\tatomic_long_inc(&NFS_I(inode)->nrequests);\n\t\t}\n\t}\n}\n\n \nstatic void\nnfs_page_group_destroy(struct kref *kref)\n{\n\tstruct nfs_page *req = container_of(kref, struct nfs_page, wb_kref);\n\tstruct nfs_page *head = req->wb_head;\n\tstruct nfs_page *tmp, *next;\n\n\tif (!nfs_page_group_sync_on_bit(req, PG_TEARDOWN))\n\t\tgoto out;\n\n\ttmp = req;\n\tdo {\n\t\tnext = tmp->wb_this_page;\n\t\t \n\t\ttmp->wb_this_page = tmp;\n\t\ttmp->wb_head = tmp;\n\t\tnfs_free_request(tmp);\n\t\ttmp = next;\n\t} while (tmp != req);\nout:\n\t \n\tif (head != req)\n\t\tnfs_release_request(head);\n}\n\nstatic struct nfs_page *nfs_page_create(struct nfs_lock_context *l_ctx,\n\t\t\t\t\tunsigned int pgbase, pgoff_t index,\n\t\t\t\t\tunsigned int offset, unsigned int count)\n{\n\tstruct nfs_page\t\t*req;\n\tstruct nfs_open_context *ctx = l_ctx->open_context;\n\n\tif (test_bit(NFS_CONTEXT_BAD, &ctx->flags))\n\t\treturn ERR_PTR(-EBADF);\n\t \n\treq = nfs_page_alloc();\n\tif (req == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\treq->wb_lock_context = l_ctx;\n\trefcount_inc(&l_ctx->count);\n\tatomic_inc(&l_ctx->io_count);\n\n\t \n\treq->wb_pgbase = pgbase;\n\treq->wb_index = index;\n\treq->wb_offset = offset;\n\treq->wb_bytes = count;\n\tkref_init(&req->wb_kref);\n\treq->wb_nio = 0;\n\treturn req;\n}\n\nstatic void nfs_page_assign_folio(struct nfs_page *req, struct folio *folio)\n{\n\tif (folio != NULL) {\n\t\treq->wb_folio = folio;\n\t\tfolio_get(folio);\n\t\tset_bit(PG_FOLIO, &req->wb_flags);\n\t}\n}\n\nstatic void nfs_page_assign_page(struct nfs_page *req, struct page *page)\n{\n\tif (page != NULL) {\n\t\treq->wb_page = page;\n\t\tget_page(page);\n\t}\n}\n\n \nstruct nfs_page *nfs_page_create_from_page(struct nfs_open_context *ctx,\n\t\t\t\t\t   struct page *page,\n\t\t\t\t\t   unsigned int pgbase, loff_t offset,\n\t\t\t\t\t   unsigned int count)\n{\n\tstruct nfs_lock_context *l_ctx = nfs_get_lock_context(ctx);\n\tstruct nfs_page *ret;\n\n\tif (IS_ERR(l_ctx))\n\t\treturn ERR_CAST(l_ctx);\n\tret = nfs_page_create(l_ctx, pgbase, offset >> PAGE_SHIFT,\n\t\t\t      offset_in_page(offset), count);\n\tif (!IS_ERR(ret)) {\n\t\tnfs_page_assign_page(ret, page);\n\t\tnfs_page_group_init(ret, NULL);\n\t}\n\tnfs_put_lock_context(l_ctx);\n\treturn ret;\n}\n\n \nstruct nfs_page *nfs_page_create_from_folio(struct nfs_open_context *ctx,\n\t\t\t\t\t    struct folio *folio,\n\t\t\t\t\t    unsigned int offset,\n\t\t\t\t\t    unsigned int count)\n{\n\tstruct nfs_lock_context *l_ctx = nfs_get_lock_context(ctx);\n\tstruct nfs_page *ret;\n\n\tif (IS_ERR(l_ctx))\n\t\treturn ERR_CAST(l_ctx);\n\tret = nfs_page_create(l_ctx, offset, folio_index(folio), offset, count);\n\tif (!IS_ERR(ret)) {\n\t\tnfs_page_assign_folio(ret, folio);\n\t\tnfs_page_group_init(ret, NULL);\n\t}\n\tnfs_put_lock_context(l_ctx);\n\treturn ret;\n}\n\nstatic struct nfs_page *\nnfs_create_subreq(struct nfs_page *req,\n\t\t  unsigned int pgbase,\n\t\t  unsigned int offset,\n\t\t  unsigned int count)\n{\n\tstruct nfs_page *last;\n\tstruct nfs_page *ret;\n\tstruct folio *folio = nfs_page_to_folio(req);\n\tstruct page *page = nfs_page_to_page(req, pgbase);\n\n\tret = nfs_page_create(req->wb_lock_context, pgbase, req->wb_index,\n\t\t\t      offset, count);\n\tif (!IS_ERR(ret)) {\n\t\tif (folio)\n\t\t\tnfs_page_assign_folio(ret, folio);\n\t\telse\n\t\t\tnfs_page_assign_page(ret, page);\n\t\t \n\t\tfor (last = req->wb_head;\n\t\t     last->wb_this_page != req->wb_head;\n\t\t     last = last->wb_this_page)\n\t\t\t;\n\n\t\tnfs_lock_request(ret);\n\t\tnfs_page_group_init(ret, last);\n\t\tret->wb_nio = req->wb_nio;\n\t}\n\treturn ret;\n}\n\n \nvoid nfs_unlock_request(struct nfs_page *req)\n{\n\tclear_bit_unlock(PG_BUSY, &req->wb_flags);\n\tsmp_mb__after_atomic();\n\tif (!test_bit(PG_CONTENDED2, &req->wb_flags))\n\t\treturn;\n\twake_up_bit(&req->wb_flags, PG_BUSY);\n}\n\n \nvoid nfs_unlock_and_release_request(struct nfs_page *req)\n{\n\tnfs_unlock_request(req);\n\tnfs_release_request(req);\n}\n\n \nstatic void nfs_clear_request(struct nfs_page *req)\n{\n\tstruct folio *folio = nfs_page_to_folio(req);\n\tstruct page *page = req->wb_page;\n\tstruct nfs_lock_context *l_ctx = req->wb_lock_context;\n\tstruct nfs_open_context *ctx;\n\n\tif (folio != NULL) {\n\t\tfolio_put(folio);\n\t\treq->wb_folio = NULL;\n\t\tclear_bit(PG_FOLIO, &req->wb_flags);\n\t} else if (page != NULL) {\n\t\tput_page(page);\n\t\treq->wb_page = NULL;\n\t}\n\tif (l_ctx != NULL) {\n\t\tif (atomic_dec_and_test(&l_ctx->io_count)) {\n\t\t\twake_up_var(&l_ctx->io_count);\n\t\t\tctx = l_ctx->open_context;\n\t\t\tif (test_bit(NFS_CONTEXT_UNLOCK, &ctx->flags))\n\t\t\t\trpc_wake_up(&NFS_SERVER(d_inode(ctx->dentry))->uoc_rpcwaitq);\n\t\t}\n\t\tnfs_put_lock_context(l_ctx);\n\t\treq->wb_lock_context = NULL;\n\t}\n}\n\n \nvoid nfs_free_request(struct nfs_page *req)\n{\n\tWARN_ON_ONCE(req->wb_this_page != req);\n\n\t \n\tWARN_ON_ONCE(test_bit(PG_TEARDOWN, &req->wb_flags));\n\tWARN_ON_ONCE(test_bit(PG_UNLOCKPAGE, &req->wb_flags));\n\tWARN_ON_ONCE(test_bit(PG_UPTODATE, &req->wb_flags));\n\tWARN_ON_ONCE(test_bit(PG_WB_END, &req->wb_flags));\n\tWARN_ON_ONCE(test_bit(PG_REMOVE, &req->wb_flags));\n\n\t \n\tnfs_clear_request(req);\n\tnfs_page_free(req);\n}\n\nvoid nfs_release_request(struct nfs_page *req)\n{\n\tkref_put(&req->wb_kref, nfs_page_group_destroy);\n}\nEXPORT_SYMBOL_GPL(nfs_release_request);\n\n \nint\nnfs_wait_on_request(struct nfs_page *req)\n{\n\tif (!test_bit(PG_BUSY, &req->wb_flags))\n\t\treturn 0;\n\tset_bit(PG_CONTENDED2, &req->wb_flags);\n\tsmp_mb__after_atomic();\n\treturn wait_on_bit_io(&req->wb_flags, PG_BUSY,\n\t\t\t      TASK_UNINTERRUPTIBLE);\n}\nEXPORT_SYMBOL_GPL(nfs_wait_on_request);\n\n \nsize_t nfs_generic_pg_test(struct nfs_pageio_descriptor *desc,\n\t\t\t   struct nfs_page *prev, struct nfs_page *req)\n{\n\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\n\n\tif (mirror->pg_count > mirror->pg_bsize) {\n\t\t \n\t\tWARN_ON_ONCE(1);\n\t\treturn 0;\n\t}\n\n\t \n\tif (((mirror->pg_count + req->wb_bytes) >> PAGE_SHIFT) *\n\t\t\tsizeof(struct page *) > PAGE_SIZE)\n\t\treturn 0;\n\n\treturn min(mirror->pg_bsize - mirror->pg_count, (size_t)req->wb_bytes);\n}\nEXPORT_SYMBOL_GPL(nfs_generic_pg_test);\n\nstruct nfs_pgio_header *nfs_pgio_header_alloc(const struct nfs_rw_ops *ops)\n{\n\tstruct nfs_pgio_header *hdr = ops->rw_alloc_header();\n\n\tif (hdr) {\n\t\tINIT_LIST_HEAD(&hdr->pages);\n\t\thdr->rw_ops = ops;\n\t}\n\treturn hdr;\n}\nEXPORT_SYMBOL_GPL(nfs_pgio_header_alloc);\n\n \nstatic void nfs_pgio_data_destroy(struct nfs_pgio_header *hdr)\n{\n\tif (hdr->args.context)\n\t\tput_nfs_open_context(hdr->args.context);\n\tif (hdr->page_array.pagevec != hdr->page_array.page_array)\n\t\tkfree(hdr->page_array.pagevec);\n}\n\n \nvoid nfs_pgio_header_free(struct nfs_pgio_header *hdr)\n{\n\tnfs_pgio_data_destroy(hdr);\n\thdr->rw_ops->rw_free_header(hdr);\n}\nEXPORT_SYMBOL_GPL(nfs_pgio_header_free);\n\n \nstatic void nfs_pgio_rpcsetup(struct nfs_pgio_header *hdr, unsigned int pgbase,\n\t\t\t      unsigned int count, int how,\n\t\t\t      struct nfs_commit_info *cinfo)\n{\n\tstruct nfs_page *req = hdr->req;\n\n\t \n\n\thdr->args.fh     = NFS_FH(hdr->inode);\n\thdr->args.offset = req_offset(req);\n\t \n\thdr->mds_offset = hdr->args.offset;\n\thdr->args.pgbase = pgbase;\n\thdr->args.pages  = hdr->page_array.pagevec;\n\thdr->args.count  = count;\n\thdr->args.context = get_nfs_open_context(nfs_req_openctx(req));\n\thdr->args.lock_context = req->wb_lock_context;\n\thdr->args.stable  = NFS_UNSTABLE;\n\tswitch (how & (FLUSH_STABLE | FLUSH_COND_STABLE)) {\n\tcase 0:\n\t\tbreak;\n\tcase FLUSH_COND_STABLE:\n\t\tif (nfs_reqs_to_commit(cinfo))\n\t\t\tbreak;\n\t\tfallthrough;\n\tdefault:\n\t\thdr->args.stable = NFS_FILE_SYNC;\n\t}\n\n\thdr->res.fattr   = &hdr->fattr;\n\thdr->res.count   = 0;\n\thdr->res.eof     = 0;\n\thdr->res.verf    = &hdr->verf;\n\tnfs_fattr_init(&hdr->fattr);\n}\n\n \nstatic void nfs_pgio_prepare(struct rpc_task *task, void *calldata)\n{\n\tstruct nfs_pgio_header *hdr = calldata;\n\tint err;\n\terr = NFS_PROTO(hdr->inode)->pgio_rpc_prepare(task, hdr);\n\tif (err)\n\t\trpc_exit(task, err);\n}\n\nint nfs_initiate_pgio(struct rpc_clnt *clnt, struct nfs_pgio_header *hdr,\n\t\t      const struct cred *cred, const struct nfs_rpc_ops *rpc_ops,\n\t\t      const struct rpc_call_ops *call_ops, int how, int flags)\n{\n\tstruct rpc_task *task;\n\tstruct rpc_message msg = {\n\t\t.rpc_argp = &hdr->args,\n\t\t.rpc_resp = &hdr->res,\n\t\t.rpc_cred = cred,\n\t};\n\tstruct rpc_task_setup task_setup_data = {\n\t\t.rpc_client = clnt,\n\t\t.task = &hdr->task,\n\t\t.rpc_message = &msg,\n\t\t.callback_ops = call_ops,\n\t\t.callback_data = hdr,\n\t\t.workqueue = nfsiod_workqueue,\n\t\t.flags = RPC_TASK_ASYNC | flags,\n\t};\n\n\tif (nfs_server_capable(hdr->inode, NFS_CAP_MOVEABLE))\n\t\ttask_setup_data.flags |= RPC_TASK_MOVEABLE;\n\n\thdr->rw_ops->rw_initiate(hdr, &msg, rpc_ops, &task_setup_data, how);\n\n\tdprintk(\"NFS: initiated pgio call \"\n\t\t\"(req %s/%llu, %u bytes @ offset %llu)\\n\",\n\t\thdr->inode->i_sb->s_id,\n\t\t(unsigned long long)NFS_FILEID(hdr->inode),\n\t\thdr->args.count,\n\t\t(unsigned long long)hdr->args.offset);\n\n\ttask = rpc_run_task(&task_setup_data);\n\tif (IS_ERR(task))\n\t\treturn PTR_ERR(task);\n\trpc_put_task(task);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nfs_initiate_pgio);\n\n \nstatic void nfs_pgio_error(struct nfs_pgio_header *hdr)\n{\n\tset_bit(NFS_IOHDR_REDO, &hdr->flags);\n\thdr->completion_ops->completion(hdr);\n}\n\n \nstatic void nfs_pgio_release(void *calldata)\n{\n\tstruct nfs_pgio_header *hdr = calldata;\n\thdr->completion_ops->completion(hdr);\n}\n\nstatic void nfs_pageio_mirror_init(struct nfs_pgio_mirror *mirror,\n\t\t\t\t   unsigned int bsize)\n{\n\tINIT_LIST_HEAD(&mirror->pg_list);\n\tmirror->pg_bytes_written = 0;\n\tmirror->pg_count = 0;\n\tmirror->pg_bsize = bsize;\n\tmirror->pg_base = 0;\n\tmirror->pg_recoalesce = 0;\n}\n\n \nvoid nfs_pageio_init(struct nfs_pageio_descriptor *desc,\n\t\t     struct inode *inode,\n\t\t     const struct nfs_pageio_ops *pg_ops,\n\t\t     const struct nfs_pgio_completion_ops *compl_ops,\n\t\t     const struct nfs_rw_ops *rw_ops,\n\t\t     size_t bsize,\n\t\t     int io_flags)\n{\n\tdesc->pg_moreio = 0;\n\tdesc->pg_inode = inode;\n\tdesc->pg_ops = pg_ops;\n\tdesc->pg_completion_ops = compl_ops;\n\tdesc->pg_rw_ops = rw_ops;\n\tdesc->pg_ioflags = io_flags;\n\tdesc->pg_error = 0;\n\tdesc->pg_lseg = NULL;\n\tdesc->pg_io_completion = NULL;\n\tdesc->pg_dreq = NULL;\n\tnfs_netfs_reset_pageio_descriptor(desc);\n\tdesc->pg_bsize = bsize;\n\n\tdesc->pg_mirror_count = 1;\n\tdesc->pg_mirror_idx = 0;\n\n\tdesc->pg_mirrors_dynamic = NULL;\n\tdesc->pg_mirrors = desc->pg_mirrors_static;\n\tnfs_pageio_mirror_init(&desc->pg_mirrors[0], bsize);\n\tdesc->pg_maxretrans = 0;\n}\n\n \nstatic void nfs_pgio_result(struct rpc_task *task, void *calldata)\n{\n\tstruct nfs_pgio_header *hdr = calldata;\n\tstruct inode *inode = hdr->inode;\n\n\tif (hdr->rw_ops->rw_done(task, hdr, inode) != 0)\n\t\treturn;\n\tif (task->tk_status < 0)\n\t\tnfs_set_pgio_error(hdr, task->tk_status, hdr->args.offset);\n\telse\n\t\thdr->rw_ops->rw_result(task, hdr);\n}\n\n \nint nfs_generic_pgio(struct nfs_pageio_descriptor *desc,\n\t\t     struct nfs_pgio_header *hdr)\n{\n\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\n\tstruct nfs_page\t\t*req;\n\tstruct page\t\t**pages,\n\t\t\t\t*last_page;\n\tstruct list_head *head = &mirror->pg_list;\n\tstruct nfs_commit_info cinfo;\n\tstruct nfs_page_array *pg_array = &hdr->page_array;\n\tunsigned int pagecount, pageused;\n\tunsigned int pg_base = offset_in_page(mirror->pg_base);\n\tgfp_t gfp_flags = nfs_io_gfp_mask();\n\n\tpagecount = nfs_page_array_len(pg_base, mirror->pg_count);\n\tpg_array->npages = pagecount;\n\n\tif (pagecount <= ARRAY_SIZE(pg_array->page_array))\n\t\tpg_array->pagevec = pg_array->page_array;\n\telse {\n\t\tpg_array->pagevec = kcalloc(pagecount, sizeof(struct page *), gfp_flags);\n\t\tif (!pg_array->pagevec) {\n\t\t\tpg_array->npages = 0;\n\t\t\tnfs_pgio_error(hdr);\n\t\t\tdesc->pg_error = -ENOMEM;\n\t\t\treturn desc->pg_error;\n\t\t}\n\t}\n\n\tnfs_init_cinfo(&cinfo, desc->pg_inode, desc->pg_dreq);\n\tpages = hdr->page_array.pagevec;\n\tlast_page = NULL;\n\tpageused = 0;\n\twhile (!list_empty(head)) {\n\t\tstruct nfs_page_iter_page i;\n\t\tstruct page *page;\n\n\t\treq = nfs_list_entry(head->next);\n\t\tnfs_list_move_request(req, &hdr->pages);\n\n\t\tif (req->wb_pgbase == 0)\n\t\t\tlast_page = NULL;\n\n\t\tnfs_page_iter_page_init(&i, req);\n\t\twhile ((page = nfs_page_iter_page_get(&i)) != NULL) {\n\t\t\tif (last_page != page) {\n\t\t\t\tpageused++;\n\t\t\t\tif (pageused > pagecount)\n\t\t\t\t\tgoto full;\n\t\t\t\t*pages++ = last_page = page;\n\t\t\t}\n\t\t}\n\t}\nfull:\n\tif (WARN_ON_ONCE(pageused != pagecount)) {\n\t\tnfs_pgio_error(hdr);\n\t\tdesc->pg_error = -EINVAL;\n\t\treturn desc->pg_error;\n\t}\n\n\tif ((desc->pg_ioflags & FLUSH_COND_STABLE) &&\n\t    (desc->pg_moreio || nfs_reqs_to_commit(&cinfo)))\n\t\tdesc->pg_ioflags &= ~FLUSH_COND_STABLE;\n\n\t \n\tnfs_pgio_rpcsetup(hdr, pg_base, mirror->pg_count, desc->pg_ioflags,\n\t\t\t  &cinfo);\n\tdesc->pg_rpc_callops = &nfs_pgio_common_ops;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nfs_generic_pgio);\n\nstatic int nfs_generic_pg_pgios(struct nfs_pageio_descriptor *desc)\n{\n\tstruct nfs_pgio_header *hdr;\n\tint ret;\n\tunsigned short task_flags = 0;\n\n\thdr = nfs_pgio_header_alloc(desc->pg_rw_ops);\n\tif (!hdr) {\n\t\tdesc->pg_error = -ENOMEM;\n\t\treturn desc->pg_error;\n\t}\n\tnfs_pgheader_init(desc, hdr, nfs_pgio_header_free);\n\tret = nfs_generic_pgio(desc, hdr);\n\tif (ret == 0) {\n\t\tif (NFS_SERVER(hdr->inode)->nfs_client->cl_minorversion)\n\t\t\ttask_flags = RPC_TASK_MOVEABLE;\n\t\tret = nfs_initiate_pgio(NFS_CLIENT(hdr->inode),\n\t\t\t\t\thdr,\n\t\t\t\t\thdr->cred,\n\t\t\t\t\tNFS_PROTO(hdr->inode),\n\t\t\t\t\tdesc->pg_rpc_callops,\n\t\t\t\t\tdesc->pg_ioflags,\n\t\t\t\t\tRPC_TASK_CRED_NOREF | task_flags);\n\t}\n\treturn ret;\n}\n\nstatic struct nfs_pgio_mirror *\nnfs_pageio_alloc_mirrors(struct nfs_pageio_descriptor *desc,\n\t\tunsigned int mirror_count)\n{\n\tstruct nfs_pgio_mirror *ret;\n\tunsigned int i;\n\n\tkfree(desc->pg_mirrors_dynamic);\n\tdesc->pg_mirrors_dynamic = NULL;\n\tif (mirror_count == 1)\n\t\treturn desc->pg_mirrors_static;\n\tret = kmalloc_array(mirror_count, sizeof(*ret), nfs_io_gfp_mask());\n\tif (ret != NULL) {\n\t\tfor (i = 0; i < mirror_count; i++)\n\t\t\tnfs_pageio_mirror_init(&ret[i], desc->pg_bsize);\n\t\tdesc->pg_mirrors_dynamic = ret;\n\t}\n\treturn ret;\n}\n\n \nstatic void nfs_pageio_setup_mirroring(struct nfs_pageio_descriptor *pgio,\n\t\t\t\t       struct nfs_page *req)\n{\n\tunsigned int mirror_count = 1;\n\n\tif (pgio->pg_ops->pg_get_mirror_count)\n\t\tmirror_count = pgio->pg_ops->pg_get_mirror_count(pgio, req);\n\tif (mirror_count == pgio->pg_mirror_count || pgio->pg_error < 0)\n\t\treturn;\n\n\tif (!mirror_count || mirror_count > NFS_PAGEIO_DESCRIPTOR_MIRROR_MAX) {\n\t\tpgio->pg_error = -EINVAL;\n\t\treturn;\n\t}\n\n\tpgio->pg_mirrors = nfs_pageio_alloc_mirrors(pgio, mirror_count);\n\tif (pgio->pg_mirrors == NULL) {\n\t\tpgio->pg_error = -ENOMEM;\n\t\tpgio->pg_mirrors = pgio->pg_mirrors_static;\n\t\tmirror_count = 1;\n\t}\n\tpgio->pg_mirror_count = mirror_count;\n}\n\nstatic void nfs_pageio_cleanup_mirroring(struct nfs_pageio_descriptor *pgio)\n{\n\tpgio->pg_mirror_count = 1;\n\tpgio->pg_mirror_idx = 0;\n\tpgio->pg_mirrors = pgio->pg_mirrors_static;\n\tkfree(pgio->pg_mirrors_dynamic);\n\tpgio->pg_mirrors_dynamic = NULL;\n}\n\nstatic bool nfs_match_lock_context(const struct nfs_lock_context *l1,\n\t\tconst struct nfs_lock_context *l2)\n{\n\treturn l1->lockowner == l2->lockowner;\n}\n\nstatic bool nfs_page_is_contiguous(const struct nfs_page *prev,\n\t\t\t\t   const struct nfs_page *req)\n{\n\tsize_t prev_end = prev->wb_pgbase + prev->wb_bytes;\n\n\tif (req_offset(req) != req_offset(prev) + prev->wb_bytes)\n\t\treturn false;\n\tif (req->wb_pgbase == 0)\n\t\treturn prev_end == nfs_page_max_length(prev);\n\tif (req->wb_pgbase == prev_end) {\n\t\tstruct folio *folio = nfs_page_to_folio(req);\n\t\tif (folio)\n\t\t\treturn folio == nfs_page_to_folio(prev);\n\t\treturn req->wb_page == prev->wb_page;\n\t}\n\treturn false;\n}\n\n \nstatic unsigned int nfs_coalesce_size(struct nfs_page *prev,\n\t\t\t\t      struct nfs_page *req,\n\t\t\t\t      struct nfs_pageio_descriptor *pgio)\n{\n\tstruct file_lock_context *flctx;\n\n\tif (prev) {\n\t\tif (!nfs_match_open_context(nfs_req_openctx(req), nfs_req_openctx(prev)))\n\t\t\treturn 0;\n\t\tflctx = locks_inode_context(d_inode(nfs_req_openctx(req)->dentry));\n\t\tif (flctx != NULL &&\n\t\t    !(list_empty_careful(&flctx->flc_posix) &&\n\t\t      list_empty_careful(&flctx->flc_flock)) &&\n\t\t    !nfs_match_lock_context(req->wb_lock_context,\n\t\t\t\t\t    prev->wb_lock_context))\n\t\t\treturn 0;\n\t\tif (!nfs_page_is_contiguous(prev, req))\n\t\t\treturn 0;\n\t}\n\treturn pgio->pg_ops->pg_test(pgio, prev, req);\n}\n\n \nstatic unsigned int\nnfs_pageio_do_add_request(struct nfs_pageio_descriptor *desc,\n\t\tstruct nfs_page *req)\n{\n\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\tstruct nfs_page *prev = NULL;\n\tunsigned int size;\n\n\tif (list_empty(&mirror->pg_list)) {\n\t\tif (desc->pg_ops->pg_init)\n\t\t\tdesc->pg_ops->pg_init(desc, req);\n\t\tif (desc->pg_error < 0)\n\t\t\treturn 0;\n\t\tmirror->pg_base = req->wb_pgbase;\n\t\tmirror->pg_count = 0;\n\t\tmirror->pg_recoalesce = 0;\n\t} else\n\t\tprev = nfs_list_entry(mirror->pg_list.prev);\n\n\tif (desc->pg_maxretrans && req->wb_nio > desc->pg_maxretrans) {\n\t\tif (NFS_SERVER(desc->pg_inode)->flags & NFS_MOUNT_SOFTERR)\n\t\t\tdesc->pg_error = -ETIMEDOUT;\n\t\telse\n\t\t\tdesc->pg_error = -EIO;\n\t\treturn 0;\n\t}\n\n\tsize = nfs_coalesce_size(prev, req, desc);\n\tif (size < req->wb_bytes)\n\t\treturn size;\n\tnfs_list_move_request(req, &mirror->pg_list);\n\tmirror->pg_count += req->wb_bytes;\n\treturn req->wb_bytes;\n}\n\n \nstatic void nfs_pageio_doio(struct nfs_pageio_descriptor *desc)\n{\n\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\n\tif (!list_empty(&mirror->pg_list)) {\n\t\tint error = desc->pg_ops->pg_doio(desc);\n\t\tif (error < 0)\n\t\t\tdesc->pg_error = error;\n\t\tif (list_empty(&mirror->pg_list))\n\t\t\tmirror->pg_bytes_written += mirror->pg_count;\n\t}\n}\n\nstatic void\nnfs_pageio_cleanup_request(struct nfs_pageio_descriptor *desc,\n\t\tstruct nfs_page *req)\n{\n\tLIST_HEAD(head);\n\n\tnfs_list_move_request(req, &head);\n\tdesc->pg_completion_ops->error_cleanup(&head, desc->pg_error);\n}\n\n \nstatic int __nfs_pageio_add_request(struct nfs_pageio_descriptor *desc,\n\t\t\t   struct nfs_page *req)\n{\n\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\tstruct nfs_page *subreq;\n\tunsigned int size, subreq_size;\n\n\tnfs_page_group_lock(req);\n\n\tsubreq = req;\n\tsubreq_size = subreq->wb_bytes;\n\tfor(;;) {\n\t\tsize = nfs_pageio_do_add_request(desc, subreq);\n\t\tif (size == subreq_size) {\n\t\t\t \n\t\t\tif (subreq == req)\n\t\t\t\tbreak;\n\t\t\treq->wb_pgbase += size;\n\t\t\treq->wb_bytes -= size;\n\t\t\treq->wb_offset += size;\n\t\t\tsubreq_size = req->wb_bytes;\n\t\t\tsubreq = req;\n\t\t\tcontinue;\n\t\t}\n\t\tif (WARN_ON_ONCE(subreq != req)) {\n\t\t\tnfs_page_group_unlock(req);\n\t\t\tnfs_pageio_cleanup_request(desc, subreq);\n\t\t\tsubreq = req;\n\t\t\tsubreq_size = req->wb_bytes;\n\t\t\tnfs_page_group_lock(req);\n\t\t}\n\t\tif (!size) {\n\t\t\t \n\t\t\tnfs_page_group_unlock(req);\n\t\t\tdesc->pg_moreio = 1;\n\t\t\tnfs_pageio_doio(desc);\n\t\t\tif (desc->pg_error < 0 || mirror->pg_recoalesce)\n\t\t\t\treturn 0;\n\t\t\t \n\t\t\tnfs_page_group_lock(req);\n\t\t\tcontinue;\n\t\t}\n\t\tsubreq = nfs_create_subreq(req, req->wb_pgbase,\n\t\t\t\treq->wb_offset, size);\n\t\tif (IS_ERR(subreq))\n\t\t\tgoto err_ptr;\n\t\tsubreq_size = size;\n\t}\n\n\tnfs_page_group_unlock(req);\n\treturn 1;\nerr_ptr:\n\tdesc->pg_error = PTR_ERR(subreq);\n\tnfs_page_group_unlock(req);\n\treturn 0;\n}\n\nstatic int nfs_do_recoalesce(struct nfs_pageio_descriptor *desc)\n{\n\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\tLIST_HEAD(head);\n\n\tdo {\n\t\tlist_splice_init(&mirror->pg_list, &head);\n\t\tmirror->pg_recoalesce = 0;\n\n\t\twhile (!list_empty(&head)) {\n\t\t\tstruct nfs_page *req;\n\n\t\t\treq = list_first_entry(&head, struct nfs_page, wb_list);\n\t\t\tif (__nfs_pageio_add_request(desc, req))\n\t\t\t\tcontinue;\n\t\t\tif (desc->pg_error < 0) {\n\t\t\t\tlist_splice_tail(&head, &mirror->pg_list);\n\t\t\t\tmirror->pg_recoalesce = 1;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t} while (mirror->pg_recoalesce);\n\treturn 1;\n}\n\nstatic int nfs_pageio_add_request_mirror(struct nfs_pageio_descriptor *desc,\n\t\tstruct nfs_page *req)\n{\n\tint ret;\n\n\tdo {\n\t\tret = __nfs_pageio_add_request(desc, req);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tif (desc->pg_error < 0)\n\t\t\tbreak;\n\t\tret = nfs_do_recoalesce(desc);\n\t} while (ret);\n\n\treturn ret;\n}\n\nstatic void nfs_pageio_error_cleanup(struct nfs_pageio_descriptor *desc)\n{\n\tu32 midx;\n\tstruct nfs_pgio_mirror *mirror;\n\n\tif (!desc->pg_error)\n\t\treturn;\n\n\tfor (midx = 0; midx < desc->pg_mirror_count; midx++) {\n\t\tmirror = nfs_pgio_get_mirror(desc, midx);\n\t\tdesc->pg_completion_ops->error_cleanup(&mirror->pg_list,\n\t\t\t\tdesc->pg_error);\n\t}\n}\n\nint nfs_pageio_add_request(struct nfs_pageio_descriptor *desc,\n\t\t\t   struct nfs_page *req)\n{\n\tu32 midx;\n\tunsigned int pgbase, offset, bytes;\n\tstruct nfs_page *dupreq;\n\n\tpgbase = req->wb_pgbase;\n\toffset = req->wb_offset;\n\tbytes = req->wb_bytes;\n\n\tnfs_pageio_setup_mirroring(desc, req);\n\tif (desc->pg_error < 0)\n\t\tgoto out_failed;\n\n\t \n\tfor (midx = 1; midx < desc->pg_mirror_count; midx++) {\n\t\tnfs_page_group_lock(req);\n\n\t\tdupreq = nfs_create_subreq(req,\n\t\t\t\tpgbase, offset, bytes);\n\n\t\tnfs_page_group_unlock(req);\n\t\tif (IS_ERR(dupreq)) {\n\t\t\tdesc->pg_error = PTR_ERR(dupreq);\n\t\t\tgoto out_failed;\n\t\t}\n\n\t\tnfs_pgio_set_current_mirror(desc, midx);\n\t\tif (!nfs_pageio_add_request_mirror(desc, dupreq))\n\t\t\tgoto out_cleanup_subreq;\n\t}\n\n\tnfs_pgio_set_current_mirror(desc, 0);\n\tif (!nfs_pageio_add_request_mirror(desc, req))\n\t\tgoto out_failed;\n\n\treturn 1;\n\nout_cleanup_subreq:\n\tnfs_pageio_cleanup_request(desc, dupreq);\nout_failed:\n\tnfs_pageio_error_cleanup(desc);\n\treturn 0;\n}\n\n \nstatic void nfs_pageio_complete_mirror(struct nfs_pageio_descriptor *desc,\n\t\t\t\t       u32 mirror_idx)\n{\n\tstruct nfs_pgio_mirror *mirror;\n\tu32 restore_idx;\n\n\trestore_idx = nfs_pgio_set_current_mirror(desc, mirror_idx);\n\tmirror = nfs_pgio_current_mirror(desc);\n\n\tfor (;;) {\n\t\tnfs_pageio_doio(desc);\n\t\tif (desc->pg_error < 0 || !mirror->pg_recoalesce)\n\t\t\tbreak;\n\t\tif (!nfs_do_recoalesce(desc))\n\t\t\tbreak;\n\t}\n\tnfs_pgio_set_current_mirror(desc, restore_idx);\n}\n\n \nint nfs_pageio_resend(struct nfs_pageio_descriptor *desc,\n\t\t      struct nfs_pgio_header *hdr)\n{\n\tLIST_HEAD(pages);\n\n\tdesc->pg_io_completion = hdr->io_completion;\n\tdesc->pg_dreq = hdr->dreq;\n\tnfs_netfs_set_pageio_descriptor(desc, hdr);\n\tlist_splice_init(&hdr->pages, &pages);\n\twhile (!list_empty(&pages)) {\n\t\tstruct nfs_page *req = nfs_list_entry(pages.next);\n\n\t\tif (!nfs_pageio_add_request(desc, req))\n\t\t\tbreak;\n\t}\n\tnfs_pageio_complete(desc);\n\tif (!list_empty(&pages)) {\n\t\tint err = desc->pg_error < 0 ? desc->pg_error : -EIO;\n\t\thdr->completion_ops->error_cleanup(&pages, err);\n\t\tnfs_set_pgio_error(hdr, err, hdr->io_start);\n\t\treturn err;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nfs_pageio_resend);\n\n \nvoid nfs_pageio_complete(struct nfs_pageio_descriptor *desc)\n{\n\tu32 midx;\n\n\tfor (midx = 0; midx < desc->pg_mirror_count; midx++)\n\t\tnfs_pageio_complete_mirror(desc, midx);\n\n\tif (desc->pg_error < 0)\n\t\tnfs_pageio_error_cleanup(desc);\n\tif (desc->pg_ops->pg_cleanup)\n\t\tdesc->pg_ops->pg_cleanup(desc);\n\tnfs_pageio_cleanup_mirroring(desc);\n}\n\n \nvoid nfs_pageio_cond_complete(struct nfs_pageio_descriptor *desc, pgoff_t index)\n{\n\tstruct nfs_pgio_mirror *mirror;\n\tstruct nfs_page *prev;\n\tstruct folio *folio;\n\tu32 midx;\n\n\tfor (midx = 0; midx < desc->pg_mirror_count; midx++) {\n\t\tmirror = nfs_pgio_get_mirror(desc, midx);\n\t\tif (!list_empty(&mirror->pg_list)) {\n\t\t\tprev = nfs_list_entry(mirror->pg_list.prev);\n\t\t\tfolio = nfs_page_to_folio(prev);\n\t\t\tif (folio) {\n\t\t\t\tif (index == folio_next_index(folio))\n\t\t\t\t\tcontinue;\n\t\t\t} else if (index == prev->wb_index + 1)\n\t\t\t\tcontinue;\n\t\t\tnfs_pageio_complete(desc);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nvoid nfs_pageio_stop_mirroring(struct nfs_pageio_descriptor *pgio)\n{\n\tnfs_pageio_complete(pgio);\n}\n\nint __init nfs_init_nfspagecache(void)\n{\n\tnfs_page_cachep = kmem_cache_create(\"nfs_page\",\n\t\t\t\t\t    sizeof(struct nfs_page),\n\t\t\t\t\t    0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t    NULL);\n\tif (nfs_page_cachep == NULL)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nvoid nfs_destroy_nfspagecache(void)\n{\n\tkmem_cache_destroy(nfs_page_cachep);\n}\n\nstatic const struct rpc_call_ops nfs_pgio_common_ops = {\n\t.rpc_call_prepare = nfs_pgio_prepare,\n\t.rpc_call_done = nfs_pgio_result,\n\t.rpc_release = nfs_pgio_release,\n};\n\nconst struct nfs_pageio_ops nfs_pgio_rw_ops = {\n\t.pg_test = nfs_generic_pg_test,\n\t.pg_doio = nfs_generic_pg_pgios,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}