{
  "module_name": "flexfilelayout.c",
  "hash_id": "83c2c8227d89904f60cb34ea164eb77b6f1a363732e9a744a6182a368c01cd36",
  "original_prompt": "Ingested from linux-6.6.14/fs/nfs/flexfilelayout/flexfilelayout.c",
  "human_readable_source": "\n \n\n#include <linux/nfs_fs.h>\n#include <linux/nfs_mount.h>\n#include <linux/nfs_page.h>\n#include <linux/module.h>\n#include <linux/sched/mm.h>\n\n#include <linux/sunrpc/metrics.h>\n\n#include \"flexfilelayout.h\"\n#include \"../nfs4session.h\"\n#include \"../nfs4idmap.h\"\n#include \"../internal.h\"\n#include \"../delegation.h\"\n#include \"../nfs4trace.h\"\n#include \"../iostat.h\"\n#include \"../nfs.h\"\n#include \"../nfs42.h\"\n\n#define NFSDBG_FACILITY         NFSDBG_PNFS_LD\n\n#define FF_LAYOUT_POLL_RETRY_MAX     (15*HZ)\n#define FF_LAYOUTRETURN_MAXERR 20\n\nenum nfs4_ff_op_type {\n\tNFS4_FF_OP_LAYOUTSTATS,\n\tNFS4_FF_OP_LAYOUTRETURN,\n};\n\nstatic unsigned short io_maxretrans;\n\nstatic const struct pnfs_commit_ops ff_layout_commit_ops;\nstatic void ff_layout_read_record_layoutstats_done(struct rpc_task *task,\n\t\tstruct nfs_pgio_header *hdr);\nstatic int\nff_layout_mirror_prepare_stats(struct pnfs_layout_hdr *lo,\n\t\t\t       struct nfs42_layoutstat_devinfo *devinfo,\n\t\t\t       int dev_limit, enum nfs4_ff_op_type type);\nstatic void ff_layout_encode_ff_layoutupdate(struct xdr_stream *xdr,\n\t\t\t      const struct nfs42_layoutstat_devinfo *devinfo,\n\t\t\t      struct nfs4_ff_layout_mirror *mirror);\n\nstatic struct pnfs_layout_hdr *\nff_layout_alloc_layout_hdr(struct inode *inode, gfp_t gfp_flags)\n{\n\tstruct nfs4_flexfile_layout *ffl;\n\n\tffl = kzalloc(sizeof(*ffl), gfp_flags);\n\tif (ffl) {\n\t\tpnfs_init_ds_commit_info(&ffl->commit_info);\n\t\tINIT_LIST_HEAD(&ffl->error_list);\n\t\tINIT_LIST_HEAD(&ffl->mirrors);\n\t\tffl->last_report_time = ktime_get();\n\t\tffl->commit_info.ops = &ff_layout_commit_ops;\n\t\treturn &ffl->generic_hdr;\n\t} else\n\t\treturn NULL;\n}\n\nstatic void\nff_layout_free_layout_hdr(struct pnfs_layout_hdr *lo)\n{\n\tstruct nfs4_flexfile_layout *ffl = FF_LAYOUT_FROM_HDR(lo);\n\tstruct nfs4_ff_layout_ds_err *err, *n;\n\n\tlist_for_each_entry_safe(err, n, &ffl->error_list, list) {\n\t\tlist_del(&err->list);\n\t\tkfree(err);\n\t}\n\tkfree_rcu(ffl, generic_hdr.plh_rcu);\n}\n\nstatic int decode_pnfs_stateid(struct xdr_stream *xdr, nfs4_stateid *stateid)\n{\n\t__be32 *p;\n\n\tp = xdr_inline_decode(xdr, NFS4_STATEID_SIZE);\n\tif (unlikely(p == NULL))\n\t\treturn -ENOBUFS;\n\tstateid->type = NFS4_PNFS_DS_STATEID_TYPE;\n\tmemcpy(stateid->data, p, NFS4_STATEID_SIZE);\n\tdprintk(\"%s: stateid id= [%x%x%x%x]\\n\", __func__,\n\t\tp[0], p[1], p[2], p[3]);\n\treturn 0;\n}\n\nstatic int decode_deviceid(struct xdr_stream *xdr, struct nfs4_deviceid *devid)\n{\n\t__be32 *p;\n\n\tp = xdr_inline_decode(xdr, NFS4_DEVICEID4_SIZE);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tmemcpy(devid, p, NFS4_DEVICEID4_SIZE);\n\tnfs4_print_deviceid(devid);\n\treturn 0;\n}\n\nstatic int decode_nfs_fh(struct xdr_stream *xdr, struct nfs_fh *fh)\n{\n\t__be32 *p;\n\n\tp = xdr_inline_decode(xdr, 4);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tfh->size = be32_to_cpup(p++);\n\tif (fh->size > NFS_MAXFHSIZE) {\n\t\tprintk(KERN_ERR \"NFS flexfiles: Too big fh received %d\\n\",\n\t\t       fh->size);\n\t\treturn -EOVERFLOW;\n\t}\n\t \n\tp = xdr_inline_decode(xdr, fh->size);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tmemcpy(&fh->data, p, fh->size);\n\tdprintk(\"%s: fh len %d\\n\", __func__, fh->size);\n\n\treturn 0;\n}\n\n \nstatic int\ndecode_name(struct xdr_stream *xdr, u32 *id)\n{\n\t__be32 *p;\n\tint len;\n\n\t \n\tp = xdr_inline_decode(xdr, 4);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tlen = be32_to_cpup(p++);\n\tif (len < 0)\n\t\treturn -EINVAL;\n\n\tdprintk(\"%s: len %u\\n\", __func__, len);\n\n\t \n\tp = xdr_inline_decode(xdr, len);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\n\tif (!nfs_map_string_to_numeric((char *)p, len, id))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic bool ff_mirror_match_fh(const struct nfs4_ff_layout_mirror *m1,\n\t\tconst struct nfs4_ff_layout_mirror *m2)\n{\n\tint i, j;\n\n\tif (m1->fh_versions_cnt != m2->fh_versions_cnt)\n\t\treturn false;\n\tfor (i = 0; i < m1->fh_versions_cnt; i++) {\n\t\tbool found_fh = false;\n\t\tfor (j = 0; j < m2->fh_versions_cnt; j++) {\n\t\t\tif (nfs_compare_fh(&m1->fh_versions[i],\n\t\t\t\t\t&m2->fh_versions[j]) == 0) {\n\t\t\t\tfound_fh = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!found_fh)\n\t\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic struct nfs4_ff_layout_mirror *\nff_layout_add_mirror(struct pnfs_layout_hdr *lo,\n\t\tstruct nfs4_ff_layout_mirror *mirror)\n{\n\tstruct nfs4_flexfile_layout *ff_layout = FF_LAYOUT_FROM_HDR(lo);\n\tstruct nfs4_ff_layout_mirror *pos;\n\tstruct inode *inode = lo->plh_inode;\n\n\tspin_lock(&inode->i_lock);\n\tlist_for_each_entry(pos, &ff_layout->mirrors, mirrors) {\n\t\tif (memcmp(&mirror->devid, &pos->devid, sizeof(pos->devid)) != 0)\n\t\t\tcontinue;\n\t\tif (!ff_mirror_match_fh(mirror, pos))\n\t\t\tcontinue;\n\t\tif (refcount_inc_not_zero(&pos->ref)) {\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\treturn pos;\n\t\t}\n\t}\n\tlist_add(&mirror->mirrors, &ff_layout->mirrors);\n\tmirror->layout = lo;\n\tspin_unlock(&inode->i_lock);\n\treturn mirror;\n}\n\nstatic void\nff_layout_remove_mirror(struct nfs4_ff_layout_mirror *mirror)\n{\n\tstruct inode *inode;\n\tif (mirror->layout == NULL)\n\t\treturn;\n\tinode = mirror->layout->plh_inode;\n\tspin_lock(&inode->i_lock);\n\tlist_del(&mirror->mirrors);\n\tspin_unlock(&inode->i_lock);\n\tmirror->layout = NULL;\n}\n\nstatic struct nfs4_ff_layout_mirror *ff_layout_alloc_mirror(gfp_t gfp_flags)\n{\n\tstruct nfs4_ff_layout_mirror *mirror;\n\n\tmirror = kzalloc(sizeof(*mirror), gfp_flags);\n\tif (mirror != NULL) {\n\t\tspin_lock_init(&mirror->lock);\n\t\trefcount_set(&mirror->ref, 1);\n\t\tINIT_LIST_HEAD(&mirror->mirrors);\n\t}\n\treturn mirror;\n}\n\nstatic void ff_layout_free_mirror(struct nfs4_ff_layout_mirror *mirror)\n{\n\tconst struct cred\t*cred;\n\n\tff_layout_remove_mirror(mirror);\n\tkfree(mirror->fh_versions);\n\tcred = rcu_access_pointer(mirror->ro_cred);\n\tput_cred(cred);\n\tcred = rcu_access_pointer(mirror->rw_cred);\n\tput_cred(cred);\n\tnfs4_ff_layout_put_deviceid(mirror->mirror_ds);\n\tkfree(mirror);\n}\n\nstatic void ff_layout_put_mirror(struct nfs4_ff_layout_mirror *mirror)\n{\n\tif (mirror != NULL && refcount_dec_and_test(&mirror->ref))\n\t\tff_layout_free_mirror(mirror);\n}\n\nstatic void ff_layout_free_mirror_array(struct nfs4_ff_layout_segment *fls)\n{\n\tu32 i;\n\n\tfor (i = 0; i < fls->mirror_array_cnt; i++)\n\t\tff_layout_put_mirror(fls->mirror_array[i]);\n}\n\nstatic void _ff_layout_free_lseg(struct nfs4_ff_layout_segment *fls)\n{\n\tif (fls) {\n\t\tff_layout_free_mirror_array(fls);\n\t\tkfree(fls);\n\t}\n}\n\nstatic bool\nff_lseg_match_mirrors(struct pnfs_layout_segment *l1,\n\t\tstruct pnfs_layout_segment *l2)\n{\n\tconst struct nfs4_ff_layout_segment *fl1 = FF_LAYOUT_LSEG(l1);\n\tconst struct nfs4_ff_layout_segment *fl2 = FF_LAYOUT_LSEG(l1);\n\tu32 i;\n\n\tif (fl1->mirror_array_cnt != fl2->mirror_array_cnt)\n\t\treturn false;\n\tfor (i = 0; i < fl1->mirror_array_cnt; i++) {\n\t\tif (fl1->mirror_array[i] != fl2->mirror_array[i])\n\t\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic bool\nff_lseg_range_is_after(const struct pnfs_layout_range *l1,\n\t\tconst struct pnfs_layout_range *l2)\n{\n\tu64 end1, end2;\n\n\tif (l1->iomode != l2->iomode)\n\t\treturn l1->iomode != IOMODE_READ;\n\tend1 = pnfs_calc_offset_end(l1->offset, l1->length);\n\tend2 = pnfs_calc_offset_end(l2->offset, l2->length);\n\tif (end1 < l2->offset)\n\t\treturn false;\n\tif (end2 < l1->offset)\n\t\treturn true;\n\treturn l2->offset <= l1->offset;\n}\n\nstatic bool\nff_lseg_merge(struct pnfs_layout_segment *new,\n\t\tstruct pnfs_layout_segment *old)\n{\n\tu64 new_end, old_end;\n\n\tif (test_bit(NFS_LSEG_LAYOUTRETURN, &old->pls_flags))\n\t\treturn false;\n\tif (new->pls_range.iomode != old->pls_range.iomode)\n\t\treturn false;\n\told_end = pnfs_calc_offset_end(old->pls_range.offset,\n\t\t\told->pls_range.length);\n\tif (old_end < new->pls_range.offset)\n\t\treturn false;\n\tnew_end = pnfs_calc_offset_end(new->pls_range.offset,\n\t\t\tnew->pls_range.length);\n\tif (new_end < old->pls_range.offset)\n\t\treturn false;\n\tif (!ff_lseg_match_mirrors(new, old))\n\t\treturn false;\n\n\t \n\tif (new_end < old_end)\n\t\tnew_end = old_end;\n\tif (new->pls_range.offset < old->pls_range.offset)\n\t\tnew->pls_range.offset = old->pls_range.offset;\n\tnew->pls_range.length = pnfs_calc_offset_length(new->pls_range.offset,\n\t\t\tnew_end);\n\tif (test_bit(NFS_LSEG_ROC, &old->pls_flags))\n\t\tset_bit(NFS_LSEG_ROC, &new->pls_flags);\n\treturn true;\n}\n\nstatic void\nff_layout_add_lseg(struct pnfs_layout_hdr *lo,\n\t\tstruct pnfs_layout_segment *lseg,\n\t\tstruct list_head *free_me)\n{\n\tpnfs_generic_layout_insert_lseg(lo, lseg,\n\t\t\tff_lseg_range_is_after,\n\t\t\tff_lseg_merge,\n\t\t\tfree_me);\n}\n\nstatic void ff_layout_sort_mirrors(struct nfs4_ff_layout_segment *fls)\n{\n\tint i, j;\n\n\tfor (i = 0; i < fls->mirror_array_cnt - 1; i++) {\n\t\tfor (j = i + 1; j < fls->mirror_array_cnt; j++)\n\t\t\tif (fls->mirror_array[i]->efficiency <\n\t\t\t    fls->mirror_array[j]->efficiency)\n\t\t\t\tswap(fls->mirror_array[i],\n\t\t\t\t     fls->mirror_array[j]);\n\t}\n}\n\nstatic struct pnfs_layout_segment *\nff_layout_alloc_lseg(struct pnfs_layout_hdr *lh,\n\t\t     struct nfs4_layoutget_res *lgr,\n\t\t     gfp_t gfp_flags)\n{\n\tstruct pnfs_layout_segment *ret;\n\tstruct nfs4_ff_layout_segment *fls = NULL;\n\tstruct xdr_stream stream;\n\tstruct xdr_buf buf;\n\tstruct page *scratch;\n\tu64 stripe_unit;\n\tu32 mirror_array_cnt;\n\t__be32 *p;\n\tint i, rc;\n\n\tdprintk(\"--> %s\\n\", __func__);\n\tscratch = alloc_page(gfp_flags);\n\tif (!scratch)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\txdr_init_decode_pages(&stream, &buf, lgr->layoutp->pages,\n\t\t\t      lgr->layoutp->len);\n\txdr_set_scratch_page(&stream, scratch);\n\n\t \n\trc = -EIO;\n\tp = xdr_inline_decode(&stream, 8 + 4);\n\tif (!p)\n\t\tgoto out_err_free;\n\n\tp = xdr_decode_hyper(p, &stripe_unit);\n\tmirror_array_cnt = be32_to_cpup(p++);\n\tdprintk(\"%s: stripe_unit=%llu mirror_array_cnt=%u\\n\", __func__,\n\t\tstripe_unit, mirror_array_cnt);\n\n\tif (mirror_array_cnt > NFS4_FLEXFILE_LAYOUT_MAX_MIRROR_CNT ||\n\t    mirror_array_cnt == 0)\n\t\tgoto out_err_free;\n\n\trc = -ENOMEM;\n\tfls = kzalloc(struct_size(fls, mirror_array, mirror_array_cnt),\n\t\t\tgfp_flags);\n\tif (!fls)\n\t\tgoto out_err_free;\n\n\tfls->mirror_array_cnt = mirror_array_cnt;\n\tfls->stripe_unit = stripe_unit;\n\n\tfor (i = 0; i < fls->mirror_array_cnt; i++) {\n\t\tstruct nfs4_ff_layout_mirror *mirror;\n\t\tstruct cred *kcred;\n\t\tconst struct cred __rcu *cred;\n\t\tkuid_t uid;\n\t\tkgid_t gid;\n\t\tu32 ds_count, fh_count, id;\n\t\tint j;\n\n\t\trc = -EIO;\n\t\tp = xdr_inline_decode(&stream, 4);\n\t\tif (!p)\n\t\t\tgoto out_err_free;\n\t\tds_count = be32_to_cpup(p);\n\n\t\t \n\t\tif (ds_count != 1)\n\t\t\tgoto out_err_free;\n\n\t\tfls->mirror_array[i] = ff_layout_alloc_mirror(gfp_flags);\n\t\tif (fls->mirror_array[i] == NULL) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_err_free;\n\t\t}\n\n\t\tfls->mirror_array[i]->ds_count = ds_count;\n\n\t\t \n\t\trc = decode_deviceid(&stream, &fls->mirror_array[i]->devid);\n\t\tif (rc)\n\t\t\tgoto out_err_free;\n\n\t\t \n\t\trc = -EIO;\n\t\tp = xdr_inline_decode(&stream, 4);\n\t\tif (!p)\n\t\t\tgoto out_err_free;\n\t\tfls->mirror_array[i]->efficiency = be32_to_cpup(p);\n\n\t\t \n\t\trc = decode_pnfs_stateid(&stream, &fls->mirror_array[i]->stateid);\n\t\tif (rc)\n\t\t\tgoto out_err_free;\n\n\t\t \n\t\trc = -EIO;\n\t\tp = xdr_inline_decode(&stream, 4);\n\t\tif (!p)\n\t\t\tgoto out_err_free;\n\t\tfh_count = be32_to_cpup(p);\n\n\t\tfls->mirror_array[i]->fh_versions =\n\t\t\tkcalloc(fh_count, sizeof(struct nfs_fh),\n\t\t\t\tgfp_flags);\n\t\tif (fls->mirror_array[i]->fh_versions == NULL) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_err_free;\n\t\t}\n\n\t\tfor (j = 0; j < fh_count; j++) {\n\t\t\trc = decode_nfs_fh(&stream,\n\t\t\t\t\t   &fls->mirror_array[i]->fh_versions[j]);\n\t\t\tif (rc)\n\t\t\t\tgoto out_err_free;\n\t\t}\n\n\t\tfls->mirror_array[i]->fh_versions_cnt = fh_count;\n\n\t\t \n\t\trc = decode_name(&stream, &id);\n\t\tif (rc)\n\t\t\tgoto out_err_free;\n\n\t\tuid = make_kuid(&init_user_ns, id);\n\n\t\t \n\t\trc = decode_name(&stream, &id);\n\t\tif (rc)\n\t\t\tgoto out_err_free;\n\n\t\tgid = make_kgid(&init_user_ns, id);\n\n\t\tif (gfp_flags & __GFP_FS)\n\t\t\tkcred = prepare_kernel_cred(&init_task);\n\t\telse {\n\t\t\tunsigned int nofs_flags = memalloc_nofs_save();\n\t\t\tkcred = prepare_kernel_cred(&init_task);\n\t\t\tmemalloc_nofs_restore(nofs_flags);\n\t\t}\n\t\trc = -ENOMEM;\n\t\tif (!kcred)\n\t\t\tgoto out_err_free;\n\t\tkcred->fsuid = uid;\n\t\tkcred->fsgid = gid;\n\t\tcred = RCU_INITIALIZER(kcred);\n\n\t\tif (lgr->range.iomode == IOMODE_READ)\n\t\t\trcu_assign_pointer(fls->mirror_array[i]->ro_cred, cred);\n\t\telse\n\t\t\trcu_assign_pointer(fls->mirror_array[i]->rw_cred, cred);\n\n\t\tmirror = ff_layout_add_mirror(lh, fls->mirror_array[i]);\n\t\tif (mirror != fls->mirror_array[i]) {\n\t\t\t \n\t\t\tif (lgr->range.iomode == IOMODE_READ) {\n\t\t\t\tcred = xchg(&mirror->ro_cred, cred);\n\t\t\t\trcu_assign_pointer(fls->mirror_array[i]->ro_cred, cred);\n\t\t\t} else {\n\t\t\t\tcred = xchg(&mirror->rw_cred, cred);\n\t\t\t\trcu_assign_pointer(fls->mirror_array[i]->rw_cred, cred);\n\t\t\t}\n\t\t\tff_layout_free_mirror(fls->mirror_array[i]);\n\t\t\tfls->mirror_array[i] = mirror;\n\t\t}\n\n\t\tdprintk(\"%s: iomode %s uid %u gid %u\\n\", __func__,\n\t\t\tlgr->range.iomode == IOMODE_READ ? \"READ\" : \"RW\",\n\t\t\tfrom_kuid(&init_user_ns, uid),\n\t\t\tfrom_kgid(&init_user_ns, gid));\n\t}\n\n\tp = xdr_inline_decode(&stream, 4);\n\tif (!p)\n\t\tgoto out_sort_mirrors;\n\tfls->flags = be32_to_cpup(p);\n\n\tp = xdr_inline_decode(&stream, 4);\n\tif (!p)\n\t\tgoto out_sort_mirrors;\n\tfor (i=0; i < fls->mirror_array_cnt; i++)\n\t\tfls->mirror_array[i]->report_interval = be32_to_cpup(p);\n\nout_sort_mirrors:\n\tff_layout_sort_mirrors(fls);\n\tret = &fls->generic_hdr;\n\tdprintk(\"<-- %s (success)\\n\", __func__);\nout_free_page:\n\t__free_page(scratch);\n\treturn ret;\nout_err_free:\n\t_ff_layout_free_lseg(fls);\n\tret = ERR_PTR(rc);\n\tdprintk(\"<-- %s (%d)\\n\", __func__, rc);\n\tgoto out_free_page;\n}\n\nstatic void\nff_layout_free_lseg(struct pnfs_layout_segment *lseg)\n{\n\tstruct nfs4_ff_layout_segment *fls = FF_LAYOUT_LSEG(lseg);\n\n\tdprintk(\"--> %s\\n\", __func__);\n\n\tif (lseg->pls_range.iomode == IOMODE_RW) {\n\t\tstruct nfs4_flexfile_layout *ffl;\n\t\tstruct inode *inode;\n\n\t\tffl = FF_LAYOUT_FROM_HDR(lseg->pls_layout);\n\t\tinode = ffl->generic_hdr.plh_inode;\n\t\tspin_lock(&inode->i_lock);\n\t\tpnfs_generic_ds_cinfo_release_lseg(&ffl->commit_info, lseg);\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\t_ff_layout_free_lseg(fls);\n}\n\nstatic void\nnfs4_ff_start_busy_timer(struct nfs4_ff_busy_timer *timer, ktime_t now)\n{\n\t \n\tif (atomic_inc_return(&timer->n_ops) == 1) {\n\t\ttimer->start_time = now;\n\t}\n}\n\nstatic ktime_t\nnfs4_ff_end_busy_timer(struct nfs4_ff_busy_timer *timer, ktime_t now)\n{\n\tktime_t start;\n\n\tif (atomic_dec_return(&timer->n_ops) < 0)\n\t\tWARN_ON_ONCE(1);\n\n\tstart = timer->start_time;\n\ttimer->start_time = now;\n\treturn ktime_sub(now, start);\n}\n\nstatic bool\nnfs4_ff_layoutstat_start_io(struct nfs4_ff_layout_mirror *mirror,\n\t\t\t    struct nfs4_ff_layoutstat *layoutstat,\n\t\t\t    ktime_t now)\n{\n\ts64 report_interval = FF_LAYOUTSTATS_REPORT_INTERVAL;\n\tstruct nfs4_flexfile_layout *ffl = FF_LAYOUT_FROM_HDR(mirror->layout);\n\n\tnfs4_ff_start_busy_timer(&layoutstat->busy_timer, now);\n\tif (!mirror->start_time)\n\t\tmirror->start_time = now;\n\tif (mirror->report_interval != 0)\n\t\treport_interval = (s64)mirror->report_interval * 1000LL;\n\telse if (layoutstats_timer != 0)\n\t\treport_interval = (s64)layoutstats_timer * 1000LL;\n\tif (ktime_to_ms(ktime_sub(now, ffl->last_report_time)) >=\n\t\t\treport_interval) {\n\t\tffl->last_report_time = now;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void\nnfs4_ff_layout_stat_io_update_requested(struct nfs4_ff_layoutstat *layoutstat,\n\t\t__u64 requested)\n{\n\tstruct nfs4_ff_io_stat *iostat = &layoutstat->io_stat;\n\n\tiostat->ops_requested++;\n\tiostat->bytes_requested += requested;\n}\n\nstatic void\nnfs4_ff_layout_stat_io_update_completed(struct nfs4_ff_layoutstat *layoutstat,\n\t\t__u64 requested,\n\t\t__u64 completed,\n\t\tktime_t time_completed,\n\t\tktime_t time_started)\n{\n\tstruct nfs4_ff_io_stat *iostat = &layoutstat->io_stat;\n\tktime_t completion_time = ktime_sub(time_completed, time_started);\n\tktime_t timer;\n\n\tiostat->ops_completed++;\n\tiostat->bytes_completed += completed;\n\tiostat->bytes_not_delivered += requested - completed;\n\n\ttimer = nfs4_ff_end_busy_timer(&layoutstat->busy_timer, time_completed);\n\tiostat->total_busy_time =\n\t\t\tktime_add(iostat->total_busy_time, timer);\n\tiostat->aggregate_completion_time =\n\t\t\tktime_add(iostat->aggregate_completion_time,\n\t\t\t\t\tcompletion_time);\n}\n\nstatic void\nnfs4_ff_layout_stat_io_start_read(struct inode *inode,\n\t\tstruct nfs4_ff_layout_mirror *mirror,\n\t\t__u64 requested, ktime_t now)\n{\n\tbool report;\n\n\tspin_lock(&mirror->lock);\n\treport = nfs4_ff_layoutstat_start_io(mirror, &mirror->read_stat, now);\n\tnfs4_ff_layout_stat_io_update_requested(&mirror->read_stat, requested);\n\tset_bit(NFS4_FF_MIRROR_STAT_AVAIL, &mirror->flags);\n\tspin_unlock(&mirror->lock);\n\n\tif (report)\n\t\tpnfs_report_layoutstat(inode, nfs_io_gfp_mask());\n}\n\nstatic void\nnfs4_ff_layout_stat_io_end_read(struct rpc_task *task,\n\t\tstruct nfs4_ff_layout_mirror *mirror,\n\t\t__u64 requested,\n\t\t__u64 completed)\n{\n\tspin_lock(&mirror->lock);\n\tnfs4_ff_layout_stat_io_update_completed(&mirror->read_stat,\n\t\t\trequested, completed,\n\t\t\tktime_get(), task->tk_start);\n\tset_bit(NFS4_FF_MIRROR_STAT_AVAIL, &mirror->flags);\n\tspin_unlock(&mirror->lock);\n}\n\nstatic void\nnfs4_ff_layout_stat_io_start_write(struct inode *inode,\n\t\tstruct nfs4_ff_layout_mirror *mirror,\n\t\t__u64 requested, ktime_t now)\n{\n\tbool report;\n\n\tspin_lock(&mirror->lock);\n\treport = nfs4_ff_layoutstat_start_io(mirror , &mirror->write_stat, now);\n\tnfs4_ff_layout_stat_io_update_requested(&mirror->write_stat, requested);\n\tset_bit(NFS4_FF_MIRROR_STAT_AVAIL, &mirror->flags);\n\tspin_unlock(&mirror->lock);\n\n\tif (report)\n\t\tpnfs_report_layoutstat(inode, nfs_io_gfp_mask());\n}\n\nstatic void\nnfs4_ff_layout_stat_io_end_write(struct rpc_task *task,\n\t\tstruct nfs4_ff_layout_mirror *mirror,\n\t\t__u64 requested,\n\t\t__u64 completed,\n\t\tenum nfs3_stable_how committed)\n{\n\tif (committed == NFS_UNSTABLE)\n\t\trequested = completed = 0;\n\n\tspin_lock(&mirror->lock);\n\tnfs4_ff_layout_stat_io_update_completed(&mirror->write_stat,\n\t\t\trequested, completed, ktime_get(), task->tk_start);\n\tset_bit(NFS4_FF_MIRROR_STAT_AVAIL, &mirror->flags);\n\tspin_unlock(&mirror->lock);\n}\n\nstatic void\nff_layout_mark_ds_unreachable(struct pnfs_layout_segment *lseg, u32 idx)\n{\n\tstruct nfs4_deviceid_node *devid = FF_LAYOUT_DEVID_NODE(lseg, idx);\n\n\tif (devid)\n\t\tnfs4_mark_deviceid_unavailable(devid);\n}\n\nstatic void\nff_layout_mark_ds_reachable(struct pnfs_layout_segment *lseg, u32 idx)\n{\n\tstruct nfs4_deviceid_node *devid = FF_LAYOUT_DEVID_NODE(lseg, idx);\n\n\tif (devid)\n\t\tnfs4_mark_deviceid_available(devid);\n}\n\nstatic struct nfs4_pnfs_ds *\nff_layout_choose_ds_for_read(struct pnfs_layout_segment *lseg,\n\t\t\t     u32 start_idx, u32 *best_idx,\n\t\t\t     bool check_device)\n{\n\tstruct nfs4_ff_layout_segment *fls = FF_LAYOUT_LSEG(lseg);\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tstruct nfs4_pnfs_ds *ds;\n\tu32 idx;\n\n\t \n\tfor (idx = start_idx; idx < fls->mirror_array_cnt; idx++) {\n\t\tmirror = FF_LAYOUT_COMP(lseg, idx);\n\t\tds = nfs4_ff_layout_prepare_ds(lseg, mirror, false);\n\t\tif (!ds)\n\t\t\tcontinue;\n\n\t\tif (check_device &&\n\t\t    nfs4_test_deviceid_unavailable(&mirror->mirror_ds->id_node))\n\t\t\tcontinue;\n\n\t\t*best_idx = idx;\n\t\treturn ds;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct nfs4_pnfs_ds *\nff_layout_choose_any_ds_for_read(struct pnfs_layout_segment *lseg,\n\t\t\t\t u32 start_idx, u32 *best_idx)\n{\n\treturn ff_layout_choose_ds_for_read(lseg, start_idx, best_idx, false);\n}\n\nstatic struct nfs4_pnfs_ds *\nff_layout_choose_valid_ds_for_read(struct pnfs_layout_segment *lseg,\n\t\t\t\t   u32 start_idx, u32 *best_idx)\n{\n\treturn ff_layout_choose_ds_for_read(lseg, start_idx, best_idx, true);\n}\n\nstatic struct nfs4_pnfs_ds *\nff_layout_choose_best_ds_for_read(struct pnfs_layout_segment *lseg,\n\t\t\t\t  u32 start_idx, u32 *best_idx)\n{\n\tstruct nfs4_pnfs_ds *ds;\n\n\tds = ff_layout_choose_valid_ds_for_read(lseg, start_idx, best_idx);\n\tif (ds)\n\t\treturn ds;\n\treturn ff_layout_choose_any_ds_for_read(lseg, start_idx, best_idx);\n}\n\nstatic struct nfs4_pnfs_ds *\nff_layout_get_ds_for_read(struct nfs_pageio_descriptor *pgio,\n\t\t\t  u32 *best_idx)\n{\n\tstruct pnfs_layout_segment *lseg = pgio->pg_lseg;\n\tstruct nfs4_pnfs_ds *ds;\n\n\tds = ff_layout_choose_best_ds_for_read(lseg, pgio->pg_mirror_idx,\n\t\t\t\t\t       best_idx);\n\tif (ds || !pgio->pg_mirror_idx)\n\t\treturn ds;\n\treturn ff_layout_choose_best_ds_for_read(lseg, 0, best_idx);\n}\n\nstatic void\nff_layout_pg_get_read(struct nfs_pageio_descriptor *pgio,\n\t\t      struct nfs_page *req,\n\t\t      bool strict_iomode)\n{\n\tpnfs_put_lseg(pgio->pg_lseg);\n\tpgio->pg_lseg =\n\t\tpnfs_update_layout(pgio->pg_inode, nfs_req_openctx(req),\n\t\t\t\t   req_offset(req), req->wb_bytes, IOMODE_READ,\n\t\t\t\t   strict_iomode, nfs_io_gfp_mask());\n\tif (IS_ERR(pgio->pg_lseg)) {\n\t\tpgio->pg_error = PTR_ERR(pgio->pg_lseg);\n\t\tpgio->pg_lseg = NULL;\n\t}\n}\n\nstatic void\nff_layout_pg_check_layout(struct nfs_pageio_descriptor *pgio,\n\t\t\t  struct nfs_page *req)\n{\n\tpnfs_generic_pg_check_layout(pgio);\n\tpnfs_generic_pg_check_range(pgio, req);\n}\n\nstatic void\nff_layout_pg_init_read(struct nfs_pageio_descriptor *pgio,\n\t\t\tstruct nfs_page *req)\n{\n\tstruct nfs_pgio_mirror *pgm;\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tstruct nfs4_pnfs_ds *ds;\n\tu32 ds_idx;\n\nretry:\n\tff_layout_pg_check_layout(pgio, req);\n\t \n\tif (!pgio->pg_lseg) {\n\t\tff_layout_pg_get_read(pgio, req, false);\n\t\tif (!pgio->pg_lseg)\n\t\t\tgoto out_nolseg;\n\t}\n\tif (ff_layout_avoid_read_on_rw(pgio->pg_lseg)) {\n\t\tff_layout_pg_get_read(pgio, req, true);\n\t\tif (!pgio->pg_lseg)\n\t\t\tgoto out_nolseg;\n\t}\n\n\tds = ff_layout_get_ds_for_read(pgio, &ds_idx);\n\tif (!ds) {\n\t\tif (!ff_layout_no_fallback_to_mds(pgio->pg_lseg))\n\t\t\tgoto out_mds;\n\t\tpnfs_generic_pg_cleanup(pgio);\n\t\t \n\t\tssleep(1);\n\t\tgoto retry;\n\t}\n\n\tmirror = FF_LAYOUT_COMP(pgio->pg_lseg, ds_idx);\n\tpgm = &pgio->pg_mirrors[0];\n\tpgm->pg_bsize = mirror->mirror_ds->ds_versions[0].rsize;\n\n\tpgio->pg_mirror_idx = ds_idx;\n\n\tif (NFS_SERVER(pgio->pg_inode)->flags &\n\t\t\t(NFS_MOUNT_SOFT|NFS_MOUNT_SOFTERR))\n\t\tpgio->pg_maxretrans = io_maxretrans;\n\treturn;\nout_nolseg:\n\tif (pgio->pg_error < 0)\n\t\treturn;\nout_mds:\n\ttrace_pnfs_mds_fallback_pg_init_read(pgio->pg_inode,\n\t\t\t0, NFS4_MAX_UINT64, IOMODE_READ,\n\t\t\tNFS_I(pgio->pg_inode)->layout,\n\t\t\tpgio->pg_lseg);\n\tpgio->pg_maxretrans = 0;\n\tnfs_pageio_reset_read_mds(pgio);\n}\n\nstatic void\nff_layout_pg_init_write(struct nfs_pageio_descriptor *pgio,\n\t\t\tstruct nfs_page *req)\n{\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tstruct nfs_pgio_mirror *pgm;\n\tstruct nfs4_pnfs_ds *ds;\n\tu32 i;\n\nretry:\n\tff_layout_pg_check_layout(pgio, req);\n\tif (!pgio->pg_lseg) {\n\t\tpgio->pg_lseg =\n\t\t\tpnfs_update_layout(pgio->pg_inode, nfs_req_openctx(req),\n\t\t\t\t\t   req_offset(req), req->wb_bytes,\n\t\t\t\t\t   IOMODE_RW, false, nfs_io_gfp_mask());\n\t\tif (IS_ERR(pgio->pg_lseg)) {\n\t\t\tpgio->pg_error = PTR_ERR(pgio->pg_lseg);\n\t\t\tpgio->pg_lseg = NULL;\n\t\t\treturn;\n\t\t}\n\t}\n\t \n\tif (pgio->pg_lseg == NULL)\n\t\tgoto out_mds;\n\n\t \n\tif (pgio->pg_mirror_count != FF_LAYOUT_MIRROR_COUNT(pgio->pg_lseg))\n\t\tgoto out_eagain;\n\n\tfor (i = 0; i < pgio->pg_mirror_count; i++) {\n\t\tmirror = FF_LAYOUT_COMP(pgio->pg_lseg, i);\n\t\tds = nfs4_ff_layout_prepare_ds(pgio->pg_lseg, mirror, true);\n\t\tif (!ds) {\n\t\t\tif (!ff_layout_no_fallback_to_mds(pgio->pg_lseg))\n\t\t\t\tgoto out_mds;\n\t\t\tpnfs_generic_pg_cleanup(pgio);\n\t\t\t \n\t\t\tssleep(1);\n\t\t\tgoto retry;\n\t\t}\n\t\tpgm = &pgio->pg_mirrors[i];\n\t\tpgm->pg_bsize = mirror->mirror_ds->ds_versions[0].wsize;\n\t}\n\n\tif (NFS_SERVER(pgio->pg_inode)->flags &\n\t\t\t(NFS_MOUNT_SOFT|NFS_MOUNT_SOFTERR))\n\t\tpgio->pg_maxretrans = io_maxretrans;\n\treturn;\nout_eagain:\n\tpnfs_generic_pg_cleanup(pgio);\n\tpgio->pg_error = -EAGAIN;\n\treturn;\nout_mds:\n\ttrace_pnfs_mds_fallback_pg_init_write(pgio->pg_inode,\n\t\t\t0, NFS4_MAX_UINT64, IOMODE_RW,\n\t\t\tNFS_I(pgio->pg_inode)->layout,\n\t\t\tpgio->pg_lseg);\n\tpgio->pg_maxretrans = 0;\n\tnfs_pageio_reset_write_mds(pgio);\n\tpgio->pg_error = -EAGAIN;\n}\n\nstatic unsigned int\nff_layout_pg_get_mirror_count_write(struct nfs_pageio_descriptor *pgio,\n\t\t\t\t    struct nfs_page *req)\n{\n\tif (!pgio->pg_lseg) {\n\t\tpgio->pg_lseg =\n\t\t\tpnfs_update_layout(pgio->pg_inode, nfs_req_openctx(req),\n\t\t\t\t\t   req_offset(req), req->wb_bytes,\n\t\t\t\t\t   IOMODE_RW, false, nfs_io_gfp_mask());\n\t\tif (IS_ERR(pgio->pg_lseg)) {\n\t\t\tpgio->pg_error = PTR_ERR(pgio->pg_lseg);\n\t\t\tpgio->pg_lseg = NULL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\tif (pgio->pg_lseg)\n\t\treturn FF_LAYOUT_MIRROR_COUNT(pgio->pg_lseg);\n\n\ttrace_pnfs_mds_fallback_pg_get_mirror_count(pgio->pg_inode,\n\t\t\t0, NFS4_MAX_UINT64, IOMODE_RW,\n\t\t\tNFS_I(pgio->pg_inode)->layout,\n\t\t\tpgio->pg_lseg);\n\t \n\tnfs_pageio_reset_write_mds(pgio);\nout:\n\treturn 1;\n}\n\nstatic u32\nff_layout_pg_set_mirror_write(struct nfs_pageio_descriptor *desc, u32 idx)\n{\n\tu32 old = desc->pg_mirror_idx;\n\n\tdesc->pg_mirror_idx = idx;\n\treturn old;\n}\n\nstatic struct nfs_pgio_mirror *\nff_layout_pg_get_mirror_write(struct nfs_pageio_descriptor *desc, u32 idx)\n{\n\treturn &desc->pg_mirrors[idx];\n}\n\nstatic const struct nfs_pageio_ops ff_layout_pg_read_ops = {\n\t.pg_init = ff_layout_pg_init_read,\n\t.pg_test = pnfs_generic_pg_test,\n\t.pg_doio = pnfs_generic_pg_readpages,\n\t.pg_cleanup = pnfs_generic_pg_cleanup,\n};\n\nstatic const struct nfs_pageio_ops ff_layout_pg_write_ops = {\n\t.pg_init = ff_layout_pg_init_write,\n\t.pg_test = pnfs_generic_pg_test,\n\t.pg_doio = pnfs_generic_pg_writepages,\n\t.pg_get_mirror_count = ff_layout_pg_get_mirror_count_write,\n\t.pg_cleanup = pnfs_generic_pg_cleanup,\n\t.pg_get_mirror = ff_layout_pg_get_mirror_write,\n\t.pg_set_mirror = ff_layout_pg_set_mirror_write,\n};\n\nstatic void ff_layout_reset_write(struct nfs_pgio_header *hdr, bool retry_pnfs)\n{\n\tstruct rpc_task *task = &hdr->task;\n\n\tpnfs_layoutcommit_inode(hdr->inode, false);\n\n\tif (retry_pnfs) {\n\t\tdprintk(\"%s Reset task %5u for i/o through pNFS \"\n\t\t\t\"(req %s/%llu, %u bytes @ offset %llu)\\n\", __func__,\n\t\t\thdr->task.tk_pid,\n\t\t\thdr->inode->i_sb->s_id,\n\t\t\t(unsigned long long)NFS_FILEID(hdr->inode),\n\t\t\thdr->args.count,\n\t\t\t(unsigned long long)hdr->args.offset);\n\n\t\thdr->completion_ops->reschedule_io(hdr);\n\t\treturn;\n\t}\n\n\tif (!test_and_set_bit(NFS_IOHDR_REDO, &hdr->flags)) {\n\t\tdprintk(\"%s Reset task %5u for i/o through MDS \"\n\t\t\t\"(req %s/%llu, %u bytes @ offset %llu)\\n\", __func__,\n\t\t\thdr->task.tk_pid,\n\t\t\thdr->inode->i_sb->s_id,\n\t\t\t(unsigned long long)NFS_FILEID(hdr->inode),\n\t\t\thdr->args.count,\n\t\t\t(unsigned long long)hdr->args.offset);\n\n\t\ttrace_pnfs_mds_fallback_write_done(hdr->inode,\n\t\t\t\thdr->args.offset, hdr->args.count,\n\t\t\t\tIOMODE_RW, NFS_I(hdr->inode)->layout,\n\t\t\t\thdr->lseg);\n\t\ttask->tk_status = pnfs_write_done_resend_to_mds(hdr);\n\t}\n}\n\nstatic void ff_layout_resend_pnfs_read(struct nfs_pgio_header *hdr)\n{\n\tu32 idx = hdr->pgio_mirror_idx + 1;\n\tu32 new_idx = 0;\n\n\tif (ff_layout_choose_any_ds_for_read(hdr->lseg, idx, &new_idx))\n\t\tff_layout_send_layouterror(hdr->lseg);\n\telse\n\t\tpnfs_error_mark_layout_for_return(hdr->inode, hdr->lseg);\n\tpnfs_read_resend_pnfs(hdr, new_idx);\n}\n\nstatic void ff_layout_reset_read(struct nfs_pgio_header *hdr)\n{\n\tstruct rpc_task *task = &hdr->task;\n\n\tpnfs_layoutcommit_inode(hdr->inode, false);\n\tpnfs_error_mark_layout_for_return(hdr->inode, hdr->lseg);\n\n\tif (!test_and_set_bit(NFS_IOHDR_REDO, &hdr->flags)) {\n\t\tdprintk(\"%s Reset task %5u for i/o through MDS \"\n\t\t\t\"(req %s/%llu, %u bytes @ offset %llu)\\n\", __func__,\n\t\t\thdr->task.tk_pid,\n\t\t\thdr->inode->i_sb->s_id,\n\t\t\t(unsigned long long)NFS_FILEID(hdr->inode),\n\t\t\thdr->args.count,\n\t\t\t(unsigned long long)hdr->args.offset);\n\n\t\ttrace_pnfs_mds_fallback_read_done(hdr->inode,\n\t\t\t\thdr->args.offset, hdr->args.count,\n\t\t\t\tIOMODE_READ, NFS_I(hdr->inode)->layout,\n\t\t\t\thdr->lseg);\n\t\ttask->tk_status = pnfs_read_done_resend_to_mds(hdr);\n\t}\n}\n\nstatic int ff_layout_async_handle_error_v4(struct rpc_task *task,\n\t\t\t\t\t   struct nfs4_state *state,\n\t\t\t\t\t   struct nfs_client *clp,\n\t\t\t\t\t   struct pnfs_layout_segment *lseg,\n\t\t\t\t\t   u32 idx)\n{\n\tstruct pnfs_layout_hdr *lo = lseg->pls_layout;\n\tstruct inode *inode = lo->plh_inode;\n\tstruct nfs4_deviceid_node *devid = FF_LAYOUT_DEVID_NODE(lseg, idx);\n\tstruct nfs4_slot_table *tbl = &clp->cl_session->fc_slot_table;\n\n\tswitch (task->tk_status) {\n\tcase -NFS4ERR_BADSESSION:\n\tcase -NFS4ERR_BADSLOT:\n\tcase -NFS4ERR_BAD_HIGH_SLOT:\n\tcase -NFS4ERR_DEADSESSION:\n\tcase -NFS4ERR_CONN_NOT_BOUND_TO_SESSION:\n\tcase -NFS4ERR_SEQ_FALSE_RETRY:\n\tcase -NFS4ERR_SEQ_MISORDERED:\n\t\tdprintk(\"%s ERROR %d, Reset session. Exchangeid \"\n\t\t\t\"flags 0x%x\\n\", __func__, task->tk_status,\n\t\t\tclp->cl_exchange_flags);\n\t\tnfs4_schedule_session_recovery(clp->cl_session, task->tk_status);\n\t\tbreak;\n\tcase -NFS4ERR_DELAY:\n\tcase -NFS4ERR_GRACE:\n\t\trpc_delay(task, FF_LAYOUT_POLL_RETRY_MAX);\n\t\tbreak;\n\tcase -NFS4ERR_RETRY_UNCACHED_REP:\n\t\tbreak;\n\t \n\tcase -NFS4ERR_PNFS_NO_LAYOUT:\n\tcase -ESTALE:            \n\tcase -EBADHANDLE:        \n\tcase -EISDIR:            \n\tcase -NFS4ERR_FHEXPIRED:\n\tcase -NFS4ERR_WRONG_TYPE:\n\t\tdprintk(\"%s Invalid layout error %d\\n\", __func__,\n\t\t\ttask->tk_status);\n\t\t \n\t\tpnfs_destroy_layout(NFS_I(inode));\n\t\trpc_wake_up(&tbl->slot_tbl_waitq);\n\t\tgoto reset;\n\t \n\tcase -ECONNREFUSED:\n\tcase -EHOSTDOWN:\n\tcase -EHOSTUNREACH:\n\tcase -ENETUNREACH:\n\tcase -EIO:\n\tcase -ETIMEDOUT:\n\tcase -EPIPE:\n\tcase -EPROTO:\n\tcase -ENODEV:\n\t\tdprintk(\"%s DS connection error %d\\n\", __func__,\n\t\t\ttask->tk_status);\n\t\tnfs4_delete_deviceid(devid->ld, devid->nfs_client,\n\t\t\t\t&devid->deviceid);\n\t\trpc_wake_up(&tbl->slot_tbl_waitq);\n\t\tfallthrough;\n\tdefault:\n\t\tif (ff_layout_avoid_mds_available_ds(lseg))\n\t\t\treturn -NFS4ERR_RESET_TO_PNFS;\nreset:\n\t\tdprintk(\"%s Retry through MDS. Error %d\\n\", __func__,\n\t\t\ttask->tk_status);\n\t\treturn -NFS4ERR_RESET_TO_MDS;\n\t}\n\ttask->tk_status = 0;\n\treturn -EAGAIN;\n}\n\n \nstatic int ff_layout_async_handle_error_v3(struct rpc_task *task,\n\t\t\t\t\t   struct pnfs_layout_segment *lseg,\n\t\t\t\t\t   u32 idx)\n{\n\tstruct nfs4_deviceid_node *devid = FF_LAYOUT_DEVID_NODE(lseg, idx);\n\n\tswitch (task->tk_status) {\n\t \n\tcase -EACCES:\n\tcase -ESTALE:\n\tcase -EISDIR:\n\tcase -EBADHANDLE:\n\tcase -ELOOP:\n\tcase -ENOSPC:\n\t\tbreak;\n\tcase -EJUKEBOX:\n\t\tnfs_inc_stats(lseg->pls_layout->plh_inode, NFSIOS_DELAY);\n\t\tgoto out_retry;\n\tdefault:\n\t\tdprintk(\"%s DS connection error %d\\n\", __func__,\n\t\t\ttask->tk_status);\n\t\tnfs4_delete_deviceid(devid->ld, devid->nfs_client,\n\t\t\t\t&devid->deviceid);\n\t}\n\t \n\treturn -NFS4ERR_RESET_TO_PNFS;\nout_retry:\n\ttask->tk_status = 0;\n\trpc_restart_call_prepare(task);\n\trpc_delay(task, NFS_JUKEBOX_RETRY_TIME);\n\treturn -EAGAIN;\n}\n\nstatic int ff_layout_async_handle_error(struct rpc_task *task,\n\t\t\t\t\tstruct nfs4_state *state,\n\t\t\t\t\tstruct nfs_client *clp,\n\t\t\t\t\tstruct pnfs_layout_segment *lseg,\n\t\t\t\t\tu32 idx)\n{\n\tint vers = clp->cl_nfs_mod->rpc_vers->number;\n\n\tif (task->tk_status >= 0) {\n\t\tff_layout_mark_ds_reachable(lseg, idx);\n\t\treturn 0;\n\t}\n\n\t \n\tif (!pnfs_is_valid_lseg(lseg))\n\t\treturn -NFS4ERR_RESET_TO_PNFS;\n\n\tswitch (vers) {\n\tcase 3:\n\t\treturn ff_layout_async_handle_error_v3(task, lseg, idx);\n\tcase 4:\n\t\treturn ff_layout_async_handle_error_v4(task, state, clp,\n\t\t\t\t\t\t       lseg, idx);\n\tdefault:\n\t\t \n\t\tWARN_ON_ONCE(1);\n\t\treturn 0;\n\t}\n}\n\nstatic void ff_layout_io_track_ds_error(struct pnfs_layout_segment *lseg,\n\t\t\t\t\tu32 idx, u64 offset, u64 length,\n\t\t\t\t\tu32 *op_status, int opnum, int error)\n{\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tu32 status = *op_status;\n\tint err;\n\n\tif (status == 0) {\n\t\tswitch (error) {\n\t\tcase -ETIMEDOUT:\n\t\tcase -EPFNOSUPPORT:\n\t\tcase -EPROTONOSUPPORT:\n\t\tcase -EOPNOTSUPP:\n\t\tcase -EINVAL:\n\t\tcase -ECONNREFUSED:\n\t\tcase -ECONNRESET:\n\t\tcase -EHOSTDOWN:\n\t\tcase -EHOSTUNREACH:\n\t\tcase -ENETUNREACH:\n\t\tcase -EADDRINUSE:\n\t\tcase -ENOBUFS:\n\t\tcase -EPIPE:\n\t\tcase -EPERM:\n\t\tcase -EPROTO:\n\t\tcase -ENODEV:\n\t\t\t*op_status = status = NFS4ERR_NXIO;\n\t\t\tbreak;\n\t\tcase -EACCES:\n\t\t\t*op_status = status = NFS4ERR_ACCESS;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn;\n\t\t}\n\t}\n\n\tmirror = FF_LAYOUT_COMP(lseg, idx);\n\terr = ff_layout_track_ds_error(FF_LAYOUT_FROM_HDR(lseg->pls_layout),\n\t\t\t\t       mirror, offset, length, status, opnum,\n\t\t\t\t       nfs_io_gfp_mask());\n\n\tswitch (status) {\n\tcase NFS4ERR_DELAY:\n\tcase NFS4ERR_GRACE:\n\t\tbreak;\n\tcase NFS4ERR_NXIO:\n\t\tff_layout_mark_ds_unreachable(lseg, idx);\n\t\t \n\t\tif (opnum == OP_READ)\n\t\t\tbreak;\n\t\tfallthrough;\n\tdefault:\n\t\tpnfs_error_mark_layout_for_return(lseg->pls_layout->plh_inode,\n\t\t\t\t\t\t  lseg);\n\t}\n\n\tdprintk(\"%s: err %d op %d status %u\\n\", __func__, err, opnum, status);\n}\n\n \nstatic int ff_layout_read_done_cb(struct rpc_task *task,\n\t\t\t\tstruct nfs_pgio_header *hdr)\n{\n\tint err;\n\n\tif (task->tk_status < 0) {\n\t\tff_layout_io_track_ds_error(hdr->lseg, hdr->pgio_mirror_idx,\n\t\t\t\t\t    hdr->args.offset, hdr->args.count,\n\t\t\t\t\t    &hdr->res.op_status, OP_READ,\n\t\t\t\t\t    task->tk_status);\n\t\ttrace_ff_layout_read_error(hdr);\n\t}\n\n\terr = ff_layout_async_handle_error(task, hdr->args.context->state,\n\t\t\t\t\t   hdr->ds_clp, hdr->lseg,\n\t\t\t\t\t   hdr->pgio_mirror_idx);\n\n\ttrace_nfs4_pnfs_read(hdr, err);\n\tclear_bit(NFS_IOHDR_RESEND_PNFS, &hdr->flags);\n\tclear_bit(NFS_IOHDR_RESEND_MDS, &hdr->flags);\n\tswitch (err) {\n\tcase -NFS4ERR_RESET_TO_PNFS:\n\t\tset_bit(NFS_IOHDR_RESEND_PNFS, &hdr->flags);\n\t\treturn task->tk_status;\n\tcase -NFS4ERR_RESET_TO_MDS:\n\t\tset_bit(NFS_IOHDR_RESEND_MDS, &hdr->flags);\n\t\treturn task->tk_status;\n\tcase -EAGAIN:\n\t\tgoto out_eagain;\n\t}\n\n\treturn 0;\nout_eagain:\n\trpc_restart_call_prepare(task);\n\treturn -EAGAIN;\n}\n\nstatic bool\nff_layout_need_layoutcommit(struct pnfs_layout_segment *lseg)\n{\n\treturn !(FF_LAYOUT_LSEG(lseg)->flags & FF_FLAGS_NO_LAYOUTCOMMIT);\n}\n\n \nstatic void\nff_layout_set_layoutcommit(struct inode *inode,\n\t\tstruct pnfs_layout_segment *lseg,\n\t\tloff_t end_offset)\n{\n\tif (!ff_layout_need_layoutcommit(lseg))\n\t\treturn;\n\n\tpnfs_set_layoutcommit(inode, lseg, end_offset);\n\tdprintk(\"%s inode %lu pls_end_pos %llu\\n\", __func__, inode->i_ino,\n\t\t(unsigned long long) NFS_I(inode)->layout->plh_lwb);\n}\n\nstatic void ff_layout_read_record_layoutstats_start(struct rpc_task *task,\n\t\tstruct nfs_pgio_header *hdr)\n{\n\tif (test_and_set_bit(NFS_IOHDR_STAT, &hdr->flags))\n\t\treturn;\n\tnfs4_ff_layout_stat_io_start_read(hdr->inode,\n\t\t\tFF_LAYOUT_COMP(hdr->lseg, hdr->pgio_mirror_idx),\n\t\t\thdr->args.count,\n\t\t\ttask->tk_start);\n}\n\nstatic void ff_layout_read_record_layoutstats_done(struct rpc_task *task,\n\t\tstruct nfs_pgio_header *hdr)\n{\n\tif (!test_and_clear_bit(NFS_IOHDR_STAT, &hdr->flags))\n\t\treturn;\n\tnfs4_ff_layout_stat_io_end_read(task,\n\t\t\tFF_LAYOUT_COMP(hdr->lseg, hdr->pgio_mirror_idx),\n\t\t\thdr->args.count,\n\t\t\thdr->res.count);\n\tset_bit(NFS_LSEG_LAYOUTRETURN, &hdr->lseg->pls_flags);\n}\n\nstatic int ff_layout_read_prepare_common(struct rpc_task *task,\n\t\t\t\t\t struct nfs_pgio_header *hdr)\n{\n\tif (unlikely(test_bit(NFS_CONTEXT_BAD, &hdr->args.context->flags))) {\n\t\trpc_exit(task, -EIO);\n\t\treturn -EIO;\n\t}\n\n\tif (!pnfs_is_valid_lseg(hdr->lseg)) {\n\t\trpc_exit(task, -EAGAIN);\n\t\treturn -EAGAIN;\n\t}\n\n\tff_layout_read_record_layoutstats_start(task, hdr);\n\treturn 0;\n}\n\n \nstatic void ff_layout_read_prepare_v3(struct rpc_task *task, void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\tif (ff_layout_read_prepare_common(task, hdr))\n\t\treturn;\n\n\trpc_call_start(task);\n}\n\nstatic void ff_layout_read_prepare_v4(struct rpc_task *task, void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\tif (nfs4_setup_sequence(hdr->ds_clp,\n\t\t\t\t&hdr->args.seq_args,\n\t\t\t\t&hdr->res.seq_res,\n\t\t\t\ttask))\n\t\treturn;\n\n\tff_layout_read_prepare_common(task, hdr);\n}\n\nstatic void ff_layout_read_call_done(struct rpc_task *task, void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\tif (test_bit(NFS_IOHDR_REDO, &hdr->flags) &&\n\t    task->tk_status == 0) {\n\t\tnfs4_sequence_done(task, &hdr->res.seq_res);\n\t\treturn;\n\t}\n\n\t \n\thdr->mds_ops->rpc_call_done(task, hdr);\n}\n\nstatic void ff_layout_read_count_stats(struct rpc_task *task, void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\tff_layout_read_record_layoutstats_done(task, hdr);\n\trpc_count_iostats_metrics(task,\n\t    &NFS_CLIENT(hdr->inode)->cl_metrics[NFSPROC4_CLNT_READ]);\n}\n\nstatic void ff_layout_read_release(void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\tff_layout_read_record_layoutstats_done(&hdr->task, hdr);\n\tif (test_bit(NFS_IOHDR_RESEND_PNFS, &hdr->flags))\n\t\tff_layout_resend_pnfs_read(hdr);\n\telse if (test_bit(NFS_IOHDR_RESEND_MDS, &hdr->flags))\n\t\tff_layout_reset_read(hdr);\n\tpnfs_generic_rw_release(data);\n}\n\n\nstatic int ff_layout_write_done_cb(struct rpc_task *task,\n\t\t\t\tstruct nfs_pgio_header *hdr)\n{\n\tloff_t end_offs = 0;\n\tint err;\n\n\tif (task->tk_status < 0) {\n\t\tff_layout_io_track_ds_error(hdr->lseg, hdr->pgio_mirror_idx,\n\t\t\t\t\t    hdr->args.offset, hdr->args.count,\n\t\t\t\t\t    &hdr->res.op_status, OP_WRITE,\n\t\t\t\t\t    task->tk_status);\n\t\ttrace_ff_layout_write_error(hdr);\n\t}\n\n\terr = ff_layout_async_handle_error(task, hdr->args.context->state,\n\t\t\t\t\t   hdr->ds_clp, hdr->lseg,\n\t\t\t\t\t   hdr->pgio_mirror_idx);\n\n\ttrace_nfs4_pnfs_write(hdr, err);\n\tclear_bit(NFS_IOHDR_RESEND_PNFS, &hdr->flags);\n\tclear_bit(NFS_IOHDR_RESEND_MDS, &hdr->flags);\n\tswitch (err) {\n\tcase -NFS4ERR_RESET_TO_PNFS:\n\t\tset_bit(NFS_IOHDR_RESEND_PNFS, &hdr->flags);\n\t\treturn task->tk_status;\n\tcase -NFS4ERR_RESET_TO_MDS:\n\t\tset_bit(NFS_IOHDR_RESEND_MDS, &hdr->flags);\n\t\treturn task->tk_status;\n\tcase -EAGAIN:\n\t\treturn -EAGAIN;\n\t}\n\n\tif (hdr->res.verf->committed == NFS_FILE_SYNC ||\n\t    hdr->res.verf->committed == NFS_DATA_SYNC)\n\t\tend_offs = hdr->mds_offset + (loff_t)hdr->res.count;\n\n\t \n\tff_layout_set_layoutcommit(hdr->inode, hdr->lseg, end_offs);\n\n\t \n\thdr->fattr.valid = 0;\n\tif (task->tk_status >= 0)\n\t\tnfs_writeback_update_inode(hdr);\n\n\treturn 0;\n}\n\nstatic int ff_layout_commit_done_cb(struct rpc_task *task,\n\t\t\t\t     struct nfs_commit_data *data)\n{\n\tint err;\n\n\tif (task->tk_status < 0) {\n\t\tff_layout_io_track_ds_error(data->lseg, data->ds_commit_index,\n\t\t\t\t\t    data->args.offset, data->args.count,\n\t\t\t\t\t    &data->res.op_status, OP_COMMIT,\n\t\t\t\t\t    task->tk_status);\n\t\ttrace_ff_layout_commit_error(data);\n\t}\n\n\terr = ff_layout_async_handle_error(task, NULL, data->ds_clp,\n\t\t\t\t\t   data->lseg, data->ds_commit_index);\n\n\ttrace_nfs4_pnfs_commit_ds(data, err);\n\tswitch (err) {\n\tcase -NFS4ERR_RESET_TO_PNFS:\n\t\tpnfs_generic_prepare_to_resend_writes(data);\n\t\treturn -EAGAIN;\n\tcase -NFS4ERR_RESET_TO_MDS:\n\t\tpnfs_generic_prepare_to_resend_writes(data);\n\t\treturn -EAGAIN;\n\tcase -EAGAIN:\n\t\trpc_restart_call_prepare(task);\n\t\treturn -EAGAIN;\n\t}\n\n\tff_layout_set_layoutcommit(data->inode, data->lseg, data->lwb);\n\n\treturn 0;\n}\n\nstatic void ff_layout_write_record_layoutstats_start(struct rpc_task *task,\n\t\tstruct nfs_pgio_header *hdr)\n{\n\tif (test_and_set_bit(NFS_IOHDR_STAT, &hdr->flags))\n\t\treturn;\n\tnfs4_ff_layout_stat_io_start_write(hdr->inode,\n\t\t\tFF_LAYOUT_COMP(hdr->lseg, hdr->pgio_mirror_idx),\n\t\t\thdr->args.count,\n\t\t\ttask->tk_start);\n}\n\nstatic void ff_layout_write_record_layoutstats_done(struct rpc_task *task,\n\t\tstruct nfs_pgio_header *hdr)\n{\n\tif (!test_and_clear_bit(NFS_IOHDR_STAT, &hdr->flags))\n\t\treturn;\n\tnfs4_ff_layout_stat_io_end_write(task,\n\t\t\tFF_LAYOUT_COMP(hdr->lseg, hdr->pgio_mirror_idx),\n\t\t\thdr->args.count, hdr->res.count,\n\t\t\thdr->res.verf->committed);\n\tset_bit(NFS_LSEG_LAYOUTRETURN, &hdr->lseg->pls_flags);\n}\n\nstatic int ff_layout_write_prepare_common(struct rpc_task *task,\n\t\t\t\t\t  struct nfs_pgio_header *hdr)\n{\n\tif (unlikely(test_bit(NFS_CONTEXT_BAD, &hdr->args.context->flags))) {\n\t\trpc_exit(task, -EIO);\n\t\treturn -EIO;\n\t}\n\n\tif (!pnfs_is_valid_lseg(hdr->lseg)) {\n\t\trpc_exit(task, -EAGAIN);\n\t\treturn -EAGAIN;\n\t}\n\n\tff_layout_write_record_layoutstats_start(task, hdr);\n\treturn 0;\n}\n\nstatic void ff_layout_write_prepare_v3(struct rpc_task *task, void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\tif (ff_layout_write_prepare_common(task, hdr))\n\t\treturn;\n\n\trpc_call_start(task);\n}\n\nstatic void ff_layout_write_prepare_v4(struct rpc_task *task, void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\tif (nfs4_setup_sequence(hdr->ds_clp,\n\t\t\t\t&hdr->args.seq_args,\n\t\t\t\t&hdr->res.seq_res,\n\t\t\t\ttask))\n\t\treturn;\n\n\tff_layout_write_prepare_common(task, hdr);\n}\n\nstatic void ff_layout_write_call_done(struct rpc_task *task, void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\tif (test_bit(NFS_IOHDR_REDO, &hdr->flags) &&\n\t    task->tk_status == 0) {\n\t\tnfs4_sequence_done(task, &hdr->res.seq_res);\n\t\treturn;\n\t}\n\n\t \n\thdr->mds_ops->rpc_call_done(task, hdr);\n}\n\nstatic void ff_layout_write_count_stats(struct rpc_task *task, void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\tff_layout_write_record_layoutstats_done(task, hdr);\n\trpc_count_iostats_metrics(task,\n\t    &NFS_CLIENT(hdr->inode)->cl_metrics[NFSPROC4_CLNT_WRITE]);\n}\n\nstatic void ff_layout_write_release(void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\tff_layout_write_record_layoutstats_done(&hdr->task, hdr);\n\tif (test_bit(NFS_IOHDR_RESEND_PNFS, &hdr->flags)) {\n\t\tff_layout_send_layouterror(hdr->lseg);\n\t\tff_layout_reset_write(hdr, true);\n\t} else if (test_bit(NFS_IOHDR_RESEND_MDS, &hdr->flags))\n\t\tff_layout_reset_write(hdr, false);\n\tpnfs_generic_rw_release(data);\n}\n\nstatic void ff_layout_commit_record_layoutstats_start(struct rpc_task *task,\n\t\tstruct nfs_commit_data *cdata)\n{\n\tif (test_and_set_bit(NFS_IOHDR_STAT, &cdata->flags))\n\t\treturn;\n\tnfs4_ff_layout_stat_io_start_write(cdata->inode,\n\t\t\tFF_LAYOUT_COMP(cdata->lseg, cdata->ds_commit_index),\n\t\t\t0, task->tk_start);\n}\n\nstatic void ff_layout_commit_record_layoutstats_done(struct rpc_task *task,\n\t\tstruct nfs_commit_data *cdata)\n{\n\tstruct nfs_page *req;\n\t__u64 count = 0;\n\n\tif (!test_and_clear_bit(NFS_IOHDR_STAT, &cdata->flags))\n\t\treturn;\n\n\tif (task->tk_status == 0) {\n\t\tlist_for_each_entry(req, &cdata->pages, wb_list)\n\t\t\tcount += req->wb_bytes;\n\t}\n\tnfs4_ff_layout_stat_io_end_write(task,\n\t\t\tFF_LAYOUT_COMP(cdata->lseg, cdata->ds_commit_index),\n\t\t\tcount, count, NFS_FILE_SYNC);\n\tset_bit(NFS_LSEG_LAYOUTRETURN, &cdata->lseg->pls_flags);\n}\n\nstatic int ff_layout_commit_prepare_common(struct rpc_task *task,\n\t\t\t\t\t   struct nfs_commit_data *cdata)\n{\n\tif (!pnfs_is_valid_lseg(cdata->lseg)) {\n\t\trpc_exit(task, -EAGAIN);\n\t\treturn -EAGAIN;\n\t}\n\n\tff_layout_commit_record_layoutstats_start(task, cdata);\n\treturn 0;\n}\n\nstatic void ff_layout_commit_prepare_v3(struct rpc_task *task, void *data)\n{\n\tif (ff_layout_commit_prepare_common(task, data))\n\t\treturn;\n\n\trpc_call_start(task);\n}\n\nstatic void ff_layout_commit_prepare_v4(struct rpc_task *task, void *data)\n{\n\tstruct nfs_commit_data *wdata = data;\n\n\tif (nfs4_setup_sequence(wdata->ds_clp,\n\t\t\t\t&wdata->args.seq_args,\n\t\t\t\t&wdata->res.seq_res,\n\t\t\t\ttask))\n\t\treturn;\n\tff_layout_commit_prepare_common(task, data);\n}\n\nstatic void ff_layout_commit_done(struct rpc_task *task, void *data)\n{\n\tpnfs_generic_write_commit_done(task, data);\n}\n\nstatic void ff_layout_commit_count_stats(struct rpc_task *task, void *data)\n{\n\tstruct nfs_commit_data *cdata = data;\n\n\tff_layout_commit_record_layoutstats_done(task, cdata);\n\trpc_count_iostats_metrics(task,\n\t    &NFS_CLIENT(cdata->inode)->cl_metrics[NFSPROC4_CLNT_COMMIT]);\n}\n\nstatic void ff_layout_commit_release(void *data)\n{\n\tstruct nfs_commit_data *cdata = data;\n\n\tff_layout_commit_record_layoutstats_done(&cdata->task, cdata);\n\tpnfs_generic_commit_release(data);\n}\n\nstatic const struct rpc_call_ops ff_layout_read_call_ops_v3 = {\n\t.rpc_call_prepare = ff_layout_read_prepare_v3,\n\t.rpc_call_done = ff_layout_read_call_done,\n\t.rpc_count_stats = ff_layout_read_count_stats,\n\t.rpc_release = ff_layout_read_release,\n};\n\nstatic const struct rpc_call_ops ff_layout_read_call_ops_v4 = {\n\t.rpc_call_prepare = ff_layout_read_prepare_v4,\n\t.rpc_call_done = ff_layout_read_call_done,\n\t.rpc_count_stats = ff_layout_read_count_stats,\n\t.rpc_release = ff_layout_read_release,\n};\n\nstatic const struct rpc_call_ops ff_layout_write_call_ops_v3 = {\n\t.rpc_call_prepare = ff_layout_write_prepare_v3,\n\t.rpc_call_done = ff_layout_write_call_done,\n\t.rpc_count_stats = ff_layout_write_count_stats,\n\t.rpc_release = ff_layout_write_release,\n};\n\nstatic const struct rpc_call_ops ff_layout_write_call_ops_v4 = {\n\t.rpc_call_prepare = ff_layout_write_prepare_v4,\n\t.rpc_call_done = ff_layout_write_call_done,\n\t.rpc_count_stats = ff_layout_write_count_stats,\n\t.rpc_release = ff_layout_write_release,\n};\n\nstatic const struct rpc_call_ops ff_layout_commit_call_ops_v3 = {\n\t.rpc_call_prepare = ff_layout_commit_prepare_v3,\n\t.rpc_call_done = ff_layout_commit_done,\n\t.rpc_count_stats = ff_layout_commit_count_stats,\n\t.rpc_release = ff_layout_commit_release,\n};\n\nstatic const struct rpc_call_ops ff_layout_commit_call_ops_v4 = {\n\t.rpc_call_prepare = ff_layout_commit_prepare_v4,\n\t.rpc_call_done = ff_layout_commit_done,\n\t.rpc_count_stats = ff_layout_commit_count_stats,\n\t.rpc_release = ff_layout_commit_release,\n};\n\nstatic enum pnfs_try_status\nff_layout_read_pagelist(struct nfs_pgio_header *hdr)\n{\n\tstruct pnfs_layout_segment *lseg = hdr->lseg;\n\tstruct nfs4_pnfs_ds *ds;\n\tstruct rpc_clnt *ds_clnt;\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tconst struct cred *ds_cred;\n\tloff_t offset = hdr->args.offset;\n\tu32 idx = hdr->pgio_mirror_idx;\n\tint vers;\n\tstruct nfs_fh *fh;\n\n\tdprintk(\"--> %s ino %lu pgbase %u req %zu@%llu\\n\",\n\t\t__func__, hdr->inode->i_ino,\n\t\thdr->args.pgbase, (size_t)hdr->args.count, offset);\n\n\tmirror = FF_LAYOUT_COMP(lseg, idx);\n\tds = nfs4_ff_layout_prepare_ds(lseg, mirror, false);\n\tif (!ds)\n\t\tgoto out_failed;\n\n\tds_clnt = nfs4_ff_find_or_create_ds_client(mirror, ds->ds_clp,\n\t\t\t\t\t\t   hdr->inode);\n\tif (IS_ERR(ds_clnt))\n\t\tgoto out_failed;\n\n\tds_cred = ff_layout_get_ds_cred(mirror, &lseg->pls_range, hdr->cred);\n\tif (!ds_cred)\n\t\tgoto out_failed;\n\n\tvers = nfs4_ff_layout_ds_version(mirror);\n\n\tdprintk(\"%s USE DS: %s cl_count %d vers %d\\n\", __func__,\n\t\tds->ds_remotestr, refcount_read(&ds->ds_clp->cl_count), vers);\n\n\thdr->pgio_done_cb = ff_layout_read_done_cb;\n\trefcount_inc(&ds->ds_clp->cl_count);\n\thdr->ds_clp = ds->ds_clp;\n\tfh = nfs4_ff_layout_select_ds_fh(mirror);\n\tif (fh)\n\t\thdr->args.fh = fh;\n\n\tnfs4_ff_layout_select_ds_stateid(mirror, &hdr->args.stateid);\n\n\t \n\thdr->args.offset = offset;\n\thdr->mds_offset = offset;\n\n\t \n\tnfs_initiate_pgio(ds_clnt, hdr, ds_cred, ds->ds_clp->rpc_ops,\n\t\t\t  vers == 3 ? &ff_layout_read_call_ops_v3 :\n\t\t\t\t      &ff_layout_read_call_ops_v4,\n\t\t\t  0, RPC_TASK_SOFTCONN);\n\tput_cred(ds_cred);\n\treturn PNFS_ATTEMPTED;\n\nout_failed:\n\tif (ff_layout_avoid_mds_available_ds(lseg))\n\t\treturn PNFS_TRY_AGAIN;\n\ttrace_pnfs_mds_fallback_read_pagelist(hdr->inode,\n\t\t\thdr->args.offset, hdr->args.count,\n\t\t\tIOMODE_READ, NFS_I(hdr->inode)->layout, lseg);\n\treturn PNFS_NOT_ATTEMPTED;\n}\n\n \nstatic enum pnfs_try_status\nff_layout_write_pagelist(struct nfs_pgio_header *hdr, int sync)\n{\n\tstruct pnfs_layout_segment *lseg = hdr->lseg;\n\tstruct nfs4_pnfs_ds *ds;\n\tstruct rpc_clnt *ds_clnt;\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tconst struct cred *ds_cred;\n\tloff_t offset = hdr->args.offset;\n\tint vers;\n\tstruct nfs_fh *fh;\n\tu32 idx = hdr->pgio_mirror_idx;\n\n\tmirror = FF_LAYOUT_COMP(lseg, idx);\n\tds = nfs4_ff_layout_prepare_ds(lseg, mirror, true);\n\tif (!ds)\n\t\tgoto out_failed;\n\n\tds_clnt = nfs4_ff_find_or_create_ds_client(mirror, ds->ds_clp,\n\t\t\t\t\t\t   hdr->inode);\n\tif (IS_ERR(ds_clnt))\n\t\tgoto out_failed;\n\n\tds_cred = ff_layout_get_ds_cred(mirror, &lseg->pls_range, hdr->cred);\n\tif (!ds_cred)\n\t\tgoto out_failed;\n\n\tvers = nfs4_ff_layout_ds_version(mirror);\n\n\tdprintk(\"%s ino %lu sync %d req %zu@%llu DS: %s cl_count %d vers %d\\n\",\n\t\t__func__, hdr->inode->i_ino, sync, (size_t) hdr->args.count,\n\t\toffset, ds->ds_remotestr, refcount_read(&ds->ds_clp->cl_count),\n\t\tvers);\n\n\thdr->pgio_done_cb = ff_layout_write_done_cb;\n\trefcount_inc(&ds->ds_clp->cl_count);\n\thdr->ds_clp = ds->ds_clp;\n\thdr->ds_commit_idx = idx;\n\tfh = nfs4_ff_layout_select_ds_fh(mirror);\n\tif (fh)\n\t\thdr->args.fh = fh;\n\n\tnfs4_ff_layout_select_ds_stateid(mirror, &hdr->args.stateid);\n\n\t \n\thdr->args.offset = offset;\n\n\t \n\tnfs_initiate_pgio(ds_clnt, hdr, ds_cred, ds->ds_clp->rpc_ops,\n\t\t\t  vers == 3 ? &ff_layout_write_call_ops_v3 :\n\t\t\t\t      &ff_layout_write_call_ops_v4,\n\t\t\t  sync, RPC_TASK_SOFTCONN);\n\tput_cred(ds_cred);\n\treturn PNFS_ATTEMPTED;\n\nout_failed:\n\tif (ff_layout_avoid_mds_available_ds(lseg))\n\t\treturn PNFS_TRY_AGAIN;\n\ttrace_pnfs_mds_fallback_write_pagelist(hdr->inode,\n\t\t\thdr->args.offset, hdr->args.count,\n\t\t\tIOMODE_RW, NFS_I(hdr->inode)->layout, lseg);\n\treturn PNFS_NOT_ATTEMPTED;\n}\n\nstatic u32 calc_ds_index_from_commit(struct pnfs_layout_segment *lseg, u32 i)\n{\n\treturn i;\n}\n\nstatic struct nfs_fh *\nselect_ds_fh_from_commit(struct pnfs_layout_segment *lseg, u32 i)\n{\n\tstruct nfs4_ff_layout_segment *flseg = FF_LAYOUT_LSEG(lseg);\n\n\t \n\treturn &flseg->mirror_array[i]->fh_versions[0];\n}\n\nstatic int ff_layout_initiate_commit(struct nfs_commit_data *data, int how)\n{\n\tstruct pnfs_layout_segment *lseg = data->lseg;\n\tstruct nfs4_pnfs_ds *ds;\n\tstruct rpc_clnt *ds_clnt;\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tconst struct cred *ds_cred;\n\tu32 idx;\n\tint vers, ret;\n\tstruct nfs_fh *fh;\n\n\tif (!lseg || !(pnfs_is_valid_lseg(lseg) ||\n\t    test_bit(NFS_LSEG_LAYOUTRETURN, &lseg->pls_flags)))\n\t\tgoto out_err;\n\n\tidx = calc_ds_index_from_commit(lseg, data->ds_commit_index);\n\tmirror = FF_LAYOUT_COMP(lseg, idx);\n\tds = nfs4_ff_layout_prepare_ds(lseg, mirror, true);\n\tif (!ds)\n\t\tgoto out_err;\n\n\tds_clnt = nfs4_ff_find_or_create_ds_client(mirror, ds->ds_clp,\n\t\t\t\t\t\t   data->inode);\n\tif (IS_ERR(ds_clnt))\n\t\tgoto out_err;\n\n\tds_cred = ff_layout_get_ds_cred(mirror, &lseg->pls_range, data->cred);\n\tif (!ds_cred)\n\t\tgoto out_err;\n\n\tvers = nfs4_ff_layout_ds_version(mirror);\n\n\tdprintk(\"%s ino %lu, how %d cl_count %d vers %d\\n\", __func__,\n\t\tdata->inode->i_ino, how, refcount_read(&ds->ds_clp->cl_count),\n\t\tvers);\n\tdata->commit_done_cb = ff_layout_commit_done_cb;\n\tdata->cred = ds_cred;\n\trefcount_inc(&ds->ds_clp->cl_count);\n\tdata->ds_clp = ds->ds_clp;\n\tfh = select_ds_fh_from_commit(lseg, data->ds_commit_index);\n\tif (fh)\n\t\tdata->args.fh = fh;\n\n\tret = nfs_initiate_commit(ds_clnt, data, ds->ds_clp->rpc_ops,\n\t\t\t\t   vers == 3 ? &ff_layout_commit_call_ops_v3 :\n\t\t\t\t\t       &ff_layout_commit_call_ops_v4,\n\t\t\t\t   how, RPC_TASK_SOFTCONN);\n\tput_cred(ds_cred);\n\treturn ret;\nout_err:\n\tpnfs_generic_prepare_to_resend_writes(data);\n\tpnfs_generic_commit_release(data);\n\treturn -EAGAIN;\n}\n\nstatic int\nff_layout_commit_pagelist(struct inode *inode, struct list_head *mds_pages,\n\t\t\t   int how, struct nfs_commit_info *cinfo)\n{\n\treturn pnfs_generic_commit_pagelist(inode, mds_pages, how, cinfo,\n\t\t\t\t\t    ff_layout_initiate_commit);\n}\n\nstatic bool ff_layout_match_rw(const struct rpc_task *task,\n\t\t\t       const struct nfs_pgio_header *hdr,\n\t\t\t       const struct pnfs_layout_segment *lseg)\n{\n\treturn hdr->lseg == lseg;\n}\n\nstatic bool ff_layout_match_commit(const struct rpc_task *task,\n\t\t\t\t   const struct nfs_commit_data *cdata,\n\t\t\t\t   const struct pnfs_layout_segment *lseg)\n{\n\treturn cdata->lseg == lseg;\n}\n\nstatic bool ff_layout_match_io(const struct rpc_task *task, const void *data)\n{\n\tconst struct rpc_call_ops *ops = task->tk_ops;\n\n\tif (ops == &ff_layout_read_call_ops_v3 ||\n\t    ops == &ff_layout_read_call_ops_v4 ||\n\t    ops == &ff_layout_write_call_ops_v3 ||\n\t    ops == &ff_layout_write_call_ops_v4)\n\t\treturn ff_layout_match_rw(task, task->tk_calldata, data);\n\tif (ops == &ff_layout_commit_call_ops_v3 ||\n\t    ops == &ff_layout_commit_call_ops_v4)\n\t\treturn ff_layout_match_commit(task, task->tk_calldata, data);\n\treturn false;\n}\n\nstatic void ff_layout_cancel_io(struct pnfs_layout_segment *lseg)\n{\n\tstruct nfs4_ff_layout_segment *flseg = FF_LAYOUT_LSEG(lseg);\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tstruct nfs4_ff_layout_ds *mirror_ds;\n\tstruct nfs4_pnfs_ds *ds;\n\tstruct nfs_client *ds_clp;\n\tstruct rpc_clnt *clnt;\n\tu32 idx;\n\n\tfor (idx = 0; idx < flseg->mirror_array_cnt; idx++) {\n\t\tmirror = flseg->mirror_array[idx];\n\t\tmirror_ds = mirror->mirror_ds;\n\t\tif (!mirror_ds)\n\t\t\tcontinue;\n\t\tds = mirror->mirror_ds->ds;\n\t\tif (!ds)\n\t\t\tcontinue;\n\t\tds_clp = ds->ds_clp;\n\t\tif (!ds_clp)\n\t\t\tcontinue;\n\t\tclnt = ds_clp->cl_rpcclient;\n\t\tif (!clnt)\n\t\t\tcontinue;\n\t\tif (!rpc_cancel_tasks(clnt, -EAGAIN, ff_layout_match_io, lseg))\n\t\t\tcontinue;\n\t\trpc_clnt_disconnect(clnt);\n\t}\n}\n\nstatic struct pnfs_ds_commit_info *\nff_layout_get_ds_info(struct inode *inode)\n{\n\tstruct pnfs_layout_hdr *layout = NFS_I(inode)->layout;\n\n\tif (layout == NULL)\n\t\treturn NULL;\n\n\treturn &FF_LAYOUT_FROM_HDR(layout)->commit_info;\n}\n\nstatic void\nff_layout_setup_ds_info(struct pnfs_ds_commit_info *fl_cinfo,\n\t\tstruct pnfs_layout_segment *lseg)\n{\n\tstruct nfs4_ff_layout_segment *flseg = FF_LAYOUT_LSEG(lseg);\n\tstruct inode *inode = lseg->pls_layout->plh_inode;\n\tstruct pnfs_commit_array *array, *new;\n\n\tnew = pnfs_alloc_commit_array(flseg->mirror_array_cnt,\n\t\t\t\t      nfs_io_gfp_mask());\n\tif (new) {\n\t\tspin_lock(&inode->i_lock);\n\t\tarray = pnfs_add_commit_array(fl_cinfo, new, lseg);\n\t\tspin_unlock(&inode->i_lock);\n\t\tif (array != new)\n\t\t\tpnfs_free_commit_array(new);\n\t}\n}\n\nstatic void\nff_layout_release_ds_info(struct pnfs_ds_commit_info *fl_cinfo,\n\t\tstruct inode *inode)\n{\n\tspin_lock(&inode->i_lock);\n\tpnfs_generic_ds_cinfo_destroy(fl_cinfo);\n\tspin_unlock(&inode->i_lock);\n}\n\nstatic void\nff_layout_free_deviceid_node(struct nfs4_deviceid_node *d)\n{\n\tnfs4_ff_layout_free_deviceid(container_of(d, struct nfs4_ff_layout_ds,\n\t\t\t\t\t\t  id_node));\n}\n\nstatic int ff_layout_encode_ioerr(struct xdr_stream *xdr,\n\t\t\t\t  const struct nfs4_layoutreturn_args *args,\n\t\t\t\t  const struct nfs4_flexfile_layoutreturn_args *ff_args)\n{\n\t__be32 *start;\n\n\tstart = xdr_reserve_space(xdr, 4);\n\tif (unlikely(!start))\n\t\treturn -E2BIG;\n\n\t*start = cpu_to_be32(ff_args->num_errors);\n\t \n\treturn ff_layout_encode_ds_ioerr(xdr, &ff_args->errors);\n}\n\nstatic void\nencode_opaque_fixed(struct xdr_stream *xdr, const void *buf, size_t len)\n{\n\tWARN_ON_ONCE(xdr_stream_encode_opaque_fixed(xdr, buf, len) < 0);\n}\n\nstatic void\nff_layout_encode_ff_iostat_head(struct xdr_stream *xdr,\n\t\t\t    const nfs4_stateid *stateid,\n\t\t\t    const struct nfs42_layoutstat_devinfo *devinfo)\n{\n\t__be32 *p;\n\n\tp = xdr_reserve_space(xdr, 8 + 8);\n\tp = xdr_encode_hyper(p, devinfo->offset);\n\tp = xdr_encode_hyper(p, devinfo->length);\n\tencode_opaque_fixed(xdr, stateid->data, NFS4_STATEID_SIZE);\n\tp = xdr_reserve_space(xdr, 4*8);\n\tp = xdr_encode_hyper(p, devinfo->read_count);\n\tp = xdr_encode_hyper(p, devinfo->read_bytes);\n\tp = xdr_encode_hyper(p, devinfo->write_count);\n\tp = xdr_encode_hyper(p, devinfo->write_bytes);\n\tencode_opaque_fixed(xdr, devinfo->dev_id.data, NFS4_DEVICEID4_SIZE);\n}\n\nstatic void\nff_layout_encode_ff_iostat(struct xdr_stream *xdr,\n\t\t\t    const nfs4_stateid *stateid,\n\t\t\t    const struct nfs42_layoutstat_devinfo *devinfo)\n{\n\tff_layout_encode_ff_iostat_head(xdr, stateid, devinfo);\n\tff_layout_encode_ff_layoutupdate(xdr, devinfo,\n\t\t\tdevinfo->ld_private.data);\n}\n\n \nstatic void ff_layout_encode_iostats_array(struct xdr_stream *xdr,\n\t\tconst struct nfs4_layoutreturn_args *args,\n\t\tstruct nfs4_flexfile_layoutreturn_args *ff_args)\n{\n\t__be32 *p;\n\tint i;\n\n\tp = xdr_reserve_space(xdr, 4);\n\t*p = cpu_to_be32(ff_args->num_dev);\n\tfor (i = 0; i < ff_args->num_dev; i++)\n\t\tff_layout_encode_ff_iostat(xdr,\n\t\t\t\t&args->layout->plh_stateid,\n\t\t\t\t&ff_args->devinfo[i]);\n}\n\nstatic void\nff_layout_free_iostats_array(struct nfs42_layoutstat_devinfo *devinfo,\n\t\tunsigned int num_entries)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tif (!devinfo[i].ld_private.ops)\n\t\t\tcontinue;\n\t\tif (!devinfo[i].ld_private.ops->free)\n\t\t\tcontinue;\n\t\tdevinfo[i].ld_private.ops->free(&devinfo[i].ld_private);\n\t}\n}\n\nstatic struct nfs4_deviceid_node *\nff_layout_alloc_deviceid_node(struct nfs_server *server,\n\t\t\t      struct pnfs_device *pdev, gfp_t gfp_flags)\n{\n\tstruct nfs4_ff_layout_ds *dsaddr;\n\n\tdsaddr = nfs4_ff_alloc_deviceid_node(server, pdev, gfp_flags);\n\tif (!dsaddr)\n\t\treturn NULL;\n\treturn &dsaddr->id_node;\n}\n\nstatic void\nff_layout_encode_layoutreturn(struct xdr_stream *xdr,\n\t\tconst void *voidargs,\n\t\tconst struct nfs4_xdr_opaque_data *ff_opaque)\n{\n\tconst struct nfs4_layoutreturn_args *args = voidargs;\n\tstruct nfs4_flexfile_layoutreturn_args *ff_args = ff_opaque->data;\n\tstruct xdr_buf tmp_buf = {\n\t\t.head = {\n\t\t\t[0] = {\n\t\t\t\t.iov_base = page_address(ff_args->pages[0]),\n\t\t\t},\n\t\t},\n\t\t.buflen = PAGE_SIZE,\n\t};\n\tstruct xdr_stream tmp_xdr;\n\t__be32 *start;\n\n\tdprintk(\"%s: Begin\\n\", __func__);\n\n\txdr_init_encode(&tmp_xdr, &tmp_buf, NULL, NULL);\n\n\tff_layout_encode_ioerr(&tmp_xdr, args, ff_args);\n\tff_layout_encode_iostats_array(&tmp_xdr, args, ff_args);\n\n\tstart = xdr_reserve_space(xdr, 4);\n\t*start = cpu_to_be32(tmp_buf.len);\n\txdr_write_pages(xdr, ff_args->pages, 0, tmp_buf.len);\n\n\tdprintk(\"%s: Return\\n\", __func__);\n}\n\nstatic void\nff_layout_free_layoutreturn(struct nfs4_xdr_opaque_data *args)\n{\n\tstruct nfs4_flexfile_layoutreturn_args *ff_args;\n\n\tif (!args->data)\n\t\treturn;\n\tff_args = args->data;\n\targs->data = NULL;\n\n\tff_layout_free_ds_ioerr(&ff_args->errors);\n\tff_layout_free_iostats_array(ff_args->devinfo, ff_args->num_dev);\n\n\tput_page(ff_args->pages[0]);\n\tkfree(ff_args);\n}\n\nstatic const struct nfs4_xdr_opaque_ops layoutreturn_ops = {\n\t.encode = ff_layout_encode_layoutreturn,\n\t.free = ff_layout_free_layoutreturn,\n};\n\nstatic int\nff_layout_prepare_layoutreturn(struct nfs4_layoutreturn_args *args)\n{\n\tstruct nfs4_flexfile_layoutreturn_args *ff_args;\n\tstruct nfs4_flexfile_layout *ff_layout = FF_LAYOUT_FROM_HDR(args->layout);\n\n\tff_args = kmalloc(sizeof(*ff_args), nfs_io_gfp_mask());\n\tif (!ff_args)\n\t\tgoto out_nomem;\n\tff_args->pages[0] = alloc_page(nfs_io_gfp_mask());\n\tif (!ff_args->pages[0])\n\t\tgoto out_nomem_free;\n\n\tINIT_LIST_HEAD(&ff_args->errors);\n\tff_args->num_errors = ff_layout_fetch_ds_ioerr(args->layout,\n\t\t\t&args->range, &ff_args->errors,\n\t\t\tFF_LAYOUTRETURN_MAXERR);\n\n\tspin_lock(&args->inode->i_lock);\n\tff_args->num_dev = ff_layout_mirror_prepare_stats(\n\t\t&ff_layout->generic_hdr, &ff_args->devinfo[0],\n\t\tARRAY_SIZE(ff_args->devinfo), NFS4_FF_OP_LAYOUTRETURN);\n\tspin_unlock(&args->inode->i_lock);\n\n\targs->ld_private->ops = &layoutreturn_ops;\n\targs->ld_private->data = ff_args;\n\treturn 0;\nout_nomem_free:\n\tkfree(ff_args);\nout_nomem:\n\treturn -ENOMEM;\n}\n\n#ifdef CONFIG_NFS_V4_2\nvoid\nff_layout_send_layouterror(struct pnfs_layout_segment *lseg)\n{\n\tstruct pnfs_layout_hdr *lo = lseg->pls_layout;\n\tstruct nfs42_layout_error *errors;\n\tLIST_HEAD(head);\n\n\tif (!nfs_server_capable(lo->plh_inode, NFS_CAP_LAYOUTERROR))\n\t\treturn;\n\tff_layout_fetch_ds_ioerr(lo, &lseg->pls_range, &head, -1);\n\tif (list_empty(&head))\n\t\treturn;\n\n\terrors = kmalloc_array(NFS42_LAYOUTERROR_MAX, sizeof(*errors),\n\t\t\t       nfs_io_gfp_mask());\n\tif (errors != NULL) {\n\t\tconst struct nfs4_ff_layout_ds_err *pos;\n\t\tsize_t n = 0;\n\n\t\tlist_for_each_entry(pos, &head, list) {\n\t\t\terrors[n].offset = pos->offset;\n\t\t\terrors[n].length = pos->length;\n\t\t\tnfs4_stateid_copy(&errors[n].stateid, &pos->stateid);\n\t\t\terrors[n].errors[0].dev_id = pos->deviceid;\n\t\t\terrors[n].errors[0].status = pos->status;\n\t\t\terrors[n].errors[0].opnum = pos->opnum;\n\t\t\tn++;\n\t\t\tif (!list_is_last(&pos->list, &head) &&\n\t\t\t    n < NFS42_LAYOUTERROR_MAX)\n\t\t\t\tcontinue;\n\t\t\tif (nfs42_proc_layouterror(lseg, errors, n) < 0)\n\t\t\t\tbreak;\n\t\t\tn = 0;\n\t\t}\n\t\tkfree(errors);\n\t}\n\tff_layout_free_ds_ioerr(&head);\n}\n#else\nvoid\nff_layout_send_layouterror(struct pnfs_layout_segment *lseg)\n{\n}\n#endif\n\nstatic int\nff_layout_ntop4(const struct sockaddr *sap, char *buf, const size_t buflen)\n{\n\tconst struct sockaddr_in *sin = (struct sockaddr_in *)sap;\n\n\treturn snprintf(buf, buflen, \"%pI4\", &sin->sin_addr);\n}\n\nstatic size_t\nff_layout_ntop6_noscopeid(const struct sockaddr *sap, char *buf,\n\t\t\t  const int buflen)\n{\n\tconst struct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)sap;\n\tconst struct in6_addr *addr = &sin6->sin6_addr;\n\n\t \n\tif (ipv6_addr_any(addr))\n\t\treturn snprintf(buf, buflen, \"::\");\n\n\t \n\tif (ipv6_addr_loopback(addr))\n\t\treturn snprintf(buf, buflen, \"::1\");\n\n\t \n\tif (ipv6_addr_v4mapped(addr))\n\t\treturn snprintf(buf, buflen, \"::ffff:%pI4\",\n\t\t\t\t\t&addr->s6_addr32[3]);\n\n\t \n\treturn snprintf(buf, buflen, \"%pI6c\", addr);\n}\n\n \nstatic void\nff_layout_encode_netaddr(struct xdr_stream *xdr, struct nfs4_pnfs_ds_addr *da)\n{\n\tstruct sockaddr *sap = (struct sockaddr *)&da->da_addr;\n\tchar portbuf[RPCBIND_MAXUADDRPLEN];\n\tchar addrbuf[RPCBIND_MAXUADDRLEN];\n\tunsigned short port;\n\tint len, netid_len;\n\t__be32 *p;\n\n\tswitch (sap->sa_family) {\n\tcase AF_INET:\n\t\tif (ff_layout_ntop4(sap, addrbuf, sizeof(addrbuf)) == 0)\n\t\t\treturn;\n\t\tport = ntohs(((struct sockaddr_in *)sap)->sin_port);\n\t\tbreak;\n\tcase AF_INET6:\n\t\tif (ff_layout_ntop6_noscopeid(sap, addrbuf, sizeof(addrbuf)) == 0)\n\t\t\treturn;\n\t\tport = ntohs(((struct sockaddr_in6 *)sap)->sin6_port);\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn;\n\t}\n\n\tsnprintf(portbuf, sizeof(portbuf), \".%u.%u\", port >> 8, port & 0xff);\n\tlen = strlcat(addrbuf, portbuf, sizeof(addrbuf));\n\n\tnetid_len = strlen(da->da_netid);\n\tp = xdr_reserve_space(xdr, 4 + netid_len);\n\txdr_encode_opaque(p, da->da_netid, netid_len);\n\n\tp = xdr_reserve_space(xdr, 4 + len);\n\txdr_encode_opaque(p, addrbuf, len);\n}\n\nstatic void\nff_layout_encode_nfstime(struct xdr_stream *xdr,\n\t\t\t ktime_t t)\n{\n\tstruct timespec64 ts;\n\t__be32 *p;\n\n\tp = xdr_reserve_space(xdr, 12);\n\tts = ktime_to_timespec64(t);\n\tp = xdr_encode_hyper(p, ts.tv_sec);\n\t*p++ = cpu_to_be32(ts.tv_nsec);\n}\n\nstatic void\nff_layout_encode_io_latency(struct xdr_stream *xdr,\n\t\t\t    struct nfs4_ff_io_stat *stat)\n{\n\t__be32 *p;\n\n\tp = xdr_reserve_space(xdr, 5 * 8);\n\tp = xdr_encode_hyper(p, stat->ops_requested);\n\tp = xdr_encode_hyper(p, stat->bytes_requested);\n\tp = xdr_encode_hyper(p, stat->ops_completed);\n\tp = xdr_encode_hyper(p, stat->bytes_completed);\n\tp = xdr_encode_hyper(p, stat->bytes_not_delivered);\n\tff_layout_encode_nfstime(xdr, stat->total_busy_time);\n\tff_layout_encode_nfstime(xdr, stat->aggregate_completion_time);\n}\n\nstatic void\nff_layout_encode_ff_layoutupdate(struct xdr_stream *xdr,\n\t\t\t      const struct nfs42_layoutstat_devinfo *devinfo,\n\t\t\t      struct nfs4_ff_layout_mirror *mirror)\n{\n\tstruct nfs4_pnfs_ds_addr *da;\n\tstruct nfs4_pnfs_ds *ds = mirror->mirror_ds->ds;\n\tstruct nfs_fh *fh = &mirror->fh_versions[0];\n\t__be32 *p;\n\n\tda = list_first_entry(&ds->ds_addrs, struct nfs4_pnfs_ds_addr, da_node);\n\tdprintk(\"%s: DS %s: encoding address %s\\n\",\n\t\t__func__, ds->ds_remotestr, da->da_remotestr);\n\t \n\tff_layout_encode_netaddr(xdr, da);\n\t \n\tp = xdr_reserve_space(xdr, 4 + fh->size);\n\txdr_encode_opaque(p, fh->data, fh->size);\n\t \n\tspin_lock(&mirror->lock);\n\tff_layout_encode_io_latency(xdr, &mirror->read_stat.io_stat);\n\t \n\tff_layout_encode_io_latency(xdr, &mirror->write_stat.io_stat);\n\tspin_unlock(&mirror->lock);\n\t \n\tff_layout_encode_nfstime(xdr, ktime_sub(ktime_get(), mirror->start_time));\n\t \n\tp = xdr_reserve_space(xdr, 4);\n\t*p = cpu_to_be32(false);\n}\n\nstatic void\nff_layout_encode_layoutstats(struct xdr_stream *xdr, const void *args,\n\t\t\t     const struct nfs4_xdr_opaque_data *opaque)\n{\n\tstruct nfs42_layoutstat_devinfo *devinfo = container_of(opaque,\n\t\t\tstruct nfs42_layoutstat_devinfo, ld_private);\n\t__be32 *start;\n\n\t \n\tstart = xdr_reserve_space(xdr, 4);\n\tff_layout_encode_ff_layoutupdate(xdr, devinfo, opaque->data);\n\n\t*start = cpu_to_be32((xdr->p - start - 1) * 4);\n}\n\nstatic void\nff_layout_free_layoutstats(struct nfs4_xdr_opaque_data *opaque)\n{\n\tstruct nfs4_ff_layout_mirror *mirror = opaque->data;\n\n\tff_layout_put_mirror(mirror);\n}\n\nstatic const struct nfs4_xdr_opaque_ops layoutstat_ops = {\n\t.encode = ff_layout_encode_layoutstats,\n\t.free\t= ff_layout_free_layoutstats,\n};\n\nstatic int\nff_layout_mirror_prepare_stats(struct pnfs_layout_hdr *lo,\n\t\t\t       struct nfs42_layoutstat_devinfo *devinfo,\n\t\t\t       int dev_limit, enum nfs4_ff_op_type type)\n{\n\tstruct nfs4_flexfile_layout *ff_layout = FF_LAYOUT_FROM_HDR(lo);\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tstruct nfs4_deviceid_node *dev;\n\tint i = 0;\n\n\tlist_for_each_entry(mirror, &ff_layout->mirrors, mirrors) {\n\t\tif (i >= dev_limit)\n\t\t\tbreak;\n\t\tif (IS_ERR_OR_NULL(mirror->mirror_ds))\n\t\t\tcontinue;\n\t\tif (!test_and_clear_bit(NFS4_FF_MIRROR_STAT_AVAIL,\n\t\t\t\t\t&mirror->flags) &&\n\t\t    type != NFS4_FF_OP_LAYOUTRETURN)\n\t\t\tcontinue;\n\t\t \n\t\tif (!refcount_inc_not_zero(&mirror->ref))\n\t\t\tcontinue;\n\t\tdev = &mirror->mirror_ds->id_node; \n\t\tmemcpy(&devinfo->dev_id, &dev->deviceid, NFS4_DEVICEID4_SIZE);\n\t\tdevinfo->offset = 0;\n\t\tdevinfo->length = NFS4_MAX_UINT64;\n\t\tspin_lock(&mirror->lock);\n\t\tdevinfo->read_count = mirror->read_stat.io_stat.ops_completed;\n\t\tdevinfo->read_bytes = mirror->read_stat.io_stat.bytes_completed;\n\t\tdevinfo->write_count = mirror->write_stat.io_stat.ops_completed;\n\t\tdevinfo->write_bytes = mirror->write_stat.io_stat.bytes_completed;\n\t\tspin_unlock(&mirror->lock);\n\t\tdevinfo->layout_type = LAYOUT_FLEX_FILES;\n\t\tdevinfo->ld_private.ops = &layoutstat_ops;\n\t\tdevinfo->ld_private.data = mirror;\n\n\t\tdevinfo++;\n\t\ti++;\n\t}\n\treturn i;\n}\n\nstatic int ff_layout_prepare_layoutstats(struct nfs42_layoutstat_args *args)\n{\n\tstruct pnfs_layout_hdr *lo;\n\tstruct nfs4_flexfile_layout *ff_layout;\n\tconst int dev_count = PNFS_LAYOUTSTATS_MAXDEV;\n\n\t \n\targs->devinfo = kmalloc_array(dev_count, sizeof(*args->devinfo),\n\t\t\t\t      nfs_io_gfp_mask());\n\tif (!args->devinfo)\n\t\treturn -ENOMEM;\n\n\tspin_lock(&args->inode->i_lock);\n\tlo = NFS_I(args->inode)->layout;\n\tif (lo && pnfs_layout_is_valid(lo)) {\n\t\tff_layout = FF_LAYOUT_FROM_HDR(lo);\n\t\targs->num_dev = ff_layout_mirror_prepare_stats(\n\t\t\t&ff_layout->generic_hdr, &args->devinfo[0], dev_count,\n\t\t\tNFS4_FF_OP_LAYOUTSTATS);\n\t} else\n\t\targs->num_dev = 0;\n\tspin_unlock(&args->inode->i_lock);\n\tif (!args->num_dev) {\n\t\tkfree(args->devinfo);\n\t\targs->devinfo = NULL;\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nff_layout_set_layoutdriver(struct nfs_server *server,\n\t\tconst struct nfs_fh *dummy)\n{\n#if IS_ENABLED(CONFIG_NFS_V4_2)\n\tserver->caps |= NFS_CAP_LAYOUTSTATS;\n#endif\n\treturn 0;\n}\n\nstatic const struct pnfs_commit_ops ff_layout_commit_ops = {\n\t.setup_ds_info\t\t= ff_layout_setup_ds_info,\n\t.release_ds_info\t= ff_layout_release_ds_info,\n\t.mark_request_commit\t= pnfs_layout_mark_request_commit,\n\t.clear_request_commit\t= pnfs_generic_clear_request_commit,\n\t.scan_commit_lists\t= pnfs_generic_scan_commit_lists,\n\t.recover_commit_reqs\t= pnfs_generic_recover_commit_reqs,\n\t.commit_pagelist\t= ff_layout_commit_pagelist,\n};\n\nstatic struct pnfs_layoutdriver_type flexfilelayout_type = {\n\t.id\t\t\t= LAYOUT_FLEX_FILES,\n\t.name\t\t\t= \"LAYOUT_FLEX_FILES\",\n\t.owner\t\t\t= THIS_MODULE,\n\t.flags\t\t\t= PNFS_LAYOUTGET_ON_OPEN,\n\t.max_layoutget_response\t= 4096,  \n\t.set_layoutdriver\t= ff_layout_set_layoutdriver,\n\t.alloc_layout_hdr\t= ff_layout_alloc_layout_hdr,\n\t.free_layout_hdr\t= ff_layout_free_layout_hdr,\n\t.alloc_lseg\t\t= ff_layout_alloc_lseg,\n\t.free_lseg\t\t= ff_layout_free_lseg,\n\t.add_lseg\t\t= ff_layout_add_lseg,\n\t.pg_read_ops\t\t= &ff_layout_pg_read_ops,\n\t.pg_write_ops\t\t= &ff_layout_pg_write_ops,\n\t.get_ds_info\t\t= ff_layout_get_ds_info,\n\t.free_deviceid_node\t= ff_layout_free_deviceid_node,\n\t.read_pagelist\t\t= ff_layout_read_pagelist,\n\t.write_pagelist\t\t= ff_layout_write_pagelist,\n\t.alloc_deviceid_node    = ff_layout_alloc_deviceid_node,\n\t.prepare_layoutreturn   = ff_layout_prepare_layoutreturn,\n\t.sync\t\t\t= pnfs_nfs_generic_sync,\n\t.prepare_layoutstats\t= ff_layout_prepare_layoutstats,\n\t.cancel_io\t\t= ff_layout_cancel_io,\n};\n\nstatic int __init nfs4flexfilelayout_init(void)\n{\n\tprintk(KERN_INFO \"%s: NFSv4 Flexfile Layout Driver Registering...\\n\",\n\t       __func__);\n\treturn pnfs_register_layoutdriver(&flexfilelayout_type);\n}\n\nstatic void __exit nfs4flexfilelayout_exit(void)\n{\n\tprintk(KERN_INFO \"%s: NFSv4 Flexfile Layout Driver Unregistering...\\n\",\n\t       __func__);\n\tpnfs_unregister_layoutdriver(&flexfilelayout_type);\n}\n\nMODULE_ALIAS(\"nfs-layouttype4-4\");\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"The NFSv4 flexfile layout driver\");\n\nmodule_init(nfs4flexfilelayout_init);\nmodule_exit(nfs4flexfilelayout_exit);\n\nmodule_param(io_maxretrans, ushort, 0644);\nMODULE_PARM_DESC(io_maxretrans, \"The  number of times the NFSv4.1 client \"\n\t\t\t\"retries an I/O request before returning an error. \");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}