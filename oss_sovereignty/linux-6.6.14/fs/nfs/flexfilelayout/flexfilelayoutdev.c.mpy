{
  "module_name": "flexfilelayoutdev.c",
  "hash_id": "76838e9b7c1b0c0cdb55e3c234ed933fd23051059ec8f16748d5fd1cccd337ff",
  "original_prompt": "Ingested from linux-6.6.14/fs/nfs/flexfilelayout/flexfilelayoutdev.c",
  "human_readable_source": "\n \n\n#include <linux/nfs_fs.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n#include <linux/sunrpc/addr.h>\n\n#include \"../internal.h\"\n#include \"../nfs4session.h\"\n#include \"flexfilelayout.h\"\n\n#define NFSDBG_FACILITY\t\tNFSDBG_PNFS_LD\n\nstatic unsigned int dataserver_timeo = NFS_DEF_TCP_TIMEO;\nstatic unsigned int dataserver_retrans;\n\nstatic bool ff_layout_has_available_ds(struct pnfs_layout_segment *lseg);\n\nvoid nfs4_ff_layout_put_deviceid(struct nfs4_ff_layout_ds *mirror_ds)\n{\n\tif (!IS_ERR_OR_NULL(mirror_ds))\n\t\tnfs4_put_deviceid_node(&mirror_ds->id_node);\n}\n\nvoid nfs4_ff_layout_free_deviceid(struct nfs4_ff_layout_ds *mirror_ds)\n{\n\tnfs4_print_deviceid(&mirror_ds->id_node.deviceid);\n\tnfs4_pnfs_ds_put(mirror_ds->ds);\n\tkfree(mirror_ds->ds_versions);\n\tkfree_rcu(mirror_ds, id_node.rcu);\n}\n\n \nstruct nfs4_ff_layout_ds *\nnfs4_ff_alloc_deviceid_node(struct nfs_server *server, struct pnfs_device *pdev,\n\t\t\t    gfp_t gfp_flags)\n{\n\tstruct xdr_stream stream;\n\tstruct xdr_buf buf;\n\tstruct page *scratch;\n\tstruct list_head dsaddrs;\n\tstruct nfs4_pnfs_ds_addr *da;\n\tstruct nfs4_ff_layout_ds *new_ds = NULL;\n\tstruct nfs4_ff_ds_version *ds_versions = NULL;\n\tu32 mp_count;\n\tu32 version_count;\n\t__be32 *p;\n\tint i, ret = -ENOMEM;\n\n\t \n\tscratch = alloc_page(gfp_flags);\n\tif (!scratch)\n\t\tgoto out_err;\n\n\tnew_ds = kzalloc(sizeof(struct nfs4_ff_layout_ds), gfp_flags);\n\tif (!new_ds)\n\t\tgoto out_scratch;\n\n\tnfs4_init_deviceid_node(&new_ds->id_node,\n\t\t\t\tserver,\n\t\t\t\t&pdev->dev_id);\n\tINIT_LIST_HEAD(&dsaddrs);\n\n\txdr_init_decode_pages(&stream, &buf, pdev->pages, pdev->pglen);\n\txdr_set_scratch_page(&stream, scratch);\n\n\t \n\tp = xdr_inline_decode(&stream, 4);\n\tif (unlikely(!p))\n\t\tgoto out_err_drain_dsaddrs;\n\tmp_count = be32_to_cpup(p);\n\tdprintk(\"%s: multipath ds count %d\\n\", __func__, mp_count);\n\n\tfor (i = 0; i < mp_count; i++) {\n\t\t \n\t\tda = nfs4_decode_mp_ds_addr(server->nfs_client->cl_net,\n\t\t\t\t\t    &stream, gfp_flags);\n\t\tif (da)\n\t\t\tlist_add_tail(&da->da_node, &dsaddrs);\n\t}\n\tif (list_empty(&dsaddrs)) {\n\t\tdprintk(\"%s: no suitable DS addresses found\\n\",\n\t\t\t__func__);\n\t\tret = -ENOMEDIUM;\n\t\tgoto out_err_drain_dsaddrs;\n\t}\n\n\t \n\tp = xdr_inline_decode(&stream, 4);\n\tif (unlikely(!p))\n\t\tgoto out_err_drain_dsaddrs;\n\tversion_count = be32_to_cpup(p);\n\tdprintk(\"%s: version count %d\\n\", __func__, version_count);\n\n\tds_versions = kcalloc(version_count,\n\t\t\t      sizeof(struct nfs4_ff_ds_version),\n\t\t\t      gfp_flags);\n\tif (!ds_versions)\n\t\tgoto out_scratch;\n\n\tfor (i = 0; i < version_count; i++) {\n\t\t \n\t\tp = xdr_inline_decode(&stream, 20);\n\t\tif (unlikely(!p))\n\t\t\tgoto out_err_drain_dsaddrs;\n\t\tds_versions[i].version = be32_to_cpup(p++);\n\t\tds_versions[i].minor_version = be32_to_cpup(p++);\n\t\tds_versions[i].rsize = nfs_io_size(be32_to_cpup(p++),\n\t\t\t\t\t\t   server->nfs_client->cl_proto);\n\t\tds_versions[i].wsize = nfs_io_size(be32_to_cpup(p++),\n\t\t\t\t\t\t   server->nfs_client->cl_proto);\n\t\tds_versions[i].tightly_coupled = be32_to_cpup(p);\n\n\t\tif (ds_versions[i].rsize > NFS_MAX_FILE_IO_SIZE)\n\t\t\tds_versions[i].rsize = NFS_MAX_FILE_IO_SIZE;\n\t\tif (ds_versions[i].wsize > NFS_MAX_FILE_IO_SIZE)\n\t\t\tds_versions[i].wsize = NFS_MAX_FILE_IO_SIZE;\n\n\t\t \n\t\tif (!((ds_versions[i].version == 3 && ds_versions[i].minor_version == 0) ||\n\t\t\t(ds_versions[i].version == 4 && ds_versions[i].minor_version < 3))) {\n\t\t\tdprintk(\"%s: [%d] unsupported ds version %d-%d\\n\", __func__,\n\t\t\t\ti, ds_versions[i].version,\n\t\t\t\tds_versions[i].minor_version);\n\t\t\tret = -EPROTONOSUPPORT;\n\t\t\tgoto out_err_drain_dsaddrs;\n\t\t}\n\n\t\tdprintk(\"%s: [%d] vers %u minor_ver %u rsize %u wsize %u coupled %d\\n\",\n\t\t\t__func__, i, ds_versions[i].version,\n\t\t\tds_versions[i].minor_version,\n\t\t\tds_versions[i].rsize,\n\t\t\tds_versions[i].wsize,\n\t\t\tds_versions[i].tightly_coupled);\n\t}\n\n\tnew_ds->ds_versions = ds_versions;\n\tnew_ds->ds_versions_cnt = version_count;\n\n\tnew_ds->ds = nfs4_pnfs_ds_add(&dsaddrs, gfp_flags);\n\tif (!new_ds->ds)\n\t\tgoto out_err_drain_dsaddrs;\n\n\t \n\twhile (!list_empty(&dsaddrs)) {\n\t\tda = list_first_entry(&dsaddrs,\n\t\t\t\t      struct nfs4_pnfs_ds_addr,\n\t\t\t\t      da_node);\n\t\tlist_del_init(&da->da_node);\n\t\tkfree(da->da_remotestr);\n\t\tkfree(da);\n\t}\n\n\t__free_page(scratch);\n\treturn new_ds;\n\nout_err_drain_dsaddrs:\n\twhile (!list_empty(&dsaddrs)) {\n\t\tda = list_first_entry(&dsaddrs, struct nfs4_pnfs_ds_addr,\n\t\t\t\t      da_node);\n\t\tlist_del_init(&da->da_node);\n\t\tkfree(da->da_remotestr);\n\t\tkfree(da);\n\t}\n\n\tkfree(ds_versions);\nout_scratch:\n\t__free_page(scratch);\nout_err:\n\tkfree(new_ds);\n\n\tdprintk(\"%s ERROR: returning %d\\n\", __func__, ret);\n\treturn NULL;\n}\n\nstatic void extend_ds_error(struct nfs4_ff_layout_ds_err *err,\n\t\t\t    u64 offset, u64 length)\n{\n\tu64 end;\n\n\tend = max_t(u64, pnfs_end_offset(err->offset, err->length),\n\t\t    pnfs_end_offset(offset, length));\n\terr->offset = min_t(u64, err->offset, offset);\n\terr->length = end - err->offset;\n}\n\nstatic int\nff_ds_error_match(const struct nfs4_ff_layout_ds_err *e1,\n\t\tconst struct nfs4_ff_layout_ds_err *e2)\n{\n\tint ret;\n\n\tif (e1->opnum != e2->opnum)\n\t\treturn e1->opnum < e2->opnum ? -1 : 1;\n\tif (e1->status != e2->status)\n\t\treturn e1->status < e2->status ? -1 : 1;\n\tret = memcmp(e1->stateid.data, e2->stateid.data,\n\t\t\tsizeof(e1->stateid.data));\n\tif (ret != 0)\n\t\treturn ret;\n\tret = memcmp(&e1->deviceid, &e2->deviceid, sizeof(e1->deviceid));\n\tif (ret != 0)\n\t\treturn ret;\n\tif (pnfs_end_offset(e1->offset, e1->length) < e2->offset)\n\t\treturn -1;\n\tif (e1->offset > pnfs_end_offset(e2->offset, e2->length))\n\t\treturn 1;\n\t \n\treturn 0;\n}\n\nstatic void\nff_layout_add_ds_error_locked(struct nfs4_flexfile_layout *flo,\n\t\t\t      struct nfs4_ff_layout_ds_err *dserr)\n{\n\tstruct nfs4_ff_layout_ds_err *err, *tmp;\n\tstruct list_head *head = &flo->error_list;\n\tint match;\n\n\t \n\tlist_for_each_entry_safe(err, tmp, &flo->error_list, list) {\n\t\tmatch = ff_ds_error_match(err, dserr);\n\t\tif (match < 0)\n\t\t\tcontinue;\n\t\tif (match > 0) {\n\t\t\t \n\t\t\thead = &err->list;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\textend_ds_error(dserr, err->offset, err->length);\n\t\tlist_replace(&err->list, &dserr->list);\n\t\tkfree(err);\n\t\treturn;\n\t}\n\n\tlist_add_tail(&dserr->list, head);\n}\n\nint ff_layout_track_ds_error(struct nfs4_flexfile_layout *flo,\n\t\t\t     struct nfs4_ff_layout_mirror *mirror, u64 offset,\n\t\t\t     u64 length, int status, enum nfs_opnum4 opnum,\n\t\t\t     gfp_t gfp_flags)\n{\n\tstruct nfs4_ff_layout_ds_err *dserr;\n\n\tif (status == 0)\n\t\treturn 0;\n\n\tif (IS_ERR_OR_NULL(mirror->mirror_ds))\n\t\treturn -EINVAL;\n\n\tdserr = kmalloc(sizeof(*dserr), gfp_flags);\n\tif (!dserr)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&dserr->list);\n\tdserr->offset = offset;\n\tdserr->length = length;\n\tdserr->status = status;\n\tdserr->opnum = opnum;\n\tnfs4_stateid_copy(&dserr->stateid, &mirror->stateid);\n\tmemcpy(&dserr->deviceid, &mirror->mirror_ds->id_node.deviceid,\n\t       NFS4_DEVICEID4_SIZE);\n\n\tspin_lock(&flo->generic_hdr.plh_inode->i_lock);\n\tff_layout_add_ds_error_locked(flo, dserr);\n\tspin_unlock(&flo->generic_hdr.plh_inode->i_lock);\n\treturn 0;\n}\n\nstatic const struct cred *\nff_layout_get_mirror_cred(struct nfs4_ff_layout_mirror *mirror, u32 iomode)\n{\n\tconst struct cred *cred, __rcu **pcred;\n\n\tif (iomode == IOMODE_READ)\n\t\tpcred = &mirror->ro_cred;\n\telse\n\t\tpcred = &mirror->rw_cred;\n\n\trcu_read_lock();\n\tdo {\n\t\tcred = rcu_dereference(*pcred);\n\t\tif (!cred)\n\t\t\tbreak;\n\n\t\tcred = get_cred_rcu(cred);\n\t} while(!cred);\n\trcu_read_unlock();\n\treturn cred;\n}\n\nstruct nfs_fh *\nnfs4_ff_layout_select_ds_fh(struct nfs4_ff_layout_mirror *mirror)\n{\n\t \n\treturn &mirror->fh_versions[0];\n}\n\nvoid\nnfs4_ff_layout_select_ds_stateid(const struct nfs4_ff_layout_mirror *mirror,\n\t\tnfs4_stateid *stateid)\n{\n\tif (nfs4_ff_layout_ds_version(mirror) == 4)\n\t\tnfs4_stateid_copy(stateid, &mirror->stateid);\n}\n\nstatic bool\nff_layout_init_mirror_ds(struct pnfs_layout_hdr *lo,\n\t\t\t struct nfs4_ff_layout_mirror *mirror)\n{\n\tif (mirror == NULL)\n\t\tgoto outerr;\n\tif (mirror->mirror_ds == NULL) {\n\t\tstruct nfs4_deviceid_node *node;\n\t\tstruct nfs4_ff_layout_ds *mirror_ds = ERR_PTR(-ENODEV);\n\n\t\tnode = nfs4_find_get_deviceid(NFS_SERVER(lo->plh_inode),\n\t\t\t\t&mirror->devid, lo->plh_lc_cred,\n\t\t\t\tGFP_KERNEL);\n\t\tif (node)\n\t\t\tmirror_ds = FF_LAYOUT_MIRROR_DS(node);\n\n\t\t \n\t\tif (cmpxchg(&mirror->mirror_ds, NULL, mirror_ds) &&\n\t\t    mirror_ds != ERR_PTR(-ENODEV))\n\t\t\tnfs4_put_deviceid_node(node);\n\t}\n\n\tif (IS_ERR(mirror->mirror_ds))\n\t\tgoto outerr;\n\n\treturn true;\nouterr:\n\treturn false;\n}\n\n \nstruct nfs4_pnfs_ds *\nnfs4_ff_layout_prepare_ds(struct pnfs_layout_segment *lseg,\n\t\t\t  struct nfs4_ff_layout_mirror *mirror,\n\t\t\t  bool fail_return)\n{\n\tstruct nfs4_pnfs_ds *ds = NULL;\n\tstruct inode *ino = lseg->pls_layout->plh_inode;\n\tstruct nfs_server *s = NFS_SERVER(ino);\n\tunsigned int max_payload;\n\tint status;\n\n\tif (!ff_layout_init_mirror_ds(lseg->pls_layout, mirror))\n\t\tgoto noconnect;\n\n\tds = mirror->mirror_ds->ds;\n\tif (READ_ONCE(ds->ds_clp))\n\t\tgoto out;\n\t \n\tsmp_rmb();\n\n\t \n\tstatus = nfs4_pnfs_ds_connect(s, ds, &mirror->mirror_ds->id_node,\n\t\t\t     dataserver_timeo, dataserver_retrans,\n\t\t\t     mirror->mirror_ds->ds_versions[0].version,\n\t\t\t     mirror->mirror_ds->ds_versions[0].minor_version);\n\n\t \n\tif (!status) {\n\t\tmax_payload =\n\t\t\tnfs_block_size(rpc_max_payload(ds->ds_clp->cl_rpcclient),\n\t\t\t\t       NULL);\n\t\tif (mirror->mirror_ds->ds_versions[0].rsize > max_payload)\n\t\t\tmirror->mirror_ds->ds_versions[0].rsize = max_payload;\n\t\tif (mirror->mirror_ds->ds_versions[0].wsize > max_payload)\n\t\t\tmirror->mirror_ds->ds_versions[0].wsize = max_payload;\n\t\tgoto out;\n\t}\nnoconnect:\n\tff_layout_track_ds_error(FF_LAYOUT_FROM_HDR(lseg->pls_layout),\n\t\t\t\t mirror, lseg->pls_range.offset,\n\t\t\t\t lseg->pls_range.length, NFS4ERR_NXIO,\n\t\t\t\t OP_ILLEGAL, GFP_NOIO);\n\tff_layout_send_layouterror(lseg);\n\tif (fail_return || !ff_layout_has_available_ds(lseg))\n\t\tpnfs_error_mark_layout_for_return(ino, lseg);\n\tds = NULL;\nout:\n\treturn ds;\n}\n\nconst struct cred *\nff_layout_get_ds_cred(struct nfs4_ff_layout_mirror *mirror,\n\t\t      const struct pnfs_layout_range *range,\n\t\t      const struct cred *mdscred)\n{\n\tconst struct cred *cred;\n\n\tif (mirror && !mirror->mirror_ds->ds_versions[0].tightly_coupled) {\n\t\tcred = ff_layout_get_mirror_cred(mirror, range->iomode);\n\t\tif (!cred)\n\t\t\tcred = get_cred(mdscred);\n\t} else {\n\t\tcred = get_cred(mdscred);\n\t}\n\treturn cred;\n}\n\n \nstruct rpc_clnt *\nnfs4_ff_find_or_create_ds_client(struct nfs4_ff_layout_mirror *mirror,\n\t\t\t\t struct nfs_client *ds_clp, struct inode *inode)\n{\n\tswitch (mirror->mirror_ds->ds_versions[0].version) {\n\tcase 3:\n\t\t \n\t\treturn ds_clp->cl_rpcclient;\n\tcase 4:\n\t\treturn nfs4_find_or_create_ds_client(ds_clp, inode);\n\tdefault:\n\t\tBUG();\n\t}\n}\n\nvoid ff_layout_free_ds_ioerr(struct list_head *head)\n{\n\tstruct nfs4_ff_layout_ds_err *err;\n\n\twhile (!list_empty(head)) {\n\t\terr = list_first_entry(head,\n\t\t\t\tstruct nfs4_ff_layout_ds_err,\n\t\t\t\tlist);\n\t\tlist_del(&err->list);\n\t\tkfree(err);\n\t}\n}\n\n \nint ff_layout_encode_ds_ioerr(struct xdr_stream *xdr, const struct list_head *head)\n{\n\tstruct nfs4_ff_layout_ds_err *err;\n\t__be32 *p;\n\n\tlist_for_each_entry(err, head, list) {\n\t\t \n\t\tp = xdr_reserve_space(xdr,\n\t\t\t\t28 + NFS4_STATEID_SIZE + NFS4_DEVICEID4_SIZE);\n\t\tif (unlikely(!p))\n\t\t\treturn -ENOBUFS;\n\t\tp = xdr_encode_hyper(p, err->offset);\n\t\tp = xdr_encode_hyper(p, err->length);\n\t\tp = xdr_encode_opaque_fixed(p, &err->stateid,\n\t\t\t\t\t    NFS4_STATEID_SIZE);\n\t\t \n\t\t*p++ = cpu_to_be32(1);\n\t\tp = xdr_encode_opaque_fixed(p, &err->deviceid,\n\t\t\t\t\t    NFS4_DEVICEID4_SIZE);\n\t\t*p++ = cpu_to_be32(err->status);\n\t\t*p++ = cpu_to_be32(err->opnum);\n\t\tdprintk(\"%s: offset %llu length %llu status %d op %d\\n\",\n\t\t\t__func__, err->offset, err->length, err->status,\n\t\t\terr->opnum);\n\t}\n\n\treturn 0;\n}\n\nstatic\nunsigned int do_layout_fetch_ds_ioerr(struct pnfs_layout_hdr *lo,\n\t\t\t\t      const struct pnfs_layout_range *range,\n\t\t\t\t      struct list_head *head,\n\t\t\t\t      unsigned int maxnum)\n{\n\tstruct nfs4_flexfile_layout *flo = FF_LAYOUT_FROM_HDR(lo);\n\tstruct inode *inode = lo->plh_inode;\n\tstruct nfs4_ff_layout_ds_err *err, *n;\n\tunsigned int ret = 0;\n\n\tspin_lock(&inode->i_lock);\n\tlist_for_each_entry_safe(err, n, &flo->error_list, list) {\n\t\tif (!pnfs_is_range_intersecting(err->offset,\n\t\t\t\tpnfs_end_offset(err->offset, err->length),\n\t\t\t\trange->offset,\n\t\t\t\tpnfs_end_offset(range->offset, range->length)))\n\t\t\tcontinue;\n\t\tif (!maxnum)\n\t\t\tbreak;\n\t\tlist_move(&err->list, head);\n\t\tmaxnum--;\n\t\tret++;\n\t}\n\tspin_unlock(&inode->i_lock);\n\treturn ret;\n}\n\nunsigned int ff_layout_fetch_ds_ioerr(struct pnfs_layout_hdr *lo,\n\t\t\t\t      const struct pnfs_layout_range *range,\n\t\t\t\t      struct list_head *head,\n\t\t\t\t      unsigned int maxnum)\n{\n\tunsigned int ret;\n\n\tret = do_layout_fetch_ds_ioerr(lo, range, head, maxnum);\n\t \n\tif (ret == maxnum) {\n\t\tLIST_HEAD(discard);\n\t\tdo_layout_fetch_ds_ioerr(lo, range, &discard, -1);\n\t\tff_layout_free_ds_ioerr(&discard);\n\t}\n\treturn ret;\n}\n\nstatic bool ff_read_layout_has_available_ds(struct pnfs_layout_segment *lseg)\n{\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tstruct nfs4_deviceid_node *devid;\n\tu32 idx;\n\n\tfor (idx = 0; idx < FF_LAYOUT_MIRROR_COUNT(lseg); idx++) {\n\t\tmirror = FF_LAYOUT_COMP(lseg, idx);\n\t\tif (mirror) {\n\t\t\tif (!mirror->mirror_ds)\n\t\t\t\treturn true;\n\t\t\tif (IS_ERR(mirror->mirror_ds))\n\t\t\t\tcontinue;\n\t\t\tdevid = &mirror->mirror_ds->id_node;\n\t\t\tif (!nfs4_test_deviceid_unavailable(devid))\n\t\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n\nstatic bool ff_rw_layout_has_available_ds(struct pnfs_layout_segment *lseg)\n{\n\tstruct nfs4_ff_layout_mirror *mirror;\n\tstruct nfs4_deviceid_node *devid;\n\tu32 idx;\n\n\tfor (idx = 0; idx < FF_LAYOUT_MIRROR_COUNT(lseg); idx++) {\n\t\tmirror = FF_LAYOUT_COMP(lseg, idx);\n\t\tif (!mirror || IS_ERR(mirror->mirror_ds))\n\t\t\treturn false;\n\t\tif (!mirror->mirror_ds)\n\t\t\tcontinue;\n\t\tdevid = &mirror->mirror_ds->id_node;\n\t\tif (nfs4_test_deviceid_unavailable(devid))\n\t\t\treturn false;\n\t}\n\n\treturn FF_LAYOUT_MIRROR_COUNT(lseg) != 0;\n}\n\nstatic bool ff_layout_has_available_ds(struct pnfs_layout_segment *lseg)\n{\n\tif (lseg->pls_range.iomode == IOMODE_READ)\n\t\treturn  ff_read_layout_has_available_ds(lseg);\n\t \n\treturn ff_rw_layout_has_available_ds(lseg);\n}\n\nbool ff_layout_avoid_mds_available_ds(struct pnfs_layout_segment *lseg)\n{\n\treturn ff_layout_no_fallback_to_mds(lseg) ||\n\t       ff_layout_has_available_ds(lseg);\n}\n\nbool ff_layout_avoid_read_on_rw(struct pnfs_layout_segment *lseg)\n{\n\treturn lseg->pls_range.iomode == IOMODE_RW &&\n\t       ff_layout_no_read_on_rw(lseg);\n}\n\nmodule_param(dataserver_retrans, uint, 0644);\nMODULE_PARM_DESC(dataserver_retrans, \"The  number of times the NFSv4.1 client \"\n\t\t\t\"retries a request before it attempts further \"\n\t\t\t\" recovery  action.\");\nmodule_param(dataserver_timeo, uint, 0644);\nMODULE_PARM_DESC(dataserver_timeo, \"The time (in tenths of a second) the \"\n\t\t\t\"NFSv4.1  client  waits for a response from a \"\n\t\t\t\" data server before it retries an NFS request.\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}