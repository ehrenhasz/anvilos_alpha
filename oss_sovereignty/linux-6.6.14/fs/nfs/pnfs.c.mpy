{
  "module_name": "pnfs.c",
  "hash_id": "b4d80167c0edcfaaced22bf1f69668ff00a98e1e2086bcf851ec1ec36b0581a8",
  "original_prompt": "Ingested from linux-6.6.14/fs/nfs/pnfs.c",
  "human_readable_source": " \n\n#include <linux/nfs_fs.h>\n#include <linux/nfs_page.h>\n#include <linux/module.h>\n#include <linux/sort.h>\n#include \"internal.h\"\n#include \"pnfs.h\"\n#include \"iostat.h\"\n#include \"nfs4trace.h\"\n#include \"delegation.h\"\n#include \"nfs42.h\"\n#include \"nfs4_fs.h\"\n\n#define NFSDBG_FACILITY\t\tNFSDBG_PNFS\n#define PNFS_LAYOUTGET_RETRY_TIMEOUT (120*HZ)\n\n \nstatic DEFINE_SPINLOCK(pnfs_spinlock);\n\n \nstatic LIST_HEAD(pnfs_modules_tbl);\n\nstatic void pnfs_layoutreturn_before_put_layout_hdr(struct pnfs_layout_hdr *lo);\nstatic void pnfs_free_returned_lsegs(struct pnfs_layout_hdr *lo,\n\t\tstruct list_head *free_me,\n\t\tconst struct pnfs_layout_range *range,\n\t\tu32 seq);\nstatic bool pnfs_lseg_dec_and_remove_zero(struct pnfs_layout_segment *lseg,\n\t\t                struct list_head *tmp_list);\n\n \nstatic struct pnfs_layoutdriver_type *\nfind_pnfs_driver_locked(u32 id)\n{\n\tstruct pnfs_layoutdriver_type *local;\n\n\tlist_for_each_entry(local, &pnfs_modules_tbl, pnfs_tblid)\n\t\tif (local->id == id)\n\t\t\tgoto out;\n\tlocal = NULL;\nout:\n\tdprintk(\"%s: Searching for id %u, found %p\\n\", __func__, id, local);\n\treturn local;\n}\n\nstatic struct pnfs_layoutdriver_type *\nfind_pnfs_driver(u32 id)\n{\n\tstruct pnfs_layoutdriver_type *local;\n\n\tspin_lock(&pnfs_spinlock);\n\tlocal = find_pnfs_driver_locked(id);\n\tif (local != NULL && !try_module_get(local->owner)) {\n\t\tdprintk(\"%s: Could not grab reference on module\\n\", __func__);\n\t\tlocal = NULL;\n\t}\n\tspin_unlock(&pnfs_spinlock);\n\treturn local;\n}\n\nconst struct pnfs_layoutdriver_type *pnfs_find_layoutdriver(u32 id)\n{\n\treturn find_pnfs_driver(id);\n}\n\nvoid pnfs_put_layoutdriver(const struct pnfs_layoutdriver_type *ld)\n{\n\tif (ld)\n\t\tmodule_put(ld->owner);\n}\n\nvoid\nunset_pnfs_layoutdriver(struct nfs_server *nfss)\n{\n\tif (nfss->pnfs_curr_ld) {\n\t\tif (nfss->pnfs_curr_ld->clear_layoutdriver)\n\t\t\tnfss->pnfs_curr_ld->clear_layoutdriver(nfss);\n\t\t \n\t\tif (atomic_dec_and_test(&nfss->nfs_client->cl_mds_count))\n\t\t\tnfs4_deviceid_purge_client(nfss->nfs_client);\n\t\tmodule_put(nfss->pnfs_curr_ld->owner);\n\t}\n\tnfss->pnfs_curr_ld = NULL;\n}\n\n \nstatic const u32 ld_prefs[] = {\n\tLAYOUT_SCSI,\n\tLAYOUT_BLOCK_VOLUME,\n\tLAYOUT_OSD2_OBJECTS,\n\tLAYOUT_FLEX_FILES,\n\tLAYOUT_NFSV4_1_FILES,\n\t0\n};\n\nstatic int\nld_cmp(const void *e1, const void *e2)\n{\n\tu32 ld1 = *((u32 *)e1);\n\tu32 ld2 = *((u32 *)e2);\n\tint i;\n\n\tfor (i = 0; ld_prefs[i] != 0; i++) {\n\t\tif (ld1 == ld_prefs[i])\n\t\t\treturn -1;\n\n\t\tif (ld2 == ld_prefs[i])\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nvoid\nset_pnfs_layoutdriver(struct nfs_server *server, const struct nfs_fh *mntfh,\n\t\t      struct nfs_fsinfo *fsinfo)\n{\n\tstruct pnfs_layoutdriver_type *ld_type = NULL;\n\tu32 id;\n\tint i;\n\n\tif (fsinfo->nlayouttypes == 0)\n\t\tgoto out_no_driver;\n\tif (!(server->nfs_client->cl_exchange_flags &\n\t\t (EXCHGID4_FLAG_USE_NON_PNFS | EXCHGID4_FLAG_USE_PNFS_MDS))) {\n\t\tprintk(KERN_ERR \"NFS: %s: cl_exchange_flags 0x%x\\n\",\n\t\t\t__func__, server->nfs_client->cl_exchange_flags);\n\t\tgoto out_no_driver;\n\t}\n\n\tsort(fsinfo->layouttype, fsinfo->nlayouttypes,\n\t\tsizeof(*fsinfo->layouttype), ld_cmp, NULL);\n\n\tfor (i = 0; i < fsinfo->nlayouttypes; i++) {\n\t\tid = fsinfo->layouttype[i];\n\t\tld_type = find_pnfs_driver(id);\n\t\tif (!ld_type) {\n\t\t\trequest_module(\"%s-%u\", LAYOUT_NFSV4_1_MODULE_PREFIX,\n\t\t\t\t\tid);\n\t\t\tld_type = find_pnfs_driver(id);\n\t\t}\n\t\tif (ld_type)\n\t\t\tbreak;\n\t}\n\n\tif (!ld_type) {\n\t\tdprintk(\"%s: No pNFS module found!\\n\", __func__);\n\t\tgoto out_no_driver;\n\t}\n\n\tserver->pnfs_curr_ld = ld_type;\n\tif (ld_type->set_layoutdriver\n\t    && ld_type->set_layoutdriver(server, mntfh)) {\n\t\tprintk(KERN_ERR \"NFS: %s: Error initializing pNFS layout \"\n\t\t\t\"driver %u.\\n\", __func__, id);\n\t\tmodule_put(ld_type->owner);\n\t\tgoto out_no_driver;\n\t}\n\t \n\tatomic_inc(&server->nfs_client->cl_mds_count);\n\n\tdprintk(\"%s: pNFS module for %u set\\n\", __func__, id);\n\treturn;\n\nout_no_driver:\n\tdprintk(\"%s: Using NFSv4 I/O\\n\", __func__);\n\tserver->pnfs_curr_ld = NULL;\n}\n\nint\npnfs_register_layoutdriver(struct pnfs_layoutdriver_type *ld_type)\n{\n\tint status = -EINVAL;\n\tstruct pnfs_layoutdriver_type *tmp;\n\n\tif (ld_type->id == 0) {\n\t\tprintk(KERN_ERR \"NFS: %s id 0 is reserved\\n\", __func__);\n\t\treturn status;\n\t}\n\tif (!ld_type->alloc_lseg || !ld_type->free_lseg) {\n\t\tprintk(KERN_ERR \"NFS: %s Layout driver must provide \"\n\t\t       \"alloc_lseg and free_lseg.\\n\", __func__);\n\t\treturn status;\n\t}\n\n\tspin_lock(&pnfs_spinlock);\n\ttmp = find_pnfs_driver_locked(ld_type->id);\n\tif (!tmp) {\n\t\tlist_add(&ld_type->pnfs_tblid, &pnfs_modules_tbl);\n\t\tstatus = 0;\n\t\tdprintk(\"%s Registering id:%u name:%s\\n\", __func__, ld_type->id,\n\t\t\tld_type->name);\n\t} else {\n\t\tprintk(KERN_ERR \"NFS: %s Module with id %d already loaded!\\n\",\n\t\t\t__func__, ld_type->id);\n\t}\n\tspin_unlock(&pnfs_spinlock);\n\n\treturn status;\n}\nEXPORT_SYMBOL_GPL(pnfs_register_layoutdriver);\n\nvoid\npnfs_unregister_layoutdriver(struct pnfs_layoutdriver_type *ld_type)\n{\n\tdprintk(\"%s Deregistering id:%u\\n\", __func__, ld_type->id);\n\tspin_lock(&pnfs_spinlock);\n\tlist_del(&ld_type->pnfs_tblid);\n\tspin_unlock(&pnfs_spinlock);\n}\nEXPORT_SYMBOL_GPL(pnfs_unregister_layoutdriver);\n\n \n\n \nvoid\npnfs_get_layout_hdr(struct pnfs_layout_hdr *lo)\n{\n\trefcount_inc(&lo->plh_refcount);\n}\n\nstatic struct pnfs_layout_hdr *\npnfs_alloc_layout_hdr(struct inode *ino, gfp_t gfp_flags)\n{\n\tstruct pnfs_layoutdriver_type *ld = NFS_SERVER(ino)->pnfs_curr_ld;\n\treturn ld->alloc_layout_hdr(ino, gfp_flags);\n}\n\nstatic void\npnfs_free_layout_hdr(struct pnfs_layout_hdr *lo)\n{\n\tstruct nfs_server *server = NFS_SERVER(lo->plh_inode);\n\tstruct pnfs_layoutdriver_type *ld = server->pnfs_curr_ld;\n\n\tif (test_and_clear_bit(NFS_LAYOUT_HASHED, &lo->plh_flags)) {\n\t\tstruct nfs_client *clp = server->nfs_client;\n\n\t\tspin_lock(&clp->cl_lock);\n\t\tlist_del_rcu(&lo->plh_layouts);\n\t\tspin_unlock(&clp->cl_lock);\n\t}\n\tput_cred(lo->plh_lc_cred);\n\treturn ld->free_layout_hdr(lo);\n}\n\nstatic void\npnfs_detach_layout_hdr(struct pnfs_layout_hdr *lo)\n{\n\tstruct nfs_inode *nfsi = NFS_I(lo->plh_inode);\n\tdprintk(\"%s: freeing layout cache %p\\n\", __func__, lo);\n\tnfsi->layout = NULL;\n\t \n\tnfsi->write_io = 0;\n\tnfsi->read_io = 0;\n}\n\nvoid\npnfs_put_layout_hdr(struct pnfs_layout_hdr *lo)\n{\n\tstruct inode *inode;\n\tunsigned long i_state;\n\n\tif (!lo)\n\t\treturn;\n\tinode = lo->plh_inode;\n\tpnfs_layoutreturn_before_put_layout_hdr(lo);\n\n\tif (refcount_dec_and_lock(&lo->plh_refcount, &inode->i_lock)) {\n\t\tif (!list_empty(&lo->plh_segs))\n\t\t\tWARN_ONCE(1, \"NFS: BUG unfreed layout segments.\\n\");\n\t\tpnfs_detach_layout_hdr(lo);\n\t\ti_state = inode->i_state;\n\t\tspin_unlock(&inode->i_lock);\n\t\tpnfs_free_layout_hdr(lo);\n\t\t \n\t\tif (i_state & (I_FREEING | I_CLEAR))\n\t\t\twake_up_var(lo);\n\t}\n}\n\nstatic struct inode *\npnfs_grab_inode_layout_hdr(struct pnfs_layout_hdr *lo)\n{\n\tstruct inode *inode = igrab(lo->plh_inode);\n\tif (inode)\n\t\treturn inode;\n\tset_bit(NFS_LAYOUT_INODE_FREEING, &lo->plh_flags);\n\treturn NULL;\n}\n\n \nstatic bool pnfs_seqid_is_newer(u32 s1, u32 s2)\n{\n\treturn (s32)(s1 - s2) > 0;\n}\n\nstatic void pnfs_barrier_update(struct pnfs_layout_hdr *lo, u32 newseq)\n{\n\tif (pnfs_seqid_is_newer(newseq, lo->plh_barrier) || !lo->plh_barrier)\n\t\tlo->plh_barrier = newseq;\n}\n\nstatic void\npnfs_set_plh_return_info(struct pnfs_layout_hdr *lo, enum pnfs_iomode iomode,\n\t\t\t u32 seq)\n{\n\tif (lo->plh_return_iomode != 0 && lo->plh_return_iomode != iomode)\n\t\tiomode = IOMODE_ANY;\n\tlo->plh_return_iomode = iomode;\n\tset_bit(NFS_LAYOUT_RETURN_REQUESTED, &lo->plh_flags);\n\t \n\tif (seq == 0)\n\t\tseq = be32_to_cpu(lo->plh_stateid.seqid);\n\tif (!lo->plh_return_seq || pnfs_seqid_is_newer(seq, lo->plh_return_seq))\n\t\tlo->plh_return_seq = seq;\n\tpnfs_barrier_update(lo, seq);\n}\n\nstatic void\npnfs_clear_layoutreturn_info(struct pnfs_layout_hdr *lo)\n{\n\tstruct pnfs_layout_segment *lseg;\n\tlo->plh_return_iomode = 0;\n\tlo->plh_return_seq = 0;\n\tclear_bit(NFS_LAYOUT_RETURN_REQUESTED, &lo->plh_flags);\n\tlist_for_each_entry(lseg, &lo->plh_segs, pls_list) {\n\t\tif (!test_bit(NFS_LSEG_LAYOUTRETURN, &lseg->pls_flags))\n\t\t\tcontinue;\n\t\tpnfs_set_plh_return_info(lo, lseg->pls_range.iomode, 0);\n\t}\n}\n\nstatic void pnfs_clear_layoutreturn_waitbit(struct pnfs_layout_hdr *lo)\n{\n\tclear_bit_unlock(NFS_LAYOUT_RETURN, &lo->plh_flags);\n\tclear_bit(NFS_LAYOUT_RETURN_LOCK, &lo->plh_flags);\n\tsmp_mb__after_atomic();\n\twake_up_bit(&lo->plh_flags, NFS_LAYOUT_RETURN);\n\trpc_wake_up(&NFS_SERVER(lo->plh_inode)->roc_rpcwaitq);\n}\n\nstatic void\npnfs_clear_lseg_state(struct pnfs_layout_segment *lseg,\n\t\tstruct list_head *free_me)\n{\n\tclear_bit(NFS_LSEG_ROC, &lseg->pls_flags);\n\tclear_bit(NFS_LSEG_LAYOUTRETURN, &lseg->pls_flags);\n\tif (test_and_clear_bit(NFS_LSEG_VALID, &lseg->pls_flags))\n\t\tpnfs_lseg_dec_and_remove_zero(lseg, free_me);\n\tif (test_and_clear_bit(NFS_LSEG_LAYOUTCOMMIT, &lseg->pls_flags))\n\t\tpnfs_lseg_dec_and_remove_zero(lseg, free_me);\n}\n\n \nbool nfs4_layout_refresh_old_stateid(nfs4_stateid *dst,\n\t\tstruct pnfs_layout_range *dst_range,\n\t\tstruct inode *inode)\n{\n\tstruct pnfs_layout_hdr *lo;\n\tstruct pnfs_layout_range range = {\n\t\t.iomode = IOMODE_ANY,\n\t\t.offset = 0,\n\t\t.length = NFS4_MAX_UINT64,\n\t};\n\tbool ret = false;\n\tLIST_HEAD(head);\n\tint err;\n\n\tspin_lock(&inode->i_lock);\n\tlo = NFS_I(inode)->layout;\n\tif (lo &&  pnfs_layout_is_valid(lo) &&\n\t    nfs4_stateid_match_other(dst, &lo->plh_stateid)) {\n\t\t \n\t\tif (!nfs4_stateid_is_newer(&lo->plh_stateid, dst)) {\n\t\t\tnfs4_stateid_seqid_inc(dst);\n\t\t\tret = true;\n\t\t\tgoto out;\n\t\t}\n\t\t \n\t\terr = pnfs_mark_matching_lsegs_return(lo, &head, &range, 0);\n\t\tif (err != -EBUSY) {\n\t\t\tdst->seqid = lo->plh_stateid.seqid;\n\t\t\t*dst_range = range;\n\t\t\tret = true;\n\t\t}\n\t}\nout:\n\tspin_unlock(&inode->i_lock);\n\tpnfs_free_lseg_list(&head);\n\treturn ret;\n}\n\n \nint\npnfs_mark_layout_stateid_invalid(struct pnfs_layout_hdr *lo,\n\t\tstruct list_head *lseg_list)\n{\n\tstruct pnfs_layout_range range = {\n\t\t.iomode = IOMODE_ANY,\n\t\t.offset = 0,\n\t\t.length = NFS4_MAX_UINT64,\n\t};\n\tstruct pnfs_layout_segment *lseg, *next;\n\n\tset_bit(NFS_LAYOUT_INVALID_STID, &lo->plh_flags);\n\tlist_for_each_entry_safe(lseg, next, &lo->plh_segs, pls_list)\n\t\tpnfs_clear_lseg_state(lseg, lseg_list);\n\tpnfs_clear_layoutreturn_info(lo);\n\tpnfs_free_returned_lsegs(lo, lseg_list, &range, 0);\n\tset_bit(NFS_LAYOUT_DRAIN, &lo->plh_flags);\n\tif (test_bit(NFS_LAYOUT_RETURN, &lo->plh_flags) &&\n\t    !test_and_set_bit(NFS_LAYOUT_RETURN_LOCK, &lo->plh_flags))\n\t\tpnfs_clear_layoutreturn_waitbit(lo);\n\treturn !list_empty(&lo->plh_segs);\n}\n\nstatic int\npnfs_iomode_to_fail_bit(u32 iomode)\n{\n\treturn iomode == IOMODE_RW ?\n\t\tNFS_LAYOUT_RW_FAILED : NFS_LAYOUT_RO_FAILED;\n}\n\nstatic void\npnfs_layout_set_fail_bit(struct pnfs_layout_hdr *lo, int fail_bit)\n{\n\tlo->plh_retry_timestamp = jiffies;\n\tif (!test_and_set_bit(fail_bit, &lo->plh_flags))\n\t\trefcount_inc(&lo->plh_refcount);\n}\n\nstatic void\npnfs_layout_clear_fail_bit(struct pnfs_layout_hdr *lo, int fail_bit)\n{\n\tif (test_and_clear_bit(fail_bit, &lo->plh_flags))\n\t\trefcount_dec(&lo->plh_refcount);\n}\n\nstatic void\npnfs_layout_io_set_failed(struct pnfs_layout_hdr *lo, u32 iomode)\n{\n\tstruct inode *inode = lo->plh_inode;\n\tstruct pnfs_layout_range range = {\n\t\t.iomode = iomode,\n\t\t.offset = 0,\n\t\t.length = NFS4_MAX_UINT64,\n\t};\n\tLIST_HEAD(head);\n\n\tspin_lock(&inode->i_lock);\n\tpnfs_layout_set_fail_bit(lo, pnfs_iomode_to_fail_bit(iomode));\n\tpnfs_mark_matching_lsegs_return(lo, &head, &range, 0);\n\tspin_unlock(&inode->i_lock);\n\tpnfs_free_lseg_list(&head);\n\tdprintk(\"%s Setting layout IOMODE_%s fail bit\\n\", __func__,\n\t\t\tiomode == IOMODE_RW ?  \"RW\" : \"READ\");\n}\n\nstatic bool\npnfs_layout_io_test_failed(struct pnfs_layout_hdr *lo, u32 iomode)\n{\n\tunsigned long start, end;\n\tint fail_bit = pnfs_iomode_to_fail_bit(iomode);\n\n\tif (test_bit(fail_bit, &lo->plh_flags) == 0)\n\t\treturn false;\n\tend = jiffies;\n\tstart = end - PNFS_LAYOUTGET_RETRY_TIMEOUT;\n\tif (!time_in_range(lo->plh_retry_timestamp, start, end)) {\n\t\t \n\t\tpnfs_layout_clear_fail_bit(lo, fail_bit);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic void\npnfs_init_lseg(struct pnfs_layout_hdr *lo, struct pnfs_layout_segment *lseg,\n\t\tconst struct pnfs_layout_range *range,\n\t\tconst nfs4_stateid *stateid)\n{\n\tINIT_LIST_HEAD(&lseg->pls_list);\n\tINIT_LIST_HEAD(&lseg->pls_lc_list);\n\tINIT_LIST_HEAD(&lseg->pls_commits);\n\trefcount_set(&lseg->pls_refcount, 1);\n\tset_bit(NFS_LSEG_VALID, &lseg->pls_flags);\n\tlseg->pls_layout = lo;\n\tlseg->pls_range = *range;\n\tlseg->pls_seq = be32_to_cpu(stateid->seqid);\n}\n\nstatic void pnfs_free_lseg(struct pnfs_layout_segment *lseg)\n{\n\tif (lseg != NULL) {\n\t\tstruct inode *inode = lseg->pls_layout->plh_inode;\n\t\tNFS_SERVER(inode)->pnfs_curr_ld->free_lseg(lseg);\n\t}\n}\n\nstatic void\npnfs_layout_remove_lseg(struct pnfs_layout_hdr *lo,\n\t\tstruct pnfs_layout_segment *lseg)\n{\n\tWARN_ON(test_bit(NFS_LSEG_VALID, &lseg->pls_flags));\n\tlist_del_init(&lseg->pls_list);\n\t \n\trefcount_dec(&lo->plh_refcount);\n\tif (test_bit(NFS_LSEG_LAYOUTRETURN, &lseg->pls_flags))\n\t\treturn;\n\tif (list_empty(&lo->plh_segs) &&\n\t    !test_bit(NFS_LAYOUT_RETURN_REQUESTED, &lo->plh_flags) &&\n\t    !test_bit(NFS_LAYOUT_RETURN, &lo->plh_flags)) {\n\t\tif (atomic_read(&lo->plh_outstanding) == 0)\n\t\t\tset_bit(NFS_LAYOUT_INVALID_STID, &lo->plh_flags);\n\t\tclear_bit(NFS_LAYOUT_BULK_RECALL, &lo->plh_flags);\n\t}\n}\n\nstatic bool\npnfs_cache_lseg_for_layoutreturn(struct pnfs_layout_hdr *lo,\n\t\tstruct pnfs_layout_segment *lseg)\n{\n\tif (test_and_clear_bit(NFS_LSEG_LAYOUTRETURN, &lseg->pls_flags) &&\n\t    pnfs_layout_is_valid(lo)) {\n\t\tpnfs_set_plh_return_info(lo, lseg->pls_range.iomode, 0);\n\t\tlist_move_tail(&lseg->pls_list, &lo->plh_return_segs);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nvoid\npnfs_put_lseg(struct pnfs_layout_segment *lseg)\n{\n\tstruct pnfs_layout_hdr *lo;\n\tstruct inode *inode;\n\n\tif (!lseg)\n\t\treturn;\n\n\tdprintk(\"%s: lseg %p ref %d valid %d\\n\", __func__, lseg,\n\t\trefcount_read(&lseg->pls_refcount),\n\t\ttest_bit(NFS_LSEG_VALID, &lseg->pls_flags));\n\n\tlo = lseg->pls_layout;\n\tinode = lo->plh_inode;\n\n\tif (refcount_dec_and_lock(&lseg->pls_refcount, &inode->i_lock)) {\n\t\tpnfs_get_layout_hdr(lo);\n\t\tpnfs_layout_remove_lseg(lo, lseg);\n\t\tif (pnfs_cache_lseg_for_layoutreturn(lo, lseg))\n\t\t\tlseg = NULL;\n\t\tspin_unlock(&inode->i_lock);\n\t\tpnfs_free_lseg(lseg);\n\t\tpnfs_put_layout_hdr(lo);\n\t}\n}\nEXPORT_SYMBOL_GPL(pnfs_put_lseg);\n\n \nstatic bool\npnfs_lseg_range_contained(const struct pnfs_layout_range *l1,\n\t\t const struct pnfs_layout_range *l2)\n{\n\tu64 start1 = l1->offset;\n\tu64 end1 = pnfs_end_offset(start1, l1->length);\n\tu64 start2 = l2->offset;\n\tu64 end2 = pnfs_end_offset(start2, l2->length);\n\n\treturn (start1 <= start2) && (end1 >= end2);\n}\n\nstatic bool pnfs_lseg_dec_and_remove_zero(struct pnfs_layout_segment *lseg,\n\t\tstruct list_head *tmp_list)\n{\n\tif (!refcount_dec_and_test(&lseg->pls_refcount))\n\t\treturn false;\n\tpnfs_layout_remove_lseg(lseg->pls_layout, lseg);\n\tlist_add(&lseg->pls_list, tmp_list);\n\treturn true;\n}\n\n \nstatic int mark_lseg_invalid(struct pnfs_layout_segment *lseg,\n\t\t\t     struct list_head *tmp_list)\n{\n\tint rv = 0;\n\n\tif (test_and_clear_bit(NFS_LSEG_VALID, &lseg->pls_flags)) {\n\t\t \n\t\tdprintk(\"%s: lseg %p ref %d\\n\", __func__, lseg,\n\t\t\trefcount_read(&lseg->pls_refcount));\n\t\tif (pnfs_lseg_dec_and_remove_zero(lseg, tmp_list))\n\t\t\trv = 1;\n\t}\n\treturn rv;\n}\n\nstatic bool\npnfs_should_free_range(const struct pnfs_layout_range *lseg_range,\n\t\t const struct pnfs_layout_range *recall_range)\n{\n\treturn (recall_range->iomode == IOMODE_ANY ||\n\t\tlseg_range->iomode == recall_range->iomode) &&\n\t       pnfs_lseg_range_intersecting(lseg_range, recall_range);\n}\n\nstatic bool\npnfs_match_lseg_recall(const struct pnfs_layout_segment *lseg,\n\t\tconst struct pnfs_layout_range *recall_range,\n\t\tu32 seq)\n{\n\tif (seq != 0 && pnfs_seqid_is_newer(lseg->pls_seq, seq))\n\t\treturn false;\n\tif (recall_range == NULL)\n\t\treturn true;\n\treturn pnfs_should_free_range(&lseg->pls_range, recall_range);\n}\n\n \nint\npnfs_mark_matching_lsegs_invalid(struct pnfs_layout_hdr *lo,\n\t\t\t    struct list_head *tmp_list,\n\t\t\t    const struct pnfs_layout_range *recall_range,\n\t\t\t    u32 seq)\n{\n\tstruct pnfs_layout_segment *lseg, *next;\n\tstruct nfs_server *server = NFS_SERVER(lo->plh_inode);\n\tint remaining = 0;\n\n\tdprintk(\"%s:Begin lo %p\\n\", __func__, lo);\n\n\tif (list_empty(&lo->plh_segs))\n\t\treturn 0;\n\tlist_for_each_entry_safe(lseg, next, &lo->plh_segs, pls_list)\n\t\tif (pnfs_match_lseg_recall(lseg, recall_range, seq)) {\n\t\t\tdprintk(\"%s: freeing lseg %p iomode %d seq %u \"\n\t\t\t\t\"offset %llu length %llu\\n\", __func__,\n\t\t\t\tlseg, lseg->pls_range.iomode, lseg->pls_seq,\n\t\t\t\tlseg->pls_range.offset, lseg->pls_range.length);\n\t\t\tif (mark_lseg_invalid(lseg, tmp_list))\n\t\t\t\tcontinue;\n\t\t\tremaining++;\n\t\t\tpnfs_lseg_cancel_io(server, lseg);\n\t\t}\n\tdprintk(\"%s:Return %i\\n\", __func__, remaining);\n\treturn remaining;\n}\n\nstatic void\npnfs_free_returned_lsegs(struct pnfs_layout_hdr *lo,\n\t\tstruct list_head *free_me,\n\t\tconst struct pnfs_layout_range *range,\n\t\tu32 seq)\n{\n\tstruct pnfs_layout_segment *lseg, *next;\n\n\tlist_for_each_entry_safe(lseg, next, &lo->plh_return_segs, pls_list) {\n\t\tif (pnfs_match_lseg_recall(lseg, range, seq))\n\t\t\tlist_move_tail(&lseg->pls_list, free_me);\n\t}\n}\n\n \nvoid\npnfs_free_lseg_list(struct list_head *free_me)\n{\n\tstruct pnfs_layout_segment *lseg, *tmp;\n\n\tif (list_empty(free_me))\n\t\treturn;\n\n\tlist_for_each_entry_safe(lseg, tmp, free_me, pls_list) {\n\t\tlist_del(&lseg->pls_list);\n\t\tpnfs_free_lseg(lseg);\n\t}\n}\n\nstatic struct pnfs_layout_hdr *__pnfs_destroy_layout(struct nfs_inode *nfsi)\n{\n\tstruct pnfs_layout_hdr *lo;\n\tLIST_HEAD(tmp_list);\n\n\tspin_lock(&nfsi->vfs_inode.i_lock);\n\tlo = nfsi->layout;\n\tif (lo) {\n\t\tpnfs_get_layout_hdr(lo);\n\t\tpnfs_mark_layout_stateid_invalid(lo, &tmp_list);\n\t\tpnfs_layout_clear_fail_bit(lo, NFS_LAYOUT_RO_FAILED);\n\t\tpnfs_layout_clear_fail_bit(lo, NFS_LAYOUT_RW_FAILED);\n\t\tspin_unlock(&nfsi->vfs_inode.i_lock);\n\t\tpnfs_free_lseg_list(&tmp_list);\n\t\tnfs_commit_inode(&nfsi->vfs_inode, 0);\n\t\tpnfs_put_layout_hdr(lo);\n\t} else\n\t\tspin_unlock(&nfsi->vfs_inode.i_lock);\n\treturn lo;\n}\n\nvoid pnfs_destroy_layout(struct nfs_inode *nfsi)\n{\n\t__pnfs_destroy_layout(nfsi);\n}\nEXPORT_SYMBOL_GPL(pnfs_destroy_layout);\n\nstatic bool pnfs_layout_removed(struct nfs_inode *nfsi,\n\t\t\t\tstruct pnfs_layout_hdr *lo)\n{\n\tbool ret;\n\n\tspin_lock(&nfsi->vfs_inode.i_lock);\n\tret = nfsi->layout != lo;\n\tspin_unlock(&nfsi->vfs_inode.i_lock);\n\treturn ret;\n}\n\nvoid pnfs_destroy_layout_final(struct nfs_inode *nfsi)\n{\n\tstruct pnfs_layout_hdr *lo = __pnfs_destroy_layout(nfsi);\n\n\tif (lo)\n\t\twait_var_event(lo, pnfs_layout_removed(nfsi, lo));\n}\n\nstatic bool\npnfs_layout_add_bulk_destroy_list(struct inode *inode,\n\t\tstruct list_head *layout_list)\n{\n\tstruct pnfs_layout_hdr *lo;\n\tbool ret = false;\n\n\tspin_lock(&inode->i_lock);\n\tlo = NFS_I(inode)->layout;\n\tif (lo != NULL && list_empty(&lo->plh_bulk_destroy)) {\n\t\tpnfs_get_layout_hdr(lo);\n\t\tlist_add(&lo->plh_bulk_destroy, layout_list);\n\t\tret = true;\n\t}\n\tspin_unlock(&inode->i_lock);\n\treturn ret;\n}\n\n \nstatic int\npnfs_layout_bulk_destroy_byserver_locked(struct nfs_client *clp,\n\t\tstruct nfs_server *server,\n\t\tstruct list_head *layout_list)\n\t__must_hold(&clp->cl_lock)\n\t__must_hold(RCU)\n{\n\tstruct pnfs_layout_hdr *lo, *next;\n\tstruct inode *inode;\n\n\tlist_for_each_entry_safe(lo, next, &server->layouts, plh_layouts) {\n\t\tif (test_bit(NFS_LAYOUT_INVALID_STID, &lo->plh_flags) ||\n\t\t    test_bit(NFS_LAYOUT_INODE_FREEING, &lo->plh_flags) ||\n\t\t    !list_empty(&lo->plh_bulk_destroy))\n\t\t\tcontinue;\n\t\t \n\t\tif (!nfs_sb_active(server->super))\n\t\t\tbreak;\n\t\tinode = pnfs_grab_inode_layout_hdr(lo);\n\t\tif (inode != NULL) {\n\t\t\tif (test_and_clear_bit(NFS_LAYOUT_HASHED, &lo->plh_flags))\n\t\t\t\tlist_del_rcu(&lo->plh_layouts);\n\t\t\tif (pnfs_layout_add_bulk_destroy_list(inode,\n\t\t\t\t\t\tlayout_list))\n\t\t\t\tcontinue;\n\t\t\trcu_read_unlock();\n\t\t\tspin_unlock(&clp->cl_lock);\n\t\t\tiput(inode);\n\t\t} else {\n\t\t\trcu_read_unlock();\n\t\t\tspin_unlock(&clp->cl_lock);\n\t\t}\n\t\tnfs_sb_deactive(server->super);\n\t\tspin_lock(&clp->cl_lock);\n\t\trcu_read_lock();\n\t\treturn -EAGAIN;\n\t}\n\treturn 0;\n}\n\nstatic int\npnfs_layout_free_bulk_destroy_list(struct list_head *layout_list,\n\t\tbool is_bulk_recall)\n{\n\tstruct pnfs_layout_hdr *lo;\n\tstruct inode *inode;\n\tLIST_HEAD(lseg_list);\n\tint ret = 0;\n\n\twhile (!list_empty(layout_list)) {\n\t\tlo = list_entry(layout_list->next, struct pnfs_layout_hdr,\n\t\t\t\tplh_bulk_destroy);\n\t\tdprintk(\"%s freeing layout for inode %lu\\n\", __func__,\n\t\t\tlo->plh_inode->i_ino);\n\t\tinode = lo->plh_inode;\n\n\t\tpnfs_layoutcommit_inode(inode, false);\n\n\t\tspin_lock(&inode->i_lock);\n\t\tlist_del_init(&lo->plh_bulk_destroy);\n\t\tif (pnfs_mark_layout_stateid_invalid(lo, &lseg_list)) {\n\t\t\tif (is_bulk_recall)\n\t\t\t\tset_bit(NFS_LAYOUT_BULK_RECALL, &lo->plh_flags);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\tspin_unlock(&inode->i_lock);\n\t\tpnfs_free_lseg_list(&lseg_list);\n\t\t \n\t\tnfs_commit_inode(inode, 0);\n\t\tpnfs_put_layout_hdr(lo);\n\t\tnfs_iput_and_deactive(inode);\n\t}\n\treturn ret;\n}\n\nint\npnfs_destroy_layouts_byfsid(struct nfs_client *clp,\n\t\tstruct nfs_fsid *fsid,\n\t\tbool is_recall)\n{\n\tstruct nfs_server *server;\n\tLIST_HEAD(layout_list);\n\n\tspin_lock(&clp->cl_lock);\n\trcu_read_lock();\nrestart:\n\tlist_for_each_entry_rcu(server, &clp->cl_superblocks, client_link) {\n\t\tif (memcmp(&server->fsid, fsid, sizeof(*fsid)) != 0)\n\t\t\tcontinue;\n\t\tif (pnfs_layout_bulk_destroy_byserver_locked(clp,\n\t\t\t\tserver,\n\t\t\t\t&layout_list) != 0)\n\t\t\tgoto restart;\n\t}\n\trcu_read_unlock();\n\tspin_unlock(&clp->cl_lock);\n\n\tif (list_empty(&layout_list))\n\t\treturn 0;\n\treturn pnfs_layout_free_bulk_destroy_list(&layout_list, is_recall);\n}\n\nint\npnfs_destroy_layouts_byclid(struct nfs_client *clp,\n\t\tbool is_recall)\n{\n\tstruct nfs_server *server;\n\tLIST_HEAD(layout_list);\n\n\tspin_lock(&clp->cl_lock);\n\trcu_read_lock();\nrestart:\n\tlist_for_each_entry_rcu(server, &clp->cl_superblocks, client_link) {\n\t\tif (pnfs_layout_bulk_destroy_byserver_locked(clp,\n\t\t\t\t\tserver,\n\t\t\t\t\t&layout_list) != 0)\n\t\t\tgoto restart;\n\t}\n\trcu_read_unlock();\n\tspin_unlock(&clp->cl_lock);\n\n\tif (list_empty(&layout_list))\n\t\treturn 0;\n\treturn pnfs_layout_free_bulk_destroy_list(&layout_list, is_recall);\n}\n\n \nvoid\npnfs_destroy_all_layouts(struct nfs_client *clp)\n{\n\tnfs4_deviceid_mark_client_invalid(clp);\n\tnfs4_deviceid_purge_client(clp);\n\n\tpnfs_destroy_layouts_byclid(clp, false);\n}\n\nstatic void\npnfs_set_layout_cred(struct pnfs_layout_hdr *lo, const struct cred *cred)\n{\n\tconst struct cred *old;\n\n\tif (cred && cred_fscmp(lo->plh_lc_cred, cred) != 0) {\n\t\told = xchg(&lo->plh_lc_cred, get_cred(cred));\n\t\tput_cred(old);\n\t}\n}\n\n \nvoid\npnfs_set_layout_stateid(struct pnfs_layout_hdr *lo, const nfs4_stateid *new,\n\t\t\tconst struct cred *cred, bool update_barrier)\n{\n\tu32 oldseq = be32_to_cpu(lo->plh_stateid.seqid);\n\tu32 newseq = be32_to_cpu(new->seqid);\n\n\tif (!pnfs_layout_is_valid(lo)) {\n\t\tpnfs_set_layout_cred(lo, cred);\n\t\tnfs4_stateid_copy(&lo->plh_stateid, new);\n\t\tlo->plh_barrier = newseq;\n\t\tpnfs_clear_layoutreturn_info(lo);\n\t\tclear_bit(NFS_LAYOUT_INVALID_STID, &lo->plh_flags);\n\t\treturn;\n\t}\n\n\tif (pnfs_seqid_is_newer(newseq, oldseq))\n\t\tnfs4_stateid_copy(&lo->plh_stateid, new);\n\n\tif (update_barrier) {\n\t\tpnfs_barrier_update(lo, newseq);\n\t\treturn;\n\t}\n\t \n\tif (atomic_read(&lo->plh_outstanding) == 1)\n\t\t pnfs_barrier_update(lo, be32_to_cpu(lo->plh_stateid.seqid));\n}\n\nstatic bool\npnfs_layout_stateid_blocked(const struct pnfs_layout_hdr *lo,\n\t\tconst nfs4_stateid *stateid)\n{\n\tu32 seqid = be32_to_cpu(stateid->seqid);\n\n\treturn lo->plh_barrier && pnfs_seqid_is_newer(lo->plh_barrier, seqid);\n}\n\n \nstatic bool\npnfs_layoutgets_blocked(const struct pnfs_layout_hdr *lo)\n{\n\treturn lo->plh_block_lgets ||\n\t\ttest_bit(NFS_LAYOUT_BULK_RECALL, &lo->plh_flags);\n}\n\nstatic struct nfs_server *\npnfs_find_server(struct inode *inode, struct nfs_open_context *ctx)\n{\n\tstruct nfs_server *server;\n\n\tif (inode) {\n\t\tserver = NFS_SERVER(inode);\n\t} else {\n\t\tstruct dentry *parent_dir = dget_parent(ctx->dentry);\n\t\tserver = NFS_SERVER(parent_dir->d_inode);\n\t\tdput(parent_dir);\n\t}\n\treturn server;\n}\n\nstatic void nfs4_free_pages(struct page **pages, size_t size)\n{\n\tint i;\n\n\tif (!pages)\n\t\treturn;\n\n\tfor (i = 0; i < size; i++) {\n\t\tif (!pages[i])\n\t\t\tbreak;\n\t\t__free_page(pages[i]);\n\t}\n\tkfree(pages);\n}\n\nstatic struct page **nfs4_alloc_pages(size_t size, gfp_t gfp_flags)\n{\n\tstruct page **pages;\n\tint i;\n\n\tpages = kmalloc_array(size, sizeof(struct page *), gfp_flags);\n\tif (!pages) {\n\t\tdprintk(\"%s: can't alloc array of %zu pages\\n\", __func__, size);\n\t\treturn NULL;\n\t}\n\n\tfor (i = 0; i < size; i++) {\n\t\tpages[i] = alloc_page(gfp_flags);\n\t\tif (!pages[i]) {\n\t\t\tdprintk(\"%s: failed to allocate page\\n\", __func__);\n\t\t\tnfs4_free_pages(pages, i);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\treturn pages;\n}\n\nstatic struct nfs4_layoutget *\npnfs_alloc_init_layoutget_args(struct inode *ino,\n\t   struct nfs_open_context *ctx,\n\t   const nfs4_stateid *stateid,\n\t   const struct pnfs_layout_range *range,\n\t   gfp_t gfp_flags)\n{\n\tstruct nfs_server *server = pnfs_find_server(ino, ctx);\n\tsize_t max_reply_sz = server->pnfs_curr_ld->max_layoutget_response;\n\tsize_t max_pages = max_response_pages(server);\n\tstruct nfs4_layoutget *lgp;\n\n\tdprintk(\"--> %s\\n\", __func__);\n\n\tlgp = kzalloc(sizeof(*lgp), gfp_flags);\n\tif (lgp == NULL)\n\t\treturn NULL;\n\n\tif (max_reply_sz) {\n\t\tsize_t npages = (max_reply_sz + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\t\tif (npages < max_pages)\n\t\t\tmax_pages = npages;\n\t}\n\n\tlgp->args.layout.pages = nfs4_alloc_pages(max_pages, gfp_flags);\n\tif (!lgp->args.layout.pages) {\n\t\tkfree(lgp);\n\t\treturn NULL;\n\t}\n\tlgp->args.layout.pglen = max_pages * PAGE_SIZE;\n\tlgp->res.layoutp = &lgp->args.layout;\n\n\t \n\tlgp->res.status = -NFS4ERR_DELAY;\n\n\tlgp->args.minlength = PAGE_SIZE;\n\tif (lgp->args.minlength > range->length)\n\t\tlgp->args.minlength = range->length;\n\tif (ino) {\n\t\tloff_t i_size = i_size_read(ino);\n\n\t\tif (range->iomode == IOMODE_READ) {\n\t\t\tif (range->offset >= i_size)\n\t\t\t\tlgp->args.minlength = 0;\n\t\t\telse if (i_size - range->offset < lgp->args.minlength)\n\t\t\t\tlgp->args.minlength = i_size - range->offset;\n\t\t}\n\t}\n\tlgp->args.maxcount = PNFS_LAYOUT_MAXSIZE;\n\tpnfs_copy_range(&lgp->args.range, range);\n\tlgp->args.type = server->pnfs_curr_ld->id;\n\tlgp->args.inode = ino;\n\tlgp->args.ctx = get_nfs_open_context(ctx);\n\tnfs4_stateid_copy(&lgp->args.stateid, stateid);\n\tlgp->gfp_flags = gfp_flags;\n\tlgp->cred = ctx->cred;\n\treturn lgp;\n}\n\nvoid pnfs_layoutget_free(struct nfs4_layoutget *lgp)\n{\n\tsize_t max_pages = lgp->args.layout.pglen / PAGE_SIZE;\n\n\tnfs4_free_pages(lgp->args.layout.pages, max_pages);\n\tpnfs_put_layout_hdr(lgp->lo);\n\tput_nfs_open_context(lgp->args.ctx);\n\tkfree(lgp);\n}\n\nstatic void pnfs_clear_layoutcommit(struct inode *inode,\n\t\tstruct list_head *head)\n{\n\tstruct nfs_inode *nfsi = NFS_I(inode);\n\tstruct pnfs_layout_segment *lseg, *tmp;\n\n\tif (!test_and_clear_bit(NFS_INO_LAYOUTCOMMIT, &nfsi->flags))\n\t\treturn;\n\tlist_for_each_entry_safe(lseg, tmp, &nfsi->layout->plh_segs, pls_list) {\n\t\tif (!test_and_clear_bit(NFS_LSEG_LAYOUTCOMMIT, &lseg->pls_flags))\n\t\t\tcontinue;\n\t\tpnfs_lseg_dec_and_remove_zero(lseg, head);\n\t}\n}\n\nvoid pnfs_layoutreturn_free_lsegs(struct pnfs_layout_hdr *lo,\n\t\tconst nfs4_stateid *arg_stateid,\n\t\tconst struct pnfs_layout_range *range,\n\t\tconst nfs4_stateid *stateid)\n{\n\tstruct inode *inode = lo->plh_inode;\n\tLIST_HEAD(freeme);\n\n\tspin_lock(&inode->i_lock);\n\tif (!pnfs_layout_is_valid(lo) ||\n\t    !nfs4_stateid_match_other(&lo->plh_stateid, arg_stateid))\n\t\tgoto out_unlock;\n\tif (stateid) {\n\t\tu32 seq = be32_to_cpu(arg_stateid->seqid);\n\n\t\tpnfs_mark_matching_lsegs_invalid(lo, &freeme, range, seq);\n\t\tpnfs_free_returned_lsegs(lo, &freeme, range, seq);\n\t\tpnfs_set_layout_stateid(lo, stateid, NULL, true);\n\t} else\n\t\tpnfs_mark_layout_stateid_invalid(lo, &freeme);\nout_unlock:\n\tpnfs_clear_layoutreturn_waitbit(lo);\n\tspin_unlock(&inode->i_lock);\n\tpnfs_free_lseg_list(&freeme);\n\n}\n\nstatic bool\npnfs_prepare_layoutreturn(struct pnfs_layout_hdr *lo,\n\t\tnfs4_stateid *stateid,\n\t\tconst struct cred **cred,\n\t\tenum pnfs_iomode *iomode)\n{\n\t \n\tif (atomic_read(&lo->plh_outstanding) != 0)\n\t\treturn false;\n\tif (test_and_set_bit(NFS_LAYOUT_RETURN_LOCK, &lo->plh_flags))\n\t\treturn false;\n\tset_bit(NFS_LAYOUT_RETURN, &lo->plh_flags);\n\tpnfs_get_layout_hdr(lo);\n\tnfs4_stateid_copy(stateid, &lo->plh_stateid);\n\t*cred = get_cred(lo->plh_lc_cred);\n\tif (test_bit(NFS_LAYOUT_RETURN_REQUESTED, &lo->plh_flags)) {\n\t\tif (lo->plh_return_seq != 0)\n\t\t\tstateid->seqid = cpu_to_be32(lo->plh_return_seq);\n\t\tif (iomode != NULL)\n\t\t\t*iomode = lo->plh_return_iomode;\n\t\tpnfs_clear_layoutreturn_info(lo);\n\t} else if (iomode != NULL)\n\t\t*iomode = IOMODE_ANY;\n\tpnfs_barrier_update(lo, be32_to_cpu(stateid->seqid));\n\treturn true;\n}\n\nstatic void\npnfs_init_layoutreturn_args(struct nfs4_layoutreturn_args *args,\n\t\tstruct pnfs_layout_hdr *lo,\n\t\tconst nfs4_stateid *stateid,\n\t\tenum pnfs_iomode iomode)\n{\n\tstruct inode *inode = lo->plh_inode;\n\n\targs->layout_type = NFS_SERVER(inode)->pnfs_curr_ld->id;\n\targs->inode = inode;\n\targs->range.iomode = iomode;\n\targs->range.offset = 0;\n\targs->range.length = NFS4_MAX_UINT64;\n\targs->layout = lo;\n\tnfs4_stateid_copy(&args->stateid, stateid);\n}\n\nstatic int\npnfs_send_layoutreturn(struct pnfs_layout_hdr *lo,\n\t\t       const nfs4_stateid *stateid,\n\t\t       const struct cred **pcred,\n\t\t       enum pnfs_iomode iomode,\n\t\t       bool sync)\n{\n\tstruct inode *ino = lo->plh_inode;\n\tstruct pnfs_layoutdriver_type *ld = NFS_SERVER(ino)->pnfs_curr_ld;\n\tstruct nfs4_layoutreturn *lrp;\n\tconst struct cred *cred = *pcred;\n\tint status = 0;\n\n\t*pcred = NULL;\n\tlrp = kzalloc(sizeof(*lrp), nfs_io_gfp_mask());\n\tif (unlikely(lrp == NULL)) {\n\t\tstatus = -ENOMEM;\n\t\tspin_lock(&ino->i_lock);\n\t\tpnfs_clear_layoutreturn_waitbit(lo);\n\t\tspin_unlock(&ino->i_lock);\n\t\tput_cred(cred);\n\t\tpnfs_put_layout_hdr(lo);\n\t\tgoto out;\n\t}\n\n\tpnfs_init_layoutreturn_args(&lrp->args, lo, stateid, iomode);\n\tlrp->args.ld_private = &lrp->ld_private;\n\tlrp->clp = NFS_SERVER(ino)->nfs_client;\n\tlrp->cred = cred;\n\tif (ld->prepare_layoutreturn)\n\t\tld->prepare_layoutreturn(&lrp->args);\n\n\tstatus = nfs4_proc_layoutreturn(lrp, sync);\nout:\n\tdprintk(\"<-- %s status: %d\\n\", __func__, status);\n\treturn status;\n}\n\nstatic bool\npnfs_layout_segments_returnable(struct pnfs_layout_hdr *lo,\n\t\t\t\tenum pnfs_iomode iomode,\n\t\t\t\tu32 seq)\n{\n\tstruct pnfs_layout_range recall_range = {\n\t\t.length = NFS4_MAX_UINT64,\n\t\t.iomode = iomode,\n\t};\n\treturn pnfs_mark_matching_lsegs_return(lo, &lo->plh_return_segs,\n\t\t\t\t\t       &recall_range, seq) != -EBUSY;\n}\n\n \nstatic bool\npnfs_layout_need_return(struct pnfs_layout_hdr *lo)\n{\n\tif (!test_bit(NFS_LAYOUT_RETURN_REQUESTED, &lo->plh_flags))\n\t\treturn false;\n\treturn pnfs_layout_segments_returnable(lo, lo->plh_return_iomode,\n\t\t\t\t\t       lo->plh_return_seq);\n}\n\nstatic void pnfs_layoutreturn_before_put_layout_hdr(struct pnfs_layout_hdr *lo)\n{\n\tstruct inode *inode= lo->plh_inode;\n\n\tif (!test_bit(NFS_LAYOUT_RETURN_REQUESTED, &lo->plh_flags))\n\t\treturn;\n\tspin_lock(&inode->i_lock);\n\tif (pnfs_layout_need_return(lo)) {\n\t\tconst struct cred *cred;\n\t\tnfs4_stateid stateid;\n\t\tenum pnfs_iomode iomode;\n\t\tbool send;\n\n\t\tsend = pnfs_prepare_layoutreturn(lo, &stateid, &cred, &iomode);\n\t\tspin_unlock(&inode->i_lock);\n\t\tif (send) {\n\t\t\t \n\t\t\tpnfs_send_layoutreturn(lo, &stateid, &cred, iomode, false);\n\t\t}\n\t} else\n\t\tspin_unlock(&inode->i_lock);\n}\n\n \nint\n_pnfs_return_layout(struct inode *ino)\n{\n\tstruct pnfs_layout_hdr *lo = NULL;\n\tstruct nfs_inode *nfsi = NFS_I(ino);\n\tstruct pnfs_layout_range range = {\n\t\t.iomode\t\t= IOMODE_ANY,\n\t\t.offset\t\t= 0,\n\t\t.length\t\t= NFS4_MAX_UINT64,\n\t};\n\tLIST_HEAD(tmp_list);\n\tconst struct cred *cred;\n\tnfs4_stateid stateid;\n\tint status = 0;\n\tbool send, valid_layout;\n\n\tdprintk(\"NFS: %s for inode %lu\\n\", __func__, ino->i_ino);\n\n\tspin_lock(&ino->i_lock);\n\tlo = nfsi->layout;\n\tif (!lo) {\n\t\tspin_unlock(&ino->i_lock);\n\t\tdprintk(\"NFS: %s no layout to return\\n\", __func__);\n\t\tgoto out;\n\t}\n\t \n\tpnfs_get_layout_hdr(lo);\n\t \n\tif (test_bit(NFS_LAYOUT_RETURN_LOCK, &lo->plh_flags)) {\n\t\tspin_unlock(&ino->i_lock);\n\t\tif (wait_on_bit(&lo->plh_flags, NFS_LAYOUT_RETURN,\n\t\t\t\t\tTASK_UNINTERRUPTIBLE))\n\t\t\tgoto out_put_layout_hdr;\n\t\tspin_lock(&ino->i_lock);\n\t}\n\tvalid_layout = pnfs_layout_is_valid(lo);\n\tpnfs_clear_layoutcommit(ino, &tmp_list);\n\tpnfs_mark_matching_lsegs_return(lo, &tmp_list, &range, 0);\n\n\tif (NFS_SERVER(ino)->pnfs_curr_ld->return_range)\n\t\tNFS_SERVER(ino)->pnfs_curr_ld->return_range(lo, &range);\n\n\t \n\tif (!test_bit(NFS_LAYOUT_RETURN_REQUESTED, &lo->plh_flags) ||\n\t\t\t!valid_layout) {\n\t\tspin_unlock(&ino->i_lock);\n\t\tdprintk(\"NFS: %s no layout segments to return\\n\", __func__);\n\t\tgoto out_wait_layoutreturn;\n\t}\n\n\tsend = pnfs_prepare_layoutreturn(lo, &stateid, &cred, NULL);\n\tspin_unlock(&ino->i_lock);\n\tif (send)\n\t\tstatus = pnfs_send_layoutreturn(lo, &stateid, &cred, IOMODE_ANY, true);\nout_wait_layoutreturn:\n\twait_on_bit(&lo->plh_flags, NFS_LAYOUT_RETURN, TASK_UNINTERRUPTIBLE);\nout_put_layout_hdr:\n\tpnfs_free_lseg_list(&tmp_list);\n\tpnfs_put_layout_hdr(lo);\nout:\n\tdprintk(\"<-- %s status: %d\\n\", __func__, status);\n\treturn status;\n}\n\nint\npnfs_commit_and_return_layout(struct inode *inode)\n{\n\tstruct pnfs_layout_hdr *lo;\n\tint ret;\n\n\tspin_lock(&inode->i_lock);\n\tlo = NFS_I(inode)->layout;\n\tif (lo == NULL) {\n\t\tspin_unlock(&inode->i_lock);\n\t\treturn 0;\n\t}\n\tpnfs_get_layout_hdr(lo);\n\t \n\tlo->plh_block_lgets++;\n\tspin_unlock(&inode->i_lock);\n\tfilemap_fdatawait(inode->i_mapping);\n\tret = pnfs_layoutcommit_inode(inode, true);\n\tif (ret == 0)\n\t\tret = _pnfs_return_layout(inode);\n\tspin_lock(&inode->i_lock);\n\tlo->plh_block_lgets--;\n\tspin_unlock(&inode->i_lock);\n\tpnfs_put_layout_hdr(lo);\n\treturn ret;\n}\n\nbool pnfs_roc(struct inode *ino,\n\t\tstruct nfs4_layoutreturn_args *args,\n\t\tstruct nfs4_layoutreturn_res *res,\n\t\tconst struct cred *cred)\n{\n\tstruct nfs_inode *nfsi = NFS_I(ino);\n\tstruct nfs_open_context *ctx;\n\tstruct nfs4_state *state;\n\tstruct pnfs_layout_hdr *lo;\n\tstruct pnfs_layout_segment *lseg, *next;\n\tconst struct cred *lc_cred;\n\tnfs4_stateid stateid;\n\tenum pnfs_iomode iomode = 0;\n\tbool layoutreturn = false, roc = false;\n\tbool skip_read = false;\n\n\tif (!nfs_have_layout(ino))\n\t\treturn false;\nretry:\n\trcu_read_lock();\n\tspin_lock(&ino->i_lock);\n\tlo = nfsi->layout;\n\tif (!lo || !pnfs_layout_is_valid(lo) ||\n\t    test_bit(NFS_LAYOUT_BULK_RECALL, &lo->plh_flags)) {\n\t\tlo = NULL;\n\t\tgoto out_noroc;\n\t}\n\tpnfs_get_layout_hdr(lo);\n\tif (test_bit(NFS_LAYOUT_RETURN_LOCK, &lo->plh_flags)) {\n\t\tspin_unlock(&ino->i_lock);\n\t\trcu_read_unlock();\n\t\twait_on_bit(&lo->plh_flags, NFS_LAYOUT_RETURN,\n\t\t\t\tTASK_UNINTERRUPTIBLE);\n\t\tpnfs_put_layout_hdr(lo);\n\t\tgoto retry;\n\t}\n\n\t \n\tif (nfs4_check_delegation(ino, FMODE_READ)) {\n\t\tif (nfs4_check_delegation(ino, FMODE_WRITE))\n\t\t\tgoto out_noroc;\n\t\tskip_read = true;\n\t}\n\n\tlist_for_each_entry_rcu(ctx, &nfsi->open_files, list) {\n\t\tstate = ctx->state;\n\t\tif (state == NULL)\n\t\t\tcontinue;\n\t\t \n\t\tif (state->state & FMODE_WRITE)\n\t\t\tgoto out_noroc;\n\t\tif (state->state & FMODE_READ)\n\t\t\tskip_read = true;\n\t}\n\n\n\tlist_for_each_entry_safe(lseg, next, &lo->plh_segs, pls_list) {\n\t\tif (skip_read && lseg->pls_range.iomode == IOMODE_READ)\n\t\t\tcontinue;\n\t\t \n\t\tif (!test_and_clear_bit(NFS_LSEG_ROC, &lseg->pls_flags))\n\t\t\tcontinue;\n\t\t \n\t\tset_bit(NFS_LSEG_LAYOUTRETURN, &lseg->pls_flags);\n\t\tif (!mark_lseg_invalid(lseg, &lo->plh_return_segs))\n\t\t\tcontinue;\n\t\tpnfs_set_plh_return_info(lo, lseg->pls_range.iomode, 0);\n\t}\n\n\tif (!test_bit(NFS_LAYOUT_RETURN_REQUESTED, &lo->plh_flags))\n\t\tgoto out_noroc;\n\n\t \n\t \n\tlayoutreturn = pnfs_prepare_layoutreturn(lo, &stateid, &lc_cred, &iomode);\n\t \n\tif (!layoutreturn || cred_fscmp(cred, lc_cred) != 0)\n\t\tgoto out_noroc;\n\n\troc = layoutreturn;\n\tpnfs_init_layoutreturn_args(args, lo, &stateid, iomode);\n\tres->lrs_present = 0;\n\tlayoutreturn = false;\n\tput_cred(lc_cred);\n\nout_noroc:\n\tspin_unlock(&ino->i_lock);\n\trcu_read_unlock();\n\tpnfs_layoutcommit_inode(ino, true);\n\tif (roc) {\n\t\tstruct pnfs_layoutdriver_type *ld = NFS_SERVER(ino)->pnfs_curr_ld;\n\t\tif (ld->prepare_layoutreturn)\n\t\t\tld->prepare_layoutreturn(args);\n\t\tpnfs_put_layout_hdr(lo);\n\t\treturn true;\n\t}\n\tif (layoutreturn)\n\t\tpnfs_send_layoutreturn(lo, &stateid, &lc_cred, iomode, true);\n\tpnfs_put_layout_hdr(lo);\n\treturn false;\n}\n\nint pnfs_roc_done(struct rpc_task *task, struct nfs4_layoutreturn_args **argpp,\n\t\t  struct nfs4_layoutreturn_res **respp, int *ret)\n{\n\tstruct nfs4_layoutreturn_args *arg = *argpp;\n\tint retval = -EAGAIN;\n\n\tif (!arg)\n\t\treturn 0;\n\t \n\tswitch (*ret) {\n\tcase 0:\n\t\tretval = 0;\n\t\tbreak;\n\tcase -NFS4ERR_NOMATCHING_LAYOUT:\n\t\t \n\t\tif (task->tk_rpc_status == 0)\n\t\t\tbreak;\n\t\t \n\t\tif (!RPC_WAS_SENT(task))\n\t\t\treturn 0;\n\t\t \n\t\t*ret = 0;\n\t\t(*respp)->lrs_present = 0;\n\t\tretval = 0;\n\t\tbreak;\n\tcase -NFS4ERR_DELAY:\n\t\t \n\t\t*ret = -NFS4ERR_NOMATCHING_LAYOUT;\n\t\treturn 0;\n\tcase -NFS4ERR_OLD_STATEID:\n\t\tif (!nfs4_layout_refresh_old_stateid(&arg->stateid,\n\t\t\t\t\t\t     &arg->range, arg->inode))\n\t\t\tbreak;\n\t\t*ret = -NFS4ERR_NOMATCHING_LAYOUT;\n\t\treturn -EAGAIN;\n\t}\n\t*argpp = NULL;\n\t*respp = NULL;\n\treturn retval;\n}\n\nvoid pnfs_roc_release(struct nfs4_layoutreturn_args *args,\n\t\tstruct nfs4_layoutreturn_res *res,\n\t\tint ret)\n{\n\tstruct pnfs_layout_hdr *lo = args->layout;\n\tstruct inode *inode = args->inode;\n\tconst nfs4_stateid *res_stateid = NULL;\n\tstruct nfs4_xdr_opaque_data *ld_private = args->ld_private;\n\n\tswitch (ret) {\n\tcase -NFS4ERR_NOMATCHING_LAYOUT:\n\t\tspin_lock(&inode->i_lock);\n\t\tif (pnfs_layout_is_valid(lo) &&\n\t\t    nfs4_stateid_match_other(&args->stateid, &lo->plh_stateid))\n\t\t\tpnfs_set_plh_return_info(lo, args->range.iomode, 0);\n\t\tpnfs_clear_layoutreturn_waitbit(lo);\n\t\tspin_unlock(&inode->i_lock);\n\t\tbreak;\n\tcase 0:\n\t\tif (res->lrs_present)\n\t\t\tres_stateid = &res->stateid;\n\t\tfallthrough;\n\tdefault:\n\t\tpnfs_layoutreturn_free_lsegs(lo, &args->stateid, &args->range,\n\t\t\t\t\t     res_stateid);\n\t}\n\ttrace_nfs4_layoutreturn_on_close(args->inode, &args->stateid, ret);\n\tif (ld_private && ld_private->ops && ld_private->ops->free)\n\t\tld_private->ops->free(ld_private);\n\tpnfs_put_layout_hdr(lo);\n}\n\nbool pnfs_wait_on_layoutreturn(struct inode *ino, struct rpc_task *task)\n{\n\tstruct nfs_inode *nfsi = NFS_I(ino);\n        struct pnfs_layout_hdr *lo;\n        bool sleep = false;\n\n\t \n        spin_lock(&ino->i_lock);\n        lo = nfsi->layout;\n        if (lo && test_bit(NFS_LAYOUT_RETURN, &lo->plh_flags)) {\n                rpc_sleep_on(&NFS_SERVER(ino)->roc_rpcwaitq, task, NULL);\n                sleep = true;\n\t}\n        spin_unlock(&ino->i_lock);\n        return sleep;\n}\n\n \nstatic s64\npnfs_lseg_range_cmp(const struct pnfs_layout_range *l1,\n\t   const struct pnfs_layout_range *l2)\n{\n\ts64 d;\n\n\t \n\td = l1->offset - l2->offset;\n\tif (d)\n\t\treturn d;\n\n\t \n\td = l2->length - l1->length;\n\tif (d)\n\t\treturn d;\n\n\t \n\treturn (int)(l1->iomode == IOMODE_READ) - (int)(l2->iomode == IOMODE_READ);\n}\n\nstatic bool\npnfs_lseg_range_is_after(const struct pnfs_layout_range *l1,\n\t\tconst struct pnfs_layout_range *l2)\n{\n\treturn pnfs_lseg_range_cmp(l1, l2) > 0;\n}\n\nstatic bool\npnfs_lseg_no_merge(struct pnfs_layout_segment *lseg,\n\t\tstruct pnfs_layout_segment *old)\n{\n\treturn false;\n}\n\nvoid\npnfs_generic_layout_insert_lseg(struct pnfs_layout_hdr *lo,\n\t\t   struct pnfs_layout_segment *lseg,\n\t\t   bool (*is_after)(const struct pnfs_layout_range *,\n\t\t\t   const struct pnfs_layout_range *),\n\t\t   bool (*do_merge)(struct pnfs_layout_segment *,\n\t\t\t   struct pnfs_layout_segment *),\n\t\t   struct list_head *free_me)\n{\n\tstruct pnfs_layout_segment *lp, *tmp;\n\n\tdprintk(\"%s:Begin\\n\", __func__);\n\n\tlist_for_each_entry_safe(lp, tmp, &lo->plh_segs, pls_list) {\n\t\tif (test_bit(NFS_LSEG_VALID, &lp->pls_flags) == 0)\n\t\t\tcontinue;\n\t\tif (do_merge(lseg, lp)) {\n\t\t\tmark_lseg_invalid(lp, free_me);\n\t\t\tcontinue;\n\t\t}\n\t\tif (is_after(&lseg->pls_range, &lp->pls_range))\n\t\t\tcontinue;\n\t\tlist_add_tail(&lseg->pls_list, &lp->pls_list);\n\t\tdprintk(\"%s: inserted lseg %p \"\n\t\t\t\"iomode %d offset %llu length %llu before \"\n\t\t\t\"lp %p iomode %d offset %llu length %llu\\n\",\n\t\t\t__func__, lseg, lseg->pls_range.iomode,\n\t\t\tlseg->pls_range.offset, lseg->pls_range.length,\n\t\t\tlp, lp->pls_range.iomode, lp->pls_range.offset,\n\t\t\tlp->pls_range.length);\n\t\tgoto out;\n\t}\n\tlist_add_tail(&lseg->pls_list, &lo->plh_segs);\n\tdprintk(\"%s: inserted lseg %p \"\n\t\t\"iomode %d offset %llu length %llu at tail\\n\",\n\t\t__func__, lseg, lseg->pls_range.iomode,\n\t\tlseg->pls_range.offset, lseg->pls_range.length);\nout:\n\tpnfs_get_layout_hdr(lo);\n\n\tdprintk(\"%s:Return\\n\", __func__);\n}\nEXPORT_SYMBOL_GPL(pnfs_generic_layout_insert_lseg);\n\nstatic void\npnfs_layout_insert_lseg(struct pnfs_layout_hdr *lo,\n\t\t   struct pnfs_layout_segment *lseg,\n\t\t   struct list_head *free_me)\n{\n\tstruct inode *inode = lo->plh_inode;\n\tstruct pnfs_layoutdriver_type *ld = NFS_SERVER(inode)->pnfs_curr_ld;\n\n\tif (ld->add_lseg != NULL)\n\t\tld->add_lseg(lo, lseg, free_me);\n\telse\n\t\tpnfs_generic_layout_insert_lseg(lo, lseg,\n\t\t\t\tpnfs_lseg_range_is_after,\n\t\t\t\tpnfs_lseg_no_merge,\n\t\t\t\tfree_me);\n}\n\nstatic struct pnfs_layout_hdr *\nalloc_init_layout_hdr(struct inode *ino,\n\t\t      struct nfs_open_context *ctx,\n\t\t      gfp_t gfp_flags)\n{\n\tstruct pnfs_layout_hdr *lo;\n\n\tlo = pnfs_alloc_layout_hdr(ino, gfp_flags);\n\tif (!lo)\n\t\treturn NULL;\n\trefcount_set(&lo->plh_refcount, 1);\n\tINIT_LIST_HEAD(&lo->plh_layouts);\n\tINIT_LIST_HEAD(&lo->plh_segs);\n\tINIT_LIST_HEAD(&lo->plh_return_segs);\n\tINIT_LIST_HEAD(&lo->plh_bulk_destroy);\n\tlo->plh_inode = ino;\n\tlo->plh_lc_cred = get_cred(ctx->cred);\n\tlo->plh_flags |= 1 << NFS_LAYOUT_INVALID_STID;\n\treturn lo;\n}\n\nstatic struct pnfs_layout_hdr *\npnfs_find_alloc_layout(struct inode *ino,\n\t\t       struct nfs_open_context *ctx,\n\t\t       gfp_t gfp_flags)\n\t__releases(&ino->i_lock)\n\t__acquires(&ino->i_lock)\n{\n\tstruct nfs_inode *nfsi = NFS_I(ino);\n\tstruct pnfs_layout_hdr *new = NULL;\n\n\tdprintk(\"%s Begin ino=%p layout=%p\\n\", __func__, ino, nfsi->layout);\n\n\tif (nfsi->layout != NULL)\n\t\tgoto out_existing;\n\tspin_unlock(&ino->i_lock);\n\tnew = alloc_init_layout_hdr(ino, ctx, gfp_flags);\n\tspin_lock(&ino->i_lock);\n\n\tif (likely(nfsi->layout == NULL)) {\t \n\t\tnfsi->layout = new;\n\t\treturn new;\n\t} else if (new != NULL)\n\t\tpnfs_free_layout_hdr(new);\nout_existing:\n\tpnfs_get_layout_hdr(nfsi->layout);\n\treturn nfsi->layout;\n}\n\n \nstatic bool\npnfs_lseg_range_match(const struct pnfs_layout_range *ls_range,\n\t\t const struct pnfs_layout_range *range,\n\t\t bool strict_iomode)\n{\n\tstruct pnfs_layout_range range1;\n\n\tif ((range->iomode == IOMODE_RW &&\n\t     ls_range->iomode != IOMODE_RW) ||\n\t    (range->iomode != ls_range->iomode &&\n\t     strict_iomode) ||\n\t    !pnfs_lseg_range_intersecting(ls_range, range))\n\t\treturn false;\n\n\t \n\trange1 = *range;\n\trange1.length = 1;\n\treturn pnfs_lseg_range_contained(ls_range, &range1);\n}\n\n \nstatic struct pnfs_layout_segment *\npnfs_find_lseg(struct pnfs_layout_hdr *lo,\n\t\tstruct pnfs_layout_range *range,\n\t\tbool strict_iomode)\n{\n\tstruct pnfs_layout_segment *lseg, *ret = NULL;\n\n\tdprintk(\"%s:Begin\\n\", __func__);\n\n\tlist_for_each_entry(lseg, &lo->plh_segs, pls_list) {\n\t\tif (test_bit(NFS_LSEG_VALID, &lseg->pls_flags) &&\n\t\t    pnfs_lseg_range_match(&lseg->pls_range, range,\n\t\t\t\t\t  strict_iomode)) {\n\t\t\tret = pnfs_get_lseg(lseg);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tdprintk(\"%s:Return lseg %p ref %d\\n\",\n\t\t__func__, ret, ret ? refcount_read(&ret->pls_refcount) : 0);\n\treturn ret;\n}\n\n \nstatic bool pnfs_within_mdsthreshold(struct nfs_open_context *ctx,\n\t\t\t\t     struct inode *ino, int iomode)\n{\n\tstruct nfs4_threshold *t = ctx->mdsthreshold;\n\tstruct nfs_inode *nfsi = NFS_I(ino);\n\tloff_t fsize = i_size_read(ino);\n\tbool size = false, size_set = false, io = false, io_set = false, ret = false;\n\n\tif (t == NULL)\n\t\treturn ret;\n\n\tdprintk(\"%s bm=0x%x rd_sz=%llu wr_sz=%llu rd_io=%llu wr_io=%llu\\n\",\n\t\t__func__, t->bm, t->rd_sz, t->wr_sz, t->rd_io_sz, t->wr_io_sz);\n\n\tswitch (iomode) {\n\tcase IOMODE_READ:\n\t\tif (t->bm & THRESHOLD_RD) {\n\t\t\tdprintk(\"%s fsize %llu\\n\", __func__, fsize);\n\t\t\tsize_set = true;\n\t\t\tif (fsize < t->rd_sz)\n\t\t\t\tsize = true;\n\t\t}\n\t\tif (t->bm & THRESHOLD_RD_IO) {\n\t\t\tdprintk(\"%s nfsi->read_io %llu\\n\", __func__,\n\t\t\t\tnfsi->read_io);\n\t\t\tio_set = true;\n\t\t\tif (nfsi->read_io < t->rd_io_sz)\n\t\t\t\tio = true;\n\t\t}\n\t\tbreak;\n\tcase IOMODE_RW:\n\t\tif (t->bm & THRESHOLD_WR) {\n\t\t\tdprintk(\"%s fsize %llu\\n\", __func__, fsize);\n\t\t\tsize_set = true;\n\t\t\tif (fsize < t->wr_sz)\n\t\t\t\tsize = true;\n\t\t}\n\t\tif (t->bm & THRESHOLD_WR_IO) {\n\t\t\tdprintk(\"%s nfsi->write_io %llu\\n\", __func__,\n\t\t\t\tnfsi->write_io);\n\t\t\tio_set = true;\n\t\t\tif (nfsi->write_io < t->wr_io_sz)\n\t\t\t\tio = true;\n\t\t}\n\t\tbreak;\n\t}\n\tif (size_set && io_set) {\n\t\tif (size && io)\n\t\t\tret = true;\n\t} else if (size || io)\n\t\tret = true;\n\n\tdprintk(\"<-- %s size %d io %d ret %d\\n\", __func__, size, io, ret);\n\treturn ret;\n}\n\nstatic int pnfs_prepare_to_retry_layoutget(struct pnfs_layout_hdr *lo)\n{\n\t \n\tpnfs_layoutcommit_inode(lo->plh_inode, false);\n\treturn wait_on_bit_action(&lo->plh_flags, NFS_LAYOUT_RETURN,\n\t\t\t\t   nfs_wait_bit_killable,\n\t\t\t\t   TASK_KILLABLE|TASK_FREEZABLE_UNSAFE);\n}\n\nstatic void nfs_layoutget_begin(struct pnfs_layout_hdr *lo)\n{\n\tatomic_inc(&lo->plh_outstanding);\n}\n\nstatic void nfs_layoutget_end(struct pnfs_layout_hdr *lo)\n{\n\tif (atomic_dec_and_test(&lo->plh_outstanding) &&\n\t    test_and_clear_bit(NFS_LAYOUT_DRAIN, &lo->plh_flags))\n\t\twake_up_bit(&lo->plh_flags, NFS_LAYOUT_DRAIN);\n}\n\nstatic bool pnfs_is_first_layoutget(struct pnfs_layout_hdr *lo)\n{\n\treturn test_bit(NFS_LAYOUT_FIRST_LAYOUTGET, &lo->plh_flags);\n}\n\nstatic void pnfs_clear_first_layoutget(struct pnfs_layout_hdr *lo)\n{\n\tunsigned long *bitlock = &lo->plh_flags;\n\n\tclear_bit_unlock(NFS_LAYOUT_FIRST_LAYOUTGET, bitlock);\n\tsmp_mb__after_atomic();\n\twake_up_bit(bitlock, NFS_LAYOUT_FIRST_LAYOUTGET);\n}\n\nstatic void _add_to_server_list(struct pnfs_layout_hdr *lo,\n\t\t\t\tstruct nfs_server *server)\n{\n\tif (!test_and_set_bit(NFS_LAYOUT_HASHED, &lo->plh_flags)) {\n\t\tstruct nfs_client *clp = server->nfs_client;\n\n\t\t \n\t\tspin_lock(&clp->cl_lock);\n\t\tlist_add_tail_rcu(&lo->plh_layouts, &server->layouts);\n\t\tspin_unlock(&clp->cl_lock);\n\t}\n}\n\n \nstruct pnfs_layout_segment *\npnfs_update_layout(struct inode *ino,\n\t\t   struct nfs_open_context *ctx,\n\t\t   loff_t pos,\n\t\t   u64 count,\n\t\t   enum pnfs_iomode iomode,\n\t\t   bool strict_iomode,\n\t\t   gfp_t gfp_flags)\n{\n\tstruct pnfs_layout_range arg = {\n\t\t.iomode = iomode,\n\t\t.offset = pos,\n\t\t.length = count,\n\t};\n\tunsigned pg_offset;\n\tstruct nfs_server *server = NFS_SERVER(ino);\n\tstruct nfs_client *clp = server->nfs_client;\n\tstruct pnfs_layout_hdr *lo = NULL;\n\tstruct pnfs_layout_segment *lseg = NULL;\n\tstruct nfs4_layoutget *lgp;\n\tnfs4_stateid stateid;\n\tlong timeout = 0;\n\tunsigned long giveup = jiffies + (clp->cl_lease_time << 1);\n\tbool first;\n\n\tif (!pnfs_enabled_sb(NFS_SERVER(ino))) {\n\t\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, lseg,\n\t\t\t\t PNFS_UPDATE_LAYOUT_NO_PNFS);\n\t\tgoto out;\n\t}\n\n\tif (pnfs_within_mdsthreshold(ctx, ino, iomode)) {\n\t\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, lseg,\n\t\t\t\t PNFS_UPDATE_LAYOUT_MDSTHRESH);\n\t\tgoto out;\n\t}\n\nlookup_again:\n\tlseg = ERR_PTR(nfs4_client_recover_expired_lease(clp));\n\tif (IS_ERR(lseg))\n\t\tgoto out;\n\tfirst = false;\n\tspin_lock(&ino->i_lock);\n\tlo = pnfs_find_alloc_layout(ino, ctx, gfp_flags);\n\tif (lo == NULL) {\n\t\tspin_unlock(&ino->i_lock);\n\t\tlseg = ERR_PTR(-ENOMEM);\n\t\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, lseg,\n\t\t\t\t PNFS_UPDATE_LAYOUT_NOMEM);\n\t\tgoto out;\n\t}\n\n\t \n\tif (test_bit(NFS_LAYOUT_BULK_RECALL, &lo->plh_flags)) {\n\t\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, lseg,\n\t\t\t\t PNFS_UPDATE_LAYOUT_BULK_RECALL);\n\t\tdprintk(\"%s matches recall, use MDS\\n\", __func__);\n\t\tgoto out_unlock;\n\t}\n\n\t \n\tif (pnfs_layout_io_test_failed(lo, iomode)) {\n\t\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, lseg,\n\t\t\t\t PNFS_UPDATE_LAYOUT_IO_TEST_FAIL);\n\t\tgoto out_unlock;\n\t}\n\n\t \n\tif (test_bit(NFS_LAYOUT_DRAIN, &lo->plh_flags) &&\n\t    atomic_read(&lo->plh_outstanding) != 0) {\n\t\tspin_unlock(&ino->i_lock);\n\t\tlseg = ERR_PTR(wait_on_bit(&lo->plh_flags, NFS_LAYOUT_DRAIN,\n\t\t\t\t\t   TASK_KILLABLE));\n\t\tif (IS_ERR(lseg))\n\t\t\tgoto out_put_layout_hdr;\n\t\tpnfs_put_layout_hdr(lo);\n\t\tgoto lookup_again;\n\t}\n\n\t \n\tif (test_bit(NFS_LAYOUT_RETURN, &lo->plh_flags)) {\n\t\tspin_unlock(&ino->i_lock);\n\t\tdprintk(\"%s wait for layoutreturn\\n\", __func__);\n\t\tlseg = ERR_PTR(pnfs_prepare_to_retry_layoutget(lo));\n\t\tif (!IS_ERR(lseg)) {\n\t\t\tpnfs_put_layout_hdr(lo);\n\t\t\tdprintk(\"%s retrying\\n\", __func__);\n\t\t\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo,\n\t\t\t\t\t\t lseg,\n\t\t\t\t\t\t PNFS_UPDATE_LAYOUT_RETRY);\n\t\t\tgoto lookup_again;\n\t\t}\n\t\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, lseg,\n\t\t\t\t\t PNFS_UPDATE_LAYOUT_RETURN);\n\t\tgoto out_put_layout_hdr;\n\t}\n\n\tlseg = pnfs_find_lseg(lo, &arg, strict_iomode);\n\tif (lseg) {\n\t\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, lseg,\n\t\t\t\tPNFS_UPDATE_LAYOUT_FOUND_CACHED);\n\t\tgoto out_unlock;\n\t}\n\n\t \n\tif (test_bit(NFS_LAYOUT_INVALID_STID, &lo->plh_flags)) {\n\t\tint status;\n\n\t\t \n\t\tif (test_and_set_bit(NFS_LAYOUT_FIRST_LAYOUTGET,\n\t\t\t\t     &lo->plh_flags)) {\n\t\t\tspin_unlock(&ino->i_lock);\n\t\t\tlseg = ERR_PTR(wait_on_bit(&lo->plh_flags,\n\t\t\t\t\t\tNFS_LAYOUT_FIRST_LAYOUTGET,\n\t\t\t\t\t\tTASK_KILLABLE));\n\t\t\tif (IS_ERR(lseg))\n\t\t\t\tgoto out_put_layout_hdr;\n\t\t\tpnfs_put_layout_hdr(lo);\n\t\t\tdprintk(\"%s retrying\\n\", __func__);\n\t\t\tgoto lookup_again;\n\t\t}\n\n\t\tspin_unlock(&ino->i_lock);\n\t\tfirst = true;\n\t\tstatus = nfs4_select_rw_stateid(ctx->state,\n\t\t\t\t\tiomode == IOMODE_RW ? FMODE_WRITE : FMODE_READ,\n\t\t\t\t\tNULL, &stateid, NULL);\n\t\tif (status != 0) {\n\t\t\tlseg = ERR_PTR(status);\n\t\t\ttrace_pnfs_update_layout(ino, pos, count,\n\t\t\t\t\tiomode, lo, lseg,\n\t\t\t\t\tPNFS_UPDATE_LAYOUT_INVALID_OPEN);\n\t\t\tnfs4_schedule_stateid_recovery(server, ctx->state);\n\t\t\tpnfs_clear_first_layoutget(lo);\n\t\t\tpnfs_put_layout_hdr(lo);\n\t\t\tgoto lookup_again;\n\t\t}\n\t\tspin_lock(&ino->i_lock);\n\t} else {\n\t\tnfs4_stateid_copy(&stateid, &lo->plh_stateid);\n\t}\n\n\tif (pnfs_layoutgets_blocked(lo)) {\n\t\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, lseg,\n\t\t\t\tPNFS_UPDATE_LAYOUT_BLOCKED);\n\t\tgoto out_unlock;\n\t}\n\tnfs_layoutget_begin(lo);\n\tspin_unlock(&ino->i_lock);\n\n\t_add_to_server_list(lo, server);\n\n\tpg_offset = arg.offset & ~PAGE_MASK;\n\tif (pg_offset) {\n\t\targ.offset -= pg_offset;\n\t\targ.length += pg_offset;\n\t}\n\tif (arg.length != NFS4_MAX_UINT64)\n\t\targ.length = PAGE_ALIGN(arg.length);\n\n\tlgp = pnfs_alloc_init_layoutget_args(ino, ctx, &stateid, &arg, gfp_flags);\n\tif (!lgp) {\n\t\tlseg = ERR_PTR(-ENOMEM);\n\t\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, NULL,\n\t\t\t\t\t PNFS_UPDATE_LAYOUT_NOMEM);\n\t\tnfs_layoutget_end(lo);\n\t\tgoto out_put_layout_hdr;\n\t}\n\n\tlgp->lo = lo;\n\tpnfs_get_layout_hdr(lo);\n\n\tlseg = nfs4_proc_layoutget(lgp, &timeout);\n\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, lseg,\n\t\t\t\t PNFS_UPDATE_LAYOUT_SEND_LAYOUTGET);\n\tnfs_layoutget_end(lo);\n\tif (IS_ERR(lseg)) {\n\t\tswitch(PTR_ERR(lseg)) {\n\t\tcase -EBUSY:\n\t\t\tif (time_after(jiffies, giveup))\n\t\t\t\tlseg = NULL;\n\t\t\tbreak;\n\t\tcase -ERECALLCONFLICT:\n\t\tcase -EAGAIN:\n\t\t\tbreak;\n\t\tcase -ENODATA:\n\t\t\t \n\t\t\tpnfs_layout_set_fail_bit(\n\t\t\t\tlo, pnfs_iomode_to_fail_bit(iomode));\n\t\t\tlseg = NULL;\n\t\t\tgoto out_put_layout_hdr;\n\t\tdefault:\n\t\t\tif (!nfs_error_is_fatal(PTR_ERR(lseg))) {\n\t\t\t\tpnfs_layout_clear_fail_bit(lo, pnfs_iomode_to_fail_bit(iomode));\n\t\t\t\tlseg = NULL;\n\t\t\t}\n\t\t\tgoto out_put_layout_hdr;\n\t\t}\n\t\tif (lseg) {\n\t\t\tif (first)\n\t\t\t\tpnfs_clear_first_layoutget(lo);\n\t\t\ttrace_pnfs_update_layout(ino, pos, count,\n\t\t\t\tiomode, lo, lseg, PNFS_UPDATE_LAYOUT_RETRY);\n\t\t\tpnfs_put_layout_hdr(lo);\n\t\t\tgoto lookup_again;\n\t\t}\n\t} else {\n\t\tpnfs_layout_clear_fail_bit(lo, pnfs_iomode_to_fail_bit(iomode));\n\t}\n\nout_put_layout_hdr:\n\tif (first)\n\t\tpnfs_clear_first_layoutget(lo);\n\ttrace_pnfs_update_layout(ino, pos, count, iomode, lo, lseg,\n\t\t\t\t PNFS_UPDATE_LAYOUT_EXIT);\n\tpnfs_put_layout_hdr(lo);\nout:\n\tdprintk(\"%s: inode %s/%llu pNFS layout segment %s for \"\n\t\t\t\"(%s, offset: %llu, length: %llu)\\n\",\n\t\t\t__func__, ino->i_sb->s_id,\n\t\t\t(unsigned long long)NFS_FILEID(ino),\n\t\t\tIS_ERR_OR_NULL(lseg) ? \"not found\" : \"found\",\n\t\t\tiomode==IOMODE_RW ?  \"read/write\" : \"read-only\",\n\t\t\t(unsigned long long)pos,\n\t\t\t(unsigned long long)count);\n\treturn lseg;\nout_unlock:\n\tspin_unlock(&ino->i_lock);\n\tgoto out_put_layout_hdr;\n}\nEXPORT_SYMBOL_GPL(pnfs_update_layout);\n\nstatic bool\npnfs_sanity_check_layout_range(struct pnfs_layout_range *range)\n{\n\tswitch (range->iomode) {\n\tcase IOMODE_READ:\n\tcase IOMODE_RW:\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\tif (range->offset == NFS4_MAX_UINT64)\n\t\treturn false;\n\tif (range->length == 0)\n\t\treturn false;\n\tif (range->length != NFS4_MAX_UINT64 &&\n\t    range->length > NFS4_MAX_UINT64 - range->offset)\n\t\treturn false;\n\treturn true;\n}\n\nstatic struct pnfs_layout_hdr *\n_pnfs_grab_empty_layout(struct inode *ino, struct nfs_open_context *ctx)\n{\n\tstruct pnfs_layout_hdr *lo;\n\n\tspin_lock(&ino->i_lock);\n\tlo = pnfs_find_alloc_layout(ino, ctx, nfs_io_gfp_mask());\n\tif (!lo)\n\t\tgoto out_unlock;\n\tif (!test_bit(NFS_LAYOUT_INVALID_STID, &lo->plh_flags))\n\t\tgoto out_unlock;\n\tif (test_bit(NFS_LAYOUT_RETURN, &lo->plh_flags))\n\t\tgoto out_unlock;\n\tif (pnfs_layoutgets_blocked(lo))\n\t\tgoto out_unlock;\n\tif (test_and_set_bit(NFS_LAYOUT_FIRST_LAYOUTGET, &lo->plh_flags))\n\t\tgoto out_unlock;\n\tnfs_layoutget_begin(lo);\n\tspin_unlock(&ino->i_lock);\n\t_add_to_server_list(lo, NFS_SERVER(ino));\n\treturn lo;\n\nout_unlock:\n\tspin_unlock(&ino->i_lock);\n\tpnfs_put_layout_hdr(lo);\n\treturn NULL;\n}\n\nstatic void _lgopen_prepare_attached(struct nfs4_opendata *data,\n\t\t\t\t     struct nfs_open_context *ctx)\n{\n\tstruct inode *ino = data->dentry->d_inode;\n\tstruct pnfs_layout_range rng = {\n\t\t.iomode = (data->o_arg.fmode & FMODE_WRITE) ?\n\t\t\t  IOMODE_RW: IOMODE_READ,\n\t\t.offset = 0,\n\t\t.length = NFS4_MAX_UINT64,\n\t};\n\tstruct nfs4_layoutget *lgp;\n\tstruct pnfs_layout_hdr *lo;\n\n\t \n\tif (rng.iomode == IOMODE_READ &&\n\t   (i_size_read(ino) == 0 || ino->i_mapping->nrpages != 0))\n\t\treturn;\n\n\tlo = _pnfs_grab_empty_layout(ino, ctx);\n\tif (!lo)\n\t\treturn;\n\tlgp = pnfs_alloc_init_layoutget_args(ino, ctx, &current_stateid, &rng,\n\t\t\t\t\t     nfs_io_gfp_mask());\n\tif (!lgp) {\n\t\tpnfs_clear_first_layoutget(lo);\n\t\tnfs_layoutget_end(lo);\n\t\tpnfs_put_layout_hdr(lo);\n\t\treturn;\n\t}\n\tlgp->lo = lo;\n\tdata->lgp = lgp;\n\tdata->o_arg.lg_args = &lgp->args;\n\tdata->o_res.lg_res = &lgp->res;\n}\n\nstatic void _lgopen_prepare_floating(struct nfs4_opendata *data,\n\t\t\t\t     struct nfs_open_context *ctx)\n{\n\tstruct inode *ino = data->dentry->d_inode;\n\tstruct pnfs_layout_range rng = {\n\t\t.iomode = (data->o_arg.fmode & FMODE_WRITE) ?\n\t\t\t  IOMODE_RW: IOMODE_READ,\n\t\t.offset = 0,\n\t\t.length = NFS4_MAX_UINT64,\n\t};\n\tstruct nfs4_layoutget *lgp;\n\n\tlgp = pnfs_alloc_init_layoutget_args(ino, ctx, &current_stateid, &rng,\n\t\t\t\t\t     nfs_io_gfp_mask());\n\tif (!lgp)\n\t\treturn;\n\tdata->lgp = lgp;\n\tdata->o_arg.lg_args = &lgp->args;\n\tdata->o_res.lg_res = &lgp->res;\n}\n\nvoid pnfs_lgopen_prepare(struct nfs4_opendata *data,\n\t\t\t struct nfs_open_context *ctx)\n{\n\tstruct nfs_server *server = NFS_SERVER(data->dir->d_inode);\n\n\tif (!(pnfs_enabled_sb(server) &&\n\t      server->pnfs_curr_ld->flags & PNFS_LAYOUTGET_ON_OPEN))\n\t\treturn;\n\t \n\tif (!nfs_server_capable(data->dir->d_inode, NFS_CAP_LGOPEN))\n\t\treturn;\n\tif (data->lgp)\n\t\treturn;\n\tif (data->state)\n\t\t_lgopen_prepare_attached(data, ctx);\n\telse\n\t\t_lgopen_prepare_floating(data, ctx);\n}\n\nvoid pnfs_parse_lgopen(struct inode *ino, struct nfs4_layoutget *lgp,\n\t\t       struct nfs_open_context *ctx)\n{\n\tstruct pnfs_layout_hdr *lo;\n\tstruct pnfs_layout_segment *lseg;\n\tstruct nfs_server *srv = NFS_SERVER(ino);\n\tu32 iomode;\n\n\tif (!lgp)\n\t\treturn;\n\tdprintk(\"%s: entered with status %i\\n\", __func__, lgp->res.status);\n\tif (lgp->res.status) {\n\t\tswitch (lgp->res.status) {\n\t\tdefault:\n\t\t\tbreak;\n\t\t \n\t\tcase -NFS4ERR_BAD_STATEID:\n\t\tcase -NFS4ERR_NOTSUPP:\n\t\tcase -NFS4ERR_REP_TOO_BIG:\n\t\tcase -NFS4ERR_REP_TOO_BIG_TO_CACHE:\n\t\tcase -NFS4ERR_REQ_TOO_BIG:\n\t\tcase -NFS4ERR_TOO_MANY_OPS:\n\t\tcase -NFS4ERR_UNKNOWN_LAYOUTTYPE:\n\t\t\tsrv->caps &= ~NFS_CAP_LGOPEN;\n\t\t}\n\t\treturn;\n\t}\n\tif (!lgp->lo) {\n\t\tlo = _pnfs_grab_empty_layout(ino, ctx);\n\t\tif (!lo)\n\t\t\treturn;\n\t\tlgp->lo = lo;\n\t} else\n\t\tlo = lgp->lo;\n\n\tlseg = pnfs_layout_process(lgp);\n\tif (!IS_ERR(lseg)) {\n\t\tiomode = lgp->args.range.iomode;\n\t\tpnfs_layout_clear_fail_bit(lo, pnfs_iomode_to_fail_bit(iomode));\n\t\tpnfs_put_lseg(lseg);\n\t}\n}\n\nvoid nfs4_lgopen_release(struct nfs4_layoutget *lgp)\n{\n\tif (lgp != NULL) {\n\t\tif (lgp->lo) {\n\t\t\tpnfs_clear_first_layoutget(lgp->lo);\n\t\t\tnfs_layoutget_end(lgp->lo);\n\t\t}\n\t\tpnfs_layoutget_free(lgp);\n\t}\n}\n\nstruct pnfs_layout_segment *\npnfs_layout_process(struct nfs4_layoutget *lgp)\n{\n\tstruct pnfs_layout_hdr *lo = lgp->lo;\n\tstruct nfs4_layoutget_res *res = &lgp->res;\n\tstruct pnfs_layout_segment *lseg;\n\tstruct inode *ino = lo->plh_inode;\n\tLIST_HEAD(free_me);\n\n\tif (!pnfs_sanity_check_layout_range(&res->range))\n\t\treturn ERR_PTR(-EINVAL);\n\n\t \n\tlseg = NFS_SERVER(ino)->pnfs_curr_ld->alloc_lseg(lo, res, lgp->gfp_flags);\n\tif (IS_ERR_OR_NULL(lseg)) {\n\t\tif (!lseg)\n\t\t\tlseg = ERR_PTR(-ENOMEM);\n\n\t\tdprintk(\"%s: Could not allocate layout: error %ld\\n\",\n\t\t       __func__, PTR_ERR(lseg));\n\t\treturn lseg;\n\t}\n\n\tpnfs_init_lseg(lo, lseg, &res->range, &res->stateid);\n\n\tspin_lock(&ino->i_lock);\n\tif (pnfs_layoutgets_blocked(lo)) {\n\t\tdprintk(\"%s forget reply due to state\\n\", __func__);\n\t\tgoto out_forget;\n\t}\n\n\tif (test_bit(NFS_LAYOUT_DRAIN, &lo->plh_flags) &&\n\t    !pnfs_is_first_layoutget(lo))\n\t\tgoto out_forget;\n\n\tif (nfs4_stateid_match_other(&lo->plh_stateid, &res->stateid)) {\n\t\t \n\t\tif (pnfs_layout_stateid_blocked(lo, &res->stateid)) {\n\t\t\tif (!pnfs_layout_is_valid(lo))\n\t\t\t\tlo->plh_barrier = 0;\n\t\t\tdprintk(\"%s forget reply due to sequence\\n\", __func__);\n\t\t\tgoto out_forget;\n\t\t}\n\t\tpnfs_set_layout_stateid(lo, &res->stateid, lgp->cred, false);\n\t} else if (pnfs_layout_is_valid(lo)) {\n\t\t \n\t\tstruct pnfs_layout_range range = {\n\t\t\t.iomode = IOMODE_ANY,\n\t\t\t.length = NFS4_MAX_UINT64,\n\t\t};\n\t\tpnfs_mark_matching_lsegs_return(lo, &free_me, &range, 0);\n\t\tgoto out_forget;\n\t} else {\n\t\t \n\t\tpnfs_set_layout_stateid(lo, &res->stateid, lgp->cred, true);\n\t}\n\n\tpnfs_get_lseg(lseg);\n\tpnfs_layout_insert_lseg(lo, lseg, &free_me);\n\n\n\tif (res->return_on_close)\n\t\tset_bit(NFS_LSEG_ROC, &lseg->pls_flags);\n\n\tspin_unlock(&ino->i_lock);\n\tpnfs_free_lseg_list(&free_me);\n\treturn lseg;\n\nout_forget:\n\tspin_unlock(&ino->i_lock);\n\tlseg->pls_layout = lo;\n\tNFS_SERVER(ino)->pnfs_curr_ld->free_lseg(lseg);\n\treturn ERR_PTR(-EAGAIN);\n}\n\n \nint\npnfs_mark_matching_lsegs_return(struct pnfs_layout_hdr *lo,\n\t\t\t\tstruct list_head *tmp_list,\n\t\t\t\tconst struct pnfs_layout_range *return_range,\n\t\t\t\tu32 seq)\n{\n\tstruct pnfs_layout_segment *lseg, *next;\n\tstruct nfs_server *server = NFS_SERVER(lo->plh_inode);\n\tint remaining = 0;\n\n\tdprintk(\"%s:Begin lo %p\\n\", __func__, lo);\n\n\tassert_spin_locked(&lo->plh_inode->i_lock);\n\n\tif (test_bit(NFS_LAYOUT_RETURN_REQUESTED, &lo->plh_flags))\n\t\ttmp_list = &lo->plh_return_segs;\n\n\tlist_for_each_entry_safe(lseg, next, &lo->plh_segs, pls_list)\n\t\tif (pnfs_match_lseg_recall(lseg, return_range, seq)) {\n\t\t\tdprintk(\"%s: marking lseg %p iomode %d \"\n\t\t\t\t\"offset %llu length %llu\\n\", __func__,\n\t\t\t\tlseg, lseg->pls_range.iomode,\n\t\t\t\tlseg->pls_range.offset,\n\t\t\t\tlseg->pls_range.length);\n\t\t\tif (test_bit(NFS_LSEG_LAYOUTRETURN, &lseg->pls_flags))\n\t\t\t\ttmp_list = &lo->plh_return_segs;\n\t\t\tif (mark_lseg_invalid(lseg, tmp_list))\n\t\t\t\tcontinue;\n\t\t\tremaining++;\n\t\t\tset_bit(NFS_LSEG_LAYOUTRETURN, &lseg->pls_flags);\n\t\t\tpnfs_lseg_cancel_io(server, lseg);\n\t\t}\n\n\tif (remaining) {\n\t\tpnfs_set_plh_return_info(lo, return_range->iomode, seq);\n\t\treturn -EBUSY;\n\t}\n\n\tif (!list_empty(&lo->plh_return_segs)) {\n\t\tpnfs_set_plh_return_info(lo, return_range->iomode, seq);\n\t\treturn 0;\n\t}\n\n\treturn -ENOENT;\n}\n\nstatic void\npnfs_mark_layout_for_return(struct inode *inode,\n\t\t\t    const struct pnfs_layout_range *range)\n{\n\tstruct pnfs_layout_hdr *lo;\n\tbool return_now = false;\n\n\tspin_lock(&inode->i_lock);\n\tlo = NFS_I(inode)->layout;\n\tif (!pnfs_layout_is_valid(lo)) {\n\t\tspin_unlock(&inode->i_lock);\n\t\treturn;\n\t}\n\tpnfs_set_plh_return_info(lo, range->iomode, 0);\n\t \n\tif (pnfs_mark_matching_lsegs_return(lo, &lo->plh_return_segs, range, 0) != -EBUSY) {\n\t\tconst struct cred *cred;\n\t\tnfs4_stateid stateid;\n\t\tenum pnfs_iomode iomode;\n\n\t\treturn_now = pnfs_prepare_layoutreturn(lo, &stateid, &cred, &iomode);\n\t\tspin_unlock(&inode->i_lock);\n\t\tif (return_now)\n\t\t\tpnfs_send_layoutreturn(lo, &stateid, &cred, iomode, false);\n\t} else {\n\t\tspin_unlock(&inode->i_lock);\n\t\tnfs_commit_inode(inode, 0);\n\t}\n}\n\nvoid pnfs_error_mark_layout_for_return(struct inode *inode,\n\t\t\t\t       struct pnfs_layout_segment *lseg)\n{\n\tstruct pnfs_layout_range range = {\n\t\t.iomode = lseg->pls_range.iomode,\n\t\t.offset = 0,\n\t\t.length = NFS4_MAX_UINT64,\n\t};\n\n\tpnfs_mark_layout_for_return(inode, &range);\n}\nEXPORT_SYMBOL_GPL(pnfs_error_mark_layout_for_return);\n\nstatic bool\npnfs_layout_can_be_returned(struct pnfs_layout_hdr *lo)\n{\n\treturn pnfs_layout_is_valid(lo) &&\n\t\t!test_bit(NFS_LAYOUT_INODE_FREEING, &lo->plh_flags) &&\n\t\t!test_bit(NFS_LAYOUT_RETURN, &lo->plh_flags);\n}\n\nstatic struct pnfs_layout_segment *\npnfs_find_first_lseg(struct pnfs_layout_hdr *lo,\n\t\t     const struct pnfs_layout_range *range,\n\t\t     enum pnfs_iomode iomode)\n{\n\tstruct pnfs_layout_segment *lseg;\n\n\tlist_for_each_entry(lseg, &lo->plh_segs, pls_list) {\n\t\tif (!test_bit(NFS_LSEG_VALID, &lseg->pls_flags))\n\t\t\tcontinue;\n\t\tif (test_bit(NFS_LSEG_LAYOUTRETURN, &lseg->pls_flags))\n\t\t\tcontinue;\n\t\tif (lseg->pls_range.iomode != iomode && iomode != IOMODE_ANY)\n\t\t\tcontinue;\n\t\tif (pnfs_lseg_range_intersecting(&lseg->pls_range, range))\n\t\t\treturn lseg;\n\t}\n\treturn NULL;\n}\n\n \nstatic bool\npnfs_should_return_unused_layout(struct pnfs_layout_hdr *lo,\n\t\t\t\t const struct pnfs_layout_range *range)\n{\n\tstruct list_head *head;\n\tstruct nfs_open_context *ctx;\n\tfmode_t mode = 0;\n\n\tif (!pnfs_layout_can_be_returned(lo) ||\n\t    !pnfs_find_first_lseg(lo, range, range->iomode))\n\t\treturn false;\n\n\thead = &NFS_I(lo->plh_inode)->open_files;\n\tlist_for_each_entry_rcu(ctx, head, list) {\n\t\tif (ctx->state)\n\t\t\tmode |= ctx->state->state & (FMODE_READ|FMODE_WRITE);\n\t}\n\n\tswitch (range->iomode) {\n\tdefault:\n\t\tbreak;\n\tcase IOMODE_READ:\n\t\tmode &= ~FMODE_WRITE;\n\t\tbreak;\n\tcase IOMODE_RW:\n\t\tif (pnfs_find_first_lseg(lo, range, IOMODE_READ))\n\t\t\tmode &= ~FMODE_READ;\n\t}\n\treturn mode == 0;\n}\n\nstatic int pnfs_layout_return_unused_byserver(struct nfs_server *server,\n\t\t\t\t\t      void *data)\n{\n\tconst struct pnfs_layout_range *range = data;\n\tconst struct cred *cred;\n\tstruct pnfs_layout_hdr *lo;\n\tstruct inode *inode;\n\tnfs4_stateid stateid;\n\tenum pnfs_iomode iomode;\n\nrestart:\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(lo, &server->layouts, plh_layouts) {\n\t\tinode = lo->plh_inode;\n\t\tif (!inode || !pnfs_layout_can_be_returned(lo) ||\n\t\t    test_bit(NFS_LAYOUT_RETURN_REQUESTED, &lo->plh_flags))\n\t\t\tcontinue;\n\t\tspin_lock(&inode->i_lock);\n\t\tif (!lo->plh_inode ||\n\t\t    !pnfs_should_return_unused_layout(lo, range)) {\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\tcontinue;\n\t\t}\n\t\tpnfs_get_layout_hdr(lo);\n\t\tpnfs_set_plh_return_info(lo, range->iomode, 0);\n\t\tif (pnfs_mark_matching_lsegs_return(lo, &lo->plh_return_segs,\n\t\t\t\t\t\t    range, 0) != 0 ||\n\t\t    !pnfs_prepare_layoutreturn(lo, &stateid, &cred, &iomode)) {\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\trcu_read_unlock();\n\t\t\tpnfs_put_layout_hdr(lo);\n\t\t\tcond_resched();\n\t\t\tgoto restart;\n\t\t}\n\t\tspin_unlock(&inode->i_lock);\n\t\trcu_read_unlock();\n\t\tpnfs_send_layoutreturn(lo, &stateid, &cred, iomode, false);\n\t\tpnfs_put_layout_hdr(lo);\n\t\tcond_resched();\n\t\tgoto restart;\n\t}\n\trcu_read_unlock();\n\treturn 0;\n}\n\nvoid\npnfs_layout_return_unused_byclid(struct nfs_client *clp,\n\t\t\t\t enum pnfs_iomode iomode)\n{\n\tstruct pnfs_layout_range range = {\n\t\t.iomode = iomode,\n\t\t.offset = 0,\n\t\t.length = NFS4_MAX_UINT64,\n\t};\n\n\tnfs_client_for_each_server(clp, pnfs_layout_return_unused_byserver,\n\t\t\t&range);\n}\n\nvoid\npnfs_generic_pg_check_layout(struct nfs_pageio_descriptor *pgio)\n{\n\tif (pgio->pg_lseg == NULL ||\n\t    test_bit(NFS_LSEG_VALID, &pgio->pg_lseg->pls_flags))\n\t\treturn;\n\tpnfs_put_lseg(pgio->pg_lseg);\n\tpgio->pg_lseg = NULL;\n}\nEXPORT_SYMBOL_GPL(pnfs_generic_pg_check_layout);\n\n \nvoid\npnfs_generic_pg_check_range(struct nfs_pageio_descriptor *pgio, struct nfs_page *req)\n{\n\tif (pgio->pg_lseg && !pnfs_lseg_request_intersecting(pgio->pg_lseg, req)) {\n\t\tpnfs_put_lseg(pgio->pg_lseg);\n\t\tpgio->pg_lseg = NULL;\n\t}\n}\nEXPORT_SYMBOL_GPL(pnfs_generic_pg_check_range);\n\nvoid\npnfs_generic_pg_init_read(struct nfs_pageio_descriptor *pgio, struct nfs_page *req)\n{\n\tu64 rd_size;\n\n\tpnfs_generic_pg_check_layout(pgio);\n\tpnfs_generic_pg_check_range(pgio, req);\n\tif (pgio->pg_lseg == NULL) {\n\t\tif (pgio->pg_dreq == NULL)\n\t\t\trd_size = i_size_read(pgio->pg_inode) - req_offset(req);\n\t\telse\n\t\t\trd_size = nfs_dreq_bytes_left(pgio->pg_dreq,\n\t\t\t\t\t\t      req_offset(req));\n\n\t\tpgio->pg_lseg =\n\t\t\tpnfs_update_layout(pgio->pg_inode, nfs_req_openctx(req),\n\t\t\t\t\t   req_offset(req), rd_size,\n\t\t\t\t\t   IOMODE_READ, false,\n\t\t\t\t\t   nfs_io_gfp_mask());\n\t\tif (IS_ERR(pgio->pg_lseg)) {\n\t\t\tpgio->pg_error = PTR_ERR(pgio->pg_lseg);\n\t\t\tpgio->pg_lseg = NULL;\n\t\t\treturn;\n\t\t}\n\t}\n\t \n\tif (pgio->pg_lseg == NULL)\n\t\tnfs_pageio_reset_read_mds(pgio);\n\n}\nEXPORT_SYMBOL_GPL(pnfs_generic_pg_init_read);\n\nvoid\npnfs_generic_pg_init_write(struct nfs_pageio_descriptor *pgio,\n\t\t\t   struct nfs_page *req, u64 wb_size)\n{\n\tpnfs_generic_pg_check_layout(pgio);\n\tpnfs_generic_pg_check_range(pgio, req);\n\tif (pgio->pg_lseg == NULL) {\n\t\tpgio->pg_lseg =\n\t\t\tpnfs_update_layout(pgio->pg_inode, nfs_req_openctx(req),\n\t\t\t\t\t   req_offset(req), wb_size, IOMODE_RW,\n\t\t\t\t\t   false, nfs_io_gfp_mask());\n\t\tif (IS_ERR(pgio->pg_lseg)) {\n\t\t\tpgio->pg_error = PTR_ERR(pgio->pg_lseg);\n\t\t\tpgio->pg_lseg = NULL;\n\t\t\treturn;\n\t\t}\n\t}\n\t \n\tif (pgio->pg_lseg == NULL)\n\t\tnfs_pageio_reset_write_mds(pgio);\n}\nEXPORT_SYMBOL_GPL(pnfs_generic_pg_init_write);\n\nvoid\npnfs_generic_pg_cleanup(struct nfs_pageio_descriptor *desc)\n{\n\tif (desc->pg_lseg) {\n\t\tpnfs_put_lseg(desc->pg_lseg);\n\t\tdesc->pg_lseg = NULL;\n\t}\n}\nEXPORT_SYMBOL_GPL(pnfs_generic_pg_cleanup);\n\n \nsize_t\npnfs_generic_pg_test(struct nfs_pageio_descriptor *pgio,\n\t\t     struct nfs_page *prev, struct nfs_page *req)\n{\n\tunsigned int size;\n\tu64 seg_end, req_start, seg_left;\n\n\tsize = nfs_generic_pg_test(pgio, prev, req);\n\tif (!size)\n\t\treturn 0;\n\n\t \n\tif (pgio->pg_lseg) {\n\t\tseg_end = pnfs_end_offset(pgio->pg_lseg->pls_range.offset,\n\t\t\t\t     pgio->pg_lseg->pls_range.length);\n\t\treq_start = req_offset(req);\n\n\t\t \n\t\tif (req_start >= seg_end)\n\t\t\treturn 0;\n\n\t\t \n\t\tseg_left = seg_end - req_start;\n\t\tif (seg_left < size)\n\t\t\tsize = (unsigned int)seg_left;\n\t}\n\n\treturn size;\n}\nEXPORT_SYMBOL_GPL(pnfs_generic_pg_test);\n\nint pnfs_write_done_resend_to_mds(struct nfs_pgio_header *hdr)\n{\n\tstruct nfs_pageio_descriptor pgio;\n\n\t \n\tnfs_pageio_init_write(&pgio, hdr->inode, FLUSH_STABLE, true,\n\t\t\t      hdr->completion_ops);\n\treturn nfs_pageio_resend(&pgio, hdr);\n}\nEXPORT_SYMBOL_GPL(pnfs_write_done_resend_to_mds);\n\nstatic void pnfs_ld_handle_write_error(struct nfs_pgio_header *hdr)\n{\n\n\tdprintk(\"pnfs write error = %d\\n\", hdr->pnfs_error);\n\tif (NFS_SERVER(hdr->inode)->pnfs_curr_ld->flags &\n\t    PNFS_LAYOUTRET_ON_ERROR) {\n\t\tpnfs_return_layout(hdr->inode);\n\t}\n\tif (!test_and_set_bit(NFS_IOHDR_REDO, &hdr->flags))\n\t\thdr->task.tk_status = pnfs_write_done_resend_to_mds(hdr);\n}\n\n \nvoid pnfs_ld_write_done(struct nfs_pgio_header *hdr)\n{\n\tif (likely(!hdr->pnfs_error)) {\n\t\tpnfs_set_layoutcommit(hdr->inode, hdr->lseg,\n\t\t\t\thdr->mds_offset + hdr->res.count);\n\t\thdr->mds_ops->rpc_call_done(&hdr->task, hdr);\n\t}\n\ttrace_nfs4_pnfs_write(hdr, hdr->pnfs_error);\n\tif (unlikely(hdr->pnfs_error))\n\t\tpnfs_ld_handle_write_error(hdr);\n\thdr->mds_ops->rpc_release(hdr);\n}\nEXPORT_SYMBOL_GPL(pnfs_ld_write_done);\n\nstatic void\npnfs_write_through_mds(struct nfs_pageio_descriptor *desc,\n\t\tstruct nfs_pgio_header *hdr)\n{\n\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\n\tif (!test_and_set_bit(NFS_IOHDR_REDO, &hdr->flags)) {\n\t\tlist_splice_tail_init(&hdr->pages, &mirror->pg_list);\n\t\tnfs_pageio_reset_write_mds(desc);\n\t\tmirror->pg_recoalesce = 1;\n\t}\n\thdr->completion_ops->completion(hdr);\n}\n\nstatic enum pnfs_try_status\npnfs_try_to_write_data(struct nfs_pgio_header *hdr,\n\t\t\tconst struct rpc_call_ops *call_ops,\n\t\t\tstruct pnfs_layout_segment *lseg,\n\t\t\tint how)\n{\n\tstruct inode *inode = hdr->inode;\n\tenum pnfs_try_status trypnfs;\n\tstruct nfs_server *nfss = NFS_SERVER(inode);\n\n\thdr->mds_ops = call_ops;\n\n\tdprintk(\"%s: Writing ino:%lu %u@%llu (how %d)\\n\", __func__,\n\t\tinode->i_ino, hdr->args.count, hdr->args.offset, how);\n\ttrypnfs = nfss->pnfs_curr_ld->write_pagelist(hdr, how);\n\tif (trypnfs != PNFS_NOT_ATTEMPTED)\n\t\tnfs_inc_stats(inode, NFSIOS_PNFS_WRITE);\n\tdprintk(\"%s End (trypnfs:%d)\\n\", __func__, trypnfs);\n\treturn trypnfs;\n}\n\nstatic void\npnfs_do_write(struct nfs_pageio_descriptor *desc,\n\t      struct nfs_pgio_header *hdr, int how)\n{\n\tconst struct rpc_call_ops *call_ops = desc->pg_rpc_callops;\n\tstruct pnfs_layout_segment *lseg = desc->pg_lseg;\n\tenum pnfs_try_status trypnfs;\n\n\ttrypnfs = pnfs_try_to_write_data(hdr, call_ops, lseg, how);\n\tswitch (trypnfs) {\n\tcase PNFS_NOT_ATTEMPTED:\n\t\tpnfs_write_through_mds(desc, hdr);\n\t\tbreak;\n\tcase PNFS_ATTEMPTED:\n\t\tbreak;\n\tcase PNFS_TRY_AGAIN:\n\t\t \n\t\tif (!test_and_set_bit(NFS_IOHDR_REDO, &hdr->flags)) {\n\t\t\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\t\t\tlist_splice_init(&hdr->pages, &mirror->pg_list);\n\t\t\tmirror->pg_recoalesce = 1;\n\t\t}\n\t\thdr->mds_ops->rpc_release(hdr);\n\t}\n}\n\nstatic void pnfs_writehdr_free(struct nfs_pgio_header *hdr)\n{\n\tpnfs_put_lseg(hdr->lseg);\n\tnfs_pgio_header_free(hdr);\n}\n\nint\npnfs_generic_pg_writepages(struct nfs_pageio_descriptor *desc)\n{\n\tstruct nfs_pgio_header *hdr;\n\tint ret;\n\n\thdr = nfs_pgio_header_alloc(desc->pg_rw_ops);\n\tif (!hdr) {\n\t\tdesc->pg_error = -ENOMEM;\n\t\treturn desc->pg_error;\n\t}\n\tnfs_pgheader_init(desc, hdr, pnfs_writehdr_free);\n\n\thdr->lseg = pnfs_get_lseg(desc->pg_lseg);\n\tret = nfs_generic_pgio(desc, hdr);\n\tif (!ret)\n\t\tpnfs_do_write(desc, hdr, desc->pg_ioflags);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(pnfs_generic_pg_writepages);\n\nint pnfs_read_done_resend_to_mds(struct nfs_pgio_header *hdr)\n{\n\tstruct nfs_pageio_descriptor pgio;\n\n\t \n\tnfs_pageio_init_read(&pgio, hdr->inode, true, hdr->completion_ops);\n\treturn nfs_pageio_resend(&pgio, hdr);\n}\nEXPORT_SYMBOL_GPL(pnfs_read_done_resend_to_mds);\n\nstatic void pnfs_ld_handle_read_error(struct nfs_pgio_header *hdr)\n{\n\tdprintk(\"pnfs read error = %d\\n\", hdr->pnfs_error);\n\tif (NFS_SERVER(hdr->inode)->pnfs_curr_ld->flags &\n\t    PNFS_LAYOUTRET_ON_ERROR) {\n\t\tpnfs_return_layout(hdr->inode);\n\t}\n\tif (!test_and_set_bit(NFS_IOHDR_REDO, &hdr->flags))\n\t\thdr->task.tk_status = pnfs_read_done_resend_to_mds(hdr);\n}\n\n \nvoid pnfs_ld_read_done(struct nfs_pgio_header *hdr)\n{\n\tif (likely(!hdr->pnfs_error))\n\t\thdr->mds_ops->rpc_call_done(&hdr->task, hdr);\n\ttrace_nfs4_pnfs_read(hdr, hdr->pnfs_error);\n\tif (unlikely(hdr->pnfs_error))\n\t\tpnfs_ld_handle_read_error(hdr);\n\thdr->mds_ops->rpc_release(hdr);\n}\nEXPORT_SYMBOL_GPL(pnfs_ld_read_done);\n\nstatic void\npnfs_read_through_mds(struct nfs_pageio_descriptor *desc,\n\t\tstruct nfs_pgio_header *hdr)\n{\n\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\n\tif (!test_and_set_bit(NFS_IOHDR_REDO, &hdr->flags)) {\n\t\tlist_splice_tail_init(&hdr->pages, &mirror->pg_list);\n\t\tnfs_pageio_reset_read_mds(desc);\n\t\tmirror->pg_recoalesce = 1;\n\t}\n\thdr->completion_ops->completion(hdr);\n}\n\n \nstatic enum pnfs_try_status\npnfs_try_to_read_data(struct nfs_pgio_header *hdr,\n\t\t       const struct rpc_call_ops *call_ops,\n\t\t       struct pnfs_layout_segment *lseg)\n{\n\tstruct inode *inode = hdr->inode;\n\tstruct nfs_server *nfss = NFS_SERVER(inode);\n\tenum pnfs_try_status trypnfs;\n\n\thdr->mds_ops = call_ops;\n\n\tdprintk(\"%s: Reading ino:%lu %u@%llu\\n\",\n\t\t__func__, inode->i_ino, hdr->args.count, hdr->args.offset);\n\n\ttrypnfs = nfss->pnfs_curr_ld->read_pagelist(hdr);\n\tif (trypnfs != PNFS_NOT_ATTEMPTED)\n\t\tnfs_inc_stats(inode, NFSIOS_PNFS_READ);\n\tdprintk(\"%s End (trypnfs:%d)\\n\", __func__, trypnfs);\n\treturn trypnfs;\n}\n\n \nvoid pnfs_read_resend_pnfs(struct nfs_pgio_header *hdr,\n\t\t\t   unsigned int mirror_idx)\n{\n\tstruct nfs_pageio_descriptor pgio;\n\n\tif (!test_and_set_bit(NFS_IOHDR_REDO, &hdr->flags)) {\n\t\t \n\t\tpnfs_put_lseg(hdr->lseg);\n\t\thdr->lseg = NULL;\n\n\t\tnfs_pageio_init_read(&pgio, hdr->inode, false,\n\t\t\t\t\thdr->completion_ops);\n\t\tpgio.pg_mirror_idx = mirror_idx;\n\t\thdr->task.tk_status = nfs_pageio_resend(&pgio, hdr);\n\t}\n}\nEXPORT_SYMBOL_GPL(pnfs_read_resend_pnfs);\n\nstatic void\npnfs_do_read(struct nfs_pageio_descriptor *desc, struct nfs_pgio_header *hdr)\n{\n\tconst struct rpc_call_ops *call_ops = desc->pg_rpc_callops;\n\tstruct pnfs_layout_segment *lseg = desc->pg_lseg;\n\tenum pnfs_try_status trypnfs;\n\n\ttrypnfs = pnfs_try_to_read_data(hdr, call_ops, lseg);\n\tswitch (trypnfs) {\n\tcase PNFS_NOT_ATTEMPTED:\n\t\tpnfs_read_through_mds(desc, hdr);\n\t\tbreak;\n\tcase PNFS_ATTEMPTED:\n\t\tbreak;\n\tcase PNFS_TRY_AGAIN:\n\t\t \n\t\tif (!test_and_set_bit(NFS_IOHDR_REDO, &hdr->flags)) {\n\t\t\tstruct nfs_pgio_mirror *mirror = nfs_pgio_current_mirror(desc);\n\t\t\tlist_splice_init(&hdr->pages, &mirror->pg_list);\n\t\t\tmirror->pg_recoalesce = 1;\n\t\t}\n\t\thdr->mds_ops->rpc_release(hdr);\n\t}\n}\n\nstatic void pnfs_readhdr_free(struct nfs_pgio_header *hdr)\n{\n\tpnfs_put_lseg(hdr->lseg);\n\tnfs_pgio_header_free(hdr);\n}\n\nint\npnfs_generic_pg_readpages(struct nfs_pageio_descriptor *desc)\n{\n\tstruct nfs_pgio_header *hdr;\n\tint ret;\n\n\thdr = nfs_pgio_header_alloc(desc->pg_rw_ops);\n\tif (!hdr) {\n\t\tdesc->pg_error = -ENOMEM;\n\t\treturn desc->pg_error;\n\t}\n\tnfs_pgheader_init(desc, hdr, pnfs_readhdr_free);\n\thdr->lseg = pnfs_get_lseg(desc->pg_lseg);\n\tret = nfs_generic_pgio(desc, hdr);\n\tif (!ret)\n\t\tpnfs_do_read(desc, hdr);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(pnfs_generic_pg_readpages);\n\nstatic void pnfs_clear_layoutcommitting(struct inode *inode)\n{\n\tunsigned long *bitlock = &NFS_I(inode)->flags;\n\n\tclear_bit_unlock(NFS_INO_LAYOUTCOMMITTING, bitlock);\n\tsmp_mb__after_atomic();\n\twake_up_bit(bitlock, NFS_INO_LAYOUTCOMMITTING);\n}\n\n \nstatic void pnfs_list_write_lseg(struct inode *inode, struct list_head *listp)\n{\n\tstruct pnfs_layout_segment *lseg;\n\n\tlist_for_each_entry(lseg, &NFS_I(inode)->layout->plh_segs, pls_list) {\n\t\tif (lseg->pls_range.iomode == IOMODE_RW &&\n\t\t    test_and_clear_bit(NFS_LSEG_LAYOUTCOMMIT, &lseg->pls_flags))\n\t\t\tlist_add(&lseg->pls_lc_list, listp);\n\t}\n}\n\nstatic void pnfs_list_write_lseg_done(struct inode *inode, struct list_head *listp)\n{\n\tstruct pnfs_layout_segment *lseg, *tmp;\n\n\t \n\tlist_for_each_entry_safe(lseg, tmp, listp, pls_lc_list) {\n\t\tlist_del_init(&lseg->pls_lc_list);\n\t\tpnfs_put_lseg(lseg);\n\t}\n\n\tpnfs_clear_layoutcommitting(inode);\n}\n\nvoid pnfs_set_lo_fail(struct pnfs_layout_segment *lseg)\n{\n\tpnfs_layout_io_set_failed(lseg->pls_layout, lseg->pls_range.iomode);\n}\nEXPORT_SYMBOL_GPL(pnfs_set_lo_fail);\n\nvoid\npnfs_set_layoutcommit(struct inode *inode, struct pnfs_layout_segment *lseg,\n\t\tloff_t end_pos)\n{\n\tstruct nfs_inode *nfsi = NFS_I(inode);\n\tbool mark_as_dirty = false;\n\n\tspin_lock(&inode->i_lock);\n\tif (!test_and_set_bit(NFS_INO_LAYOUTCOMMIT, &nfsi->flags)) {\n\t\tnfsi->layout->plh_lwb = end_pos;\n\t\tmark_as_dirty = true;\n\t\tdprintk(\"%s: Set layoutcommit for inode %lu \",\n\t\t\t__func__, inode->i_ino);\n\t} else if (end_pos > nfsi->layout->plh_lwb)\n\t\tnfsi->layout->plh_lwb = end_pos;\n\tif (!test_and_set_bit(NFS_LSEG_LAYOUTCOMMIT, &lseg->pls_flags)) {\n\t\t \n\t\tpnfs_get_lseg(lseg);\n\t}\n\tspin_unlock(&inode->i_lock);\n\tdprintk(\"%s: lseg %p end_pos %llu\\n\",\n\t\t__func__, lseg, nfsi->layout->plh_lwb);\n\n\t \n\tif (mark_as_dirty)\n\t\tmark_inode_dirty_sync(inode);\n}\nEXPORT_SYMBOL_GPL(pnfs_set_layoutcommit);\n\nvoid pnfs_cleanup_layoutcommit(struct nfs4_layoutcommit_data *data)\n{\n\tstruct nfs_server *nfss = NFS_SERVER(data->args.inode);\n\n\tif (nfss->pnfs_curr_ld->cleanup_layoutcommit)\n\t\tnfss->pnfs_curr_ld->cleanup_layoutcommit(data);\n\tpnfs_list_write_lseg_done(data->args.inode, &data->lseg_list);\n}\n\n \nint\npnfs_layoutcommit_inode(struct inode *inode, bool sync)\n{\n\tstruct pnfs_layoutdriver_type *ld = NFS_SERVER(inode)->pnfs_curr_ld;\n\tstruct nfs4_layoutcommit_data *data;\n\tstruct nfs_inode *nfsi = NFS_I(inode);\n\tloff_t end_pos;\n\tint status;\n\n\tif (!pnfs_layoutcommit_outstanding(inode))\n\t\treturn 0;\n\n\tdprintk(\"--> %s inode %lu\\n\", __func__, inode->i_ino);\n\n\tstatus = -EAGAIN;\n\tif (test_and_set_bit(NFS_INO_LAYOUTCOMMITTING, &nfsi->flags)) {\n\t\tif (!sync)\n\t\t\tgoto out;\n\t\tstatus = wait_on_bit_lock_action(&nfsi->flags,\n\t\t\t\tNFS_INO_LAYOUTCOMMITTING,\n\t\t\t\tnfs_wait_bit_killable,\n\t\t\t\tTASK_KILLABLE|TASK_FREEZABLE_UNSAFE);\n\t\tif (status)\n\t\t\tgoto out;\n\t}\n\n\tstatus = -ENOMEM;\n\t \n\tdata = kzalloc(sizeof(*data), nfs_io_gfp_mask());\n\tif (!data)\n\t\tgoto clear_layoutcommitting;\n\n\tstatus = 0;\n\tspin_lock(&inode->i_lock);\n\tif (!test_and_clear_bit(NFS_INO_LAYOUTCOMMIT, &nfsi->flags))\n\t\tgoto out_unlock;\n\n\tINIT_LIST_HEAD(&data->lseg_list);\n\tpnfs_list_write_lseg(inode, &data->lseg_list);\n\n\tend_pos = nfsi->layout->plh_lwb;\n\n\tnfs4_stateid_copy(&data->args.stateid, &nfsi->layout->plh_stateid);\n\tdata->cred = get_cred(nfsi->layout->plh_lc_cred);\n\tspin_unlock(&inode->i_lock);\n\n\tdata->args.inode = inode;\n\tnfs_fattr_init(&data->fattr);\n\tdata->args.bitmask = NFS_SERVER(inode)->cache_consistency_bitmask;\n\tdata->res.fattr = &data->fattr;\n\tif (end_pos != 0)\n\t\tdata->args.lastbytewritten = end_pos - 1;\n\telse\n\t\tdata->args.lastbytewritten = U64_MAX;\n\tdata->res.server = NFS_SERVER(inode);\n\n\tif (ld->prepare_layoutcommit) {\n\t\tstatus = ld->prepare_layoutcommit(&data->args);\n\t\tif (status) {\n\t\t\tput_cred(data->cred);\n\t\t\tspin_lock(&inode->i_lock);\n\t\t\tset_bit(NFS_INO_LAYOUTCOMMIT, &nfsi->flags);\n\t\t\tif (end_pos > nfsi->layout->plh_lwb)\n\t\t\t\tnfsi->layout->plh_lwb = end_pos;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\n\tstatus = nfs4_proc_layoutcommit(data, sync);\nout:\n\tif (status)\n\t\tmark_inode_dirty_sync(inode);\n\tdprintk(\"<-- %s status %d\\n\", __func__, status);\n\treturn status;\nout_unlock:\n\tspin_unlock(&inode->i_lock);\n\tkfree(data);\nclear_layoutcommitting:\n\tpnfs_clear_layoutcommitting(inode);\n\tgoto out;\n}\nEXPORT_SYMBOL_GPL(pnfs_layoutcommit_inode);\n\nint\npnfs_generic_sync(struct inode *inode, bool datasync)\n{\n\treturn pnfs_layoutcommit_inode(inode, true);\n}\nEXPORT_SYMBOL_GPL(pnfs_generic_sync);\n\nstruct nfs4_threshold *pnfs_mdsthreshold_alloc(void)\n{\n\tstruct nfs4_threshold *thp;\n\n\tthp = kzalloc(sizeof(*thp), nfs_io_gfp_mask());\n\tif (!thp) {\n\t\tdprintk(\"%s mdsthreshold allocation failed\\n\", __func__);\n\t\treturn NULL;\n\t}\n\treturn thp;\n}\n\n#if IS_ENABLED(CONFIG_NFS_V4_2)\nint\npnfs_report_layoutstat(struct inode *inode, gfp_t gfp_flags)\n{\n\tstruct pnfs_layoutdriver_type *ld = NFS_SERVER(inode)->pnfs_curr_ld;\n\tstruct nfs_server *server = NFS_SERVER(inode);\n\tstruct nfs_inode *nfsi = NFS_I(inode);\n\tstruct nfs42_layoutstat_data *data;\n\tstruct pnfs_layout_hdr *hdr;\n\tint status = 0;\n\n\tif (!pnfs_enabled_sb(server) || !ld->prepare_layoutstats)\n\t\tgoto out;\n\n\tif (!nfs_server_capable(inode, NFS_CAP_LAYOUTSTATS))\n\t\tgoto out;\n\n\tif (test_and_set_bit(NFS_INO_LAYOUTSTATS, &nfsi->flags))\n\t\tgoto out;\n\n\tspin_lock(&inode->i_lock);\n\tif (!NFS_I(inode)->layout) {\n\t\tspin_unlock(&inode->i_lock);\n\t\tgoto out_clear_layoutstats;\n\t}\n\thdr = NFS_I(inode)->layout;\n\tpnfs_get_layout_hdr(hdr);\n\tspin_unlock(&inode->i_lock);\n\n\tdata = kzalloc(sizeof(*data), gfp_flags);\n\tif (!data) {\n\t\tstatus = -ENOMEM;\n\t\tgoto out_put;\n\t}\n\n\tdata->args.fh = NFS_FH(inode);\n\tdata->args.inode = inode;\n\tstatus = ld->prepare_layoutstats(&data->args);\n\tif (status)\n\t\tgoto out_free;\n\n\tstatus = nfs42_proc_layoutstats_generic(NFS_SERVER(inode), data);\n\nout:\n\tdprintk(\"%s returns %d\\n\", __func__, status);\n\treturn status;\n\nout_free:\n\tkfree(data);\nout_put:\n\tpnfs_put_layout_hdr(hdr);\nout_clear_layoutstats:\n\tsmp_mb__before_atomic();\n\tclear_bit(NFS_INO_LAYOUTSTATS, &nfsi->flags);\n\tsmp_mb__after_atomic();\n\tgoto out;\n}\nEXPORT_SYMBOL_GPL(pnfs_report_layoutstat);\n#endif\n\nunsigned int layoutstats_timer;\nmodule_param(layoutstats_timer, uint, 0644);\nEXPORT_SYMBOL_GPL(layoutstats_timer);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}