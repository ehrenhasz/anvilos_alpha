{
  "module_name": "direct.c",
  "hash_id": "665222138ec7f3385495e14fc96e286a3c7f5dfeaddc0ce442b86b6ad7359e32",
  "original_prompt": "Ingested from linux-6.6.14/fs/nfs/direct.c",
  "human_readable_source": "\n \n\n#include <linux/errno.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/file.h>\n#include <linux/pagemap.h>\n#include <linux/kref.h>\n#include <linux/slab.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/module.h>\n\n#include <linux/nfs_fs.h>\n#include <linux/nfs_page.h>\n#include <linux/sunrpc/clnt.h>\n\n#include <linux/uaccess.h>\n#include <linux/atomic.h>\n\n#include \"internal.h\"\n#include \"iostat.h\"\n#include \"pnfs.h\"\n#include \"fscache.h\"\n#include \"nfstrace.h\"\n\n#define NFSDBG_FACILITY\t\tNFSDBG_VFS\n\nstatic struct kmem_cache *nfs_direct_cachep;\n\nstatic const struct nfs_pgio_completion_ops nfs_direct_write_completion_ops;\nstatic const struct nfs_commit_completion_ops nfs_direct_commit_completion_ops;\nstatic void nfs_direct_write_complete(struct nfs_direct_req *dreq);\nstatic void nfs_direct_write_schedule_work(struct work_struct *work);\n\nstatic inline void get_dreq(struct nfs_direct_req *dreq)\n{\n\tatomic_inc(&dreq->io_count);\n}\n\nstatic inline int put_dreq(struct nfs_direct_req *dreq)\n{\n\treturn atomic_dec_and_test(&dreq->io_count);\n}\n\nstatic void\nnfs_direct_handle_truncated(struct nfs_direct_req *dreq,\n\t\t\t    const struct nfs_pgio_header *hdr,\n\t\t\t    ssize_t dreq_len)\n{\n\tif (!(test_bit(NFS_IOHDR_ERROR, &hdr->flags) ||\n\t      test_bit(NFS_IOHDR_EOF, &hdr->flags)))\n\t\treturn;\n\tif (dreq->max_count >= dreq_len) {\n\t\tdreq->max_count = dreq_len;\n\t\tif (dreq->count > dreq_len)\n\t\t\tdreq->count = dreq_len;\n\t}\n\n\tif (test_bit(NFS_IOHDR_ERROR, &hdr->flags) && !dreq->error)\n\t\tdreq->error = hdr->error;\n}\n\nstatic void\nnfs_direct_count_bytes(struct nfs_direct_req *dreq,\n\t\t       const struct nfs_pgio_header *hdr)\n{\n\tloff_t hdr_end = hdr->io_start + hdr->good_bytes;\n\tssize_t dreq_len = 0;\n\n\tif (hdr_end > dreq->io_start)\n\t\tdreq_len = hdr_end - dreq->io_start;\n\n\tnfs_direct_handle_truncated(dreq, hdr, dreq_len);\n\n\tif (dreq_len > dreq->max_count)\n\t\tdreq_len = dreq->max_count;\n\n\tif (dreq->count < dreq_len)\n\t\tdreq->count = dreq_len;\n}\n\nstatic void nfs_direct_truncate_request(struct nfs_direct_req *dreq,\n\t\t\t\t\tstruct nfs_page *req)\n{\n\tloff_t offs = req_offset(req);\n\tsize_t req_start = (size_t)(offs - dreq->io_start);\n\n\tif (req_start < dreq->max_count)\n\t\tdreq->max_count = req_start;\n\tif (req_start < dreq->count)\n\t\tdreq->count = req_start;\n}\n\n \nint nfs_swap_rw(struct kiocb *iocb, struct iov_iter *iter)\n{\n\tssize_t ret;\n\n\tVM_BUG_ON(iov_iter_count(iter) != PAGE_SIZE);\n\n\tif (iov_iter_rw(iter) == READ)\n\t\tret = nfs_file_direct_read(iocb, iter, true);\n\telse\n\t\tret = nfs_file_direct_write(iocb, iter, true);\n\tif (ret < 0)\n\t\treturn ret;\n\treturn 0;\n}\n\nstatic void nfs_direct_release_pages(struct page **pages, unsigned int npages)\n{\n\tunsigned int i;\n\tfor (i = 0; i < npages; i++)\n\t\tput_page(pages[i]);\n}\n\nvoid nfs_init_cinfo_from_dreq(struct nfs_commit_info *cinfo,\n\t\t\t      struct nfs_direct_req *dreq)\n{\n\tcinfo->inode = dreq->inode;\n\tcinfo->mds = &dreq->mds_cinfo;\n\tcinfo->ds = &dreq->ds_cinfo;\n\tcinfo->dreq = dreq;\n\tcinfo->completion_ops = &nfs_direct_commit_completion_ops;\n}\n\nstatic inline struct nfs_direct_req *nfs_direct_req_alloc(void)\n{\n\tstruct nfs_direct_req *dreq;\n\n\tdreq = kmem_cache_zalloc(nfs_direct_cachep, GFP_KERNEL);\n\tif (!dreq)\n\t\treturn NULL;\n\n\tkref_init(&dreq->kref);\n\tkref_get(&dreq->kref);\n\tinit_completion(&dreq->completion);\n\tINIT_LIST_HEAD(&dreq->mds_cinfo.list);\n\tpnfs_init_ds_commit_info(&dreq->ds_cinfo);\n\tINIT_WORK(&dreq->work, nfs_direct_write_schedule_work);\n\tspin_lock_init(&dreq->lock);\n\n\treturn dreq;\n}\n\nstatic void nfs_direct_req_free(struct kref *kref)\n{\n\tstruct nfs_direct_req *dreq = container_of(kref, struct nfs_direct_req, kref);\n\n\tpnfs_release_ds_info(&dreq->ds_cinfo, dreq->inode);\n\tif (dreq->l_ctx != NULL)\n\t\tnfs_put_lock_context(dreq->l_ctx);\n\tif (dreq->ctx != NULL)\n\t\tput_nfs_open_context(dreq->ctx);\n\tkmem_cache_free(nfs_direct_cachep, dreq);\n}\n\nstatic void nfs_direct_req_release(struct nfs_direct_req *dreq)\n{\n\tkref_put(&dreq->kref, nfs_direct_req_free);\n}\n\nssize_t nfs_dreq_bytes_left(struct nfs_direct_req *dreq, loff_t offset)\n{\n\tloff_t start = offset - dreq->io_start;\n\treturn dreq->max_count - start;\n}\nEXPORT_SYMBOL_GPL(nfs_dreq_bytes_left);\n\n \nstatic ssize_t nfs_direct_wait(struct nfs_direct_req *dreq)\n{\n\tssize_t result = -EIOCBQUEUED;\n\n\t \n\tif (dreq->iocb)\n\t\tgoto out;\n\n\tresult = wait_for_completion_killable(&dreq->completion);\n\n\tif (!result) {\n\t\tresult = dreq->count;\n\t\tWARN_ON_ONCE(dreq->count < 0);\n\t}\n\tif (!result)\n\t\tresult = dreq->error;\n\nout:\n\treturn (ssize_t) result;\n}\n\n \nstatic void nfs_direct_complete(struct nfs_direct_req *dreq)\n{\n\tstruct inode *inode = dreq->inode;\n\n\tinode_dio_end(inode);\n\n\tif (dreq->iocb) {\n\t\tlong res = (long) dreq->error;\n\t\tif (dreq->count != 0) {\n\t\t\tres = (long) dreq->count;\n\t\t\tWARN_ON_ONCE(dreq->count < 0);\n\t\t}\n\t\tdreq->iocb->ki_complete(dreq->iocb, res);\n\t}\n\n\tcomplete(&dreq->completion);\n\n\tnfs_direct_req_release(dreq);\n}\n\nstatic void nfs_direct_read_completion(struct nfs_pgio_header *hdr)\n{\n\tunsigned long bytes = 0;\n\tstruct nfs_direct_req *dreq = hdr->dreq;\n\n\tspin_lock(&dreq->lock);\n\tif (test_bit(NFS_IOHDR_REDO, &hdr->flags)) {\n\t\tspin_unlock(&dreq->lock);\n\t\tgoto out_put;\n\t}\n\n\tnfs_direct_count_bytes(dreq, hdr);\n\tspin_unlock(&dreq->lock);\n\n\twhile (!list_empty(&hdr->pages)) {\n\t\tstruct nfs_page *req = nfs_list_entry(hdr->pages.next);\n\t\tstruct page *page = req->wb_page;\n\n\t\tif (!PageCompound(page) && bytes < hdr->good_bytes &&\n\t\t    (dreq->flags == NFS_ODIRECT_SHOULD_DIRTY))\n\t\t\tset_page_dirty(page);\n\t\tbytes += req->wb_bytes;\n\t\tnfs_list_remove_request(req);\n\t\tnfs_release_request(req);\n\t}\nout_put:\n\tif (put_dreq(dreq))\n\t\tnfs_direct_complete(dreq);\n\thdr->release(hdr);\n}\n\nstatic void nfs_read_sync_pgio_error(struct list_head *head, int error)\n{\n\tstruct nfs_page *req;\n\n\twhile (!list_empty(head)) {\n\t\treq = nfs_list_entry(head->next);\n\t\tnfs_list_remove_request(req);\n\t\tnfs_release_request(req);\n\t}\n}\n\nstatic void nfs_direct_pgio_init(struct nfs_pgio_header *hdr)\n{\n\tget_dreq(hdr->dreq);\n}\n\nstatic const struct nfs_pgio_completion_ops nfs_direct_read_completion_ops = {\n\t.error_cleanup = nfs_read_sync_pgio_error,\n\t.init_hdr = nfs_direct_pgio_init,\n\t.completion = nfs_direct_read_completion,\n};\n\n \n\nstatic ssize_t nfs_direct_read_schedule_iovec(struct nfs_direct_req *dreq,\n\t\t\t\t\t      struct iov_iter *iter,\n\t\t\t\t\t      loff_t pos)\n{\n\tstruct nfs_pageio_descriptor desc;\n\tstruct inode *inode = dreq->inode;\n\tssize_t result = -EINVAL;\n\tsize_t requested_bytes = 0;\n\tsize_t rsize = max_t(size_t, NFS_SERVER(inode)->rsize, PAGE_SIZE);\n\n\tnfs_pageio_init_read(&desc, dreq->inode, false,\n\t\t\t     &nfs_direct_read_completion_ops);\n\tget_dreq(dreq);\n\tdesc.pg_dreq = dreq;\n\tinode_dio_begin(inode);\n\n\twhile (iov_iter_count(iter)) {\n\t\tstruct page **pagevec;\n\t\tsize_t bytes;\n\t\tsize_t pgbase;\n\t\tunsigned npages, i;\n\n\t\tresult = iov_iter_get_pages_alloc2(iter, &pagevec,\n\t\t\t\t\t\t  rsize, &pgbase);\n\t\tif (result < 0)\n\t\t\tbreak;\n\t\n\t\tbytes = result;\n\t\tnpages = (result + pgbase + PAGE_SIZE - 1) / PAGE_SIZE;\n\t\tfor (i = 0; i < npages; i++) {\n\t\t\tstruct nfs_page *req;\n\t\t\tunsigned int req_len = min_t(size_t, bytes, PAGE_SIZE - pgbase);\n\t\t\t \n\t\t\treq = nfs_page_create_from_page(dreq->ctx, pagevec[i],\n\t\t\t\t\t\t\tpgbase, pos, req_len);\n\t\t\tif (IS_ERR(req)) {\n\t\t\t\tresult = PTR_ERR(req);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!nfs_pageio_add_request(&desc, req)) {\n\t\t\t\tresult = desc.pg_error;\n\t\t\t\tnfs_release_request(req);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tpgbase = 0;\n\t\t\tbytes -= req_len;\n\t\t\trequested_bytes += req_len;\n\t\t\tpos += req_len;\n\t\t\tdreq->bytes_left -= req_len;\n\t\t}\n\t\tnfs_direct_release_pages(pagevec, npages);\n\t\tkvfree(pagevec);\n\t\tif (result < 0)\n\t\t\tbreak;\n\t}\n\n\tnfs_pageio_complete(&desc);\n\n\t \n\tif (requested_bytes == 0) {\n\t\tinode_dio_end(inode);\n\t\tnfs_direct_req_release(dreq);\n\t\treturn result < 0 ? result : -EIO;\n\t}\n\n\tif (put_dreq(dreq))\n\t\tnfs_direct_complete(dreq);\n\treturn requested_bytes;\n}\n\n \nssize_t nfs_file_direct_read(struct kiocb *iocb, struct iov_iter *iter,\n\t\t\t     bool swap)\n{\n\tstruct file *file = iocb->ki_filp;\n\tstruct address_space *mapping = file->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tstruct nfs_direct_req *dreq;\n\tstruct nfs_lock_context *l_ctx;\n\tssize_t result, requested;\n\tsize_t count = iov_iter_count(iter);\n\tnfs_add_stats(mapping->host, NFSIOS_DIRECTREADBYTES, count);\n\n\tdfprintk(FILE, \"NFS: direct read(%pD2, %zd@%Ld)\\n\",\n\t\tfile, count, (long long) iocb->ki_pos);\n\n\tresult = 0;\n\tif (!count)\n\t\tgoto out;\n\n\ttask_io_account_read(count);\n\n\tresult = -ENOMEM;\n\tdreq = nfs_direct_req_alloc();\n\tif (dreq == NULL)\n\t\tgoto out;\n\n\tdreq->inode = inode;\n\tdreq->bytes_left = dreq->max_count = count;\n\tdreq->io_start = iocb->ki_pos;\n\tdreq->ctx = get_nfs_open_context(nfs_file_open_context(iocb->ki_filp));\n\tl_ctx = nfs_get_lock_context(dreq->ctx);\n\tif (IS_ERR(l_ctx)) {\n\t\tresult = PTR_ERR(l_ctx);\n\t\tnfs_direct_req_release(dreq);\n\t\tgoto out_release;\n\t}\n\tdreq->l_ctx = l_ctx;\n\tif (!is_sync_kiocb(iocb))\n\t\tdreq->iocb = iocb;\n\n\tif (user_backed_iter(iter))\n\t\tdreq->flags = NFS_ODIRECT_SHOULD_DIRTY;\n\n\tif (!swap)\n\t\tnfs_start_io_direct(inode);\n\n\tNFS_I(inode)->read_io += count;\n\trequested = nfs_direct_read_schedule_iovec(dreq, iter, iocb->ki_pos);\n\n\tif (!swap)\n\t\tnfs_end_io_direct(inode);\n\n\tif (requested > 0) {\n\t\tresult = nfs_direct_wait(dreq);\n\t\tif (result > 0) {\n\t\t\trequested -= result;\n\t\t\tiocb->ki_pos += result;\n\t\t}\n\t\tiov_iter_revert(iter, requested);\n\t} else {\n\t\tresult = requested;\n\t}\n\nout_release:\n\tnfs_direct_req_release(dreq);\nout:\n\treturn result;\n}\n\nstatic void nfs_direct_add_page_head(struct list_head *list,\n\t\t\t\t     struct nfs_page *req)\n{\n\tstruct nfs_page *head = req->wb_head;\n\n\tif (!list_empty(&head->wb_list) || !nfs_lock_request(head))\n\t\treturn;\n\tif (!list_empty(&head->wb_list)) {\n\t\tnfs_unlock_request(head);\n\t\treturn;\n\t}\n\tlist_add(&head->wb_list, list);\n\tkref_get(&head->wb_kref);\n\tkref_get(&head->wb_kref);\n}\n\nstatic void nfs_direct_join_group(struct list_head *list,\n\t\t\t\t  struct nfs_commit_info *cinfo,\n\t\t\t\t  struct inode *inode)\n{\n\tstruct nfs_page *req, *subreq;\n\n\tlist_for_each_entry(req, list, wb_list) {\n\t\tif (req->wb_head != req) {\n\t\t\tnfs_direct_add_page_head(&req->wb_list, req);\n\t\t\tcontinue;\n\t\t}\n\t\tsubreq = req->wb_this_page;\n\t\tif (subreq == req)\n\t\t\tcontinue;\n\t\tdo {\n\t\t\t \n\t\t\tif (!list_empty(&subreq->wb_list)) {\n\t\t\t\tnfs_list_remove_request(subreq);\n\t\t\t\tnfs_release_request(subreq);\n\t\t\t}\n\t\t} while ((subreq = subreq->wb_this_page) != req);\n\t\tnfs_join_page_group(req, cinfo, inode);\n\t}\n}\n\nstatic void\nnfs_direct_write_scan_commit_list(struct inode *inode,\n\t\t\t\t  struct list_head *list,\n\t\t\t\t  struct nfs_commit_info *cinfo)\n{\n\tmutex_lock(&NFS_I(cinfo->inode)->commit_mutex);\n\tpnfs_recover_commit_reqs(list, cinfo);\n\tnfs_scan_commit_list(&cinfo->mds->list, list, cinfo, 0);\n\tmutex_unlock(&NFS_I(cinfo->inode)->commit_mutex);\n}\n\nstatic void nfs_direct_write_reschedule(struct nfs_direct_req *dreq)\n{\n\tstruct nfs_pageio_descriptor desc;\n\tstruct nfs_page *req;\n\tLIST_HEAD(reqs);\n\tstruct nfs_commit_info cinfo;\n\n\tnfs_init_cinfo_from_dreq(&cinfo, dreq);\n\tnfs_direct_write_scan_commit_list(dreq->inode, &reqs, &cinfo);\n\n\tnfs_direct_join_group(&reqs, &cinfo, dreq->inode);\n\n\tnfs_clear_pnfs_ds_commit_verifiers(&dreq->ds_cinfo);\n\tget_dreq(dreq);\n\n\tnfs_pageio_init_write(&desc, dreq->inode, FLUSH_STABLE, false,\n\t\t\t      &nfs_direct_write_completion_ops);\n\tdesc.pg_dreq = dreq;\n\n\twhile (!list_empty(&reqs)) {\n\t\treq = nfs_list_entry(reqs.next);\n\t\t \n\t\treq->wb_nio++;\n\t\tif (!nfs_pageio_add_request(&desc, req)) {\n\t\t\tspin_lock(&dreq->lock);\n\t\t\tif (dreq->error < 0) {\n\t\t\t\tdesc.pg_error = dreq->error;\n\t\t\t} else if (desc.pg_error != -EAGAIN) {\n\t\t\t\tdreq->flags = 0;\n\t\t\t\tif (!desc.pg_error)\n\t\t\t\t\tdesc.pg_error = -EIO;\n\t\t\t\tdreq->error = desc.pg_error;\n\t\t\t} else\n\t\t\t\tdreq->flags = NFS_ODIRECT_RESCHED_WRITES;\n\t\t\tspin_unlock(&dreq->lock);\n\t\t\tbreak;\n\t\t}\n\t\tnfs_release_request(req);\n\t}\n\tnfs_pageio_complete(&desc);\n\n\twhile (!list_empty(&reqs)) {\n\t\treq = nfs_list_entry(reqs.next);\n\t\tnfs_list_remove_request(req);\n\t\tnfs_unlock_and_release_request(req);\n\t\tif (desc.pg_error == -EAGAIN) {\n\t\t\tnfs_mark_request_commit(req, NULL, &cinfo, 0);\n\t\t} else {\n\t\t\tspin_lock(&dreq->lock);\n\t\t\tnfs_direct_truncate_request(dreq, req);\n\t\t\tspin_unlock(&dreq->lock);\n\t\t\tnfs_release_request(req);\n\t\t}\n\t}\n\n\tif (put_dreq(dreq))\n\t\tnfs_direct_write_complete(dreq);\n}\n\nstatic void nfs_direct_commit_complete(struct nfs_commit_data *data)\n{\n\tconst struct nfs_writeverf *verf = data->res.verf;\n\tstruct nfs_direct_req *dreq = data->dreq;\n\tstruct nfs_commit_info cinfo;\n\tstruct nfs_page *req;\n\tint status = data->task.tk_status;\n\n\ttrace_nfs_direct_commit_complete(dreq);\n\n\tif (status < 0) {\n\t\t \n\t\tdreq->error = status;\n\t\tdreq->flags = NFS_ODIRECT_DONE;\n\t} else {\n\t\tstatus = dreq->error;\n\t}\n\n\tnfs_init_cinfo_from_dreq(&cinfo, dreq);\n\n\twhile (!list_empty(&data->pages)) {\n\t\treq = nfs_list_entry(data->pages.next);\n\t\tnfs_list_remove_request(req);\n\t\tif (status < 0) {\n\t\t\tspin_lock(&dreq->lock);\n\t\t\tnfs_direct_truncate_request(dreq, req);\n\t\t\tspin_unlock(&dreq->lock);\n\t\t\tnfs_release_request(req);\n\t\t} else if (!nfs_write_match_verf(verf, req)) {\n\t\t\tdreq->flags = NFS_ODIRECT_RESCHED_WRITES;\n\t\t\t \n\t\t\treq->wb_nio = 0;\n\t\t\tnfs_mark_request_commit(req, NULL, &cinfo, 0);\n\t\t} else\n\t\t\tnfs_release_request(req);\n\t\tnfs_unlock_and_release_request(req);\n\t}\n\n\tif (nfs_commit_end(cinfo.mds))\n\t\tnfs_direct_write_complete(dreq);\n}\n\nstatic void nfs_direct_resched_write(struct nfs_commit_info *cinfo,\n\t\tstruct nfs_page *req)\n{\n\tstruct nfs_direct_req *dreq = cinfo->dreq;\n\n\ttrace_nfs_direct_resched_write(dreq);\n\n\tspin_lock(&dreq->lock);\n\tif (dreq->flags != NFS_ODIRECT_DONE)\n\t\tdreq->flags = NFS_ODIRECT_RESCHED_WRITES;\n\tspin_unlock(&dreq->lock);\n\tnfs_mark_request_commit(req, NULL, cinfo, 0);\n}\n\nstatic const struct nfs_commit_completion_ops nfs_direct_commit_completion_ops = {\n\t.completion = nfs_direct_commit_complete,\n\t.resched_write = nfs_direct_resched_write,\n};\n\nstatic void nfs_direct_commit_schedule(struct nfs_direct_req *dreq)\n{\n\tint res;\n\tstruct nfs_commit_info cinfo;\n\tLIST_HEAD(mds_list);\n\n\tnfs_init_cinfo_from_dreq(&cinfo, dreq);\n\tnfs_scan_commit(dreq->inode, &mds_list, &cinfo);\n\tres = nfs_generic_commit_list(dreq->inode, &mds_list, 0, &cinfo);\n\tif (res < 0)  \n\t\tnfs_direct_write_reschedule(dreq);\n}\n\nstatic void nfs_direct_write_clear_reqs(struct nfs_direct_req *dreq)\n{\n\tstruct nfs_commit_info cinfo;\n\tstruct nfs_page *req;\n\tLIST_HEAD(reqs);\n\n\tnfs_init_cinfo_from_dreq(&cinfo, dreq);\n\tnfs_direct_write_scan_commit_list(dreq->inode, &reqs, &cinfo);\n\n\twhile (!list_empty(&reqs)) {\n\t\treq = nfs_list_entry(reqs.next);\n\t\tnfs_list_remove_request(req);\n\t\tnfs_direct_truncate_request(dreq, req);\n\t\tnfs_release_request(req);\n\t\tnfs_unlock_and_release_request(req);\n\t}\n}\n\nstatic void nfs_direct_write_schedule_work(struct work_struct *work)\n{\n\tstruct nfs_direct_req *dreq = container_of(work, struct nfs_direct_req, work);\n\tint flags = dreq->flags;\n\n\tdreq->flags = 0;\n\tswitch (flags) {\n\t\tcase NFS_ODIRECT_DO_COMMIT:\n\t\t\tnfs_direct_commit_schedule(dreq);\n\t\t\tbreak;\n\t\tcase NFS_ODIRECT_RESCHED_WRITES:\n\t\t\tnfs_direct_write_reschedule(dreq);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnfs_direct_write_clear_reqs(dreq);\n\t\t\tnfs_zap_mapping(dreq->inode, dreq->inode->i_mapping);\n\t\t\tnfs_direct_complete(dreq);\n\t}\n}\n\nstatic void nfs_direct_write_complete(struct nfs_direct_req *dreq)\n{\n\ttrace_nfs_direct_write_complete(dreq);\n\tqueue_work(nfsiod_workqueue, &dreq->work);  \n}\n\nstatic void nfs_direct_write_completion(struct nfs_pgio_header *hdr)\n{\n\tstruct nfs_direct_req *dreq = hdr->dreq;\n\tstruct nfs_commit_info cinfo;\n\tstruct nfs_page *req = nfs_list_entry(hdr->pages.next);\n\tint flags = NFS_ODIRECT_DONE;\n\n\ttrace_nfs_direct_write_completion(dreq);\n\n\tnfs_init_cinfo_from_dreq(&cinfo, dreq);\n\n\tspin_lock(&dreq->lock);\n\tif (test_bit(NFS_IOHDR_REDO, &hdr->flags)) {\n\t\tspin_unlock(&dreq->lock);\n\t\tgoto out_put;\n\t}\n\n\tnfs_direct_count_bytes(dreq, hdr);\n\tif (test_bit(NFS_IOHDR_UNSTABLE_WRITES, &hdr->flags) &&\n\t    !test_bit(NFS_IOHDR_ERROR, &hdr->flags)) {\n\t\tif (!dreq->flags)\n\t\t\tdreq->flags = NFS_ODIRECT_DO_COMMIT;\n\t\tflags = dreq->flags;\n\t}\n\tspin_unlock(&dreq->lock);\n\n\twhile (!list_empty(&hdr->pages)) {\n\n\t\treq = nfs_list_entry(hdr->pages.next);\n\t\tnfs_list_remove_request(req);\n\t\tif (flags == NFS_ODIRECT_DO_COMMIT) {\n\t\t\tkref_get(&req->wb_kref);\n\t\t\tmemcpy(&req->wb_verf, &hdr->verf.verifier,\n\t\t\t       sizeof(req->wb_verf));\n\t\t\tnfs_mark_request_commit(req, hdr->lseg, &cinfo,\n\t\t\t\thdr->ds_commit_idx);\n\t\t} else if (flags == NFS_ODIRECT_RESCHED_WRITES) {\n\t\t\tkref_get(&req->wb_kref);\n\t\t\tnfs_mark_request_commit(req, NULL, &cinfo, 0);\n\t\t}\n\t\tnfs_unlock_and_release_request(req);\n\t}\n\nout_put:\n\tif (put_dreq(dreq))\n\t\tnfs_direct_write_complete(dreq);\n\thdr->release(hdr);\n}\n\nstatic void nfs_write_sync_pgio_error(struct list_head *head, int error)\n{\n\tstruct nfs_page *req;\n\n\twhile (!list_empty(head)) {\n\t\treq = nfs_list_entry(head->next);\n\t\tnfs_list_remove_request(req);\n\t\tnfs_unlock_and_release_request(req);\n\t}\n}\n\nstatic void nfs_direct_write_reschedule_io(struct nfs_pgio_header *hdr)\n{\n\tstruct nfs_direct_req *dreq = hdr->dreq;\n\tstruct nfs_page *req;\n\tstruct nfs_commit_info cinfo;\n\n\ttrace_nfs_direct_write_reschedule_io(dreq);\n\n\tnfs_init_cinfo_from_dreq(&cinfo, dreq);\n\tspin_lock(&dreq->lock);\n\tif (dreq->error == 0)\n\t\tdreq->flags = NFS_ODIRECT_RESCHED_WRITES;\n\tset_bit(NFS_IOHDR_REDO, &hdr->flags);\n\tspin_unlock(&dreq->lock);\n\twhile (!list_empty(&hdr->pages)) {\n\t\treq = nfs_list_entry(hdr->pages.next);\n\t\tnfs_list_remove_request(req);\n\t\tnfs_unlock_request(req);\n\t\tnfs_mark_request_commit(req, NULL, &cinfo, 0);\n\t}\n}\n\nstatic const struct nfs_pgio_completion_ops nfs_direct_write_completion_ops = {\n\t.error_cleanup = nfs_write_sync_pgio_error,\n\t.init_hdr = nfs_direct_pgio_init,\n\t.completion = nfs_direct_write_completion,\n\t.reschedule_io = nfs_direct_write_reschedule_io,\n};\n\n\n \n \nstatic ssize_t nfs_direct_write_schedule_iovec(struct nfs_direct_req *dreq,\n\t\t\t\t\t       struct iov_iter *iter,\n\t\t\t\t\t       loff_t pos, int ioflags)\n{\n\tstruct nfs_pageio_descriptor desc;\n\tstruct inode *inode = dreq->inode;\n\tstruct nfs_commit_info cinfo;\n\tssize_t result = 0;\n\tsize_t requested_bytes = 0;\n\tsize_t wsize = max_t(size_t, NFS_SERVER(inode)->wsize, PAGE_SIZE);\n\tbool defer = false;\n\n\ttrace_nfs_direct_write_schedule_iovec(dreq);\n\n\tnfs_pageio_init_write(&desc, inode, ioflags, false,\n\t\t\t      &nfs_direct_write_completion_ops);\n\tdesc.pg_dreq = dreq;\n\tget_dreq(dreq);\n\tinode_dio_begin(inode);\n\n\tNFS_I(inode)->write_io += iov_iter_count(iter);\n\twhile (iov_iter_count(iter)) {\n\t\tstruct page **pagevec;\n\t\tsize_t bytes;\n\t\tsize_t pgbase;\n\t\tunsigned npages, i;\n\n\t\tresult = iov_iter_get_pages_alloc2(iter, &pagevec,\n\t\t\t\t\t\t  wsize, &pgbase);\n\t\tif (result < 0)\n\t\t\tbreak;\n\n\t\tbytes = result;\n\t\tnpages = (result + pgbase + PAGE_SIZE - 1) / PAGE_SIZE;\n\t\tfor (i = 0; i < npages; i++) {\n\t\t\tstruct nfs_page *req;\n\t\t\tunsigned int req_len = min_t(size_t, bytes, PAGE_SIZE - pgbase);\n\n\t\t\treq = nfs_page_create_from_page(dreq->ctx, pagevec[i],\n\t\t\t\t\t\t\tpgbase, pos, req_len);\n\t\t\tif (IS_ERR(req)) {\n\t\t\t\tresult = PTR_ERR(req);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (desc.pg_error < 0) {\n\t\t\t\tnfs_free_request(req);\n\t\t\t\tresult = desc.pg_error;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tpgbase = 0;\n\t\t\tbytes -= req_len;\n\t\t\trequested_bytes += req_len;\n\t\t\tpos += req_len;\n\t\t\tdreq->bytes_left -= req_len;\n\n\t\t\tif (defer) {\n\t\t\t\tnfs_mark_request_commit(req, NULL, &cinfo, 0);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tnfs_lock_request(req);\n\t\t\tif (nfs_pageio_add_request(&desc, req))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (desc.pg_error < 0 && desc.pg_error != -EAGAIN) {\n\t\t\t\tresult = desc.pg_error;\n\t\t\t\tnfs_unlock_and_release_request(req);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tnfs_init_cinfo_from_dreq(&cinfo, dreq);\n\t\t\tspin_lock(&dreq->lock);\n\t\t\tdreq->flags = NFS_ODIRECT_RESCHED_WRITES;\n\t\t\tspin_unlock(&dreq->lock);\n\t\t\tnfs_unlock_request(req);\n\t\t\tnfs_mark_request_commit(req, NULL, &cinfo, 0);\n\t\t\tdesc.pg_error = 0;\n\t\t\tdefer = true;\n\t\t}\n\t\tnfs_direct_release_pages(pagevec, npages);\n\t\tkvfree(pagevec);\n\t\tif (result < 0)\n\t\t\tbreak;\n\t}\n\tnfs_pageio_complete(&desc);\n\n\t \n\tif (requested_bytes == 0) {\n\t\tinode_dio_end(inode);\n\t\tnfs_direct_req_release(dreq);\n\t\treturn result < 0 ? result : -EIO;\n\t}\n\n\tif (put_dreq(dreq))\n\t\tnfs_direct_write_complete(dreq);\n\treturn requested_bytes;\n}\n\n \nssize_t nfs_file_direct_write(struct kiocb *iocb, struct iov_iter *iter,\n\t\t\t      bool swap)\n{\n\tssize_t result, requested;\n\tsize_t count;\n\tstruct file *file = iocb->ki_filp;\n\tstruct address_space *mapping = file->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tstruct nfs_direct_req *dreq;\n\tstruct nfs_lock_context *l_ctx;\n\tloff_t pos, end;\n\n\tdfprintk(FILE, \"NFS: direct write(%pD2, %zd@%Ld)\\n\",\n\t\tfile, iov_iter_count(iter), (long long) iocb->ki_pos);\n\n\tif (swap)\n\t\t \n\t\tresult =  iov_iter_count(iter);\n\telse\n\t\tresult = generic_write_checks(iocb, iter);\n\tif (result <= 0)\n\t\treturn result;\n\tcount = result;\n\tnfs_add_stats(mapping->host, NFSIOS_DIRECTWRITTENBYTES, count);\n\n\tpos = iocb->ki_pos;\n\tend = (pos + iov_iter_count(iter) - 1) >> PAGE_SHIFT;\n\n\ttask_io_account_write(count);\n\n\tresult = -ENOMEM;\n\tdreq = nfs_direct_req_alloc();\n\tif (!dreq)\n\t\tgoto out;\n\n\tdreq->inode = inode;\n\tdreq->bytes_left = dreq->max_count = count;\n\tdreq->io_start = pos;\n\tdreq->ctx = get_nfs_open_context(nfs_file_open_context(iocb->ki_filp));\n\tl_ctx = nfs_get_lock_context(dreq->ctx);\n\tif (IS_ERR(l_ctx)) {\n\t\tresult = PTR_ERR(l_ctx);\n\t\tnfs_direct_req_release(dreq);\n\t\tgoto out_release;\n\t}\n\tdreq->l_ctx = l_ctx;\n\tif (!is_sync_kiocb(iocb))\n\t\tdreq->iocb = iocb;\n\tpnfs_init_ds_commit_info_ops(&dreq->ds_cinfo, inode);\n\n\tif (swap) {\n\t\trequested = nfs_direct_write_schedule_iovec(dreq, iter, pos,\n\t\t\t\t\t\t\t    FLUSH_STABLE);\n\t} else {\n\t\tnfs_start_io_direct(inode);\n\n\t\trequested = nfs_direct_write_schedule_iovec(dreq, iter, pos,\n\t\t\t\t\t\t\t    FLUSH_COND_STABLE);\n\n\t\tif (mapping->nrpages) {\n\t\t\tinvalidate_inode_pages2_range(mapping,\n\t\t\t\t\t\t      pos >> PAGE_SHIFT, end);\n\t\t}\n\n\t\tnfs_end_io_direct(inode);\n\t}\n\n\tif (requested > 0) {\n\t\tresult = nfs_direct_wait(dreq);\n\t\tif (result > 0) {\n\t\t\trequested -= result;\n\t\t\tiocb->ki_pos = pos + result;\n\t\t\t \n\t\t\tgeneric_write_sync(iocb, result);\n\t\t}\n\t\tiov_iter_revert(iter, requested);\n\t} else {\n\t\tresult = requested;\n\t}\n\tnfs_fscache_invalidate(inode, FSCACHE_INVAL_DIO_WRITE);\nout_release:\n\tnfs_direct_req_release(dreq);\nout:\n\treturn result;\n}\n\n \nint __init nfs_init_directcache(void)\n{\n\tnfs_direct_cachep = kmem_cache_create(\"nfs_direct_cache\",\n\t\t\t\t\t\tsizeof(struct nfs_direct_req),\n\t\t\t\t\t\t0, (SLAB_RECLAIM_ACCOUNT|\n\t\t\t\t\t\t\tSLAB_MEM_SPREAD),\n\t\t\t\t\t\tNULL);\n\tif (nfs_direct_cachep == NULL)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n \nvoid nfs_destroy_directcache(void)\n{\n\tkmem_cache_destroy(nfs_direct_cachep);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}