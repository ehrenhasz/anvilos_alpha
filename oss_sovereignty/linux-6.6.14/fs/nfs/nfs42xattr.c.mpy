{
  "module_name": "nfs42xattr.c",
  "hash_id": "f1ddef2d4c4a22517489f34a5d522e8aeee63338d97d7047043c1998446d1272",
  "original_prompt": "Ingested from linux-6.6.14/fs/nfs/nfs42xattr.c",
  "human_readable_source": "\n\n \n#include <linux/errno.h>\n#include <linux/nfs_fs.h>\n#include <linux/hashtable.h>\n#include <linux/refcount.h>\n#include <uapi/linux/xattr.h>\n\n#include \"nfs4_fs.h\"\n#include \"internal.h\"\n\n \n\n \n#define NFS4_XATTR_HASH_SIZE\t64\n\n#define NFSDBG_FACILITY\tNFSDBG_XATTRCACHE\n\nstruct nfs4_xattr_cache;\nstruct nfs4_xattr_entry;\n\nstruct nfs4_xattr_bucket {\n\tspinlock_t lock;\n\tstruct hlist_head hlist;\n\tstruct nfs4_xattr_cache *cache;\n\tbool draining;\n};\n\nstruct nfs4_xattr_cache {\n\tstruct kref ref;\n\tstruct nfs4_xattr_bucket buckets[NFS4_XATTR_HASH_SIZE];\n\tstruct list_head lru;\n\tstruct list_head dispose;\n\tatomic_long_t nent;\n\tspinlock_t listxattr_lock;\n\tstruct inode *inode;\n\tstruct nfs4_xattr_entry *listxattr;\n};\n\nstruct nfs4_xattr_entry {\n\tstruct kref ref;\n\tstruct hlist_node hnode;\n\tstruct list_head lru;\n\tstruct list_head dispose;\n\tchar *xattr_name;\n\tvoid *xattr_value;\n\tsize_t xattr_size;\n\tstruct nfs4_xattr_bucket *bucket;\n\tuint32_t flags;\n};\n\n#define\tNFS4_XATTR_ENTRY_EXTVAL\t0x0001\n\n \nstatic struct list_lru nfs4_xattr_cache_lru;\nstatic struct list_lru nfs4_xattr_entry_lru;\nstatic struct list_lru nfs4_xattr_large_entry_lru;\n\nstatic struct kmem_cache *nfs4_xattr_cache_cachep;\n\n \nstatic void\nnfs4_xattr_hash_init(struct nfs4_xattr_cache *cache)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < NFS4_XATTR_HASH_SIZE; i++) {\n\t\tINIT_HLIST_HEAD(&cache->buckets[i].hlist);\n\t\tspin_lock_init(&cache->buckets[i].lock);\n\t\tcache->buckets[i].cache = cache;\n\t\tcache->buckets[i].draining = false;\n\t}\n}\n\n \n\n \nstatic bool\nnfs4_xattr_entry_lru_add(struct nfs4_xattr_entry *entry)\n{\n\tstruct list_lru *lru;\n\n\tlru = (entry->flags & NFS4_XATTR_ENTRY_EXTVAL) ?\n\t    &nfs4_xattr_large_entry_lru : &nfs4_xattr_entry_lru;\n\n\treturn list_lru_add(lru, &entry->lru);\n}\n\nstatic bool\nnfs4_xattr_entry_lru_del(struct nfs4_xattr_entry *entry)\n{\n\tstruct list_lru *lru;\n\n\tlru = (entry->flags & NFS4_XATTR_ENTRY_EXTVAL) ?\n\t    &nfs4_xattr_large_entry_lru : &nfs4_xattr_entry_lru;\n\n\treturn list_lru_del(lru, &entry->lru);\n}\n\n \nstatic struct nfs4_xattr_entry *\nnfs4_xattr_alloc_entry(const char *name, const void *value,\n\t\t       struct page **pages, size_t len)\n{\n\tstruct nfs4_xattr_entry *entry;\n\tvoid *valp;\n\tchar *namep;\n\tsize_t alloclen, slen;\n\tchar *buf;\n\tuint32_t flags;\n\n\tBUILD_BUG_ON(sizeof(struct nfs4_xattr_entry) +\n\t    XATTR_NAME_MAX + 1 > PAGE_SIZE);\n\n\talloclen = sizeof(struct nfs4_xattr_entry);\n\tif (name != NULL) {\n\t\tslen = strlen(name) + 1;\n\t\talloclen += slen;\n\t} else\n\t\tslen = 0;\n\n\tif (alloclen + len <= PAGE_SIZE) {\n\t\talloclen += len;\n\t\tflags = 0;\n\t} else {\n\t\tflags = NFS4_XATTR_ENTRY_EXTVAL;\n\t}\n\n\tbuf = kmalloc(alloclen, GFP_KERNEL);\n\tif (buf == NULL)\n\t\treturn NULL;\n\tentry = (struct nfs4_xattr_entry *)buf;\n\n\tif (name != NULL) {\n\t\tnamep = buf + sizeof(struct nfs4_xattr_entry);\n\t\tmemcpy(namep, name, slen);\n\t} else {\n\t\tnamep = NULL;\n\t}\n\n\n\tif (flags & NFS4_XATTR_ENTRY_EXTVAL) {\n\t\tvalp = kvmalloc(len, GFP_KERNEL);\n\t\tif (valp == NULL) {\n\t\t\tkfree(buf);\n\t\t\treturn NULL;\n\t\t}\n\t} else if (len != 0) {\n\t\tvalp = buf + sizeof(struct nfs4_xattr_entry) + slen;\n\t} else\n\t\tvalp = NULL;\n\n\tif (valp != NULL) {\n\t\tif (value != NULL)\n\t\t\tmemcpy(valp, value, len);\n\t\telse\n\t\t\t_copy_from_pages(valp, pages, 0, len);\n\t}\n\n\tentry->flags = flags;\n\tentry->xattr_value = valp;\n\tkref_init(&entry->ref);\n\tentry->xattr_name = namep;\n\tentry->xattr_size = len;\n\tentry->bucket = NULL;\n\tINIT_LIST_HEAD(&entry->lru);\n\tINIT_LIST_HEAD(&entry->dispose);\n\tINIT_HLIST_NODE(&entry->hnode);\n\n\treturn entry;\n}\n\nstatic void\nnfs4_xattr_free_entry(struct nfs4_xattr_entry *entry)\n{\n\tif (entry->flags & NFS4_XATTR_ENTRY_EXTVAL)\n\t\tkvfree(entry->xattr_value);\n\tkfree(entry);\n}\n\nstatic void\nnfs4_xattr_free_entry_cb(struct kref *kref)\n{\n\tstruct nfs4_xattr_entry *entry;\n\n\tentry = container_of(kref, struct nfs4_xattr_entry, ref);\n\n\tif (WARN_ON(!list_empty(&entry->lru)))\n\t\treturn;\n\n\tnfs4_xattr_free_entry(entry);\n}\n\nstatic void\nnfs4_xattr_free_cache_cb(struct kref *kref)\n{\n\tstruct nfs4_xattr_cache *cache;\n\tint i;\n\n\tcache = container_of(kref, struct nfs4_xattr_cache, ref);\n\n\tfor (i = 0; i < NFS4_XATTR_HASH_SIZE; i++) {\n\t\tif (WARN_ON(!hlist_empty(&cache->buckets[i].hlist)))\n\t\t\treturn;\n\t\tcache->buckets[i].draining = false;\n\t}\n\n\tcache->listxattr = NULL;\n\n\tkmem_cache_free(nfs4_xattr_cache_cachep, cache);\n\n}\n\nstatic struct nfs4_xattr_cache *\nnfs4_xattr_alloc_cache(void)\n{\n\tstruct nfs4_xattr_cache *cache;\n\n\tcache = kmem_cache_alloc(nfs4_xattr_cache_cachep, GFP_KERNEL);\n\tif (cache == NULL)\n\t\treturn NULL;\n\n\tkref_init(&cache->ref);\n\tatomic_long_set(&cache->nent, 0);\n\n\treturn cache;\n}\n\n \nstatic int\nnfs4_xattr_set_listcache(struct nfs4_xattr_cache *cache,\n\t\t\t struct nfs4_xattr_entry *new)\n{\n\tstruct nfs4_xattr_entry *old;\n\tint ret = 1;\n\n\tspin_lock(&cache->listxattr_lock);\n\n\told = cache->listxattr;\n\n\tif (old == ERR_PTR(-ESTALE)) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tcache->listxattr = new;\n\tif (new != NULL && new != ERR_PTR(-ESTALE))\n\t\tnfs4_xattr_entry_lru_add(new);\n\n\tif (old != NULL) {\n\t\tnfs4_xattr_entry_lru_del(old);\n\t\tkref_put(&old->ref, nfs4_xattr_free_entry_cb);\n\t}\nout:\n\tspin_unlock(&cache->listxattr_lock);\n\n\treturn ret;\n}\n\n \nstatic struct nfs4_xattr_cache *\nnfs4_xattr_cache_unlink(struct inode *inode)\n{\n\tstruct nfs_inode *nfsi;\n\tstruct nfs4_xattr_cache *oldcache;\n\n\tnfsi = NFS_I(inode);\n\n\toldcache = nfsi->xattr_cache;\n\tif (oldcache != NULL) {\n\t\tlist_lru_del(&nfs4_xattr_cache_lru, &oldcache->lru);\n\t\toldcache->inode = NULL;\n\t}\n\tnfsi->xattr_cache = NULL;\n\tnfsi->cache_validity &= ~NFS_INO_INVALID_XATTR;\n\n\treturn oldcache;\n\n}\n\n \nstatic void\nnfs4_xattr_discard_cache(struct nfs4_xattr_cache *cache)\n{\n\tunsigned int i;\n\tstruct nfs4_xattr_entry *entry;\n\tstruct nfs4_xattr_bucket *bucket;\n\tstruct hlist_node *n;\n\n\tnfs4_xattr_set_listcache(cache, ERR_PTR(-ESTALE));\n\n\tfor (i = 0; i < NFS4_XATTR_HASH_SIZE; i++) {\n\t\tbucket = &cache->buckets[i];\n\n\t\tspin_lock(&bucket->lock);\n\t\tbucket->draining = true;\n\t\thlist_for_each_entry_safe(entry, n, &bucket->hlist, hnode) {\n\t\t\tnfs4_xattr_entry_lru_del(entry);\n\t\t\thlist_del_init(&entry->hnode);\n\t\t\tkref_put(&entry->ref, nfs4_xattr_free_entry_cb);\n\t\t}\n\t\tspin_unlock(&bucket->lock);\n\t}\n\n\tatomic_long_set(&cache->nent, 0);\n\n\tkref_put(&cache->ref, nfs4_xattr_free_cache_cb);\n}\n\n \n\nstatic struct nfs4_xattr_cache *\nnfs4_xattr_get_cache(struct inode *inode, int add)\n{\n\tstruct nfs_inode *nfsi;\n\tstruct nfs4_xattr_cache *cache, *oldcache, *newcache;\n\n\tnfsi = NFS_I(inode);\n\n\tcache = oldcache = NULL;\n\n\tspin_lock(&inode->i_lock);\n\n\tif (nfsi->cache_validity & NFS_INO_INVALID_XATTR)\n\t\toldcache = nfs4_xattr_cache_unlink(inode);\n\telse\n\t\tcache = nfsi->xattr_cache;\n\n\tif (cache != NULL)\n\t\tkref_get(&cache->ref);\n\n\tspin_unlock(&inode->i_lock);\n\n\tif (add && cache == NULL) {\n\t\tnewcache = NULL;\n\n\t\tcache = nfs4_xattr_alloc_cache();\n\t\tif (cache == NULL)\n\t\t\tgoto out;\n\n\t\tspin_lock(&inode->i_lock);\n\t\tif (nfsi->cache_validity & NFS_INO_INVALID_XATTR) {\n\t\t\t \n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\tkref_put(&cache->ref, nfs4_xattr_free_cache_cb);\n\t\t\tcache = NULL;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tif (nfsi->xattr_cache != NULL) {\n\t\t\tnewcache = nfsi->xattr_cache;\n\t\t\tkref_get(&newcache->ref);\n\t\t} else {\n\t\t\tkref_get(&cache->ref);\n\t\t\tnfsi->xattr_cache = cache;\n\t\t\tcache->inode = inode;\n\t\t\tlist_lru_add(&nfs4_xattr_cache_lru, &cache->lru);\n\t\t}\n\n\t\tspin_unlock(&inode->i_lock);\n\n\t\t \n\t\tif (newcache != NULL) {\n\t\t\tkref_put(&cache->ref, nfs4_xattr_free_cache_cb);\n\t\t\tcache = newcache;\n\t\t}\n\t}\n\nout:\n\t \n\tif (oldcache != NULL)\n\t\tnfs4_xattr_discard_cache(oldcache);\n\n\treturn cache;\n}\n\nstatic inline struct nfs4_xattr_bucket *\nnfs4_xattr_hash_bucket(struct nfs4_xattr_cache *cache, const char *name)\n{\n\treturn &cache->buckets[jhash(name, strlen(name), 0) &\n\t    (ARRAY_SIZE(cache->buckets) - 1)];\n}\n\nstatic struct nfs4_xattr_entry *\nnfs4_xattr_get_entry(struct nfs4_xattr_bucket *bucket, const char *name)\n{\n\tstruct nfs4_xattr_entry *entry;\n\n\tentry = NULL;\n\n\thlist_for_each_entry(entry, &bucket->hlist, hnode) {\n\t\tif (!strcmp(entry->xattr_name, name))\n\t\t\tbreak;\n\t}\n\n\treturn entry;\n}\n\nstatic int\nnfs4_xattr_hash_add(struct nfs4_xattr_cache *cache,\n\t\t    struct nfs4_xattr_entry *entry)\n{\n\tstruct nfs4_xattr_bucket *bucket;\n\tstruct nfs4_xattr_entry *oldentry = NULL;\n\tint ret = 1;\n\n\tbucket = nfs4_xattr_hash_bucket(cache, entry->xattr_name);\n\tentry->bucket = bucket;\n\n\tspin_lock(&bucket->lock);\n\n\tif (bucket->draining) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\toldentry = nfs4_xattr_get_entry(bucket, entry->xattr_name);\n\tif (oldentry != NULL) {\n\t\thlist_del_init(&oldentry->hnode);\n\t\tnfs4_xattr_entry_lru_del(oldentry);\n\t} else {\n\t\tatomic_long_inc(&cache->nent);\n\t}\n\n\thlist_add_head(&entry->hnode, &bucket->hlist);\n\tnfs4_xattr_entry_lru_add(entry);\n\nout:\n\tspin_unlock(&bucket->lock);\n\n\tif (oldentry != NULL)\n\t\tkref_put(&oldentry->ref, nfs4_xattr_free_entry_cb);\n\n\treturn ret;\n}\n\nstatic void\nnfs4_xattr_hash_remove(struct nfs4_xattr_cache *cache, const char *name)\n{\n\tstruct nfs4_xattr_bucket *bucket;\n\tstruct nfs4_xattr_entry *entry;\n\n\tbucket = nfs4_xattr_hash_bucket(cache, name);\n\n\tspin_lock(&bucket->lock);\n\n\tentry = nfs4_xattr_get_entry(bucket, name);\n\tif (entry != NULL) {\n\t\thlist_del_init(&entry->hnode);\n\t\tnfs4_xattr_entry_lru_del(entry);\n\t\tatomic_long_dec(&cache->nent);\n\t}\n\n\tspin_unlock(&bucket->lock);\n\n\tif (entry != NULL)\n\t\tkref_put(&entry->ref, nfs4_xattr_free_entry_cb);\n}\n\nstatic struct nfs4_xattr_entry *\nnfs4_xattr_hash_find(struct nfs4_xattr_cache *cache, const char *name)\n{\n\tstruct nfs4_xattr_bucket *bucket;\n\tstruct nfs4_xattr_entry *entry;\n\n\tbucket = nfs4_xattr_hash_bucket(cache, name);\n\n\tspin_lock(&bucket->lock);\n\n\tentry = nfs4_xattr_get_entry(bucket, name);\n\tif (entry != NULL)\n\t\tkref_get(&entry->ref);\n\n\tspin_unlock(&bucket->lock);\n\n\treturn entry;\n}\n\n \nssize_t nfs4_xattr_cache_get(struct inode *inode, const char *name, char *buf,\n\t\t\t ssize_t buflen)\n{\n\tstruct nfs4_xattr_cache *cache;\n\tstruct nfs4_xattr_entry *entry;\n\tssize_t ret;\n\n\tcache = nfs4_xattr_get_cache(inode, 0);\n\tif (cache == NULL)\n\t\treturn -ENOENT;\n\n\tret = 0;\n\tentry = nfs4_xattr_hash_find(cache, name);\n\n\tif (entry != NULL) {\n\t\tdprintk(\"%s: cache hit '%s', len %lu\\n\", __func__,\n\t\t    entry->xattr_name, (unsigned long)entry->xattr_size);\n\t\tif (buflen == 0) {\n\t\t\t \n\t\t\tret = entry->xattr_size;\n\t\t} else if (buflen < entry->xattr_size)\n\t\t\tret = -ERANGE;\n\t\telse {\n\t\t\tmemcpy(buf, entry->xattr_value, entry->xattr_size);\n\t\t\tret = entry->xattr_size;\n\t\t}\n\t\tkref_put(&entry->ref, nfs4_xattr_free_entry_cb);\n\t} else {\n\t\tdprintk(\"%s: cache miss '%s'\\n\", __func__, name);\n\t\tret = -ENOENT;\n\t}\n\n\tkref_put(&cache->ref, nfs4_xattr_free_cache_cb);\n\n\treturn ret;\n}\n\n \nssize_t nfs4_xattr_cache_list(struct inode *inode, char *buf, ssize_t buflen)\n{\n\tstruct nfs4_xattr_cache *cache;\n\tstruct nfs4_xattr_entry *entry;\n\tssize_t ret;\n\n\tcache = nfs4_xattr_get_cache(inode, 0);\n\tif (cache == NULL)\n\t\treturn -ENOENT;\n\n\tspin_lock(&cache->listxattr_lock);\n\n\tentry = cache->listxattr;\n\n\tif (entry != NULL && entry != ERR_PTR(-ESTALE)) {\n\t\tif (buflen == 0) {\n\t\t\t \n\t\t\tret = entry->xattr_size;\n\t\t} else if (entry->xattr_size > buflen)\n\t\t\tret = -ERANGE;\n\t\telse {\n\t\t\tmemcpy(buf, entry->xattr_value, entry->xattr_size);\n\t\t\tret = entry->xattr_size;\n\t\t}\n\t} else {\n\t\tret = -ENOENT;\n\t}\n\n\tspin_unlock(&cache->listxattr_lock);\n\n\tkref_put(&cache->ref, nfs4_xattr_free_cache_cb);\n\n\treturn ret;\n}\n\n \nvoid nfs4_xattr_cache_add(struct inode *inode, const char *name,\n\t\t\t  const char *buf, struct page **pages, ssize_t buflen)\n{\n\tstruct nfs4_xattr_cache *cache;\n\tstruct nfs4_xattr_entry *entry;\n\n\tdprintk(\"%s: add '%s' len %lu\\n\", __func__,\n\t    name, (unsigned long)buflen);\n\n\tcache = nfs4_xattr_get_cache(inode, 1);\n\tif (cache == NULL)\n\t\treturn;\n\n\tentry = nfs4_xattr_alloc_entry(name, buf, pages, buflen);\n\tif (entry == NULL)\n\t\tgoto out;\n\n\t(void)nfs4_xattr_set_listcache(cache, NULL);\n\n\tif (!nfs4_xattr_hash_add(cache, entry))\n\t\tkref_put(&entry->ref, nfs4_xattr_free_entry_cb);\n\nout:\n\tkref_put(&cache->ref, nfs4_xattr_free_cache_cb);\n}\n\n\n \nvoid nfs4_xattr_cache_remove(struct inode *inode, const char *name)\n{\n\tstruct nfs4_xattr_cache *cache;\n\n\tdprintk(\"%s: remove '%s'\\n\", __func__, name);\n\n\tcache = nfs4_xattr_get_cache(inode, 0);\n\tif (cache == NULL)\n\t\treturn;\n\n\t(void)nfs4_xattr_set_listcache(cache, NULL);\n\tnfs4_xattr_hash_remove(cache, name);\n\n\tkref_put(&cache->ref, nfs4_xattr_free_cache_cb);\n}\n\n \nvoid nfs4_xattr_cache_set_list(struct inode *inode, const char *buf,\n\t\t\t       ssize_t buflen)\n{\n\tstruct nfs4_xattr_cache *cache;\n\tstruct nfs4_xattr_entry *entry;\n\n\tcache = nfs4_xattr_get_cache(inode, 1);\n\tif (cache == NULL)\n\t\treturn;\n\n\tentry = nfs4_xattr_alloc_entry(NULL, buf, NULL, buflen);\n\tif (entry == NULL)\n\t\tgoto out;\n\n\t \n\tentry->bucket = &cache->buckets[0];\n\n\tif (!nfs4_xattr_set_listcache(cache, entry))\n\t\tkref_put(&entry->ref, nfs4_xattr_free_entry_cb);\n\nout:\n\tkref_put(&cache->ref, nfs4_xattr_free_cache_cb);\n}\n\n \nvoid nfs4_xattr_cache_zap(struct inode *inode)\n{\n\tstruct nfs4_xattr_cache *oldcache;\n\n\tspin_lock(&inode->i_lock);\n\toldcache = nfs4_xattr_cache_unlink(inode);\n\tspin_unlock(&inode->i_lock);\n\n\tif (oldcache)\n\t\tnfs4_xattr_discard_cache(oldcache);\n}\n\n \n\nstatic unsigned long nfs4_xattr_cache_count(struct shrinker *shrink,\n\t\t\t\t\t    struct shrink_control *sc);\nstatic unsigned long nfs4_xattr_entry_count(struct shrinker *shrink,\n\t\t\t\t\t    struct shrink_control *sc);\nstatic unsigned long nfs4_xattr_cache_scan(struct shrinker *shrink,\n\t\t\t\t\t   struct shrink_control *sc);\nstatic unsigned long nfs4_xattr_entry_scan(struct shrinker *shrink,\n\t\t\t\t\t   struct shrink_control *sc);\n\nstatic struct shrinker nfs4_xattr_cache_shrinker = {\n\t.count_objects\t= nfs4_xattr_cache_count,\n\t.scan_objects\t= nfs4_xattr_cache_scan,\n\t.seeks\t\t= DEFAULT_SEEKS,\n\t.flags\t\t= SHRINKER_MEMCG_AWARE,\n};\n\nstatic struct shrinker nfs4_xattr_entry_shrinker = {\n\t.count_objects\t= nfs4_xattr_entry_count,\n\t.scan_objects\t= nfs4_xattr_entry_scan,\n\t.seeks\t\t= DEFAULT_SEEKS,\n\t.batch\t\t= 512,\n\t.flags\t\t= SHRINKER_MEMCG_AWARE,\n};\n\nstatic struct shrinker nfs4_xattr_large_entry_shrinker = {\n\t.count_objects\t= nfs4_xattr_entry_count,\n\t.scan_objects\t= nfs4_xattr_entry_scan,\n\t.seeks\t\t= 1,\n\t.batch\t\t= 512,\n\t.flags\t\t= SHRINKER_MEMCG_AWARE,\n};\n\nstatic enum lru_status\ncache_lru_isolate(struct list_head *item,\n\tstruct list_lru_one *lru, spinlock_t *lru_lock, void *arg)\n{\n\tstruct list_head *dispose = arg;\n\tstruct inode *inode;\n\tstruct nfs4_xattr_cache *cache = container_of(item,\n\t    struct nfs4_xattr_cache, lru);\n\n\tif (atomic_long_read(&cache->nent) > 1)\n\t\treturn LRU_SKIP;\n\n\t \n\tinode = cache->inode;\n\n\tif (!spin_trylock(&inode->i_lock))\n\t\treturn LRU_SKIP;\n\n\tkref_get(&cache->ref);\n\n\tcache->inode = NULL;\n\tNFS_I(inode)->xattr_cache = NULL;\n\tNFS_I(inode)->cache_validity &= ~NFS_INO_INVALID_XATTR;\n\tlist_lru_isolate(lru, &cache->lru);\n\n\tspin_unlock(&inode->i_lock);\n\n\tlist_add_tail(&cache->dispose, dispose);\n\treturn LRU_REMOVED;\n}\n\nstatic unsigned long\nnfs4_xattr_cache_scan(struct shrinker *shrink, struct shrink_control *sc)\n{\n\tLIST_HEAD(dispose);\n\tunsigned long freed;\n\tstruct nfs4_xattr_cache *cache;\n\n\tfreed = list_lru_shrink_walk(&nfs4_xattr_cache_lru, sc,\n\t    cache_lru_isolate, &dispose);\n\twhile (!list_empty(&dispose)) {\n\t\tcache = list_first_entry(&dispose, struct nfs4_xattr_cache,\n\t\t    dispose);\n\t\tlist_del_init(&cache->dispose);\n\t\tnfs4_xattr_discard_cache(cache);\n\t\tkref_put(&cache->ref, nfs4_xattr_free_cache_cb);\n\t}\n\n\treturn freed;\n}\n\n\nstatic unsigned long\nnfs4_xattr_cache_count(struct shrinker *shrink, struct shrink_control *sc)\n{\n\tunsigned long count;\n\n\tcount = list_lru_shrink_count(&nfs4_xattr_cache_lru, sc);\n\treturn vfs_pressure_ratio(count);\n}\n\nstatic enum lru_status\nentry_lru_isolate(struct list_head *item,\n\tstruct list_lru_one *lru, spinlock_t *lru_lock, void *arg)\n{\n\tstruct list_head *dispose = arg;\n\tstruct nfs4_xattr_bucket *bucket;\n\tstruct nfs4_xattr_cache *cache;\n\tstruct nfs4_xattr_entry *entry = container_of(item,\n\t    struct nfs4_xattr_entry, lru);\n\n\tbucket = entry->bucket;\n\tcache = bucket->cache;\n\n\t \n\tif (entry->xattr_name != NULL) {\n\t\t \n\t\tif (!spin_trylock(&bucket->lock))\n\t\t\treturn LRU_SKIP;\n\n\t\tkref_get(&entry->ref);\n\n\t\thlist_del_init(&entry->hnode);\n\t\tatomic_long_dec(&cache->nent);\n\t\tlist_lru_isolate(lru, &entry->lru);\n\n\t\tspin_unlock(&bucket->lock);\n\t} else {\n\t\t \n\t\tif (!spin_trylock(&cache->listxattr_lock))\n\t\t\treturn LRU_SKIP;\n\n\t\tkref_get(&entry->ref);\n\n\t\tcache->listxattr = NULL;\n\t\tlist_lru_isolate(lru, &entry->lru);\n\n\t\tspin_unlock(&cache->listxattr_lock);\n\t}\n\n\tlist_add_tail(&entry->dispose, dispose);\n\treturn LRU_REMOVED;\n}\n\nstatic unsigned long\nnfs4_xattr_entry_scan(struct shrinker *shrink, struct shrink_control *sc)\n{\n\tLIST_HEAD(dispose);\n\tunsigned long freed;\n\tstruct nfs4_xattr_entry *entry;\n\tstruct list_lru *lru;\n\n\tlru = (shrink == &nfs4_xattr_large_entry_shrinker) ?\n\t    &nfs4_xattr_large_entry_lru : &nfs4_xattr_entry_lru;\n\n\tfreed = list_lru_shrink_walk(lru, sc, entry_lru_isolate, &dispose);\n\n\twhile (!list_empty(&dispose)) {\n\t\tentry = list_first_entry(&dispose, struct nfs4_xattr_entry,\n\t\t    dispose);\n\t\tlist_del_init(&entry->dispose);\n\n\t\t \n\t\tkref_put(&entry->ref, nfs4_xattr_free_entry_cb);\n\t\tkref_put(&entry->ref, nfs4_xattr_free_entry_cb);\n\t}\n\n\treturn freed;\n}\n\nstatic unsigned long\nnfs4_xattr_entry_count(struct shrinker *shrink, struct shrink_control *sc)\n{\n\tunsigned long count;\n\tstruct list_lru *lru;\n\n\tlru = (shrink == &nfs4_xattr_large_entry_shrinker) ?\n\t    &nfs4_xattr_large_entry_lru : &nfs4_xattr_entry_lru;\n\n\tcount = list_lru_shrink_count(lru, sc);\n\treturn vfs_pressure_ratio(count);\n}\n\n\nstatic void nfs4_xattr_cache_init_once(void *p)\n{\n\tstruct nfs4_xattr_cache *cache = p;\n\n\tspin_lock_init(&cache->listxattr_lock);\n\tatomic_long_set(&cache->nent, 0);\n\tnfs4_xattr_hash_init(cache);\n\tcache->listxattr = NULL;\n\tINIT_LIST_HEAD(&cache->lru);\n\tINIT_LIST_HEAD(&cache->dispose);\n}\n\nstatic int nfs4_xattr_shrinker_init(struct shrinker *shrinker,\n\t\t\t\t    struct list_lru *lru, const char *name)\n{\n\tint ret = 0;\n\n\tret = register_shrinker(shrinker, name);\n\tif (ret)\n\t\treturn ret;\n\n\tret = list_lru_init_memcg(lru, shrinker);\n\tif (ret)\n\t\tunregister_shrinker(shrinker);\n\n\treturn ret;\n}\n\nstatic void nfs4_xattr_shrinker_destroy(struct shrinker *shrinker,\n\t\t\t\t\tstruct list_lru *lru)\n{\n\tunregister_shrinker(shrinker);\n\tlist_lru_destroy(lru);\n}\n\nint __init nfs4_xattr_cache_init(void)\n{\n\tint ret = 0;\n\n\tnfs4_xattr_cache_cachep = kmem_cache_create(\"nfs4_xattr_cache_cache\",\n\t    sizeof(struct nfs4_xattr_cache), 0,\n\t    (SLAB_RECLAIM_ACCOUNT|SLAB_MEM_SPREAD),\n\t    nfs4_xattr_cache_init_once);\n\tif (nfs4_xattr_cache_cachep == NULL)\n\t\treturn -ENOMEM;\n\n\tret = nfs4_xattr_shrinker_init(&nfs4_xattr_cache_shrinker,\n\t\t\t\t       &nfs4_xattr_cache_lru,\n\t\t\t\t       \"nfs-xattr_cache\");\n\tif (ret)\n\t\tgoto out1;\n\n\tret = nfs4_xattr_shrinker_init(&nfs4_xattr_entry_shrinker,\n\t\t\t\t       &nfs4_xattr_entry_lru,\n\t\t\t\t       \"nfs-xattr_entry\");\n\tif (ret)\n\t\tgoto out2;\n\n\tret = nfs4_xattr_shrinker_init(&nfs4_xattr_large_entry_shrinker,\n\t\t\t\t       &nfs4_xattr_large_entry_lru,\n\t\t\t\t       \"nfs-xattr_large_entry\");\n\tif (!ret)\n\t\treturn 0;\n\n\tnfs4_xattr_shrinker_destroy(&nfs4_xattr_entry_shrinker,\n\t\t\t\t    &nfs4_xattr_entry_lru);\nout2:\n\tnfs4_xattr_shrinker_destroy(&nfs4_xattr_cache_shrinker,\n\t\t\t\t    &nfs4_xattr_cache_lru);\nout1:\n\tkmem_cache_destroy(nfs4_xattr_cache_cachep);\n\n\treturn ret;\n}\n\nvoid nfs4_xattr_cache_exit(void)\n{\n\tnfs4_xattr_shrinker_destroy(&nfs4_xattr_large_entry_shrinker,\n\t\t\t\t    &nfs4_xattr_large_entry_lru);\n\tnfs4_xattr_shrinker_destroy(&nfs4_xattr_entry_shrinker,\n\t\t\t\t    &nfs4_xattr_entry_lru);\n\tnfs4_xattr_shrinker_destroy(&nfs4_xattr_cache_shrinker,\n\t\t\t\t    &nfs4_xattr_cache_lru);\n\tkmem_cache_destroy(nfs4_xattr_cache_cachep);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}