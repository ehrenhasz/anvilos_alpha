{
  "module_name": "blocklayout.c",
  "hash_id": "1284855f7d4477b9618911caba244fbfaf8b74285354f71912dc96f488e39f4c",
  "original_prompt": "Ingested from linux-6.6.14/fs/nfs/blocklayout/blocklayout.c",
  "human_readable_source": " \n\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/bio.h>\t\t \n#include <linux/prefetch.h>\n#include <linux/pagevec.h>\n\n#include \"../pnfs.h\"\n#include \"../nfs4session.h\"\n#include \"../internal.h\"\n#include \"blocklayout.h\"\n\n#define NFSDBG_FACILITY\tNFSDBG_PNFS_LD\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Andy Adamson <andros@citi.umich.edu>\");\nMODULE_DESCRIPTION(\"The NFSv4.1 pNFS Block layout driver\");\n\nstatic bool is_hole(struct pnfs_block_extent *be)\n{\n\tswitch (be->be_state) {\n\tcase PNFS_BLOCK_NONE_DATA:\n\t\treturn true;\n\tcase PNFS_BLOCK_INVALID_DATA:\n\t\treturn be->be_tag ? false : true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nstruct parallel_io {\n\tstruct kref refcnt;\n\tvoid (*pnfs_callback) (void *data);\n\tvoid *data;\n};\n\nstatic inline struct parallel_io *alloc_parallel(void *data)\n{\n\tstruct parallel_io *rv;\n\n\trv  = kmalloc(sizeof(*rv), GFP_NOFS);\n\tif (rv) {\n\t\trv->data = data;\n\t\tkref_init(&rv->refcnt);\n\t}\n\treturn rv;\n}\n\nstatic inline void get_parallel(struct parallel_io *p)\n{\n\tkref_get(&p->refcnt);\n}\n\nstatic void destroy_parallel(struct kref *kref)\n{\n\tstruct parallel_io *p = container_of(kref, struct parallel_io, refcnt);\n\n\tdprintk(\"%s enter\\n\", __func__);\n\tp->pnfs_callback(p->data);\n\tkfree(p);\n}\n\nstatic inline void put_parallel(struct parallel_io *p)\n{\n\tkref_put(&p->refcnt, destroy_parallel);\n}\n\nstatic struct bio *\nbl_submit_bio(struct bio *bio)\n{\n\tif (bio) {\n\t\tget_parallel(bio->bi_private);\n\t\tdprintk(\"%s submitting %s bio %u@%llu\\n\", __func__,\n\t\t\tbio_op(bio) == READ ? \"read\" : \"write\",\n\t\t\tbio->bi_iter.bi_size,\n\t\t\t(unsigned long long)bio->bi_iter.bi_sector);\n\t\tsubmit_bio(bio);\n\t}\n\treturn NULL;\n}\n\nstatic bool offset_in_map(u64 offset, struct pnfs_block_dev_map *map)\n{\n\treturn offset >= map->start && offset < map->start + map->len;\n}\n\nstatic struct bio *\ndo_add_page_to_bio(struct bio *bio, int npg, enum req_op op, sector_t isect,\n\t\tstruct page *page, struct pnfs_block_dev_map *map,\n\t\tstruct pnfs_block_extent *be, bio_end_io_t end_io,\n\t\tstruct parallel_io *par, unsigned int offset, int *len)\n{\n\tstruct pnfs_block_dev *dev =\n\t\tcontainer_of(be->be_device, struct pnfs_block_dev, node);\n\tu64 disk_addr, end;\n\n\tdprintk(\"%s: npg %d rw %d isect %llu offset %u len %d\\n\", __func__,\n\t\tnpg, (__force u32)op, (unsigned long long)isect, offset, *len);\n\n\t \n\tisect += be->be_v_offset;\n\tisect -= be->be_f_offset;\n\n\t \n\tdisk_addr = (u64)isect << SECTOR_SHIFT;\n\tif (!offset_in_map(disk_addr, map)) {\n\t\tif (!dev->map(dev, disk_addr, map) || !offset_in_map(disk_addr, map))\n\t\t\treturn ERR_PTR(-EIO);\n\t\tbio = bl_submit_bio(bio);\n\t}\n\tdisk_addr += map->disk_offset;\n\tdisk_addr -= map->start;\n\n\t \n\tend = disk_addr + *len;\n\tif (end >= map->start + map->len)\n\t\t*len = map->start + map->len - disk_addr;\n\nretry:\n\tif (!bio) {\n\t\tbio = bio_alloc(map->bdev, bio_max_segs(npg), op, GFP_NOIO);\n\t\tbio->bi_iter.bi_sector = disk_addr >> SECTOR_SHIFT;\n\t\tbio->bi_end_io = end_io;\n\t\tbio->bi_private = par;\n\t}\n\tif (bio_add_page(bio, page, *len, offset) < *len) {\n\t\tbio = bl_submit_bio(bio);\n\t\tgoto retry;\n\t}\n\treturn bio;\n}\n\nstatic void bl_mark_devices_unavailable(struct nfs_pgio_header *header, bool rw)\n{\n\tstruct pnfs_block_layout *bl = BLK_LSEG2EXT(header->lseg);\n\tsize_t bytes_left = header->args.count;\n\tsector_t isect, extent_length = 0;\n\tstruct pnfs_block_extent be;\n\n\tisect = header->args.offset >> SECTOR_SHIFT;\n\tbytes_left += header->args.offset - (isect << SECTOR_SHIFT);\n\n\twhile (bytes_left > 0) {\n\t\tif (!ext_tree_lookup(bl, isect, &be, rw))\n\t\t\t\treturn;\n\t\textent_length = be.be_length - (isect - be.be_f_offset);\n\t\tnfs4_mark_deviceid_unavailable(be.be_device);\n\t\tisect += extent_length;\n\t\tif (bytes_left > extent_length << SECTOR_SHIFT)\n\t\t\tbytes_left -= extent_length << SECTOR_SHIFT;\n\t\telse\n\t\t\tbytes_left = 0;\n\t}\n}\n\nstatic void bl_end_io_read(struct bio *bio)\n{\n\tstruct parallel_io *par = bio->bi_private;\n\n\tif (bio->bi_status) {\n\t\tstruct nfs_pgio_header *header = par->data;\n\n\t\tif (!header->pnfs_error)\n\t\t\theader->pnfs_error = -EIO;\n\t\tpnfs_set_lo_fail(header->lseg);\n\t\tbl_mark_devices_unavailable(header, false);\n\t}\n\n\tbio_put(bio);\n\tput_parallel(par);\n}\n\nstatic void bl_read_cleanup(struct work_struct *work)\n{\n\tstruct rpc_task *task;\n\tstruct nfs_pgio_header *hdr;\n\tdprintk(\"%s enter\\n\", __func__);\n\ttask = container_of(work, struct rpc_task, u.tk_work);\n\thdr = container_of(task, struct nfs_pgio_header, task);\n\tpnfs_ld_read_done(hdr);\n}\n\nstatic void\nbl_end_par_io_read(void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\thdr->task.tk_status = hdr->pnfs_error;\n\tINIT_WORK(&hdr->task.u.tk_work, bl_read_cleanup);\n\tschedule_work(&hdr->task.u.tk_work);\n}\n\nstatic enum pnfs_try_status\nbl_read_pagelist(struct nfs_pgio_header *header)\n{\n\tstruct pnfs_block_layout *bl = BLK_LSEG2EXT(header->lseg);\n\tstruct pnfs_block_dev_map map = { .start = NFS4_MAX_UINT64 };\n\tstruct bio *bio = NULL;\n\tstruct pnfs_block_extent be;\n\tsector_t isect, extent_length = 0;\n\tstruct parallel_io *par;\n\tloff_t f_offset = header->args.offset;\n\tsize_t bytes_left = header->args.count;\n\tunsigned int pg_offset = header->args.pgbase, pg_len;\n\tstruct page **pages = header->args.pages;\n\tint pg_index = header->args.pgbase >> PAGE_SHIFT;\n\tconst bool is_dio = (header->dreq != NULL);\n\tstruct blk_plug plug;\n\tint i;\n\n\tdprintk(\"%s enter nr_pages %u offset %lld count %u\\n\", __func__,\n\t\theader->page_array.npages, f_offset,\n\t\t(unsigned int)header->args.count);\n\n\tpar = alloc_parallel(header);\n\tif (!par)\n\t\treturn PNFS_NOT_ATTEMPTED;\n\tpar->pnfs_callback = bl_end_par_io_read;\n\n\tblk_start_plug(&plug);\n\n\tisect = (sector_t) (f_offset >> SECTOR_SHIFT);\n\t \n\tfor (i = pg_index; i < header->page_array.npages; i++) {\n\t\tif (extent_length <= 0) {\n\t\t\t \n\t\t\tbio = bl_submit_bio(bio);\n\n\t\t\t \n\t\t\tif (!ext_tree_lookup(bl, isect, &be, false)) {\n\t\t\t\theader->pnfs_error = -EIO;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\textent_length = be.be_length - (isect - be.be_f_offset);\n\t\t}\n\n\t\tif (is_dio) {\n\t\t\tif (pg_offset + bytes_left > PAGE_SIZE)\n\t\t\t\tpg_len = PAGE_SIZE - pg_offset;\n\t\t\telse\n\t\t\t\tpg_len = bytes_left;\n\t\t} else {\n\t\t\tBUG_ON(pg_offset != 0);\n\t\t\tpg_len = PAGE_SIZE;\n\t\t}\n\n\t\tif (is_hole(&be)) {\n\t\t\tbio = bl_submit_bio(bio);\n\t\t\t \n\t\t\tdprintk(\"%s Zeroing page for hole\\n\", __func__);\n\t\t\tzero_user_segment(pages[i], pg_offset, pg_len);\n\n\t\t\t \n\t\t\tmap.start = NFS4_MAX_UINT64;\n\t\t} else {\n\t\t\tbio = do_add_page_to_bio(bio,\n\t\t\t\t\t\t header->page_array.npages - i,\n\t\t\t\t\t\t REQ_OP_READ,\n\t\t\t\t\t\t isect, pages[i], &map, &be,\n\t\t\t\t\t\t bl_end_io_read, par,\n\t\t\t\t\t\t pg_offset, &pg_len);\n\t\t\tif (IS_ERR(bio)) {\n\t\t\t\theader->pnfs_error = PTR_ERR(bio);\n\t\t\t\tbio = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tisect += (pg_len >> SECTOR_SHIFT);\n\t\textent_length -= (pg_len >> SECTOR_SHIFT);\n\t\tf_offset += pg_len;\n\t\tbytes_left -= pg_len;\n\t\tpg_offset = 0;\n\t}\n\tif ((isect << SECTOR_SHIFT) >= header->inode->i_size) {\n\t\theader->res.eof = 1;\n\t\theader->res.count = header->inode->i_size - header->args.offset;\n\t} else {\n\t\theader->res.count = (isect << SECTOR_SHIFT) - header->args.offset;\n\t}\nout:\n\tbl_submit_bio(bio);\n\tblk_finish_plug(&plug);\n\tput_parallel(par);\n\treturn PNFS_ATTEMPTED;\n}\n\nstatic void bl_end_io_write(struct bio *bio)\n{\n\tstruct parallel_io *par = bio->bi_private;\n\tstruct nfs_pgio_header *header = par->data;\n\n\tif (bio->bi_status) {\n\t\tif (!header->pnfs_error)\n\t\t\theader->pnfs_error = -EIO;\n\t\tpnfs_set_lo_fail(header->lseg);\n\t\tbl_mark_devices_unavailable(header, true);\n\t}\n\tbio_put(bio);\n\tput_parallel(par);\n}\n\n \nstatic void bl_write_cleanup(struct work_struct *work)\n{\n\tstruct rpc_task *task = container_of(work, struct rpc_task, u.tk_work);\n\tstruct nfs_pgio_header *hdr =\n\t\t\tcontainer_of(task, struct nfs_pgio_header, task);\n\n\tdprintk(\"%s enter\\n\", __func__);\n\n\tif (likely(!hdr->pnfs_error)) {\n\t\tstruct pnfs_block_layout *bl = BLK_LSEG2EXT(hdr->lseg);\n\t\tu64 start = hdr->args.offset & (loff_t)PAGE_MASK;\n\t\tu64 end = (hdr->args.offset + hdr->args.count +\n\t\t\tPAGE_SIZE - 1) & (loff_t)PAGE_MASK;\n\t\tu64 lwb = hdr->args.offset + hdr->args.count;\n\n\t\text_tree_mark_written(bl, start >> SECTOR_SHIFT,\n\t\t\t\t\t(end - start) >> SECTOR_SHIFT, lwb);\n\t}\n\n\tpnfs_ld_write_done(hdr);\n}\n\n \nstatic void bl_end_par_io_write(void *data)\n{\n\tstruct nfs_pgio_header *hdr = data;\n\n\thdr->task.tk_status = hdr->pnfs_error;\n\thdr->verf.committed = NFS_FILE_SYNC;\n\tINIT_WORK(&hdr->task.u.tk_work, bl_write_cleanup);\n\tschedule_work(&hdr->task.u.tk_work);\n}\n\nstatic enum pnfs_try_status\nbl_write_pagelist(struct nfs_pgio_header *header, int sync)\n{\n\tstruct pnfs_block_layout *bl = BLK_LSEG2EXT(header->lseg);\n\tstruct pnfs_block_dev_map map = { .start = NFS4_MAX_UINT64 };\n\tstruct bio *bio = NULL;\n\tstruct pnfs_block_extent be;\n\tsector_t isect, extent_length = 0;\n\tstruct parallel_io *par = NULL;\n\tloff_t offset = header->args.offset;\n\tsize_t count = header->args.count;\n\tstruct page **pages = header->args.pages;\n\tint pg_index = header->args.pgbase >> PAGE_SHIFT;\n\tunsigned int pg_len;\n\tstruct blk_plug plug;\n\tint i;\n\n\tdprintk(\"%s enter, %zu@%lld\\n\", __func__, count, offset);\n\n\t \n\tpar = alloc_parallel(header);\n\tif (!par)\n\t\treturn PNFS_NOT_ATTEMPTED;\n\tpar->pnfs_callback = bl_end_par_io_write;\n\n\tblk_start_plug(&plug);\n\n\t \n\toffset = offset & (loff_t)PAGE_MASK;\n\tisect = offset >> SECTOR_SHIFT;\n\n\tfor (i = pg_index; i < header->page_array.npages; i++) {\n\t\tif (extent_length <= 0) {\n\t\t\t \n\t\t\tbio = bl_submit_bio(bio);\n\t\t\t \n\t\t\tif (!ext_tree_lookup(bl, isect, &be, true)) {\n\t\t\t\theader->pnfs_error = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\textent_length = be.be_length - (isect - be.be_f_offset);\n\t\t}\n\n\t\tpg_len = PAGE_SIZE;\n\t\tbio = do_add_page_to_bio(bio, header->page_array.npages - i,\n\t\t\t\t\t REQ_OP_WRITE, isect, pages[i], &map,\n\t\t\t\t\t &be, bl_end_io_write, par, 0, &pg_len);\n\t\tif (IS_ERR(bio)) {\n\t\t\theader->pnfs_error = PTR_ERR(bio);\n\t\t\tbio = NULL;\n\t\t\tgoto out;\n\t\t}\n\n\t\toffset += pg_len;\n\t\tcount -= pg_len;\n\t\tisect += (pg_len >> SECTOR_SHIFT);\n\t\textent_length -= (pg_len >> SECTOR_SHIFT);\n\t}\n\n\theader->res.count = header->args.count;\nout:\n\tbl_submit_bio(bio);\n\tblk_finish_plug(&plug);\n\tput_parallel(par);\n\treturn PNFS_ATTEMPTED;\n}\n\nstatic void bl_free_layout_hdr(struct pnfs_layout_hdr *lo)\n{\n\tstruct pnfs_block_layout *bl = BLK_LO2EXT(lo);\n\tint err;\n\n\tdprintk(\"%s enter\\n\", __func__);\n\n\terr = ext_tree_remove(bl, true, 0, LLONG_MAX);\n\tWARN_ON(err);\n\n\tkfree_rcu(bl, bl_layout.plh_rcu);\n}\n\nstatic struct pnfs_layout_hdr *__bl_alloc_layout_hdr(struct inode *inode,\n\t\tgfp_t gfp_flags, bool is_scsi_layout)\n{\n\tstruct pnfs_block_layout *bl;\n\n\tdprintk(\"%s enter\\n\", __func__);\n\tbl = kzalloc(sizeof(*bl), gfp_flags);\n\tif (!bl)\n\t\treturn NULL;\n\n\tbl->bl_ext_rw = RB_ROOT;\n\tbl->bl_ext_ro = RB_ROOT;\n\tspin_lock_init(&bl->bl_ext_lock);\n\n\tbl->bl_scsi_layout = is_scsi_layout;\n\treturn &bl->bl_layout;\n}\n\nstatic struct pnfs_layout_hdr *bl_alloc_layout_hdr(struct inode *inode,\n\t\t\t\t\t\t   gfp_t gfp_flags)\n{\n\treturn __bl_alloc_layout_hdr(inode, gfp_flags, false);\n}\n\nstatic struct pnfs_layout_hdr *sl_alloc_layout_hdr(struct inode *inode,\n\t\t\t\t\t\t   gfp_t gfp_flags)\n{\n\treturn __bl_alloc_layout_hdr(inode, gfp_flags, true);\n}\n\nstatic void bl_free_lseg(struct pnfs_layout_segment *lseg)\n{\n\tdprintk(\"%s enter\\n\", __func__);\n\tkfree(lseg);\n}\n\n \nstruct layout_verification {\n\tu32 mode;\t \n\tu64 start;\t \n\tu64 inval;\t \n\tu64 cowread;\t \n};\n\n \nstatic int verify_extent(struct pnfs_block_extent *be,\n\t\t\t struct layout_verification *lv)\n{\n\tif (lv->mode == IOMODE_READ) {\n\t\tif (be->be_state == PNFS_BLOCK_READWRITE_DATA ||\n\t\t    be->be_state == PNFS_BLOCK_INVALID_DATA)\n\t\t\treturn -EIO;\n\t\tif (be->be_f_offset != lv->start)\n\t\t\treturn -EIO;\n\t\tlv->start += be->be_length;\n\t\treturn 0;\n\t}\n\t \n\tif (be->be_state == PNFS_BLOCK_READWRITE_DATA) {\n\t\tif (be->be_f_offset != lv->start)\n\t\t\treturn -EIO;\n\t\tif (lv->cowread > lv->start)\n\t\t\treturn -EIO;\n\t\tlv->start += be->be_length;\n\t\tlv->inval = lv->start;\n\t\treturn 0;\n\t} else if (be->be_state == PNFS_BLOCK_INVALID_DATA) {\n\t\tif (be->be_f_offset != lv->start)\n\t\t\treturn -EIO;\n\t\tlv->start += be->be_length;\n\t\treturn 0;\n\t} else if (be->be_state == PNFS_BLOCK_READ_DATA) {\n\t\tif (be->be_f_offset > lv->start)\n\t\t\treturn -EIO;\n\t\tif (be->be_f_offset < lv->inval)\n\t\t\treturn -EIO;\n\t\tif (be->be_f_offset < lv->cowread)\n\t\t\treturn -EIO;\n\t\t \n\t\tlv->inval = lv->inval + be->be_length;\n\t\tlv->cowread = be->be_f_offset + be->be_length;\n\t\treturn 0;\n\t} else\n\t\treturn -EIO;\n}\n\nstatic int decode_sector_number(__be32 **rp, sector_t *sp)\n{\n\tuint64_t s;\n\n\t*rp = xdr_decode_hyper(*rp, &s);\n\tif (s & 0x1ff) {\n\t\tprintk(KERN_WARNING \"NFS: %s: sector not aligned\\n\", __func__);\n\t\treturn -1;\n\t}\n\t*sp = s >> SECTOR_SHIFT;\n\treturn 0;\n}\n\nstatic struct nfs4_deviceid_node *\nbl_find_get_deviceid(struct nfs_server *server,\n\t\tconst struct nfs4_deviceid *id, const struct cred *cred,\n\t\tgfp_t gfp_mask)\n{\n\tstruct nfs4_deviceid_node *node;\n\tunsigned long start, end;\n\nretry:\n\tnode = nfs4_find_get_deviceid(server, id, cred, gfp_mask);\n\tif (!node)\n\t\treturn ERR_PTR(-ENODEV);\n\n\tif (test_bit(NFS_DEVICEID_UNAVAILABLE, &node->flags) == 0)\n\t\treturn node;\n\n\tend = jiffies;\n\tstart = end - PNFS_DEVICE_RETRY_TIMEOUT;\n\tif (!time_in_range(node->timestamp_unavailable, start, end)) {\n\t\tnfs4_delete_deviceid(node->ld, node->nfs_client, id);\n\t\tgoto retry;\n\t}\n\n\tnfs4_put_deviceid_node(node);\n\treturn ERR_PTR(-ENODEV);\n}\n\nstatic int\nbl_alloc_extent(struct xdr_stream *xdr, struct pnfs_layout_hdr *lo,\n\t\tstruct layout_verification *lv, struct list_head *extents,\n\t\tgfp_t gfp_mask)\n{\n\tstruct pnfs_block_extent *be;\n\tstruct nfs4_deviceid id;\n\tint error;\n\t__be32 *p;\n\n\tp = xdr_inline_decode(xdr, 28 + NFS4_DEVICEID4_SIZE);\n\tif (!p)\n\t\treturn -EIO;\n\n\tbe = kzalloc(sizeof(*be), GFP_NOFS);\n\tif (!be)\n\t\treturn -ENOMEM;\n\n\tmemcpy(&id, p, NFS4_DEVICEID4_SIZE);\n\tp += XDR_QUADLEN(NFS4_DEVICEID4_SIZE);\n\n\tbe->be_device = bl_find_get_deviceid(NFS_SERVER(lo->plh_inode), &id,\n\t\t\t\t\t\tlo->plh_lc_cred, gfp_mask);\n\tif (IS_ERR(be->be_device)) {\n\t\terror = PTR_ERR(be->be_device);\n\t\tgoto out_free_be;\n\t}\n\n\t \n\terror = -EIO;\n\tif (decode_sector_number(&p, &be->be_f_offset) < 0)\n\t\tgoto out_put_deviceid;\n\tif (decode_sector_number(&p, &be->be_length) < 0)\n\t\tgoto out_put_deviceid;\n\tif (decode_sector_number(&p, &be->be_v_offset) < 0)\n\t\tgoto out_put_deviceid;\n\tbe->be_state = be32_to_cpup(p++);\n\n\terror = verify_extent(be, lv);\n\tif (error) {\n\t\tdprintk(\"%s: extent verification failed\\n\", __func__);\n\t\tgoto out_put_deviceid;\n\t}\n\n\tlist_add_tail(&be->be_list, extents);\n\treturn 0;\n\nout_put_deviceid:\n\tnfs4_put_deviceid_node(be->be_device);\nout_free_be:\n\tkfree(be);\n\treturn error;\n}\n\nstatic struct pnfs_layout_segment *\nbl_alloc_lseg(struct pnfs_layout_hdr *lo, struct nfs4_layoutget_res *lgr,\n\t\tgfp_t gfp_mask)\n{\n\tstruct layout_verification lv = {\n\t\t.mode = lgr->range.iomode,\n\t\t.start = lgr->range.offset >> SECTOR_SHIFT,\n\t\t.inval = lgr->range.offset >> SECTOR_SHIFT,\n\t\t.cowread = lgr->range.offset >> SECTOR_SHIFT,\n\t};\n\tstruct pnfs_block_layout *bl = BLK_LO2EXT(lo);\n\tstruct pnfs_layout_segment *lseg;\n\tstruct xdr_buf buf;\n\tstruct xdr_stream xdr;\n\tstruct page *scratch;\n\tint status, i;\n\tuint32_t count;\n\t__be32 *p;\n\tLIST_HEAD(extents);\n\n\tdprintk(\"---> %s\\n\", __func__);\n\n\tlseg = kzalloc(sizeof(*lseg), gfp_mask);\n\tif (!lseg)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tstatus = -ENOMEM;\n\tscratch = alloc_page(gfp_mask);\n\tif (!scratch)\n\t\tgoto out;\n\n\txdr_init_decode_pages(&xdr, &buf,\n\t\t\tlgr->layoutp->pages, lgr->layoutp->len);\n\txdr_set_scratch_page(&xdr, scratch);\n\n\tstatus = -EIO;\n\tp = xdr_inline_decode(&xdr, 4);\n\tif (unlikely(!p))\n\t\tgoto out_free_scratch;\n\n\tcount = be32_to_cpup(p++);\n\tdprintk(\"%s: number of extents %d\\n\", __func__, count);\n\n\t \n\tfor (i = 0; i < count; i++) {\n\t\tstatus = bl_alloc_extent(&xdr, lo, &lv, &extents, gfp_mask);\n\t\tif (status)\n\t\t\tgoto process_extents;\n\t}\n\n\tif (lgr->range.offset + lgr->range.length !=\n\t\t\tlv.start << SECTOR_SHIFT) {\n\t\tdprintk(\"%s Final length mismatch\\n\", __func__);\n\t\tstatus = -EIO;\n\t\tgoto process_extents;\n\t}\n\n\tif (lv.start < lv.cowread) {\n\t\tdprintk(\"%s Final uncovered COW extent\\n\", __func__);\n\t\tstatus = -EIO;\n\t}\n\nprocess_extents:\n\twhile (!list_empty(&extents)) {\n\t\tstruct pnfs_block_extent *be =\n\t\t\tlist_first_entry(&extents, struct pnfs_block_extent,\n\t\t\t\t\t be_list);\n\t\tlist_del(&be->be_list);\n\n\t\tif (!status)\n\t\t\tstatus = ext_tree_insert(bl, be);\n\n\t\tif (status) {\n\t\t\tnfs4_put_deviceid_node(be->be_device);\n\t\t\tkfree(be);\n\t\t}\n\t}\n\nout_free_scratch:\n\t__free_page(scratch);\nout:\n\tdprintk(\"%s returns %d\\n\", __func__, status);\n\tswitch (status) {\n\tcase -ENODEV:\n\t\t \n\t\tset_bit(NFS_LSEG_UNAVAILABLE, &lseg->pls_flags);\n\t\tfallthrough;\n\tcase 0:\n\t\treturn lseg;\n\tdefault:\n\t\tkfree(lseg);\n\t\treturn ERR_PTR(status);\n\t}\n}\n\nstatic void\nbl_return_range(struct pnfs_layout_hdr *lo,\n\t\tstruct pnfs_layout_range *range)\n{\n\tstruct pnfs_block_layout *bl = BLK_LO2EXT(lo);\n\tsector_t offset = range->offset >> SECTOR_SHIFT, end;\n\n\tif (range->offset % 8) {\n\t\tdprintk(\"%s: offset %lld not block size aligned\\n\",\n\t\t\t__func__, range->offset);\n\t\treturn;\n\t}\n\n\tif (range->length != NFS4_MAX_UINT64) {\n\t\tif (range->length % 8) {\n\t\t\tdprintk(\"%s: length %lld not block size aligned\\n\",\n\t\t\t\t__func__, range->length);\n\t\t\treturn;\n\t\t}\n\n\t\tend = offset + (range->length >> SECTOR_SHIFT);\n\t} else {\n\t\tend = round_down(NFS4_MAX_UINT64, PAGE_SIZE);\n\t}\n\n\text_tree_remove(bl, range->iomode & IOMODE_RW, offset, end);\n}\n\nstatic int\nbl_prepare_layoutcommit(struct nfs4_layoutcommit_args *arg)\n{\n\treturn ext_tree_prepare_commit(arg);\n}\n\nstatic void\nbl_cleanup_layoutcommit(struct nfs4_layoutcommit_data *lcdata)\n{\n\text_tree_mark_committed(&lcdata->args, lcdata->res.status);\n}\n\nstatic int\nbl_set_layoutdriver(struct nfs_server *server, const struct nfs_fh *fh)\n{\n\tdprintk(\"%s enter\\n\", __func__);\n\n\tif (server->pnfs_blksize == 0) {\n\t\tdprintk(\"%s Server did not return blksize\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\tif (server->pnfs_blksize > PAGE_SIZE) {\n\t\tprintk(KERN_ERR \"%s: pNFS blksize %d not supported.\\n\",\n\t\t\t__func__, server->pnfs_blksize);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic bool\nis_aligned_req(struct nfs_pageio_descriptor *pgio,\n\t\tstruct nfs_page *req, unsigned int alignment, bool is_write)\n{\n\t \n\tif (pgio->pg_dreq == NULL)\n\t\treturn true;\n\n\tif (!IS_ALIGNED(req->wb_offset, alignment))\n\t\treturn false;\n\n\tif (IS_ALIGNED(req->wb_bytes, alignment))\n\t\treturn true;\n\n\tif (is_write &&\n\t    (req_offset(req) + req->wb_bytes == i_size_read(pgio->pg_inode))) {\n\t\t \n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void\nbl_pg_init_read(struct nfs_pageio_descriptor *pgio, struct nfs_page *req)\n{\n\tif (!is_aligned_req(pgio, req, SECTOR_SIZE, false)) {\n\t\tnfs_pageio_reset_read_mds(pgio);\n\t\treturn;\n\t}\n\n\tpnfs_generic_pg_init_read(pgio, req);\n\n\tif (pgio->pg_lseg &&\n\t\ttest_bit(NFS_LSEG_UNAVAILABLE, &pgio->pg_lseg->pls_flags)) {\n\t\tpnfs_error_mark_layout_for_return(pgio->pg_inode, pgio->pg_lseg);\n\t\tpnfs_set_lo_fail(pgio->pg_lseg);\n\t\tnfs_pageio_reset_read_mds(pgio);\n\t}\n}\n\n \nstatic size_t\nbl_pg_test_read(struct nfs_pageio_descriptor *pgio, struct nfs_page *prev,\n\t\tstruct nfs_page *req)\n{\n\tif (!is_aligned_req(pgio, req, SECTOR_SIZE, false))\n\t\treturn 0;\n\treturn pnfs_generic_pg_test(pgio, prev, req);\n}\n\n \nstatic u64 pnfs_num_cont_bytes(struct inode *inode, pgoff_t idx)\n{\n\tstruct address_space *mapping = inode->i_mapping;\n\tpgoff_t end;\n\n\t \n\tend = DIV_ROUND_UP(i_size_read(inode), PAGE_SIZE);\n\tif (end != inode->i_mapping->nrpages) {\n\t\trcu_read_lock();\n\t\tend = page_cache_next_miss(mapping, idx + 1, ULONG_MAX);\n\t\trcu_read_unlock();\n\t}\n\n\tif (!end)\n\t\treturn i_size_read(inode) - (idx << PAGE_SHIFT);\n\telse\n\t\treturn (end - idx) << PAGE_SHIFT;\n}\n\nstatic void\nbl_pg_init_write(struct nfs_pageio_descriptor *pgio, struct nfs_page *req)\n{\n\tu64 wb_size;\n\n\tif (!is_aligned_req(pgio, req, PAGE_SIZE, true)) {\n\t\tnfs_pageio_reset_write_mds(pgio);\n\t\treturn;\n\t}\n\n\tif (pgio->pg_dreq == NULL)\n\t\twb_size = pnfs_num_cont_bytes(pgio->pg_inode, req->wb_index);\n\telse\n\t\twb_size = nfs_dreq_bytes_left(pgio->pg_dreq, req_offset(req));\n\n\tpnfs_generic_pg_init_write(pgio, req, wb_size);\n\n\tif (pgio->pg_lseg &&\n\t\ttest_bit(NFS_LSEG_UNAVAILABLE, &pgio->pg_lseg->pls_flags)) {\n\n\t\tpnfs_error_mark_layout_for_return(pgio->pg_inode, pgio->pg_lseg);\n\t\tpnfs_set_lo_fail(pgio->pg_lseg);\n\t\tnfs_pageio_reset_write_mds(pgio);\n\t}\n}\n\n \nstatic size_t\nbl_pg_test_write(struct nfs_pageio_descriptor *pgio, struct nfs_page *prev,\n\t\t struct nfs_page *req)\n{\n\tif (!is_aligned_req(pgio, req, PAGE_SIZE, true))\n\t\treturn 0;\n\treturn pnfs_generic_pg_test(pgio, prev, req);\n}\n\nstatic const struct nfs_pageio_ops bl_pg_read_ops = {\n\t.pg_init = bl_pg_init_read,\n\t.pg_test = bl_pg_test_read,\n\t.pg_doio = pnfs_generic_pg_readpages,\n\t.pg_cleanup = pnfs_generic_pg_cleanup,\n};\n\nstatic const struct nfs_pageio_ops bl_pg_write_ops = {\n\t.pg_init = bl_pg_init_write,\n\t.pg_test = bl_pg_test_write,\n\t.pg_doio = pnfs_generic_pg_writepages,\n\t.pg_cleanup = pnfs_generic_pg_cleanup,\n};\n\nstatic struct pnfs_layoutdriver_type blocklayout_type = {\n\t.id\t\t\t\t= LAYOUT_BLOCK_VOLUME,\n\t.name\t\t\t\t= \"LAYOUT_BLOCK_VOLUME\",\n\t.owner\t\t\t\t= THIS_MODULE,\n\t.flags\t\t\t\t= PNFS_LAYOUTRET_ON_SETATTR |\n\t\t\t\t\t  PNFS_LAYOUTRET_ON_ERROR |\n\t\t\t\t\t  PNFS_READ_WHOLE_PAGE,\n\t.read_pagelist\t\t\t= bl_read_pagelist,\n\t.write_pagelist\t\t\t= bl_write_pagelist,\n\t.alloc_layout_hdr\t\t= bl_alloc_layout_hdr,\n\t.free_layout_hdr\t\t= bl_free_layout_hdr,\n\t.alloc_lseg\t\t\t= bl_alloc_lseg,\n\t.free_lseg\t\t\t= bl_free_lseg,\n\t.return_range\t\t\t= bl_return_range,\n\t.prepare_layoutcommit\t\t= bl_prepare_layoutcommit,\n\t.cleanup_layoutcommit\t\t= bl_cleanup_layoutcommit,\n\t.set_layoutdriver\t\t= bl_set_layoutdriver,\n\t.alloc_deviceid_node\t\t= bl_alloc_deviceid_node,\n\t.free_deviceid_node\t\t= bl_free_deviceid_node,\n\t.pg_read_ops\t\t\t= &bl_pg_read_ops,\n\t.pg_write_ops\t\t\t= &bl_pg_write_ops,\n\t.sync\t\t\t\t= pnfs_generic_sync,\n};\n\nstatic struct pnfs_layoutdriver_type scsilayout_type = {\n\t.id\t\t\t\t= LAYOUT_SCSI,\n\t.name\t\t\t\t= \"LAYOUT_SCSI\",\n\t.owner\t\t\t\t= THIS_MODULE,\n\t.flags\t\t\t\t= PNFS_LAYOUTRET_ON_SETATTR |\n\t\t\t\t\t  PNFS_LAYOUTRET_ON_ERROR |\n\t\t\t\t\t  PNFS_READ_WHOLE_PAGE,\n\t.read_pagelist\t\t\t= bl_read_pagelist,\n\t.write_pagelist\t\t\t= bl_write_pagelist,\n\t.alloc_layout_hdr\t\t= sl_alloc_layout_hdr,\n\t.free_layout_hdr\t\t= bl_free_layout_hdr,\n\t.alloc_lseg\t\t\t= bl_alloc_lseg,\n\t.free_lseg\t\t\t= bl_free_lseg,\n\t.return_range\t\t\t= bl_return_range,\n\t.prepare_layoutcommit\t\t= bl_prepare_layoutcommit,\n\t.cleanup_layoutcommit\t\t= bl_cleanup_layoutcommit,\n\t.set_layoutdriver\t\t= bl_set_layoutdriver,\n\t.alloc_deviceid_node\t\t= bl_alloc_deviceid_node,\n\t.free_deviceid_node\t\t= bl_free_deviceid_node,\n\t.pg_read_ops\t\t\t= &bl_pg_read_ops,\n\t.pg_write_ops\t\t\t= &bl_pg_write_ops,\n\t.sync\t\t\t\t= pnfs_generic_sync,\n};\n\n\nstatic int __init nfs4blocklayout_init(void)\n{\n\tint ret;\n\n\tdprintk(\"%s: NFSv4 Block Layout Driver Registering...\\n\", __func__);\n\n\tret = bl_init_pipefs();\n\tif (ret)\n\t\tgoto out;\n\n\tret = pnfs_register_layoutdriver(&blocklayout_type);\n\tif (ret)\n\t\tgoto out_cleanup_pipe;\n\n\tret = pnfs_register_layoutdriver(&scsilayout_type);\n\tif (ret)\n\t\tgoto out_unregister_block;\n\treturn 0;\n\nout_unregister_block:\n\tpnfs_unregister_layoutdriver(&blocklayout_type);\nout_cleanup_pipe:\n\tbl_cleanup_pipefs();\nout:\n\treturn ret;\n}\n\nstatic void __exit nfs4blocklayout_exit(void)\n{\n\tdprintk(\"%s: NFSv4 Block Layout Driver Unregistering...\\n\",\n\t       __func__);\n\n\tpnfs_unregister_layoutdriver(&scsilayout_type);\n\tpnfs_unregister_layoutdriver(&blocklayout_type);\n\tbl_cleanup_pipefs();\n}\n\nMODULE_ALIAS(\"nfs-layouttype4-3\");\nMODULE_ALIAS(\"nfs-layouttype4-5\");\n\nmodule_init(nfs4blocklayout_init);\nmodule_exit(nfs4blocklayout_exit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}