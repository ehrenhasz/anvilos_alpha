{
  "module_name": "read.c",
  "hash_id": "06e532074e82bbfb3b98bf046ba4a070b4cf5e127f67bd2360aea0aaaf552394",
  "original_prompt": "Ingested from linux-6.6.14/fs/nfs/read.c",
  "human_readable_source": "\n \n\n#include <linux/time.h>\n#include <linux/kernel.h>\n#include <linux/errno.h>\n#include <linux/fcntl.h>\n#include <linux/stat.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/pagemap.h>\n#include <linux/sunrpc/clnt.h>\n#include <linux/nfs_fs.h>\n#include <linux/nfs_page.h>\n#include <linux/module.h>\n\n#include \"nfs4_fs.h\"\n#include \"internal.h\"\n#include \"iostat.h\"\n#include \"fscache.h\"\n#include \"pnfs.h\"\n#include \"nfstrace.h\"\n\n#define NFSDBG_FACILITY\t\tNFSDBG_PAGECACHE\n\nconst struct nfs_pgio_completion_ops nfs_async_read_completion_ops;\nstatic const struct nfs_rw_ops nfs_rw_read_ops;\n\nstatic struct kmem_cache *nfs_rdata_cachep;\n\nstatic struct nfs_pgio_header *nfs_readhdr_alloc(void)\n{\n\tstruct nfs_pgio_header *p = kmem_cache_zalloc(nfs_rdata_cachep, GFP_KERNEL);\n\n\tif (p)\n\t\tp->rw_mode = FMODE_READ;\n\treturn p;\n}\n\nstatic void nfs_readhdr_free(struct nfs_pgio_header *rhdr)\n{\n\tif (rhdr->res.scratch != NULL)\n\t\tkfree(rhdr->res.scratch);\n\tkmem_cache_free(nfs_rdata_cachep, rhdr);\n}\n\nstatic int nfs_return_empty_folio(struct folio *folio)\n{\n\tfolio_zero_segment(folio, 0, folio_size(folio));\n\tfolio_mark_uptodate(folio);\n\tfolio_unlock(folio);\n\treturn 0;\n}\n\nvoid nfs_pageio_init_read(struct nfs_pageio_descriptor *pgio,\n\t\t\t      struct inode *inode, bool force_mds,\n\t\t\t      const struct nfs_pgio_completion_ops *compl_ops)\n{\n\tstruct nfs_server *server = NFS_SERVER(inode);\n\tconst struct nfs_pageio_ops *pg_ops = &nfs_pgio_rw_ops;\n\n#ifdef CONFIG_NFS_V4_1\n\tif (server->pnfs_curr_ld && !force_mds)\n\t\tpg_ops = server->pnfs_curr_ld->pg_read_ops;\n#endif\n\tnfs_pageio_init(pgio, inode, pg_ops, compl_ops, &nfs_rw_read_ops,\n\t\t\tserver->rsize, 0);\n}\nEXPORT_SYMBOL_GPL(nfs_pageio_init_read);\n\nvoid nfs_pageio_complete_read(struct nfs_pageio_descriptor *pgio)\n{\n\tstruct nfs_pgio_mirror *pgm;\n\tunsigned long npages;\n\n\tnfs_pageio_complete(pgio);\n\n\t \n\tWARN_ON_ONCE(pgio->pg_mirror_count != 1);\n\n\tpgm = &pgio->pg_mirrors[0];\n\tNFS_I(pgio->pg_inode)->read_io += pgm->pg_bytes_written;\n\tnpages = (pgm->pg_bytes_written + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\tnfs_add_stats(pgio->pg_inode, NFSIOS_READPAGES, npages);\n}\n\n\nvoid nfs_pageio_reset_read_mds(struct nfs_pageio_descriptor *pgio)\n{\n\tstruct nfs_pgio_mirror *mirror;\n\n\tif (pgio->pg_ops && pgio->pg_ops->pg_cleanup)\n\t\tpgio->pg_ops->pg_cleanup(pgio);\n\n\tpgio->pg_ops = &nfs_pgio_rw_ops;\n\n\t \n\tWARN_ON_ONCE(pgio->pg_mirror_count != 1);\n\n\tmirror = &pgio->pg_mirrors[0];\n\tmirror->pg_bsize = NFS_SERVER(pgio->pg_inode)->rsize;\n}\nEXPORT_SYMBOL_GPL(nfs_pageio_reset_read_mds);\n\nbool nfs_read_alloc_scratch(struct nfs_pgio_header *hdr, size_t size)\n{\n\tWARN_ON(hdr->res.scratch != NULL);\n\thdr->res.scratch = kmalloc(size, GFP_KERNEL);\n\treturn hdr->res.scratch != NULL;\n}\nEXPORT_SYMBOL_GPL(nfs_read_alloc_scratch);\n\nstatic void nfs_readpage_release(struct nfs_page *req, int error)\n{\n\tstruct folio *folio = nfs_page_to_folio(req);\n\n\tif (nfs_error_is_fatal_on_server(error) && error != -ETIMEDOUT)\n\t\tfolio_set_error(folio);\n\tif (nfs_page_group_sync_on_bit(req, PG_UNLOCKPAGE))\n\t\tif (nfs_netfs_folio_unlock(folio))\n\t\t\tfolio_unlock(folio);\n\n\tnfs_release_request(req);\n}\n\nstatic void nfs_page_group_set_uptodate(struct nfs_page *req)\n{\n\tif (nfs_page_group_sync_on_bit(req, PG_UPTODATE))\n\t\tfolio_mark_uptodate(nfs_page_to_folio(req));\n}\n\nstatic void nfs_read_completion(struct nfs_pgio_header *hdr)\n{\n\tunsigned long bytes = 0;\n\tint error;\n\n\tif (test_bit(NFS_IOHDR_REDO, &hdr->flags))\n\t\tgoto out;\n\twhile (!list_empty(&hdr->pages)) {\n\t\tstruct nfs_page *req = nfs_list_entry(hdr->pages.next);\n\t\tstruct folio *folio = nfs_page_to_folio(req);\n\t\tunsigned long start = req->wb_pgbase;\n\t\tunsigned long end = req->wb_pgbase + req->wb_bytes;\n\n\t\tif (test_bit(NFS_IOHDR_EOF, &hdr->flags)) {\n\t\t\t \n\t\t\tif (bytes > hdr->good_bytes) {\n\t\t\t\t \n\t\t\t\tfolio_zero_segment(folio, start, end);\n\n\t\t\t} else if (hdr->good_bytes - bytes < req->wb_bytes) {\n\t\t\t\t \n\t\t\t\tstart += hdr->good_bytes - bytes;\n\t\t\t\tWARN_ON(start < req->wb_pgbase);\n\t\t\t\tfolio_zero_segment(folio, start, end);\n\t\t\t}\n\t\t}\n\t\terror = 0;\n\t\tbytes += req->wb_bytes;\n\t\tif (test_bit(NFS_IOHDR_ERROR, &hdr->flags)) {\n\t\t\tif (bytes <= hdr->good_bytes)\n\t\t\t\tnfs_page_group_set_uptodate(req);\n\t\t\telse {\n\t\t\t\terror = hdr->error;\n\t\t\t\txchg(&nfs_req_openctx(req)->error, error);\n\t\t\t}\n\t\t} else\n\t\t\tnfs_page_group_set_uptodate(req);\n\t\tnfs_list_remove_request(req);\n\t\tnfs_readpage_release(req, error);\n\t}\n\tnfs_netfs_read_completion(hdr);\n\nout:\n\thdr->release(hdr);\n}\n\nstatic void nfs_initiate_read(struct nfs_pgio_header *hdr,\n\t\t\t      struct rpc_message *msg,\n\t\t\t      const struct nfs_rpc_ops *rpc_ops,\n\t\t\t      struct rpc_task_setup *task_setup_data, int how)\n{\n\trpc_ops->read_setup(hdr, msg);\n\tnfs_netfs_initiate_read(hdr);\n\ttrace_nfs_initiate_read(hdr);\n}\n\nstatic void\nnfs_async_read_error(struct list_head *head, int error)\n{\n\tstruct nfs_page\t*req;\n\n\twhile (!list_empty(head)) {\n\t\treq = nfs_list_entry(head->next);\n\t\tnfs_list_remove_request(req);\n\t\tnfs_readpage_release(req, error);\n\t}\n}\n\nconst struct nfs_pgio_completion_ops nfs_async_read_completion_ops = {\n\t.error_cleanup = nfs_async_read_error,\n\t.completion = nfs_read_completion,\n};\n\n \nstatic int nfs_readpage_done(struct rpc_task *task,\n\t\t\t     struct nfs_pgio_header *hdr,\n\t\t\t     struct inode *inode)\n{\n\tint status = NFS_PROTO(inode)->read_done(task, hdr);\n\tif (status != 0)\n\t\treturn status;\n\n\tnfs_add_stats(inode, NFSIOS_SERVERREADBYTES, hdr->res.count);\n\ttrace_nfs_readpage_done(task, hdr);\n\n\tif (task->tk_status == -ESTALE) {\n\t\tnfs_set_inode_stale(inode);\n\t\tnfs_mark_for_revalidate(inode);\n\t}\n\treturn 0;\n}\n\nstatic void nfs_readpage_retry(struct rpc_task *task,\n\t\t\t       struct nfs_pgio_header *hdr)\n{\n\tstruct nfs_pgio_args *argp = &hdr->args;\n\tstruct nfs_pgio_res  *resp = &hdr->res;\n\n\t \n\tnfs_inc_stats(hdr->inode, NFSIOS_SHORTREAD);\n\ttrace_nfs_readpage_short(task, hdr);\n\n\t \n\tif (resp->count == 0) {\n\t\tnfs_set_pgio_error(hdr, -EIO, argp->offset);\n\t\treturn;\n\t}\n\n\t \n\tif (!task->tk_ops) {\n\t\thdr->pnfs_error = -EAGAIN;\n\t\treturn;\n\t}\n\n\t \n\thdr->mds_offset += resp->count;\n\targp->offset += resp->count;\n\targp->pgbase += resp->count;\n\targp->count -= resp->count;\n\tresp->count = 0;\n\tresp->eof = 0;\n\trpc_restart_call_prepare(task);\n}\n\nstatic void nfs_readpage_result(struct rpc_task *task,\n\t\t\t\tstruct nfs_pgio_header *hdr)\n{\n\tif (hdr->res.eof) {\n\t\tloff_t pos = hdr->args.offset + hdr->res.count;\n\t\tunsigned int new = pos - hdr->io_start;\n\n\t\tif (hdr->good_bytes > new) {\n\t\t\thdr->good_bytes = new;\n\t\t\tset_bit(NFS_IOHDR_EOF, &hdr->flags);\n\t\t\tclear_bit(NFS_IOHDR_ERROR, &hdr->flags);\n\t\t}\n\t} else if (hdr->res.count < hdr->args.count)\n\t\tnfs_readpage_retry(task, hdr);\n}\n\nint nfs_read_add_folio(struct nfs_pageio_descriptor *pgio,\n\t\t       struct nfs_open_context *ctx,\n\t\t       struct folio *folio)\n{\n\tstruct inode *inode = folio_file_mapping(folio)->host;\n\tstruct nfs_server *server = NFS_SERVER(inode);\n\tsize_t fsize = folio_size(folio);\n\tunsigned int rsize = server->rsize;\n\tstruct nfs_page *new;\n\tunsigned int len, aligned_len;\n\tint error;\n\n\tlen = nfs_folio_length(folio);\n\tif (len == 0)\n\t\treturn nfs_return_empty_folio(folio);\n\n\taligned_len = min_t(unsigned int, ALIGN(len, rsize), fsize);\n\n\tnew = nfs_page_create_from_folio(ctx, folio, 0, aligned_len);\n\tif (IS_ERR(new)) {\n\t\terror = PTR_ERR(new);\n\t\tgoto out;\n\t}\n\n\tif (len < fsize)\n\t\tfolio_zero_segment(folio, len, fsize);\n\tif (!nfs_pageio_add_request(pgio, new)) {\n\t\tnfs_list_remove_request(new);\n\t\terror = pgio->pg_error;\n\t\tnfs_readpage_release(new, error);\n\t\tgoto out;\n\t}\n\treturn 0;\nout:\n\treturn error;\n}\n\n \nint nfs_read_folio(struct file *file, struct folio *folio)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct nfs_pageio_descriptor pgio;\n\tstruct nfs_open_context *ctx;\n\tint ret;\n\n\ttrace_nfs_aop_readpage(inode, folio);\n\tnfs_inc_stats(inode, NFSIOS_VFSREADPAGE);\n\ttask_io_account_read(folio_size(folio));\n\n\t \n\tret = nfs_wb_folio(inode, folio);\n\tif (ret)\n\t\tgoto out_unlock;\n\tif (folio_test_uptodate(folio))\n\t\tgoto out_unlock;\n\n\tret = -ESTALE;\n\tif (NFS_STALE(inode))\n\t\tgoto out_unlock;\n\n\tret = nfs_netfs_read_folio(file, folio);\n\tif (!ret)\n\t\tgoto out;\n\n\tctx = get_nfs_open_context(nfs_file_open_context(file));\n\n\txchg(&ctx->error, 0);\n\tnfs_pageio_init_read(&pgio, inode, false,\n\t\t\t     &nfs_async_read_completion_ops);\n\n\tret = nfs_read_add_folio(&pgio, ctx, folio);\n\tif (ret)\n\t\tgoto out_put;\n\n\tnfs_pageio_complete_read(&pgio);\n\tret = pgio.pg_error < 0 ? pgio.pg_error : 0;\n\tif (!ret) {\n\t\tret = folio_wait_locked_killable(folio);\n\t\tif (!folio_test_uptodate(folio) && !ret)\n\t\t\tret = xchg(&ctx->error, 0);\n\t}\nout_put:\n\tput_nfs_open_context(ctx);\nout:\n\ttrace_nfs_aop_readpage_done(inode, folio, ret);\n\treturn ret;\nout_unlock:\n\tfolio_unlock(folio);\n\tgoto out;\n}\n\nvoid nfs_readahead(struct readahead_control *ractl)\n{\n\tstruct nfs_pageio_descriptor pgio;\n\tstruct nfs_open_context *ctx;\n\tunsigned int nr_pages = readahead_count(ractl);\n\tstruct file *file = ractl->file;\n\tstruct inode *inode = ractl->mapping->host;\n\tstruct folio *folio;\n\tint ret;\n\n\ttrace_nfs_aop_readahead(inode, readahead_pos(ractl), nr_pages);\n\tnfs_inc_stats(inode, NFSIOS_VFSREADPAGES);\n\ttask_io_account_read(readahead_length(ractl));\n\n\tret = -ESTALE;\n\tif (NFS_STALE(inode))\n\t\tgoto out;\n\n\tret = nfs_netfs_readahead(ractl);\n\tif (!ret)\n\t\tgoto out;\n\n\tif (file == NULL) {\n\t\tret = -EBADF;\n\t\tctx = nfs_find_open_context(inode, NULL, FMODE_READ);\n\t\tif (ctx == NULL)\n\t\t\tgoto out;\n\t} else\n\t\tctx = get_nfs_open_context(nfs_file_open_context(file));\n\n\tnfs_pageio_init_read(&pgio, inode, false,\n\t\t\t     &nfs_async_read_completion_ops);\n\n\twhile ((folio = readahead_folio(ractl)) != NULL) {\n\t\tret = nfs_read_add_folio(&pgio, ctx, folio);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tnfs_pageio_complete_read(&pgio);\n\n\tput_nfs_open_context(ctx);\nout:\n\ttrace_nfs_aop_readahead_done(inode, nr_pages, ret);\n}\n\nint __init nfs_init_readpagecache(void)\n{\n\tnfs_rdata_cachep = kmem_cache_create(\"nfs_read_data\",\n\t\t\t\t\t     sizeof(struct nfs_pgio_header),\n\t\t\t\t\t     0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t     NULL);\n\tif (nfs_rdata_cachep == NULL)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nvoid nfs_destroy_readpagecache(void)\n{\n\tkmem_cache_destroy(nfs_rdata_cachep);\n}\n\nstatic const struct nfs_rw_ops nfs_rw_read_ops = {\n\t.rw_alloc_header\t= nfs_readhdr_alloc,\n\t.rw_free_header\t\t= nfs_readhdr_free,\n\t.rw_done\t\t= nfs_readpage_done,\n\t.rw_result\t\t= nfs_readpage_result,\n\t.rw_initiate\t\t= nfs_initiate_read,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}