{
  "module_name": "lops.c",
  "hash_id": "9c98a53dd68e0b814a63a9bc4c9fde12f5975b38b97592eb00e5f08f216b3123",
  "original_prompt": "Ingested from linux-6.6.14/fs/gfs2/lops.c",
  "human_readable_source": "\n \n\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/completion.h>\n#include <linux/buffer_head.h>\n#include <linux/mempool.h>\n#include <linux/gfs2_ondisk.h>\n#include <linux/bio.h>\n#include <linux/fs.h>\n#include <linux/list_sort.h>\n#include <linux/blkdev.h>\n\n#include \"bmap.h\"\n#include \"dir.h\"\n#include \"gfs2.h\"\n#include \"incore.h\"\n#include \"inode.h\"\n#include \"glock.h\"\n#include \"glops.h\"\n#include \"log.h\"\n#include \"lops.h\"\n#include \"meta_io.h\"\n#include \"recovery.h\"\n#include \"rgrp.h\"\n#include \"trans.h\"\n#include \"util.h\"\n#include \"trace_gfs2.h\"\n\n \nvoid gfs2_pin(struct gfs2_sbd *sdp, struct buffer_head *bh)\n{\n\tstruct gfs2_bufdata *bd;\n\n\tBUG_ON(!current->journal_info);\n\n\tclear_buffer_dirty(bh);\n\tif (test_set_buffer_pinned(bh))\n\t\tgfs2_assert_withdraw(sdp, 0);\n\tif (!buffer_uptodate(bh))\n\t\tgfs2_io_error_bh_wd(sdp, bh);\n\tbd = bh->b_private;\n\t \n\tspin_lock(&sdp->sd_ail_lock);\n\tif (bd->bd_tr)\n\t\tlist_move(&bd->bd_ail_st_list, &bd->bd_tr->tr_ail2_list);\n\tspin_unlock(&sdp->sd_ail_lock);\n\tget_bh(bh);\n\tatomic_inc(&sdp->sd_log_pinned);\n\ttrace_gfs2_pin(bd, 1);\n}\n\nstatic bool buffer_is_rgrp(const struct gfs2_bufdata *bd)\n{\n\treturn bd->bd_gl->gl_name.ln_type == LM_TYPE_RGRP;\n}\n\nstatic void maybe_release_space(struct gfs2_bufdata *bd)\n{\n\tstruct gfs2_glock *gl = bd->bd_gl;\n\tstruct gfs2_sbd *sdp = gl->gl_name.ln_sbd;\n\tstruct gfs2_rgrpd *rgd = gfs2_glock2rgrp(gl);\n\tunsigned int index = bd->bd_bh->b_blocknr - gl->gl_name.ln_number;\n\tstruct gfs2_bitmap *bi = rgd->rd_bits + index;\n\n\trgrp_lock_local(rgd);\n\tif (bi->bi_clone == NULL)\n\t\tgoto out;\n\tif (sdp->sd_args.ar_discard)\n\t\tgfs2_rgrp_send_discards(sdp, rgd->rd_data0, bd->bd_bh, bi, 1, NULL);\n\tmemcpy(bi->bi_clone + bi->bi_offset,\n\t       bd->bd_bh->b_data + bi->bi_offset, bi->bi_bytes);\n\tclear_bit(GBF_FULL, &bi->bi_flags);\n\trgd->rd_free_clone = rgd->rd_free;\n\tBUG_ON(rgd->rd_free_clone < rgd->rd_reserved);\n\trgd->rd_extfail_pt = rgd->rd_free;\n\nout:\n\trgrp_unlock_local(rgd);\n}\n\n \n\nstatic void gfs2_unpin(struct gfs2_sbd *sdp, struct buffer_head *bh,\n\t\t       struct gfs2_trans *tr)\n{\n\tstruct gfs2_bufdata *bd = bh->b_private;\n\n\tBUG_ON(!buffer_uptodate(bh));\n\tBUG_ON(!buffer_pinned(bh));\n\n\tlock_buffer(bh);\n\tmark_buffer_dirty(bh);\n\tclear_buffer_pinned(bh);\n\n\tif (buffer_is_rgrp(bd))\n\t\tmaybe_release_space(bd);\n\n\tspin_lock(&sdp->sd_ail_lock);\n\tif (bd->bd_tr) {\n\t\tlist_del(&bd->bd_ail_st_list);\n\t\tbrelse(bh);\n\t} else {\n\t\tstruct gfs2_glock *gl = bd->bd_gl;\n\t\tlist_add(&bd->bd_ail_gl_list, &gl->gl_ail_list);\n\t\tatomic_inc(&gl->gl_ail_count);\n\t}\n\tbd->bd_tr = tr;\n\tlist_add(&bd->bd_ail_st_list, &tr->tr_ail1_list);\n\tspin_unlock(&sdp->sd_ail_lock);\n\n\tclear_bit(GLF_LFLUSH, &bd->bd_gl->gl_flags);\n\ttrace_gfs2_pin(bd, 0);\n\tunlock_buffer(bh);\n\tatomic_dec(&sdp->sd_log_pinned);\n}\n\nvoid gfs2_log_incr_head(struct gfs2_sbd *sdp)\n{\n\tBUG_ON((sdp->sd_log_flush_head == sdp->sd_log_tail) &&\n\t       (sdp->sd_log_flush_head != sdp->sd_log_head));\n\n\tif (++sdp->sd_log_flush_head == sdp->sd_jdesc->jd_blocks)\n\t\tsdp->sd_log_flush_head = 0;\n}\n\nu64 gfs2_log_bmap(struct gfs2_jdesc *jd, unsigned int lblock)\n{\n\tstruct gfs2_journal_extent *je;\n\n\tlist_for_each_entry(je, &jd->extent_list, list) {\n\t\tif (lblock >= je->lblock && lblock < je->lblock + je->blocks)\n\t\t\treturn je->dblock + lblock - je->lblock;\n\t}\n\n\treturn -1;\n}\n\n \n\nstatic void gfs2_end_log_write_bh(struct gfs2_sbd *sdp,\n\t\t\t\t  struct bio_vec *bvec,\n\t\t\t\t  blk_status_t error)\n{\n\tstruct buffer_head *bh, *next;\n\tstruct page *page = bvec->bv_page;\n\tunsigned size;\n\n\tbh = page_buffers(page);\n\tsize = bvec->bv_len;\n\twhile (bh_offset(bh) < bvec->bv_offset)\n\t\tbh = bh->b_this_page;\n\tdo {\n\t\tif (error)\n\t\t\tmark_buffer_write_io_error(bh);\n\t\tunlock_buffer(bh);\n\t\tnext = bh->b_this_page;\n\t\tsize -= bh->b_size;\n\t\tbrelse(bh);\n\t\tbh = next;\n\t} while(bh && size);\n}\n\n \n\nstatic void gfs2_end_log_write(struct bio *bio)\n{\n\tstruct gfs2_sbd *sdp = bio->bi_private;\n\tstruct bio_vec *bvec;\n\tstruct page *page;\n\tstruct bvec_iter_all iter_all;\n\n\tif (bio->bi_status) {\n\t\tif (!cmpxchg(&sdp->sd_log_error, 0, (int)bio->bi_status))\n\t\t\tfs_err(sdp, \"Error %d writing to journal, jid=%u\\n\",\n\t\t\t       bio->bi_status, sdp->sd_jdesc->jd_jid);\n\t\tgfs2_withdraw_delayed(sdp);\n\t\t \n\t\tclear_bit(SDF_JOURNAL_LIVE, &sdp->sd_flags);\n\t\twake_up(&sdp->sd_logd_waitq);\n\t}\n\n\tbio_for_each_segment_all(bvec, bio, iter_all) {\n\t\tpage = bvec->bv_page;\n\t\tif (page_has_buffers(page))\n\t\t\tgfs2_end_log_write_bh(sdp, bvec, bio->bi_status);\n\t\telse\n\t\t\tmempool_free(page, gfs2_page_pool);\n\t}\n\n\tbio_put(bio);\n\tif (atomic_dec_and_test(&sdp->sd_log_in_flight))\n\t\twake_up(&sdp->sd_log_flush_wait);\n}\n\n \n\nvoid gfs2_log_submit_bio(struct bio **biop, blk_opf_t opf)\n{\n\tstruct bio *bio = *biop;\n\tif (bio) {\n\t\tstruct gfs2_sbd *sdp = bio->bi_private;\n\t\tatomic_inc(&sdp->sd_log_in_flight);\n\t\tbio->bi_opf = opf;\n\t\tsubmit_bio(bio);\n\t\t*biop = NULL;\n\t}\n}\n\n \n\nstatic struct bio *gfs2_log_alloc_bio(struct gfs2_sbd *sdp, u64 blkno,\n\t\t\t\t      bio_end_io_t *end_io)\n{\n\tstruct super_block *sb = sdp->sd_vfs;\n\tstruct bio *bio = bio_alloc(sb->s_bdev, BIO_MAX_VECS, 0, GFP_NOIO);\n\n\tbio->bi_iter.bi_sector = blkno << sdp->sd_fsb2bb_shift;\n\tbio->bi_end_io = end_io;\n\tbio->bi_private = sdp;\n\n\treturn bio;\n}\n\n \n\nstatic struct bio *gfs2_log_get_bio(struct gfs2_sbd *sdp, u64 blkno,\n\t\t\t\t    struct bio **biop, enum req_op op,\n\t\t\t\t    bio_end_io_t *end_io, bool flush)\n{\n\tstruct bio *bio = *biop;\n\n\tif (bio) {\n\t\tu64 nblk;\n\n\t\tnblk = bio_end_sector(bio);\n\t\tnblk >>= sdp->sd_fsb2bb_shift;\n\t\tif (blkno == nblk && !flush)\n\t\t\treturn bio;\n\t\tgfs2_log_submit_bio(biop, op);\n\t}\n\n\t*biop = gfs2_log_alloc_bio(sdp, blkno, end_io);\n\treturn *biop;\n}\n\n \n\nvoid gfs2_log_write(struct gfs2_sbd *sdp, struct gfs2_jdesc *jd,\n\t\t    struct page *page, unsigned size, unsigned offset,\n\t\t    u64 blkno)\n{\n\tstruct bio *bio;\n\tint ret;\n\n\tbio = gfs2_log_get_bio(sdp, blkno, &jd->jd_log_bio, REQ_OP_WRITE,\n\t\t\t       gfs2_end_log_write, false);\n\tret = bio_add_page(bio, page, size, offset);\n\tif (ret == 0) {\n\t\tbio = gfs2_log_get_bio(sdp, blkno, &jd->jd_log_bio,\n\t\t\t\t       REQ_OP_WRITE, gfs2_end_log_write, true);\n\t\tret = bio_add_page(bio, page, size, offset);\n\t\tWARN_ON(ret == 0);\n\t}\n}\n\n \n\nstatic void gfs2_log_write_bh(struct gfs2_sbd *sdp, struct buffer_head *bh)\n{\n\tu64 dblock;\n\n\tdblock = gfs2_log_bmap(sdp->sd_jdesc, sdp->sd_log_flush_head);\n\tgfs2_log_incr_head(sdp);\n\tgfs2_log_write(sdp, sdp->sd_jdesc, bh->b_page, bh->b_size,\n\t\t       bh_offset(bh), dblock);\n}\n\n \n\nstatic void gfs2_log_write_page(struct gfs2_sbd *sdp, struct page *page)\n{\n\tstruct super_block *sb = sdp->sd_vfs;\n\tu64 dblock;\n\n\tdblock = gfs2_log_bmap(sdp->sd_jdesc, sdp->sd_log_flush_head);\n\tgfs2_log_incr_head(sdp);\n\tgfs2_log_write(sdp, sdp->sd_jdesc, page, sb->s_blocksize, 0, dblock);\n}\n\n \n\nstatic void gfs2_end_log_read(struct bio *bio)\n{\n\tstruct page *page;\n\tstruct bio_vec *bvec;\n\tstruct bvec_iter_all iter_all;\n\n\tbio_for_each_segment_all(bvec, bio, iter_all) {\n\t\tpage = bvec->bv_page;\n\t\tif (bio->bi_status) {\n\t\t\tint err = blk_status_to_errno(bio->bi_status);\n\n\t\t\tSetPageError(page);\n\t\t\tmapping_set_error(page->mapping, err);\n\t\t}\n\t\tunlock_page(page);\n\t}\n\n\tbio_put(bio);\n}\n\n \n\nstatic bool gfs2_jhead_pg_srch(struct gfs2_jdesc *jd,\n\t\t\t      struct gfs2_log_header_host *head,\n\t\t\t      struct page *page)\n{\n\tstruct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);\n\tstruct gfs2_log_header_host lh;\n\tvoid *kaddr;\n\tunsigned int offset;\n\tbool ret = false;\n\n\tkaddr = kmap_local_page(page);\n\tfor (offset = 0; offset < PAGE_SIZE; offset += sdp->sd_sb.sb_bsize) {\n\t\tif (!__get_log_header(sdp, kaddr + offset, 0, &lh)) {\n\t\t\tif (lh.lh_sequence >= head->lh_sequence)\n\t\t\t\t*head = lh;\n\t\t\telse {\n\t\t\t\tret = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tkunmap_local(kaddr);\n\treturn ret;\n}\n\n \n\nstatic void gfs2_jhead_process_page(struct gfs2_jdesc *jd, unsigned long index,\n\t\t\t\t    struct gfs2_log_header_host *head,\n\t\t\t\t    bool *done)\n{\n\tstruct folio *folio;\n\n\tfolio = filemap_get_folio(jd->jd_inode->i_mapping, index);\n\n\tfolio_wait_locked(folio);\n\tif (folio_test_error(folio))\n\t\t*done = true;\n\n\tif (!*done)\n\t\t*done = gfs2_jhead_pg_srch(jd, head, &folio->page);\n\n\t \n\tfolio_put_refs(folio, 2);\n}\n\nstatic struct bio *gfs2_chain_bio(struct bio *prev, unsigned int nr_iovecs)\n{\n\tstruct bio *new;\n\n\tnew = bio_alloc(prev->bi_bdev, nr_iovecs, prev->bi_opf, GFP_NOIO);\n\tbio_clone_blkg_association(new, prev);\n\tnew->bi_iter.bi_sector = bio_end_sector(prev);\n\tbio_chain(new, prev);\n\tsubmit_bio(prev);\n\treturn new;\n}\n\n \nint gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head,\n\t\t    bool keep_cache)\n{\n\tstruct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);\n\tstruct address_space *mapping = jd->jd_inode->i_mapping;\n\tunsigned int block = 0, blocks_submitted = 0, blocks_read = 0;\n\tunsigned int bsize = sdp->sd_sb.sb_bsize, off;\n\tunsigned int bsize_shift = sdp->sd_sb.sb_bsize_shift;\n\tunsigned int shift = PAGE_SHIFT - bsize_shift;\n\tunsigned int max_blocks = 2 * 1024 * 1024 >> bsize_shift;\n\tstruct gfs2_journal_extent *je;\n\tint sz, ret = 0;\n\tstruct bio *bio = NULL;\n\tstruct page *page = NULL;\n\tbool done = false;\n\terrseq_t since;\n\n\tmemset(head, 0, sizeof(*head));\n\tif (list_empty(&jd->extent_list))\n\t\tgfs2_map_journal_extents(sdp, jd);\n\n\tsince = filemap_sample_wb_err(mapping);\n\tlist_for_each_entry(je, &jd->extent_list, list) {\n\t\tu64 dblock = je->dblock;\n\n\t\tfor (; block < je->lblock + je->blocks; block++, dblock++) {\n\t\t\tif (!page) {\n\t\t\t\tpage = grab_cache_page(mapping, block >> shift);\n\t\t\t\tif (!page) {\n\t\t\t\t\tret = -ENOMEM;\n\t\t\t\t\tdone = true;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\toff = 0;\n\t\t\t}\n\n\t\t\tif (bio && (off || block < blocks_submitted + max_blocks)) {\n\t\t\t\tsector_t sector = dblock << sdp->sd_fsb2bb_shift;\n\n\t\t\t\tif (bio_end_sector(bio) == sector) {\n\t\t\t\t\tsz = bio_add_page(bio, page, bsize, off);\n\t\t\t\t\tif (sz == bsize)\n\t\t\t\t\t\tgoto block_added;\n\t\t\t\t}\n\t\t\t\tif (off) {\n\t\t\t\t\tunsigned int blocks =\n\t\t\t\t\t\t(PAGE_SIZE - off) >> bsize_shift;\n\n\t\t\t\t\tbio = gfs2_chain_bio(bio, blocks);\n\t\t\t\t\tgoto add_block_to_new_bio;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (bio) {\n\t\t\t\tblocks_submitted = block;\n\t\t\t\tsubmit_bio(bio);\n\t\t\t}\n\n\t\t\tbio = gfs2_log_alloc_bio(sdp, dblock, gfs2_end_log_read);\n\t\t\tbio->bi_opf = REQ_OP_READ;\nadd_block_to_new_bio:\n\t\t\tsz = bio_add_page(bio, page, bsize, off);\n\t\t\tBUG_ON(sz != bsize);\nblock_added:\n\t\t\toff += bsize;\n\t\t\tif (off == PAGE_SIZE)\n\t\t\t\tpage = NULL;\n\t\t\tif (blocks_submitted <= blocks_read + max_blocks) {\n\t\t\t\t \n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tgfs2_jhead_process_page(jd, blocks_read >> shift, head, &done);\n\t\t\tblocks_read += PAGE_SIZE >> bsize_shift;\n\t\t\tif (done)\n\t\t\t\tgoto out;   \n\t\t}\n\t}\n\nout:\n\tif (bio)\n\t\tsubmit_bio(bio);\n\twhile (blocks_read < block) {\n\t\tgfs2_jhead_process_page(jd, blocks_read >> shift, head, &done);\n\t\tblocks_read += PAGE_SIZE >> bsize_shift;\n\t}\n\n\tif (!ret)\n\t\tret = filemap_check_wb_err(mapping, since);\n\n\tif (!keep_cache)\n\t\ttruncate_inode_pages(mapping, 0);\n\n\treturn ret;\n}\n\nstatic struct page *gfs2_get_log_desc(struct gfs2_sbd *sdp, u32 ld_type,\n\t\t\t\t      u32 ld_length, u32 ld_data1)\n{\n\tstruct page *page = mempool_alloc(gfs2_page_pool, GFP_NOIO);\n\tstruct gfs2_log_descriptor *ld = page_address(page);\n\tclear_page(ld);\n\tld->ld_header.mh_magic = cpu_to_be32(GFS2_MAGIC);\n\tld->ld_header.mh_type = cpu_to_be32(GFS2_METATYPE_LD);\n\tld->ld_header.mh_format = cpu_to_be32(GFS2_FORMAT_LD);\n\tld->ld_type = cpu_to_be32(ld_type);\n\tld->ld_length = cpu_to_be32(ld_length);\n\tld->ld_data1 = cpu_to_be32(ld_data1);\n\tld->ld_data2 = 0;\n\treturn page;\n}\n\nstatic void gfs2_check_magic(struct buffer_head *bh)\n{\n\tvoid *kaddr;\n\t__be32 *ptr;\n\n\tclear_buffer_escaped(bh);\n\tkaddr = kmap_local_page(bh->b_page);\n\tptr = kaddr + bh_offset(bh);\n\tif (*ptr == cpu_to_be32(GFS2_MAGIC))\n\t\tset_buffer_escaped(bh);\n\tkunmap_local(kaddr);\n}\n\nstatic int blocknr_cmp(void *priv, const struct list_head *a,\n\t\t       const struct list_head *b)\n{\n\tstruct gfs2_bufdata *bda, *bdb;\n\n\tbda = list_entry(a, struct gfs2_bufdata, bd_list);\n\tbdb = list_entry(b, struct gfs2_bufdata, bd_list);\n\n\tif (bda->bd_bh->b_blocknr < bdb->bd_bh->b_blocknr)\n\t\treturn -1;\n\tif (bda->bd_bh->b_blocknr > bdb->bd_bh->b_blocknr)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic void gfs2_before_commit(struct gfs2_sbd *sdp, unsigned int limit,\n\t\t\t\tunsigned int total, struct list_head *blist,\n\t\t\t\tbool is_databuf)\n{\n\tstruct gfs2_log_descriptor *ld;\n\tstruct gfs2_bufdata *bd1 = NULL, *bd2;\n\tstruct page *page;\n\tunsigned int num;\n\tunsigned n;\n\t__be64 *ptr;\n\n\tgfs2_log_lock(sdp);\n\tlist_sort(NULL, blist, blocknr_cmp);\n\tbd1 = bd2 = list_prepare_entry(bd1, blist, bd_list);\n\twhile(total) {\n\t\tnum = total;\n\t\tif (total > limit)\n\t\t\tnum = limit;\n\t\tgfs2_log_unlock(sdp);\n\t\tpage = gfs2_get_log_desc(sdp,\n\t\t\t\t\t is_databuf ? GFS2_LOG_DESC_JDATA :\n\t\t\t\t\t GFS2_LOG_DESC_METADATA, num + 1, num);\n\t\tld = page_address(page);\n\t\tgfs2_log_lock(sdp);\n\t\tptr = (__be64 *)(ld + 1);\n\n\t\tn = 0;\n\t\tlist_for_each_entry_continue(bd1, blist, bd_list) {\n\t\t\t*ptr++ = cpu_to_be64(bd1->bd_bh->b_blocknr);\n\t\t\tif (is_databuf) {\n\t\t\t\tgfs2_check_magic(bd1->bd_bh);\n\t\t\t\t*ptr++ = cpu_to_be64(buffer_escaped(bd1->bd_bh) ? 1 : 0);\n\t\t\t}\n\t\t\tif (++n >= num)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tgfs2_log_unlock(sdp);\n\t\tgfs2_log_write_page(sdp, page);\n\t\tgfs2_log_lock(sdp);\n\n\t\tn = 0;\n\t\tlist_for_each_entry_continue(bd2, blist, bd_list) {\n\t\t\tget_bh(bd2->bd_bh);\n\t\t\tgfs2_log_unlock(sdp);\n\t\t\tlock_buffer(bd2->bd_bh);\n\n\t\t\tif (buffer_escaped(bd2->bd_bh)) {\n\t\t\t\tvoid *p;\n\n\t\t\t\tpage = mempool_alloc(gfs2_page_pool, GFP_NOIO);\n\t\t\t\tp = page_address(page);\n\t\t\t\tmemcpy_from_page(p, page, bh_offset(bd2->bd_bh), bd2->bd_bh->b_size);\n\t\t\t\t*(__be32 *)p = 0;\n\t\t\t\tclear_buffer_escaped(bd2->bd_bh);\n\t\t\t\tunlock_buffer(bd2->bd_bh);\n\t\t\t\tbrelse(bd2->bd_bh);\n\t\t\t\tgfs2_log_write_page(sdp, page);\n\t\t\t} else {\n\t\t\t\tgfs2_log_write_bh(sdp, bd2->bd_bh);\n\t\t\t}\n\t\t\tgfs2_log_lock(sdp);\n\t\t\tif (++n >= num)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tBUG_ON(total < num);\n\t\ttotal -= num;\n\t}\n\tgfs2_log_unlock(sdp);\n}\n\nstatic void buf_lo_before_commit(struct gfs2_sbd *sdp, struct gfs2_trans *tr)\n{\n\tunsigned int limit = buf_limit(sdp);  \n\tunsigned int nbuf;\n\tif (tr == NULL)\n\t\treturn;\n\tnbuf = tr->tr_num_buf_new - tr->tr_num_buf_rm;\n\tgfs2_before_commit(sdp, limit, nbuf, &tr->tr_buf, 0);\n}\n\nstatic void buf_lo_after_commit(struct gfs2_sbd *sdp, struct gfs2_trans *tr)\n{\n\tstruct list_head *head;\n\tstruct gfs2_bufdata *bd;\n\n\tif (tr == NULL)\n\t\treturn;\n\n\thead = &tr->tr_buf;\n\twhile (!list_empty(head)) {\n\t\tbd = list_first_entry(head, struct gfs2_bufdata, bd_list);\n\t\tlist_del_init(&bd->bd_list);\n\t\tgfs2_unpin(sdp, bd->bd_bh, tr);\n\t}\n}\n\nstatic void buf_lo_before_scan(struct gfs2_jdesc *jd,\n\t\t\t       struct gfs2_log_header_host *head, int pass)\n{\n\tif (pass != 0)\n\t\treturn;\n\n\tjd->jd_found_blocks = 0;\n\tjd->jd_replayed_blocks = 0;\n}\n\n#define obsolete_rgrp_replay \\\n\"Replaying 0x%llx from jid=%d/0x%llx but we already have a bh!\\n\"\n#define obsolete_rgrp_replay2 \\\n\"busy:%d, pinned:%d rg_gen:0x%llx, j_gen:0x%llx\\n\"\n\nstatic void obsolete_rgrp(struct gfs2_jdesc *jd, struct buffer_head *bh_log,\n\t\t\t  u64 blkno)\n{\n\tstruct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);\n\tstruct gfs2_rgrpd *rgd;\n\tstruct gfs2_rgrp *jrgd = (struct gfs2_rgrp *)bh_log->b_data;\n\n\trgd = gfs2_blk2rgrpd(sdp, blkno, false);\n\tif (rgd && rgd->rd_addr == blkno &&\n\t    rgd->rd_bits && rgd->rd_bits->bi_bh) {\n\t\tfs_info(sdp, obsolete_rgrp_replay, (unsigned long long)blkno,\n\t\t\tjd->jd_jid, bh_log->b_blocknr);\n\t\tfs_info(sdp, obsolete_rgrp_replay2,\n\t\t\tbuffer_busy(rgd->rd_bits->bi_bh) ? 1 : 0,\n\t\t\tbuffer_pinned(rgd->rd_bits->bi_bh),\n\t\t\trgd->rd_igeneration,\n\t\t\tbe64_to_cpu(jrgd->rg_igeneration));\n\t\tgfs2_dump_glock(NULL, rgd->rd_gl, true);\n\t}\n}\n\nstatic int buf_lo_scan_elements(struct gfs2_jdesc *jd, u32 start,\n\t\t\t\tstruct gfs2_log_descriptor *ld, __be64 *ptr,\n\t\t\t\tint pass)\n{\n\tstruct gfs2_inode *ip = GFS2_I(jd->jd_inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);\n\tstruct gfs2_glock *gl = ip->i_gl;\n\tunsigned int blks = be32_to_cpu(ld->ld_data1);\n\tstruct buffer_head *bh_log, *bh_ip;\n\tu64 blkno;\n\tint error = 0;\n\n\tif (pass != 1 || be32_to_cpu(ld->ld_type) != GFS2_LOG_DESC_METADATA)\n\t\treturn 0;\n\n\tgfs2_replay_incr_blk(jd, &start);\n\n\tfor (; blks; gfs2_replay_incr_blk(jd, &start), blks--) {\n\t\tblkno = be64_to_cpu(*ptr++);\n\n\t\tjd->jd_found_blocks++;\n\n\t\tif (gfs2_revoke_check(jd, blkno, start))\n\t\t\tcontinue;\n\n\t\terror = gfs2_replay_read_block(jd, start, &bh_log);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\tbh_ip = gfs2_meta_new(gl, blkno);\n\t\tmemcpy(bh_ip->b_data, bh_log->b_data, bh_log->b_size);\n\n\t\tif (gfs2_meta_check(sdp, bh_ip))\n\t\t\terror = -EIO;\n\t\telse {\n\t\t\tstruct gfs2_meta_header *mh =\n\t\t\t\t(struct gfs2_meta_header *)bh_ip->b_data;\n\n\t\t\tif (mh->mh_type == cpu_to_be32(GFS2_METATYPE_RG))\n\t\t\t\tobsolete_rgrp(jd, bh_log, blkno);\n\n\t\t\tmark_buffer_dirty(bh_ip);\n\t\t}\n\t\tbrelse(bh_log);\n\t\tbrelse(bh_ip);\n\n\t\tif (error)\n\t\t\tbreak;\n\n\t\tjd->jd_replayed_blocks++;\n\t}\n\n\treturn error;\n}\n\nstatic void buf_lo_after_scan(struct gfs2_jdesc *jd, int error, int pass)\n{\n\tstruct gfs2_inode *ip = GFS2_I(jd->jd_inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);\n\n\tif (error) {\n\t\tgfs2_inode_metasync(ip->i_gl);\n\t\treturn;\n\t}\n\tif (pass != 1)\n\t\treturn;\n\n\tgfs2_inode_metasync(ip->i_gl);\n\n\tfs_info(sdp, \"jid=%u: Replayed %u of %u blocks\\n\",\n\t        jd->jd_jid, jd->jd_replayed_blocks, jd->jd_found_blocks);\n}\n\nstatic void revoke_lo_before_commit(struct gfs2_sbd *sdp, struct gfs2_trans *tr)\n{\n\tstruct gfs2_meta_header *mh;\n\tunsigned int offset;\n\tstruct list_head *head = &sdp->sd_log_revokes;\n\tstruct gfs2_bufdata *bd;\n\tstruct page *page;\n\tunsigned int length;\n\n\tgfs2_flush_revokes(sdp);\n\tif (!sdp->sd_log_num_revoke)\n\t\treturn;\n\n\tlength = gfs2_struct2blk(sdp, sdp->sd_log_num_revoke);\n\tpage = gfs2_get_log_desc(sdp, GFS2_LOG_DESC_REVOKE, length, sdp->sd_log_num_revoke);\n\toffset = sizeof(struct gfs2_log_descriptor);\n\n\tlist_for_each_entry(bd, head, bd_list) {\n\t\tsdp->sd_log_num_revoke--;\n\n\t\tif (offset + sizeof(u64) > sdp->sd_sb.sb_bsize) {\n\t\t\tgfs2_log_write_page(sdp, page);\n\t\t\tpage = mempool_alloc(gfs2_page_pool, GFP_NOIO);\n\t\t\tmh = page_address(page);\n\t\t\tclear_page(mh);\n\t\t\tmh->mh_magic = cpu_to_be32(GFS2_MAGIC);\n\t\t\tmh->mh_type = cpu_to_be32(GFS2_METATYPE_LB);\n\t\t\tmh->mh_format = cpu_to_be32(GFS2_FORMAT_LB);\n\t\t\toffset = sizeof(struct gfs2_meta_header);\n\t\t}\n\n\t\t*(__be64 *)(page_address(page) + offset) = cpu_to_be64(bd->bd_blkno);\n\t\toffset += sizeof(u64);\n\t}\n\tgfs2_assert_withdraw(sdp, !sdp->sd_log_num_revoke);\n\n\tgfs2_log_write_page(sdp, page);\n}\n\nvoid gfs2_drain_revokes(struct gfs2_sbd *sdp)\n{\n\tstruct list_head *head = &sdp->sd_log_revokes;\n\tstruct gfs2_bufdata *bd;\n\tstruct gfs2_glock *gl;\n\n\twhile (!list_empty(head)) {\n\t\tbd = list_first_entry(head, struct gfs2_bufdata, bd_list);\n\t\tlist_del_init(&bd->bd_list);\n\t\tgl = bd->bd_gl;\n\t\tgfs2_glock_remove_revoke(gl);\n\t\tkmem_cache_free(gfs2_bufdata_cachep, bd);\n\t}\n}\n\nstatic void revoke_lo_after_commit(struct gfs2_sbd *sdp, struct gfs2_trans *tr)\n{\n\tgfs2_drain_revokes(sdp);\n}\n\nstatic void revoke_lo_before_scan(struct gfs2_jdesc *jd,\n\t\t\t\t  struct gfs2_log_header_host *head, int pass)\n{\n\tif (pass != 0)\n\t\treturn;\n\n\tjd->jd_found_revokes = 0;\n\tjd->jd_replay_tail = head->lh_tail;\n}\n\nstatic int revoke_lo_scan_elements(struct gfs2_jdesc *jd, u32 start,\n\t\t\t\t   struct gfs2_log_descriptor *ld, __be64 *ptr,\n\t\t\t\t   int pass)\n{\n\tstruct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);\n\tunsigned int blks = be32_to_cpu(ld->ld_length);\n\tunsigned int revokes = be32_to_cpu(ld->ld_data1);\n\tstruct buffer_head *bh;\n\tunsigned int offset;\n\tu64 blkno;\n\tint first = 1;\n\tint error;\n\n\tif (pass != 0 || be32_to_cpu(ld->ld_type) != GFS2_LOG_DESC_REVOKE)\n\t\treturn 0;\n\n\toffset = sizeof(struct gfs2_log_descriptor);\n\n\tfor (; blks; gfs2_replay_incr_blk(jd, &start), blks--) {\n\t\terror = gfs2_replay_read_block(jd, start, &bh);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\tif (!first)\n\t\t\tgfs2_metatype_check(sdp, bh, GFS2_METATYPE_LB);\n\n\t\twhile (offset + sizeof(u64) <= sdp->sd_sb.sb_bsize) {\n\t\t\tblkno = be64_to_cpu(*(__be64 *)(bh->b_data + offset));\n\n\t\t\terror = gfs2_revoke_add(jd, blkno, start);\n\t\t\tif (error < 0) {\n\t\t\t\tbrelse(bh);\n\t\t\t\treturn error;\n\t\t\t}\n\t\t\telse if (error)\n\t\t\t\tjd->jd_found_revokes++;\n\n\t\t\tif (!--revokes)\n\t\t\t\tbreak;\n\t\t\toffset += sizeof(u64);\n\t\t}\n\n\t\tbrelse(bh);\n\t\toffset = sizeof(struct gfs2_meta_header);\n\t\tfirst = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic void revoke_lo_after_scan(struct gfs2_jdesc *jd, int error, int pass)\n{\n\tstruct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);\n\n\tif (error) {\n\t\tgfs2_revoke_clean(jd);\n\t\treturn;\n\t}\n\tif (pass != 1)\n\t\treturn;\n\n\tfs_info(sdp, \"jid=%u: Found %u revoke tags\\n\",\n\t        jd->jd_jid, jd->jd_found_revokes);\n\n\tgfs2_revoke_clean(jd);\n}\n\n \n\nstatic void databuf_lo_before_commit(struct gfs2_sbd *sdp, struct gfs2_trans *tr)\n{\n\tunsigned int limit = databuf_limit(sdp);\n\tunsigned int nbuf;\n\tif (tr == NULL)\n\t\treturn;\n\tnbuf = tr->tr_num_databuf_new - tr->tr_num_databuf_rm;\n\tgfs2_before_commit(sdp, limit, nbuf, &tr->tr_databuf, 1);\n}\n\nstatic int databuf_lo_scan_elements(struct gfs2_jdesc *jd, u32 start,\n\t\t\t\t    struct gfs2_log_descriptor *ld,\n\t\t\t\t    __be64 *ptr, int pass)\n{\n\tstruct gfs2_inode *ip = GFS2_I(jd->jd_inode);\n\tstruct gfs2_glock *gl = ip->i_gl;\n\tunsigned int blks = be32_to_cpu(ld->ld_data1);\n\tstruct buffer_head *bh_log, *bh_ip;\n\tu64 blkno;\n\tu64 esc;\n\tint error = 0;\n\n\tif (pass != 1 || be32_to_cpu(ld->ld_type) != GFS2_LOG_DESC_JDATA)\n\t\treturn 0;\n\n\tgfs2_replay_incr_blk(jd, &start);\n\tfor (; blks; gfs2_replay_incr_blk(jd, &start), blks--) {\n\t\tblkno = be64_to_cpu(*ptr++);\n\t\tesc = be64_to_cpu(*ptr++);\n\n\t\tjd->jd_found_blocks++;\n\n\t\tif (gfs2_revoke_check(jd, blkno, start))\n\t\t\tcontinue;\n\n\t\terror = gfs2_replay_read_block(jd, start, &bh_log);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\tbh_ip = gfs2_meta_new(gl, blkno);\n\t\tmemcpy(bh_ip->b_data, bh_log->b_data, bh_log->b_size);\n\n\t\t \n\t\tif (esc) {\n\t\t\t__be32 *eptr = (__be32 *)bh_ip->b_data;\n\t\t\t*eptr = cpu_to_be32(GFS2_MAGIC);\n\t\t}\n\t\tmark_buffer_dirty(bh_ip);\n\n\t\tbrelse(bh_log);\n\t\tbrelse(bh_ip);\n\n\t\tjd->jd_replayed_blocks++;\n\t}\n\n\treturn error;\n}\n\n \n\nstatic void databuf_lo_after_scan(struct gfs2_jdesc *jd, int error, int pass)\n{\n\tstruct gfs2_inode *ip = GFS2_I(jd->jd_inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);\n\n\tif (error) {\n\t\tgfs2_inode_metasync(ip->i_gl);\n\t\treturn;\n\t}\n\tif (pass != 1)\n\t\treturn;\n\n\t \n\tgfs2_inode_metasync(ip->i_gl);\n\n\tfs_info(sdp, \"jid=%u: Replayed %u of %u data blocks\\n\",\n\t\tjd->jd_jid, jd->jd_replayed_blocks, jd->jd_found_blocks);\n}\n\nstatic void databuf_lo_after_commit(struct gfs2_sbd *sdp, struct gfs2_trans *tr)\n{\n\tstruct list_head *head;\n\tstruct gfs2_bufdata *bd;\n\n\tif (tr == NULL)\n\t\treturn;\n\n\thead = &tr->tr_databuf;\n\twhile (!list_empty(head)) {\n\t\tbd = list_first_entry(head, struct gfs2_bufdata, bd_list);\n\t\tlist_del_init(&bd->bd_list);\n\t\tgfs2_unpin(sdp, bd->bd_bh, tr);\n\t}\n}\n\n\nstatic const struct gfs2_log_operations gfs2_buf_lops = {\n\t.lo_before_commit = buf_lo_before_commit,\n\t.lo_after_commit = buf_lo_after_commit,\n\t.lo_before_scan = buf_lo_before_scan,\n\t.lo_scan_elements = buf_lo_scan_elements,\n\t.lo_after_scan = buf_lo_after_scan,\n\t.lo_name = \"buf\",\n};\n\nstatic const struct gfs2_log_operations gfs2_revoke_lops = {\n\t.lo_before_commit = revoke_lo_before_commit,\n\t.lo_after_commit = revoke_lo_after_commit,\n\t.lo_before_scan = revoke_lo_before_scan,\n\t.lo_scan_elements = revoke_lo_scan_elements,\n\t.lo_after_scan = revoke_lo_after_scan,\n\t.lo_name = \"revoke\",\n};\n\nstatic const struct gfs2_log_operations gfs2_databuf_lops = {\n\t.lo_before_commit = databuf_lo_before_commit,\n\t.lo_after_commit = databuf_lo_after_commit,\n\t.lo_scan_elements = databuf_lo_scan_elements,\n\t.lo_after_scan = databuf_lo_after_scan,\n\t.lo_name = \"databuf\",\n};\n\nconst struct gfs2_log_operations *gfs2_log_ops[] = {\n\t&gfs2_databuf_lops,\n\t&gfs2_buf_lops,\n\t&gfs2_revoke_lops,\n\tNULL,\n};\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}