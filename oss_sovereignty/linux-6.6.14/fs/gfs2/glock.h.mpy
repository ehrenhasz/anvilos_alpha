{
  "module_name": "glock.h",
  "hash_id": "8f30352ee1022162e3b8e3a3cab6529ef0cff78726fc7b1280364a0d969db3c7",
  "original_prompt": "Ingested from linux-6.6.14/fs/gfs2/glock.h",
  "human_readable_source": " \n \n\n#ifndef __GLOCK_DOT_H__\n#define __GLOCK_DOT_H__\n\n#include <linux/sched.h>\n#include <linux/parser.h>\n#include \"incore.h\"\n#include \"util.h\"\n\n \n\nenum {\n\tOpt_jid,\n\tOpt_id,\n\tOpt_first,\n\tOpt_nodir,\n\tOpt_err,\n};\n\n \n\n#define LM_TYPE_RESERVED\t0x00\n#define LM_TYPE_NONDISK\t\t0x01\n#define LM_TYPE_INODE\t\t0x02\n#define LM_TYPE_RGRP\t\t0x03\n#define LM_TYPE_META\t\t0x04\n#define LM_TYPE_IOPEN\t\t0x05\n#define LM_TYPE_FLOCK\t\t0x06\n#define LM_TYPE_PLOCK\t\t0x07\n#define LM_TYPE_QUOTA\t\t0x08\n#define LM_TYPE_JOURNAL\t\t0x09\n\n \n\n#define LM_ST_UNLOCKED\t\t0\n#define LM_ST_EXCLUSIVE\t\t1\n#define LM_ST_DEFERRED\t\t2\n#define LM_ST_SHARED\t\t3\n\n \n\n#define LM_FLAG_TRY\t\t0x0001\n#define LM_FLAG_TRY_1CB\t\t0x0002\n#define LM_FLAG_NOEXP\t\t0x0004\n#define LM_FLAG_ANY\t\t0x0008\n#define LM_FLAG_NODE_SCOPE\t0x0020\n#define GL_ASYNC\t\t0x0040\n#define GL_EXACT\t\t0x0080\n#define GL_SKIP\t\t\t0x0100\n#define GL_NOPID\t\t0x0200\n#define GL_NOCACHE\t\t0x0400\n  \n \n\n#define LM_OUT_ST_MASK\t\t0x00000003\n#define LM_OUT_CANCELED\t\t0x00000008\n#define LM_OUT_ERROR\t\t0x00000004\n\n \n\n#define LM_RD_GAVEUP\t\t308\n#define LM_RD_SUCCESS\t\t309\n\n#define GLR_TRYFAILED\t\t13\n\n#define GL_GLOCK_MAX_HOLD        (long)(HZ / 5)\n#define GL_GLOCK_DFT_HOLD        (long)(HZ / 5)\n#define GL_GLOCK_MIN_HOLD        (long)(10)\n#define GL_GLOCK_HOLD_INCR       (long)(HZ / 20)\n#define GL_GLOCK_HOLD_DECR       (long)(HZ / 40)\n\nstruct lm_lockops {\n\tconst char *lm_proto_name;\n\tint (*lm_mount) (struct gfs2_sbd *sdp, const char *table);\n\tvoid (*lm_first_done) (struct gfs2_sbd *sdp);\n\tvoid (*lm_recovery_result) (struct gfs2_sbd *sdp, unsigned int jid,\n\t\t\t\t    unsigned int result);\n\tvoid (*lm_unmount) (struct gfs2_sbd *sdp);\n\tvoid (*lm_withdraw) (struct gfs2_sbd *sdp);\n\tvoid (*lm_put_lock) (struct gfs2_glock *gl);\n\tint (*lm_lock) (struct gfs2_glock *gl, unsigned int req_state,\n\t\t\tunsigned int flags);\n\tvoid (*lm_cancel) (struct gfs2_glock *gl);\n\tconst match_table_t *lm_tokens;\n};\n\nstruct gfs2_glock_aspace {\n\tstruct gfs2_glock glock;\n\tstruct address_space mapping;\n};\n\nstatic inline struct gfs2_holder *gfs2_glock_is_locked_by_me(struct gfs2_glock *gl)\n{\n\tstruct gfs2_holder *gh;\n\tstruct pid *pid;\n\n\t \n\tspin_lock(&gl->gl_lockref.lock);\n\tpid = task_pid(current);\n\tlist_for_each_entry(gh, &gl->gl_holders, gh_list) {\n\t\tif (!test_bit(HIF_HOLDER, &gh->gh_iflags))\n\t\t\tbreak;\n\t\tif (gh->gh_owner_pid == pid)\n\t\t\tgoto out;\n\t}\n\tgh = NULL;\nout:\n\tspin_unlock(&gl->gl_lockref.lock);\n\n\treturn gh;\n}\n\nstatic inline int gfs2_glock_is_held_excl(struct gfs2_glock *gl)\n{\n\treturn gl->gl_state == LM_ST_EXCLUSIVE;\n}\n\nstatic inline int gfs2_glock_is_held_dfrd(struct gfs2_glock *gl)\n{\n\treturn gl->gl_state == LM_ST_DEFERRED;\n}\n\nstatic inline int gfs2_glock_is_held_shrd(struct gfs2_glock *gl)\n{\n\treturn gl->gl_state == LM_ST_SHARED;\n}\n\nstatic inline struct address_space *gfs2_glock2aspace(struct gfs2_glock *gl)\n{\n\tif (gl->gl_ops->go_flags & GLOF_ASPACE) {\n\t\tstruct gfs2_glock_aspace *gla =\n\t\t\tcontainer_of(gl, struct gfs2_glock_aspace, glock);\n\t\treturn &gla->mapping;\n\t}\n\treturn NULL;\n}\n\nextern int gfs2_glock_get(struct gfs2_sbd *sdp, u64 number,\n\t\t\t  const struct gfs2_glock_operations *glops,\n\t\t\t  int create, struct gfs2_glock **glp);\nextern struct gfs2_glock *gfs2_glock_hold(struct gfs2_glock *gl);\nextern void gfs2_glock_put(struct gfs2_glock *gl);\nextern void gfs2_glock_queue_put(struct gfs2_glock *gl);\n\nextern void __gfs2_holder_init(struct gfs2_glock *gl, unsigned int state,\n\t\t\t       u16 flags, struct gfs2_holder *gh,\n\t\t\t       unsigned long ip);\nstatic inline void gfs2_holder_init(struct gfs2_glock *gl, unsigned int state,\n\t\t\t\t    u16 flags, struct gfs2_holder *gh) {\n\t__gfs2_holder_init(gl, state, flags, gh, _RET_IP_);\n}\n\nextern void gfs2_holder_reinit(unsigned int state, u16 flags,\n\t\t\t       struct gfs2_holder *gh);\nextern void gfs2_holder_uninit(struct gfs2_holder *gh);\nextern int gfs2_glock_nq(struct gfs2_holder *gh);\nextern int gfs2_glock_poll(struct gfs2_holder *gh);\nextern int gfs2_instantiate(struct gfs2_holder *gh);\nextern int gfs2_glock_holder_ready(struct gfs2_holder *gh);\nextern int gfs2_glock_wait(struct gfs2_holder *gh);\nextern int gfs2_glock_async_wait(unsigned int num_gh, struct gfs2_holder *ghs);\nextern void gfs2_glock_dq(struct gfs2_holder *gh);\nextern void gfs2_glock_dq_wait(struct gfs2_holder *gh);\nextern void gfs2_glock_dq_uninit(struct gfs2_holder *gh);\nextern int gfs2_glock_nq_num(struct gfs2_sbd *sdp, u64 number,\n\t\t\t     const struct gfs2_glock_operations *glops,\n\t\t\t     unsigned int state, u16 flags,\n\t\t\t     struct gfs2_holder *gh);\nextern int gfs2_glock_nq_m(unsigned int num_gh, struct gfs2_holder *ghs);\nextern void gfs2_glock_dq_m(unsigned int num_gh, struct gfs2_holder *ghs);\nextern void gfs2_dump_glock(struct seq_file *seq, struct gfs2_glock *gl,\n\t\t\t    bool fsid);\n#define GLOCK_BUG_ON(gl,x) do { if (unlikely(x)) {\t\t\\\n\t\t\tgfs2_dump_glock(NULL, gl, true);\t\\\n\t\t\tBUG(); } } while(0)\n#define gfs2_glock_assert_warn(gl, x) do { if (unlikely(!(x))) {\t\\\n\t\t\tgfs2_dump_glock(NULL, gl, true);\t\t\\\n\t\t\tgfs2_assert_warn((gl)->gl_name.ln_sbd, (x)); } } \\\n\twhile (0)\n#define gfs2_glock_assert_withdraw(gl, x) do { if (unlikely(!(x))) {\t\\\n\t\t\tgfs2_dump_glock(NULL, gl, true);\t\t\\\n\t\t\tgfs2_assert_withdraw((gl)->gl_name.ln_sbd, (x)); } } \\\n\twhile (0)\n\nextern __printf(2, 3)\nvoid gfs2_print_dbg(struct seq_file *seq, const char *fmt, ...);\n\n \n\nstatic inline int gfs2_glock_nq_init(struct gfs2_glock *gl,\n\t\t\t\t     unsigned int state, u16 flags,\n\t\t\t\t     struct gfs2_holder *gh)\n{\n\tint error;\n\n\t__gfs2_holder_init(gl, state, flags, gh, _RET_IP_);\n\n\terror = gfs2_glock_nq(gh);\n\tif (error)\n\t\tgfs2_holder_uninit(gh);\n\n\treturn error;\n}\n\nextern void gfs2_glock_cb(struct gfs2_glock *gl, unsigned int state);\nextern void gfs2_glock_complete(struct gfs2_glock *gl, int ret);\nextern bool gfs2_queue_try_to_evict(struct gfs2_glock *gl);\nextern void gfs2_cancel_delete_work(struct gfs2_glock *gl);\nextern void gfs2_flush_delete_work(struct gfs2_sbd *sdp);\nextern void gfs2_gl_hash_clear(struct gfs2_sbd *sdp);\nextern void gfs2_gl_dq_holders(struct gfs2_sbd *sdp);\nextern void gfs2_glock_thaw(struct gfs2_sbd *sdp);\nextern void gfs2_glock_add_to_lru(struct gfs2_glock *gl);\nextern void gfs2_glock_free(struct gfs2_glock *gl);\n\nextern int __init gfs2_glock_init(void);\nextern void gfs2_glock_exit(void);\n\nextern void gfs2_create_debugfs_file(struct gfs2_sbd *sdp);\nextern void gfs2_delete_debugfs_file(struct gfs2_sbd *sdp);\nextern void gfs2_register_debugfs(void);\nextern void gfs2_unregister_debugfs(void);\n\nextern void glock_set_object(struct gfs2_glock *gl, void *object);\nextern void glock_clear_object(struct gfs2_glock *gl, void *object);\n\nextern const struct lm_lockops gfs2_dlm_ops;\n\nstatic inline void gfs2_holder_mark_uninitialized(struct gfs2_holder *gh)\n{\n\tgh->gh_gl = NULL;\n}\n\nstatic inline bool gfs2_holder_initialized(struct gfs2_holder *gh)\n{\n\treturn gh->gh_gl;\n}\n\nstatic inline bool gfs2_holder_queued(struct gfs2_holder *gh)\n{\n\treturn !list_empty(&gh->gh_list);\n}\n\nextern void gfs2_inode_remember_delete(struct gfs2_glock *gl, u64 generation);\nextern bool gfs2_inode_already_deleted(struct gfs2_glock *gl, u64 generation);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}