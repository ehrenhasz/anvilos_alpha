{
  "module_name": "super.c",
  "hash_id": "62c16bc7c52d98f0cad539d30c54e3d8c07306f9bfb816620635637b87fa20fb",
  "original_prompt": "Ingested from linux-6.6.14/fs/gfs2/super.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/bio.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/completion.h>\n#include <linux/buffer_head.h>\n#include <linux/statfs.h>\n#include <linux/seq_file.h>\n#include <linux/mount.h>\n#include <linux/kthread.h>\n#include <linux/delay.h>\n#include <linux/gfs2_ondisk.h>\n#include <linux/crc32.h>\n#include <linux/time.h>\n#include <linux/wait.h>\n#include <linux/writeback.h>\n#include <linux/backing-dev.h>\n#include <linux/kernel.h>\n\n#include \"gfs2.h\"\n#include \"incore.h\"\n#include \"bmap.h\"\n#include \"dir.h\"\n#include \"glock.h\"\n#include \"glops.h\"\n#include \"inode.h\"\n#include \"log.h\"\n#include \"meta_io.h\"\n#include \"quota.h\"\n#include \"recovery.h\"\n#include \"rgrp.h\"\n#include \"super.h\"\n#include \"trans.h\"\n#include \"util.h\"\n#include \"sys.h\"\n#include \"xattr.h\"\n#include \"lops.h\"\n\nenum dinode_demise {\n\tSHOULD_DELETE_DINODE,\n\tSHOULD_NOT_DELETE_DINODE,\n\tSHOULD_DEFER_EVICTION,\n};\n\n \n\nvoid gfs2_jindex_free(struct gfs2_sbd *sdp)\n{\n\tstruct list_head list;\n\tstruct gfs2_jdesc *jd;\n\n\tspin_lock(&sdp->sd_jindex_spin);\n\tlist_add(&list, &sdp->sd_jindex_list);\n\tlist_del_init(&sdp->sd_jindex_list);\n\tsdp->sd_journals = 0;\n\tspin_unlock(&sdp->sd_jindex_spin);\n\n\tsdp->sd_jdesc = NULL;\n\twhile (!list_empty(&list)) {\n\t\tjd = list_first_entry(&list, struct gfs2_jdesc, jd_list);\n\t\tgfs2_free_journal_extents(jd);\n\t\tlist_del(&jd->jd_list);\n\t\tiput(jd->jd_inode);\n\t\tjd->jd_inode = NULL;\n\t\tkfree(jd);\n\t}\n}\n\nstatic struct gfs2_jdesc *jdesc_find_i(struct list_head *head, unsigned int jid)\n{\n\tstruct gfs2_jdesc *jd;\n\n\tlist_for_each_entry(jd, head, jd_list) {\n\t\tif (jd->jd_jid == jid)\n\t\t\treturn jd;\n\t}\n\treturn NULL;\n}\n\nstruct gfs2_jdesc *gfs2_jdesc_find(struct gfs2_sbd *sdp, unsigned int jid)\n{\n\tstruct gfs2_jdesc *jd;\n\n\tspin_lock(&sdp->sd_jindex_spin);\n\tjd = jdesc_find_i(&sdp->sd_jindex_list, jid);\n\tspin_unlock(&sdp->sd_jindex_spin);\n\n\treturn jd;\n}\n\nint gfs2_jdesc_check(struct gfs2_jdesc *jd)\n{\n\tstruct gfs2_inode *ip = GFS2_I(jd->jd_inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);\n\tu64 size = i_size_read(jd->jd_inode);\n\n\tif (gfs2_check_internal_file_size(jd->jd_inode, 8 << 20, BIT(30)))\n\t\treturn -EIO;\n\n\tjd->jd_blocks = size >> sdp->sd_sb.sb_bsize_shift;\n\n\tif (gfs2_write_alloc_required(ip, 0, size)) {\n\t\tgfs2_consist_inode(ip);\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \n\nint gfs2_make_fs_rw(struct gfs2_sbd *sdp)\n{\n\tstruct gfs2_inode *ip = GFS2_I(sdp->sd_jdesc->jd_inode);\n\tstruct gfs2_glock *j_gl = ip->i_gl;\n\tstruct gfs2_log_header_host head;\n\tint error;\n\n\tj_gl->gl_ops->go_inval(j_gl, DIO_METADATA);\n\tif (gfs2_withdrawn(sdp))\n\t\treturn -EIO;\n\n\terror = gfs2_find_jhead(sdp->sd_jdesc, &head, false);\n\tif (error) {\n\t\tgfs2_consist(sdp);\n\t\treturn error;\n\t}\n\n\tif (!(head.lh_flags & GFS2_LOG_HEAD_UNMOUNT)) {\n\t\tgfs2_consist(sdp);\n\t\treturn -EIO;\n\t}\n\n\t \n\tsdp->sd_log_sequence = head.lh_sequence + 1;\n\tgfs2_log_pointers_init(sdp, head.lh_blkno);\n\n\terror = gfs2_quota_init(sdp);\n\tif (!error && gfs2_withdrawn(sdp))\n\t\terror = -EIO;\n\tif (!error)\n\t\tset_bit(SDF_JOURNAL_LIVE, &sdp->sd_flags);\n\treturn error;\n}\n\nvoid gfs2_statfs_change_in(struct gfs2_statfs_change_host *sc, const void *buf)\n{\n\tconst struct gfs2_statfs_change *str = buf;\n\n\tsc->sc_total = be64_to_cpu(str->sc_total);\n\tsc->sc_free = be64_to_cpu(str->sc_free);\n\tsc->sc_dinodes = be64_to_cpu(str->sc_dinodes);\n}\n\nvoid gfs2_statfs_change_out(const struct gfs2_statfs_change_host *sc, void *buf)\n{\n\tstruct gfs2_statfs_change *str = buf;\n\n\tstr->sc_total = cpu_to_be64(sc->sc_total);\n\tstr->sc_free = cpu_to_be64(sc->sc_free);\n\tstr->sc_dinodes = cpu_to_be64(sc->sc_dinodes);\n}\n\nint gfs2_statfs_init(struct gfs2_sbd *sdp)\n{\n\tstruct gfs2_inode *m_ip = GFS2_I(sdp->sd_statfs_inode);\n\tstruct gfs2_statfs_change_host *m_sc = &sdp->sd_statfs_master;\n\tstruct gfs2_statfs_change_host *l_sc = &sdp->sd_statfs_local;\n\tstruct buffer_head *m_bh;\n\tstruct gfs2_holder gh;\n\tint error;\n\n\terror = gfs2_glock_nq_init(m_ip->i_gl, LM_ST_EXCLUSIVE, GL_NOCACHE,\n\t\t\t\t   &gh);\n\tif (error)\n\t\treturn error;\n\n\terror = gfs2_meta_inode_buffer(m_ip, &m_bh);\n\tif (error)\n\t\tgoto out;\n\n\tif (sdp->sd_args.ar_spectator) {\n\t\tspin_lock(&sdp->sd_statfs_spin);\n\t\tgfs2_statfs_change_in(m_sc, m_bh->b_data +\n\t\t\t\t      sizeof(struct gfs2_dinode));\n\t\tspin_unlock(&sdp->sd_statfs_spin);\n\t} else {\n\t\tspin_lock(&sdp->sd_statfs_spin);\n\t\tgfs2_statfs_change_in(m_sc, m_bh->b_data +\n\t\t\t\t      sizeof(struct gfs2_dinode));\n\t\tgfs2_statfs_change_in(l_sc, sdp->sd_sc_bh->b_data +\n\t\t\t\t      sizeof(struct gfs2_dinode));\n\t\tspin_unlock(&sdp->sd_statfs_spin);\n\n\t}\n\n\tbrelse(m_bh);\nout:\n\tgfs2_glock_dq_uninit(&gh);\n\treturn 0;\n}\n\nvoid gfs2_statfs_change(struct gfs2_sbd *sdp, s64 total, s64 free,\n\t\t\ts64 dinodes)\n{\n\tstruct gfs2_inode *l_ip = GFS2_I(sdp->sd_sc_inode);\n\tstruct gfs2_statfs_change_host *l_sc = &sdp->sd_statfs_local;\n\tstruct gfs2_statfs_change_host *m_sc = &sdp->sd_statfs_master;\n\ts64 x, y;\n\tint need_sync = 0;\n\n\tgfs2_trans_add_meta(l_ip->i_gl, sdp->sd_sc_bh);\n\n\tspin_lock(&sdp->sd_statfs_spin);\n\tl_sc->sc_total += total;\n\tl_sc->sc_free += free;\n\tl_sc->sc_dinodes += dinodes;\n\tgfs2_statfs_change_out(l_sc, sdp->sd_sc_bh->b_data +\n\t\t\t       sizeof(struct gfs2_dinode));\n\tif (sdp->sd_args.ar_statfs_percent) {\n\t\tx = 100 * l_sc->sc_free;\n\t\ty = m_sc->sc_free * sdp->sd_args.ar_statfs_percent;\n\t\tif (x >= y || x <= -y)\n\t\t\tneed_sync = 1;\n\t}\n\tspin_unlock(&sdp->sd_statfs_spin);\n\n\tif (need_sync)\n\t\tgfs2_wake_up_statfs(sdp);\n}\n\nvoid update_statfs(struct gfs2_sbd *sdp, struct buffer_head *m_bh)\n{\n\tstruct gfs2_inode *m_ip = GFS2_I(sdp->sd_statfs_inode);\n\tstruct gfs2_inode *l_ip = GFS2_I(sdp->sd_sc_inode);\n\tstruct gfs2_statfs_change_host *m_sc = &sdp->sd_statfs_master;\n\tstruct gfs2_statfs_change_host *l_sc = &sdp->sd_statfs_local;\n\n\tgfs2_trans_add_meta(l_ip->i_gl, sdp->sd_sc_bh);\n\tgfs2_trans_add_meta(m_ip->i_gl, m_bh);\n\n\tspin_lock(&sdp->sd_statfs_spin);\n\tm_sc->sc_total += l_sc->sc_total;\n\tm_sc->sc_free += l_sc->sc_free;\n\tm_sc->sc_dinodes += l_sc->sc_dinodes;\n\tmemset(l_sc, 0, sizeof(struct gfs2_statfs_change));\n\tmemset(sdp->sd_sc_bh->b_data + sizeof(struct gfs2_dinode),\n\t       0, sizeof(struct gfs2_statfs_change));\n\tgfs2_statfs_change_out(m_sc, m_bh->b_data + sizeof(struct gfs2_dinode));\n\tspin_unlock(&sdp->sd_statfs_spin);\n}\n\nint gfs2_statfs_sync(struct super_block *sb, int type)\n{\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\tstruct gfs2_inode *m_ip = GFS2_I(sdp->sd_statfs_inode);\n\tstruct gfs2_statfs_change_host *m_sc = &sdp->sd_statfs_master;\n\tstruct gfs2_statfs_change_host *l_sc = &sdp->sd_statfs_local;\n\tstruct gfs2_holder gh;\n\tstruct buffer_head *m_bh;\n\tint error;\n\n\terror = gfs2_glock_nq_init(m_ip->i_gl, LM_ST_EXCLUSIVE, GL_NOCACHE,\n\t\t\t\t   &gh);\n\tif (error)\n\t\tgoto out;\n\n\terror = gfs2_meta_inode_buffer(m_ip, &m_bh);\n\tif (error)\n\t\tgoto out_unlock;\n\n\tspin_lock(&sdp->sd_statfs_spin);\n\tgfs2_statfs_change_in(m_sc, m_bh->b_data +\n\t\t\t      sizeof(struct gfs2_dinode));\n\tif (!l_sc->sc_total && !l_sc->sc_free && !l_sc->sc_dinodes) {\n\t\tspin_unlock(&sdp->sd_statfs_spin);\n\t\tgoto out_bh;\n\t}\n\tspin_unlock(&sdp->sd_statfs_spin);\n\n\terror = gfs2_trans_begin(sdp, 2 * RES_DINODE, 0);\n\tif (error)\n\t\tgoto out_bh;\n\n\tupdate_statfs(sdp, m_bh);\n\tsdp->sd_statfs_force_sync = 0;\n\n\tgfs2_trans_end(sdp);\n\nout_bh:\n\tbrelse(m_bh);\nout_unlock:\n\tgfs2_glock_dq_uninit(&gh);\nout:\n\treturn error;\n}\n\nstruct lfcc {\n\tstruct list_head list;\n\tstruct gfs2_holder gh;\n};\n\n \n\nstatic int gfs2_lock_fs_check_clean(struct gfs2_sbd *sdp)\n{\n\tstruct gfs2_inode *ip;\n\tstruct gfs2_jdesc *jd;\n\tstruct lfcc *lfcc;\n\tLIST_HEAD(list);\n\tstruct gfs2_log_header_host lh;\n\tint error, error2;\n\n\t \n\n\tlist_for_each_entry(jd, &sdp->sd_jindex_list, jd_list) {\n\t\tlfcc = kmalloc(sizeof(struct lfcc), GFP_KERNEL);\n\t\tif (!lfcc) {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tip = GFS2_I(jd->jd_inode);\n\t\terror = gfs2_glock_nq_init(ip->i_gl, LM_ST_SHARED, 0, &lfcc->gh);\n\t\tif (error) {\n\t\t\tkfree(lfcc);\n\t\t\tgoto out;\n\t\t}\n\t\tlist_add(&lfcc->list, &list);\n\t}\n\n\tgfs2_freeze_unlock(&sdp->sd_freeze_gh);\n\n\terror = gfs2_glock_nq_init(sdp->sd_freeze_gl, LM_ST_EXCLUSIVE,\n\t\t\t\t   LM_FLAG_NOEXP | GL_NOPID,\n\t\t\t\t   &sdp->sd_freeze_gh);\n\tif (error)\n\t\tgoto relock_shared;\n\n\tlist_for_each_entry(jd, &sdp->sd_jindex_list, jd_list) {\n\t\terror = gfs2_jdesc_check(jd);\n\t\tif (error)\n\t\t\tbreak;\n\t\terror = gfs2_find_jhead(jd, &lh, false);\n\t\tif (error)\n\t\t\tbreak;\n\t\tif (!(lh.lh_flags & GFS2_LOG_HEAD_UNMOUNT)) {\n\t\t\terror = -EBUSY;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!error)\n\t\tgoto out;   \n\n\tgfs2_freeze_unlock(&sdp->sd_freeze_gh);\n\nrelock_shared:\n\terror2 = gfs2_freeze_lock_shared(sdp);\n\tgfs2_assert_withdraw(sdp, !error2);\n\nout:\n\twhile (!list_empty(&list)) {\n\t\tlfcc = list_first_entry(&list, struct lfcc, list);\n\t\tlist_del(&lfcc->list);\n\t\tgfs2_glock_dq_uninit(&lfcc->gh);\n\t\tkfree(lfcc);\n\t}\n\treturn error;\n}\n\nvoid gfs2_dinode_out(const struct gfs2_inode *ip, void *buf)\n{\n\tconst struct inode *inode = &ip->i_inode;\n\tstruct gfs2_dinode *str = buf;\n\n\tstr->di_header.mh_magic = cpu_to_be32(GFS2_MAGIC);\n\tstr->di_header.mh_type = cpu_to_be32(GFS2_METATYPE_DI);\n\tstr->di_header.mh_format = cpu_to_be32(GFS2_FORMAT_DI);\n\tstr->di_num.no_addr = cpu_to_be64(ip->i_no_addr);\n\tstr->di_num.no_formal_ino = cpu_to_be64(ip->i_no_formal_ino);\n\tstr->di_mode = cpu_to_be32(inode->i_mode);\n\tstr->di_uid = cpu_to_be32(i_uid_read(inode));\n\tstr->di_gid = cpu_to_be32(i_gid_read(inode));\n\tstr->di_nlink = cpu_to_be32(inode->i_nlink);\n\tstr->di_size = cpu_to_be64(i_size_read(inode));\n\tstr->di_blocks = cpu_to_be64(gfs2_get_inode_blocks(inode));\n\tstr->di_atime = cpu_to_be64(inode->i_atime.tv_sec);\n\tstr->di_mtime = cpu_to_be64(inode->i_mtime.tv_sec);\n\tstr->di_ctime = cpu_to_be64(inode_get_ctime(inode).tv_sec);\n\n\tstr->di_goal_meta = cpu_to_be64(ip->i_goal);\n\tstr->di_goal_data = cpu_to_be64(ip->i_goal);\n\tstr->di_generation = cpu_to_be64(ip->i_generation);\n\n\tstr->di_flags = cpu_to_be32(ip->i_diskflags);\n\tstr->di_height = cpu_to_be16(ip->i_height);\n\tstr->di_payload_format = cpu_to_be32(S_ISDIR(inode->i_mode) &&\n\t\t\t\t\t     !(ip->i_diskflags & GFS2_DIF_EXHASH) ?\n\t\t\t\t\t     GFS2_FORMAT_DE : 0);\n\tstr->di_depth = cpu_to_be16(ip->i_depth);\n\tstr->di_entries = cpu_to_be32(ip->i_entries);\n\n\tstr->di_eattr = cpu_to_be64(ip->i_eattr);\n\tstr->di_atime_nsec = cpu_to_be32(inode->i_atime.tv_nsec);\n\tstr->di_mtime_nsec = cpu_to_be32(inode->i_mtime.tv_nsec);\n\tstr->di_ctime_nsec = cpu_to_be32(inode_get_ctime(inode).tv_nsec);\n}\n\n \n\nstatic int gfs2_write_inode(struct inode *inode, struct writeback_control *wbc)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct address_space *metamapping = gfs2_glock2aspace(ip->i_gl);\n\tstruct backing_dev_info *bdi = inode_to_bdi(metamapping->host);\n\tint ret = 0;\n\tbool flush_all = (wbc->sync_mode == WB_SYNC_ALL || gfs2_is_jdata(ip));\n\n\tif (flush_all)\n\t\tgfs2_log_flush(GFS2_SB(inode), ip->i_gl,\n\t\t\t       GFS2_LOG_HEAD_FLUSH_NORMAL |\n\t\t\t       GFS2_LFC_WRITE_INODE);\n\tif (bdi->wb.dirty_exceeded)\n\t\tgfs2_ail1_flush(sdp, wbc);\n\telse\n\t\tfilemap_fdatawrite(metamapping);\n\tif (flush_all)\n\t\tret = filemap_fdatawait(metamapping);\n\tif (ret)\n\t\tmark_inode_dirty_sync(inode);\n\telse {\n\t\tspin_lock(&inode->i_lock);\n\t\tif (!(inode->i_flags & I_DIRTY))\n\t\t\tgfs2_ordered_del_inode(ip);\n\t\tspin_unlock(&inode->i_lock);\n\t}\n\treturn ret;\n}\n\n \n\nstatic void gfs2_dirty_inode(struct inode *inode, int flags)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct buffer_head *bh;\n\tstruct gfs2_holder gh;\n\tint need_unlock = 0;\n\tint need_endtrans = 0;\n\tint ret;\n\n\tif (unlikely(!ip->i_gl)) {\n\t\t \n\t\tBUG_ON(!test_bit(GIF_ALLOC_FAILED, &ip->i_flags));\n\t\treturn;\n\t}\n\n\tif (unlikely(gfs2_withdrawn(sdp)))\n\t\treturn;\n\tif (!gfs2_glock_is_locked_by_me(ip->i_gl)) {\n\t\tret = gfs2_glock_nq_init(ip->i_gl, LM_ST_EXCLUSIVE, 0, &gh);\n\t\tif (ret) {\n\t\t\tfs_err(sdp, \"dirty_inode: glock %d\\n\", ret);\n\t\t\tgfs2_dump_glock(NULL, ip->i_gl, true);\n\t\t\treturn;\n\t\t}\n\t\tneed_unlock = 1;\n\t} else if (WARN_ON_ONCE(ip->i_gl->gl_state != LM_ST_EXCLUSIVE))\n\t\treturn;\n\n\tif (current->journal_info == NULL) {\n\t\tret = gfs2_trans_begin(sdp, RES_DINODE, 0);\n\t\tif (ret) {\n\t\t\tfs_err(sdp, \"dirty_inode: gfs2_trans_begin %d\\n\", ret);\n\t\t\tgoto out;\n\t\t}\n\t\tneed_endtrans = 1;\n\t}\n\n\tret = gfs2_meta_inode_buffer(ip, &bh);\n\tif (ret == 0) {\n\t\tgfs2_trans_add_meta(ip->i_gl, bh);\n\t\tgfs2_dinode_out(ip, bh->b_data);\n\t\tbrelse(bh);\n\t}\n\n\tif (need_endtrans)\n\t\tgfs2_trans_end(sdp);\nout:\n\tif (need_unlock)\n\t\tgfs2_glock_dq_uninit(&gh);\n}\n\n \n\nvoid gfs2_make_fs_ro(struct gfs2_sbd *sdp)\n{\n\tint log_write_allowed = test_bit(SDF_JOURNAL_LIVE, &sdp->sd_flags);\n\n\tif (!test_bit(SDF_KILL, &sdp->sd_flags))\n\t\tgfs2_flush_delete_work(sdp);\n\n\tgfs2_destroy_threads(sdp);\n\n\tif (log_write_allowed) {\n\t\tgfs2_quota_sync(sdp->sd_vfs, 0);\n\t\tgfs2_statfs_sync(sdp->sd_vfs, 0);\n\n\t\t \n\t\tgfs2_log_flush(sdp, NULL, GFS2_LFC_MAKE_FS_RO);\n\t\tgfs2_log_flush(sdp, NULL, GFS2_LOG_HEAD_FLUSH_SHUTDOWN |\n\t\t\t       GFS2_LFC_MAKE_FS_RO);\n\t\twait_event_timeout(sdp->sd_log_waitq,\n\t\t\t\t   gfs2_log_is_empty(sdp),\n\t\t\t\t   HZ * 5);\n\t\tgfs2_assert_warn(sdp, gfs2_log_is_empty(sdp));\n\t}\n\tgfs2_quota_cleanup(sdp);\n}\n\n \n\nstatic void gfs2_put_super(struct super_block *sb)\n{\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\tstruct gfs2_jdesc *jd;\n\n\t \n\tset_bit(SDF_NORECOVERY, &sdp->sd_flags);\n\tsmp_mb();\n\n\t \nrestart:\n\tspin_lock(&sdp->sd_jindex_spin);\n\tlist_for_each_entry(jd, &sdp->sd_jindex_list, jd_list) {\n\t\tif (!test_bit(JDF_RECOVERY, &jd->jd_flags))\n\t\t\tcontinue;\n\t\tspin_unlock(&sdp->sd_jindex_spin);\n\t\twait_on_bit(&jd->jd_flags, JDF_RECOVERY,\n\t\t\t    TASK_UNINTERRUPTIBLE);\n\t\tgoto restart;\n\t}\n\tspin_unlock(&sdp->sd_jindex_spin);\n\n\tif (!sb_rdonly(sb))\n\t\tgfs2_make_fs_ro(sdp);\n\telse {\n\t\tif (gfs2_withdrawn(sdp))\n\t\t\tgfs2_destroy_threads(sdp);\n\n\t\tgfs2_quota_cleanup(sdp);\n\t}\n\n\tWARN_ON(gfs2_withdrawing(sdp));\n\n\t \n\n\t \n\n\tgfs2_freeze_unlock(&sdp->sd_freeze_gh);\n\n\tiput(sdp->sd_jindex);\n\tiput(sdp->sd_statfs_inode);\n\tiput(sdp->sd_rindex);\n\tiput(sdp->sd_quota_inode);\n\n\tgfs2_glock_put(sdp->sd_rename_gl);\n\tgfs2_glock_put(sdp->sd_freeze_gl);\n\n\tif (!sdp->sd_args.ar_spectator) {\n\t\tif (gfs2_holder_initialized(&sdp->sd_journal_gh))\n\t\t\tgfs2_glock_dq_uninit(&sdp->sd_journal_gh);\n\t\tif (gfs2_holder_initialized(&sdp->sd_jinode_gh))\n\t\t\tgfs2_glock_dq_uninit(&sdp->sd_jinode_gh);\n\t\tbrelse(sdp->sd_sc_bh);\n\t\tgfs2_glock_dq_uninit(&sdp->sd_sc_gh);\n\t\tgfs2_glock_dq_uninit(&sdp->sd_qc_gh);\n\t\tfree_local_statfs_inodes(sdp);\n\t\tiput(sdp->sd_qc_inode);\n\t}\n\n\tgfs2_glock_dq_uninit(&sdp->sd_live_gh);\n\tgfs2_clear_rgrpd(sdp);\n\tgfs2_jindex_free(sdp);\n\t \n\tgfs2_gl_hash_clear(sdp);\n\ttruncate_inode_pages_final(&sdp->sd_aspace);\n\tgfs2_delete_debugfs_file(sdp);\n\t \n\tgfs2_lm_unmount(sdp);\n\n\t \n\tgfs2_sys_fs_del(sdp);\n\tfree_sbd(sdp);\n}\n\n \n\nstatic int gfs2_sync_fs(struct super_block *sb, int wait)\n{\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\n\tgfs2_quota_sync(sb, -1);\n\tif (wait)\n\t\tgfs2_log_flush(sdp, NULL, GFS2_LOG_HEAD_FLUSH_NORMAL |\n\t\t\t       GFS2_LFC_SYNC_FS);\n\treturn sdp->sd_log_error;\n}\n\nstatic int gfs2_freeze_locally(struct gfs2_sbd *sdp)\n{\n\tstruct super_block *sb = sdp->sd_vfs;\n\tint error;\n\n\terror = freeze_super(sb, FREEZE_HOLDER_USERSPACE);\n\tif (error)\n\t\treturn error;\n\n\tif (test_bit(SDF_JOURNAL_LIVE, &sdp->sd_flags)) {\n\t\tgfs2_log_flush(sdp, NULL, GFS2_LOG_HEAD_FLUSH_FREEZE |\n\t\t\t       GFS2_LFC_FREEZE_GO_SYNC);\n\t\tif (gfs2_withdrawn(sdp)) {\n\t\t\terror = thaw_super(sb, FREEZE_HOLDER_USERSPACE);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int gfs2_do_thaw(struct gfs2_sbd *sdp)\n{\n\tstruct super_block *sb = sdp->sd_vfs;\n\tint error;\n\n\terror = gfs2_freeze_lock_shared(sdp);\n\tif (error)\n\t\tgoto fail;\n\terror = thaw_super(sb, FREEZE_HOLDER_USERSPACE);\n\tif (!error)\n\t\treturn 0;\n\nfail:\n\tfs_info(sdp, \"GFS2: couldn't thaw filesystem: %d\\n\", error);\n\tgfs2_assert_withdraw(sdp, 0);\n\treturn error;\n}\n\nvoid gfs2_freeze_func(struct work_struct *work)\n{\n\tstruct gfs2_sbd *sdp = container_of(work, struct gfs2_sbd, sd_freeze_work);\n\tstruct super_block *sb = sdp->sd_vfs;\n\tint error;\n\n\tmutex_lock(&sdp->sd_freeze_mutex);\n\terror = -EBUSY;\n\tif (test_bit(SDF_FROZEN, &sdp->sd_flags))\n\t\tgoto freeze_failed;\n\n\terror = gfs2_freeze_locally(sdp);\n\tif (error)\n\t\tgoto freeze_failed;\n\n\tgfs2_freeze_unlock(&sdp->sd_freeze_gh);\n\tset_bit(SDF_FROZEN, &sdp->sd_flags);\n\n\terror = gfs2_do_thaw(sdp);\n\tif (error)\n\t\tgoto out;\n\n\tclear_bit(SDF_FROZEN, &sdp->sd_flags);\n\tgoto out;\n\nfreeze_failed:\n\tfs_info(sdp, \"GFS2: couldn't freeze filesystem: %d\\n\", error);\n\nout:\n\tmutex_unlock(&sdp->sd_freeze_mutex);\n\tdeactivate_super(sb);\n}\n\n \n\nstatic int gfs2_freeze_super(struct super_block *sb, enum freeze_holder who)\n{\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\tint error;\n\n\tif (!mutex_trylock(&sdp->sd_freeze_mutex))\n\t\treturn -EBUSY;\n\terror = -EBUSY;\n\tif (test_bit(SDF_FROZEN, &sdp->sd_flags))\n\t\tgoto out;\n\n\tfor (;;) {\n\t\terror = gfs2_freeze_locally(sdp);\n\t\tif (error) {\n\t\t\tfs_info(sdp, \"GFS2: couldn't freeze filesystem: %d\\n\",\n\t\t\t\terror);\n\t\t\tgoto out;\n\t\t}\n\n\t\terror = gfs2_lock_fs_check_clean(sdp);\n\t\tif (!error)\n\t\t\tbreak;   \n\n\t\terror = gfs2_do_thaw(sdp);\n\t\tif (error)\n\t\t\tgoto out;\n\n\t\tif (error == -EBUSY)\n\t\t\tfs_err(sdp, \"waiting for recovery before freeze\\n\");\n\t\telse if (error == -EIO) {\n\t\t\tfs_err(sdp, \"Fatal IO error: cannot freeze gfs2 due \"\n\t\t\t       \"to recovery error.\\n\");\n\t\t\tgoto out;\n\t\t} else {\n\t\t\tfs_err(sdp, \"error freezing FS: %d\\n\", error);\n\t\t}\n\t\tfs_err(sdp, \"retrying...\\n\");\n\t\tmsleep(1000);\n\t}\n\nout:\n\tif (!error) {\n\t\tset_bit(SDF_FREEZE_INITIATOR, &sdp->sd_flags);\n\t\tset_bit(SDF_FROZEN, &sdp->sd_flags);\n\t}\n\tmutex_unlock(&sdp->sd_freeze_mutex);\n\treturn error;\n}\n\n \n\nstatic int gfs2_thaw_super(struct super_block *sb, enum freeze_holder who)\n{\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\tint error;\n\n\tif (!mutex_trylock(&sdp->sd_freeze_mutex))\n\t\treturn -EBUSY;\n\terror = -EINVAL;\n\tif (!test_bit(SDF_FREEZE_INITIATOR, &sdp->sd_flags))\n\t\tgoto out;\n\n\tgfs2_freeze_unlock(&sdp->sd_freeze_gh);\n\n\terror = gfs2_do_thaw(sdp);\n\n\tif (!error) {\n\t\tclear_bit(SDF_FREEZE_INITIATOR, &sdp->sd_flags);\n\t\tclear_bit(SDF_FROZEN, &sdp->sd_flags);\n\t}\nout:\n\tmutex_unlock(&sdp->sd_freeze_mutex);\n\treturn error;\n}\n\nvoid gfs2_thaw_freeze_initiator(struct super_block *sb)\n{\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\n\tmutex_lock(&sdp->sd_freeze_mutex);\n\tif (!test_bit(SDF_FREEZE_INITIATOR, &sdp->sd_flags))\n\t\tgoto out;\n\n\tgfs2_freeze_unlock(&sdp->sd_freeze_gh);\n\nout:\n\tmutex_unlock(&sdp->sd_freeze_mutex);\n}\n\n \n\nstatic int statfs_slow_fill(struct gfs2_rgrpd *rgd,\n\t\t\t    struct gfs2_statfs_change_host *sc)\n{\n\tgfs2_rgrp_verify(rgd);\n\tsc->sc_total += rgd->rd_data;\n\tsc->sc_free += rgd->rd_free;\n\tsc->sc_dinodes += rgd->rd_dinodes;\n\treturn 0;\n}\n\n \n\nstatic int gfs2_statfs_slow(struct gfs2_sbd *sdp, struct gfs2_statfs_change_host *sc)\n{\n\tstruct gfs2_rgrpd *rgd_next;\n\tstruct gfs2_holder *gha, *gh;\n\tunsigned int slots = 64;\n\tunsigned int x;\n\tint done;\n\tint error = 0, err;\n\n\tmemset(sc, 0, sizeof(struct gfs2_statfs_change_host));\n\tgha = kmalloc_array(slots, sizeof(struct gfs2_holder), GFP_KERNEL);\n\tif (!gha)\n\t\treturn -ENOMEM;\n\tfor (x = 0; x < slots; x++)\n\t\tgfs2_holder_mark_uninitialized(gha + x);\n\n\trgd_next = gfs2_rgrpd_get_first(sdp);\n\n\tfor (;;) {\n\t\tdone = 1;\n\n\t\tfor (x = 0; x < slots; x++) {\n\t\t\tgh = gha + x;\n\n\t\t\tif (gfs2_holder_initialized(gh) && gfs2_glock_poll(gh)) {\n\t\t\t\terr = gfs2_glock_wait(gh);\n\t\t\t\tif (err) {\n\t\t\t\t\tgfs2_holder_uninit(gh);\n\t\t\t\t\terror = err;\n\t\t\t\t} else {\n\t\t\t\t\tif (!error) {\n\t\t\t\t\t\tstruct gfs2_rgrpd *rgd =\n\t\t\t\t\t\t\tgfs2_glock2rgrp(gh->gh_gl);\n\n\t\t\t\t\t\terror = statfs_slow_fill(rgd, sc);\n\t\t\t\t\t}\n\t\t\t\t\tgfs2_glock_dq_uninit(gh);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (gfs2_holder_initialized(gh))\n\t\t\t\tdone = 0;\n\t\t\telse if (rgd_next && !error) {\n\t\t\t\terror = gfs2_glock_nq_init(rgd_next->rd_gl,\n\t\t\t\t\t\t\t   LM_ST_SHARED,\n\t\t\t\t\t\t\t   GL_ASYNC,\n\t\t\t\t\t\t\t   gh);\n\t\t\t\trgd_next = gfs2_rgrpd_get_next(rgd_next);\n\t\t\t\tdone = 0;\n\t\t\t}\n\n\t\t\tif (signal_pending(current))\n\t\t\t\terror = -ERESTARTSYS;\n\t\t}\n\n\t\tif (done)\n\t\t\tbreak;\n\n\t\tyield();\n\t}\n\n\tkfree(gha);\n\treturn error;\n}\n\n \n\nstatic int gfs2_statfs_i(struct gfs2_sbd *sdp, struct gfs2_statfs_change_host *sc)\n{\n\tstruct gfs2_statfs_change_host *m_sc = &sdp->sd_statfs_master;\n\tstruct gfs2_statfs_change_host *l_sc = &sdp->sd_statfs_local;\n\n\tspin_lock(&sdp->sd_statfs_spin);\n\n\t*sc = *m_sc;\n\tsc->sc_total += l_sc->sc_total;\n\tsc->sc_free += l_sc->sc_free;\n\tsc->sc_dinodes += l_sc->sc_dinodes;\n\n\tspin_unlock(&sdp->sd_statfs_spin);\n\n\tif (sc->sc_free < 0)\n\t\tsc->sc_free = 0;\n\tif (sc->sc_free > sc->sc_total)\n\t\tsc->sc_free = sc->sc_total;\n\tif (sc->sc_dinodes < 0)\n\t\tsc->sc_dinodes = 0;\n\n\treturn 0;\n}\n\n \n\nstatic int gfs2_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct super_block *sb = dentry->d_sb;\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\tstruct gfs2_statfs_change_host sc;\n\tint error;\n\n\terror = gfs2_rindex_update(sdp);\n\tif (error)\n\t\treturn error;\n\n\tif (gfs2_tune_get(sdp, gt_statfs_slow))\n\t\terror = gfs2_statfs_slow(sdp, &sc);\n\telse\n\t\terror = gfs2_statfs_i(sdp, &sc);\n\n\tif (error)\n\t\treturn error;\n\n\tbuf->f_type = GFS2_MAGIC;\n\tbuf->f_bsize = sdp->sd_sb.sb_bsize;\n\tbuf->f_blocks = sc.sc_total;\n\tbuf->f_bfree = sc.sc_free;\n\tbuf->f_bavail = sc.sc_free;\n\tbuf->f_files = sc.sc_dinodes + sc.sc_free;\n\tbuf->f_ffree = sc.sc_free;\n\tbuf->f_namelen = GFS2_FNAMESIZE;\n\n\treturn 0;\n}\n\n \n\nstatic int gfs2_drop_inode(struct inode *inode)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\n\tif (inode->i_nlink &&\n\t    gfs2_holder_initialized(&ip->i_iopen_gh)) {\n\t\tstruct gfs2_glock *gl = ip->i_iopen_gh.gh_gl;\n\t\tif (test_bit(GLF_DEMOTE, &gl->gl_flags))\n\t\t\tclear_nlink(inode);\n\t}\n\n\t \n\tif (!inode->i_nlink &&\n\t    unlikely(current->flags & PF_MEMALLOC) &&\n\t    gfs2_holder_initialized(&ip->i_iopen_gh)) {\n\t\tstruct gfs2_glock *gl = ip->i_iopen_gh.gh_gl;\n\n\t\tgfs2_glock_hold(gl);\n\t\tif (!gfs2_queue_try_to_evict(gl))\n\t\t\tgfs2_glock_queue_put(gl);\n\t\treturn 0;\n\t}\n\n\t \n\tif (test_bit(SDF_EVICTING, &sdp->sd_flags))\n\t\treturn 1;\n\n\treturn generic_drop_inode(inode);\n}\n\nstatic int is_ancestor(const struct dentry *d1, const struct dentry *d2)\n{\n\tdo {\n\t\tif (d1 == d2)\n\t\t\treturn 1;\n\t\td1 = d1->d_parent;\n\t} while (!IS_ROOT(d1));\n\treturn 0;\n}\n\n \n\nstatic int gfs2_show_options(struct seq_file *s, struct dentry *root)\n{\n\tstruct gfs2_sbd *sdp = root->d_sb->s_fs_info;\n\tstruct gfs2_args *args = &sdp->sd_args;\n\tunsigned int logd_secs, statfs_slow, statfs_quantum, quota_quantum;\n\n\tspin_lock(&sdp->sd_tune.gt_spin);\n\tlogd_secs = sdp->sd_tune.gt_logd_secs;\n\tquota_quantum = sdp->sd_tune.gt_quota_quantum;\n\tstatfs_quantum = sdp->sd_tune.gt_statfs_quantum;\n\tstatfs_slow = sdp->sd_tune.gt_statfs_slow;\n\tspin_unlock(&sdp->sd_tune.gt_spin);\n\n\tif (is_ancestor(root, sdp->sd_master_dir))\n\t\tseq_puts(s, \",meta\");\n\tif (args->ar_lockproto[0])\n\t\tseq_show_option(s, \"lockproto\", args->ar_lockproto);\n\tif (args->ar_locktable[0])\n\t\tseq_show_option(s, \"locktable\", args->ar_locktable);\n\tif (args->ar_hostdata[0])\n\t\tseq_show_option(s, \"hostdata\", args->ar_hostdata);\n\tif (args->ar_spectator)\n\t\tseq_puts(s, \",spectator\");\n\tif (args->ar_localflocks)\n\t\tseq_puts(s, \",localflocks\");\n\tif (args->ar_debug)\n\t\tseq_puts(s, \",debug\");\n\tif (args->ar_posix_acl)\n\t\tseq_puts(s, \",acl\");\n\tif (args->ar_quota != GFS2_QUOTA_DEFAULT) {\n\t\tchar *state;\n\t\tswitch (args->ar_quota) {\n\t\tcase GFS2_QUOTA_OFF:\n\t\t\tstate = \"off\";\n\t\t\tbreak;\n\t\tcase GFS2_QUOTA_ACCOUNT:\n\t\t\tstate = \"account\";\n\t\t\tbreak;\n\t\tcase GFS2_QUOTA_ON:\n\t\t\tstate = \"on\";\n\t\t\tbreak;\n\t\tcase GFS2_QUOTA_QUIET:\n\t\t\tstate = \"quiet\";\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tstate = \"unknown\";\n\t\t\tbreak;\n\t\t}\n\t\tseq_printf(s, \",quota=%s\", state);\n\t}\n\tif (args->ar_suiddir)\n\t\tseq_puts(s, \",suiddir\");\n\tif (args->ar_data != GFS2_DATA_DEFAULT) {\n\t\tchar *state;\n\t\tswitch (args->ar_data) {\n\t\tcase GFS2_DATA_WRITEBACK:\n\t\t\tstate = \"writeback\";\n\t\t\tbreak;\n\t\tcase GFS2_DATA_ORDERED:\n\t\t\tstate = \"ordered\";\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tstate = \"unknown\";\n\t\t\tbreak;\n\t\t}\n\t\tseq_printf(s, \",data=%s\", state);\n\t}\n\tif (args->ar_discard)\n\t\tseq_puts(s, \",discard\");\n\tif (logd_secs != 30)\n\t\tseq_printf(s, \",commit=%d\", logd_secs);\n\tif (statfs_quantum != 30)\n\t\tseq_printf(s, \",statfs_quantum=%d\", statfs_quantum);\n\telse if (statfs_slow)\n\t\tseq_puts(s, \",statfs_quantum=0\");\n\tif (quota_quantum != 60)\n\t\tseq_printf(s, \",quota_quantum=%d\", quota_quantum);\n\tif (args->ar_statfs_percent)\n\t\tseq_printf(s, \",statfs_percent=%d\", args->ar_statfs_percent);\n\tif (args->ar_errors != GFS2_ERRORS_DEFAULT) {\n\t\tconst char *state;\n\n\t\tswitch (args->ar_errors) {\n\t\tcase GFS2_ERRORS_WITHDRAW:\n\t\t\tstate = \"withdraw\";\n\t\t\tbreak;\n\t\tcase GFS2_ERRORS_PANIC:\n\t\t\tstate = \"panic\";\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tstate = \"unknown\";\n\t\t\tbreak;\n\t\t}\n\t\tseq_printf(s, \",errors=%s\", state);\n\t}\n\tif (test_bit(SDF_NOBARRIERS, &sdp->sd_flags))\n\t\tseq_puts(s, \",nobarrier\");\n\tif (test_bit(SDF_DEMOTE, &sdp->sd_flags))\n\t\tseq_puts(s, \",demote_interface_used\");\n\tif (args->ar_rgrplvb)\n\t\tseq_puts(s, \",rgrplvb\");\n\tif (args->ar_loccookie)\n\t\tseq_puts(s, \",loccookie\");\n\treturn 0;\n}\n\nstatic void gfs2_final_release_pages(struct gfs2_inode *ip)\n{\n\tstruct inode *inode = &ip->i_inode;\n\tstruct gfs2_glock *gl = ip->i_gl;\n\n\tif (unlikely(!gl)) {\n\t\t \n\t\tBUG_ON(!test_bit(GIF_ALLOC_FAILED, &ip->i_flags));\n\t\treturn;\n\t}\n\n\ttruncate_inode_pages(gfs2_glock2aspace(gl), 0);\n\ttruncate_inode_pages(&inode->i_data, 0);\n\n\tif (atomic_read(&gl->gl_revokes) == 0) {\n\t\tclear_bit(GLF_LFLUSH, &gl->gl_flags);\n\t\tclear_bit(GLF_DIRTY, &gl->gl_flags);\n\t}\n}\n\nstatic int gfs2_dinode_dealloc(struct gfs2_inode *ip)\n{\n\tstruct gfs2_sbd *sdp = GFS2_SB(&ip->i_inode);\n\tstruct gfs2_rgrpd *rgd;\n\tstruct gfs2_holder gh;\n\tint error;\n\n\tif (gfs2_get_inode_blocks(&ip->i_inode) != 1) {\n\t\tgfs2_consist_inode(ip);\n\t\treturn -EIO;\n\t}\n\n\tgfs2_rindex_update(sdp);\n\n\terror = gfs2_quota_hold(ip, NO_UID_QUOTA_CHANGE, NO_GID_QUOTA_CHANGE);\n\tif (error)\n\t\treturn error;\n\n\trgd = gfs2_blk2rgrpd(sdp, ip->i_no_addr, 1);\n\tif (!rgd) {\n\t\tgfs2_consist_inode(ip);\n\t\terror = -EIO;\n\t\tgoto out_qs;\n\t}\n\n\terror = gfs2_glock_nq_init(rgd->rd_gl, LM_ST_EXCLUSIVE,\n\t\t\t\t   LM_FLAG_NODE_SCOPE, &gh);\n\tif (error)\n\t\tgoto out_qs;\n\n\terror = gfs2_trans_begin(sdp, RES_RG_BIT + RES_STATFS + RES_QUOTA,\n\t\t\t\t sdp->sd_jdesc->jd_blocks);\n\tif (error)\n\t\tgoto out_rg_gunlock;\n\n\tgfs2_free_di(rgd, ip);\n\n\tgfs2_final_release_pages(ip);\n\n\tgfs2_trans_end(sdp);\n\nout_rg_gunlock:\n\tgfs2_glock_dq_uninit(&gh);\nout_qs:\n\tgfs2_quota_unhold(ip);\n\treturn error;\n}\n\n \n\nstatic void gfs2_glock_put_eventually(struct gfs2_glock *gl)\n{\n\tif (current->flags & PF_MEMALLOC)\n\t\tgfs2_glock_queue_put(gl);\n\telse\n\t\tgfs2_glock_put(gl);\n}\n\nstatic bool gfs2_upgrade_iopen_glock(struct inode *inode)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct gfs2_holder *gh = &ip->i_iopen_gh;\n\tlong timeout = 5 * HZ;\n\tint error;\n\n\tgh->gh_flags |= GL_NOCACHE;\n\tgfs2_glock_dq_wait(gh);\n\n\t \n\n\tgfs2_holder_reinit(LM_ST_EXCLUSIVE, LM_FLAG_TRY_1CB | GL_NOCACHE, gh);\n\terror = gfs2_glock_nq(gh);\n\tif (error != GLR_TRYFAILED)\n\t\treturn !error;\n\n\tgfs2_holder_reinit(LM_ST_EXCLUSIVE, GL_ASYNC | GL_NOCACHE, gh);\n\terror = gfs2_glock_nq(gh);\n\tif (error)\n\t\treturn false;\n\n\ttimeout = wait_event_interruptible_timeout(sdp->sd_async_glock_wait,\n\t\t!test_bit(HIF_WAIT, &gh->gh_iflags) ||\n\t\ttest_bit(GLF_DEMOTE, &ip->i_gl->gl_flags),\n\t\ttimeout);\n\tif (!test_bit(HIF_HOLDER, &gh->gh_iflags)) {\n\t\tgfs2_glock_dq(gh);\n\t\treturn false;\n\t}\n\treturn gfs2_glock_holder_ready(gh) == 0;\n}\n\n \nstatic enum dinode_demise evict_should_delete(struct inode *inode,\n\t\t\t\t\t      struct gfs2_holder *gh)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct super_block *sb = inode->i_sb;\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\tint ret;\n\n\tif (unlikely(test_bit(GIF_ALLOC_FAILED, &ip->i_flags)))\n\t\tgoto should_delete;\n\n\tif (test_bit(GIF_DEFERRED_DELETE, &ip->i_flags))\n\t\treturn SHOULD_DEFER_EVICTION;\n\n\t \n\tif (WARN_ON_ONCE(current->flags & PF_MEMALLOC))\n\t\treturn SHOULD_DEFER_EVICTION;\n\n\t \n\tret = gfs2_glock_nq_init(ip->i_gl, LM_ST_EXCLUSIVE, GL_SKIP, gh);\n\tif (unlikely(ret)) {\n\t\tglock_clear_object(ip->i_iopen_gh.gh_gl, ip);\n\t\tip->i_iopen_gh.gh_flags |= GL_NOCACHE;\n\t\tgfs2_glock_dq_uninit(&ip->i_iopen_gh);\n\t\treturn SHOULD_DEFER_EVICTION;\n\t}\n\n\tif (gfs2_inode_already_deleted(ip->i_gl, ip->i_no_formal_ino))\n\t\treturn SHOULD_NOT_DELETE_DINODE;\n\tret = gfs2_check_blk_type(sdp, ip->i_no_addr, GFS2_BLKST_UNLINKED);\n\tif (ret)\n\t\treturn SHOULD_NOT_DELETE_DINODE;\n\n\tret = gfs2_instantiate(gh);\n\tif (ret)\n\t\treturn SHOULD_NOT_DELETE_DINODE;\n\n\t \n\tif (inode->i_nlink)\n\t\treturn SHOULD_NOT_DELETE_DINODE;\n\nshould_delete:\n\tif (gfs2_holder_initialized(&ip->i_iopen_gh) &&\n\t    test_bit(HIF_HOLDER, &ip->i_iopen_gh.gh_iflags)) {\n\t\tif (!gfs2_upgrade_iopen_glock(inode)) {\n\t\t\tgfs2_holder_uninit(&ip->i_iopen_gh);\n\t\t\treturn SHOULD_NOT_DELETE_DINODE;\n\t\t}\n\t}\n\treturn SHOULD_DELETE_DINODE;\n}\n\n \nstatic int evict_unlinked_inode(struct inode *inode)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tint ret;\n\n\tif (S_ISDIR(inode->i_mode) &&\n\t    (ip->i_diskflags & GFS2_DIF_EXHASH)) {\n\t\tret = gfs2_dir_exhash_dealloc(ip);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tif (ip->i_eattr) {\n\t\tret = gfs2_ea_dealloc(ip);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tif (!gfs2_is_stuffed(ip)) {\n\t\tret = gfs2_file_dealloc(ip);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\t \n\n\tret = gfs2_dinode_dealloc(ip);\n\tif (!ret && ip->i_gl)\n\t\tgfs2_inode_remember_delete(ip->i_gl, ip->i_no_formal_ino);\n\nout:\n\treturn ret;\n}\n\n \nstatic int evict_linked_inode(struct inode *inode)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct address_space *metamapping;\n\tint ret;\n\n\tgfs2_log_flush(sdp, ip->i_gl, GFS2_LOG_HEAD_FLUSH_NORMAL |\n\t\t       GFS2_LFC_EVICT_INODE);\n\tmetamapping = gfs2_glock2aspace(ip->i_gl);\n\tif (test_bit(GLF_DIRTY, &ip->i_gl->gl_flags)) {\n\t\tfilemap_fdatawrite(metamapping);\n\t\tfilemap_fdatawait(metamapping);\n\t}\n\twrite_inode_now(inode, 1);\n\tgfs2_ail_flush(ip->i_gl, 0);\n\n\tret = gfs2_trans_begin(sdp, 0, sdp->sd_jdesc->jd_blocks);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\ttruncate_inode_pages(&inode->i_data, 0);\n\ttruncate_inode_pages(metamapping, 0);\n\tgfs2_trans_end(sdp);\n\treturn 0;\n}\n\n \n\nstatic void gfs2_evict_inode(struct inode *inode)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_holder gh;\n\tint ret;\n\n\tif (inode->i_nlink || sb_rdonly(sb) || !ip->i_no_addr)\n\t\tgoto out;\n\n\t \n\tif (!sdp->sd_jdesc)\n\t\tgoto out;\n\n\tgfs2_holder_mark_uninitialized(&gh);\n\tret = evict_should_delete(inode, &gh);\n\tif (ret == SHOULD_DEFER_EVICTION)\n\t\tgoto out;\n\tif (ret == SHOULD_DELETE_DINODE)\n\t\tret = evict_unlinked_inode(inode);\n\telse\n\t\tret = evict_linked_inode(inode);\n\n\tif (gfs2_rs_active(&ip->i_res))\n\t\tgfs2_rs_deltree(&ip->i_res);\n\n\tif (gfs2_holder_initialized(&gh))\n\t\tgfs2_glock_dq_uninit(&gh);\n\tif (ret && ret != GLR_TRYFAILED && ret != -EROFS)\n\t\tfs_warn(sdp, \"gfs2_evict_inode: %d\\n\", ret);\nout:\n\ttruncate_inode_pages_final(&inode->i_data);\n\tif (ip->i_qadata)\n\t\tgfs2_assert_warn(sdp, ip->i_qadata->qa_ref == 0);\n\tgfs2_rs_deltree(&ip->i_res);\n\tgfs2_ordered_del_inode(ip);\n\tclear_inode(inode);\n\tgfs2_dir_hash_inval(ip);\n\tif (gfs2_holder_initialized(&ip->i_iopen_gh)) {\n\t\tstruct gfs2_glock *gl = ip->i_iopen_gh.gh_gl;\n\n\t\tglock_clear_object(gl, ip);\n\t\tgfs2_glock_hold(gl);\n\t\tip->i_iopen_gh.gh_flags |= GL_NOCACHE;\n\t\tgfs2_glock_dq_uninit(&ip->i_iopen_gh);\n\t\tgfs2_glock_put_eventually(gl);\n\t}\n\tif (ip->i_gl) {\n\t\tglock_clear_object(ip->i_gl, ip);\n\t\twait_on_bit_io(&ip->i_flags, GIF_GLOP_PENDING, TASK_UNINTERRUPTIBLE);\n\t\tgfs2_glock_add_to_lru(ip->i_gl);\n\t\tgfs2_glock_put_eventually(ip->i_gl);\n\t\trcu_assign_pointer(ip->i_gl, NULL);\n\t}\n}\n\nstatic struct inode *gfs2_alloc_inode(struct super_block *sb)\n{\n\tstruct gfs2_inode *ip;\n\n\tip = alloc_inode_sb(sb, gfs2_inode_cachep, GFP_KERNEL);\n\tif (!ip)\n\t\treturn NULL;\n\tip->i_no_addr = 0;\n\tip->i_flags = 0;\n\tip->i_gl = NULL;\n\tgfs2_holder_mark_uninitialized(&ip->i_iopen_gh);\n\tmemset(&ip->i_res, 0, sizeof(ip->i_res));\n\tRB_CLEAR_NODE(&ip->i_res.rs_node);\n\tip->i_rahead = 0;\n\treturn &ip->i_inode;\n}\n\nstatic void gfs2_free_inode(struct inode *inode)\n{\n\tkmem_cache_free(gfs2_inode_cachep, GFS2_I(inode));\n}\n\nextern void free_local_statfs_inodes(struct gfs2_sbd *sdp)\n{\n\tstruct local_statfs_inode *lsi, *safe;\n\n\t \n\tlist_for_each_entry_safe(lsi, safe, &sdp->sd_sc_inodes_list, si_list) {\n\t\tif (lsi->si_jid == sdp->sd_jdesc->jd_jid)\n\t\t\tsdp->sd_sc_inode = NULL;  \n\t\tif (lsi->si_sc_inode)\n\t\t\tiput(lsi->si_sc_inode);\n\t\tlist_del(&lsi->si_list);\n\t\tkfree(lsi);\n\t}\n}\n\nextern struct inode *find_local_statfs_inode(struct gfs2_sbd *sdp,\n\t\t\t\t\t     unsigned int index)\n{\n\tstruct local_statfs_inode *lsi;\n\n\t \n\tlist_for_each_entry(lsi, &sdp->sd_sc_inodes_list, si_list) {\n\t\tif (lsi->si_jid == index)\n\t\t\treturn lsi->si_sc_inode;\n\t}\n\treturn NULL;\n}\n\nconst struct super_operations gfs2_super_ops = {\n\t.alloc_inode\t\t= gfs2_alloc_inode,\n\t.free_inode\t\t= gfs2_free_inode,\n\t.write_inode\t\t= gfs2_write_inode,\n\t.dirty_inode\t\t= gfs2_dirty_inode,\n\t.evict_inode\t\t= gfs2_evict_inode,\n\t.put_super\t\t= gfs2_put_super,\n\t.sync_fs\t\t= gfs2_sync_fs,\n\t.freeze_super\t\t= gfs2_freeze_super,\n\t.thaw_super\t\t= gfs2_thaw_super,\n\t.statfs\t\t\t= gfs2_statfs,\n\t.drop_inode\t\t= gfs2_drop_inode,\n\t.show_options\t\t= gfs2_show_options,\n};\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}