{
  "module_name": "file.c",
  "hash_id": "3872b67ad3bf8e65617c136da50ce1d26a03deef4a2e749631fd55ec92217878",
  "original_prompt": "Ingested from linux-6.6.14/fs/kernfs/file.c",
  "human_readable_source": "\n \n\n#include <linux/fs.h>\n#include <linux/seq_file.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/pagemap.h>\n#include <linux/sched/mm.h>\n#include <linux/fsnotify.h>\n#include <linux/uio.h>\n\n#include \"kernfs-internal.h\"\n\nstruct kernfs_open_node {\n\tstruct rcu_head\t\trcu_head;\n\tatomic_t\t\tevent;\n\twait_queue_head_t\tpoll;\n\tstruct list_head\tfiles;  \n\tunsigned int\t\tnr_mmapped;\n\tunsigned int\t\tnr_to_release;\n};\n\n \n#define KERNFS_NOTIFY_EOL\t\t\t((void *)&kernfs_notify_list)\n\nstatic DEFINE_SPINLOCK(kernfs_notify_lock);\nstatic struct kernfs_node *kernfs_notify_list = KERNFS_NOTIFY_EOL;\n\nstatic inline struct mutex *kernfs_open_file_mutex_ptr(struct kernfs_node *kn)\n{\n\tint idx = hash_ptr(kn, NR_KERNFS_LOCK_BITS);\n\n\treturn &kernfs_locks->open_file_mutex[idx];\n}\n\nstatic inline struct mutex *kernfs_open_file_mutex_lock(struct kernfs_node *kn)\n{\n\tstruct mutex *lock;\n\n\tlock = kernfs_open_file_mutex_ptr(kn);\n\n\tmutex_lock(lock);\n\n\treturn lock;\n}\n\n \nstatic struct kernfs_open_node *of_on(struct kernfs_open_file *of)\n{\n\treturn rcu_dereference_protected(of->kn->attr.open,\n\t\t\t\t\t !list_empty(&of->list));\n}\n\n \nstatic struct kernfs_open_node *\nkernfs_deref_open_node_locked(struct kernfs_node *kn)\n{\n\treturn rcu_dereference_protected(kn->attr.open,\n\t\t\t\tlockdep_is_held(kernfs_open_file_mutex_ptr(kn)));\n}\n\nstatic struct kernfs_open_file *kernfs_of(struct file *file)\n{\n\treturn ((struct seq_file *)file->private_data)->private;\n}\n\n \nstatic const struct kernfs_ops *kernfs_ops(struct kernfs_node *kn)\n{\n\tif (kn->flags & KERNFS_LOCKDEP)\n\t\tlockdep_assert_held(kn);\n\treturn kn->attr.ops;\n}\n\n \nstatic void kernfs_seq_stop_active(struct seq_file *sf, void *v)\n{\n\tstruct kernfs_open_file *of = sf->private;\n\tconst struct kernfs_ops *ops = kernfs_ops(of->kn);\n\n\tif (ops->seq_stop)\n\t\tops->seq_stop(sf, v);\n\tkernfs_put_active(of->kn);\n}\n\nstatic void *kernfs_seq_start(struct seq_file *sf, loff_t *ppos)\n{\n\tstruct kernfs_open_file *of = sf->private;\n\tconst struct kernfs_ops *ops;\n\n\t \n\tmutex_lock(&of->mutex);\n\tif (!kernfs_get_active(of->kn))\n\t\treturn ERR_PTR(-ENODEV);\n\n\tops = kernfs_ops(of->kn);\n\tif (ops->seq_start) {\n\t\tvoid *next = ops->seq_start(sf, ppos);\n\t\t \n\t\tif (next == ERR_PTR(-ENODEV))\n\t\t\tkernfs_seq_stop_active(sf, next);\n\t\treturn next;\n\t}\n\treturn single_start(sf, ppos);\n}\n\nstatic void *kernfs_seq_next(struct seq_file *sf, void *v, loff_t *ppos)\n{\n\tstruct kernfs_open_file *of = sf->private;\n\tconst struct kernfs_ops *ops = kernfs_ops(of->kn);\n\n\tif (ops->seq_next) {\n\t\tvoid *next = ops->seq_next(sf, v, ppos);\n\t\t \n\t\tif (next == ERR_PTR(-ENODEV))\n\t\t\tkernfs_seq_stop_active(sf, next);\n\t\treturn next;\n\t} else {\n\t\t \n\t\t++*ppos;\n\t\treturn NULL;\n\t}\n}\n\nstatic void kernfs_seq_stop(struct seq_file *sf, void *v)\n{\n\tstruct kernfs_open_file *of = sf->private;\n\n\tif (v != ERR_PTR(-ENODEV))\n\t\tkernfs_seq_stop_active(sf, v);\n\tmutex_unlock(&of->mutex);\n}\n\nstatic int kernfs_seq_show(struct seq_file *sf, void *v)\n{\n\tstruct kernfs_open_file *of = sf->private;\n\n\tof->event = atomic_read(&of_on(of)->event);\n\n\treturn of->kn->attr.ops->seq_show(sf, v);\n}\n\nstatic const struct seq_operations kernfs_seq_ops = {\n\t.start = kernfs_seq_start,\n\t.next = kernfs_seq_next,\n\t.stop = kernfs_seq_stop,\n\t.show = kernfs_seq_show,\n};\n\n \nstatic ssize_t kernfs_file_read_iter(struct kiocb *iocb, struct iov_iter *iter)\n{\n\tstruct kernfs_open_file *of = kernfs_of(iocb->ki_filp);\n\tssize_t len = min_t(size_t, iov_iter_count(iter), PAGE_SIZE);\n\tconst struct kernfs_ops *ops;\n\tchar *buf;\n\n\tbuf = of->prealloc_buf;\n\tif (buf)\n\t\tmutex_lock(&of->prealloc_mutex);\n\telse\n\t\tbuf = kmalloc(len, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\t \n\tmutex_lock(&of->mutex);\n\tif (!kernfs_get_active(of->kn)) {\n\t\tlen = -ENODEV;\n\t\tmutex_unlock(&of->mutex);\n\t\tgoto out_free;\n\t}\n\n\tof->event = atomic_read(&of_on(of)->event);\n\n\tops = kernfs_ops(of->kn);\n\tif (ops->read)\n\t\tlen = ops->read(of, buf, len, iocb->ki_pos);\n\telse\n\t\tlen = -EINVAL;\n\n\tkernfs_put_active(of->kn);\n\tmutex_unlock(&of->mutex);\n\n\tif (len < 0)\n\t\tgoto out_free;\n\n\tif (copy_to_iter(buf, len, iter) != len) {\n\t\tlen = -EFAULT;\n\t\tgoto out_free;\n\t}\n\n\tiocb->ki_pos += len;\n\n out_free:\n\tif (buf == of->prealloc_buf)\n\t\tmutex_unlock(&of->prealloc_mutex);\n\telse\n\t\tkfree(buf);\n\treturn len;\n}\n\nstatic ssize_t kernfs_fop_read_iter(struct kiocb *iocb, struct iov_iter *iter)\n{\n\tif (kernfs_of(iocb->ki_filp)->kn->flags & KERNFS_HAS_SEQ_SHOW)\n\t\treturn seq_read_iter(iocb, iter);\n\treturn kernfs_file_read_iter(iocb, iter);\n}\n\n \nstatic ssize_t kernfs_fop_write_iter(struct kiocb *iocb, struct iov_iter *iter)\n{\n\tstruct kernfs_open_file *of = kernfs_of(iocb->ki_filp);\n\tssize_t len = iov_iter_count(iter);\n\tconst struct kernfs_ops *ops;\n\tchar *buf;\n\n\tif (of->atomic_write_len) {\n\t\tif (len > of->atomic_write_len)\n\t\t\treturn -E2BIG;\n\t} else {\n\t\tlen = min_t(size_t, len, PAGE_SIZE);\n\t}\n\n\tbuf = of->prealloc_buf;\n\tif (buf)\n\t\tmutex_lock(&of->prealloc_mutex);\n\telse\n\t\tbuf = kmalloc(len + 1, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_iter(buf, len, iter) != len) {\n\t\tlen = -EFAULT;\n\t\tgoto out_free;\n\t}\n\tbuf[len] = '\\0';\t \n\n\t \n\tmutex_lock(&of->mutex);\n\tif (!kernfs_get_active(of->kn)) {\n\t\tmutex_unlock(&of->mutex);\n\t\tlen = -ENODEV;\n\t\tgoto out_free;\n\t}\n\n\tops = kernfs_ops(of->kn);\n\tif (ops->write)\n\t\tlen = ops->write(of, buf, len, iocb->ki_pos);\n\telse\n\t\tlen = -EINVAL;\n\n\tkernfs_put_active(of->kn);\n\tmutex_unlock(&of->mutex);\n\n\tif (len > 0)\n\t\tiocb->ki_pos += len;\n\nout_free:\n\tif (buf == of->prealloc_buf)\n\t\tmutex_unlock(&of->prealloc_mutex);\n\telse\n\t\tkfree(buf);\n\treturn len;\n}\n\nstatic void kernfs_vma_open(struct vm_area_struct *vma)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct kernfs_open_file *of = kernfs_of(file);\n\n\tif (!of->vm_ops)\n\t\treturn;\n\n\tif (!kernfs_get_active(of->kn))\n\t\treturn;\n\n\tif (of->vm_ops->open)\n\t\tof->vm_ops->open(vma);\n\n\tkernfs_put_active(of->kn);\n}\n\nstatic vm_fault_t kernfs_vma_fault(struct vm_fault *vmf)\n{\n\tstruct file *file = vmf->vma->vm_file;\n\tstruct kernfs_open_file *of = kernfs_of(file);\n\tvm_fault_t ret;\n\n\tif (!of->vm_ops)\n\t\treturn VM_FAULT_SIGBUS;\n\n\tif (!kernfs_get_active(of->kn))\n\t\treturn VM_FAULT_SIGBUS;\n\n\tret = VM_FAULT_SIGBUS;\n\tif (of->vm_ops->fault)\n\t\tret = of->vm_ops->fault(vmf);\n\n\tkernfs_put_active(of->kn);\n\treturn ret;\n}\n\nstatic vm_fault_t kernfs_vma_page_mkwrite(struct vm_fault *vmf)\n{\n\tstruct file *file = vmf->vma->vm_file;\n\tstruct kernfs_open_file *of = kernfs_of(file);\n\tvm_fault_t ret;\n\n\tif (!of->vm_ops)\n\t\treturn VM_FAULT_SIGBUS;\n\n\tif (!kernfs_get_active(of->kn))\n\t\treturn VM_FAULT_SIGBUS;\n\n\tret = 0;\n\tif (of->vm_ops->page_mkwrite)\n\t\tret = of->vm_ops->page_mkwrite(vmf);\n\telse\n\t\tfile_update_time(file);\n\n\tkernfs_put_active(of->kn);\n\treturn ret;\n}\n\nstatic int kernfs_vma_access(struct vm_area_struct *vma, unsigned long addr,\n\t\t\t     void *buf, int len, int write)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct kernfs_open_file *of = kernfs_of(file);\n\tint ret;\n\n\tif (!of->vm_ops)\n\t\treturn -EINVAL;\n\n\tif (!kernfs_get_active(of->kn))\n\t\treturn -EINVAL;\n\n\tret = -EINVAL;\n\tif (of->vm_ops->access)\n\t\tret = of->vm_ops->access(vma, addr, buf, len, write);\n\n\tkernfs_put_active(of->kn);\n\treturn ret;\n}\n\n#ifdef CONFIG_NUMA\nstatic int kernfs_vma_set_policy(struct vm_area_struct *vma,\n\t\t\t\t struct mempolicy *new)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct kernfs_open_file *of = kernfs_of(file);\n\tint ret;\n\n\tif (!of->vm_ops)\n\t\treturn 0;\n\n\tif (!kernfs_get_active(of->kn))\n\t\treturn -EINVAL;\n\n\tret = 0;\n\tif (of->vm_ops->set_policy)\n\t\tret = of->vm_ops->set_policy(vma, new);\n\n\tkernfs_put_active(of->kn);\n\treturn ret;\n}\n\nstatic struct mempolicy *kernfs_vma_get_policy(struct vm_area_struct *vma,\n\t\t\t\t\t       unsigned long addr)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct kernfs_open_file *of = kernfs_of(file);\n\tstruct mempolicy *pol;\n\n\tif (!of->vm_ops)\n\t\treturn vma->vm_policy;\n\n\tif (!kernfs_get_active(of->kn))\n\t\treturn vma->vm_policy;\n\n\tpol = vma->vm_policy;\n\tif (of->vm_ops->get_policy)\n\t\tpol = of->vm_ops->get_policy(vma, addr);\n\n\tkernfs_put_active(of->kn);\n\treturn pol;\n}\n\n#endif\n\nstatic const struct vm_operations_struct kernfs_vm_ops = {\n\t.open\t\t= kernfs_vma_open,\n\t.fault\t\t= kernfs_vma_fault,\n\t.page_mkwrite\t= kernfs_vma_page_mkwrite,\n\t.access\t\t= kernfs_vma_access,\n#ifdef CONFIG_NUMA\n\t.set_policy\t= kernfs_vma_set_policy,\n\t.get_policy\t= kernfs_vma_get_policy,\n#endif\n};\n\nstatic int kernfs_fop_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct kernfs_open_file *of = kernfs_of(file);\n\tconst struct kernfs_ops *ops;\n\tint rc;\n\n\t \n\tif (!(of->kn->flags & KERNFS_HAS_MMAP))\n\t\treturn -ENODEV;\n\n\tmutex_lock(&of->mutex);\n\n\trc = -ENODEV;\n\tif (!kernfs_get_active(of->kn))\n\t\tgoto out_unlock;\n\n\tops = kernfs_ops(of->kn);\n\trc = ops->mmap(of, vma);\n\tif (rc)\n\t\tgoto out_put;\n\n\t \n\tif (vma->vm_file != file)\n\t\tgoto out_put;\n\n\trc = -EINVAL;\n\tif (of->mmapped && of->vm_ops != vma->vm_ops)\n\t\tgoto out_put;\n\n\t \n\tif (vma->vm_ops && vma->vm_ops->close)\n\t\tgoto out_put;\n\n\trc = 0;\n\tof->mmapped = true;\n\tof_on(of)->nr_mmapped++;\n\tof->vm_ops = vma->vm_ops;\n\tvma->vm_ops = &kernfs_vm_ops;\nout_put:\n\tkernfs_put_active(of->kn);\nout_unlock:\n\tmutex_unlock(&of->mutex);\n\n\treturn rc;\n}\n\n \nstatic int kernfs_get_open_node(struct kernfs_node *kn,\n\t\t\t\tstruct kernfs_open_file *of)\n{\n\tstruct kernfs_open_node *on;\n\tstruct mutex *mutex;\n\n\tmutex = kernfs_open_file_mutex_lock(kn);\n\ton = kernfs_deref_open_node_locked(kn);\n\n\tif (!on) {\n\t\t \n\t\ton = kzalloc(sizeof(*on), GFP_KERNEL);\n\t\tif (!on) {\n\t\t\tmutex_unlock(mutex);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tatomic_set(&on->event, 1);\n\t\tinit_waitqueue_head(&on->poll);\n\t\tINIT_LIST_HEAD(&on->files);\n\t\trcu_assign_pointer(kn->attr.open, on);\n\t}\n\n\tlist_add_tail(&of->list, &on->files);\n\tif (kn->flags & KERNFS_HAS_RELEASE)\n\t\ton->nr_to_release++;\n\n\tmutex_unlock(mutex);\n\treturn 0;\n}\n\n \nstatic void kernfs_unlink_open_file(struct kernfs_node *kn,\n\t\t\t\t    struct kernfs_open_file *of,\n\t\t\t\t    bool open_failed)\n{\n\tstruct kernfs_open_node *on;\n\tstruct mutex *mutex;\n\n\tmutex = kernfs_open_file_mutex_lock(kn);\n\n\ton = kernfs_deref_open_node_locked(kn);\n\tif (!on) {\n\t\tmutex_unlock(mutex);\n\t\treturn;\n\t}\n\n\tif (of) {\n\t\tif (kn->flags & KERNFS_HAS_RELEASE) {\n\t\t\tWARN_ON_ONCE(of->released == open_failed);\n\t\t\tif (open_failed)\n\t\t\t\ton->nr_to_release--;\n\t\t}\n\t\tif (of->mmapped)\n\t\t\ton->nr_mmapped--;\n\t\tlist_del(&of->list);\n\t}\n\n\tif (list_empty(&on->files)) {\n\t\trcu_assign_pointer(kn->attr.open, NULL);\n\t\tkfree_rcu(on, rcu_head);\n\t}\n\n\tmutex_unlock(mutex);\n}\n\nstatic int kernfs_fop_open(struct inode *inode, struct file *file)\n{\n\tstruct kernfs_node *kn = inode->i_private;\n\tstruct kernfs_root *root = kernfs_root(kn);\n\tconst struct kernfs_ops *ops;\n\tstruct kernfs_open_file *of;\n\tbool has_read, has_write, has_mmap;\n\tint error = -EACCES;\n\n\tif (!kernfs_get_active(kn))\n\t\treturn -ENODEV;\n\n\tops = kernfs_ops(kn);\n\n\thas_read = ops->seq_show || ops->read || ops->mmap;\n\thas_write = ops->write || ops->mmap;\n\thas_mmap = ops->mmap;\n\n\t \n\tif (root->flags & KERNFS_ROOT_EXTRA_OPEN_PERM_CHECK) {\n\t\tif ((file->f_mode & FMODE_WRITE) &&\n\t\t    (!(inode->i_mode & S_IWUGO) || !has_write))\n\t\t\tgoto err_out;\n\n\t\tif ((file->f_mode & FMODE_READ) &&\n\t\t    (!(inode->i_mode & S_IRUGO) || !has_read))\n\t\t\tgoto err_out;\n\t}\n\n\t \n\terror = -ENOMEM;\n\tof = kzalloc(sizeof(struct kernfs_open_file), GFP_KERNEL);\n\tif (!of)\n\t\tgoto err_out;\n\n\t \n\tif (has_mmap)\n\t\tmutex_init(&of->mutex);\n\telse\n\t\tmutex_init(&of->mutex);\n\n\tof->kn = kn;\n\tof->file = file;\n\n\t \n\tof->atomic_write_len = ops->atomic_write_len;\n\n\terror = -EINVAL;\n\t \n\tif (ops->prealloc && ops->seq_show)\n\t\tgoto err_free;\n\tif (ops->prealloc) {\n\t\tint len = of->atomic_write_len ?: PAGE_SIZE;\n\t\tof->prealloc_buf = kmalloc(len + 1, GFP_KERNEL);\n\t\terror = -ENOMEM;\n\t\tif (!of->prealloc_buf)\n\t\t\tgoto err_free;\n\t\tmutex_init(&of->prealloc_mutex);\n\t}\n\n\t \n\tif (ops->seq_show)\n\t\terror = seq_open(file, &kernfs_seq_ops);\n\telse\n\t\terror = seq_open(file, NULL);\n\tif (error)\n\t\tgoto err_free;\n\n\tof->seq_file = file->private_data;\n\tof->seq_file->private = of;\n\n\t \n\tif (file->f_mode & FMODE_WRITE)\n\t\tfile->f_mode |= FMODE_PWRITE;\n\n\t \n\terror = kernfs_get_open_node(kn, of);\n\tif (error)\n\t\tgoto err_seq_release;\n\n\tif (ops->open) {\n\t\t \n\t\terror = ops->open(of);\n\t\tif (error)\n\t\t\tgoto err_put_node;\n\t}\n\n\t \n\tkernfs_put_active(kn);\n\treturn 0;\n\nerr_put_node:\n\tkernfs_unlink_open_file(kn, of, true);\nerr_seq_release:\n\tseq_release(inode, file);\nerr_free:\n\tkfree(of->prealloc_buf);\n\tkfree(of);\nerr_out:\n\tkernfs_put_active(kn);\n\treturn error;\n}\n\n \nstatic void kernfs_release_file(struct kernfs_node *kn,\n\t\t\t\tstruct kernfs_open_file *of)\n{\n\t \n\tlockdep_assert_held(kernfs_open_file_mutex_ptr(kn));\n\n\tif (!of->released) {\n\t\t \n\t\tkn->attr.ops->release(of);\n\t\tof->released = true;\n\t\tof_on(of)->nr_to_release--;\n\t}\n}\n\nstatic int kernfs_fop_release(struct inode *inode, struct file *filp)\n{\n\tstruct kernfs_node *kn = inode->i_private;\n\tstruct kernfs_open_file *of = kernfs_of(filp);\n\n\tif (kn->flags & KERNFS_HAS_RELEASE) {\n\t\tstruct mutex *mutex;\n\n\t\tmutex = kernfs_open_file_mutex_lock(kn);\n\t\tkernfs_release_file(kn, of);\n\t\tmutex_unlock(mutex);\n\t}\n\n\tkernfs_unlink_open_file(kn, of, false);\n\tseq_release(inode, filp);\n\tkfree(of->prealloc_buf);\n\tkfree(of);\n\n\treturn 0;\n}\n\nbool kernfs_should_drain_open_files(struct kernfs_node *kn)\n{\n\tstruct kernfs_open_node *on;\n\tbool ret;\n\n\t \n\tWARN_ON_ONCE(atomic_read(&kn->active) != KN_DEACTIVATED_BIAS);\n\n\trcu_read_lock();\n\ton = rcu_dereference(kn->attr.open);\n\tret = on && (on->nr_mmapped || on->nr_to_release);\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\nvoid kernfs_drain_open_files(struct kernfs_node *kn)\n{\n\tstruct kernfs_open_node *on;\n\tstruct kernfs_open_file *of;\n\tstruct mutex *mutex;\n\n\tmutex = kernfs_open_file_mutex_lock(kn);\n\ton = kernfs_deref_open_node_locked(kn);\n\tif (!on) {\n\t\tmutex_unlock(mutex);\n\t\treturn;\n\t}\n\n\tlist_for_each_entry(of, &on->files, list) {\n\t\tstruct inode *inode = file_inode(of->file);\n\n\t\tif (of->mmapped) {\n\t\t\tunmap_mapping_range(inode->i_mapping, 0, 0, 1);\n\t\t\tof->mmapped = false;\n\t\t\ton->nr_mmapped--;\n\t\t}\n\n\t\tif (kn->flags & KERNFS_HAS_RELEASE)\n\t\t\tkernfs_release_file(kn, of);\n\t}\n\n\tWARN_ON_ONCE(on->nr_mmapped || on->nr_to_release);\n\tmutex_unlock(mutex);\n}\n\n \n__poll_t kernfs_generic_poll(struct kernfs_open_file *of, poll_table *wait)\n{\n\tstruct kernfs_open_node *on = of_on(of);\n\n\tpoll_wait(of->file, &on->poll, wait);\n\n\tif (of->event != atomic_read(&on->event))\n\t\treturn DEFAULT_POLLMASK|EPOLLERR|EPOLLPRI;\n\n\treturn DEFAULT_POLLMASK;\n}\n\nstatic __poll_t kernfs_fop_poll(struct file *filp, poll_table *wait)\n{\n\tstruct kernfs_open_file *of = kernfs_of(filp);\n\tstruct kernfs_node *kn = kernfs_dentry_node(filp->f_path.dentry);\n\t__poll_t ret;\n\n\tif (!kernfs_get_active(kn))\n\t\treturn DEFAULT_POLLMASK|EPOLLERR|EPOLLPRI;\n\n\tif (kn->attr.ops->poll)\n\t\tret = kn->attr.ops->poll(of, wait);\n\telse\n\t\tret = kernfs_generic_poll(of, wait);\n\n\tkernfs_put_active(kn);\n\treturn ret;\n}\n\nstatic void kernfs_notify_workfn(struct work_struct *work)\n{\n\tstruct kernfs_node *kn;\n\tstruct kernfs_super_info *info;\n\tstruct kernfs_root *root;\nrepeat:\n\t \n\tspin_lock_irq(&kernfs_notify_lock);\n\tkn = kernfs_notify_list;\n\tif (kn == KERNFS_NOTIFY_EOL) {\n\t\tspin_unlock_irq(&kernfs_notify_lock);\n\t\treturn;\n\t}\n\tkernfs_notify_list = kn->attr.notify_next;\n\tkn->attr.notify_next = NULL;\n\tspin_unlock_irq(&kernfs_notify_lock);\n\n\troot = kernfs_root(kn);\n\t \n\n\tdown_read(&root->kernfs_supers_rwsem);\n\tlist_for_each_entry(info, &kernfs_root(kn)->supers, node) {\n\t\tstruct kernfs_node *parent;\n\t\tstruct inode *p_inode = NULL;\n\t\tstruct inode *inode;\n\t\tstruct qstr name;\n\n\t\t \n\t\tinode = ilookup(info->sb, kernfs_ino(kn));\n\t\tif (!inode)\n\t\t\tcontinue;\n\n\t\tname = (struct qstr)QSTR_INIT(kn->name, strlen(kn->name));\n\t\tparent = kernfs_get_parent(kn);\n\t\tif (parent) {\n\t\t\tp_inode = ilookup(info->sb, kernfs_ino(parent));\n\t\t\tif (p_inode) {\n\t\t\t\tfsnotify(FS_MODIFY | FS_EVENT_ON_CHILD,\n\t\t\t\t\t inode, FSNOTIFY_EVENT_INODE,\n\t\t\t\t\t p_inode, &name, inode, 0);\n\t\t\t\tiput(p_inode);\n\t\t\t}\n\n\t\t\tkernfs_put(parent);\n\t\t}\n\n\t\tif (!p_inode)\n\t\t\tfsnotify_inode(inode, FS_MODIFY);\n\n\t\tiput(inode);\n\t}\n\n\tup_read(&root->kernfs_supers_rwsem);\n\tkernfs_put(kn);\n\tgoto repeat;\n}\n\n \nvoid kernfs_notify(struct kernfs_node *kn)\n{\n\tstatic DECLARE_WORK(kernfs_notify_work, kernfs_notify_workfn);\n\tunsigned long flags;\n\tstruct kernfs_open_node *on;\n\n\tif (WARN_ON(kernfs_type(kn) != KERNFS_FILE))\n\t\treturn;\n\n\t \n\trcu_read_lock();\n\ton = rcu_dereference(kn->attr.open);\n\tif (on) {\n\t\tatomic_inc(&on->event);\n\t\twake_up_interruptible(&on->poll);\n\t}\n\trcu_read_unlock();\n\n\t \n\tspin_lock_irqsave(&kernfs_notify_lock, flags);\n\tif (!kn->attr.notify_next) {\n\t\tkernfs_get(kn);\n\t\tkn->attr.notify_next = kernfs_notify_list;\n\t\tkernfs_notify_list = kn;\n\t\tschedule_work(&kernfs_notify_work);\n\t}\n\tspin_unlock_irqrestore(&kernfs_notify_lock, flags);\n}\nEXPORT_SYMBOL_GPL(kernfs_notify);\n\nconst struct file_operations kernfs_file_fops = {\n\t.read_iter\t= kernfs_fop_read_iter,\n\t.write_iter\t= kernfs_fop_write_iter,\n\t.llseek\t\t= generic_file_llseek,\n\t.mmap\t\t= kernfs_fop_mmap,\n\t.open\t\t= kernfs_fop_open,\n\t.release\t= kernfs_fop_release,\n\t.poll\t\t= kernfs_fop_poll,\n\t.fsync\t\t= noop_fsync,\n\t.splice_read\t= copy_splice_read,\n\t.splice_write\t= iter_file_splice_write,\n};\n\n \nstruct kernfs_node *__kernfs_create_file(struct kernfs_node *parent,\n\t\t\t\t\t const char *name,\n\t\t\t\t\t umode_t mode, kuid_t uid, kgid_t gid,\n\t\t\t\t\t loff_t size,\n\t\t\t\t\t const struct kernfs_ops *ops,\n\t\t\t\t\t void *priv, const void *ns,\n\t\t\t\t\t struct lock_class_key *key)\n{\n\tstruct kernfs_node *kn;\n\tunsigned flags;\n\tint rc;\n\n\tflags = KERNFS_FILE;\n\n\tkn = kernfs_new_node(parent, name, (mode & S_IALLUGO) | S_IFREG,\n\t\t\t     uid, gid, flags);\n\tif (!kn)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tkn->attr.ops = ops;\n\tkn->attr.size = size;\n\tkn->ns = ns;\n\tkn->priv = priv;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\tif (key) {\n\t\tlockdep_init_map(&kn->dep_map, \"kn->active\", key, 0);\n\t\tkn->flags |= KERNFS_LOCKDEP;\n\t}\n#endif\n\n\t \n\tif (ops->seq_show)\n\t\tkn->flags |= KERNFS_HAS_SEQ_SHOW;\n\tif (ops->mmap)\n\t\tkn->flags |= KERNFS_HAS_MMAP;\n\tif (ops->release)\n\t\tkn->flags |= KERNFS_HAS_RELEASE;\n\n\trc = kernfs_add_one(kn);\n\tif (rc) {\n\t\tkernfs_put(kn);\n\t\treturn ERR_PTR(rc);\n\t}\n\treturn kn;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}