{
  "module_name": "kasan_test.c",
  "hash_id": "9371292f58f43ab110368c3f683893f2095356b6f3e1bf3f6f127da17d28cec9",
  "original_prompt": "Ingested from linux-6.6.14/mm/kasan/kasan_test.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"kasan_test: \" fmt\n\n#include <kunit/test.h>\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/io.h>\n#include <linux/kasan.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/printk.h>\n#include <linux/random.h>\n#include <linux/set_memory.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include <linux/tracepoint.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <trace/events/printk.h>\n\n#include <asm/page.h>\n\n#include \"kasan.h\"\n\n#define OOB_TAG_OFF (IS_ENABLED(CONFIG_KASAN_GENERIC) ? 0 : KASAN_GRANULE_SIZE)\n\nstatic bool multishot;\n\n \nstatic struct {\n\tbool report_found;\n\tbool async_fault;\n} test_status;\n\n \nvoid *kasan_ptr_result;\nint kasan_int_result;\n\n \nstatic void probe_console(void *ignore, const char *buf, size_t len)\n{\n\tif (strnstr(buf, \"BUG: KASAN: \", len))\n\t\tWRITE_ONCE(test_status.report_found, true);\n\telse if (strnstr(buf, \"Asynchronous fault: \", len))\n\t\tWRITE_ONCE(test_status.async_fault, true);\n}\n\nstatic int kasan_suite_init(struct kunit_suite *suite)\n{\n\tif (!kasan_enabled()) {\n\t\tpr_err(\"Can't run KASAN tests with KASAN disabled\");\n\t\treturn -1;\n\t}\n\n\t \n\tkasan_kunit_test_suite_start();\n\n\t \n\tmultishot = kasan_save_enable_multi_shot();\n\n\tregister_trace_console(probe_console, NULL);\n\treturn 0;\n}\n\nstatic void kasan_suite_exit(struct kunit_suite *suite)\n{\n\tkasan_kunit_test_suite_end();\n\tkasan_restore_multi_shot(multishot);\n\tunregister_trace_console(probe_console, NULL);\n\ttracepoint_synchronize_unregister();\n}\n\nstatic void kasan_test_exit(struct kunit *test)\n{\n\tKUNIT_EXPECT_FALSE(test, READ_ONCE(test_status.report_found));\n}\n\n \n#define KUNIT_EXPECT_KASAN_FAIL(test, expression) do {\t\t\t\\\n\tif (IS_ENABLED(CONFIG_KASAN_HW_TAGS) &&\t\t\t\t\\\n\t    kasan_sync_fault_possible())\t\t\t\t\\\n\t\tmigrate_disable();\t\t\t\t\t\\\n\tKUNIT_EXPECT_FALSE(test, READ_ONCE(test_status.report_found));\t\\\n\tbarrier();\t\t\t\t\t\t\t\\\n\texpression;\t\t\t\t\t\t\t\\\n\tbarrier();\t\t\t\t\t\t\t\\\n\tif (kasan_async_fault_possible())\t\t\t\t\\\n\t\tkasan_force_async_fault();\t\t\t\t\\\n\tif (!READ_ONCE(test_status.report_found)) {\t\t\t\\\n\t\tKUNIT_FAIL(test, KUNIT_SUBTEST_INDENT \"KASAN failure \"\t\\\n\t\t\t\t\"expected in \\\"\" #expression\t\t\\\n\t\t\t\t \"\\\", but none occurred\");\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\tif (IS_ENABLED(CONFIG_KASAN_HW_TAGS) &&\t\t\t\t\\\n\t    kasan_sync_fault_possible()) {\t\t\t\t\\\n\t\tif (READ_ONCE(test_status.report_found) &&\t\t\\\n\t\t    !READ_ONCE(test_status.async_fault))\t\t\\\n\t\t\tkasan_enable_hw_tags();\t\t\t\t\\\n\t\tmigrate_enable();\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\tWRITE_ONCE(test_status.report_found, false);\t\t\t\\\n\tWRITE_ONCE(test_status.async_fault, false);\t\t\t\\\n} while (0)\n\n#define KASAN_TEST_NEEDS_CONFIG_ON(test, config) do {\t\t\t\\\n\tif (!IS_ENABLED(config))\t\t\t\t\t\\\n\t\tkunit_skip((test), \"Test requires \" #config \"=y\");\t\\\n} while (0)\n\n#define KASAN_TEST_NEEDS_CONFIG_OFF(test, config) do {\t\t\t\\\n\tif (IS_ENABLED(config))\t\t\t\t\t\t\\\n\t\tkunit_skip((test), \"Test requires \" #config \"=n\");\t\\\n} while (0)\n\n#define KASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test) do {\t\t\\\n\tif (IS_ENABLED(CONFIG_KASAN_HW_TAGS))\t\t\t\t\\\n\t\tbreak;   \t\t\\\n\tif (IS_ENABLED(CONFIG_CC_HAS_KASAN_MEMINTRINSIC_PREFIX))\t\\\n\t\tbreak;   \t\t\\\n\tif (IS_ENABLED(CONFIG_GENERIC_ENTRY))\t\t\t\t\\\n\t\tkunit_skip((test), \"Test requires checked mem*()\");\t\\\n} while (0)\n\nstatic void kmalloc_oob_right(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 128 - KASAN_GRANULE_SIZE - 5;\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(ptr);\n\t \n\tif (IS_ENABLED(CONFIG_KASAN_GENERIC))\n\t\tKUNIT_EXPECT_KASAN_FAIL(test, ptr[size] = 'x');\n\n\t \n\tKUNIT_EXPECT_KASAN_FAIL(test, ptr[size + 5] = 'y');\n\n\t \n\tKUNIT_EXPECT_KASAN_FAIL(test, ptr[0] =\n\t\t\t\t\tptr[size + KASAN_GRANULE_SIZE + 5]);\n\n\tkfree(ptr);\n}\n\nstatic void kmalloc_oob_left(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 15;\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(ptr);\n\tKUNIT_EXPECT_KASAN_FAIL(test, *ptr = *(ptr - 1));\n\tkfree(ptr);\n}\n\nstatic void kmalloc_node_oob_right(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 4096;\n\n\tptr = kmalloc_node(size, GFP_KERNEL, 0);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(ptr);\n\tKUNIT_EXPECT_KASAN_FAIL(test, ptr[0] = ptr[size]);\n\tkfree(ptr);\n}\n\n \nstatic void kmalloc_pagealloc_oob_right(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = KMALLOC_MAX_CACHE_SIZE + 10;\n\n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_SLUB);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(ptr);\n\tKUNIT_EXPECT_KASAN_FAIL(test, ptr[size + OOB_TAG_OFF] = 0);\n\n\tkfree(ptr);\n}\n\nstatic void kmalloc_pagealloc_uaf(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = KMALLOC_MAX_CACHE_SIZE + 10;\n\n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_SLUB);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\tkfree(ptr);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)ptr)[0]);\n}\n\nstatic void kmalloc_pagealloc_invalid_free(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = KMALLOC_MAX_CACHE_SIZE + 10;\n\n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_SLUB);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, kfree(ptr + 1));\n}\n\nstatic void pagealloc_oob_right(struct kunit *test)\n{\n\tchar *ptr;\n\tstruct page *pages;\n\tsize_t order = 4;\n\tsize_t size = (1UL << (PAGE_SHIFT + order));\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_KASAN_GENERIC);\n\n\tpages = alloc_pages(GFP_KERNEL, order);\n\tptr = page_address(pages);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, ptr[0] = ptr[size]);\n\tfree_pages((unsigned long)ptr, order);\n}\n\nstatic void pagealloc_uaf(struct kunit *test)\n{\n\tchar *ptr;\n\tstruct page *pages;\n\tsize_t order = 4;\n\n\tpages = alloc_pages(GFP_KERNEL, order);\n\tptr = page_address(pages);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\tfree_pages((unsigned long)ptr, order);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)ptr)[0]);\n}\n\nstatic void kmalloc_large_oob_right(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = KMALLOC_MAX_CACHE_SIZE - 256;\n\n\t \n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(ptr);\n\tKUNIT_EXPECT_KASAN_FAIL(test, ptr[size] = 0);\n\tkfree(ptr);\n}\n\nstatic void krealloc_more_oob_helper(struct kunit *test,\n\t\t\t\t\tsize_t size1, size_t size2)\n{\n\tchar *ptr1, *ptr2;\n\tsize_t middle;\n\n\tKUNIT_ASSERT_LT(test, size1, size2);\n\tmiddle = size1 + (size2 - size1) / 2;\n\n\tptr1 = kmalloc(size1, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr1);\n\n\tptr2 = krealloc(ptr1, size2, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr2);\n\n\t \n\tOPTIMIZER_HIDE_VAR(ptr2);\n\n\t \n\tptr2[size1 - 1] = 'x';\n\tptr2[size1] = 'x';\n\tptr2[middle] = 'x';\n\tptr2[size2 - 1] = 'x';\n\n\t \n\tif (IS_ENABLED(CONFIG_KASAN_GENERIC))\n\t\tKUNIT_EXPECT_KASAN_FAIL(test, ptr2[size2] = 'x');\n\n\t \n\tKUNIT_EXPECT_KASAN_FAIL(test,\n\t\tptr2[round_up(size2, KASAN_GRANULE_SIZE)] = 'x');\n\n\tkfree(ptr2);\n}\n\nstatic void krealloc_less_oob_helper(struct kunit *test,\n\t\t\t\t\tsize_t size1, size_t size2)\n{\n\tchar *ptr1, *ptr2;\n\tsize_t middle;\n\n\tKUNIT_ASSERT_LT(test, size2, size1);\n\tmiddle = size2 + (size1 - size2) / 2;\n\n\tptr1 = kmalloc(size1, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr1);\n\n\tptr2 = krealloc(ptr1, size2, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr2);\n\n\t \n\tOPTIMIZER_HIDE_VAR(ptr2);\n\n\t \n\tptr2[size2 - 1] = 'x';\n\n\t \n\tif (IS_ENABLED(CONFIG_KASAN_GENERIC))\n\t\tKUNIT_EXPECT_KASAN_FAIL(test, ptr2[size2] = 'x');\n\n\t \n\tKUNIT_EXPECT_KASAN_FAIL(test,\n\t\tptr2[round_up(size2, KASAN_GRANULE_SIZE)] = 'x');\n\n\t \n\tKUNIT_EXPECT_LE(test, round_up(size2, KASAN_GRANULE_SIZE),\n\t\t\t\tround_down(middle, KASAN_GRANULE_SIZE));\n\tKUNIT_EXPECT_LE(test, round_up(middle, KASAN_GRANULE_SIZE),\n\t\t\t\tround_down(size1, KASAN_GRANULE_SIZE));\n\tKUNIT_EXPECT_KASAN_FAIL(test, ptr2[middle] = 'x');\n\tKUNIT_EXPECT_KASAN_FAIL(test, ptr2[size1 - 1] = 'x');\n\tKUNIT_EXPECT_KASAN_FAIL(test, ptr2[size1] = 'x');\n\n\tkfree(ptr2);\n}\n\nstatic void krealloc_more_oob(struct kunit *test)\n{\n\tkrealloc_more_oob_helper(test, 201, 235);\n}\n\nstatic void krealloc_less_oob(struct kunit *test)\n{\n\tkrealloc_less_oob_helper(test, 235, 201);\n}\n\nstatic void krealloc_pagealloc_more_oob(struct kunit *test)\n{\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_SLUB);\n\n\tkrealloc_more_oob_helper(test, KMALLOC_MAX_CACHE_SIZE + 201,\n\t\t\t\t\tKMALLOC_MAX_CACHE_SIZE + 235);\n}\n\nstatic void krealloc_pagealloc_less_oob(struct kunit *test)\n{\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_SLUB);\n\n\tkrealloc_less_oob_helper(test, KMALLOC_MAX_CACHE_SIZE + 235,\n\t\t\t\t\tKMALLOC_MAX_CACHE_SIZE + 201);\n}\n\n \nstatic void krealloc_uaf(struct kunit *test)\n{\n\tchar *ptr1, *ptr2;\n\tint size1 = 201;\n\tint size2 = 235;\n\n\tptr1 = kmalloc(size1, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr1);\n\tkfree(ptr1);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, ptr2 = krealloc(ptr1, size2, GFP_KERNEL));\n\tKUNIT_ASSERT_NULL(test, ptr2);\n\tKUNIT_EXPECT_KASAN_FAIL(test, *(volatile char *)ptr1);\n}\n\nstatic void kmalloc_oob_16(struct kunit *test)\n{\n\tstruct {\n\t\tu64 words[2];\n\t} *ptr1, *ptr2;\n\n\tKASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test);\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_GENERIC);\n\n\tptr1 = kmalloc(sizeof(*ptr1) - 3, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr1);\n\n\tptr2 = kmalloc(sizeof(*ptr2), GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr2);\n\n\tOPTIMIZER_HIDE_VAR(ptr1);\n\tOPTIMIZER_HIDE_VAR(ptr2);\n\tKUNIT_EXPECT_KASAN_FAIL(test, *ptr1 = *ptr2);\n\tkfree(ptr1);\n\tkfree(ptr2);\n}\n\nstatic void kmalloc_uaf_16(struct kunit *test)\n{\n\tstruct {\n\t\tu64 words[2];\n\t} *ptr1, *ptr2;\n\n\tKASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test);\n\n\tptr1 = kmalloc(sizeof(*ptr1), GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr1);\n\n\tptr2 = kmalloc(sizeof(*ptr2), GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr2);\n\tkfree(ptr2);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, *ptr1 = *ptr2);\n\tkfree(ptr1);\n}\n\n \n\nstatic void kmalloc_oob_memset_2(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 128 - KASAN_GRANULE_SIZE;\n\n\tKASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(size);\n\tKUNIT_EXPECT_KASAN_FAIL(test, memset(ptr + size - 1, 0, 2));\n\tkfree(ptr);\n}\n\nstatic void kmalloc_oob_memset_4(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 128 - KASAN_GRANULE_SIZE;\n\n\tKASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(size);\n\tKUNIT_EXPECT_KASAN_FAIL(test, memset(ptr + size - 3, 0, 4));\n\tkfree(ptr);\n}\n\nstatic void kmalloc_oob_memset_8(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 128 - KASAN_GRANULE_SIZE;\n\n\tKASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(size);\n\tKUNIT_EXPECT_KASAN_FAIL(test, memset(ptr + size - 7, 0, 8));\n\tkfree(ptr);\n}\n\nstatic void kmalloc_oob_memset_16(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 128 - KASAN_GRANULE_SIZE;\n\n\tKASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(size);\n\tKUNIT_EXPECT_KASAN_FAIL(test, memset(ptr + size - 15, 0, 16));\n\tkfree(ptr);\n}\n\nstatic void kmalloc_oob_in_memset(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 128 - KASAN_GRANULE_SIZE;\n\n\tKASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(ptr);\n\tOPTIMIZER_HIDE_VAR(size);\n\tKUNIT_EXPECT_KASAN_FAIL(test,\n\t\t\t\tmemset(ptr, 0, size + KASAN_GRANULE_SIZE));\n\tkfree(ptr);\n}\n\nstatic void kmalloc_memmove_negative_size(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 64;\n\tsize_t invalid_size = -2;\n\n\tKASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test);\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_KASAN_HW_TAGS);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tmemset((char *)ptr, 0, 64);\n\tOPTIMIZER_HIDE_VAR(ptr);\n\tOPTIMIZER_HIDE_VAR(invalid_size);\n\tKUNIT_EXPECT_KASAN_FAIL(test,\n\t\tmemmove((char *)ptr, (char *)ptr + 4, invalid_size));\n\tkfree(ptr);\n}\n\nstatic void kmalloc_memmove_invalid_size(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 64;\n\tsize_t invalid_size = size;\n\n\tKASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tmemset((char *)ptr, 0, 64);\n\tOPTIMIZER_HIDE_VAR(ptr);\n\tOPTIMIZER_HIDE_VAR(invalid_size);\n\tKUNIT_EXPECT_KASAN_FAIL(test,\n\t\tmemmove((char *)ptr, (char *)ptr + 4, invalid_size));\n\tkfree(ptr);\n}\n\nstatic void kmalloc_uaf(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 10;\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tkfree(ptr);\n\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)ptr)[8]);\n}\n\nstatic void kmalloc_uaf_memset(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 33;\n\n\tKASAN_TEST_NEEDS_CHECKED_MEMINTRINSICS(test);\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_GENERIC);\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tkfree(ptr);\n\tKUNIT_EXPECT_KASAN_FAIL(test, memset(ptr, 0, size));\n}\n\nstatic void kmalloc_uaf2(struct kunit *test)\n{\n\tchar *ptr1, *ptr2;\n\tsize_t size = 43;\n\tint counter = 0;\n\nagain:\n\tptr1 = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr1);\n\n\tkfree(ptr1);\n\n\tptr2 = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr2);\n\n\t \n\tif (!IS_ENABLED(CONFIG_KASAN_GENERIC) && ptr1 == ptr2 && counter++ < 16) {\n\t\tkfree(ptr2);\n\t\tgoto again;\n\t}\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)ptr1)[40]);\n\tKUNIT_EXPECT_PTR_NE(test, ptr1, ptr2);\n\n\tkfree(ptr2);\n}\n\n \nstatic void kmalloc_uaf3(struct kunit *test)\n{\n\tchar *ptr1, *ptr2;\n\tsize_t size = 100;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_KASAN_GENERIC);\n\n\tptr1 = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr1);\n\tkfree(ptr1);\n\n\tptr2 = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr2);\n\tkfree(ptr2);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)ptr1)[8]);\n}\n\nstatic void kfree_via_page(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 8;\n\tstruct page *page;\n\tunsigned long offset;\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tpage = virt_to_page(ptr);\n\toffset = offset_in_page(ptr);\n\tkfree(page_address(page) + offset);\n}\n\nstatic void kfree_via_phys(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 8;\n\tphys_addr_t phys;\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tphys = virt_to_phys(ptr);\n\tkfree(phys_to_virt(phys));\n}\n\nstatic void kmem_cache_oob(struct kunit *test)\n{\n\tchar *p;\n\tsize_t size = 200;\n\tstruct kmem_cache *cache;\n\n\tcache = kmem_cache_create(\"test_cache\", size, 0, 0, NULL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, cache);\n\n\tp = kmem_cache_alloc(cache, GFP_KERNEL);\n\tif (!p) {\n\t\tkunit_err(test, \"Allocation failed: %s\\n\", __func__);\n\t\tkmem_cache_destroy(cache);\n\t\treturn;\n\t}\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, *p = p[size + OOB_TAG_OFF]);\n\n\tkmem_cache_free(cache, p);\n\tkmem_cache_destroy(cache);\n}\n\nstatic void kmem_cache_accounted(struct kunit *test)\n{\n\tint i;\n\tchar *p;\n\tsize_t size = 200;\n\tstruct kmem_cache *cache;\n\n\tcache = kmem_cache_create(\"test_cache\", size, 0, SLAB_ACCOUNT, NULL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, cache);\n\n\t \n\tfor (i = 0; i < 5; i++) {\n\t\tp = kmem_cache_alloc(cache, GFP_KERNEL);\n\t\tif (!p)\n\t\t\tgoto free_cache;\n\n\t\tkmem_cache_free(cache, p);\n\t\tmsleep(100);\n\t}\n\nfree_cache:\n\tkmem_cache_destroy(cache);\n}\n\nstatic void kmem_cache_bulk(struct kunit *test)\n{\n\tstruct kmem_cache *cache;\n\tsize_t size = 200;\n\tchar *p[10];\n\tbool ret;\n\tint i;\n\n\tcache = kmem_cache_create(\"test_cache\", size, 0, 0, NULL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, cache);\n\n\tret = kmem_cache_alloc_bulk(cache, GFP_KERNEL, ARRAY_SIZE(p), (void **)&p);\n\tif (!ret) {\n\t\tkunit_err(test, \"Allocation failed: %s\\n\", __func__);\n\t\tkmem_cache_destroy(cache);\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(p); i++)\n\t\tp[i][0] = p[i][size - 1] = 42;\n\n\tkmem_cache_free_bulk(cache, ARRAY_SIZE(p), (void **)&p);\n\tkmem_cache_destroy(cache);\n}\n\nstatic char global_array[10];\n\nstatic void kasan_global_oob_right(struct kunit *test)\n{\n\t \n\tchar *volatile array = global_array;\n\tchar *p = &array[ARRAY_SIZE(global_array) + 3];\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_GENERIC);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, *(volatile char *)p);\n}\n\nstatic void kasan_global_oob_left(struct kunit *test)\n{\n\tchar *volatile array = global_array;\n\tchar *p = array - 3;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_CC_IS_CLANG);\n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_GENERIC);\n\tKUNIT_EXPECT_KASAN_FAIL(test, *(volatile char *)p);\n}\n\n \nstatic void ksize_unpoisons_memory(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 128 - KASAN_GRANULE_SIZE - 5;\n\tsize_t real_size;\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\treal_size = ksize(ptr);\n\tKUNIT_EXPECT_GT(test, real_size, size);\n\n\tOPTIMIZER_HIDE_VAR(ptr);\n\n\t \n\tptr[0] = 'x';\n\tptr[size - 1] = 'x';\n\n\t \n\tif (IS_ENABLED(CONFIG_KASAN_GENERIC))\n\t\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)ptr)[size]);\n\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)ptr)[size + 5]);\n\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)ptr)[real_size - 1]);\n\n\tkfree(ptr);\n}\n\n \nstatic void ksize_uaf(struct kunit *test)\n{\n\tchar *ptr;\n\tint size = 128 - KASAN_GRANULE_SIZE;\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\tkfree(ptr);\n\n\tOPTIMIZER_HIDE_VAR(ptr);\n\tKUNIT_EXPECT_KASAN_FAIL(test, ksize(ptr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)ptr)[0]);\n\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)ptr)[size]);\n}\n\nstatic void kasan_stack_oob(struct kunit *test)\n{\n\tchar stack_array[10];\n\t \n\tchar *volatile array = stack_array;\n\tchar *p = &array[ARRAY_SIZE(stack_array) + OOB_TAG_OFF];\n\n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_STACK);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, *(volatile char *)p);\n}\n\nstatic void kasan_alloca_oob_left(struct kunit *test)\n{\n\tvolatile int i = 10;\n\tchar alloca_array[i];\n\t \n\tchar *volatile array = alloca_array;\n\tchar *p = array - 1;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_GENERIC);\n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_STACK);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, *(volatile char *)p);\n}\n\nstatic void kasan_alloca_oob_right(struct kunit *test)\n{\n\tvolatile int i = 10;\n\tchar alloca_array[i];\n\t \n\tchar *volatile array = alloca_array;\n\tchar *p = array + i;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_GENERIC);\n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_STACK);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, *(volatile char *)p);\n}\n\nstatic void kmem_cache_double_free(struct kunit *test)\n{\n\tchar *p;\n\tsize_t size = 200;\n\tstruct kmem_cache *cache;\n\n\tcache = kmem_cache_create(\"test_cache\", size, 0, 0, NULL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, cache);\n\n\tp = kmem_cache_alloc(cache, GFP_KERNEL);\n\tif (!p) {\n\t\tkunit_err(test, \"Allocation failed: %s\\n\", __func__);\n\t\tkmem_cache_destroy(cache);\n\t\treturn;\n\t}\n\n\tkmem_cache_free(cache, p);\n\tKUNIT_EXPECT_KASAN_FAIL(test, kmem_cache_free(cache, p));\n\tkmem_cache_destroy(cache);\n}\n\nstatic void kmem_cache_invalid_free(struct kunit *test)\n{\n\tchar *p;\n\tsize_t size = 200;\n\tstruct kmem_cache *cache;\n\n\tcache = kmem_cache_create(\"test_cache\", size, 0, SLAB_TYPESAFE_BY_RCU,\n\t\t\t\t  NULL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, cache);\n\n\tp = kmem_cache_alloc(cache, GFP_KERNEL);\n\tif (!p) {\n\t\tkunit_err(test, \"Allocation failed: %s\\n\", __func__);\n\t\tkmem_cache_destroy(cache);\n\t\treturn;\n\t}\n\n\t \n\tKUNIT_EXPECT_KASAN_FAIL(test, kmem_cache_free(cache, p + 1));\n\n\t \n\tkmem_cache_free(cache, p);\n\n\tkmem_cache_destroy(cache);\n}\n\nstatic void empty_cache_ctor(void *object) { }\n\nstatic void kmem_cache_double_destroy(struct kunit *test)\n{\n\tstruct kmem_cache *cache;\n\n\t \n\tcache = kmem_cache_create(\"test_cache\", 200, 0, 0, empty_cache_ctor);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, cache);\n\tkmem_cache_destroy(cache);\n\tKUNIT_EXPECT_KASAN_FAIL(test, kmem_cache_destroy(cache));\n}\n\nstatic void kasan_memchr(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 24;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_AMD_MEM_ENCRYPT);\n\n\tif (OOB_TAG_OFF)\n\t\tsize = round_up(size, OOB_TAG_OFF);\n\n\tptr = kmalloc(size, GFP_KERNEL | __GFP_ZERO);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tOPTIMIZER_HIDE_VAR(ptr);\n\tOPTIMIZER_HIDE_VAR(size);\n\tKUNIT_EXPECT_KASAN_FAIL(test,\n\t\tkasan_ptr_result = memchr(ptr, '1', size + 1));\n\n\tkfree(ptr);\n}\n\nstatic void kasan_memcmp(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 24;\n\tint arr[9];\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_AMD_MEM_ENCRYPT);\n\n\tif (OOB_TAG_OFF)\n\t\tsize = round_up(size, OOB_TAG_OFF);\n\n\tptr = kmalloc(size, GFP_KERNEL | __GFP_ZERO);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\tmemset(arr, 0, sizeof(arr));\n\n\tOPTIMIZER_HIDE_VAR(ptr);\n\tOPTIMIZER_HIDE_VAR(size);\n\tKUNIT_EXPECT_KASAN_FAIL(test,\n\t\tkasan_int_result = memcmp(ptr, arr, size+1));\n\tkfree(ptr);\n}\n\nstatic void kasan_strings(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 24;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_AMD_MEM_ENCRYPT);\n\n\tptr = kmalloc(size, GFP_KERNEL | __GFP_ZERO);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tkfree(ptr);\n\n\t \n\tptr += 16;\n\tKUNIT_EXPECT_KASAN_FAIL(test, kasan_ptr_result = strchr(ptr, '1'));\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, kasan_ptr_result = strrchr(ptr, '1'));\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, kasan_int_result = strcmp(ptr, \"2\"));\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, kasan_int_result = strncmp(ptr, \"2\", 1));\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, kasan_int_result = strlen(ptr));\n\n\tKUNIT_EXPECT_KASAN_FAIL(test, kasan_int_result = strnlen(ptr, 1));\n}\n\nstatic void kasan_bitops_modify(struct kunit *test, int nr, void *addr)\n{\n\tKUNIT_EXPECT_KASAN_FAIL(test, set_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, __set_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, clear_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, __clear_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, clear_bit_unlock(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, __clear_bit_unlock(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, change_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, __change_bit(nr, addr));\n}\n\nstatic void kasan_bitops_test_and_modify(struct kunit *test, int nr, void *addr)\n{\n\tKUNIT_EXPECT_KASAN_FAIL(test, test_and_set_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, __test_and_set_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, test_and_set_bit_lock(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, test_and_clear_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, __test_and_clear_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, test_and_change_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, __test_and_change_bit(nr, addr));\n\tKUNIT_EXPECT_KASAN_FAIL(test, kasan_int_result = test_bit(nr, addr));\n\n#if defined(clear_bit_unlock_is_negative_byte)\n\tKUNIT_EXPECT_KASAN_FAIL(test, kasan_int_result =\n\t\t\t\tclear_bit_unlock_is_negative_byte(nr, addr));\n#endif\n}\n\nstatic void kasan_bitops_generic(struct kunit *test)\n{\n\tlong *bits;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_GENERIC);\n\n\t \n\tbits = kzalloc(sizeof(*bits) + 1, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, bits);\n\n\t \n\tkasan_bitops_modify(test, BITS_PER_LONG, bits);\n\n\t \n\tkasan_bitops_test_and_modify(test, BITS_PER_LONG + BITS_PER_BYTE, bits);\n\n\tkfree(bits);\n}\n\nstatic void kasan_bitops_tags(struct kunit *test)\n{\n\tlong *bits;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_KASAN_GENERIC);\n\n\t \n\tbits = kzalloc(48, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, bits);\n\n\t \n\tkasan_bitops_modify(test, BITS_PER_LONG, (void *)bits + 48);\n\tkasan_bitops_test_and_modify(test, BITS_PER_LONG + BITS_PER_BYTE, (void *)bits + 48);\n\n\tkfree(bits);\n}\n\nstatic void kmalloc_double_kzfree(struct kunit *test)\n{\n\tchar *ptr;\n\tsize_t size = 16;\n\n\tptr = kmalloc(size, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tkfree_sensitive(ptr);\n\tKUNIT_EXPECT_KASAN_FAIL(test, kfree_sensitive(ptr));\n}\n\n \n\nstatic struct kasan_rcu_info {\n\tint i;\n\tstruct rcu_head rcu;\n} *global_rcu_ptr;\n\nstatic void rcu_uaf_reclaim(struct rcu_head *rp)\n{\n\tstruct kasan_rcu_info *fp =\n\t\tcontainer_of(rp, struct kasan_rcu_info, rcu);\n\n\tkfree(fp);\n\t((volatile struct kasan_rcu_info *)fp)->i;\n}\n\nstatic void rcu_uaf(struct kunit *test)\n{\n\tstruct kasan_rcu_info *ptr;\n\n\tptr = kmalloc(sizeof(struct kasan_rcu_info), GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\tglobal_rcu_ptr = rcu_dereference_protected(\n\t\t\t\t(struct kasan_rcu_info __rcu *)ptr, NULL);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test,\n\t\tcall_rcu(&global_rcu_ptr->rcu, rcu_uaf_reclaim);\n\t\trcu_barrier());\n}\n\nstatic void workqueue_uaf_work(struct work_struct *work)\n{\n\tkfree(work);\n}\n\nstatic void workqueue_uaf(struct kunit *test)\n{\n\tstruct workqueue_struct *workqueue;\n\tstruct work_struct *work;\n\n\tworkqueue = create_workqueue(\"kasan_workqueue_test\");\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, workqueue);\n\n\twork = kmalloc(sizeof(struct work_struct), GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, work);\n\n\tINIT_WORK(work, workqueue_uaf_work);\n\tqueue_work(workqueue, work);\n\tdestroy_workqueue(workqueue);\n\n\tKUNIT_EXPECT_KASAN_FAIL(test,\n\t\t((volatile struct work_struct *)work)->data);\n}\n\nstatic void vmalloc_helpers_tags(struct kunit *test)\n{\n\tvoid *ptr;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_KASAN_GENERIC);\n\n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_VMALLOC);\n\n\tptr = vmalloc(PAGE_SIZE);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\t \n\tKUNIT_EXPECT_GE(test, (u8)get_tag(ptr), (u8)KASAN_TAG_MIN);\n\tKUNIT_EXPECT_LT(test, (u8)get_tag(ptr), (u8)KASAN_TAG_KERNEL);\n\n\t \n\tKUNIT_ASSERT_TRUE(test, is_vmalloc_addr(ptr));\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, vmalloc_to_page(ptr));\n\n#if !IS_MODULE(CONFIG_KASAN_KUNIT_TEST)\n\t{\n\t\tint rv;\n\n\t\t \n\t\trv = set_memory_ro((unsigned long)ptr, 1);\n\t\tKUNIT_ASSERT_GE(test, rv, 0);\n\t\trv = set_memory_rw((unsigned long)ptr, 1);\n\t\tKUNIT_ASSERT_GE(test, rv, 0);\n\t}\n#endif\n\n\tvfree(ptr);\n}\n\nstatic void vmalloc_oob(struct kunit *test)\n{\n\tchar *v_ptr, *p_ptr;\n\tstruct page *page;\n\tsize_t size = PAGE_SIZE / 2 - KASAN_GRANULE_SIZE - 5;\n\n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_VMALLOC);\n\n\tv_ptr = vmalloc(size);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, v_ptr);\n\n\tOPTIMIZER_HIDE_VAR(v_ptr);\n\n\t \n\n\t \n\tv_ptr[0] = 0;\n\tv_ptr[size - 1] = 0;\n\n\t \n\tif (IS_ENABLED(CONFIG_KASAN_GENERIC))\n\t\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)v_ptr)[size]);\n\n\t \n\tKUNIT_EXPECT_KASAN_FAIL(test, ((volatile char *)v_ptr)[size + 5]);\n\n\t \n\tpage = vmalloc_to_page(v_ptr);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, page);\n\tp_ptr = page_address(page);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, p_ptr);\n\tp_ptr[0] = 0;\n\n\tvfree(v_ptr);\n\n\t \n}\n\nstatic void vmap_tags(struct kunit *test)\n{\n\tchar *p_ptr, *v_ptr;\n\tstruct page *p_page, *v_page;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_SW_TAGS);\n\n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_VMALLOC);\n\n\tp_page = alloc_pages(GFP_KERNEL, 1);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, p_page);\n\tp_ptr = page_address(p_page);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, p_ptr);\n\n\tv_ptr = vmap(&p_page, 1, VM_MAP, PAGE_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, v_ptr);\n\n\t \n\n\tKUNIT_EXPECT_GE(test, (u8)get_tag(v_ptr), (u8)KASAN_TAG_MIN);\n\tKUNIT_EXPECT_LT(test, (u8)get_tag(v_ptr), (u8)KASAN_TAG_KERNEL);\n\n\t \n\t*p_ptr = 0;\n\t*v_ptr = 0;\n\n\t \n\tv_page = vmalloc_to_page(v_ptr);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, v_page);\n\tKUNIT_EXPECT_PTR_EQ(test, p_page, v_page);\n\n\tvunmap(v_ptr);\n\tfree_pages((unsigned long)p_ptr, 1);\n}\n\nstatic void vm_map_ram_tags(struct kunit *test)\n{\n\tchar *p_ptr, *v_ptr;\n\tstruct page *page;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_SW_TAGS);\n\n\tpage = alloc_pages(GFP_KERNEL, 1);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, page);\n\tp_ptr = page_address(page);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, p_ptr);\n\n\tv_ptr = vm_map_ram(&page, 1, -1);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, v_ptr);\n\n\tKUNIT_EXPECT_GE(test, (u8)get_tag(v_ptr), (u8)KASAN_TAG_MIN);\n\tKUNIT_EXPECT_LT(test, (u8)get_tag(v_ptr), (u8)KASAN_TAG_KERNEL);\n\n\t \n\t*p_ptr = 0;\n\t*v_ptr = 0;\n\n\tvm_unmap_ram(v_ptr, 1);\n\tfree_pages((unsigned long)p_ptr, 1);\n}\n\nstatic void vmalloc_percpu(struct kunit *test)\n{\n\tchar __percpu *ptr;\n\tint cpu;\n\n\t \n\tKASAN_TEST_NEEDS_CONFIG_ON(test, CONFIG_KASAN_SW_TAGS);\n\n\tptr = __alloc_percpu(PAGE_SIZE, PAGE_SIZE);\n\n\tfor_each_possible_cpu(cpu) {\n\t\tchar *c_ptr = per_cpu_ptr(ptr, cpu);\n\n\t\tKUNIT_EXPECT_GE(test, (u8)get_tag(c_ptr), (u8)KASAN_TAG_MIN);\n\t\tKUNIT_EXPECT_LT(test, (u8)get_tag(c_ptr), (u8)KASAN_TAG_KERNEL);\n\n\t\t \n\t\t*c_ptr = 0;\n\t}\n\n\tfree_percpu(ptr);\n}\n\n \nstatic void match_all_not_assigned(struct kunit *test)\n{\n\tchar *ptr;\n\tstruct page *pages;\n\tint i, size, order;\n\n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_KASAN_GENERIC);\n\n\tfor (i = 0; i < 256; i++) {\n\t\tsize = get_random_u32_inclusive(1, 1024);\n\t\tptr = kmalloc(size, GFP_KERNEL);\n\t\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\t\tKUNIT_EXPECT_GE(test, (u8)get_tag(ptr), (u8)KASAN_TAG_MIN);\n\t\tKUNIT_EXPECT_LT(test, (u8)get_tag(ptr), (u8)KASAN_TAG_KERNEL);\n\t\tkfree(ptr);\n\t}\n\n\tfor (i = 0; i < 256; i++) {\n\t\torder = get_random_u32_inclusive(1, 4);\n\t\tpages = alloc_pages(GFP_KERNEL, order);\n\t\tptr = page_address(pages);\n\t\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\t\tKUNIT_EXPECT_GE(test, (u8)get_tag(ptr), (u8)KASAN_TAG_MIN);\n\t\tKUNIT_EXPECT_LT(test, (u8)get_tag(ptr), (u8)KASAN_TAG_KERNEL);\n\t\tfree_pages((unsigned long)ptr, order);\n\t}\n\n\tif (!IS_ENABLED(CONFIG_KASAN_VMALLOC))\n\t\treturn;\n\n\tfor (i = 0; i < 256; i++) {\n\t\tsize = get_random_u32_inclusive(1, 1024);\n\t\tptr = vmalloc(size);\n\t\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\t\tKUNIT_EXPECT_GE(test, (u8)get_tag(ptr), (u8)KASAN_TAG_MIN);\n\t\tKUNIT_EXPECT_LT(test, (u8)get_tag(ptr), (u8)KASAN_TAG_KERNEL);\n\t\tvfree(ptr);\n\t}\n}\n\n \nstatic void match_all_ptr_tag(struct kunit *test)\n{\n\tchar *ptr;\n\tu8 tag;\n\n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_KASAN_GENERIC);\n\n\tptr = kmalloc(128, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\n\t \n\ttag = get_tag(ptr);\n\tKUNIT_EXPECT_NE(test, tag, (u8)KASAN_TAG_KERNEL);\n\n\t \n\tptr = set_tag(ptr, KASAN_TAG_KERNEL);\n\n\t \n\t*ptr = 0;\n\n\t \n\tptr = set_tag(ptr, tag);\n\tkfree(ptr);\n}\n\n \nstatic void match_all_mem_tag(struct kunit *test)\n{\n\tchar *ptr;\n\tint tag;\n\n\tKASAN_TEST_NEEDS_CONFIG_OFF(test, CONFIG_KASAN_GENERIC);\n\n\tptr = kmalloc(128, GFP_KERNEL);\n\tKUNIT_ASSERT_NOT_ERR_OR_NULL(test, ptr);\n\tKUNIT_EXPECT_NE(test, (u8)get_tag(ptr), (u8)KASAN_TAG_KERNEL);\n\n\t \n\tfor (tag = KASAN_TAG_MIN; tag <= KASAN_TAG_KERNEL; tag++) {\n\t\tif (tag == get_tag(ptr))\n\t\t\tcontinue;\n\n\t\t \n\t\tkasan_poison(ptr, KASAN_GRANULE_SIZE, (u8)tag, false);\n\n\t\t \n\t\tKUNIT_EXPECT_KASAN_FAIL(test, *ptr = 0);\n\t}\n\n\t \n\tkasan_poison(ptr, KASAN_GRANULE_SIZE, get_tag(ptr), false);\n\tkfree(ptr);\n}\n\nstatic struct kunit_case kasan_kunit_test_cases[] = {\n\tKUNIT_CASE(kmalloc_oob_right),\n\tKUNIT_CASE(kmalloc_oob_left),\n\tKUNIT_CASE(kmalloc_node_oob_right),\n\tKUNIT_CASE(kmalloc_pagealloc_oob_right),\n\tKUNIT_CASE(kmalloc_pagealloc_uaf),\n\tKUNIT_CASE(kmalloc_pagealloc_invalid_free),\n\tKUNIT_CASE(pagealloc_oob_right),\n\tKUNIT_CASE(pagealloc_uaf),\n\tKUNIT_CASE(kmalloc_large_oob_right),\n\tKUNIT_CASE(krealloc_more_oob),\n\tKUNIT_CASE(krealloc_less_oob),\n\tKUNIT_CASE(krealloc_pagealloc_more_oob),\n\tKUNIT_CASE(krealloc_pagealloc_less_oob),\n\tKUNIT_CASE(krealloc_uaf),\n\tKUNIT_CASE(kmalloc_oob_16),\n\tKUNIT_CASE(kmalloc_uaf_16),\n\tKUNIT_CASE(kmalloc_oob_in_memset),\n\tKUNIT_CASE(kmalloc_oob_memset_2),\n\tKUNIT_CASE(kmalloc_oob_memset_4),\n\tKUNIT_CASE(kmalloc_oob_memset_8),\n\tKUNIT_CASE(kmalloc_oob_memset_16),\n\tKUNIT_CASE(kmalloc_memmove_negative_size),\n\tKUNIT_CASE(kmalloc_memmove_invalid_size),\n\tKUNIT_CASE(kmalloc_uaf),\n\tKUNIT_CASE(kmalloc_uaf_memset),\n\tKUNIT_CASE(kmalloc_uaf2),\n\tKUNIT_CASE(kmalloc_uaf3),\n\tKUNIT_CASE(kfree_via_page),\n\tKUNIT_CASE(kfree_via_phys),\n\tKUNIT_CASE(kmem_cache_oob),\n\tKUNIT_CASE(kmem_cache_accounted),\n\tKUNIT_CASE(kmem_cache_bulk),\n\tKUNIT_CASE(kasan_global_oob_right),\n\tKUNIT_CASE(kasan_global_oob_left),\n\tKUNIT_CASE(kasan_stack_oob),\n\tKUNIT_CASE(kasan_alloca_oob_left),\n\tKUNIT_CASE(kasan_alloca_oob_right),\n\tKUNIT_CASE(ksize_unpoisons_memory),\n\tKUNIT_CASE(ksize_uaf),\n\tKUNIT_CASE(kmem_cache_double_free),\n\tKUNIT_CASE(kmem_cache_invalid_free),\n\tKUNIT_CASE(kmem_cache_double_destroy),\n\tKUNIT_CASE(kasan_memchr),\n\tKUNIT_CASE(kasan_memcmp),\n\tKUNIT_CASE(kasan_strings),\n\tKUNIT_CASE(kasan_bitops_generic),\n\tKUNIT_CASE(kasan_bitops_tags),\n\tKUNIT_CASE(kmalloc_double_kzfree),\n\tKUNIT_CASE(rcu_uaf),\n\tKUNIT_CASE(workqueue_uaf),\n\tKUNIT_CASE(vmalloc_helpers_tags),\n\tKUNIT_CASE(vmalloc_oob),\n\tKUNIT_CASE(vmap_tags),\n\tKUNIT_CASE(vm_map_ram_tags),\n\tKUNIT_CASE(vmalloc_percpu),\n\tKUNIT_CASE(match_all_not_assigned),\n\tKUNIT_CASE(match_all_ptr_tag),\n\tKUNIT_CASE(match_all_mem_tag),\n\t{}\n};\n\nstatic struct kunit_suite kasan_kunit_test_suite = {\n\t.name = \"kasan\",\n\t.test_cases = kasan_kunit_test_cases,\n\t.exit = kasan_test_exit,\n\t.suite_init = kasan_suite_init,\n\t.suite_exit = kasan_suite_exit,\n};\n\nkunit_test_suite(kasan_kunit_test_suite);\n\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}