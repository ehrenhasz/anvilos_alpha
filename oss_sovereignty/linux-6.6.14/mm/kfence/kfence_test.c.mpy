{
  "module_name": "kfence_test.c",
  "hash_id": "e236bd6662dd9a09bc88d89cad54cab25c264237d2b8269965f78e0839e16487",
  "original_prompt": "Ingested from linux-6.6.14/mm/kfence/kfence_test.c",
  "human_readable_source": "\n \n\n#include <kunit/test.h>\n#include <linux/jiffies.h>\n#include <linux/kernel.h>\n#include <linux/kfence.h>\n#include <linux/mm.h>\n#include <linux/random.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/string.h>\n#include <linux/tracepoint.h>\n#include <trace/events/printk.h>\n\n#include <asm/kfence.h>\n\n#include \"kfence.h\"\n\n \n#ifndef arch_kfence_test_address\n#define arch_kfence_test_address(addr) (addr)\n#endif\n\n#define KFENCE_TEST_REQUIRES(test, cond) do {\t\t\t\\\n\tif (!(cond))\t\t\t\t\t\t\\\n\t\tkunit_skip((test), \"Test requires: \" #cond);\t\\\n} while (0)\n\n \nstatic struct {\n\tspinlock_t lock;\n\tint nlines;\n\tchar lines[2][256];\n} observed = {\n\t.lock = __SPIN_LOCK_UNLOCKED(observed.lock),\n};\n\n \nstatic void probe_console(void *ignore, const char *buf, size_t len)\n{\n\tunsigned long flags;\n\tint nlines;\n\n\tspin_lock_irqsave(&observed.lock, flags);\n\tnlines = observed.nlines;\n\n\tif (strnstr(buf, \"BUG: KFENCE: \", len) && strnstr(buf, \"test_\", len)) {\n\t\t \n\t\tstrscpy(observed.lines[0], buf, min(len + 1, sizeof(observed.lines[0])));\n\t\tnlines = 1;\n\t} else if (nlines == 1 && (strnstr(buf, \"at 0x\", len) || strnstr(buf, \"of 0x\", len))) {\n\t\tstrscpy(observed.lines[nlines++], buf, min(len + 1, sizeof(observed.lines[0])));\n\t}\n\n\tWRITE_ONCE(observed.nlines, nlines);  \n\tspin_unlock_irqrestore(&observed.lock, flags);\n}\n\n \nstatic bool report_available(void)\n{\n\treturn READ_ONCE(observed.nlines) == ARRAY_SIZE(observed.lines);\n}\n\n \nstruct expect_report {\n\tenum kfence_error_type type;  \n\tvoid *fn;  \n\tchar *addr;  \n\tbool is_write;  \n};\n\nstatic const char *get_access_type(const struct expect_report *r)\n{\n\treturn r->is_write ? \"write\" : \"read\";\n}\n\n \nstatic bool report_matches(const struct expect_report *r)\n{\n\tunsigned long addr = (unsigned long)r->addr;\n\tbool ret = false;\n\tunsigned long flags;\n\ttypeof(observed.lines) expect;\n\tconst char *end;\n\tchar *cur;\n\n\t \n\tif (!report_available())\n\t\treturn false;\n\n\t \n\n\t \n\tcur = expect[0];\n\tend = &expect[0][sizeof(expect[0]) - 1];\n\tswitch (r->type) {\n\tcase KFENCE_ERROR_OOB:\n\t\tcur += scnprintf(cur, end - cur, \"BUG: KFENCE: out-of-bounds %s\",\n\t\t\t\t get_access_type(r));\n\t\tbreak;\n\tcase KFENCE_ERROR_UAF:\n\t\tcur += scnprintf(cur, end - cur, \"BUG: KFENCE: use-after-free %s\",\n\t\t\t\t get_access_type(r));\n\t\tbreak;\n\tcase KFENCE_ERROR_CORRUPTION:\n\t\tcur += scnprintf(cur, end - cur, \"BUG: KFENCE: memory corruption\");\n\t\tbreak;\n\tcase KFENCE_ERROR_INVALID:\n\t\tcur += scnprintf(cur, end - cur, \"BUG: KFENCE: invalid %s\",\n\t\t\t\t get_access_type(r));\n\t\tbreak;\n\tcase KFENCE_ERROR_INVALID_FREE:\n\t\tcur += scnprintf(cur, end - cur, \"BUG: KFENCE: invalid free\");\n\t\tbreak;\n\t}\n\n\tscnprintf(cur, end - cur, \" in %pS\", r->fn);\n\t \n\tcur = strchr(expect[0], '+');\n\tif (cur)\n\t\t*cur = '\\0';\n\n\t \n\tcur = expect[1];\n\tend = &expect[1][sizeof(expect[1]) - 1];\n\n\tswitch (r->type) {\n\tcase KFENCE_ERROR_OOB:\n\t\tcur += scnprintf(cur, end - cur, \"Out-of-bounds %s at\", get_access_type(r));\n\t\taddr = arch_kfence_test_address(addr);\n\t\tbreak;\n\tcase KFENCE_ERROR_UAF:\n\t\tcur += scnprintf(cur, end - cur, \"Use-after-free %s at\", get_access_type(r));\n\t\taddr = arch_kfence_test_address(addr);\n\t\tbreak;\n\tcase KFENCE_ERROR_CORRUPTION:\n\t\tcur += scnprintf(cur, end - cur, \"Corrupted memory at\");\n\t\tbreak;\n\tcase KFENCE_ERROR_INVALID:\n\t\tcur += scnprintf(cur, end - cur, \"Invalid %s at\", get_access_type(r));\n\t\taddr = arch_kfence_test_address(addr);\n\t\tbreak;\n\tcase KFENCE_ERROR_INVALID_FREE:\n\t\tcur += scnprintf(cur, end - cur, \"Invalid free of\");\n\t\tbreak;\n\t}\n\n\tcur += scnprintf(cur, end - cur, \" 0x%p\", (void *)addr);\n\n\tspin_lock_irqsave(&observed.lock, flags);\n\tif (!report_available())\n\t\tgoto out;  \n\n\t \n\tret = strstr(observed.lines[0], expect[0]) && strstr(observed.lines[1], expect[1]);\nout:\n\tspin_unlock_irqrestore(&observed.lock, flags);\n\treturn ret;\n}\n\n \n\n#define TEST_PRIV_WANT_MEMCACHE ((void *)1)\n\n \nstatic struct kmem_cache *test_cache;\n\nstatic size_t setup_test_cache(struct kunit *test, size_t size, slab_flags_t flags,\n\t\t\t       void (*ctor)(void *))\n{\n\tif (test->priv != TEST_PRIV_WANT_MEMCACHE)\n\t\treturn size;\n\n\tkunit_info(test, \"%s: size=%zu, ctor=%ps\\n\", __func__, size, ctor);\n\n\t \n\tflags |= SLAB_NO_MERGE | SLAB_ACCOUNT;\n\ttest_cache = kmem_cache_create(\"test\", size, 1, flags, ctor);\n\tKUNIT_ASSERT_TRUE_MSG(test, test_cache, \"could not create cache\");\n\n\treturn size;\n}\n\nstatic void test_cache_destroy(void)\n{\n\tif (!test_cache)\n\t\treturn;\n\n\tkmem_cache_destroy(test_cache);\n\ttest_cache = NULL;\n}\n\nstatic inline size_t kmalloc_cache_alignment(size_t size)\n{\n\t \n\tenum kmalloc_cache_type type = kmalloc_type(GFP_KERNEL, 0);\n\treturn kmalloc_caches[type][__kmalloc_index(size, false)]->align;\n}\n\n \nstatic __always_inline void test_free(void *ptr)\n{\n\tif (test_cache)\n\t\tkmem_cache_free(test_cache, ptr);\n\telse\n\t\tkfree(ptr);\n}\n\n \nenum allocation_policy {\n\tALLOCATE_ANY,  \n\tALLOCATE_LEFT,  \n\tALLOCATE_RIGHT,  \n\tALLOCATE_NONE,  \n};\n\n \nstatic void *test_alloc(struct kunit *test, size_t size, gfp_t gfp, enum allocation_policy policy)\n{\n\tvoid *alloc;\n\tunsigned long timeout, resched_after;\n\tconst char *policy_name;\n\n\tswitch (policy) {\n\tcase ALLOCATE_ANY:\n\t\tpolicy_name = \"any\";\n\t\tbreak;\n\tcase ALLOCATE_LEFT:\n\t\tpolicy_name = \"left\";\n\t\tbreak;\n\tcase ALLOCATE_RIGHT:\n\t\tpolicy_name = \"right\";\n\t\tbreak;\n\tcase ALLOCATE_NONE:\n\t\tpolicy_name = \"none\";\n\t\tbreak;\n\t}\n\n\tkunit_info(test, \"%s: size=%zu, gfp=%x, policy=%s, cache=%i\\n\", __func__, size, gfp,\n\t\t   policy_name, !!test_cache);\n\n\t \n\ttimeout = jiffies + msecs_to_jiffies(100 * kfence_sample_interval);\n\t \n\tresched_after = jiffies + msecs_to_jiffies(kfence_sample_interval);\n\tdo {\n\t\tif (test_cache)\n\t\t\talloc = kmem_cache_alloc(test_cache, gfp);\n\t\telse\n\t\t\talloc = kmalloc(size, gfp);\n\n\t\tif (is_kfence_address(alloc)) {\n\t\t\tstruct slab *slab = virt_to_slab(alloc);\n\t\t\tenum kmalloc_cache_type type = kmalloc_type(GFP_KERNEL, _RET_IP_);\n\t\t\tstruct kmem_cache *s = test_cache ?:\n\t\t\t\t\tkmalloc_caches[type][__kmalloc_index(size, false)];\n\n\t\t\t \n\t\t\tKUNIT_EXPECT_EQ(test, obj_to_index(s, slab, alloc), 0U);\n\t\t\tKUNIT_EXPECT_EQ(test, objs_per_slab(s, slab), 1);\n\n\t\t\tif (policy == ALLOCATE_ANY)\n\t\t\t\treturn alloc;\n\t\t\tif (policy == ALLOCATE_LEFT && PAGE_ALIGNED(alloc))\n\t\t\t\treturn alloc;\n\t\t\tif (policy == ALLOCATE_RIGHT && !PAGE_ALIGNED(alloc))\n\t\t\t\treturn alloc;\n\t\t} else if (policy == ALLOCATE_NONE)\n\t\t\treturn alloc;\n\n\t\ttest_free(alloc);\n\n\t\tif (time_after(jiffies, resched_after))\n\t\t\tcond_resched();\n\t} while (time_before(jiffies, timeout));\n\n\tKUNIT_ASSERT_TRUE_MSG(test, false, \"failed to allocate from KFENCE\");\n\treturn NULL;  \n}\n\nstatic void test_out_of_bounds_read(struct kunit *test)\n{\n\tsize_t size = 32;\n\tstruct expect_report expect = {\n\t\t.type = KFENCE_ERROR_OOB,\n\t\t.fn = test_out_of_bounds_read,\n\t\t.is_write = false,\n\t};\n\tchar *buf;\n\n\tsetup_test_cache(test, size, 0, NULL);\n\n\t \n\tif (!test_cache)\n\t\tsize = kmalloc_cache_alignment(size);\n\n\t \n\n\tbuf = test_alloc(test, size, GFP_KERNEL, ALLOCATE_LEFT);\n\texpect.addr = buf - 1;\n\tREAD_ONCE(*expect.addr);\n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n\ttest_free(buf);\n\n\tbuf = test_alloc(test, size, GFP_KERNEL, ALLOCATE_RIGHT);\n\texpect.addr = buf + size;\n\tREAD_ONCE(*expect.addr);\n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n\ttest_free(buf);\n}\n\nstatic void test_out_of_bounds_write(struct kunit *test)\n{\n\tsize_t size = 32;\n\tstruct expect_report expect = {\n\t\t.type = KFENCE_ERROR_OOB,\n\t\t.fn = test_out_of_bounds_write,\n\t\t.is_write = true,\n\t};\n\tchar *buf;\n\n\tsetup_test_cache(test, size, 0, NULL);\n\tbuf = test_alloc(test, size, GFP_KERNEL, ALLOCATE_LEFT);\n\texpect.addr = buf - 1;\n\tWRITE_ONCE(*expect.addr, 42);\n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n\ttest_free(buf);\n}\n\nstatic void test_use_after_free_read(struct kunit *test)\n{\n\tconst size_t size = 32;\n\tstruct expect_report expect = {\n\t\t.type = KFENCE_ERROR_UAF,\n\t\t.fn = test_use_after_free_read,\n\t\t.is_write = false,\n\t};\n\n\tsetup_test_cache(test, size, 0, NULL);\n\texpect.addr = test_alloc(test, size, GFP_KERNEL, ALLOCATE_ANY);\n\ttest_free(expect.addr);\n\tREAD_ONCE(*expect.addr);\n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n}\n\nstatic void test_double_free(struct kunit *test)\n{\n\tconst size_t size = 32;\n\tstruct expect_report expect = {\n\t\t.type = KFENCE_ERROR_INVALID_FREE,\n\t\t.fn = test_double_free,\n\t};\n\n\tsetup_test_cache(test, size, 0, NULL);\n\texpect.addr = test_alloc(test, size, GFP_KERNEL, ALLOCATE_ANY);\n\ttest_free(expect.addr);\n\ttest_free(expect.addr);  \n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n}\n\nstatic void test_invalid_addr_free(struct kunit *test)\n{\n\tconst size_t size = 32;\n\tstruct expect_report expect = {\n\t\t.type = KFENCE_ERROR_INVALID_FREE,\n\t\t.fn = test_invalid_addr_free,\n\t};\n\tchar *buf;\n\n\tsetup_test_cache(test, size, 0, NULL);\n\tbuf = test_alloc(test, size, GFP_KERNEL, ALLOCATE_ANY);\n\texpect.addr = buf + 1;  \n\ttest_free(expect.addr);  \n\ttest_free(buf);  \n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n}\n\nstatic void test_corruption(struct kunit *test)\n{\n\tsize_t size = 32;\n\tstruct expect_report expect = {\n\t\t.type = KFENCE_ERROR_CORRUPTION,\n\t\t.fn = test_corruption,\n\t};\n\tchar *buf;\n\n\tsetup_test_cache(test, size, 0, NULL);\n\n\t \n\n\tbuf = test_alloc(test, size, GFP_KERNEL, ALLOCATE_LEFT);\n\texpect.addr = buf + size;\n\tWRITE_ONCE(*expect.addr, 42);\n\ttest_free(buf);\n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n\n\tbuf = test_alloc(test, size, GFP_KERNEL, ALLOCATE_RIGHT);\n\texpect.addr = buf - 1;\n\tWRITE_ONCE(*expect.addr, 42);\n\ttest_free(buf);\n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n}\n\n \nstatic void test_kmalloc_aligned_oob_read(struct kunit *test)\n{\n\tconst size_t size = 73;\n\tconst size_t align = kmalloc_cache_alignment(size);\n\tstruct expect_report expect = {\n\t\t.type = KFENCE_ERROR_OOB,\n\t\t.fn = test_kmalloc_aligned_oob_read,\n\t\t.is_write = false,\n\t};\n\tchar *buf;\n\n\tbuf = test_alloc(test, size, GFP_KERNEL, ALLOCATE_RIGHT);\n\n\t \n\tREAD_ONCE(*(buf - 1));\n\tKUNIT_EXPECT_FALSE(test, report_available());\n\n\t \n\tREAD_ONCE(*(buf + size));\n\tKUNIT_EXPECT_FALSE(test, report_available());\n\n\t \n\texpect.addr = buf + size + align;\n\tREAD_ONCE(*expect.addr);\n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n\n\ttest_free(buf);\n}\n\nstatic void test_kmalloc_aligned_oob_write(struct kunit *test)\n{\n\tconst size_t size = 73;\n\tstruct expect_report expect = {\n\t\t.type = KFENCE_ERROR_CORRUPTION,\n\t\t.fn = test_kmalloc_aligned_oob_write,\n\t};\n\tchar *buf;\n\n\tbuf = test_alloc(test, size, GFP_KERNEL, ALLOCATE_RIGHT);\n\t \n\texpect.addr = buf + size;\n\tWRITE_ONCE(*expect.addr, READ_ONCE(*expect.addr) + 1);\n\tKUNIT_EXPECT_FALSE(test, report_available());\n\ttest_free(buf);\n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n}\n\n \nstatic void test_shrink_memcache(struct kunit *test)\n{\n\tconst size_t size = 32;\n\tvoid *buf;\n\n\tsetup_test_cache(test, size, 0, NULL);\n\tKUNIT_EXPECT_TRUE(test, test_cache);\n\tbuf = test_alloc(test, size, GFP_KERNEL, ALLOCATE_ANY);\n\tkmem_cache_shrink(test_cache);\n\ttest_free(buf);\n\n\tKUNIT_EXPECT_FALSE(test, report_available());\n}\n\nstatic void ctor_set_x(void *obj)\n{\n\t \n\tmemset(obj, 'x', 8);\n}\n\n \nstatic void test_free_bulk(struct kunit *test)\n{\n\tint iter;\n\n\tfor (iter = 0; iter < 5; iter++) {\n\t\tconst size_t size = setup_test_cache(test, get_random_u32_inclusive(8, 307),\n\t\t\t\t\t\t     0, (iter & 1) ? ctor_set_x : NULL);\n\t\tvoid *objects[] = {\n\t\t\ttest_alloc(test, size, GFP_KERNEL, ALLOCATE_RIGHT),\n\t\t\ttest_alloc(test, size, GFP_KERNEL, ALLOCATE_NONE),\n\t\t\ttest_alloc(test, size, GFP_KERNEL, ALLOCATE_LEFT),\n\t\t\ttest_alloc(test, size, GFP_KERNEL, ALLOCATE_NONE),\n\t\t\ttest_alloc(test, size, GFP_KERNEL, ALLOCATE_NONE),\n\t\t};\n\n\t\tkmem_cache_free_bulk(test_cache, ARRAY_SIZE(objects), objects);\n\t\tKUNIT_ASSERT_FALSE(test, report_available());\n\t\ttest_cache_destroy();\n\t}\n}\n\n \nstatic void test_init_on_free(struct kunit *test)\n{\n\tconst size_t size = 32;\n\tstruct expect_report expect = {\n\t\t.type = KFENCE_ERROR_UAF,\n\t\t.fn = test_init_on_free,\n\t\t.is_write = false,\n\t};\n\tint i;\n\n\tKFENCE_TEST_REQUIRES(test, IS_ENABLED(CONFIG_INIT_ON_FREE_DEFAULT_ON));\n\t \n\n\tsetup_test_cache(test, size, 0, NULL);\n\texpect.addr = test_alloc(test, size, GFP_KERNEL, ALLOCATE_ANY);\n\tfor (i = 0; i < size; i++)\n\t\texpect.addr[i] = i + 1;\n\ttest_free(expect.addr);\n\n\tfor (i = 0; i < size; i++) {\n\t\t \n\t\tKUNIT_EXPECT_EQ(test, expect.addr[i], (char)0);\n\n\t\tif (!i)  \n\t\t\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n\t}\n}\n\n \nstatic void test_memcache_ctor(struct kunit *test)\n{\n\tconst size_t size = 32;\n\tchar *buf;\n\tint i;\n\n\tsetup_test_cache(test, size, 0, ctor_set_x);\n\tbuf = test_alloc(test, size, GFP_KERNEL, ALLOCATE_ANY);\n\n\tfor (i = 0; i < 8; i++)\n\t\tKUNIT_EXPECT_EQ(test, buf[i], (char)'x');\n\n\ttest_free(buf);\n\n\tKUNIT_EXPECT_FALSE(test, report_available());\n}\n\n \nstatic void test_gfpzero(struct kunit *test)\n{\n\tconst size_t size = PAGE_SIZE;  \n\tchar *buf1, *buf2;\n\tint i;\n\n\t \n\tKFENCE_TEST_REQUIRES(test, kfence_sample_interval <= 100);\n\n\tsetup_test_cache(test, size, 0, NULL);\n\tbuf1 = test_alloc(test, size, GFP_KERNEL, ALLOCATE_ANY);\n\tfor (i = 0; i < size; i++)\n\t\tbuf1[i] = i + 1;\n\ttest_free(buf1);\n\n\t \n\tfor (i = 0;; i++) {\n\t\tbuf2 = test_alloc(test, size, GFP_KERNEL | __GFP_ZERO, ALLOCATE_ANY);\n\t\tif (buf1 == buf2)\n\t\t\tbreak;\n\t\ttest_free(buf2);\n\n\t\tif (kthread_should_stop() || (i == CONFIG_KFENCE_NUM_OBJECTS)) {\n\t\t\tkunit_warn(test, \"giving up ... cannot get same object back\\n\");\n\t\t\treturn;\n\t\t}\n\t\tcond_resched();\n\t}\n\n\tfor (i = 0; i < size; i++)\n\t\tKUNIT_EXPECT_EQ(test, buf2[i], (char)0);\n\n\ttest_free(buf2);\n\n\tKUNIT_EXPECT_FALSE(test, report_available());\n}\n\nstatic void test_invalid_access(struct kunit *test)\n{\n\tconst struct expect_report expect = {\n\t\t.type = KFENCE_ERROR_INVALID,\n\t\t.fn = test_invalid_access,\n\t\t.addr = &__kfence_pool[10],\n\t\t.is_write = false,\n\t};\n\n\tREAD_ONCE(__kfence_pool[10]);\n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n}\n\n \nstatic void test_memcache_typesafe_by_rcu(struct kunit *test)\n{\n\tconst size_t size = 32;\n\tstruct expect_report expect = {\n\t\t.type = KFENCE_ERROR_UAF,\n\t\t.fn = test_memcache_typesafe_by_rcu,\n\t\t.is_write = false,\n\t};\n\n\tsetup_test_cache(test, size, SLAB_TYPESAFE_BY_RCU, NULL);\n\tKUNIT_EXPECT_TRUE(test, test_cache);  \n\n\texpect.addr = test_alloc(test, size, GFP_KERNEL, ALLOCATE_ANY);\n\t*expect.addr = 42;\n\n\trcu_read_lock();\n\ttest_free(expect.addr);\n\tKUNIT_EXPECT_EQ(test, *expect.addr, (char)42);\n\t \n\trcu_read_unlock();\n\n\t \n\tKUNIT_EXPECT_FALSE(test, report_available());\n\n\t \n\trcu_barrier();\n\n\t \n\tKUNIT_EXPECT_EQ(test, *expect.addr, (char)42);\n\tKUNIT_EXPECT_TRUE(test, report_matches(&expect));\n}\n\n \nstatic void test_krealloc(struct kunit *test)\n{\n\tconst size_t size = 32;\n\tconst struct expect_report expect = {\n\t\t.type = KFENCE_ERROR_UAF,\n\t\t.fn = test_krealloc,\n\t\t.addr = test_alloc(test, size, GFP_KERNEL, ALLOCATE_ANY),\n\t\t.is_write = false,\n\t};\n\tchar *buf = expect.addr;\n\tint i;\n\n\tKUNIT_EXPECT_FALSE(test, test_cache);\n\tKUNIT_EXPECT_EQ(test, ksize(buf), size);  \n\tfor (i = 0; i < size; i++)\n\t\tbuf[i] = i + 1;\n\n\t \n\tbuf = krealloc(buf, size * 3, GFP_KERNEL);  \n\t \n\tKUNIT_EXPECT_GE(test, ksize(buf), size * 3);\n\tfor (i = 0; i < size; i++)\n\t\tKUNIT_EXPECT_EQ(test, buf[i], (char)(i + 1));\n\tfor (; i < size * 3; i++)  \n\t\tbuf[i] = i + 1;\n\n\tbuf = krealloc(buf, size * 2, GFP_KERNEL);  \n\tKUNIT_EXPECT_GE(test, ksize(buf), size * 2);\n\tfor (i = 0; i < size * 2; i++)\n\t\tKUNIT_EXPECT_EQ(test, buf[i], (char)(i + 1));\n\n\tbuf = krealloc(buf, 0, GFP_KERNEL);  \n\tKUNIT_EXPECT_EQ(test, (unsigned long)buf, (unsigned long)ZERO_SIZE_PTR);\n\tKUNIT_ASSERT_FALSE(test, report_available());  \n\n\tREAD_ONCE(*expect.addr);  \n\tKUNIT_ASSERT_TRUE(test, report_matches(&expect));\n}\n\n \nstatic void test_memcache_alloc_bulk(struct kunit *test)\n{\n\tconst size_t size = 32;\n\tbool pass = false;\n\tunsigned long timeout;\n\n\tsetup_test_cache(test, size, 0, NULL);\n\tKUNIT_EXPECT_TRUE(test, test_cache);  \n\t \n\ttimeout = jiffies + msecs_to_jiffies(100 * kfence_sample_interval);\n\tdo {\n\t\tvoid *objects[100];\n\t\tint i, num = kmem_cache_alloc_bulk(test_cache, GFP_ATOMIC, ARRAY_SIZE(objects),\n\t\t\t\t\t\t   objects);\n\t\tif (!num)\n\t\t\tcontinue;\n\t\tfor (i = 0; i < ARRAY_SIZE(objects); i++) {\n\t\t\tif (is_kfence_address(objects[i])) {\n\t\t\t\tpass = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tkmem_cache_free_bulk(test_cache, num, objects);\n\t\t \n\t\tcond_resched();\n\t} while (!pass && time_before(jiffies, timeout));\n\n\tKUNIT_EXPECT_TRUE(test, pass);\n\tKUNIT_EXPECT_FALSE(test, report_available());\n}\n\n \n#define KFENCE_KUNIT_CASE(test_name)\t\t\t\t\t\t\\\n\t{ .run_case = test_name, .name = #test_name },\t\t\t\t\\\n\t{ .run_case = test_name, .name = #test_name \"-memcache\" }\n\nstatic struct kunit_case kfence_test_cases[] = {\n\tKFENCE_KUNIT_CASE(test_out_of_bounds_read),\n\tKFENCE_KUNIT_CASE(test_out_of_bounds_write),\n\tKFENCE_KUNIT_CASE(test_use_after_free_read),\n\tKFENCE_KUNIT_CASE(test_double_free),\n\tKFENCE_KUNIT_CASE(test_invalid_addr_free),\n\tKFENCE_KUNIT_CASE(test_corruption),\n\tKFENCE_KUNIT_CASE(test_free_bulk),\n\tKFENCE_KUNIT_CASE(test_init_on_free),\n\tKUNIT_CASE(test_kmalloc_aligned_oob_read),\n\tKUNIT_CASE(test_kmalloc_aligned_oob_write),\n\tKUNIT_CASE(test_shrink_memcache),\n\tKUNIT_CASE(test_memcache_ctor),\n\tKUNIT_CASE(test_invalid_access),\n\tKUNIT_CASE(test_gfpzero),\n\tKUNIT_CASE(test_memcache_typesafe_by_rcu),\n\tKUNIT_CASE(test_krealloc),\n\tKUNIT_CASE(test_memcache_alloc_bulk),\n\t{},\n};\n\n \n\nstatic int test_init(struct kunit *test)\n{\n\tunsigned long flags;\n\tint i;\n\n\tif (!__kfence_pool)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&observed.lock, flags);\n\tfor (i = 0; i < ARRAY_SIZE(observed.lines); i++)\n\t\tobserved.lines[i][0] = '\\0';\n\tobserved.nlines = 0;\n\tspin_unlock_irqrestore(&observed.lock, flags);\n\n\t \n\tif (strstr(test->name, \"memcache\"))\n\t\ttest->priv = TEST_PRIV_WANT_MEMCACHE;\n\telse\n\t\ttest->priv = NULL;\n\n\treturn 0;\n}\n\nstatic void test_exit(struct kunit *test)\n{\n\ttest_cache_destroy();\n}\n\nstatic int kfence_suite_init(struct kunit_suite *suite)\n{\n\tregister_trace_console(probe_console, NULL);\n\treturn 0;\n}\n\nstatic void kfence_suite_exit(struct kunit_suite *suite)\n{\n\tunregister_trace_console(probe_console, NULL);\n\ttracepoint_synchronize_unregister();\n}\n\nstatic struct kunit_suite kfence_test_suite = {\n\t.name = \"kfence\",\n\t.test_cases = kfence_test_cases,\n\t.init = test_init,\n\t.exit = test_exit,\n\t.suite_init = kfence_suite_init,\n\t.suite_exit = kfence_suite_exit,\n};\n\nkunit_test_suites(&kfence_test_suite);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_AUTHOR(\"Alexander Potapenko <glider@google.com>, Marco Elver <elver@google.com>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}