{
  "module_name": "debug.c",
  "hash_id": "5eb1a8b28f17c9f888c6c004d9e7792e254018474999d7a305182c96fc91afa0",
  "original_prompt": "Ingested from linux-6.6.14/mm/debug.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/mm.h>\n#include <linux/trace_events.h>\n#include <linux/memcontrol.h>\n#include <trace/events/mmflags.h>\n#include <linux/migrate.h>\n#include <linux/page_owner.h>\n#include <linux/ctype.h>\n\n#include \"internal.h\"\n#include <trace/events/migrate.h>\n\n \n#undef EM\n#undef EMe\n#define EM(a, b)\tb,\n#define EMe(a, b)\tb\n\nconst char *migrate_reason_names[MR_TYPES] = {\n\tMIGRATE_REASON\n};\n\nconst struct trace_print_flags pageflag_names[] = {\n\t__def_pageflag_names,\n\t{0, NULL}\n};\n\nconst struct trace_print_flags pagetype_names[] = {\n\t__def_pagetype_names,\n\t{0, NULL}\n};\n\nconst struct trace_print_flags gfpflag_names[] = {\n\t__def_gfpflag_names,\n\t{0, NULL}\n};\n\nconst struct trace_print_flags vmaflag_names[] = {\n\t__def_vmaflag_names,\n\t{0, NULL}\n};\n\nstatic void __dump_page(struct page *page)\n{\n\tstruct folio *folio = page_folio(page);\n\tstruct page *head = &folio->page;\n\tstruct address_space *mapping;\n\tbool compound = PageCompound(page);\n\t \n\tbool page_cma = is_migrate_cma_page(page);\n\tint mapcount;\n\tchar *type = \"\";\n\n\tif (page < head || (page >= head + MAX_ORDER_NR_PAGES)) {\n\t\t \n\t\tunsigned long tmp = (unsigned long)page->mapping;\n\n\t\tif (tmp & PAGE_MAPPING_ANON)\n\t\t\tmapping = NULL;\n\t\telse\n\t\t\tmapping = (void *)(tmp & ~PAGE_MAPPING_FLAGS);\n\t\thead = page;\n\t\tfolio = (struct folio *)page;\n\t\tcompound = false;\n\t} else {\n\t\tmapping = page_mapping(page);\n\t}\n\n\t \n\tmapcount = PageSlab(head) ? 0 : page_mapcount(page);\n\n\tpr_warn(\"page:%p refcount:%d mapcount:%d mapping:%p index:%#lx pfn:%#lx\\n\",\n\t\t\tpage, page_ref_count(head), mapcount, mapping,\n\t\t\tpage_to_pgoff(page), page_to_pfn(page));\n\tif (compound) {\n\t\tpr_warn(\"head:%p order:%u entire_mapcount:%d nr_pages_mapped:%d pincount:%d\\n\",\n\t\t\t\thead, compound_order(head),\n\t\t\t\tfolio_entire_mapcount(folio),\n\t\t\t\tfolio_nr_pages_mapped(folio),\n\t\t\t\tatomic_read(&folio->_pincount));\n\t}\n\n#ifdef CONFIG_MEMCG\n\tif (head->memcg_data)\n\t\tpr_warn(\"memcg:%lx\\n\", head->memcg_data);\n#endif\n\tif (PageKsm(page))\n\t\ttype = \"ksm \";\n\telse if (PageAnon(page))\n\t\ttype = \"anon \";\n\telse if (mapping)\n\t\tdump_mapping(mapping);\n\tBUILD_BUG_ON(ARRAY_SIZE(pageflag_names) != __NR_PAGEFLAGS + 1);\n\n\tpr_warn(\"%sflags: %pGp%s\\n\", type, &head->flags,\n\t\tpage_cma ? \" CMA\" : \"\");\n\tpr_warn(\"page_type: %pGt\\n\", &head->page_type);\n\n\tprint_hex_dump(KERN_WARNING, \"raw: \", DUMP_PREFIX_NONE, 32,\n\t\t\tsizeof(unsigned long), page,\n\t\t\tsizeof(struct page), false);\n\tif (head != page)\n\t\tprint_hex_dump(KERN_WARNING, \"head: \", DUMP_PREFIX_NONE, 32,\n\t\t\tsizeof(unsigned long), head,\n\t\t\tsizeof(struct page), false);\n}\n\nvoid dump_page(struct page *page, const char *reason)\n{\n\tif (PagePoisoned(page))\n\t\tpr_warn(\"page:%p is uninitialized and poisoned\", page);\n\telse\n\t\t__dump_page(page);\n\tif (reason)\n\t\tpr_warn(\"page dumped because: %s\\n\", reason);\n\tdump_page_owner(page);\n}\nEXPORT_SYMBOL(dump_page);\n\n#ifdef CONFIG_DEBUG_VM\n\nvoid dump_vma(const struct vm_area_struct *vma)\n{\n\tpr_emerg(\"vma %px start %px end %px mm %px\\n\"\n\t\t\"prot %lx anon_vma %px vm_ops %px\\n\"\n\t\t\"pgoff %lx file %px private_data %px\\n\"\n\t\t\"flags: %#lx(%pGv)\\n\",\n\t\tvma, (void *)vma->vm_start, (void *)vma->vm_end, vma->vm_mm,\n\t\t(unsigned long)pgprot_val(vma->vm_page_prot),\n\t\tvma->anon_vma, vma->vm_ops, vma->vm_pgoff,\n\t\tvma->vm_file, vma->vm_private_data,\n\t\tvma->vm_flags, &vma->vm_flags);\n}\nEXPORT_SYMBOL(dump_vma);\n\nvoid dump_mm(const struct mm_struct *mm)\n{\n\tpr_emerg(\"mm %px task_size %lu\\n\"\n#ifdef CONFIG_MMU\n\t\t\"get_unmapped_area %px\\n\"\n#endif\n\t\t\"mmap_base %lu mmap_legacy_base %lu\\n\"\n\t\t\"pgd %px mm_users %d mm_count %d pgtables_bytes %lu map_count %d\\n\"\n\t\t\"hiwater_rss %lx hiwater_vm %lx total_vm %lx locked_vm %lx\\n\"\n\t\t\"pinned_vm %llx data_vm %lx exec_vm %lx stack_vm %lx\\n\"\n\t\t\"start_code %lx end_code %lx start_data %lx end_data %lx\\n\"\n\t\t\"start_brk %lx brk %lx start_stack %lx\\n\"\n\t\t\"arg_start %lx arg_end %lx env_start %lx env_end %lx\\n\"\n\t\t\"binfmt %px flags %lx\\n\"\n#ifdef CONFIG_AIO\n\t\t\"ioctx_table %px\\n\"\n#endif\n#ifdef CONFIG_MEMCG\n\t\t\"owner %px \"\n#endif\n\t\t\"exe_file %px\\n\"\n#ifdef CONFIG_MMU_NOTIFIER\n\t\t\"notifier_subscriptions %px\\n\"\n#endif\n#ifdef CONFIG_NUMA_BALANCING\n\t\t\"numa_next_scan %lu numa_scan_offset %lu numa_scan_seq %d\\n\"\n#endif\n\t\t\"tlb_flush_pending %d\\n\"\n\t\t\"def_flags: %#lx(%pGv)\\n\",\n\n\t\tmm, mm->task_size,\n#ifdef CONFIG_MMU\n\t\tmm->get_unmapped_area,\n#endif\n\t\tmm->mmap_base, mm->mmap_legacy_base,\n\t\tmm->pgd, atomic_read(&mm->mm_users),\n\t\tatomic_read(&mm->mm_count),\n\t\tmm_pgtables_bytes(mm),\n\t\tmm->map_count,\n\t\tmm->hiwater_rss, mm->hiwater_vm, mm->total_vm, mm->locked_vm,\n\t\t(u64)atomic64_read(&mm->pinned_vm),\n\t\tmm->data_vm, mm->exec_vm, mm->stack_vm,\n\t\tmm->start_code, mm->end_code, mm->start_data, mm->end_data,\n\t\tmm->start_brk, mm->brk, mm->start_stack,\n\t\tmm->arg_start, mm->arg_end, mm->env_start, mm->env_end,\n\t\tmm->binfmt, mm->flags,\n#ifdef CONFIG_AIO\n\t\tmm->ioctx_table,\n#endif\n#ifdef CONFIG_MEMCG\n\t\tmm->owner,\n#endif\n\t\tmm->exe_file,\n#ifdef CONFIG_MMU_NOTIFIER\n\t\tmm->notifier_subscriptions,\n#endif\n#ifdef CONFIG_NUMA_BALANCING\n\t\tmm->numa_next_scan, mm->numa_scan_offset, mm->numa_scan_seq,\n#endif\n\t\tatomic_read(&mm->tlb_flush_pending),\n\t\tmm->def_flags, &mm->def_flags\n\t);\n}\nEXPORT_SYMBOL(dump_mm);\n\nstatic bool page_init_poisoning __read_mostly = true;\n\nstatic int __init setup_vm_debug(char *str)\n{\n\tbool __page_init_poisoning = true;\n\n\t \n\tif (*str++ != '=' || !*str)\n\t\tgoto out;\n\n\t__page_init_poisoning = false;\n\tif (*str == '-')\n\t\tgoto out;\n\n\twhile (*str) {\n\t\tswitch (tolower(*str)) {\n\t\tcase'p':\n\t\t\t__page_init_poisoning = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_err(\"vm_debug option '%c' unknown. skipped\\n\",\n\t\t\t       *str);\n\t\t}\n\n\t\tstr++;\n\t}\nout:\n\tif (page_init_poisoning && !__page_init_poisoning)\n\t\tpr_warn(\"Page struct poisoning disabled by kernel command line option 'vm_debug'\\n\");\n\n\tpage_init_poisoning = __page_init_poisoning;\n\n\treturn 1;\n}\n__setup(\"vm_debug\", setup_vm_debug);\n\nvoid page_init_poison(struct page *page, size_t size)\n{\n\tif (page_init_poisoning)\n\t\tmemset(page, PAGE_POISON_PATTERN, size);\n}\n\nvoid vma_iter_dump_tree(const struct vma_iterator *vmi)\n{\n#if defined(CONFIG_DEBUG_VM_MAPLE_TREE)\n\tmas_dump(&vmi->mas);\n\tmt_dump(vmi->mas.tree, mt_dump_hex);\n#endif\t \n}\n\n#endif\t\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}