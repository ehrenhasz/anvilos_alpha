{
  "module_name": "readahead.c",
  "hash_id": "dd3da1a17db573933b9581e1da46bfd1c826b48c06b3597a2ef92b673afe32c3",
  "original_prompt": "Ingested from linux-6.6.14/mm/readahead.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/blkdev.h>\n#include <linux/kernel.h>\n#include <linux/dax.h>\n#include <linux/gfp.h>\n#include <linux/export.h>\n#include <linux/backing-dev.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/pagemap.h>\n#include <linux/psi.h>\n#include <linux/syscalls.h>\n#include <linux/file.h>\n#include <linux/mm_inline.h>\n#include <linux/blk-cgroup.h>\n#include <linux/fadvise.h>\n#include <linux/sched/mm.h>\n\n#include \"internal.h\"\n\n \nvoid\nfile_ra_state_init(struct file_ra_state *ra, struct address_space *mapping)\n{\n\tra->ra_pages = inode_to_bdi(mapping->host)->ra_pages;\n\tra->prev_pos = -1;\n}\nEXPORT_SYMBOL_GPL(file_ra_state_init);\n\nstatic void read_pages(struct readahead_control *rac)\n{\n\tconst struct address_space_operations *aops = rac->mapping->a_ops;\n\tstruct folio *folio;\n\tstruct blk_plug plug;\n\n\tif (!readahead_count(rac))\n\t\treturn;\n\n\tif (unlikely(rac->_workingset))\n\t\tpsi_memstall_enter(&rac->_pflags);\n\tblk_start_plug(&plug);\n\n\tif (aops->readahead) {\n\t\taops->readahead(rac);\n\t\t \n\t\twhile ((folio = readahead_folio(rac)) != NULL) {\n\t\t\tunsigned long nr = folio_nr_pages(folio);\n\n\t\t\tfolio_get(folio);\n\t\t\trac->ra->size -= nr;\n\t\t\tif (rac->ra->async_size >= nr) {\n\t\t\t\trac->ra->async_size -= nr;\n\t\t\t\tfilemap_remove_folio(folio);\n\t\t\t}\n\t\t\tfolio_unlock(folio);\n\t\t\tfolio_put(folio);\n\t\t}\n\t} else {\n\t\twhile ((folio = readahead_folio(rac)) != NULL)\n\t\t\taops->read_folio(rac->file, folio);\n\t}\n\n\tblk_finish_plug(&plug);\n\tif (unlikely(rac->_workingset))\n\t\tpsi_memstall_leave(&rac->_pflags);\n\trac->_workingset = false;\n\n\tBUG_ON(readahead_count(rac));\n}\n\n \nvoid page_cache_ra_unbounded(struct readahead_control *ractl,\n\t\tunsigned long nr_to_read, unsigned long lookahead_size)\n{\n\tstruct address_space *mapping = ractl->mapping;\n\tunsigned long index = readahead_index(ractl);\n\tgfp_t gfp_mask = readahead_gfp_mask(mapping);\n\tunsigned long i;\n\n\t \n\tunsigned int nofs = memalloc_nofs_save();\n\n\tfilemap_invalidate_lock_shared(mapping);\n\t \n\tfor (i = 0; i < nr_to_read; i++) {\n\t\tstruct folio *folio = xa_load(&mapping->i_pages, index + i);\n\n\t\tif (folio && !xa_is_value(folio)) {\n\t\t\t \n\t\t\tread_pages(ractl);\n\t\t\tractl->_index++;\n\t\t\ti = ractl->_index + ractl->_nr_pages - index - 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tfolio = filemap_alloc_folio(gfp_mask, 0);\n\t\tif (!folio)\n\t\t\tbreak;\n\t\tif (filemap_add_folio(mapping, folio, index + i,\n\t\t\t\t\tgfp_mask) < 0) {\n\t\t\tfolio_put(folio);\n\t\t\tread_pages(ractl);\n\t\t\tractl->_index++;\n\t\t\ti = ractl->_index + ractl->_nr_pages - index - 1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (i == nr_to_read - lookahead_size)\n\t\t\tfolio_set_readahead(folio);\n\t\tractl->_workingset |= folio_test_workingset(folio);\n\t\tractl->_nr_pages++;\n\t}\n\n\t \n\tread_pages(ractl);\n\tfilemap_invalidate_unlock_shared(mapping);\n\tmemalloc_nofs_restore(nofs);\n}\nEXPORT_SYMBOL_GPL(page_cache_ra_unbounded);\n\n \nstatic void do_page_cache_ra(struct readahead_control *ractl,\n\t\tunsigned long nr_to_read, unsigned long lookahead_size)\n{\n\tstruct inode *inode = ractl->mapping->host;\n\tunsigned long index = readahead_index(ractl);\n\tloff_t isize = i_size_read(inode);\n\tpgoff_t end_index;\t \n\n\tif (isize == 0)\n\t\treturn;\n\n\tend_index = (isize - 1) >> PAGE_SHIFT;\n\tif (index > end_index)\n\t\treturn;\n\t \n\tif (nr_to_read > end_index - index)\n\t\tnr_to_read = end_index - index + 1;\n\n\tpage_cache_ra_unbounded(ractl, nr_to_read, lookahead_size);\n}\n\n \nvoid force_page_cache_ra(struct readahead_control *ractl,\n\t\tunsigned long nr_to_read)\n{\n\tstruct address_space *mapping = ractl->mapping;\n\tstruct file_ra_state *ra = ractl->ra;\n\tstruct backing_dev_info *bdi = inode_to_bdi(mapping->host);\n\tunsigned long max_pages, index;\n\n\tif (unlikely(!mapping->a_ops->read_folio && !mapping->a_ops->readahead))\n\t\treturn;\n\n\t \n\tindex = readahead_index(ractl);\n\tmax_pages = max_t(unsigned long, bdi->io_pages, ra->ra_pages);\n\tnr_to_read = min_t(unsigned long, nr_to_read, max_pages);\n\twhile (nr_to_read) {\n\t\tunsigned long this_chunk = (2 * 1024 * 1024) / PAGE_SIZE;\n\n\t\tif (this_chunk > nr_to_read)\n\t\t\tthis_chunk = nr_to_read;\n\t\tractl->_index = index;\n\t\tdo_page_cache_ra(ractl, this_chunk, 0);\n\n\t\tindex += this_chunk;\n\t\tnr_to_read -= this_chunk;\n\t}\n}\n\n \nstatic unsigned long get_init_ra_size(unsigned long size, unsigned long max)\n{\n\tunsigned long newsize = roundup_pow_of_two(size);\n\n\tif (newsize <= max / 32)\n\t\tnewsize = newsize * 4;\n\telse if (newsize <= max / 4)\n\t\tnewsize = newsize * 2;\n\telse\n\t\tnewsize = max;\n\n\treturn newsize;\n}\n\n \nstatic unsigned long get_next_ra_size(struct file_ra_state *ra,\n\t\t\t\t      unsigned long max)\n{\n\tunsigned long cur = ra->size;\n\n\tif (cur < max / 16)\n\t\treturn 4 * cur;\n\tif (cur <= max / 2)\n\t\treturn 2 * cur;\n\treturn max;\n}\n\n \n\n \nstatic pgoff_t count_history_pages(struct address_space *mapping,\n\t\t\t\t   pgoff_t index, unsigned long max)\n{\n\tpgoff_t head;\n\n\trcu_read_lock();\n\thead = page_cache_prev_miss(mapping, index - 1, max);\n\trcu_read_unlock();\n\n\treturn index - 1 - head;\n}\n\n \nstatic int try_context_readahead(struct address_space *mapping,\n\t\t\t\t struct file_ra_state *ra,\n\t\t\t\t pgoff_t index,\n\t\t\t\t unsigned long req_size,\n\t\t\t\t unsigned long max)\n{\n\tpgoff_t size;\n\n\tsize = count_history_pages(mapping, index, max);\n\n\t \n\tif (size <= req_size)\n\t\treturn 0;\n\n\t \n\tif (size >= index)\n\t\tsize *= 2;\n\n\tra->start = index;\n\tra->size = min(size + req_size, max);\n\tra->async_size = 1;\n\n\treturn 1;\n}\n\nstatic inline int ra_alloc_folio(struct readahead_control *ractl, pgoff_t index,\n\t\tpgoff_t mark, unsigned int order, gfp_t gfp)\n{\n\tint err;\n\tstruct folio *folio = filemap_alloc_folio(gfp, order);\n\n\tif (!folio)\n\t\treturn -ENOMEM;\n\tmark = round_up(mark, 1UL << order);\n\tif (index == mark)\n\t\tfolio_set_readahead(folio);\n\terr = filemap_add_folio(ractl->mapping, folio, index, gfp);\n\tif (err) {\n\t\tfolio_put(folio);\n\t\treturn err;\n\t}\n\n\tractl->_nr_pages += 1UL << order;\n\tractl->_workingset |= folio_test_workingset(folio);\n\treturn 0;\n}\n\nvoid page_cache_ra_order(struct readahead_control *ractl,\n\t\tstruct file_ra_state *ra, unsigned int new_order)\n{\n\tstruct address_space *mapping = ractl->mapping;\n\tpgoff_t index = readahead_index(ractl);\n\tpgoff_t limit = (i_size_read(mapping->host) - 1) >> PAGE_SHIFT;\n\tpgoff_t mark = index + ra->size - ra->async_size;\n\tint err = 0;\n\tgfp_t gfp = readahead_gfp_mask(mapping);\n\n\tif (!mapping_large_folio_support(mapping) || ra->size < 4)\n\t\tgoto fallback;\n\n\tlimit = min(limit, index + ra->size - 1);\n\n\tif (new_order < MAX_PAGECACHE_ORDER) {\n\t\tnew_order += 2;\n\t\tif (new_order > MAX_PAGECACHE_ORDER)\n\t\t\tnew_order = MAX_PAGECACHE_ORDER;\n\t\twhile ((1 << new_order) > ra->size)\n\t\t\tnew_order--;\n\t}\n\n\tfilemap_invalidate_lock_shared(mapping);\n\twhile (index <= limit) {\n\t\tunsigned int order = new_order;\n\n\t\t \n\t\tif (index & ((1UL << order) - 1)) {\n\t\t\torder = __ffs(index);\n\t\t\tif (order == 1)\n\t\t\t\torder = 0;\n\t\t}\n\t\t \n\t\twhile (index + (1UL << order) - 1 > limit) {\n\t\t\tif (--order == 1)\n\t\t\t\torder = 0;\n\t\t}\n\t\terr = ra_alloc_folio(ractl, index, mark, order, gfp);\n\t\tif (err)\n\t\t\tbreak;\n\t\tindex += 1UL << order;\n\t}\n\n\tif (index > limit) {\n\t\tra->size += index - limit - 1;\n\t\tra->async_size += index - limit - 1;\n\t}\n\n\tread_pages(ractl);\n\tfilemap_invalidate_unlock_shared(mapping);\n\n\t \n\tif (!err)\n\t\treturn;\nfallback:\n\tdo_page_cache_ra(ractl, ra->size, ra->async_size);\n}\n\n \nstatic void ondemand_readahead(struct readahead_control *ractl,\n\t\tstruct folio *folio, unsigned long req_size)\n{\n\tstruct backing_dev_info *bdi = inode_to_bdi(ractl->mapping->host);\n\tstruct file_ra_state *ra = ractl->ra;\n\tunsigned long max_pages = ra->ra_pages;\n\tunsigned long add_pages;\n\tpgoff_t index = readahead_index(ractl);\n\tpgoff_t expected, prev_index;\n\tunsigned int order = folio ? folio_order(folio) : 0;\n\n\t \n\tif (req_size > max_pages && bdi->io_pages > max_pages)\n\t\tmax_pages = min(req_size, bdi->io_pages);\n\n\t \n\tif (!index)\n\t\tgoto initial_readahead;\n\n\t \n\texpected = round_up(ra->start + ra->size - ra->async_size,\n\t\t\t1UL << order);\n\tif (index == expected || index == (ra->start + ra->size)) {\n\t\tra->start += ra->size;\n\t\tra->size = get_next_ra_size(ra, max_pages);\n\t\tra->async_size = ra->size;\n\t\tgoto readit;\n\t}\n\n\t \n\tif (folio) {\n\t\tpgoff_t start;\n\n\t\trcu_read_lock();\n\t\tstart = page_cache_next_miss(ractl->mapping, index + 1,\n\t\t\t\tmax_pages);\n\t\trcu_read_unlock();\n\n\t\tif (!start || start - index > max_pages)\n\t\t\treturn;\n\n\t\tra->start = start;\n\t\tra->size = start - index;\t \n\t\tra->size += req_size;\n\t\tra->size = get_next_ra_size(ra, max_pages);\n\t\tra->async_size = ra->size;\n\t\tgoto readit;\n\t}\n\n\t \n\tif (req_size > max_pages)\n\t\tgoto initial_readahead;\n\n\t \n\tprev_index = (unsigned long long)ra->prev_pos >> PAGE_SHIFT;\n\tif (index - prev_index <= 1UL)\n\t\tgoto initial_readahead;\n\n\t \n\tif (try_context_readahead(ractl->mapping, ra, index, req_size,\n\t\t\tmax_pages))\n\t\tgoto readit;\n\n\t \n\tdo_page_cache_ra(ractl, req_size, 0);\n\treturn;\n\ninitial_readahead:\n\tra->start = index;\n\tra->size = get_init_ra_size(req_size, max_pages);\n\tra->async_size = ra->size > req_size ? ra->size - req_size : ra->size;\n\nreadit:\n\t \n\tif (index == ra->start && ra->size == ra->async_size) {\n\t\tadd_pages = get_next_ra_size(ra, max_pages);\n\t\tif (ra->size + add_pages <= max_pages) {\n\t\t\tra->async_size = add_pages;\n\t\t\tra->size += add_pages;\n\t\t} else {\n\t\t\tra->size = max_pages;\n\t\t\tra->async_size = max_pages >> 1;\n\t\t}\n\t}\n\n\tractl->_index = ra->start;\n\tpage_cache_ra_order(ractl, ra, order);\n}\n\nvoid page_cache_sync_ra(struct readahead_control *ractl,\n\t\tunsigned long req_count)\n{\n\tbool do_forced_ra = ractl->file && (ractl->file->f_mode & FMODE_RANDOM);\n\n\t \n\tif (!ractl->ra->ra_pages || blk_cgroup_congested()) {\n\t\tif (!ractl->file)\n\t\t\treturn;\n\t\treq_count = 1;\n\t\tdo_forced_ra = true;\n\t}\n\n\t \n\tif (do_forced_ra) {\n\t\tforce_page_cache_ra(ractl, req_count);\n\t\treturn;\n\t}\n\n\tondemand_readahead(ractl, NULL, req_count);\n}\nEXPORT_SYMBOL_GPL(page_cache_sync_ra);\n\nvoid page_cache_async_ra(struct readahead_control *ractl,\n\t\tstruct folio *folio, unsigned long req_count)\n{\n\t \n\tif (!ractl->ra->ra_pages)\n\t\treturn;\n\n\t \n\tif (folio_test_writeback(folio))\n\t\treturn;\n\n\tfolio_clear_readahead(folio);\n\n\tif (blk_cgroup_congested())\n\t\treturn;\n\n\tondemand_readahead(ractl, folio, req_count);\n}\nEXPORT_SYMBOL_GPL(page_cache_async_ra);\n\nssize_t ksys_readahead(int fd, loff_t offset, size_t count)\n{\n\tssize_t ret;\n\tstruct fd f;\n\n\tret = -EBADF;\n\tf = fdget(fd);\n\tif (!f.file || !(f.file->f_mode & FMODE_READ))\n\t\tgoto out;\n\n\t \n\tret = -EINVAL;\n\tif (!f.file->f_mapping || !f.file->f_mapping->a_ops ||\n\t    (!S_ISREG(file_inode(f.file)->i_mode) &&\n\t    !S_ISBLK(file_inode(f.file)->i_mode)))\n\t\tgoto out;\n\n\tret = vfs_fadvise(f.file, offset, count, POSIX_FADV_WILLNEED);\nout:\n\tfdput(f);\n\treturn ret;\n}\n\nSYSCALL_DEFINE3(readahead, int, fd, loff_t, offset, size_t, count)\n{\n\treturn ksys_readahead(fd, offset, count);\n}\n\n#if defined(CONFIG_COMPAT) && defined(__ARCH_WANT_COMPAT_READAHEAD)\nCOMPAT_SYSCALL_DEFINE4(readahead, int, fd, compat_arg_u64_dual(offset), size_t, count)\n{\n\treturn ksys_readahead(fd, compat_arg_u64_glue(offset), count);\n}\n#endif\n\n \nvoid readahead_expand(struct readahead_control *ractl,\n\t\t      loff_t new_start, size_t new_len)\n{\n\tstruct address_space *mapping = ractl->mapping;\n\tstruct file_ra_state *ra = ractl->ra;\n\tpgoff_t new_index, new_nr_pages;\n\tgfp_t gfp_mask = readahead_gfp_mask(mapping);\n\n\tnew_index = new_start / PAGE_SIZE;\n\n\t \n\twhile (ractl->_index > new_index) {\n\t\tunsigned long index = ractl->_index - 1;\n\t\tstruct folio *folio = xa_load(&mapping->i_pages, index);\n\n\t\tif (folio && !xa_is_value(folio))\n\t\t\treturn;  \n\n\t\tfolio = filemap_alloc_folio(gfp_mask, 0);\n\t\tif (!folio)\n\t\t\treturn;\n\t\tif (filemap_add_folio(mapping, folio, index, gfp_mask) < 0) {\n\t\t\tfolio_put(folio);\n\t\t\treturn;\n\t\t}\n\t\tif (unlikely(folio_test_workingset(folio)) &&\n\t\t\t\t!ractl->_workingset) {\n\t\t\tractl->_workingset = true;\n\t\t\tpsi_memstall_enter(&ractl->_pflags);\n\t\t}\n\t\tractl->_nr_pages++;\n\t\tractl->_index = folio->index;\n\t}\n\n\tnew_len += new_start - readahead_pos(ractl);\n\tnew_nr_pages = DIV_ROUND_UP(new_len, PAGE_SIZE);\n\n\t \n\twhile (ractl->_nr_pages < new_nr_pages) {\n\t\tunsigned long index = ractl->_index + ractl->_nr_pages;\n\t\tstruct folio *folio = xa_load(&mapping->i_pages, index);\n\n\t\tif (folio && !xa_is_value(folio))\n\t\t\treturn;  \n\n\t\tfolio = filemap_alloc_folio(gfp_mask, 0);\n\t\tif (!folio)\n\t\t\treturn;\n\t\tif (filemap_add_folio(mapping, folio, index, gfp_mask) < 0) {\n\t\t\tfolio_put(folio);\n\t\t\treturn;\n\t\t}\n\t\tif (unlikely(folio_test_workingset(folio)) &&\n\t\t\t\t!ractl->_workingset) {\n\t\t\tractl->_workingset = true;\n\t\t\tpsi_memstall_enter(&ractl->_pflags);\n\t\t}\n\t\tractl->_nr_pages++;\n\t\tif (ra) {\n\t\t\tra->size++;\n\t\t\tra->async_size++;\n\t\t}\n\t}\n}\nEXPORT_SYMBOL(readahead_expand);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}