{
  "module_name": "hooks.c",
  "hash_id": "313fa9760713ff925df3dce1731e82110d18c2e55adec70f3012042db487c618",
  "original_prompt": "Ingested from linux-6.6.14/mm/kmsan/hooks.c",
  "human_readable_source": "\n \n\n#include <linux/cacheflush.h>\n#include <linux/dma-direction.h>\n#include <linux/gfp.h>\n#include <linux/kmsan.h>\n#include <linux/mm.h>\n#include <linux/mm_types.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/usb.h>\n\n#include \"../internal.h\"\n#include \"../slab.h\"\n#include \"kmsan.h\"\n\n \n\nvoid kmsan_task_create(struct task_struct *task)\n{\n\tkmsan_enter_runtime();\n\tkmsan_internal_task_create(task);\n\tkmsan_leave_runtime();\n}\n\nvoid kmsan_task_exit(struct task_struct *task)\n{\n\tstruct kmsan_ctx *ctx = &task->kmsan_ctx;\n\n\tif (!kmsan_enabled || kmsan_in_runtime())\n\t\treturn;\n\n\tctx->allow_reporting = false;\n}\n\nvoid kmsan_slab_alloc(struct kmem_cache *s, void *object, gfp_t flags)\n{\n\tif (unlikely(object == NULL))\n\t\treturn;\n\tif (!kmsan_enabled || kmsan_in_runtime())\n\t\treturn;\n\t \n\tif (s->ctor || (s->flags & SLAB_TYPESAFE_BY_RCU))\n\t\treturn;\n\n\tkmsan_enter_runtime();\n\tif (flags & __GFP_ZERO)\n\t\tkmsan_internal_unpoison_memory(object, s->object_size,\n\t\t\t\t\t       KMSAN_POISON_CHECK);\n\telse\n\t\tkmsan_internal_poison_memory(object, s->object_size, flags,\n\t\t\t\t\t     KMSAN_POISON_CHECK);\n\tkmsan_leave_runtime();\n}\n\nvoid kmsan_slab_free(struct kmem_cache *s, void *object)\n{\n\tif (!kmsan_enabled || kmsan_in_runtime())\n\t\treturn;\n\n\t \n\tif (unlikely(s->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_POISON)))\n\t\treturn;\n\t \n\tif (s->ctor)\n\t\treturn;\n\tkmsan_enter_runtime();\n\tkmsan_internal_poison_memory(object, s->object_size, GFP_KERNEL,\n\t\t\t\t     KMSAN_POISON_CHECK | KMSAN_POISON_FREE);\n\tkmsan_leave_runtime();\n}\n\nvoid kmsan_kmalloc_large(const void *ptr, size_t size, gfp_t flags)\n{\n\tif (unlikely(ptr == NULL))\n\t\treturn;\n\tif (!kmsan_enabled || kmsan_in_runtime())\n\t\treturn;\n\tkmsan_enter_runtime();\n\tif (flags & __GFP_ZERO)\n\t\tkmsan_internal_unpoison_memory((void *)ptr, size,\n\t\t\t\t\t         true);\n\telse\n\t\tkmsan_internal_poison_memory((void *)ptr, size, flags,\n\t\t\t\t\t     KMSAN_POISON_CHECK);\n\tkmsan_leave_runtime();\n}\n\nvoid kmsan_kfree_large(const void *ptr)\n{\n\tstruct page *page;\n\n\tif (!kmsan_enabled || kmsan_in_runtime())\n\t\treturn;\n\tkmsan_enter_runtime();\n\tpage = virt_to_head_page((void *)ptr);\n\tKMSAN_WARN_ON(ptr != page_address(page));\n\tkmsan_internal_poison_memory((void *)ptr,\n\t\t\t\t     page_size(page),\n\t\t\t\t     GFP_KERNEL,\n\t\t\t\t     KMSAN_POISON_CHECK | KMSAN_POISON_FREE);\n\tkmsan_leave_runtime();\n}\n\nstatic unsigned long vmalloc_shadow(unsigned long addr)\n{\n\treturn (unsigned long)kmsan_get_metadata((void *)addr,\n\t\t\t\t\t\t KMSAN_META_SHADOW);\n}\n\nstatic unsigned long vmalloc_origin(unsigned long addr)\n{\n\treturn (unsigned long)kmsan_get_metadata((void *)addr,\n\t\t\t\t\t\t KMSAN_META_ORIGIN);\n}\n\nvoid kmsan_vunmap_range_noflush(unsigned long start, unsigned long end)\n{\n\t__vunmap_range_noflush(vmalloc_shadow(start), vmalloc_shadow(end));\n\t__vunmap_range_noflush(vmalloc_origin(start), vmalloc_origin(end));\n\tflush_cache_vmap(vmalloc_shadow(start), vmalloc_shadow(end));\n\tflush_cache_vmap(vmalloc_origin(start), vmalloc_origin(end));\n}\n\n \nint kmsan_ioremap_page_range(unsigned long start, unsigned long end,\n\t\t\t     phys_addr_t phys_addr, pgprot_t prot,\n\t\t\t     unsigned int page_shift)\n{\n\tgfp_t gfp_mask = GFP_KERNEL | __GFP_ZERO;\n\tstruct page *shadow, *origin;\n\tunsigned long off = 0;\n\tint nr, err = 0, clean = 0, mapped;\n\n\tif (!kmsan_enabled || kmsan_in_runtime())\n\t\treturn 0;\n\n\tnr = (end - start) / PAGE_SIZE;\n\tkmsan_enter_runtime();\n\tfor (int i = 0; i < nr; i++, off += PAGE_SIZE, clean = i) {\n\t\tshadow = alloc_pages(gfp_mask, 1);\n\t\torigin = alloc_pages(gfp_mask, 1);\n\t\tif (!shadow || !origin) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto ret;\n\t\t}\n\t\tmapped = __vmap_pages_range_noflush(\n\t\t\tvmalloc_shadow(start + off),\n\t\t\tvmalloc_shadow(start + off + PAGE_SIZE), prot, &shadow,\n\t\t\tPAGE_SHIFT);\n\t\tif (mapped) {\n\t\t\terr = mapped;\n\t\t\tgoto ret;\n\t\t}\n\t\tshadow = NULL;\n\t\tmapped = __vmap_pages_range_noflush(\n\t\t\tvmalloc_origin(start + off),\n\t\t\tvmalloc_origin(start + off + PAGE_SIZE), prot, &origin,\n\t\t\tPAGE_SHIFT);\n\t\tif (mapped) {\n\t\t\t__vunmap_range_noflush(\n\t\t\t\tvmalloc_shadow(start + off),\n\t\t\t\tvmalloc_shadow(start + off + PAGE_SIZE));\n\t\t\terr = mapped;\n\t\t\tgoto ret;\n\t\t}\n\t\torigin = NULL;\n\t}\n\t \n\tclean = 0;\n\nret:\n\tif (clean > 0) {\n\t\t \n\t\tif (shadow)\n\t\t\t__free_pages(shadow, 1);\n\t\tif (origin)\n\t\t\t__free_pages(origin, 1);\n\t\t__vunmap_range_noflush(\n\t\t\tvmalloc_shadow(start),\n\t\t\tvmalloc_shadow(start + clean * PAGE_SIZE));\n\t\t__vunmap_range_noflush(\n\t\t\tvmalloc_origin(start),\n\t\t\tvmalloc_origin(start + clean * PAGE_SIZE));\n\t}\n\tflush_cache_vmap(vmalloc_shadow(start), vmalloc_shadow(end));\n\tflush_cache_vmap(vmalloc_origin(start), vmalloc_origin(end));\n\tkmsan_leave_runtime();\n\treturn err;\n}\n\nvoid kmsan_iounmap_page_range(unsigned long start, unsigned long end)\n{\n\tunsigned long v_shadow, v_origin;\n\tstruct page *shadow, *origin;\n\tint nr;\n\n\tif (!kmsan_enabled || kmsan_in_runtime())\n\t\treturn;\n\n\tnr = (end - start) / PAGE_SIZE;\n\tkmsan_enter_runtime();\n\tv_shadow = (unsigned long)vmalloc_shadow(start);\n\tv_origin = (unsigned long)vmalloc_origin(start);\n\tfor (int i = 0; i < nr;\n\t     i++, v_shadow += PAGE_SIZE, v_origin += PAGE_SIZE) {\n\t\tshadow = kmsan_vmalloc_to_page_or_null((void *)v_shadow);\n\t\torigin = kmsan_vmalloc_to_page_or_null((void *)v_origin);\n\t\t__vunmap_range_noflush(v_shadow, vmalloc_shadow(end));\n\t\t__vunmap_range_noflush(v_origin, vmalloc_origin(end));\n\t\tif (shadow)\n\t\t\t__free_pages(shadow, 1);\n\t\tif (origin)\n\t\t\t__free_pages(origin, 1);\n\t}\n\tflush_cache_vmap(vmalloc_shadow(start), vmalloc_shadow(end));\n\tflush_cache_vmap(vmalloc_origin(start), vmalloc_origin(end));\n\tkmsan_leave_runtime();\n}\n\nvoid kmsan_copy_to_user(void __user *to, const void *from, size_t to_copy,\n\t\t\tsize_t left)\n{\n\tunsigned long ua_flags;\n\n\tif (!kmsan_enabled || kmsan_in_runtime())\n\t\treturn;\n\t \n\n\t \n\tif (!to_copy)\n\t\treturn;\n\t \n\tif (to_copy <= left)\n\t\treturn;\n\n\tua_flags = user_access_save();\n\tif ((u64)to < TASK_SIZE) {\n\t\t \n\t\tkmsan_internal_check_memory((void *)from, to_copy - left, to,\n\t\t\t\t\t    REASON_COPY_TO_USER);\n\t} else {\n\t\t \n\t\tkmsan_internal_memmove_metadata((void *)to, (void *)from,\n\t\t\t\t\t\tto_copy - left);\n\t}\n\tuser_access_restore(ua_flags);\n}\nEXPORT_SYMBOL(kmsan_copy_to_user);\n\n \nvoid kmsan_handle_urb(const struct urb *urb, bool is_out)\n{\n\tif (!urb)\n\t\treturn;\n\tif (is_out)\n\t\tkmsan_internal_check_memory(urb->transfer_buffer,\n\t\t\t\t\t    urb->transfer_buffer_length,\n\t\t\t\t\t      0, REASON_SUBMIT_URB);\n\telse\n\t\tkmsan_internal_unpoison_memory(urb->transfer_buffer,\n\t\t\t\t\t       urb->transfer_buffer_length,\n\t\t\t\t\t         false);\n}\nEXPORT_SYMBOL_GPL(kmsan_handle_urb);\n\nstatic void kmsan_handle_dma_page(const void *addr, size_t size,\n\t\t\t\t  enum dma_data_direction dir)\n{\n\tswitch (dir) {\n\tcase DMA_BIDIRECTIONAL:\n\t\tkmsan_internal_check_memory((void *)addr, size,   0,\n\t\t\t\t\t    REASON_ANY);\n\t\tkmsan_internal_unpoison_memory((void *)addr, size,\n\t\t\t\t\t         false);\n\t\tbreak;\n\tcase DMA_TO_DEVICE:\n\t\tkmsan_internal_check_memory((void *)addr, size,   0,\n\t\t\t\t\t    REASON_ANY);\n\t\tbreak;\n\tcase DMA_FROM_DEVICE:\n\t\tkmsan_internal_unpoison_memory((void *)addr, size,\n\t\t\t\t\t         false);\n\t\tbreak;\n\tcase DMA_NONE:\n\t\tbreak;\n\t}\n}\n\n \nvoid kmsan_handle_dma(struct page *page, size_t offset, size_t size,\n\t\t      enum dma_data_direction dir)\n{\n\tu64 page_offset, to_go, addr;\n\n\tif (PageHighMem(page))\n\t\treturn;\n\taddr = (u64)page_address(page) + offset;\n\t \n\twhile (size > 0) {\n\t\tpage_offset = offset_in_page(addr);\n\t\tto_go = min(PAGE_SIZE - page_offset, (u64)size);\n\t\tkmsan_handle_dma_page((void *)addr, to_go, dir);\n\t\taddr += to_go;\n\t\tsize -= to_go;\n\t}\n}\n\nvoid kmsan_handle_dma_sg(struct scatterlist *sg, int nents,\n\t\t\t enum dma_data_direction dir)\n{\n\tstruct scatterlist *item;\n\tint i;\n\n\tfor_each_sg(sg, item, nents, i)\n\t\tkmsan_handle_dma(sg_page(item), item->offset, item->length,\n\t\t\t\t dir);\n}\n\n \nvoid kmsan_poison_memory(const void *address, size_t size, gfp_t flags)\n{\n\tif (!kmsan_enabled || kmsan_in_runtime())\n\t\treturn;\n\tkmsan_enter_runtime();\n\t \n\tkmsan_internal_poison_memory((void *)address, size, flags,\n\t\t\t\t     KMSAN_POISON_NOCHECK);\n\tkmsan_leave_runtime();\n}\nEXPORT_SYMBOL(kmsan_poison_memory);\n\nvoid kmsan_unpoison_memory(const void *address, size_t size)\n{\n\tunsigned long ua_flags;\n\n\tif (!kmsan_enabled || kmsan_in_runtime())\n\t\treturn;\n\n\tua_flags = user_access_save();\n\tkmsan_enter_runtime();\n\t \n\tkmsan_internal_unpoison_memory((void *)address, size,\n\t\t\t\t       KMSAN_POISON_NOCHECK);\n\tkmsan_leave_runtime();\n\tuser_access_restore(ua_flags);\n}\nEXPORT_SYMBOL(kmsan_unpoison_memory);\n\n \nvoid kmsan_unpoison_entry_regs(const struct pt_regs *regs)\n{\n\tunsigned long ua_flags;\n\n\tif (!kmsan_enabled)\n\t\treturn;\n\n\tua_flags = user_access_save();\n\tkmsan_internal_unpoison_memory((void *)regs, sizeof(*regs),\n\t\t\t\t       KMSAN_POISON_NOCHECK);\n\tuser_access_restore(ua_flags);\n}\n\nvoid kmsan_check_memory(const void *addr, size_t size)\n{\n\tif (!kmsan_enabled)\n\t\treturn;\n\treturn kmsan_internal_check_memory((void *)addr, size,   0,\n\t\t\t\t\t   REASON_ANY);\n}\nEXPORT_SYMBOL(kmsan_check_memory);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}