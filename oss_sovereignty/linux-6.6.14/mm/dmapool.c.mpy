{
  "module_name": "dmapool.c",
  "hash_id": "1738d4b87847b154564f01d7be9161edd456078f1992e10cc81c02d05914fe3d",
  "original_prompt": "Ingested from linux-6.6.14/mm/dmapool.c",
  "human_readable_source": "\n \n\n#include <linux/device.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmapool.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/poison.h>\n#include <linux/sched.h>\n#include <linux/sched/mm.h>\n#include <linux/slab.h>\n#include <linux/stat.h>\n#include <linux/spinlock.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/wait.h>\n\n#if defined(CONFIG_DEBUG_SLAB) || defined(CONFIG_SLUB_DEBUG_ON)\n#define DMAPOOL_DEBUG 1\n#endif\n\nstruct dma_block {\n\tstruct dma_block *next_block;\n\tdma_addr_t dma;\n};\n\nstruct dma_pool {\t\t \n\tstruct list_head page_list;\n\tspinlock_t lock;\n\tstruct dma_block *next_block;\n\tsize_t nr_blocks;\n\tsize_t nr_active;\n\tsize_t nr_pages;\n\tstruct device *dev;\n\tunsigned int size;\n\tunsigned int allocation;\n\tunsigned int boundary;\n\tchar name[32];\n\tstruct list_head pools;\n};\n\nstruct dma_page {\t\t \n\tstruct list_head page_list;\n\tvoid *vaddr;\n\tdma_addr_t dma;\n};\n\nstatic DEFINE_MUTEX(pools_lock);\nstatic DEFINE_MUTEX(pools_reg_lock);\n\nstatic ssize_t pools_show(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct dma_pool *pool;\n\tunsigned size;\n\n\tsize = sysfs_emit(buf, \"poolinfo - 0.1\\n\");\n\n\tmutex_lock(&pools_lock);\n\tlist_for_each_entry(pool, &dev->dma_pools, pools) {\n\t\t \n\t\tsize += sysfs_emit_at(buf, size, \"%-16s %4zu %4zu %4u %2zu\\n\",\n\t\t\t\t      pool->name, pool->nr_active,\n\t\t\t\t      pool->nr_blocks, pool->size,\n\t\t\t\t      pool->nr_pages);\n\t}\n\tmutex_unlock(&pools_lock);\n\n\treturn size;\n}\n\nstatic DEVICE_ATTR_RO(pools);\n\n#ifdef DMAPOOL_DEBUG\nstatic void pool_check_block(struct dma_pool *pool, struct dma_block *block,\n\t\t\t     gfp_t mem_flags)\n{\n\tu8 *data = (void *)block;\n\tint i;\n\n\tfor (i = sizeof(struct dma_block); i < pool->size; i++) {\n\t\tif (data[i] == POOL_POISON_FREED)\n\t\t\tcontinue;\n\t\tdev_err(pool->dev, \"%s %s, %p (corrupted)\\n\", __func__,\n\t\t\tpool->name, block);\n\n\t\t \n\t\tprint_hex_dump(KERN_ERR, \"\", DUMP_PREFIX_OFFSET, 16, 1,\n\t\t\t\tdata, pool->size, 1);\n\t\tbreak;\n\t}\n\n\tif (!want_init_on_alloc(mem_flags))\n\t\tmemset(block, POOL_POISON_ALLOCATED, pool->size);\n}\n\nstatic struct dma_page *pool_find_page(struct dma_pool *pool, dma_addr_t dma)\n{\n\tstruct dma_page *page;\n\n\tlist_for_each_entry(page, &pool->page_list, page_list) {\n\t\tif (dma < page->dma)\n\t\t\tcontinue;\n\t\tif ((dma - page->dma) < pool->allocation)\n\t\t\treturn page;\n\t}\n\treturn NULL;\n}\n\nstatic bool pool_block_err(struct dma_pool *pool, void *vaddr, dma_addr_t dma)\n{\n\tstruct dma_block *block = pool->next_block;\n\tstruct dma_page *page;\n\n\tpage = pool_find_page(pool, dma);\n\tif (!page) {\n\t\tdev_err(pool->dev, \"%s %s, %p/%pad (bad dma)\\n\",\n\t\t\t__func__, pool->name, vaddr, &dma);\n\t\treturn true;\n\t}\n\n\twhile (block) {\n\t\tif (block != vaddr) {\n\t\t\tblock = block->next_block;\n\t\t\tcontinue;\n\t\t}\n\t\tdev_err(pool->dev, \"%s %s, dma %pad already free\\n\",\n\t\t\t__func__, pool->name, &dma);\n\t\treturn true;\n\t}\n\n\tmemset(vaddr, POOL_POISON_FREED, pool->size);\n\treturn false;\n}\n\nstatic void pool_init_page(struct dma_pool *pool, struct dma_page *page)\n{\n\tmemset(page->vaddr, POOL_POISON_FREED, pool->allocation);\n}\n#else\nstatic void pool_check_block(struct dma_pool *pool, struct dma_block *block,\n\t\t\t     gfp_t mem_flags)\n{\n}\n\nstatic bool pool_block_err(struct dma_pool *pool, void *vaddr, dma_addr_t dma)\n{\n\tif (want_init_on_free())\n\t\tmemset(vaddr, 0, pool->size);\n\treturn false;\n}\n\nstatic void pool_init_page(struct dma_pool *pool, struct dma_page *page)\n{\n}\n#endif\n\nstatic struct dma_block *pool_block_pop(struct dma_pool *pool)\n{\n\tstruct dma_block *block = pool->next_block;\n\n\tif (block) {\n\t\tpool->next_block = block->next_block;\n\t\tpool->nr_active++;\n\t}\n\treturn block;\n}\n\nstatic void pool_block_push(struct dma_pool *pool, struct dma_block *block,\n\t\t\t    dma_addr_t dma)\n{\n\tblock->dma = dma;\n\tblock->next_block = pool->next_block;\n\tpool->next_block = block;\n}\n\n\n \nstruct dma_pool *dma_pool_create(const char *name, struct device *dev,\n\t\t\t\t size_t size, size_t align, size_t boundary)\n{\n\tstruct dma_pool *retval;\n\tsize_t allocation;\n\tbool empty;\n\n\tif (!dev)\n\t\treturn NULL;\n\n\tif (align == 0)\n\t\talign = 1;\n\telse if (align & (align - 1))\n\t\treturn NULL;\n\n\tif (size == 0 || size > INT_MAX)\n\t\treturn NULL;\n\tif (size < sizeof(struct dma_block))\n\t\tsize = sizeof(struct dma_block);\n\n\tsize = ALIGN(size, align);\n\tallocation = max_t(size_t, size, PAGE_SIZE);\n\n\tif (!boundary)\n\t\tboundary = allocation;\n\telse if ((boundary < size) || (boundary & (boundary - 1)))\n\t\treturn NULL;\n\n\tboundary = min(boundary, allocation);\n\n\tretval = kzalloc(sizeof(*retval), GFP_KERNEL);\n\tif (!retval)\n\t\treturn retval;\n\n\tstrscpy(retval->name, name, sizeof(retval->name));\n\n\tretval->dev = dev;\n\n\tINIT_LIST_HEAD(&retval->page_list);\n\tspin_lock_init(&retval->lock);\n\tretval->size = size;\n\tretval->boundary = boundary;\n\tretval->allocation = allocation;\n\tINIT_LIST_HEAD(&retval->pools);\n\n\t \n\tmutex_lock(&pools_reg_lock);\n\tmutex_lock(&pools_lock);\n\tempty = list_empty(&dev->dma_pools);\n\tlist_add(&retval->pools, &dev->dma_pools);\n\tmutex_unlock(&pools_lock);\n\tif (empty) {\n\t\tint err;\n\n\t\terr = device_create_file(dev, &dev_attr_pools);\n\t\tif (err) {\n\t\t\tmutex_lock(&pools_lock);\n\t\t\tlist_del(&retval->pools);\n\t\t\tmutex_unlock(&pools_lock);\n\t\t\tmutex_unlock(&pools_reg_lock);\n\t\t\tkfree(retval);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\tmutex_unlock(&pools_reg_lock);\n\treturn retval;\n}\nEXPORT_SYMBOL(dma_pool_create);\n\nstatic void pool_initialise_page(struct dma_pool *pool, struct dma_page *page)\n{\n\tunsigned int next_boundary = pool->boundary, offset = 0;\n\tstruct dma_block *block, *first = NULL, *last = NULL;\n\n\tpool_init_page(pool, page);\n\twhile (offset + pool->size <= pool->allocation) {\n\t\tif (offset + pool->size > next_boundary) {\n\t\t\toffset = next_boundary;\n\t\t\tnext_boundary += pool->boundary;\n\t\t\tcontinue;\n\t\t}\n\n\t\tblock = page->vaddr + offset;\n\t\tblock->dma = page->dma + offset;\n\t\tblock->next_block = NULL;\n\n\t\tif (last)\n\t\t\tlast->next_block = block;\n\t\telse\n\t\t\tfirst = block;\n\t\tlast = block;\n\n\t\toffset += pool->size;\n\t\tpool->nr_blocks++;\n\t}\n\n\tlast->next_block = pool->next_block;\n\tpool->next_block = first;\n\n\tlist_add(&page->page_list, &pool->page_list);\n\tpool->nr_pages++;\n}\n\nstatic struct dma_page *pool_alloc_page(struct dma_pool *pool, gfp_t mem_flags)\n{\n\tstruct dma_page *page;\n\n\tpage = kmalloc(sizeof(*page), mem_flags);\n\tif (!page)\n\t\treturn NULL;\n\n\tpage->vaddr = dma_alloc_coherent(pool->dev, pool->allocation,\n\t\t\t\t\t &page->dma, mem_flags);\n\tif (!page->vaddr) {\n\t\tkfree(page);\n\t\treturn NULL;\n\t}\n\n\treturn page;\n}\n\n \nvoid dma_pool_destroy(struct dma_pool *pool)\n{\n\tstruct dma_page *page, *tmp;\n\tbool empty, busy = false;\n\n\tif (unlikely(!pool))\n\t\treturn;\n\n\tmutex_lock(&pools_reg_lock);\n\tmutex_lock(&pools_lock);\n\tlist_del(&pool->pools);\n\tempty = list_empty(&pool->dev->dma_pools);\n\tmutex_unlock(&pools_lock);\n\tif (empty)\n\t\tdevice_remove_file(pool->dev, &dev_attr_pools);\n\tmutex_unlock(&pools_reg_lock);\n\n\tif (pool->nr_active) {\n\t\tdev_err(pool->dev, \"%s %s busy\\n\", __func__, pool->name);\n\t\tbusy = true;\n\t}\n\n\tlist_for_each_entry_safe(page, tmp, &pool->page_list, page_list) {\n\t\tif (!busy)\n\t\t\tdma_free_coherent(pool->dev, pool->allocation,\n\t\t\t\t\t  page->vaddr, page->dma);\n\t\tlist_del(&page->page_list);\n\t\tkfree(page);\n\t}\n\n\tkfree(pool);\n}\nEXPORT_SYMBOL(dma_pool_destroy);\n\n \nvoid *dma_pool_alloc(struct dma_pool *pool, gfp_t mem_flags,\n\t\t     dma_addr_t *handle)\n{\n\tstruct dma_block *block;\n\tstruct dma_page *page;\n\tunsigned long flags;\n\n\tmight_alloc(mem_flags);\n\n\tspin_lock_irqsave(&pool->lock, flags);\n\tblock = pool_block_pop(pool);\n\tif (!block) {\n\t\t \n\t\tspin_unlock_irqrestore(&pool->lock, flags);\n\n\t\tpage = pool_alloc_page(pool, mem_flags & (~__GFP_ZERO));\n\t\tif (!page)\n\t\t\treturn NULL;\n\n\t\tspin_lock_irqsave(&pool->lock, flags);\n\t\tpool_initialise_page(pool, page);\n\t\tblock = pool_block_pop(pool);\n\t}\n\tspin_unlock_irqrestore(&pool->lock, flags);\n\n\t*handle = block->dma;\n\tpool_check_block(pool, block, mem_flags);\n\tif (want_init_on_alloc(mem_flags))\n\t\tmemset(block, 0, pool->size);\n\n\treturn block;\n}\nEXPORT_SYMBOL(dma_pool_alloc);\n\n \nvoid dma_pool_free(struct dma_pool *pool, void *vaddr, dma_addr_t dma)\n{\n\tstruct dma_block *block = vaddr;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&pool->lock, flags);\n\tif (!pool_block_err(pool, vaddr, dma)) {\n\t\tpool_block_push(pool, block, dma);\n\t\tpool->nr_active--;\n\t}\n\tspin_unlock_irqrestore(&pool->lock, flags);\n}\nEXPORT_SYMBOL(dma_pool_free);\n\n \nstatic void dmam_pool_release(struct device *dev, void *res)\n{\n\tstruct dma_pool *pool = *(struct dma_pool **)res;\n\n\tdma_pool_destroy(pool);\n}\n\nstatic int dmam_pool_match(struct device *dev, void *res, void *match_data)\n{\n\treturn *(struct dma_pool **)res == match_data;\n}\n\n \nstruct dma_pool *dmam_pool_create(const char *name, struct device *dev,\n\t\t\t\t  size_t size, size_t align, size_t allocation)\n{\n\tstruct dma_pool **ptr, *pool;\n\n\tptr = devres_alloc(dmam_pool_release, sizeof(*ptr), GFP_KERNEL);\n\tif (!ptr)\n\t\treturn NULL;\n\n\tpool = *ptr = dma_pool_create(name, dev, size, align, allocation);\n\tif (pool)\n\t\tdevres_add(dev, ptr);\n\telse\n\t\tdevres_free(ptr);\n\n\treturn pool;\n}\nEXPORT_SYMBOL(dmam_pool_create);\n\n \nvoid dmam_pool_destroy(struct dma_pool *pool)\n{\n\tstruct device *dev = pool->dev;\n\n\tWARN_ON(devres_release(dev, dmam_pool_release, dmam_pool_match, pool));\n}\nEXPORT_SYMBOL(dmam_pool_destroy);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}