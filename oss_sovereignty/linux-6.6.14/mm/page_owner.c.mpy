{
  "module_name": "page_owner.c",
  "hash_id": "dc778988c0e6b2ff2d7c875afd7d9b4d119a6b8a3840f9a4968a25120e4602c2",
  "original_prompt": "Ingested from linux-6.6.14/mm/page_owner.c",
  "human_readable_source": "\n#include <linux/debugfs.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/memblock.h>\n#include <linux/stacktrace.h>\n#include <linux/page_owner.h>\n#include <linux/jump_label.h>\n#include <linux/migrate.h>\n#include <linux/stackdepot.h>\n#include <linux/seq_file.h>\n#include <linux/memcontrol.h>\n#include <linux/sched/clock.h>\n\n#include \"internal.h\"\n\n \n#define PAGE_OWNER_STACK_DEPTH (16)\n\nstruct page_owner {\n\tunsigned short order;\n\tshort last_migrate_reason;\n\tgfp_t gfp_mask;\n\tdepot_stack_handle_t handle;\n\tdepot_stack_handle_t free_handle;\n\tu64 ts_nsec;\n\tu64 free_ts_nsec;\n\tchar comm[TASK_COMM_LEN];\n\tpid_t pid;\n\tpid_t tgid;\n};\n\nstatic bool page_owner_enabled __initdata;\nDEFINE_STATIC_KEY_FALSE(page_owner_inited);\n\nstatic depot_stack_handle_t dummy_handle;\nstatic depot_stack_handle_t failure_handle;\nstatic depot_stack_handle_t early_handle;\n\nstatic void init_early_allocated_pages(void);\n\nstatic int __init early_page_owner_param(char *buf)\n{\n\tint ret = kstrtobool(buf, &page_owner_enabled);\n\n\tif (page_owner_enabled)\n\t\tstack_depot_request_early_init();\n\n\treturn ret;\n}\nearly_param(\"page_owner\", early_page_owner_param);\n\nstatic __init bool need_page_owner(void)\n{\n\treturn page_owner_enabled;\n}\n\nstatic __always_inline depot_stack_handle_t create_dummy_stack(void)\n{\n\tunsigned long entries[4];\n\tunsigned int nr_entries;\n\n\tnr_entries = stack_trace_save(entries, ARRAY_SIZE(entries), 0);\n\treturn stack_depot_save(entries, nr_entries, GFP_KERNEL);\n}\n\nstatic noinline void register_dummy_stack(void)\n{\n\tdummy_handle = create_dummy_stack();\n}\n\nstatic noinline void register_failure_stack(void)\n{\n\tfailure_handle = create_dummy_stack();\n}\n\nstatic noinline void register_early_stack(void)\n{\n\tearly_handle = create_dummy_stack();\n}\n\nstatic __init void init_page_owner(void)\n{\n\tif (!page_owner_enabled)\n\t\treturn;\n\n\tregister_dummy_stack();\n\tregister_failure_stack();\n\tregister_early_stack();\n\tstatic_branch_enable(&page_owner_inited);\n\tinit_early_allocated_pages();\n}\n\nstruct page_ext_operations page_owner_ops = {\n\t.size = sizeof(struct page_owner),\n\t.need = need_page_owner,\n\t.init = init_page_owner,\n\t.need_shared_flags = true,\n};\n\nstatic inline struct page_owner *get_page_owner(struct page_ext *page_ext)\n{\n\treturn page_ext_data(page_ext, &page_owner_ops);\n}\n\nstatic noinline depot_stack_handle_t save_stack(gfp_t flags)\n{\n\tunsigned long entries[PAGE_OWNER_STACK_DEPTH];\n\tdepot_stack_handle_t handle;\n\tunsigned int nr_entries;\n\n\t \n\tif (current->in_page_owner)\n\t\treturn dummy_handle;\n\tcurrent->in_page_owner = 1;\n\n\tnr_entries = stack_trace_save(entries, ARRAY_SIZE(entries), 2);\n\thandle = stack_depot_save(entries, nr_entries, flags);\n\tif (!handle)\n\t\thandle = failure_handle;\n\n\tcurrent->in_page_owner = 0;\n\treturn handle;\n}\n\nvoid __reset_page_owner(struct page *page, unsigned short order)\n{\n\tint i;\n\tstruct page_ext *page_ext;\n\tdepot_stack_handle_t handle;\n\tstruct page_owner *page_owner;\n\tu64 free_ts_nsec = local_clock();\n\n\tpage_ext = page_ext_get(page);\n\tif (unlikely(!page_ext))\n\t\treturn;\n\n\thandle = save_stack(GFP_NOWAIT | __GFP_NOWARN);\n\tfor (i = 0; i < (1 << order); i++) {\n\t\t__clear_bit(PAGE_EXT_OWNER_ALLOCATED, &page_ext->flags);\n\t\tpage_owner = get_page_owner(page_ext);\n\t\tpage_owner->free_handle = handle;\n\t\tpage_owner->free_ts_nsec = free_ts_nsec;\n\t\tpage_ext = page_ext_next(page_ext);\n\t}\n\tpage_ext_put(page_ext);\n}\n\nstatic inline void __set_page_owner_handle(struct page_ext *page_ext,\n\t\t\t\t\tdepot_stack_handle_t handle,\n\t\t\t\t\tunsigned short order, gfp_t gfp_mask)\n{\n\tstruct page_owner *page_owner;\n\tint i;\n\tu64 ts_nsec = local_clock();\n\n\tfor (i = 0; i < (1 << order); i++) {\n\t\tpage_owner = get_page_owner(page_ext);\n\t\tpage_owner->handle = handle;\n\t\tpage_owner->order = order;\n\t\tpage_owner->gfp_mask = gfp_mask;\n\t\tpage_owner->last_migrate_reason = -1;\n\t\tpage_owner->pid = current->pid;\n\t\tpage_owner->tgid = current->tgid;\n\t\tpage_owner->ts_nsec = ts_nsec;\n\t\tstrscpy(page_owner->comm, current->comm,\n\t\t\tsizeof(page_owner->comm));\n\t\t__set_bit(PAGE_EXT_OWNER, &page_ext->flags);\n\t\t__set_bit(PAGE_EXT_OWNER_ALLOCATED, &page_ext->flags);\n\n\t\tpage_ext = page_ext_next(page_ext);\n\t}\n}\n\nnoinline void __set_page_owner(struct page *page, unsigned short order,\n\t\t\t\t\tgfp_t gfp_mask)\n{\n\tstruct page_ext *page_ext;\n\tdepot_stack_handle_t handle;\n\n\thandle = save_stack(gfp_mask);\n\n\tpage_ext = page_ext_get(page);\n\tif (unlikely(!page_ext))\n\t\treturn;\n\t__set_page_owner_handle(page_ext, handle, order, gfp_mask);\n\tpage_ext_put(page_ext);\n}\n\nvoid __set_page_owner_migrate_reason(struct page *page, int reason)\n{\n\tstruct page_ext *page_ext = page_ext_get(page);\n\tstruct page_owner *page_owner;\n\n\tif (unlikely(!page_ext))\n\t\treturn;\n\n\tpage_owner = get_page_owner(page_ext);\n\tpage_owner->last_migrate_reason = reason;\n\tpage_ext_put(page_ext);\n}\n\nvoid __split_page_owner(struct page *page, unsigned int nr)\n{\n\tint i;\n\tstruct page_ext *page_ext = page_ext_get(page);\n\tstruct page_owner *page_owner;\n\n\tif (unlikely(!page_ext))\n\t\treturn;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tpage_owner = get_page_owner(page_ext);\n\t\tpage_owner->order = 0;\n\t\tpage_ext = page_ext_next(page_ext);\n\t}\n\tpage_ext_put(page_ext);\n}\n\nvoid __folio_copy_owner(struct folio *newfolio, struct folio *old)\n{\n\tstruct page_ext *old_ext;\n\tstruct page_ext *new_ext;\n\tstruct page_owner *old_page_owner, *new_page_owner;\n\n\told_ext = page_ext_get(&old->page);\n\tif (unlikely(!old_ext))\n\t\treturn;\n\n\tnew_ext = page_ext_get(&newfolio->page);\n\tif (unlikely(!new_ext)) {\n\t\tpage_ext_put(old_ext);\n\t\treturn;\n\t}\n\n\told_page_owner = get_page_owner(old_ext);\n\tnew_page_owner = get_page_owner(new_ext);\n\tnew_page_owner->order = old_page_owner->order;\n\tnew_page_owner->gfp_mask = old_page_owner->gfp_mask;\n\tnew_page_owner->last_migrate_reason =\n\t\told_page_owner->last_migrate_reason;\n\tnew_page_owner->handle = old_page_owner->handle;\n\tnew_page_owner->pid = old_page_owner->pid;\n\tnew_page_owner->tgid = old_page_owner->tgid;\n\tnew_page_owner->ts_nsec = old_page_owner->ts_nsec;\n\tnew_page_owner->free_ts_nsec = old_page_owner->ts_nsec;\n\tstrcpy(new_page_owner->comm, old_page_owner->comm);\n\n\t \n\t__set_bit(PAGE_EXT_OWNER, &new_ext->flags);\n\t__set_bit(PAGE_EXT_OWNER_ALLOCATED, &new_ext->flags);\n\tpage_ext_put(new_ext);\n\tpage_ext_put(old_ext);\n}\n\nvoid pagetypeinfo_showmixedcount_print(struct seq_file *m,\n\t\t\t\t       pg_data_t *pgdat, struct zone *zone)\n{\n\tstruct page *page;\n\tstruct page_ext *page_ext;\n\tstruct page_owner *page_owner;\n\tunsigned long pfn, block_end_pfn;\n\tunsigned long end_pfn = zone_end_pfn(zone);\n\tunsigned long count[MIGRATE_TYPES] = { 0, };\n\tint pageblock_mt, page_mt;\n\tint i;\n\n\t \n\tpfn = zone->zone_start_pfn;\n\n\t \n\tfor (; pfn < end_pfn; ) {\n\t\tpage = pfn_to_online_page(pfn);\n\t\tif (!page) {\n\t\t\tpfn = ALIGN(pfn + 1, MAX_ORDER_NR_PAGES);\n\t\t\tcontinue;\n\t\t}\n\n\t\tblock_end_pfn = pageblock_end_pfn(pfn);\n\t\tblock_end_pfn = min(block_end_pfn, end_pfn);\n\n\t\tpageblock_mt = get_pageblock_migratetype(page);\n\n\t\tfor (; pfn < block_end_pfn; pfn++) {\n\t\t\t \n\t\t\tpage = pfn_to_page(pfn);\n\n\t\t\tif (page_zone(page) != zone)\n\t\t\t\tcontinue;\n\n\t\t\tif (PageBuddy(page)) {\n\t\t\t\tunsigned long freepage_order;\n\n\t\t\t\tfreepage_order = buddy_order_unsafe(page);\n\t\t\t\tif (freepage_order <= MAX_ORDER)\n\t\t\t\t\tpfn += (1UL << freepage_order) - 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (PageReserved(page))\n\t\t\t\tcontinue;\n\n\t\t\tpage_ext = page_ext_get(page);\n\t\t\tif (unlikely(!page_ext))\n\t\t\t\tcontinue;\n\n\t\t\tif (!test_bit(PAGE_EXT_OWNER_ALLOCATED, &page_ext->flags))\n\t\t\t\tgoto ext_put_continue;\n\n\t\t\tpage_owner = get_page_owner(page_ext);\n\t\t\tpage_mt = gfp_migratetype(page_owner->gfp_mask);\n\t\t\tif (pageblock_mt != page_mt) {\n\t\t\t\tif (is_migrate_cma(pageblock_mt))\n\t\t\t\t\tcount[MIGRATE_MOVABLE]++;\n\t\t\t\telse\n\t\t\t\t\tcount[pageblock_mt]++;\n\n\t\t\t\tpfn = block_end_pfn;\n\t\t\t\tpage_ext_put(page_ext);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tpfn += (1UL << page_owner->order) - 1;\next_put_continue:\n\t\t\tpage_ext_put(page_ext);\n\t\t}\n\t}\n\n\t \n\tseq_printf(m, \"Node %d, zone %8s \", pgdat->node_id, zone->name);\n\tfor (i = 0; i < MIGRATE_TYPES; i++)\n\t\tseq_printf(m, \"%12lu \", count[i]);\n\tseq_putc(m, '\\n');\n}\n\n \nstatic inline int print_page_owner_memcg(char *kbuf, size_t count, int ret,\n\t\t\t\t\t struct page *page)\n{\n#ifdef CONFIG_MEMCG\n\tunsigned long memcg_data;\n\tstruct mem_cgroup *memcg;\n\tbool online;\n\tchar name[80];\n\n\trcu_read_lock();\n\tmemcg_data = READ_ONCE(page->memcg_data);\n\tif (!memcg_data)\n\t\tgoto out_unlock;\n\n\tif (memcg_data & MEMCG_DATA_OBJCGS)\n\t\tret += scnprintf(kbuf + ret, count - ret,\n\t\t\t\t\"Slab cache page\\n\");\n\n\tmemcg = page_memcg_check(page);\n\tif (!memcg)\n\t\tgoto out_unlock;\n\n\tonline = (memcg->css.flags & CSS_ONLINE);\n\tcgroup_name(memcg->css.cgroup, name, sizeof(name));\n\tret += scnprintf(kbuf + ret, count - ret,\n\t\t\t\"Charged %sto %smemcg %s\\n\",\n\t\t\tPageMemcgKmem(page) ? \"(via objcg) \" : \"\",\n\t\t\tonline ? \"\" : \"offline \",\n\t\t\tname);\nout_unlock:\n\trcu_read_unlock();\n#endif  \n\n\treturn ret;\n}\n\nstatic ssize_t\nprint_page_owner(char __user *buf, size_t count, unsigned long pfn,\n\t\tstruct page *page, struct page_owner *page_owner,\n\t\tdepot_stack_handle_t handle)\n{\n\tint ret, pageblock_mt, page_mt;\n\tchar *kbuf;\n\n\tcount = min_t(size_t, count, PAGE_SIZE);\n\tkbuf = kmalloc(count, GFP_KERNEL);\n\tif (!kbuf)\n\t\treturn -ENOMEM;\n\n\tret = scnprintf(kbuf, count,\n\t\t\t\"Page allocated via order %u, mask %#x(%pGg), pid %d, tgid %d (%s), ts %llu ns, free_ts %llu ns\\n\",\n\t\t\tpage_owner->order, page_owner->gfp_mask,\n\t\t\t&page_owner->gfp_mask, page_owner->pid,\n\t\t\tpage_owner->tgid, page_owner->comm,\n\t\t\tpage_owner->ts_nsec, page_owner->free_ts_nsec);\n\n\t \n\tpageblock_mt = get_pageblock_migratetype(page);\n\tpage_mt  = gfp_migratetype(page_owner->gfp_mask);\n\tret += scnprintf(kbuf + ret, count - ret,\n\t\t\t\"PFN 0x%lx type %s Block %lu type %s Flags %pGp\\n\",\n\t\t\tpfn,\n\t\t\tmigratetype_names[page_mt],\n\t\t\tpfn >> pageblock_order,\n\t\t\tmigratetype_names[pageblock_mt],\n\t\t\t&page->flags);\n\n\tret += stack_depot_snprint(handle, kbuf + ret, count - ret, 0);\n\tif (ret >= count)\n\t\tgoto err;\n\n\tif (page_owner->last_migrate_reason != -1) {\n\t\tret += scnprintf(kbuf + ret, count - ret,\n\t\t\t\"Page has been migrated, last migrate reason: %s\\n\",\n\t\t\tmigrate_reason_names[page_owner->last_migrate_reason]);\n\t}\n\n\tret = print_page_owner_memcg(kbuf, count, ret, page);\n\n\tret += snprintf(kbuf + ret, count - ret, \"\\n\");\n\tif (ret >= count)\n\t\tgoto err;\n\n\tif (copy_to_user(buf, kbuf, ret))\n\t\tret = -EFAULT;\n\n\tkfree(kbuf);\n\treturn ret;\n\nerr:\n\tkfree(kbuf);\n\treturn -ENOMEM;\n}\n\nvoid __dump_page_owner(const struct page *page)\n{\n\tstruct page_ext *page_ext = page_ext_get((void *)page);\n\tstruct page_owner *page_owner;\n\tdepot_stack_handle_t handle;\n\tgfp_t gfp_mask;\n\tint mt;\n\n\tif (unlikely(!page_ext)) {\n\t\tpr_alert(\"There is not page extension available.\\n\");\n\t\treturn;\n\t}\n\n\tpage_owner = get_page_owner(page_ext);\n\tgfp_mask = page_owner->gfp_mask;\n\tmt = gfp_migratetype(gfp_mask);\n\n\tif (!test_bit(PAGE_EXT_OWNER, &page_ext->flags)) {\n\t\tpr_alert(\"page_owner info is not present (never set?)\\n\");\n\t\tpage_ext_put(page_ext);\n\t\treturn;\n\t}\n\n\tif (test_bit(PAGE_EXT_OWNER_ALLOCATED, &page_ext->flags))\n\t\tpr_alert(\"page_owner tracks the page as allocated\\n\");\n\telse\n\t\tpr_alert(\"page_owner tracks the page as freed\\n\");\n\n\tpr_alert(\"page last allocated via order %u, migratetype %s, gfp_mask %#x(%pGg), pid %d, tgid %d (%s), ts %llu, free_ts %llu\\n\",\n\t\t page_owner->order, migratetype_names[mt], gfp_mask, &gfp_mask,\n\t\t page_owner->pid, page_owner->tgid, page_owner->comm,\n\t\t page_owner->ts_nsec, page_owner->free_ts_nsec);\n\n\thandle = READ_ONCE(page_owner->handle);\n\tif (!handle)\n\t\tpr_alert(\"page_owner allocation stack trace missing\\n\");\n\telse\n\t\tstack_depot_print(handle);\n\n\thandle = READ_ONCE(page_owner->free_handle);\n\tif (!handle) {\n\t\tpr_alert(\"page_owner free stack trace missing\\n\");\n\t} else {\n\t\tpr_alert(\"page last free stack trace:\\n\");\n\t\tstack_depot_print(handle);\n\t}\n\n\tif (page_owner->last_migrate_reason != -1)\n\t\tpr_alert(\"page has been migrated, last migrate reason: %s\\n\",\n\t\t\tmigrate_reason_names[page_owner->last_migrate_reason]);\n\tpage_ext_put(page_ext);\n}\n\nstatic ssize_t\nread_page_owner(struct file *file, char __user *buf, size_t count, loff_t *ppos)\n{\n\tunsigned long pfn;\n\tstruct page *page;\n\tstruct page_ext *page_ext;\n\tstruct page_owner *page_owner;\n\tdepot_stack_handle_t handle;\n\n\tif (!static_branch_unlikely(&page_owner_inited))\n\t\treturn -EINVAL;\n\n\tpage = NULL;\n\tif (*ppos == 0)\n\t\tpfn = min_low_pfn;\n\telse\n\t\tpfn = *ppos;\n\t \n\twhile (!pfn_valid(pfn) && (pfn & (MAX_ORDER_NR_PAGES - 1)) != 0)\n\t\tpfn++;\n\n\t \n\tfor (; pfn < max_pfn; pfn++) {\n\t\t \n\t\tstruct page_owner page_owner_tmp;\n\n\t\t \n\t\tif ((pfn & (MAX_ORDER_NR_PAGES - 1)) == 0 && !pfn_valid(pfn)) {\n\t\t\tpfn += MAX_ORDER_NR_PAGES - 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tpage = pfn_to_page(pfn);\n\t\tif (PageBuddy(page)) {\n\t\t\tunsigned long freepage_order = buddy_order_unsafe(page);\n\n\t\t\tif (freepage_order <= MAX_ORDER)\n\t\t\t\tpfn += (1UL << freepage_order) - 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tpage_ext = page_ext_get(page);\n\t\tif (unlikely(!page_ext))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (!test_bit(PAGE_EXT_OWNER, &page_ext->flags))\n\t\t\tgoto ext_put_continue;\n\n\t\t \n\t\tif (!test_bit(PAGE_EXT_OWNER_ALLOCATED, &page_ext->flags))\n\t\t\tgoto ext_put_continue;\n\n\t\tpage_owner = get_page_owner(page_ext);\n\n\t\t \n\t\tif (!IS_ALIGNED(pfn, 1 << page_owner->order))\n\t\t\tgoto ext_put_continue;\n\n\t\t \n\t\thandle = READ_ONCE(page_owner->handle);\n\t\tif (!handle)\n\t\t\tgoto ext_put_continue;\n\n\t\t \n\t\t*ppos = pfn + 1;\n\n\t\tpage_owner_tmp = *page_owner;\n\t\tpage_ext_put(page_ext);\n\t\treturn print_page_owner(buf, count, pfn, page,\n\t\t\t\t&page_owner_tmp, handle);\next_put_continue:\n\t\tpage_ext_put(page_ext);\n\t}\n\n\treturn 0;\n}\n\nstatic loff_t lseek_page_owner(struct file *file, loff_t offset, int orig)\n{\n\tswitch (orig) {\n\tcase SEEK_SET:\n\t\tfile->f_pos = offset;\n\t\tbreak;\n\tcase SEEK_CUR:\n\t\tfile->f_pos += offset;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn file->f_pos;\n}\n\nstatic void init_pages_in_zone(pg_data_t *pgdat, struct zone *zone)\n{\n\tunsigned long pfn = zone->zone_start_pfn;\n\tunsigned long end_pfn = zone_end_pfn(zone);\n\tunsigned long count = 0;\n\n\t \n\tfor (; pfn < end_pfn; ) {\n\t\tunsigned long block_end_pfn;\n\n\t\tif (!pfn_valid(pfn)) {\n\t\t\tpfn = ALIGN(pfn + 1, MAX_ORDER_NR_PAGES);\n\t\t\tcontinue;\n\t\t}\n\n\t\tblock_end_pfn = pageblock_end_pfn(pfn);\n\t\tblock_end_pfn = min(block_end_pfn, end_pfn);\n\n\t\tfor (; pfn < block_end_pfn; pfn++) {\n\t\t\tstruct page *page = pfn_to_page(pfn);\n\t\t\tstruct page_ext *page_ext;\n\n\t\t\tif (page_zone(page) != zone)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (PageBuddy(page)) {\n\t\t\t\tunsigned long order = buddy_order_unsafe(page);\n\n\t\t\t\tif (order > 0 && order <= MAX_ORDER)\n\t\t\t\t\tpfn += (1UL << order) - 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (PageReserved(page))\n\t\t\t\tcontinue;\n\n\t\t\tpage_ext = page_ext_get(page);\n\t\t\tif (unlikely(!page_ext))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (test_bit(PAGE_EXT_OWNER, &page_ext->flags))\n\t\t\t\tgoto ext_put_continue;\n\n\t\t\t \n\t\t\t__set_page_owner_handle(page_ext, early_handle,\n\t\t\t\t\t\t0, 0);\n\t\t\tcount++;\next_put_continue:\n\t\t\tpage_ext_put(page_ext);\n\t\t}\n\t\tcond_resched();\n\t}\n\n\tpr_info(\"Node %d, zone %8s: page owner found early allocated %lu pages\\n\",\n\t\tpgdat->node_id, zone->name, count);\n}\n\nstatic void init_zones_in_node(pg_data_t *pgdat)\n{\n\tstruct zone *zone;\n\tstruct zone *node_zones = pgdat->node_zones;\n\n\tfor (zone = node_zones; zone - node_zones < MAX_NR_ZONES; ++zone) {\n\t\tif (!populated_zone(zone))\n\t\t\tcontinue;\n\n\t\tinit_pages_in_zone(pgdat, zone);\n\t}\n}\n\nstatic void init_early_allocated_pages(void)\n{\n\tpg_data_t *pgdat;\n\n\tfor_each_online_pgdat(pgdat)\n\t\tinit_zones_in_node(pgdat);\n}\n\nstatic const struct file_operations proc_page_owner_operations = {\n\t.read\t\t= read_page_owner,\n\t.llseek\t\t= lseek_page_owner,\n};\n\nstatic int __init pageowner_init(void)\n{\n\tif (!static_branch_unlikely(&page_owner_inited)) {\n\t\tpr_info(\"page_owner is disabled\\n\");\n\t\treturn 0;\n\t}\n\n\tdebugfs_create_file(\"page_owner\", 0400, NULL, NULL,\n\t\t\t    &proc_page_owner_operations);\n\n\treturn 0;\n}\nlate_initcall(pageowner_init)\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}