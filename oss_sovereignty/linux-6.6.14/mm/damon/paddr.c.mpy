{
  "module_name": "paddr.c",
  "hash_id": "7d3f1d2665ca0ba460222d48f0d5ed8b4b2e7c553231919da3927d9750da52e0",
  "original_prompt": "Ingested from linux-6.6.14/mm/damon/paddr.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"damon-pa: \" fmt\n\n#include <linux/mmu_notifier.h>\n#include <linux/page_idle.h>\n#include <linux/pagemap.h>\n#include <linux/rmap.h>\n#include <linux/swap.h>\n\n#include \"../internal.h\"\n#include \"ops-common.h\"\n\nstatic bool __damon_pa_mkold(struct folio *folio, struct vm_area_struct *vma,\n\t\tunsigned long addr, void *arg)\n{\n\tDEFINE_FOLIO_VMA_WALK(pvmw, folio, vma, addr, 0);\n\n\twhile (page_vma_mapped_walk(&pvmw)) {\n\t\taddr = pvmw.address;\n\t\tif (pvmw.pte)\n\t\t\tdamon_ptep_mkold(pvmw.pte, vma, addr);\n\t\telse\n\t\t\tdamon_pmdp_mkold(pvmw.pmd, vma, addr);\n\t}\n\treturn true;\n}\n\nstatic void damon_pa_mkold(unsigned long paddr)\n{\n\tstruct folio *folio = damon_get_folio(PHYS_PFN(paddr));\n\tstruct rmap_walk_control rwc = {\n\t\t.rmap_one = __damon_pa_mkold,\n\t\t.anon_lock = folio_lock_anon_vma_read,\n\t};\n\tbool need_lock;\n\n\tif (!folio)\n\t\treturn;\n\n\tif (!folio_mapped(folio) || !folio_raw_mapping(folio)) {\n\t\tfolio_set_idle(folio);\n\t\tgoto out;\n\t}\n\n\tneed_lock = !folio_test_anon(folio) || folio_test_ksm(folio);\n\tif (need_lock && !folio_trylock(folio))\n\t\tgoto out;\n\n\trmap_walk(folio, &rwc);\n\n\tif (need_lock)\n\t\tfolio_unlock(folio);\n\nout:\n\tfolio_put(folio);\n}\n\nstatic void __damon_pa_prepare_access_check(struct damon_region *r)\n{\n\tr->sampling_addr = damon_rand(r->ar.start, r->ar.end);\n\n\tdamon_pa_mkold(r->sampling_addr);\n}\n\nstatic void damon_pa_prepare_access_checks(struct damon_ctx *ctx)\n{\n\tstruct damon_target *t;\n\tstruct damon_region *r;\n\n\tdamon_for_each_target(t, ctx) {\n\t\tdamon_for_each_region(r, t)\n\t\t\t__damon_pa_prepare_access_check(r);\n\t}\n}\n\nstatic bool __damon_pa_young(struct folio *folio, struct vm_area_struct *vma,\n\t\tunsigned long addr, void *arg)\n{\n\tbool *accessed = arg;\n\tDEFINE_FOLIO_VMA_WALK(pvmw, folio, vma, addr, 0);\n\n\t*accessed = false;\n\twhile (page_vma_mapped_walk(&pvmw)) {\n\t\taddr = pvmw.address;\n\t\tif (pvmw.pte) {\n\t\t\t*accessed = pte_young(ptep_get(pvmw.pte)) ||\n\t\t\t\t!folio_test_idle(folio) ||\n\t\t\t\tmmu_notifier_test_young(vma->vm_mm, addr);\n\t\t} else {\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t\t\t*accessed = pmd_young(pmdp_get(pvmw.pmd)) ||\n\t\t\t\t!folio_test_idle(folio) ||\n\t\t\t\tmmu_notifier_test_young(vma->vm_mm, addr);\n#else\n\t\t\tWARN_ON_ONCE(1);\n#endif\t \n\t\t}\n\t\tif (*accessed) {\n\t\t\tpage_vma_mapped_walk_done(&pvmw);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\treturn *accessed == false;\n}\n\nstatic bool damon_pa_young(unsigned long paddr, unsigned long *folio_sz)\n{\n\tstruct folio *folio = damon_get_folio(PHYS_PFN(paddr));\n\tbool accessed = false;\n\tstruct rmap_walk_control rwc = {\n\t\t.arg = &accessed,\n\t\t.rmap_one = __damon_pa_young,\n\t\t.anon_lock = folio_lock_anon_vma_read,\n\t};\n\tbool need_lock;\n\n\tif (!folio)\n\t\treturn false;\n\n\tif (!folio_mapped(folio) || !folio_raw_mapping(folio)) {\n\t\tif (folio_test_idle(folio))\n\t\t\taccessed = false;\n\t\telse\n\t\t\taccessed = true;\n\t\tgoto out;\n\t}\n\n\tneed_lock = !folio_test_anon(folio) || folio_test_ksm(folio);\n\tif (need_lock && !folio_trylock(folio))\n\t\tgoto out;\n\n\trmap_walk(folio, &rwc);\n\n\tif (need_lock)\n\t\tfolio_unlock(folio);\n\nout:\n\t*folio_sz = folio_size(folio);\n\tfolio_put(folio);\n\treturn accessed;\n}\n\nstatic void __damon_pa_check_access(struct damon_region *r)\n{\n\tstatic unsigned long last_addr;\n\tstatic unsigned long last_folio_sz = PAGE_SIZE;\n\tstatic bool last_accessed;\n\n\t \n\tif (ALIGN_DOWN(last_addr, last_folio_sz) ==\n\t\t\t\tALIGN_DOWN(r->sampling_addr, last_folio_sz)) {\n\t\tif (last_accessed)\n\t\t\tr->nr_accesses++;\n\t\treturn;\n\t}\n\n\tlast_accessed = damon_pa_young(r->sampling_addr, &last_folio_sz);\n\tif (last_accessed)\n\t\tr->nr_accesses++;\n\n\tlast_addr = r->sampling_addr;\n}\n\nstatic unsigned int damon_pa_check_accesses(struct damon_ctx *ctx)\n{\n\tstruct damon_target *t;\n\tstruct damon_region *r;\n\tunsigned int max_nr_accesses = 0;\n\n\tdamon_for_each_target(t, ctx) {\n\t\tdamon_for_each_region(r, t) {\n\t\t\t__damon_pa_check_access(r);\n\t\t\tmax_nr_accesses = max(r->nr_accesses, max_nr_accesses);\n\t\t}\n\t}\n\n\treturn max_nr_accesses;\n}\n\nstatic bool __damos_pa_filter_out(struct damos_filter *filter,\n\t\tstruct folio *folio)\n{\n\tbool matched = false;\n\tstruct mem_cgroup *memcg;\n\n\tswitch (filter->type) {\n\tcase DAMOS_FILTER_TYPE_ANON:\n\t\tmatched = folio_test_anon(folio);\n\t\tbreak;\n\tcase DAMOS_FILTER_TYPE_MEMCG:\n\t\trcu_read_lock();\n\t\tmemcg = folio_memcg_check(folio);\n\t\tif (!memcg)\n\t\t\tmatched = false;\n\t\telse\n\t\t\tmatched = filter->memcg_id == mem_cgroup_id(memcg);\n\t\trcu_read_unlock();\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn matched == filter->matching;\n}\n\n \nstatic bool damos_pa_filter_out(struct damos *scheme, struct folio *folio)\n{\n\tstruct damos_filter *filter;\n\n\tdamos_for_each_filter(filter, scheme) {\n\t\tif (__damos_pa_filter_out(filter, folio))\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic unsigned long damon_pa_pageout(struct damon_region *r, struct damos *s)\n{\n\tunsigned long addr, applied;\n\tLIST_HEAD(folio_list);\n\n\tfor (addr = r->ar.start; addr < r->ar.end; addr += PAGE_SIZE) {\n\t\tstruct folio *folio = damon_get_folio(PHYS_PFN(addr));\n\n\t\tif (!folio)\n\t\t\tcontinue;\n\n\t\tif (damos_pa_filter_out(s, folio))\n\t\t\tgoto put_folio;\n\n\t\tfolio_clear_referenced(folio);\n\t\tfolio_test_clear_young(folio);\n\t\tif (!folio_isolate_lru(folio))\n\t\t\tgoto put_folio;\n\t\tif (folio_test_unevictable(folio))\n\t\t\tfolio_putback_lru(folio);\n\t\telse\n\t\t\tlist_add(&folio->lru, &folio_list);\nput_folio:\n\t\tfolio_put(folio);\n\t}\n\tapplied = reclaim_pages(&folio_list);\n\tcond_resched();\n\treturn applied * PAGE_SIZE;\n}\n\nstatic inline unsigned long damon_pa_mark_accessed_or_deactivate(\n\t\tstruct damon_region *r, struct damos *s, bool mark_accessed)\n{\n\tunsigned long addr, applied = 0;\n\n\tfor (addr = r->ar.start; addr < r->ar.end; addr += PAGE_SIZE) {\n\t\tstruct folio *folio = damon_get_folio(PHYS_PFN(addr));\n\n\t\tif (!folio)\n\t\t\tcontinue;\n\n\t\tif (damos_pa_filter_out(s, folio))\n\t\t\tgoto put_folio;\n\n\t\tif (mark_accessed)\n\t\t\tfolio_mark_accessed(folio);\n\t\telse\n\t\t\tfolio_deactivate(folio);\n\t\tapplied += folio_nr_pages(folio);\nput_folio:\n\t\tfolio_put(folio);\n\t}\n\treturn applied * PAGE_SIZE;\n}\n\nstatic unsigned long damon_pa_mark_accessed(struct damon_region *r,\n\tstruct damos *s)\n{\n\treturn damon_pa_mark_accessed_or_deactivate(r, s, true);\n}\n\nstatic unsigned long damon_pa_deactivate_pages(struct damon_region *r,\n\tstruct damos *s)\n{\n\treturn damon_pa_mark_accessed_or_deactivate(r, s, false);\n}\n\nstatic unsigned long damon_pa_apply_scheme(struct damon_ctx *ctx,\n\t\tstruct damon_target *t, struct damon_region *r,\n\t\tstruct damos *scheme)\n{\n\tswitch (scheme->action) {\n\tcase DAMOS_PAGEOUT:\n\t\treturn damon_pa_pageout(r, scheme);\n\tcase DAMOS_LRU_PRIO:\n\t\treturn damon_pa_mark_accessed(r, scheme);\n\tcase DAMOS_LRU_DEPRIO:\n\t\treturn damon_pa_deactivate_pages(r, scheme);\n\tcase DAMOS_STAT:\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int damon_pa_scheme_score(struct damon_ctx *context,\n\t\tstruct damon_target *t, struct damon_region *r,\n\t\tstruct damos *scheme)\n{\n\tswitch (scheme->action) {\n\tcase DAMOS_PAGEOUT:\n\t\treturn damon_cold_score(context, r, scheme);\n\tcase DAMOS_LRU_PRIO:\n\t\treturn damon_hot_score(context, r, scheme);\n\tcase DAMOS_LRU_DEPRIO:\n\t\treturn damon_cold_score(context, r, scheme);\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn DAMOS_MAX_SCORE;\n}\n\nstatic int __init damon_pa_initcall(void)\n{\n\tstruct damon_operations ops = {\n\t\t.id = DAMON_OPS_PADDR,\n\t\t.init = NULL,\n\t\t.update = NULL,\n\t\t.prepare_access_checks = damon_pa_prepare_access_checks,\n\t\t.check_accesses = damon_pa_check_accesses,\n\t\t.reset_aggregated = NULL,\n\t\t.target_valid = NULL,\n\t\t.cleanup = NULL,\n\t\t.apply_scheme = damon_pa_apply_scheme,\n\t\t.get_scheme_score = damon_pa_scheme_score,\n\t};\n\n\treturn damon_register_ops(&ops);\n};\n\nsubsys_initcall(damon_pa_initcall);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}