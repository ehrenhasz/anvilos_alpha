{
  "module_name": "backing-dev.c",
  "hash_id": "8d0cd8264b550284a80036c6add6eb0e9efd42799377f9d5777022b86ba245a2",
  "original_prompt": "Ingested from linux-6.6.14/mm/backing-dev.c",
  "human_readable_source": "\n\n#include <linux/blkdev.h>\n#include <linux/wait.h>\n#include <linux/rbtree.h>\n#include <linux/kthread.h>\n#include <linux/backing-dev.h>\n#include <linux/blk-cgroup.h>\n#include <linux/freezer.h>\n#include <linux/fs.h>\n#include <linux/pagemap.h>\n#include <linux/mm.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/module.h>\n#include <linux/writeback.h>\n#include <linux/device.h>\n#include <trace/events/writeback.h>\n#include \"internal.h\"\n\nstruct backing_dev_info noop_backing_dev_info;\nEXPORT_SYMBOL_GPL(noop_backing_dev_info);\n\nstatic const char *bdi_unknown_name = \"(unknown)\";\n\n \nDEFINE_SPINLOCK(bdi_lock);\nstatic u64 bdi_id_cursor;\nstatic struct rb_root bdi_tree = RB_ROOT;\nLIST_HEAD(bdi_list);\n\n \nstruct workqueue_struct *bdi_wq;\n\n#ifdef CONFIG_DEBUG_FS\n#include <linux/debugfs.h>\n#include <linux/seq_file.h>\n\nstatic struct dentry *bdi_debug_root;\n\nstatic void bdi_debug_init(void)\n{\n\tbdi_debug_root = debugfs_create_dir(\"bdi\", NULL);\n}\n\nstatic int bdi_debug_stats_show(struct seq_file *m, void *v)\n{\n\tstruct backing_dev_info *bdi = m->private;\n\tstruct bdi_writeback *wb = &bdi->wb;\n\tunsigned long background_thresh;\n\tunsigned long dirty_thresh;\n\tunsigned long wb_thresh;\n\tunsigned long nr_dirty, nr_io, nr_more_io, nr_dirty_time;\n\tstruct inode *inode;\n\n\tnr_dirty = nr_io = nr_more_io = nr_dirty_time = 0;\n\tspin_lock(&wb->list_lock);\n\tlist_for_each_entry(inode, &wb->b_dirty, i_io_list)\n\t\tnr_dirty++;\n\tlist_for_each_entry(inode, &wb->b_io, i_io_list)\n\t\tnr_io++;\n\tlist_for_each_entry(inode, &wb->b_more_io, i_io_list)\n\t\tnr_more_io++;\n\tlist_for_each_entry(inode, &wb->b_dirty_time, i_io_list)\n\t\tif (inode->i_state & I_DIRTY_TIME)\n\t\t\tnr_dirty_time++;\n\tspin_unlock(&wb->list_lock);\n\n\tglobal_dirty_limits(&background_thresh, &dirty_thresh);\n\twb_thresh = wb_calc_thresh(wb, dirty_thresh);\n\n\tseq_printf(m,\n\t\t   \"BdiWriteback:       %10lu kB\\n\"\n\t\t   \"BdiReclaimable:     %10lu kB\\n\"\n\t\t   \"BdiDirtyThresh:     %10lu kB\\n\"\n\t\t   \"DirtyThresh:        %10lu kB\\n\"\n\t\t   \"BackgroundThresh:   %10lu kB\\n\"\n\t\t   \"BdiDirtied:         %10lu kB\\n\"\n\t\t   \"BdiWritten:         %10lu kB\\n\"\n\t\t   \"BdiWriteBandwidth:  %10lu kBps\\n\"\n\t\t   \"b_dirty:            %10lu\\n\"\n\t\t   \"b_io:               %10lu\\n\"\n\t\t   \"b_more_io:          %10lu\\n\"\n\t\t   \"b_dirty_time:       %10lu\\n\"\n\t\t   \"bdi_list:           %10u\\n\"\n\t\t   \"state:              %10lx\\n\",\n\t\t   (unsigned long) K(wb_stat(wb, WB_WRITEBACK)),\n\t\t   (unsigned long) K(wb_stat(wb, WB_RECLAIMABLE)),\n\t\t   K(wb_thresh),\n\t\t   K(dirty_thresh),\n\t\t   K(background_thresh),\n\t\t   (unsigned long) K(wb_stat(wb, WB_DIRTIED)),\n\t\t   (unsigned long) K(wb_stat(wb, WB_WRITTEN)),\n\t\t   (unsigned long) K(wb->write_bandwidth),\n\t\t   nr_dirty,\n\t\t   nr_io,\n\t\t   nr_more_io,\n\t\t   nr_dirty_time,\n\t\t   !list_empty(&bdi->bdi_list), bdi->wb.state);\n\n\treturn 0;\n}\nDEFINE_SHOW_ATTRIBUTE(bdi_debug_stats);\n\nstatic void bdi_debug_register(struct backing_dev_info *bdi, const char *name)\n{\n\tbdi->debug_dir = debugfs_create_dir(name, bdi_debug_root);\n\n\tdebugfs_create_file(\"stats\", 0444, bdi->debug_dir, bdi,\n\t\t\t    &bdi_debug_stats_fops);\n}\n\nstatic void bdi_debug_unregister(struct backing_dev_info *bdi)\n{\n\tdebugfs_remove_recursive(bdi->debug_dir);\n}\n#else\nstatic inline void bdi_debug_init(void)\n{\n}\nstatic inline void bdi_debug_register(struct backing_dev_info *bdi,\n\t\t\t\t      const char *name)\n{\n}\nstatic inline void bdi_debug_unregister(struct backing_dev_info *bdi)\n{\n}\n#endif\n\nstatic ssize_t read_ahead_kb_store(struct device *dev,\n\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t  const char *buf, size_t count)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\tunsigned long read_ahead_kb;\n\tssize_t ret;\n\n\tret = kstrtoul(buf, 10, &read_ahead_kb);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbdi->ra_pages = read_ahead_kb >> (PAGE_SHIFT - 10);\n\n\treturn count;\n}\n\n#define BDI_SHOW(name, expr)\t\t\t\t\t\t\\\nstatic ssize_t name##_show(struct device *dev,\t\t\t\t\\\n\t\t\t   struct device_attribute *attr, char *buf)\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\treturn sysfs_emit(buf, \"%lld\\n\", (long long)expr);\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\nstatic DEVICE_ATTR_RW(name);\n\nBDI_SHOW(read_ahead_kb, K(bdi->ra_pages))\n\nstatic ssize_t min_ratio_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\tunsigned int ratio;\n\tssize_t ret;\n\n\tret = kstrtouint(buf, 10, &ratio);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = bdi_set_min_ratio(bdi, ratio);\n\tif (!ret)\n\t\tret = count;\n\n\treturn ret;\n}\nBDI_SHOW(min_ratio, bdi->min_ratio / BDI_RATIO_SCALE)\n\nstatic ssize_t min_ratio_fine_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\tunsigned int ratio;\n\tssize_t ret;\n\n\tret = kstrtouint(buf, 10, &ratio);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = bdi_set_min_ratio_no_scale(bdi, ratio);\n\tif (!ret)\n\t\tret = count;\n\n\treturn ret;\n}\nBDI_SHOW(min_ratio_fine, bdi->min_ratio)\n\nstatic ssize_t max_ratio_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\tunsigned int ratio;\n\tssize_t ret;\n\n\tret = kstrtouint(buf, 10, &ratio);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = bdi_set_max_ratio(bdi, ratio);\n\tif (!ret)\n\t\tret = count;\n\n\treturn ret;\n}\nBDI_SHOW(max_ratio, bdi->max_ratio / BDI_RATIO_SCALE)\n\nstatic ssize_t max_ratio_fine_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\tunsigned int ratio;\n\tssize_t ret;\n\n\tret = kstrtouint(buf, 10, &ratio);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = bdi_set_max_ratio_no_scale(bdi, ratio);\n\tif (!ret)\n\t\tret = count;\n\n\treturn ret;\n}\nBDI_SHOW(max_ratio_fine, bdi->max_ratio)\n\nstatic ssize_t min_bytes_show(struct device *dev,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%llu\\n\", bdi_get_min_bytes(bdi));\n}\n\nstatic ssize_t min_bytes_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\tu64 bytes;\n\tssize_t ret;\n\n\tret = kstrtoull(buf, 10, &bytes);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = bdi_set_min_bytes(bdi, bytes);\n\tif (!ret)\n\t\tret = count;\n\n\treturn ret;\n}\nstatic DEVICE_ATTR_RW(min_bytes);\n\nstatic ssize_t max_bytes_show(struct device *dev,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%llu\\n\", bdi_get_max_bytes(bdi));\n}\n\nstatic ssize_t max_bytes_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\tu64 bytes;\n\tssize_t ret;\n\n\tret = kstrtoull(buf, 10, &bytes);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = bdi_set_max_bytes(bdi, bytes);\n\tif (!ret)\n\t\tret = count;\n\n\treturn ret;\n}\nstatic DEVICE_ATTR_RW(max_bytes);\n\nstatic ssize_t stable_pages_required_show(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  char *buf)\n{\n\tdev_warn_once(dev,\n\t\t\"the stable_pages_required attribute has been removed. Use the stable_writes queue attribute instead.\\n\");\n\treturn sysfs_emit(buf, \"%d\\n\", 0);\n}\nstatic DEVICE_ATTR_RO(stable_pages_required);\n\nstatic ssize_t strict_limit_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\tunsigned int strict_limit;\n\tssize_t ret;\n\n\tret = kstrtouint(buf, 10, &strict_limit);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = bdi_set_strict_limit(bdi, strict_limit);\n\tif (!ret)\n\t\tret = count;\n\n\treturn ret;\n}\n\nstatic ssize_t strict_limit_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct backing_dev_info *bdi = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\",\n\t\t\t!!(bdi->capabilities & BDI_CAP_STRICTLIMIT));\n}\nstatic DEVICE_ATTR_RW(strict_limit);\n\nstatic struct attribute *bdi_dev_attrs[] = {\n\t&dev_attr_read_ahead_kb.attr,\n\t&dev_attr_min_ratio.attr,\n\t&dev_attr_min_ratio_fine.attr,\n\t&dev_attr_max_ratio.attr,\n\t&dev_attr_max_ratio_fine.attr,\n\t&dev_attr_min_bytes.attr,\n\t&dev_attr_max_bytes.attr,\n\t&dev_attr_stable_pages_required.attr,\n\t&dev_attr_strict_limit.attr,\n\tNULL,\n};\nATTRIBUTE_GROUPS(bdi_dev);\n\nstatic const struct class bdi_class = {\n\t.name\t\t= \"bdi\",\n\t.dev_groups\t= bdi_dev_groups,\n};\n\nstatic __init int bdi_class_init(void)\n{\n\tint ret;\n\n\tret = class_register(&bdi_class);\n\tif (ret)\n\t\treturn ret;\n\n\tbdi_debug_init();\n\n\treturn 0;\n}\npostcore_initcall(bdi_class_init);\n\nstatic int __init default_bdi_init(void)\n{\n\tbdi_wq = alloc_workqueue(\"writeback\", WQ_MEM_RECLAIM | WQ_UNBOUND |\n\t\t\t\t WQ_SYSFS, 0);\n\tif (!bdi_wq)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\nsubsys_initcall(default_bdi_init);\n\n \nvoid wb_wakeup_delayed(struct bdi_writeback *wb)\n{\n\tunsigned long timeout;\n\n\ttimeout = msecs_to_jiffies(dirty_writeback_interval * 10);\n\tspin_lock_irq(&wb->work_lock);\n\tif (test_bit(WB_registered, &wb->state))\n\t\tqueue_delayed_work(bdi_wq, &wb->dwork, timeout);\n\tspin_unlock_irq(&wb->work_lock);\n}\n\nstatic void wb_update_bandwidth_workfn(struct work_struct *work)\n{\n\tstruct bdi_writeback *wb = container_of(to_delayed_work(work),\n\t\t\t\t\t\tstruct bdi_writeback, bw_dwork);\n\n\twb_update_bandwidth(wb);\n}\n\n \n#define INIT_BW\t\t(100 << (20 - PAGE_SHIFT))\n\nstatic int wb_init(struct bdi_writeback *wb, struct backing_dev_info *bdi,\n\t\t   gfp_t gfp)\n{\n\tint i, err;\n\n\tmemset(wb, 0, sizeof(*wb));\n\n\twb->bdi = bdi;\n\twb->last_old_flush = jiffies;\n\tINIT_LIST_HEAD(&wb->b_dirty);\n\tINIT_LIST_HEAD(&wb->b_io);\n\tINIT_LIST_HEAD(&wb->b_more_io);\n\tINIT_LIST_HEAD(&wb->b_dirty_time);\n\tspin_lock_init(&wb->list_lock);\n\n\tatomic_set(&wb->writeback_inodes, 0);\n\twb->bw_time_stamp = jiffies;\n\twb->balanced_dirty_ratelimit = INIT_BW;\n\twb->dirty_ratelimit = INIT_BW;\n\twb->write_bandwidth = INIT_BW;\n\twb->avg_write_bandwidth = INIT_BW;\n\n\tspin_lock_init(&wb->work_lock);\n\tINIT_LIST_HEAD(&wb->work_list);\n\tINIT_DELAYED_WORK(&wb->dwork, wb_workfn);\n\tINIT_DELAYED_WORK(&wb->bw_dwork, wb_update_bandwidth_workfn);\n\twb->dirty_sleep = jiffies;\n\n\terr = fprop_local_init_percpu(&wb->completions, gfp);\n\tif (err)\n\t\treturn err;\n\n\tfor (i = 0; i < NR_WB_STAT_ITEMS; i++) {\n\t\terr = percpu_counter_init(&wb->stat[i], 0, gfp);\n\t\tif (err)\n\t\t\tgoto out_destroy_stat;\n\t}\n\n\treturn 0;\n\nout_destroy_stat:\n\twhile (i--)\n\t\tpercpu_counter_destroy(&wb->stat[i]);\n\tfprop_local_destroy_percpu(&wb->completions);\n\treturn err;\n}\n\nstatic void cgwb_remove_from_bdi_list(struct bdi_writeback *wb);\n\n \nstatic void wb_shutdown(struct bdi_writeback *wb)\n{\n\t \n\tspin_lock_irq(&wb->work_lock);\n\tif (!test_and_clear_bit(WB_registered, &wb->state)) {\n\t\tspin_unlock_irq(&wb->work_lock);\n\t\treturn;\n\t}\n\tspin_unlock_irq(&wb->work_lock);\n\n\tcgwb_remove_from_bdi_list(wb);\n\t \n\tmod_delayed_work(bdi_wq, &wb->dwork, 0);\n\tflush_delayed_work(&wb->dwork);\n\tWARN_ON(!list_empty(&wb->work_list));\n\tflush_delayed_work(&wb->bw_dwork);\n}\n\nstatic void wb_exit(struct bdi_writeback *wb)\n{\n\tint i;\n\n\tWARN_ON(delayed_work_pending(&wb->dwork));\n\n\tfor (i = 0; i < NR_WB_STAT_ITEMS; i++)\n\t\tpercpu_counter_destroy(&wb->stat[i]);\n\n\tfprop_local_destroy_percpu(&wb->completions);\n}\n\n#ifdef CONFIG_CGROUP_WRITEBACK\n\n#include <linux/memcontrol.h>\n\n \nstatic DEFINE_SPINLOCK(cgwb_lock);\nstatic struct workqueue_struct *cgwb_release_wq;\n\nstatic LIST_HEAD(offline_cgwbs);\nstatic void cleanup_offline_cgwbs_workfn(struct work_struct *work);\nstatic DECLARE_WORK(cleanup_offline_cgwbs_work, cleanup_offline_cgwbs_workfn);\n\nstatic void cgwb_free_rcu(struct rcu_head *rcu_head)\n{\n\tstruct bdi_writeback *wb = container_of(rcu_head,\n\t\t\tstruct bdi_writeback, rcu);\n\n\tpercpu_ref_exit(&wb->refcnt);\n\tkfree(wb);\n}\n\nstatic void cgwb_release_workfn(struct work_struct *work)\n{\n\tstruct bdi_writeback *wb = container_of(work, struct bdi_writeback,\n\t\t\t\t\t\trelease_work);\n\tstruct backing_dev_info *bdi = wb->bdi;\n\n\tmutex_lock(&wb->bdi->cgwb_release_mutex);\n\twb_shutdown(wb);\n\n\tcss_put(wb->memcg_css);\n\tcss_put(wb->blkcg_css);\n\tmutex_unlock(&wb->bdi->cgwb_release_mutex);\n\n\t \n\tblkcg_unpin_online(wb->blkcg_css);\n\n\tfprop_local_destroy_percpu(&wb->memcg_completions);\n\n\tspin_lock_irq(&cgwb_lock);\n\tlist_del(&wb->offline_node);\n\tspin_unlock_irq(&cgwb_lock);\n\n\twb_exit(wb);\n\tbdi_put(bdi);\n\tWARN_ON_ONCE(!list_empty(&wb->b_attached));\n\tcall_rcu(&wb->rcu, cgwb_free_rcu);\n}\n\nstatic void cgwb_release(struct percpu_ref *refcnt)\n{\n\tstruct bdi_writeback *wb = container_of(refcnt, struct bdi_writeback,\n\t\t\t\t\t\trefcnt);\n\tqueue_work(cgwb_release_wq, &wb->release_work);\n}\n\nstatic void cgwb_kill(struct bdi_writeback *wb)\n{\n\tlockdep_assert_held(&cgwb_lock);\n\n\tWARN_ON(!radix_tree_delete(&wb->bdi->cgwb_tree, wb->memcg_css->id));\n\tlist_del(&wb->memcg_node);\n\tlist_del(&wb->blkcg_node);\n\tlist_add(&wb->offline_node, &offline_cgwbs);\n\tpercpu_ref_kill(&wb->refcnt);\n}\n\nstatic void cgwb_remove_from_bdi_list(struct bdi_writeback *wb)\n{\n\tspin_lock_irq(&cgwb_lock);\n\tlist_del_rcu(&wb->bdi_node);\n\tspin_unlock_irq(&cgwb_lock);\n}\n\nstatic int cgwb_create(struct backing_dev_info *bdi,\n\t\t       struct cgroup_subsys_state *memcg_css, gfp_t gfp)\n{\n\tstruct mem_cgroup *memcg;\n\tstruct cgroup_subsys_state *blkcg_css;\n\tstruct list_head *memcg_cgwb_list, *blkcg_cgwb_list;\n\tstruct bdi_writeback *wb;\n\tunsigned long flags;\n\tint ret = 0;\n\n\tmemcg = mem_cgroup_from_css(memcg_css);\n\tblkcg_css = cgroup_get_e_css(memcg_css->cgroup, &io_cgrp_subsys);\n\tmemcg_cgwb_list = &memcg->cgwb_list;\n\tblkcg_cgwb_list = blkcg_get_cgwb_list(blkcg_css);\n\n\t \n\tspin_lock_irqsave(&cgwb_lock, flags);\n\twb = radix_tree_lookup(&bdi->cgwb_tree, memcg_css->id);\n\tif (wb && wb->blkcg_css != blkcg_css) {\n\t\tcgwb_kill(wb);\n\t\twb = NULL;\n\t}\n\tspin_unlock_irqrestore(&cgwb_lock, flags);\n\tif (wb)\n\t\tgoto out_put;\n\n\t \n\twb = kmalloc(sizeof(*wb), gfp);\n\tif (!wb) {\n\t\tret = -ENOMEM;\n\t\tgoto out_put;\n\t}\n\n\tret = wb_init(wb, bdi, gfp);\n\tif (ret)\n\t\tgoto err_free;\n\n\tret = percpu_ref_init(&wb->refcnt, cgwb_release, 0, gfp);\n\tif (ret)\n\t\tgoto err_wb_exit;\n\n\tret = fprop_local_init_percpu(&wb->memcg_completions, gfp);\n\tif (ret)\n\t\tgoto err_ref_exit;\n\n\twb->memcg_css = memcg_css;\n\twb->blkcg_css = blkcg_css;\n\tINIT_LIST_HEAD(&wb->b_attached);\n\tINIT_WORK(&wb->release_work, cgwb_release_workfn);\n\tset_bit(WB_registered, &wb->state);\n\tbdi_get(bdi);\n\n\t \n\tret = -ENODEV;\n\tspin_lock_irqsave(&cgwb_lock, flags);\n\tif (test_bit(WB_registered, &bdi->wb.state) &&\n\t    blkcg_cgwb_list->next && memcg_cgwb_list->next) {\n\t\t \n\t\tret = radix_tree_insert(&bdi->cgwb_tree, memcg_css->id, wb);\n\t\tif (!ret) {\n\t\t\tlist_add_tail_rcu(&wb->bdi_node, &bdi->wb_list);\n\t\t\tlist_add(&wb->memcg_node, memcg_cgwb_list);\n\t\t\tlist_add(&wb->blkcg_node, blkcg_cgwb_list);\n\t\t\tblkcg_pin_online(blkcg_css);\n\t\t\tcss_get(memcg_css);\n\t\t\tcss_get(blkcg_css);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cgwb_lock, flags);\n\tif (ret) {\n\t\tif (ret == -EEXIST)\n\t\t\tret = 0;\n\t\tgoto err_fprop_exit;\n\t}\n\tgoto out_put;\n\nerr_fprop_exit:\n\tbdi_put(bdi);\n\tfprop_local_destroy_percpu(&wb->memcg_completions);\nerr_ref_exit:\n\tpercpu_ref_exit(&wb->refcnt);\nerr_wb_exit:\n\twb_exit(wb);\nerr_free:\n\tkfree(wb);\nout_put:\n\tcss_put(blkcg_css);\n\treturn ret;\n}\n\n \nstruct bdi_writeback *wb_get_lookup(struct backing_dev_info *bdi,\n\t\t\t\t    struct cgroup_subsys_state *memcg_css)\n{\n\tstruct bdi_writeback *wb;\n\n\tif (!memcg_css->parent)\n\t\treturn &bdi->wb;\n\n\trcu_read_lock();\n\twb = radix_tree_lookup(&bdi->cgwb_tree, memcg_css->id);\n\tif (wb) {\n\t\tstruct cgroup_subsys_state *blkcg_css;\n\n\t\t \n\t\tblkcg_css = cgroup_get_e_css(memcg_css->cgroup, &io_cgrp_subsys);\n\t\tif (unlikely(wb->blkcg_css != blkcg_css || !wb_tryget(wb)))\n\t\t\twb = NULL;\n\t\tcss_put(blkcg_css);\n\t}\n\trcu_read_unlock();\n\n\treturn wb;\n}\n\n \nstruct bdi_writeback *wb_get_create(struct backing_dev_info *bdi,\n\t\t\t\t    struct cgroup_subsys_state *memcg_css,\n\t\t\t\t    gfp_t gfp)\n{\n\tstruct bdi_writeback *wb;\n\n\tmight_alloc(gfp);\n\n\tdo {\n\t\twb = wb_get_lookup(bdi, memcg_css);\n\t} while (!wb && !cgwb_create(bdi, memcg_css, gfp));\n\n\treturn wb;\n}\n\nstatic int cgwb_bdi_init(struct backing_dev_info *bdi)\n{\n\tint ret;\n\n\tINIT_RADIX_TREE(&bdi->cgwb_tree, GFP_ATOMIC);\n\tmutex_init(&bdi->cgwb_release_mutex);\n\tinit_rwsem(&bdi->wb_switch_rwsem);\n\n\tret = wb_init(&bdi->wb, bdi, GFP_KERNEL);\n\tif (!ret) {\n\t\tbdi->wb.memcg_css = &root_mem_cgroup->css;\n\t\tbdi->wb.blkcg_css = blkcg_root_css;\n\t}\n\treturn ret;\n}\n\nstatic void cgwb_bdi_unregister(struct backing_dev_info *bdi)\n{\n\tstruct radix_tree_iter iter;\n\tvoid **slot;\n\tstruct bdi_writeback *wb;\n\n\tWARN_ON(test_bit(WB_registered, &bdi->wb.state));\n\n\tspin_lock_irq(&cgwb_lock);\n\tradix_tree_for_each_slot(slot, &bdi->cgwb_tree, &iter, 0)\n\t\tcgwb_kill(*slot);\n\tspin_unlock_irq(&cgwb_lock);\n\n\tmutex_lock(&bdi->cgwb_release_mutex);\n\tspin_lock_irq(&cgwb_lock);\n\twhile (!list_empty(&bdi->wb_list)) {\n\t\twb = list_first_entry(&bdi->wb_list, struct bdi_writeback,\n\t\t\t\t      bdi_node);\n\t\tspin_unlock_irq(&cgwb_lock);\n\t\twb_shutdown(wb);\n\t\tspin_lock_irq(&cgwb_lock);\n\t}\n\tspin_unlock_irq(&cgwb_lock);\n\tmutex_unlock(&bdi->cgwb_release_mutex);\n}\n\n \nstatic void cleanup_offline_cgwbs_workfn(struct work_struct *work)\n{\n\tstruct bdi_writeback *wb;\n\tLIST_HEAD(processed);\n\n\tspin_lock_irq(&cgwb_lock);\n\n\twhile (!list_empty(&offline_cgwbs)) {\n\t\twb = list_first_entry(&offline_cgwbs, struct bdi_writeback,\n\t\t\t\t      offline_node);\n\t\tlist_move(&wb->offline_node, &processed);\n\n\t\t \n\t\tif (wb_has_dirty_io(wb))\n\t\t\tcontinue;\n\n\t\tif (!wb_tryget(wb))\n\t\t\tcontinue;\n\n\t\tspin_unlock_irq(&cgwb_lock);\n\t\twhile (cleanup_offline_cgwb(wb))\n\t\t\tcond_resched();\n\t\tspin_lock_irq(&cgwb_lock);\n\n\t\twb_put(wb);\n\t}\n\n\tif (!list_empty(&processed))\n\t\tlist_splice_tail(&processed, &offline_cgwbs);\n\n\tspin_unlock_irq(&cgwb_lock);\n}\n\n \nvoid wb_memcg_offline(struct mem_cgroup *memcg)\n{\n\tstruct list_head *memcg_cgwb_list = &memcg->cgwb_list;\n\tstruct bdi_writeback *wb, *next;\n\n\tspin_lock_irq(&cgwb_lock);\n\tlist_for_each_entry_safe(wb, next, memcg_cgwb_list, memcg_node)\n\t\tcgwb_kill(wb);\n\tmemcg_cgwb_list->next = NULL;\t \n\tspin_unlock_irq(&cgwb_lock);\n\n\tqueue_work(system_unbound_wq, &cleanup_offline_cgwbs_work);\n}\n\n \nvoid wb_blkcg_offline(struct cgroup_subsys_state *css)\n{\n\tstruct bdi_writeback *wb, *next;\n\tstruct list_head *list = blkcg_get_cgwb_list(css);\n\n\tspin_lock_irq(&cgwb_lock);\n\tlist_for_each_entry_safe(wb, next, list, blkcg_node)\n\t\tcgwb_kill(wb);\n\tlist->next = NULL;\t \n\tspin_unlock_irq(&cgwb_lock);\n}\n\nstatic void cgwb_bdi_register(struct backing_dev_info *bdi)\n{\n\tspin_lock_irq(&cgwb_lock);\n\tlist_add_tail_rcu(&bdi->wb.bdi_node, &bdi->wb_list);\n\tspin_unlock_irq(&cgwb_lock);\n}\n\nstatic int __init cgwb_init(void)\n{\n\t \n\tcgwb_release_wq = alloc_workqueue(\"cgwb_release\", 0, 1);\n\tif (!cgwb_release_wq)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\nsubsys_initcall(cgwb_init);\n\n#else\t \n\nstatic int cgwb_bdi_init(struct backing_dev_info *bdi)\n{\n\treturn wb_init(&bdi->wb, bdi, GFP_KERNEL);\n}\n\nstatic void cgwb_bdi_unregister(struct backing_dev_info *bdi) { }\n\nstatic void cgwb_bdi_register(struct backing_dev_info *bdi)\n{\n\tlist_add_tail_rcu(&bdi->wb.bdi_node, &bdi->wb_list);\n}\n\nstatic void cgwb_remove_from_bdi_list(struct bdi_writeback *wb)\n{\n\tlist_del_rcu(&wb->bdi_node);\n}\n\n#endif\t \n\nint bdi_init(struct backing_dev_info *bdi)\n{\n\tbdi->dev = NULL;\n\n\tkref_init(&bdi->refcnt);\n\tbdi->min_ratio = 0;\n\tbdi->max_ratio = 100 * BDI_RATIO_SCALE;\n\tbdi->max_prop_frac = FPROP_FRAC_BASE;\n\tINIT_LIST_HEAD(&bdi->bdi_list);\n\tINIT_LIST_HEAD(&bdi->wb_list);\n\tinit_waitqueue_head(&bdi->wb_waitq);\n\n\treturn cgwb_bdi_init(bdi);\n}\n\nstruct backing_dev_info *bdi_alloc(int node_id)\n{\n\tstruct backing_dev_info *bdi;\n\n\tbdi = kzalloc_node(sizeof(*bdi), GFP_KERNEL, node_id);\n\tif (!bdi)\n\t\treturn NULL;\n\n\tif (bdi_init(bdi)) {\n\t\tkfree(bdi);\n\t\treturn NULL;\n\t}\n\tbdi->capabilities = BDI_CAP_WRITEBACK | BDI_CAP_WRITEBACK_ACCT;\n\tbdi->ra_pages = VM_READAHEAD_PAGES;\n\tbdi->io_pages = VM_READAHEAD_PAGES;\n\ttimer_setup(&bdi->laptop_mode_wb_timer, laptop_mode_timer_fn, 0);\n\treturn bdi;\n}\nEXPORT_SYMBOL(bdi_alloc);\n\nstatic struct rb_node **bdi_lookup_rb_node(u64 id, struct rb_node **parentp)\n{\n\tstruct rb_node **p = &bdi_tree.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct backing_dev_info *bdi;\n\n\tlockdep_assert_held(&bdi_lock);\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tbdi = rb_entry(parent, struct backing_dev_info, rb_node);\n\n\t\tif (bdi->id > id)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (bdi->id < id)\n\t\t\tp = &(*p)->rb_right;\n\t\telse\n\t\t\tbreak;\n\t}\n\n\tif (parentp)\n\t\t*parentp = parent;\n\treturn p;\n}\n\n \nstruct backing_dev_info *bdi_get_by_id(u64 id)\n{\n\tstruct backing_dev_info *bdi = NULL;\n\tstruct rb_node **p;\n\n\tspin_lock_bh(&bdi_lock);\n\tp = bdi_lookup_rb_node(id, NULL);\n\tif (*p) {\n\t\tbdi = rb_entry(*p, struct backing_dev_info, rb_node);\n\t\tbdi_get(bdi);\n\t}\n\tspin_unlock_bh(&bdi_lock);\n\n\treturn bdi;\n}\n\nint bdi_register_va(struct backing_dev_info *bdi, const char *fmt, va_list args)\n{\n\tstruct device *dev;\n\tstruct rb_node *parent, **p;\n\n\tif (bdi->dev)\t \n\t\treturn 0;\n\n\tvsnprintf(bdi->dev_name, sizeof(bdi->dev_name), fmt, args);\n\tdev = device_create(&bdi_class, NULL, MKDEV(0, 0), bdi, bdi->dev_name);\n\tif (IS_ERR(dev))\n\t\treturn PTR_ERR(dev);\n\n\tcgwb_bdi_register(bdi);\n\tbdi->dev = dev;\n\n\tbdi_debug_register(bdi, dev_name(dev));\n\tset_bit(WB_registered, &bdi->wb.state);\n\n\tspin_lock_bh(&bdi_lock);\n\n\tbdi->id = ++bdi_id_cursor;\n\n\tp = bdi_lookup_rb_node(bdi->id, &parent);\n\trb_link_node(&bdi->rb_node, parent, p);\n\trb_insert_color(&bdi->rb_node, &bdi_tree);\n\n\tlist_add_tail_rcu(&bdi->bdi_list, &bdi_list);\n\n\tspin_unlock_bh(&bdi_lock);\n\n\ttrace_writeback_bdi_register(bdi);\n\treturn 0;\n}\n\nint bdi_register(struct backing_dev_info *bdi, const char *fmt, ...)\n{\n\tva_list args;\n\tint ret;\n\n\tva_start(args, fmt);\n\tret = bdi_register_va(bdi, fmt, args);\n\tva_end(args);\n\treturn ret;\n}\nEXPORT_SYMBOL(bdi_register);\n\nvoid bdi_set_owner(struct backing_dev_info *bdi, struct device *owner)\n{\n\tWARN_ON_ONCE(bdi->owner);\n\tbdi->owner = owner;\n\tget_device(owner);\n}\n\n \nstatic void bdi_remove_from_list(struct backing_dev_info *bdi)\n{\n\tspin_lock_bh(&bdi_lock);\n\trb_erase(&bdi->rb_node, &bdi_tree);\n\tlist_del_rcu(&bdi->bdi_list);\n\tspin_unlock_bh(&bdi_lock);\n\n\tsynchronize_rcu_expedited();\n}\n\nvoid bdi_unregister(struct backing_dev_info *bdi)\n{\n\tdel_timer_sync(&bdi->laptop_mode_wb_timer);\n\n\t \n\tbdi_remove_from_list(bdi);\n\twb_shutdown(&bdi->wb);\n\tcgwb_bdi_unregister(bdi);\n\n\t \n\tif (bdi->min_ratio)\n\t\tbdi_set_min_ratio(bdi, 0);\n\n\tif (bdi->dev) {\n\t\tbdi_debug_unregister(bdi);\n\t\tdevice_unregister(bdi->dev);\n\t\tbdi->dev = NULL;\n\t}\n\n\tif (bdi->owner) {\n\t\tput_device(bdi->owner);\n\t\tbdi->owner = NULL;\n\t}\n}\nEXPORT_SYMBOL(bdi_unregister);\n\nstatic void release_bdi(struct kref *ref)\n{\n\tstruct backing_dev_info *bdi =\n\t\t\tcontainer_of(ref, struct backing_dev_info, refcnt);\n\n\tWARN_ON_ONCE(test_bit(WB_registered, &bdi->wb.state));\n\tWARN_ON_ONCE(bdi->dev);\n\twb_exit(&bdi->wb);\n\tkfree(bdi);\n}\n\nvoid bdi_put(struct backing_dev_info *bdi)\n{\n\tkref_put(&bdi->refcnt, release_bdi);\n}\nEXPORT_SYMBOL(bdi_put);\n\nstruct backing_dev_info *inode_to_bdi(struct inode *inode)\n{\n\tstruct super_block *sb;\n\n\tif (!inode)\n\t\treturn &noop_backing_dev_info;\n\n\tsb = inode->i_sb;\n#ifdef CONFIG_BLOCK\n\tif (sb_is_blkdev_sb(sb))\n\t\treturn I_BDEV(inode)->bd_disk->bdi;\n#endif\n\treturn sb->s_bdi;\n}\nEXPORT_SYMBOL(inode_to_bdi);\n\nconst char *bdi_dev_name(struct backing_dev_info *bdi)\n{\n\tif (!bdi || !bdi->dev)\n\t\treturn bdi_unknown_name;\n\treturn bdi->dev_name;\n}\nEXPORT_SYMBOL_GPL(bdi_dev_name);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}