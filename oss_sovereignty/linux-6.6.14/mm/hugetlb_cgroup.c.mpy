{
  "module_name": "hugetlb_cgroup.c",
  "hash_id": "2cac8b0afa07904712d6886072b545071f3a5628e52050411c43ad2284e63ae8",
  "original_prompt": "Ingested from linux-6.6.14/mm/hugetlb_cgroup.c",
  "human_readable_source": " \n\n#include <linux/cgroup.h>\n#include <linux/page_counter.h>\n#include <linux/slab.h>\n#include <linux/hugetlb.h>\n#include <linux/hugetlb_cgroup.h>\n\n#define MEMFILE_PRIVATE(x, val)\t(((x) << 16) | (val))\n#define MEMFILE_IDX(val)\t(((val) >> 16) & 0xffff)\n#define MEMFILE_ATTR(val)\t((val) & 0xffff)\n\nstatic struct hugetlb_cgroup *root_h_cgroup __read_mostly;\n\nstatic inline struct page_counter *\n__hugetlb_cgroup_counter_from_cgroup(struct hugetlb_cgroup *h_cg, int idx,\n\t\t\t\t     bool rsvd)\n{\n\tif (rsvd)\n\t\treturn &h_cg->rsvd_hugepage[idx];\n\treturn &h_cg->hugepage[idx];\n}\n\nstatic inline struct page_counter *\nhugetlb_cgroup_counter_from_cgroup(struct hugetlb_cgroup *h_cg, int idx)\n{\n\treturn __hugetlb_cgroup_counter_from_cgroup(h_cg, idx, false);\n}\n\nstatic inline struct page_counter *\nhugetlb_cgroup_counter_from_cgroup_rsvd(struct hugetlb_cgroup *h_cg, int idx)\n{\n\treturn __hugetlb_cgroup_counter_from_cgroup(h_cg, idx, true);\n}\n\nstatic inline\nstruct hugetlb_cgroup *hugetlb_cgroup_from_css(struct cgroup_subsys_state *s)\n{\n\treturn s ? container_of(s, struct hugetlb_cgroup, css) : NULL;\n}\n\nstatic inline\nstruct hugetlb_cgroup *hugetlb_cgroup_from_task(struct task_struct *task)\n{\n\treturn hugetlb_cgroup_from_css(task_css(task, hugetlb_cgrp_id));\n}\n\nstatic inline bool hugetlb_cgroup_is_root(struct hugetlb_cgroup *h_cg)\n{\n\treturn (h_cg == root_h_cgroup);\n}\n\nstatic inline struct hugetlb_cgroup *\nparent_hugetlb_cgroup(struct hugetlb_cgroup *h_cg)\n{\n\treturn hugetlb_cgroup_from_css(h_cg->css.parent);\n}\n\nstatic inline bool hugetlb_cgroup_have_usage(struct hugetlb_cgroup *h_cg)\n{\n\tstruct hstate *h;\n\n\tfor_each_hstate(h) {\n\t\tif (page_counter_read(\n\t\t    hugetlb_cgroup_counter_from_cgroup(h_cg, hstate_index(h))))\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic void hugetlb_cgroup_init(struct hugetlb_cgroup *h_cgroup,\n\t\t\t\tstruct hugetlb_cgroup *parent_h_cgroup)\n{\n\tint idx;\n\n\tfor (idx = 0; idx < HUGE_MAX_HSTATE; idx++) {\n\t\tstruct page_counter *fault_parent = NULL;\n\t\tstruct page_counter *rsvd_parent = NULL;\n\t\tunsigned long limit;\n\t\tint ret;\n\n\t\tif (parent_h_cgroup) {\n\t\t\tfault_parent = hugetlb_cgroup_counter_from_cgroup(\n\t\t\t\tparent_h_cgroup, idx);\n\t\t\trsvd_parent = hugetlb_cgroup_counter_from_cgroup_rsvd(\n\t\t\t\tparent_h_cgroup, idx);\n\t\t}\n\t\tpage_counter_init(hugetlb_cgroup_counter_from_cgroup(h_cgroup,\n\t\t\t\t\t\t\t\t     idx),\n\t\t\t\t  fault_parent);\n\t\tpage_counter_init(\n\t\t\thugetlb_cgroup_counter_from_cgroup_rsvd(h_cgroup, idx),\n\t\t\trsvd_parent);\n\n\t\tlimit = round_down(PAGE_COUNTER_MAX,\n\t\t\t\t   pages_per_huge_page(&hstates[idx]));\n\n\t\tret = page_counter_set_max(\n\t\t\thugetlb_cgroup_counter_from_cgroup(h_cgroup, idx),\n\t\t\tlimit);\n\t\tVM_BUG_ON(ret);\n\t\tret = page_counter_set_max(\n\t\t\thugetlb_cgroup_counter_from_cgroup_rsvd(h_cgroup, idx),\n\t\t\tlimit);\n\t\tVM_BUG_ON(ret);\n\t}\n}\n\nstatic void hugetlb_cgroup_free(struct hugetlb_cgroup *h_cgroup)\n{\n\tint node;\n\n\tfor_each_node(node)\n\t\tkfree(h_cgroup->nodeinfo[node]);\n\tkfree(h_cgroup);\n}\n\nstatic struct cgroup_subsys_state *\nhugetlb_cgroup_css_alloc(struct cgroup_subsys_state *parent_css)\n{\n\tstruct hugetlb_cgroup *parent_h_cgroup = hugetlb_cgroup_from_css(parent_css);\n\tstruct hugetlb_cgroup *h_cgroup;\n\tint node;\n\n\th_cgroup = kzalloc(struct_size(h_cgroup, nodeinfo, nr_node_ids),\n\t\t\t   GFP_KERNEL);\n\n\tif (!h_cgroup)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (!parent_h_cgroup)\n\t\troot_h_cgroup = h_cgroup;\n\n\t \n\tfor_each_node(node) {\n\t\t \n\t\tint node_to_alloc =\n\t\t\tnode_state(node, N_NORMAL_MEMORY) ? node : NUMA_NO_NODE;\n\t\th_cgroup->nodeinfo[node] =\n\t\t\tkzalloc_node(sizeof(struct hugetlb_cgroup_per_node),\n\t\t\t\t     GFP_KERNEL, node_to_alloc);\n\t\tif (!h_cgroup->nodeinfo[node])\n\t\t\tgoto fail_alloc_nodeinfo;\n\t}\n\n\thugetlb_cgroup_init(h_cgroup, parent_h_cgroup);\n\treturn &h_cgroup->css;\n\nfail_alloc_nodeinfo:\n\thugetlb_cgroup_free(h_cgroup);\n\treturn ERR_PTR(-ENOMEM);\n}\n\nstatic void hugetlb_cgroup_css_free(struct cgroup_subsys_state *css)\n{\n\thugetlb_cgroup_free(hugetlb_cgroup_from_css(css));\n}\n\n \nstatic void hugetlb_cgroup_move_parent(int idx, struct hugetlb_cgroup *h_cg,\n\t\t\t\t       struct page *page)\n{\n\tunsigned int nr_pages;\n\tstruct page_counter *counter;\n\tstruct hugetlb_cgroup *page_hcg;\n\tstruct hugetlb_cgroup *parent = parent_hugetlb_cgroup(h_cg);\n\tstruct folio *folio = page_folio(page);\n\n\tpage_hcg = hugetlb_cgroup_from_folio(folio);\n\t \n\tif (!page_hcg || page_hcg != h_cg)\n\t\tgoto out;\n\n\tnr_pages = compound_nr(page);\n\tif (!parent) {\n\t\tparent = root_h_cgroup;\n\t\t \n\t\tpage_counter_charge(&parent->hugepage[idx], nr_pages);\n\t}\n\tcounter = &h_cg->hugepage[idx];\n\t \n\tpage_counter_cancel(counter, nr_pages);\n\n\tset_hugetlb_cgroup(folio, parent);\nout:\n\treturn;\n}\n\n \nstatic void hugetlb_cgroup_css_offline(struct cgroup_subsys_state *css)\n{\n\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(css);\n\tstruct hstate *h;\n\tstruct page *page;\n\n\tdo {\n\t\tfor_each_hstate(h) {\n\t\t\tspin_lock_irq(&hugetlb_lock);\n\t\t\tlist_for_each_entry(page, &h->hugepage_activelist, lru)\n\t\t\t\thugetlb_cgroup_move_parent(hstate_index(h), h_cg, page);\n\n\t\t\tspin_unlock_irq(&hugetlb_lock);\n\t\t}\n\t\tcond_resched();\n\t} while (hugetlb_cgroup_have_usage(h_cg));\n}\n\nstatic inline void hugetlb_event(struct hugetlb_cgroup *hugetlb, int idx,\n\t\t\t\t enum hugetlb_memory_event event)\n{\n\tatomic_long_inc(&hugetlb->events_local[idx][event]);\n\tcgroup_file_notify(&hugetlb->events_local_file[idx]);\n\n\tdo {\n\t\tatomic_long_inc(&hugetlb->events[idx][event]);\n\t\tcgroup_file_notify(&hugetlb->events_file[idx]);\n\t} while ((hugetlb = parent_hugetlb_cgroup(hugetlb)) &&\n\t\t !hugetlb_cgroup_is_root(hugetlb));\n}\n\nstatic int __hugetlb_cgroup_charge_cgroup(int idx, unsigned long nr_pages,\n\t\t\t\t\t  struct hugetlb_cgroup **ptr,\n\t\t\t\t\t  bool rsvd)\n{\n\tint ret = 0;\n\tstruct page_counter *counter;\n\tstruct hugetlb_cgroup *h_cg = NULL;\n\n\tif (hugetlb_cgroup_disabled())\n\t\tgoto done;\n\t \n\tif (huge_page_order(&hstates[idx]) < HUGETLB_CGROUP_MIN_ORDER)\n\t\tgoto done;\nagain:\n\trcu_read_lock();\n\th_cg = hugetlb_cgroup_from_task(current);\n\tif (!css_tryget(&h_cg->css)) {\n\t\trcu_read_unlock();\n\t\tgoto again;\n\t}\n\trcu_read_unlock();\n\n\tif (!page_counter_try_charge(\n\t\t    __hugetlb_cgroup_counter_from_cgroup(h_cg, idx, rsvd),\n\t\t    nr_pages, &counter)) {\n\t\tret = -ENOMEM;\n\t\thugetlb_event(h_cg, idx, HUGETLB_MAX);\n\t\tcss_put(&h_cg->css);\n\t\tgoto done;\n\t}\n\t \n\tif (!rsvd)\n\t\tcss_put(&h_cg->css);\ndone:\n\t*ptr = h_cg;\n\treturn ret;\n}\n\nint hugetlb_cgroup_charge_cgroup(int idx, unsigned long nr_pages,\n\t\t\t\t struct hugetlb_cgroup **ptr)\n{\n\treturn __hugetlb_cgroup_charge_cgroup(idx, nr_pages, ptr, false);\n}\n\nint hugetlb_cgroup_charge_cgroup_rsvd(int idx, unsigned long nr_pages,\n\t\t\t\t      struct hugetlb_cgroup **ptr)\n{\n\treturn __hugetlb_cgroup_charge_cgroup(idx, nr_pages, ptr, true);\n}\n\n \nstatic void __hugetlb_cgroup_commit_charge(int idx, unsigned long nr_pages,\n\t\t\t\t\t   struct hugetlb_cgroup *h_cg,\n\t\t\t\t\t   struct folio *folio, bool rsvd)\n{\n\tif (hugetlb_cgroup_disabled() || !h_cg)\n\t\treturn;\n\n\t__set_hugetlb_cgroup(folio, h_cg, rsvd);\n\tif (!rsvd) {\n\t\tunsigned long usage =\n\t\t\th_cg->nodeinfo[folio_nid(folio)]->usage[idx];\n\t\t \n\t\tWRITE_ONCE(h_cg->nodeinfo[folio_nid(folio)]->usage[idx],\n\t\t\t   usage + nr_pages);\n\t}\n}\n\nvoid hugetlb_cgroup_commit_charge(int idx, unsigned long nr_pages,\n\t\t\t\t  struct hugetlb_cgroup *h_cg,\n\t\t\t\t  struct folio *folio)\n{\n\t__hugetlb_cgroup_commit_charge(idx, nr_pages, h_cg, folio, false);\n}\n\nvoid hugetlb_cgroup_commit_charge_rsvd(int idx, unsigned long nr_pages,\n\t\t\t\t       struct hugetlb_cgroup *h_cg,\n\t\t\t\t       struct folio *folio)\n{\n\t__hugetlb_cgroup_commit_charge(idx, nr_pages, h_cg, folio, true);\n}\n\n \nstatic void __hugetlb_cgroup_uncharge_folio(int idx, unsigned long nr_pages,\n\t\t\t\t\t   struct folio *folio, bool rsvd)\n{\n\tstruct hugetlb_cgroup *h_cg;\n\n\tif (hugetlb_cgroup_disabled())\n\t\treturn;\n\tlockdep_assert_held(&hugetlb_lock);\n\th_cg = __hugetlb_cgroup_from_folio(folio, rsvd);\n\tif (unlikely(!h_cg))\n\t\treturn;\n\t__set_hugetlb_cgroup(folio, NULL, rsvd);\n\n\tpage_counter_uncharge(__hugetlb_cgroup_counter_from_cgroup(h_cg, idx,\n\t\t\t\t\t\t\t\t   rsvd),\n\t\t\t      nr_pages);\n\n\tif (rsvd)\n\t\tcss_put(&h_cg->css);\n\telse {\n\t\tunsigned long usage =\n\t\t\th_cg->nodeinfo[folio_nid(folio)]->usage[idx];\n\t\t \n\t\tWRITE_ONCE(h_cg->nodeinfo[folio_nid(folio)]->usage[idx],\n\t\t\t   usage - nr_pages);\n\t}\n}\n\nvoid hugetlb_cgroup_uncharge_folio(int idx, unsigned long nr_pages,\n\t\t\t\t  struct folio *folio)\n{\n\t__hugetlb_cgroup_uncharge_folio(idx, nr_pages, folio, false);\n}\n\nvoid hugetlb_cgroup_uncharge_folio_rsvd(int idx, unsigned long nr_pages,\n\t\t\t\t       struct folio *folio)\n{\n\t__hugetlb_cgroup_uncharge_folio(idx, nr_pages, folio, true);\n}\n\nstatic void __hugetlb_cgroup_uncharge_cgroup(int idx, unsigned long nr_pages,\n\t\t\t\t\t     struct hugetlb_cgroup *h_cg,\n\t\t\t\t\t     bool rsvd)\n{\n\tif (hugetlb_cgroup_disabled() || !h_cg)\n\t\treturn;\n\n\tif (huge_page_order(&hstates[idx]) < HUGETLB_CGROUP_MIN_ORDER)\n\t\treturn;\n\n\tpage_counter_uncharge(__hugetlb_cgroup_counter_from_cgroup(h_cg, idx,\n\t\t\t\t\t\t\t\t   rsvd),\n\t\t\t      nr_pages);\n\n\tif (rsvd)\n\t\tcss_put(&h_cg->css);\n}\n\nvoid hugetlb_cgroup_uncharge_cgroup(int idx, unsigned long nr_pages,\n\t\t\t\t    struct hugetlb_cgroup *h_cg)\n{\n\t__hugetlb_cgroup_uncharge_cgroup(idx, nr_pages, h_cg, false);\n}\n\nvoid hugetlb_cgroup_uncharge_cgroup_rsvd(int idx, unsigned long nr_pages,\n\t\t\t\t\t struct hugetlb_cgroup *h_cg)\n{\n\t__hugetlb_cgroup_uncharge_cgroup(idx, nr_pages, h_cg, true);\n}\n\nvoid hugetlb_cgroup_uncharge_counter(struct resv_map *resv, unsigned long start,\n\t\t\t\t     unsigned long end)\n{\n\tif (hugetlb_cgroup_disabled() || !resv || !resv->reservation_counter ||\n\t    !resv->css)\n\t\treturn;\n\n\tpage_counter_uncharge(resv->reservation_counter,\n\t\t\t      (end - start) * resv->pages_per_hpage);\n\tcss_put(resv->css);\n}\n\nvoid hugetlb_cgroup_uncharge_file_region(struct resv_map *resv,\n\t\t\t\t\t struct file_region *rg,\n\t\t\t\t\t unsigned long nr_pages,\n\t\t\t\t\t bool region_del)\n{\n\tif (hugetlb_cgroup_disabled() || !resv || !rg || !nr_pages)\n\t\treturn;\n\n\tif (rg->reservation_counter && resv->pages_per_hpage &&\n\t    !resv->reservation_counter) {\n\t\tpage_counter_uncharge(rg->reservation_counter,\n\t\t\t\t      nr_pages * resv->pages_per_hpage);\n\t\t \n\t\tif (region_del)\n\t\t\tcss_put(rg->css);\n\t}\n}\n\nenum {\n\tRES_USAGE,\n\tRES_RSVD_USAGE,\n\tRES_LIMIT,\n\tRES_RSVD_LIMIT,\n\tRES_MAX_USAGE,\n\tRES_RSVD_MAX_USAGE,\n\tRES_FAILCNT,\n\tRES_RSVD_FAILCNT,\n};\n\nstatic int hugetlb_cgroup_read_numa_stat(struct seq_file *seq, void *dummy)\n{\n\tint nid;\n\tstruct cftype *cft = seq_cft(seq);\n\tint idx = MEMFILE_IDX(cft->private);\n\tbool legacy = MEMFILE_ATTR(cft->private);\n\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(seq_css(seq));\n\tstruct cgroup_subsys_state *css;\n\tunsigned long usage;\n\n\tif (legacy) {\n\t\t \n\t\tusage = 0;\n\t\tfor_each_node_state(nid, N_MEMORY)\n\t\t\tusage += READ_ONCE(h_cg->nodeinfo[nid]->usage[idx]);\n\t\tseq_printf(seq, \"total=%lu\", usage * PAGE_SIZE);\n\n\t\t \n\t\tfor_each_node_state(nid, N_MEMORY)\n\t\t\tseq_printf(seq, \" N%d=%lu\", nid,\n\t\t\t\t   READ_ONCE(h_cg->nodeinfo[nid]->usage[idx]) *\n\t\t\t\t\t   PAGE_SIZE);\n\t\tseq_putc(seq, '\\n');\n\t}\n\n\t \n\tseq_printf(seq, \"%stotal=%lu\", legacy ? \"hierarchical_\" : \"\",\n\t\t   page_counter_read(&h_cg->hugepage[idx]) * PAGE_SIZE);\n\n\t \n\tfor_each_node_state(nid, N_MEMORY) {\n\t\tusage = 0;\n\t\trcu_read_lock();\n\t\tcss_for_each_descendant_pre(css, &h_cg->css) {\n\t\t\tusage += READ_ONCE(hugetlb_cgroup_from_css(css)\n\t\t\t\t\t\t   ->nodeinfo[nid]\n\t\t\t\t\t\t   ->usage[idx]);\n\t\t}\n\t\trcu_read_unlock();\n\t\tseq_printf(seq, \" N%d=%lu\", nid, usage * PAGE_SIZE);\n\t}\n\n\tseq_putc(seq, '\\n');\n\n\treturn 0;\n}\n\nstatic u64 hugetlb_cgroup_read_u64(struct cgroup_subsys_state *css,\n\t\t\t\t   struct cftype *cft)\n{\n\tstruct page_counter *counter;\n\tstruct page_counter *rsvd_counter;\n\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(css);\n\n\tcounter = &h_cg->hugepage[MEMFILE_IDX(cft->private)];\n\trsvd_counter = &h_cg->rsvd_hugepage[MEMFILE_IDX(cft->private)];\n\n\tswitch (MEMFILE_ATTR(cft->private)) {\n\tcase RES_USAGE:\n\t\treturn (u64)page_counter_read(counter) * PAGE_SIZE;\n\tcase RES_RSVD_USAGE:\n\t\treturn (u64)page_counter_read(rsvd_counter) * PAGE_SIZE;\n\tcase RES_LIMIT:\n\t\treturn (u64)counter->max * PAGE_SIZE;\n\tcase RES_RSVD_LIMIT:\n\t\treturn (u64)rsvd_counter->max * PAGE_SIZE;\n\tcase RES_MAX_USAGE:\n\t\treturn (u64)counter->watermark * PAGE_SIZE;\n\tcase RES_RSVD_MAX_USAGE:\n\t\treturn (u64)rsvd_counter->watermark * PAGE_SIZE;\n\tcase RES_FAILCNT:\n\t\treturn counter->failcnt;\n\tcase RES_RSVD_FAILCNT:\n\t\treturn rsvd_counter->failcnt;\n\tdefault:\n\t\tBUG();\n\t}\n}\n\nstatic int hugetlb_cgroup_read_u64_max(struct seq_file *seq, void *v)\n{\n\tint idx;\n\tu64 val;\n\tstruct cftype *cft = seq_cft(seq);\n\tunsigned long limit;\n\tstruct page_counter *counter;\n\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(seq_css(seq));\n\n\tidx = MEMFILE_IDX(cft->private);\n\tcounter = &h_cg->hugepage[idx];\n\n\tlimit = round_down(PAGE_COUNTER_MAX,\n\t\t\t   pages_per_huge_page(&hstates[idx]));\n\n\tswitch (MEMFILE_ATTR(cft->private)) {\n\tcase RES_RSVD_USAGE:\n\t\tcounter = &h_cg->rsvd_hugepage[idx];\n\t\tfallthrough;\n\tcase RES_USAGE:\n\t\tval = (u64)page_counter_read(counter);\n\t\tseq_printf(seq, \"%llu\\n\", val * PAGE_SIZE);\n\t\tbreak;\n\tcase RES_RSVD_LIMIT:\n\t\tcounter = &h_cg->rsvd_hugepage[idx];\n\t\tfallthrough;\n\tcase RES_LIMIT:\n\t\tval = (u64)counter->max;\n\t\tif (val == limit)\n\t\t\tseq_puts(seq, \"max\\n\");\n\t\telse\n\t\t\tseq_printf(seq, \"%llu\\n\", val * PAGE_SIZE);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn 0;\n}\n\nstatic DEFINE_MUTEX(hugetlb_limit_mutex);\n\nstatic ssize_t hugetlb_cgroup_write(struct kernfs_open_file *of,\n\t\t\t\t    char *buf, size_t nbytes, loff_t off,\n\t\t\t\t    const char *max)\n{\n\tint ret, idx;\n\tunsigned long nr_pages;\n\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(of_css(of));\n\tbool rsvd = false;\n\n\tif (hugetlb_cgroup_is_root(h_cg))  \n\t\treturn -EINVAL;\n\n\tbuf = strstrip(buf);\n\tret = page_counter_memparse(buf, max, &nr_pages);\n\tif (ret)\n\t\treturn ret;\n\n\tidx = MEMFILE_IDX(of_cft(of)->private);\n\tnr_pages = round_down(nr_pages, pages_per_huge_page(&hstates[idx]));\n\n\tswitch (MEMFILE_ATTR(of_cft(of)->private)) {\n\tcase RES_RSVD_LIMIT:\n\t\trsvd = true;\n\t\tfallthrough;\n\tcase RES_LIMIT:\n\t\tmutex_lock(&hugetlb_limit_mutex);\n\t\tret = page_counter_set_max(\n\t\t\t__hugetlb_cgroup_counter_from_cgroup(h_cg, idx, rsvd),\n\t\t\tnr_pages);\n\t\tmutex_unlock(&hugetlb_limit_mutex);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\treturn ret ?: nbytes;\n}\n\nstatic ssize_t hugetlb_cgroup_write_legacy(struct kernfs_open_file *of,\n\t\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\treturn hugetlb_cgroup_write(of, buf, nbytes, off, \"-1\");\n}\n\nstatic ssize_t hugetlb_cgroup_write_dfl(struct kernfs_open_file *of,\n\t\t\t\t\tchar *buf, size_t nbytes, loff_t off)\n{\n\treturn hugetlb_cgroup_write(of, buf, nbytes, off, \"max\");\n}\n\nstatic ssize_t hugetlb_cgroup_reset(struct kernfs_open_file *of,\n\t\t\t\t    char *buf, size_t nbytes, loff_t off)\n{\n\tint ret = 0;\n\tstruct page_counter *counter, *rsvd_counter;\n\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(of_css(of));\n\n\tcounter = &h_cg->hugepage[MEMFILE_IDX(of_cft(of)->private)];\n\trsvd_counter = &h_cg->rsvd_hugepage[MEMFILE_IDX(of_cft(of)->private)];\n\n\tswitch (MEMFILE_ATTR(of_cft(of)->private)) {\n\tcase RES_MAX_USAGE:\n\t\tpage_counter_reset_watermark(counter);\n\t\tbreak;\n\tcase RES_RSVD_MAX_USAGE:\n\t\tpage_counter_reset_watermark(rsvd_counter);\n\t\tbreak;\n\tcase RES_FAILCNT:\n\t\tcounter->failcnt = 0;\n\t\tbreak;\n\tcase RES_RSVD_FAILCNT:\n\t\trsvd_counter->failcnt = 0;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\treturn ret ?: nbytes;\n}\n\nstatic char *mem_fmt(char *buf, int size, unsigned long hsize)\n{\n\tif (hsize >= SZ_1G)\n\t\tsnprintf(buf, size, \"%luGB\", hsize / SZ_1G);\n\telse if (hsize >= SZ_1M)\n\t\tsnprintf(buf, size, \"%luMB\", hsize / SZ_1M);\n\telse\n\t\tsnprintf(buf, size, \"%luKB\", hsize / SZ_1K);\n\treturn buf;\n}\n\nstatic int __hugetlb_events_show(struct seq_file *seq, bool local)\n{\n\tint idx;\n\tlong max;\n\tstruct cftype *cft = seq_cft(seq);\n\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(seq_css(seq));\n\n\tidx = MEMFILE_IDX(cft->private);\n\n\tif (local)\n\t\tmax = atomic_long_read(&h_cg->events_local[idx][HUGETLB_MAX]);\n\telse\n\t\tmax = atomic_long_read(&h_cg->events[idx][HUGETLB_MAX]);\n\n\tseq_printf(seq, \"max %lu\\n\", max);\n\n\treturn 0;\n}\n\nstatic int hugetlb_events_show(struct seq_file *seq, void *v)\n{\n\treturn __hugetlb_events_show(seq, false);\n}\n\nstatic int hugetlb_events_local_show(struct seq_file *seq, void *v)\n{\n\treturn __hugetlb_events_show(seq, true);\n}\n\nstatic void __init __hugetlb_cgroup_file_dfl_init(int idx)\n{\n\tchar buf[32];\n\tstruct cftype *cft;\n\tstruct hstate *h = &hstates[idx];\n\n\t \n\tmem_fmt(buf, sizeof(buf), huge_page_size(h));\n\n\t \n\tcft = &h->cgroup_files_dfl[0];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.max\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_LIMIT);\n\tcft->seq_show = hugetlb_cgroup_read_u64_max;\n\tcft->write = hugetlb_cgroup_write_dfl;\n\tcft->flags = CFTYPE_NOT_ON_ROOT;\n\n\t \n\tcft = &h->cgroup_files_dfl[1];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.max\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_LIMIT);\n\tcft->seq_show = hugetlb_cgroup_read_u64_max;\n\tcft->write = hugetlb_cgroup_write_dfl;\n\tcft->flags = CFTYPE_NOT_ON_ROOT;\n\n\t \n\tcft = &h->cgroup_files_dfl[2];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.current\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_USAGE);\n\tcft->seq_show = hugetlb_cgroup_read_u64_max;\n\tcft->flags = CFTYPE_NOT_ON_ROOT;\n\n\t \n\tcft = &h->cgroup_files_dfl[3];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.current\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_USAGE);\n\tcft->seq_show = hugetlb_cgroup_read_u64_max;\n\tcft->flags = CFTYPE_NOT_ON_ROOT;\n\n\t \n\tcft = &h->cgroup_files_dfl[4];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.events\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, 0);\n\tcft->seq_show = hugetlb_events_show;\n\tcft->file_offset = offsetof(struct hugetlb_cgroup, events_file[idx]);\n\tcft->flags = CFTYPE_NOT_ON_ROOT;\n\n\t \n\tcft = &h->cgroup_files_dfl[5];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.events.local\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, 0);\n\tcft->seq_show = hugetlb_events_local_show;\n\tcft->file_offset = offsetof(struct hugetlb_cgroup,\n\t\t\t\t    events_local_file[idx]);\n\tcft->flags = CFTYPE_NOT_ON_ROOT;\n\n\t \n\tcft = &h->cgroup_files_dfl[6];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.numa_stat\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, 0);\n\tcft->seq_show = hugetlb_cgroup_read_numa_stat;\n\tcft->flags = CFTYPE_NOT_ON_ROOT;\n\n\t \n\tcft = &h->cgroup_files_dfl[7];\n\tmemset(cft, 0, sizeof(*cft));\n\n\tWARN_ON(cgroup_add_dfl_cftypes(&hugetlb_cgrp_subsys,\n\t\t\t\t       h->cgroup_files_dfl));\n}\n\nstatic void __init __hugetlb_cgroup_file_legacy_init(int idx)\n{\n\tchar buf[32];\n\tstruct cftype *cft;\n\tstruct hstate *h = &hstates[idx];\n\n\t \n\tmem_fmt(buf, sizeof(buf), huge_page_size(h));\n\n\t \n\tcft = &h->cgroup_files_legacy[0];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.limit_in_bytes\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_LIMIT);\n\tcft->read_u64 = hugetlb_cgroup_read_u64;\n\tcft->write = hugetlb_cgroup_write_legacy;\n\n\t \n\tcft = &h->cgroup_files_legacy[1];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.limit_in_bytes\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_LIMIT);\n\tcft->read_u64 = hugetlb_cgroup_read_u64;\n\tcft->write = hugetlb_cgroup_write_legacy;\n\n\t \n\tcft = &h->cgroup_files_legacy[2];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.usage_in_bytes\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_USAGE);\n\tcft->read_u64 = hugetlb_cgroup_read_u64;\n\n\t \n\tcft = &h->cgroup_files_legacy[3];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.usage_in_bytes\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_USAGE);\n\tcft->read_u64 = hugetlb_cgroup_read_u64;\n\n\t \n\tcft = &h->cgroup_files_legacy[4];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.max_usage_in_bytes\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_MAX_USAGE);\n\tcft->write = hugetlb_cgroup_reset;\n\tcft->read_u64 = hugetlb_cgroup_read_u64;\n\n\t \n\tcft = &h->cgroup_files_legacy[5];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.max_usage_in_bytes\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_MAX_USAGE);\n\tcft->write = hugetlb_cgroup_reset;\n\tcft->read_u64 = hugetlb_cgroup_read_u64;\n\n\t \n\tcft = &h->cgroup_files_legacy[6];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.failcnt\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_FAILCNT);\n\tcft->write = hugetlb_cgroup_reset;\n\tcft->read_u64 = hugetlb_cgroup_read_u64;\n\n\t \n\tcft = &h->cgroup_files_legacy[7];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.failcnt\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_FAILCNT);\n\tcft->write = hugetlb_cgroup_reset;\n\tcft->read_u64 = hugetlb_cgroup_read_u64;\n\n\t \n\tcft = &h->cgroup_files_legacy[8];\n\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.numa_stat\", buf);\n\tcft->private = MEMFILE_PRIVATE(idx, 1);\n\tcft->seq_show = hugetlb_cgroup_read_numa_stat;\n\n\t \n\tcft = &h->cgroup_files_legacy[9];\n\tmemset(cft, 0, sizeof(*cft));\n\n\tWARN_ON(cgroup_add_legacy_cftypes(&hugetlb_cgrp_subsys,\n\t\t\t\t\t  h->cgroup_files_legacy));\n}\n\nstatic void __init __hugetlb_cgroup_file_init(int idx)\n{\n\t__hugetlb_cgroup_file_dfl_init(idx);\n\t__hugetlb_cgroup_file_legacy_init(idx);\n}\n\nvoid __init hugetlb_cgroup_file_init(void)\n{\n\tstruct hstate *h;\n\n\tfor_each_hstate(h) {\n\t\t \n\t\tif (huge_page_order(h) >= HUGETLB_CGROUP_MIN_ORDER)\n\t\t\t__hugetlb_cgroup_file_init(hstate_index(h));\n\t}\n}\n\n \nvoid hugetlb_cgroup_migrate(struct folio *old_folio, struct folio *new_folio)\n{\n\tstruct hugetlb_cgroup *h_cg;\n\tstruct hugetlb_cgroup *h_cg_rsvd;\n\tstruct hstate *h = folio_hstate(old_folio);\n\n\tif (hugetlb_cgroup_disabled())\n\t\treturn;\n\n\tspin_lock_irq(&hugetlb_lock);\n\th_cg = hugetlb_cgroup_from_folio(old_folio);\n\th_cg_rsvd = hugetlb_cgroup_from_folio_rsvd(old_folio);\n\tset_hugetlb_cgroup(old_folio, NULL);\n\tset_hugetlb_cgroup_rsvd(old_folio, NULL);\n\n\t \n\tset_hugetlb_cgroup(new_folio, h_cg);\n\tset_hugetlb_cgroup_rsvd(new_folio, h_cg_rsvd);\n\tlist_move(&new_folio->lru, &h->hugepage_activelist);\n\tspin_unlock_irq(&hugetlb_lock);\n\treturn;\n}\n\nstatic struct cftype hugetlb_files[] = {\n\t{}  \n};\n\nstruct cgroup_subsys hugetlb_cgrp_subsys = {\n\t.css_alloc\t= hugetlb_cgroup_css_alloc,\n\t.css_offline\t= hugetlb_cgroup_css_offline,\n\t.css_free\t= hugetlb_cgroup_css_free,\n\t.dfl_cftypes\t= hugetlb_files,\n\t.legacy_cftypes\t= hugetlb_files,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}