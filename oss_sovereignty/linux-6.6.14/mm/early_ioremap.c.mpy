{
  "module_name": "early_ioremap.c",
  "hash_id": "053633fe13ab1a9d22ccfb61660e74c4d8fea34ad0e5ddf10d688bc250ab9d28",
  "original_prompt": "Ingested from linux-6.6.14/mm/early_ioremap.c",
  "human_readable_source": "\n \n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/io.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <asm/fixmap.h>\n#include <asm/early_ioremap.h>\n#include \"internal.h\"\n\n#ifdef CONFIG_MMU\nstatic int early_ioremap_debug __initdata;\n\nstatic int __init early_ioremap_debug_setup(char *str)\n{\n\tearly_ioremap_debug = 1;\n\n\treturn 0;\n}\nearly_param(\"early_ioremap_debug\", early_ioremap_debug_setup);\n\nstatic int after_paging_init __initdata;\n\npgprot_t __init __weak early_memremap_pgprot_adjust(resource_size_t phys_addr,\n\t\t\t\t\t\t    unsigned long size,\n\t\t\t\t\t\t    pgprot_t prot)\n{\n\treturn prot;\n}\n\nvoid __init early_ioremap_reset(void)\n{\n\tafter_paging_init = 1;\n}\n\n \n#ifndef __late_set_fixmap\nstatic inline void __init __late_set_fixmap(enum fixed_addresses idx,\n\t\t\t\t\t    phys_addr_t phys, pgprot_t prot)\n{\n\tBUG();\n}\n#endif\n\n#ifndef __late_clear_fixmap\nstatic inline void __init __late_clear_fixmap(enum fixed_addresses idx)\n{\n\tBUG();\n}\n#endif\n\nstatic void __iomem *prev_map[FIX_BTMAPS_SLOTS] __initdata;\nstatic unsigned long prev_size[FIX_BTMAPS_SLOTS] __initdata;\nstatic unsigned long slot_virt[FIX_BTMAPS_SLOTS] __initdata;\n\nvoid __init early_ioremap_setup(void)\n{\n\tint i;\n\n\tfor (i = 0; i < FIX_BTMAPS_SLOTS; i++) {\n\t\tWARN_ON_ONCE(prev_map[i]);\n\t\tslot_virt[i] = __fix_to_virt(FIX_BTMAP_BEGIN - NR_FIX_BTMAPS*i);\n\t}\n}\n\nstatic int __init check_early_ioremap_leak(void)\n{\n\tint count = 0;\n\tint i;\n\n\tfor (i = 0; i < FIX_BTMAPS_SLOTS; i++)\n\t\tif (prev_map[i])\n\t\t\tcount++;\n\n\tif (WARN(count, KERN_WARNING\n\t\t \"Debug warning: early ioremap leak of %d areas detected.\\n\"\n\t\t \"please boot with early_ioremap_debug and report the dmesg.\\n\",\n\t\t count))\n\t\treturn 1;\n\treturn 0;\n}\nlate_initcall(check_early_ioremap_leak);\n\nstatic void __init __iomem *\n__early_ioremap(resource_size_t phys_addr, unsigned long size, pgprot_t prot)\n{\n\tunsigned long offset;\n\tresource_size_t last_addr;\n\tunsigned int nrpages;\n\tenum fixed_addresses idx;\n\tint i, slot;\n\n\tWARN_ON(system_state >= SYSTEM_RUNNING);\n\n\tslot = -1;\n\tfor (i = 0; i < FIX_BTMAPS_SLOTS; i++) {\n\t\tif (!prev_map[i]) {\n\t\t\tslot = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (WARN(slot < 0, \"%s(%pa, %08lx) not found slot\\n\",\n\t\t __func__, &phys_addr, size))\n\t\treturn NULL;\n\n\t \n\tlast_addr = phys_addr + size - 1;\n\tif (WARN_ON(!size || last_addr < phys_addr))\n\t\treturn NULL;\n\n\tprev_size[slot] = size;\n\t \n\toffset = offset_in_page(phys_addr);\n\tphys_addr &= PAGE_MASK;\n\tsize = PAGE_ALIGN(last_addr + 1) - phys_addr;\n\n\t \n\tnrpages = size >> PAGE_SHIFT;\n\tif (WARN_ON(nrpages > NR_FIX_BTMAPS))\n\t\treturn NULL;\n\n\t \n\tidx = FIX_BTMAP_BEGIN - NR_FIX_BTMAPS*slot;\n\twhile (nrpages > 0) {\n\t\tif (after_paging_init)\n\t\t\t__late_set_fixmap(idx, phys_addr, prot);\n\t\telse\n\t\t\t__early_set_fixmap(idx, phys_addr, prot);\n\t\tphys_addr += PAGE_SIZE;\n\t\t--idx;\n\t\t--nrpages;\n\t}\n\tWARN(early_ioremap_debug, \"%s(%pa, %08lx) [%d] => %08lx + %08lx\\n\",\n\t     __func__, &phys_addr, size, slot, offset, slot_virt[slot]);\n\n\tprev_map[slot] = (void __iomem *)(offset + slot_virt[slot]);\n\treturn prev_map[slot];\n}\n\nvoid __init early_iounmap(void __iomem *addr, unsigned long size)\n{\n\tunsigned long virt_addr;\n\tunsigned long offset;\n\tunsigned int nrpages;\n\tenum fixed_addresses idx;\n\tint i, slot;\n\n\tslot = -1;\n\tfor (i = 0; i < FIX_BTMAPS_SLOTS; i++) {\n\t\tif (prev_map[i] == addr) {\n\t\t\tslot = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (WARN(slot < 0, \"%s(%p, %08lx) not found slot\\n\",\n\t\t  __func__, addr, size))\n\t\treturn;\n\n\tif (WARN(prev_size[slot] != size,\n\t\t \"%s(%p, %08lx) [%d] size not consistent %08lx\\n\",\n\t\t  __func__, addr, size, slot, prev_size[slot]))\n\t\treturn;\n\n\tWARN(early_ioremap_debug, \"%s(%p, %08lx) [%d]\\n\",\n\t      __func__, addr, size, slot);\n\n\tvirt_addr = (unsigned long)addr;\n\tif (WARN_ON(virt_addr < fix_to_virt(FIX_BTMAP_BEGIN)))\n\t\treturn;\n\n\toffset = offset_in_page(virt_addr);\n\tnrpages = PAGE_ALIGN(offset + size) >> PAGE_SHIFT;\n\n\tidx = FIX_BTMAP_BEGIN - NR_FIX_BTMAPS*slot;\n\twhile (nrpages > 0) {\n\t\tif (after_paging_init)\n\t\t\t__late_clear_fixmap(idx);\n\t\telse\n\t\t\t__early_set_fixmap(idx, 0, FIXMAP_PAGE_CLEAR);\n\t\t--idx;\n\t\t--nrpages;\n\t}\n\tprev_map[slot] = NULL;\n}\n\n \nvoid __init __iomem *\nearly_ioremap(resource_size_t phys_addr, unsigned long size)\n{\n\treturn __early_ioremap(phys_addr, size, FIXMAP_PAGE_IO);\n}\n\n \nvoid __init *\nearly_memremap(resource_size_t phys_addr, unsigned long size)\n{\n\tpgprot_t prot = early_memremap_pgprot_adjust(phys_addr, size,\n\t\t\t\t\t\t     FIXMAP_PAGE_NORMAL);\n\n\treturn (__force void *)__early_ioremap(phys_addr, size, prot);\n}\n#ifdef FIXMAP_PAGE_RO\nvoid __init *\nearly_memremap_ro(resource_size_t phys_addr, unsigned long size)\n{\n\tpgprot_t prot = early_memremap_pgprot_adjust(phys_addr, size,\n\t\t\t\t\t\t     FIXMAP_PAGE_RO);\n\n\treturn (__force void *)__early_ioremap(phys_addr, size, prot);\n}\n#endif\n\n#ifdef CONFIG_ARCH_USE_MEMREMAP_PROT\nvoid __init *\nearly_memremap_prot(resource_size_t phys_addr, unsigned long size,\n\t\t    unsigned long prot_val)\n{\n\treturn (__force void *)__early_ioremap(phys_addr, size,\n\t\t\t\t\t       __pgprot(prot_val));\n}\n#endif\n\n#define MAX_MAP_CHUNK\t(NR_FIX_BTMAPS << PAGE_SHIFT)\n\nvoid __init copy_from_early_mem(void *dest, phys_addr_t src, unsigned long size)\n{\n\tunsigned long slop, clen;\n\tchar *p;\n\n\twhile (size) {\n\t\tslop = offset_in_page(src);\n\t\tclen = size;\n\t\tif (clen > MAX_MAP_CHUNK - slop)\n\t\t\tclen = MAX_MAP_CHUNK - slop;\n\t\tp = early_memremap(src & PAGE_MASK, clen + slop);\n\t\tmemcpy(dest, p + slop, clen);\n\t\tearly_memunmap(p, clen + slop);\n\t\tdest += clen;\n\t\tsrc += clen;\n\t\tsize -= clen;\n\t}\n}\n\n#else  \n\nvoid __init __iomem *\nearly_ioremap(resource_size_t phys_addr, unsigned long size)\n{\n\treturn (__force void __iomem *)phys_addr;\n}\n\n \nvoid __init *\nearly_memremap(resource_size_t phys_addr, unsigned long size)\n{\n\treturn (void *)phys_addr;\n}\nvoid __init *\nearly_memremap_ro(resource_size_t phys_addr, unsigned long size)\n{\n\treturn (void *)phys_addr;\n}\n\nvoid __init early_iounmap(void __iomem *addr, unsigned long size)\n{\n}\n\n#endif  \n\n\nvoid __init early_memunmap(void *addr, unsigned long size)\n{\n\tearly_iounmap((__force void __iomem *)addr, size);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}