{
  "module_name": "helpers.rs",
  "hash_id": "b9d5c6ab9d904f496e6ac800f25a9b00da2adb8bc2e9a8e766e88a3edc3ea05a",
  "original_prompt": "Ingested from linux-6.6.14/rust/macros/helpers.rs",
  "human_readable_source": "// SPDX-License-Identifier: GPL-2.0\n\nuse proc_macro::{token_stream, Group, Punct, Spacing, TokenStream, TokenTree};\n\npub(crate) fn try_ident(it: &mut token_stream::IntoIter) -> Option<String> {\n    if let Some(TokenTree::Ident(ident)) = it.next() {\n        Some(ident.to_string())\n    } else {\n        None\n    }\n}\n\npub(crate) fn try_literal(it: &mut token_stream::IntoIter) -> Option<String> {\n    if let Some(TokenTree::Literal(literal)) = it.next() {\n        Some(literal.to_string())\n    } else {\n        None\n    }\n}\n\npub(crate) fn try_string(it: &mut token_stream::IntoIter) -> Option<String> {\n    try_literal(it).and_then(|string| {\n        if string.starts_with('\\\"') && string.ends_with('\\\"') {\n            let content = &string[1..string.len() - 1];\n            if content.contains('\\\\') {\n                panic!(\"Escape sequences in string literals not yet handled\");\n            }\n            Some(content.to_string())\n        } else if string.starts_with(\"r\\\"\") {\n            panic!(\"Raw string literals are not yet handled\");\n        } else {\n            None\n        }\n    })\n}\n\npub(crate) fn expect_ident(it: &mut token_stream::IntoIter) -> String {\n    try_ident(it).expect(\"Expected Ident\")\n}\n\npub(crate) fn expect_punct(it: &mut token_stream::IntoIter) -> char {\n    if let TokenTree::Punct(punct) = it.next().expect(\"Reached end of token stream for Punct\") {\n        punct.as_char()\n    } else {\n        panic!(\"Expected Punct\");\n    }\n}\n\npub(crate) fn expect_string(it: &mut token_stream::IntoIter) -> String {\n    try_string(it).expect(\"Expected string\")\n}\n\npub(crate) fn expect_string_ascii(it: &mut token_stream::IntoIter) -> String {\n    let string = try_string(it).expect(\"Expected string\");\n    assert!(string.is_ascii(), \"Expected ASCII string\");\n    string\n}\n\npub(crate) fn expect_group(it: &mut token_stream::IntoIter) -> Group {\n    if let TokenTree::Group(group) = it.next().expect(\"Reached end of token stream for Group\") {\n        group\n    } else {\n        panic!(\"Expected Group\");\n    }\n}\n\npub(crate) fn expect_end(it: &mut token_stream::IntoIter) {\n    if it.next().is_some() {\n        panic!(\"Expected end\");\n    }\n}\n\npub(crate) struct Generics {\n    pub(crate) impl_generics: Vec<TokenTree>,\n    pub(crate) ty_generics: Vec<TokenTree>,\n}\n\n/// Parses the given `TokenStream` into `Generics` and the rest.\n///\n/// The generics are not present in the rest, but a where clause might remain.\npub(crate) fn parse_generics(input: TokenStream) -> (Generics, Vec<TokenTree>) {\n    // `impl_generics`, the declared generics with their bounds.\n    let mut impl_generics = vec![];\n    // Only the names of the generics, without any bounds.\n    let mut ty_generics = vec![];\n    // Tokens not related to the generics e.g. the `where` token and definition.\n    let mut rest = vec![];\n    // The current level of `<`.\n    let mut nesting = 0;\n    let mut toks = input.into_iter();\n    // If we are at the beginning of a generic parameter.\n    let mut at_start = true;\n    for tt in &mut toks {\n        match tt.clone() {\n            TokenTree::Punct(p) if p.as_char() == '<' => {\n                if nesting >= 1 {\n                    // This is inside of the generics and part of some bound.\n                    impl_generics.push(tt);\n                }\n                nesting += 1;\n            }\n            TokenTree::Punct(p) if p.as_char() == '>' => {\n                // This is a parsing error, so we just end it here.\n                if nesting == 0 {\n                    break;\n                } else {\n                    nesting -= 1;\n                    if nesting >= 1 {\n                        // We are still inside of the generics and part of some bound.\n                        impl_generics.push(tt);\n                    }\n                    if nesting == 0 {\n                        break;\n                    }\n                }\n            }\n            tt => {\n                if nesting == 1 {\n                    // Here depending on the token, it might be a generic variable name.\n                    match &tt {\n                        // Ignore const.\n                        TokenTree::Ident(i) if i.to_string() == \"const\" => {}\n                        TokenTree::Ident(_) if at_start => {\n                            ty_generics.push(tt.clone());\n                            // We also already push the `,` token, this makes it easier to append\n                            // generics.\n                            ty_generics.push(TokenTree::Punct(Punct::new(',', Spacing::Alone)));\n                            at_start = false;\n                        }\n                        TokenTree::Punct(p) if p.as_char() == ',' => at_start = true,\n                        // Lifetimes begin with `'`.\n                        TokenTree::Punct(p) if p.as_char() == '\\'' && at_start => {\n                            ty_generics.push(tt.clone());\n                        }\n                        _ => {}\n                    }\n                }\n                if nesting >= 1 {\n                    impl_generics.push(tt);\n                } else if nesting == 0 {\n                    // If we haven't entered the generics yet, we still want to keep these tokens.\n                    rest.push(tt);\n                }\n            }\n        }\n    }\n    rest.extend(toks);\n    (\n        Generics {\n            impl_generics,\n            ty_generics,\n        },\n        rest,\n    )\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}