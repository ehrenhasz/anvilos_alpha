{
  "module_name": "paste.rs",
  "hash_id": "edf9eccecf176f1b9ace73e96c8c981d3b8360671f0529381f817a5b64b11717",
  "original_prompt": "Ingested from linux-6.6.14/rust/macros/paste.rs",
  "human_readable_source": "// SPDX-License-Identifier: GPL-2.0\n\nuse proc_macro::{Delimiter, Group, Ident, Spacing, Span, TokenTree};\n\nfn concat(tokens: &[TokenTree], group_span: Span) -> TokenTree {\n    let mut tokens = tokens.iter();\n    let mut segments = Vec::new();\n    let mut span = None;\n    loop {\n        match tokens.next() {\n            None => break,\n            Some(TokenTree::Literal(lit)) => segments.push((lit.to_string(), lit.span())),\n            Some(TokenTree::Ident(ident)) => {\n                let mut value = ident.to_string();\n                if value.starts_with(\"r#\") {\n                    value.replace_range(0..2, \"\");\n                }\n                segments.push((value, ident.span()));\n            }\n            Some(TokenTree::Punct(p)) if p.as_char() == ':' => {\n                let Some(TokenTree::Ident(ident)) = tokens.next() else {\n                    panic!(\"expected identifier as modifier\");\n                };\n\n                let (mut value, sp) = segments.pop().expect(\"expected identifier before modifier\");\n                match ident.to_string().as_str() {\n                    // Set the overall span of concatenated token as current span\n                    \"span\" => {\n                        assert!(\n                            span.is_none(),\n                            \"span modifier should only appear at most once\"\n                        );\n                        span = Some(sp);\n                    }\n                    \"lower\" => value = value.to_lowercase(),\n                    \"upper\" => value = value.to_uppercase(),\n                    v => panic!(\"unknown modifier `{v}`\"),\n                };\n                segments.push((value, sp));\n            }\n            _ => panic!(\"unexpected token in paste segments\"),\n        };\n    }\n\n    let pasted: String = segments.into_iter().map(|x| x.0).collect();\n    TokenTree::Ident(Ident::new(&pasted, span.unwrap_or(group_span)))\n}\n\npub(crate) fn expand(tokens: &mut Vec<TokenTree>) {\n    for token in tokens.iter_mut() {\n        if let TokenTree::Group(group) = token {\n            let delimiter = group.delimiter();\n            let span = group.span();\n            let mut stream: Vec<_> = group.stream().into_iter().collect();\n            // Find groups that looks like `[< A B C D >]`\n            if delimiter == Delimiter::Bracket\n                && stream.len() >= 3\n                && matches!(&stream[0], TokenTree::Punct(p) if p.as_char() == '<')\n                && matches!(&stream[stream.len() - 1], TokenTree::Punct(p) if p.as_char() == '>')\n            {\n                // Replace the group with concatenated token\n                *token = concat(&stream[1..stream.len() - 1], span);\n            } else {\n                // Recursively expand tokens inside the group\n                expand(&mut stream);\n                let mut group = Group::new(delimiter, stream.into_iter().collect());\n                group.set_span(span);\n                *token = TokenTree::Group(group);\n            }\n        }\n    }\n\n    // Path segments cannot contain invisible delimiter group, so remove them if any.\n    for i in (0..tokens.len().saturating_sub(3)).rev() {\n        // Looking for a double colon\n        if matches!(\n            (&tokens[i + 1], &tokens[i + 2]),\n            (TokenTree::Punct(a), TokenTree::Punct(b))\n                if a.as_char() == ':' && a.spacing() == Spacing::Joint && b.as_char() == ':'\n        ) {\n            match &tokens[i + 3] {\n                TokenTree::Group(group) if group.delimiter() == Delimiter::None => {\n                    tokens.splice(i + 3..i + 4, group.stream());\n                }\n                _ => (),\n            }\n\n            match &tokens[i] {\n                TokenTree::Group(group) if group.delimiter() == Delimiter::None => {\n                    tokens.splice(i..i + 1, group.stream());\n                }\n                _ => (),\n            }\n        }\n    }\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}