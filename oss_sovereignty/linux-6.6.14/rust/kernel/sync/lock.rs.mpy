{
  "module_name": "lock.rs",
  "hash_id": "069dda57a951dea19ca70ebd9ffcfbc24c5121821d8fa893ec21bbb14adabab7",
  "original_prompt": "Ingested from linux-6.6.14/rust/kernel/sync/lock.rs",
  "human_readable_source": "// SPDX-License-Identifier: GPL-2.0\n\n//! Generic kernel lock and guard.\n//!\n//! It contains a generic Rust lock and guard that allow for different backends (e.g., mutexes,\n//! spinlocks, raw spinlocks) to be provided with minimal effort.\n\nuse super::LockClassKey;\nuse crate::{bindings, init::PinInit, pin_init, str::CStr, types::Opaque, types::ScopeGuard};\nuse core::{cell::UnsafeCell, marker::PhantomData, marker::PhantomPinned};\nuse macros::pin_data;\n\npub mod mutex;\npub mod spinlock;\n\n/// The \"backend\" of a lock.\n///\n/// It is the actual implementation of the lock, without the need to repeat patterns used in all\n/// locks.\n///\n/// # Safety\n///\n/// - Implementers must ensure that only one thread/CPU may access the protected data once the lock\n/// is owned, that is, between calls to `lock` and `unlock`.\n/// - Implementers must also ensure that `relock` uses the same locking method as the original\n/// lock operation.\npub unsafe trait Backend {\n    /// The state required by the lock.\n    type State;\n\n    /// The state required to be kept between lock and unlock.\n    type GuardState;\n\n    /// Initialises the lock.\n    ///\n    /// # Safety\n    ///\n    /// `ptr` must be valid for write for the duration of the call, while `name` and `key` must\n    /// remain valid for read indefinitely.\n    unsafe fn init(\n        ptr: *mut Self::State,\n        name: *const core::ffi::c_char,\n        key: *mut bindings::lock_class_key,\n    );\n\n    /// Acquires the lock, making the caller its owner.\n    ///\n    /// # Safety\n    ///\n    /// Callers must ensure that [`Backend::init`] has been previously called.\n    #[must_use]\n    unsafe fn lock(ptr: *mut Self::State) -> Self::GuardState;\n\n    /// Releases the lock, giving up its ownership.\n    ///\n    /// # Safety\n    ///\n    /// It must only be called by the current owner of the lock.\n    unsafe fn unlock(ptr: *mut Self::State, guard_state: &Self::GuardState);\n\n    /// Reacquires the lock, making the caller its owner.\n    ///\n    /// # Safety\n    ///\n    /// Callers must ensure that `guard_state` comes from a previous call to [`Backend::lock`] (or\n    /// variant) that has been unlocked with [`Backend::unlock`] and will be relocked now.\n    unsafe fn relock(ptr: *mut Self::State, guard_state: &mut Self::GuardState) {\n        // SAFETY: The safety requirements ensure that the lock is initialised.\n        *guard_state = unsafe { Self::lock(ptr) };\n    }\n}\n\n/// A mutual exclusion primitive.\n///\n/// Exposes one of the kernel locking primitives. Which one is exposed depends on the lock\n/// [`Backend`] specified as the generic parameter `B`.\n#[pin_data]\npub struct Lock<T: ?Sized, B: Backend> {\n    /// The kernel lock object.\n    #[pin]\n    state: Opaque<B::State>,\n\n    /// Some locks are known to be self-referential (e.g., mutexes), while others are architecture\n    /// or config defined (e.g., spinlocks). So we conservatively require them to be pinned in case\n    /// some architecture uses self-references now or in the future.\n    #[pin]\n    _pin: PhantomPinned,\n\n    /// The data protected by the lock.\n    pub(crate) data: UnsafeCell<T>,\n}\n\n// SAFETY: `Lock` can be transferred across thread boundaries iff the data it protects can.\nunsafe impl<T: ?Sized + Send, B: Backend> Send for Lock<T, B> {}\n\n// SAFETY: `Lock` serialises the interior mutability it provides, so it is `Sync` as long as the\n// data it protects is `Send`.\nunsafe impl<T: ?Sized + Send, B: Backend> Sync for Lock<T, B> {}\n\nimpl<T, B: Backend> Lock<T, B> {\n    /// Constructs a new lock initialiser.\n    #[allow(clippy::new_ret_no_self)]\n    pub fn new(t: T, name: &'static CStr, key: &'static LockClassKey) -> impl PinInit<Self> {\n        pin_init!(Self {\n            data: UnsafeCell::new(t),\n            _pin: PhantomPinned,\n            // SAFETY: `slot` is valid while the closure is called and both `name` and `key` have\n            // static lifetimes so they live indefinitely.\n            state <- Opaque::ffi_init(|slot| unsafe {\n                B::init(slot, name.as_char_ptr(), key.as_ptr())\n            }),\n        })\n    }\n}\n\nimpl<T: ?Sized, B: Backend> Lock<T, B> {\n    /// Acquires the lock and gives the caller access to the data protected by it.\n    pub fn lock(&self) -> Guard<'_, T, B> {\n        // SAFETY: The constructor of the type calls `init`, so the existence of the object proves\n        // that `init` was called.\n        let state = unsafe { B::lock(self.state.get()) };\n        // SAFETY: The lock was just acquired.\n        unsafe { Guard::new(self, state) }\n    }\n}\n\n/// A lock guard.\n///\n/// Allows mutual exclusion primitives that implement the [`Backend`] trait to automatically unlock\n/// when a guard goes out of scope. It also provides a safe and convenient way to access the data\n/// protected by the lock.\n#[must_use = \"the lock unlocks immediately when the guard is unused\"]\npub struct Guard<'a, T: ?Sized, B: Backend> {\n    pub(crate) lock: &'a Lock<T, B>,\n    pub(crate) state: B::GuardState,\n    _not_send: PhantomData<*mut ()>,\n}\n\n// SAFETY: `Guard` is sync when the data protected by the lock is also sync.\nunsafe impl<T: Sync + ?Sized, B: Backend> Sync for Guard<'_, T, B> {}\n\nimpl<T: ?Sized, B: Backend> Guard<'_, T, B> {\n    pub(crate) fn do_unlocked(&mut self, cb: impl FnOnce()) {\n        // SAFETY: The caller owns the lock, so it is safe to unlock it.\n        unsafe { B::unlock(self.lock.state.get(), &self.state) };\n\n        // SAFETY: The lock was just unlocked above and is being relocked now.\n        let _relock =\n            ScopeGuard::new(|| unsafe { B::relock(self.lock.state.get(), &mut self.state) });\n\n        cb();\n    }\n}\n\nimpl<T: ?Sized, B: Backend> core::ops::Deref for Guard<'_, T, B> {\n    type Target = T;\n\n    fn deref(&self) -> &Self::Target {\n        // SAFETY: The caller owns the lock, so it is safe to deref the protected data.\n        unsafe { &*self.lock.data.get() }\n    }\n}\n\nimpl<T: ?Sized, B: Backend> core::ops::DerefMut for Guard<'_, T, B> {\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        // SAFETY: The caller owns the lock, so it is safe to deref the protected data.\n        unsafe { &mut *self.lock.data.get() }\n    }\n}\n\nimpl<T: ?Sized, B: Backend> Drop for Guard<'_, T, B> {\n    fn drop(&mut self) {\n        // SAFETY: The caller owns the lock, so it is safe to unlock it.\n        unsafe { B::unlock(self.lock.state.get(), &self.state) };\n    }\n}\n\nimpl<'a, T: ?Sized, B: Backend> Guard<'a, T, B> {\n    /// Constructs a new immutable lock guard.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that it owns the lock.\n    pub(crate) unsafe fn new(lock: &'a Lock<T, B>, state: B::GuardState) -> Self {\n        Self {\n            lock,\n            state,\n            _not_send: PhantomData,\n        }\n    }\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}