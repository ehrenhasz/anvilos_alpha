{
  "module_name": "into_iter.rs",
  "hash_id": "7e457f47d9bc18c7604677e294be7178d01a4501b3f163c64d443c239a67b95f",
  "original_prompt": "Ingested from linux-6.6.14/rust/alloc/vec/into_iter.rs",
  "human_readable_source": "// SPDX-License-Identifier: Apache-2.0 OR MIT\n\n#[cfg(not(no_global_oom_handling))]\nuse super::AsVecIntoIter;\nuse crate::alloc::{Allocator, Global};\n#[cfg(not(no_global_oom_handling))]\nuse crate::collections::VecDeque;\nuse crate::raw_vec::RawVec;\nuse core::array;\nuse core::fmt;\nuse core::iter::{\n    FusedIterator, InPlaceIterable, SourceIter, TrustedLen, TrustedRandomAccessNoCoerce,\n};\nuse core::marker::PhantomData;\nuse core::mem::{self, ManuallyDrop, MaybeUninit, SizedTypeProperties};\nuse core::num::NonZeroUsize;\n#[cfg(not(no_global_oom_handling))]\nuse core::ops::Deref;\nuse core::ptr::{self, NonNull};\nuse core::slice::{self};\n\n/// An iterator that moves out of a vector.\n///\n/// This `struct` is created by the `into_iter` method on [`Vec`](super::Vec)\n/// (provided by the [`IntoIterator`] trait).\n///\n/// # Example\n///\n/// ```\n/// let v = vec![0, 1, 2];\n/// let iter: std::vec::IntoIter<_> = v.into_iter();\n/// ```\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[rustc_insignificant_dtor]\npub struct IntoIter<\n    T,\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")] A: Allocator = Global,\n> {\n    pub(super) buf: NonNull<T>,\n    pub(super) phantom: PhantomData<T>,\n    pub(super) cap: usize,\n    // the drop impl reconstructs a RawVec from buf, cap and alloc\n    // to avoid dropping the allocator twice we need to wrap it into ManuallyDrop\n    pub(super) alloc: ManuallyDrop<A>,\n    pub(super) ptr: *const T,\n    pub(super) end: *const T, // If T is a ZST, this is actually ptr+len. This encoding is picked so that\n                              // ptr == end is a quick test for the Iterator being empty, that works\n                              // for both ZST and non-ZST.\n}\n\n#[stable(feature = \"vec_intoiter_debug\", since = \"1.13.0\")]\nimpl<T: fmt::Debug, A: Allocator> fmt::Debug for IntoIter<T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"IntoIter\").field(&self.as_slice()).finish()\n    }\n}\n\nimpl<T, A: Allocator> IntoIter<T, A> {\n    /// Returns the remaining items of this iterator as a slice.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let vec = vec!['a', 'b', 'c'];\n    /// let mut into_iter = vec.into_iter();\n    /// assert_eq!(into_iter.as_slice(), &['a', 'b', 'c']);\n    /// let _ = into_iter.next().unwrap();\n    /// assert_eq!(into_iter.as_slice(), &['b', 'c']);\n    /// ```\n    #[stable(feature = \"vec_into_iter_as_slice\", since = \"1.15.0\")]\n    pub fn as_slice(&self) -> &[T] {\n        unsafe { slice::from_raw_parts(self.ptr, self.len()) }\n    }\n\n    /// Returns the remaining items of this iterator as a mutable slice.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// let vec = vec!['a', 'b', 'c'];\n    /// let mut into_iter = vec.into_iter();\n    /// assert_eq!(into_iter.as_slice(), &['a', 'b', 'c']);\n    /// into_iter.as_mut_slice()[2] = 'z';\n    /// assert_eq!(into_iter.next().unwrap(), 'a');\n    /// assert_eq!(into_iter.next().unwrap(), 'b');\n    /// assert_eq!(into_iter.next().unwrap(), 'z');\n    /// ```\n    #[stable(feature = \"vec_into_iter_as_slice\", since = \"1.15.0\")]\n    pub fn as_mut_slice(&mut self) -> &mut [T] {\n        unsafe { &mut *self.as_raw_mut_slice() }\n    }\n\n    /// Returns a reference to the underlying allocator.\n    #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n    #[inline]\n    pub fn allocator(&self) -> &A {\n        &self.alloc\n    }\n\n    fn as_raw_mut_slice(&mut self) -> *mut [T] {\n        ptr::slice_from_raw_parts_mut(self.ptr as *mut T, self.len())\n    }\n\n    /// Drops remaining elements and relinquishes the backing allocation.\n    /// This method guarantees it won't panic before relinquishing\n    /// the backing allocation.\n    ///\n    /// This is roughly equivalent to the following, but more efficient\n    ///\n    /// ```\n    /// # let mut into_iter = Vec::<u8>::with_capacity(10).into_iter();\n    /// let mut into_iter = std::mem::replace(&mut into_iter, Vec::new().into_iter());\n    /// (&mut into_iter).for_each(drop);\n    /// std::mem::forget(into_iter);\n    /// ```\n    ///\n    /// This method is used by in-place iteration, refer to the vec::in_place_collect\n    /// documentation for an overview.\n    #[cfg(not(no_global_oom_handling))]\n    pub(super) fn forget_allocation_drop_remaining(&mut self) {\n        let remaining = self.as_raw_mut_slice();\n\n        // overwrite the individual fields instead of creating a new\n        // struct and then overwriting &mut self.\n        // this creates less assembly\n        self.cap = 0;\n        self.buf = unsafe { NonNull::new_unchecked(RawVec::NEW.ptr()) };\n        self.ptr = self.buf.as_ptr();\n        self.end = self.buf.as_ptr();\n\n        // Dropping the remaining elements can panic, so this needs to be\n        // done only after updating the other fields.\n        unsafe {\n            ptr::drop_in_place(remaining);\n        }\n    }\n\n    /// Forgets to Drop the remaining elements while still allowing the backing allocation to be freed.\n    pub(crate) fn forget_remaining_elements(&mut self) {\n        // For th ZST case, it is crucial that we mutate `end` here, not `ptr`.\n        // `ptr` must stay aligned, while `end` may be unaligned.\n        self.end = self.ptr;\n    }\n\n    #[cfg(not(no_global_oom_handling))]\n    #[inline]\n    pub(crate) fn into_vecdeque(self) -> VecDeque<T, A> {\n        // Keep our `Drop` impl from dropping the elements and the allocator\n        let mut this = ManuallyDrop::new(self);\n\n        // SAFETY: This allocation originally came from a `Vec`, so it passes\n        // all those checks. We have `this.buf` \u2264 `this.ptr` \u2264 `this.end`,\n        // so the `sub_ptr`s below cannot wrap, and will produce a well-formed\n        // range. `end` \u2264 `buf + cap`, so the range will be in-bounds.\n        // Taking `alloc` is ok because nothing else is going to look at it,\n        // since our `Drop` impl isn't going to run so there's no more code.\n        unsafe {\n            let buf = this.buf.as_ptr();\n            let initialized = if T::IS_ZST {\n                // All the pointers are the same for ZSTs, so it's fine to\n                // say that they're all at the beginning of the \"allocation\".\n                0..this.len()\n            } else {\n                this.ptr.sub_ptr(buf)..this.end.sub_ptr(buf)\n            };\n            let cap = this.cap;\n            let alloc = ManuallyDrop::take(&mut this.alloc);\n            VecDeque::from_contiguous_raw_parts_in(buf, initialized, cap, alloc)\n        }\n    }\n}\n\n#[stable(feature = \"vec_intoiter_as_ref\", since = \"1.46.0\")]\nimpl<T, A: Allocator> AsRef<[T]> for IntoIter<T, A> {\n    fn as_ref(&self) -> &[T] {\n        self.as_slice()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Send, A: Allocator + Send> Send for IntoIter<T, A> {}\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<T: Sync, A: Allocator + Sync> Sync for IntoIter<T, A> {}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> Iterator for IntoIter<T, A> {\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<T> {\n        if self.ptr == self.end {\n            None\n        } else if T::IS_ZST {\n            // `ptr` has to stay where it is to remain aligned, so we reduce the length by 1 by\n            // reducing the `end`.\n            self.end = self.end.wrapping_byte_sub(1);\n\n            // Make up a value of this ZST.\n            Some(unsafe { mem::zeroed() })\n        } else {\n            let old = self.ptr;\n            self.ptr = unsafe { self.ptr.add(1) };\n\n            Some(unsafe { ptr::read(old) })\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let exact = if T::IS_ZST {\n            self.end.addr().wrapping_sub(self.ptr.addr())\n        } else {\n            unsafe { self.end.sub_ptr(self.ptr) }\n        };\n        (exact, Some(exact))\n    }\n\n    #[inline]\n    fn advance_by(&mut self, n: usize) -> Result<(), NonZeroUsize> {\n        let step_size = self.len().min(n);\n        let to_drop = ptr::slice_from_raw_parts_mut(self.ptr as *mut T, step_size);\n        if T::IS_ZST {\n            // See `next` for why we sub `end` here.\n            self.end = self.end.wrapping_byte_sub(step_size);\n        } else {\n            // SAFETY: the min() above ensures that step_size is in bounds\n            self.ptr = unsafe { self.ptr.add(step_size) };\n        }\n        // SAFETY: the min() above ensures that step_size is in bounds\n        unsafe {\n            ptr::drop_in_place(to_drop);\n        }\n        NonZeroUsize::new(n - step_size).map_or(Ok(()), Err)\n    }\n\n    #[inline]\n    fn count(self) -> usize {\n        self.len()\n    }\n\n    #[inline]\n    fn next_chunk<const N: usize>(&mut self) -> Result<[T; N], core::array::IntoIter<T, N>> {\n        let mut raw_ary = MaybeUninit::uninit_array();\n\n        let len = self.len();\n\n        if T::IS_ZST {\n            if len < N {\n                self.forget_remaining_elements();\n                // Safety: ZSTs can be conjured ex nihilo, only the amount has to be correct\n                return Err(unsafe { array::IntoIter::new_unchecked(raw_ary, 0..len) });\n            }\n\n            self.end = self.end.wrapping_byte_sub(N);\n            // Safety: ditto\n            return Ok(unsafe { raw_ary.transpose().assume_init() });\n        }\n\n        if len < N {\n            // Safety: `len` indicates that this many elements are available and we just checked that\n            // it fits into the array.\n            unsafe {\n                ptr::copy_nonoverlapping(self.ptr, raw_ary.as_mut_ptr() as *mut T, len);\n                self.forget_remaining_elements();\n                return Err(array::IntoIter::new_unchecked(raw_ary, 0..len));\n            }\n        }\n\n        // Safety: `len` is larger than the array size. Copy a fixed amount here to fully initialize\n        // the array.\n        return unsafe {\n            ptr::copy_nonoverlapping(self.ptr, raw_ary.as_mut_ptr() as *mut T, N);\n            self.ptr = self.ptr.add(N);\n            Ok(raw_ary.transpose().assume_init())\n        };\n    }\n\n    unsafe fn __iterator_get_unchecked(&mut self, i: usize) -> Self::Item\n    where\n        Self: TrustedRandomAccessNoCoerce,\n    {\n        // SAFETY: the caller must guarantee that `i` is in bounds of the\n        // `Vec<T>`, so `i` cannot overflow an `isize`, and the `self.ptr.add(i)`\n        // is guaranteed to pointer to an element of the `Vec<T>` and\n        // thus guaranteed to be valid to dereference.\n        //\n        // Also note the implementation of `Self: TrustedRandomAccess` requires\n        // that `T: Copy` so reading elements from the buffer doesn't invalidate\n        // them for `Drop`.\n        unsafe {\n            if T::IS_ZST { mem::zeroed() } else { ptr::read(self.ptr.add(i)) }\n        }\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> DoubleEndedIterator for IntoIter<T, A> {\n    #[inline]\n    fn next_back(&mut self) -> Option<T> {\n        if self.end == self.ptr {\n            None\n        } else if T::IS_ZST {\n            // See above for why 'ptr.offset' isn't used\n            self.end = self.end.wrapping_byte_sub(1);\n\n            // Make up a value of this ZST.\n            Some(unsafe { mem::zeroed() })\n        } else {\n            self.end = unsafe { self.end.sub(1) };\n\n            Some(unsafe { ptr::read(self.end) })\n        }\n    }\n\n    #[inline]\n    fn advance_back_by(&mut self, n: usize) -> Result<(), NonZeroUsize> {\n        let step_size = self.len().min(n);\n        if T::IS_ZST {\n            // SAFETY: same as for advance_by()\n            self.end = self.end.wrapping_byte_sub(step_size);\n        } else {\n            // SAFETY: same as for advance_by()\n            self.end = unsafe { self.end.sub(step_size) };\n        }\n        let to_drop = ptr::slice_from_raw_parts_mut(self.end as *mut T, step_size);\n        // SAFETY: same as for advance_by()\n        unsafe {\n            ptr::drop_in_place(to_drop);\n        }\n        NonZeroUsize::new(n - step_size).map_or(Ok(()), Err)\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nimpl<T, A: Allocator> ExactSizeIterator for IntoIter<T, A> {\n    fn is_empty(&self) -> bool {\n        self.ptr == self.end\n    }\n}\n\n#[stable(feature = \"fused\", since = \"1.26.0\")]\nimpl<T, A: Allocator> FusedIterator for IntoIter<T, A> {}\n\n#[unstable(feature = \"trusted_len\", issue = \"37572\")]\nunsafe impl<T, A: Allocator> TrustedLen for IntoIter<T, A> {}\n\n#[stable(feature = \"default_iters\", since = \"1.70.0\")]\nimpl<T, A> Default for IntoIter<T, A>\nwhere\n    A: Allocator + Default,\n{\n    /// Creates an empty `vec::IntoIter`.\n    ///\n    /// ```\n    /// # use std::vec;\n    /// let iter: vec::IntoIter<u8> = Default::default();\n    /// assert_eq!(iter.len(), 0);\n    /// assert_eq!(iter.as_slice(), &[]);\n    /// ```\n    fn default() -> Self {\n        super::Vec::new_in(Default::default()).into_iter()\n    }\n}\n\n#[doc(hidden)]\n#[unstable(issue = \"none\", feature = \"std_internals\")]\n#[rustc_unsafe_specialization_marker]\npub trait NonDrop {}\n\n// T: Copy as approximation for !Drop since get_unchecked does not advance self.ptr\n// and thus we can't implement drop-handling\n#[unstable(issue = \"none\", feature = \"std_internals\")]\nimpl<T: Copy> NonDrop for T {}\n\n#[doc(hidden)]\n#[unstable(issue = \"none\", feature = \"std_internals\")]\n// TrustedRandomAccess (without NoCoerce) must not be implemented because\n// subtypes/supertypes of `T` might not be `NonDrop`\nunsafe impl<T, A: Allocator> TrustedRandomAccessNoCoerce for IntoIter<T, A>\nwhere\n    T: NonDrop,\n{\n    const MAY_HAVE_SIDE_EFFECT: bool = false;\n}\n\n#[cfg(not(no_global_oom_handling))]\n#[stable(feature = \"vec_into_iter_clone\", since = \"1.8.0\")]\nimpl<T: Clone, A: Allocator + Clone> Clone for IntoIter<T, A> {\n    #[cfg(not(test))]\n    fn clone(&self) -> Self {\n        self.as_slice().to_vec_in(self.alloc.deref().clone()).into_iter()\n    }\n    #[cfg(test)]\n    fn clone(&self) -> Self {\n        crate::slice::to_vec(self.as_slice(), self.alloc.deref().clone()).into_iter()\n    }\n}\n\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\nunsafe impl<#[may_dangle] T, A: Allocator> Drop for IntoIter<T, A> {\n    fn drop(&mut self) {\n        struct DropGuard<'a, T, A: Allocator>(&'a mut IntoIter<T, A>);\n\n        impl<T, A: Allocator> Drop for DropGuard<'_, T, A> {\n            fn drop(&mut self) {\n                unsafe {\n                    // `IntoIter::alloc` is not used anymore after this and will be dropped by RawVec\n                    let alloc = ManuallyDrop::take(&mut self.0.alloc);\n                    // RawVec handles deallocation\n                    let _ = RawVec::from_raw_parts_in(self.0.buf.as_ptr(), self.0.cap, alloc);\n                }\n            }\n        }\n\n        let guard = DropGuard(self);\n        // destroy the remaining elements\n        unsafe {\n            ptr::drop_in_place(guard.0.as_raw_mut_slice());\n        }\n        // now `guard` will be dropped and do the rest\n    }\n}\n\n// In addition to the SAFETY invariants of the following three unsafe traits\n// also refer to the vec::in_place_collect module documentation to get an overview\n#[unstable(issue = \"none\", feature = \"inplace_iteration\")]\n#[doc(hidden)]\nunsafe impl<T, A: Allocator> InPlaceIterable for IntoIter<T, A> {}\n\n#[unstable(issue = \"none\", feature = \"inplace_iteration\")]\n#[doc(hidden)]\nunsafe impl<T, A: Allocator> SourceIter for IntoIter<T, A> {\n    type Source = Self;\n\n    #[inline]\n    unsafe fn as_inner(&mut self) -> &mut Self::Source {\n        self\n    }\n}\n\n#[cfg(not(no_global_oom_handling))]\nunsafe impl<T> AsVecIntoIter for IntoIter<T> {\n    type Item = T;\n\n    fn as_into_iter(&mut self) -> &mut IntoIter<Self::Item> {\n        self\n    }\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}