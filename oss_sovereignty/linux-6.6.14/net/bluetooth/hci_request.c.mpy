{
  "module_name": "hci_request.c",
  "hash_id": "38f1fe525130bdce18687337ee26c26f9ee0e4e724d62f28799b2dbd95d09c67",
  "original_prompt": "Ingested from linux-6.6.14/net/bluetooth/hci_request.c",
  "human_readable_source": " \n\n#include <linux/sched/signal.h>\n\n#include <net/bluetooth/bluetooth.h>\n#include <net/bluetooth/hci_core.h>\n#include <net/bluetooth/mgmt.h>\n\n#include \"smp.h\"\n#include \"hci_request.h\"\n#include \"msft.h\"\n#include \"eir.h\"\n\nvoid hci_req_init(struct hci_request *req, struct hci_dev *hdev)\n{\n\tskb_queue_head_init(&req->cmd_q);\n\treq->hdev = hdev;\n\treq->err = 0;\n}\n\nvoid hci_req_purge(struct hci_request *req)\n{\n\tskb_queue_purge(&req->cmd_q);\n}\n\nbool hci_req_status_pend(struct hci_dev *hdev)\n{\n\treturn hdev->req_status == HCI_REQ_PEND;\n}\n\nstatic int req_run(struct hci_request *req, hci_req_complete_t complete,\n\t\t   hci_req_complete_skb_t complete_skb)\n{\n\tstruct hci_dev *hdev = req->hdev;\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\n\tbt_dev_dbg(hdev, \"length %u\", skb_queue_len(&req->cmd_q));\n\n\t \n\tif (req->err) {\n\t\tskb_queue_purge(&req->cmd_q);\n\t\treturn req->err;\n\t}\n\n\t \n\tif (skb_queue_empty(&req->cmd_q))\n\t\treturn -ENODATA;\n\n\tskb = skb_peek_tail(&req->cmd_q);\n\tif (complete) {\n\t\tbt_cb(skb)->hci.req_complete = complete;\n\t} else if (complete_skb) {\n\t\tbt_cb(skb)->hci.req_complete_skb = complete_skb;\n\t\tbt_cb(skb)->hci.req_flags |= HCI_REQ_SKB;\n\t}\n\n\tspin_lock_irqsave(&hdev->cmd_q.lock, flags);\n\tskb_queue_splice_tail(&req->cmd_q, &hdev->cmd_q);\n\tspin_unlock_irqrestore(&hdev->cmd_q.lock, flags);\n\n\tqueue_work(hdev->workqueue, &hdev->cmd_work);\n\n\treturn 0;\n}\n\nint hci_req_run(struct hci_request *req, hci_req_complete_t complete)\n{\n\treturn req_run(req, complete, NULL);\n}\n\nint hci_req_run_skb(struct hci_request *req, hci_req_complete_skb_t complete)\n{\n\treturn req_run(req, NULL, complete);\n}\n\nvoid hci_req_sync_complete(struct hci_dev *hdev, u8 result, u16 opcode,\n\t\t\t   struct sk_buff *skb)\n{\n\tbt_dev_dbg(hdev, \"result 0x%2.2x\", result);\n\n\tif (hdev->req_status == HCI_REQ_PEND) {\n\t\thdev->req_result = result;\n\t\thdev->req_status = HCI_REQ_DONE;\n\t\tif (skb)\n\t\t\thdev->req_skb = skb_get(skb);\n\t\twake_up_interruptible(&hdev->req_wait_q);\n\t}\n}\n\n \nint __hci_req_sync(struct hci_dev *hdev, int (*func)(struct hci_request *req,\n\t\t\t\t\t\t     unsigned long opt),\n\t\t   unsigned long opt, u32 timeout, u8 *hci_status)\n{\n\tstruct hci_request req;\n\tint err = 0;\n\n\tbt_dev_dbg(hdev, \"start\");\n\n\thci_req_init(&req, hdev);\n\n\thdev->req_status = HCI_REQ_PEND;\n\n\terr = func(&req, opt);\n\tif (err) {\n\t\tif (hci_status)\n\t\t\t*hci_status = HCI_ERROR_UNSPECIFIED;\n\t\treturn err;\n\t}\n\n\terr = hci_req_run_skb(&req, hci_req_sync_complete);\n\tif (err < 0) {\n\t\thdev->req_status = 0;\n\n\t\t \n\t\tif (err == -ENODATA) {\n\t\t\tif (hci_status)\n\t\t\t\t*hci_status = 0;\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (hci_status)\n\t\t\t*hci_status = HCI_ERROR_UNSPECIFIED;\n\n\t\treturn err;\n\t}\n\n\terr = wait_event_interruptible_timeout(hdev->req_wait_q,\n\t\t\thdev->req_status != HCI_REQ_PEND, timeout);\n\n\tif (err == -ERESTARTSYS)\n\t\treturn -EINTR;\n\n\tswitch (hdev->req_status) {\n\tcase HCI_REQ_DONE:\n\t\terr = -bt_to_errno(hdev->req_result);\n\t\tif (hci_status)\n\t\t\t*hci_status = hdev->req_result;\n\t\tbreak;\n\n\tcase HCI_REQ_CANCELED:\n\t\terr = -hdev->req_result;\n\t\tif (hci_status)\n\t\t\t*hci_status = HCI_ERROR_UNSPECIFIED;\n\t\tbreak;\n\n\tdefault:\n\t\terr = -ETIMEDOUT;\n\t\tif (hci_status)\n\t\t\t*hci_status = HCI_ERROR_UNSPECIFIED;\n\t\tbreak;\n\t}\n\n\tkfree_skb(hdev->req_skb);\n\thdev->req_skb = NULL;\n\thdev->req_status = hdev->req_result = 0;\n\n\tbt_dev_dbg(hdev, \"end: err %d\", err);\n\n\treturn err;\n}\n\nint hci_req_sync(struct hci_dev *hdev, int (*req)(struct hci_request *req,\n\t\t\t\t\t\t  unsigned long opt),\n\t\t unsigned long opt, u32 timeout, u8 *hci_status)\n{\n\tint ret;\n\n\t \n\thci_req_sync_lock(hdev);\n\t \n\tif (test_bit(HCI_UP, &hdev->flags))\n\t\tret = __hci_req_sync(hdev, req, opt, timeout, hci_status);\n\telse\n\t\tret = -ENETDOWN;\n\thci_req_sync_unlock(hdev);\n\n\treturn ret;\n}\n\nstruct sk_buff *hci_prepare_cmd(struct hci_dev *hdev, u16 opcode, u32 plen,\n\t\t\t\tconst void *param)\n{\n\tint len = HCI_COMMAND_HDR_SIZE + plen;\n\tstruct hci_command_hdr *hdr;\n\tstruct sk_buff *skb;\n\n\tskb = bt_skb_alloc(len, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn NULL;\n\n\thdr = skb_put(skb, HCI_COMMAND_HDR_SIZE);\n\thdr->opcode = cpu_to_le16(opcode);\n\thdr->plen   = plen;\n\n\tif (plen)\n\t\tskb_put_data(skb, param, plen);\n\n\tbt_dev_dbg(hdev, \"skb len %d\", skb->len);\n\n\thci_skb_pkt_type(skb) = HCI_COMMAND_PKT;\n\thci_skb_opcode(skb) = opcode;\n\n\treturn skb;\n}\n\n \nvoid hci_req_add_ev(struct hci_request *req, u16 opcode, u32 plen,\n\t\t    const void *param, u8 event)\n{\n\tstruct hci_dev *hdev = req->hdev;\n\tstruct sk_buff *skb;\n\n\tbt_dev_dbg(hdev, \"opcode 0x%4.4x plen %d\", opcode, plen);\n\n\t \n\tif (req->err)\n\t\treturn;\n\n\tskb = hci_prepare_cmd(hdev, opcode, plen, param);\n\tif (!skb) {\n\t\tbt_dev_err(hdev, \"no memory for command (opcode 0x%4.4x)\",\n\t\t\t   opcode);\n\t\treq->err = -ENOMEM;\n\t\treturn;\n\t}\n\n\tif (skb_queue_empty(&req->cmd_q))\n\t\tbt_cb(skb)->hci.req_flags |= HCI_REQ_START;\n\n\thci_skb_event(skb) = event;\n\n\tskb_queue_tail(&req->cmd_q, skb);\n}\n\nvoid hci_req_add(struct hci_request *req, u16 opcode, u32 plen,\n\t\t const void *param)\n{\n\tbt_dev_dbg(req->hdev, \"HCI_REQ-0x%4.4x\", opcode);\n\thci_req_add_ev(req, opcode, plen, param, 0);\n}\n\nstatic void start_interleave_scan(struct hci_dev *hdev)\n{\n\thdev->interleave_scan_state = INTERLEAVE_SCAN_NO_FILTER;\n\tqueue_delayed_work(hdev->req_workqueue,\n\t\t\t   &hdev->interleave_scan, 0);\n}\n\nstatic bool is_interleave_scanning(struct hci_dev *hdev)\n{\n\treturn hdev->interleave_scan_state != INTERLEAVE_SCAN_NONE;\n}\n\nstatic void cancel_interleave_scan(struct hci_dev *hdev)\n{\n\tbt_dev_dbg(hdev, \"cancelling interleave scan\");\n\n\tcancel_delayed_work_sync(&hdev->interleave_scan);\n\n\thdev->interleave_scan_state = INTERLEAVE_SCAN_NONE;\n}\n\n \nstatic bool __hci_update_interleaved_scan(struct hci_dev *hdev)\n{\n\t \n\tbool use_interleaving = hci_is_adv_monitoring(hdev) &&\n\t\t\t\t!(list_empty(&hdev->pend_le_conns) &&\n\t\t\t\t  list_empty(&hdev->pend_le_reports)) &&\n\t\t\t\thci_get_adv_monitor_offload_ext(hdev) ==\n\t\t\t\t    HCI_ADV_MONITOR_EXT_NONE;\n\tbool is_interleaving = is_interleave_scanning(hdev);\n\n\tif (use_interleaving && !is_interleaving) {\n\t\tstart_interleave_scan(hdev);\n\t\tbt_dev_dbg(hdev, \"starting interleave scan\");\n\t\treturn true;\n\t}\n\n\tif (!use_interleaving && is_interleaving)\n\t\tcancel_interleave_scan(hdev);\n\n\treturn false;\n}\n\nvoid hci_req_add_le_scan_disable(struct hci_request *req, bool rpa_le_conn)\n{\n\tstruct hci_dev *hdev = req->hdev;\n\n\tif (hdev->scanning_paused) {\n\t\tbt_dev_dbg(hdev, \"Scanning is paused for suspend\");\n\t\treturn;\n\t}\n\n\tif (use_ext_scan(hdev)) {\n\t\tstruct hci_cp_le_set_ext_scan_enable cp;\n\n\t\tmemset(&cp, 0, sizeof(cp));\n\t\tcp.enable = LE_SCAN_DISABLE;\n\t\thci_req_add(req, HCI_OP_LE_SET_EXT_SCAN_ENABLE, sizeof(cp),\n\t\t\t    &cp);\n\t} else {\n\t\tstruct hci_cp_le_set_scan_enable cp;\n\n\t\tmemset(&cp, 0, sizeof(cp));\n\t\tcp.enable = LE_SCAN_DISABLE;\n\t\thci_req_add(req, HCI_OP_LE_SET_SCAN_ENABLE, sizeof(cp), &cp);\n\t}\n\n\t \n\tif (hci_dev_test_flag(hdev, HCI_LL_RPA_RESOLUTION) && !rpa_le_conn) {\n\t\t__u8 enable = 0x00;\n\n\t\thci_req_add(req, HCI_OP_LE_SET_ADDR_RESOLV_ENABLE, 1, &enable);\n\t}\n}\n\nstatic void del_from_accept_list(struct hci_request *req, bdaddr_t *bdaddr,\n\t\t\t\t u8 bdaddr_type)\n{\n\tstruct hci_cp_le_del_from_accept_list cp;\n\n\tcp.bdaddr_type = bdaddr_type;\n\tbacpy(&cp.bdaddr, bdaddr);\n\n\tbt_dev_dbg(req->hdev, \"Remove %pMR (0x%x) from accept list\", &cp.bdaddr,\n\t\t   cp.bdaddr_type);\n\thci_req_add(req, HCI_OP_LE_DEL_FROM_ACCEPT_LIST, sizeof(cp), &cp);\n\n\tif (use_ll_privacy(req->hdev)) {\n\t\tstruct smp_irk *irk;\n\n\t\tirk = hci_find_irk_by_addr(req->hdev, bdaddr, bdaddr_type);\n\t\tif (irk) {\n\t\t\tstruct hci_cp_le_del_from_resolv_list cp;\n\n\t\t\tcp.bdaddr_type = bdaddr_type;\n\t\t\tbacpy(&cp.bdaddr, bdaddr);\n\n\t\t\thci_req_add(req, HCI_OP_LE_DEL_FROM_RESOLV_LIST,\n\t\t\t\t    sizeof(cp), &cp);\n\t\t}\n\t}\n}\n\n \nstatic int add_to_accept_list(struct hci_request *req,\n\t\t\t      struct hci_conn_params *params, u8 *num_entries,\n\t\t\t      bool allow_rpa)\n{\n\tstruct hci_cp_le_add_to_accept_list cp;\n\tstruct hci_dev *hdev = req->hdev;\n\n\t \n\tif (hci_bdaddr_list_lookup(&hdev->le_accept_list, &params->addr,\n\t\t\t\t   params->addr_type))\n\t\treturn 0;\n\n\t \n\tif (*num_entries >= hdev->le_accept_list_size)\n\t\treturn -1;\n\n\t \n\tif (!allow_rpa &&\n\t    !hci_dev_test_flag(hdev, HCI_ENABLE_LL_PRIVACY) &&\n\t    hci_find_irk_by_addr(hdev, &params->addr, params->addr_type)) {\n\t\treturn -1;\n\t}\n\n\t \n\tif (hdev->suspended &&\n\t    !(params->flags & HCI_CONN_FLAG_REMOTE_WAKEUP))\n\t\treturn 0;\n\n\t*num_entries += 1;\n\tcp.bdaddr_type = params->addr_type;\n\tbacpy(&cp.bdaddr, &params->addr);\n\n\tbt_dev_dbg(hdev, \"Add %pMR (0x%x) to accept list\", &cp.bdaddr,\n\t\t   cp.bdaddr_type);\n\thci_req_add(req, HCI_OP_LE_ADD_TO_ACCEPT_LIST, sizeof(cp), &cp);\n\n\tif (use_ll_privacy(hdev)) {\n\t\tstruct smp_irk *irk;\n\n\t\tirk = hci_find_irk_by_addr(hdev, &params->addr,\n\t\t\t\t\t   params->addr_type);\n\t\tif (irk) {\n\t\t\tstruct hci_cp_le_add_to_resolv_list cp;\n\n\t\t\tcp.bdaddr_type = params->addr_type;\n\t\t\tbacpy(&cp.bdaddr, &params->addr);\n\t\t\tmemcpy(cp.peer_irk, irk->val, 16);\n\n\t\t\tif (hci_dev_test_flag(hdev, HCI_PRIVACY))\n\t\t\t\tmemcpy(cp.local_irk, hdev->irk, 16);\n\t\t\telse\n\t\t\t\tmemset(cp.local_irk, 0, 16);\n\n\t\t\thci_req_add(req, HCI_OP_LE_ADD_TO_RESOLV_LIST,\n\t\t\t\t    sizeof(cp), &cp);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic u8 update_accept_list(struct hci_request *req)\n{\n\tstruct hci_dev *hdev = req->hdev;\n\tstruct hci_conn_params *params;\n\tstruct bdaddr_list *b;\n\tu8 num_entries = 0;\n\tbool pend_conn, pend_report;\n\t \n\tbool allow_rpa = hdev->suspended;\n\n\tif (use_ll_privacy(hdev))\n\t\tallow_rpa = true;\n\n\t \n\tlist_for_each_entry(b, &hdev->le_accept_list, list) {\n\t\tpend_conn = hci_pend_le_action_lookup(&hdev->pend_le_conns,\n\t\t\t\t\t\t      &b->bdaddr,\n\t\t\t\t\t\t      b->bdaddr_type);\n\t\tpend_report = hci_pend_le_action_lookup(&hdev->pend_le_reports,\n\t\t\t\t\t\t\t&b->bdaddr,\n\t\t\t\t\t\t\tb->bdaddr_type);\n\n\t\t \n\t\tif (!pend_conn && !pend_report) {\n\t\t\tdel_from_accept_list(req, &b->bdaddr, b->bdaddr_type);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (!allow_rpa &&\n\t\t    !hci_dev_test_flag(hdev, HCI_ENABLE_LL_PRIVACY) &&\n\t\t    hci_find_irk_by_addr(hdev, &b->bdaddr, b->bdaddr_type)) {\n\t\t\treturn 0x00;\n\t\t}\n\n\t\tnum_entries++;\n\t}\n\n\t \n\tlist_for_each_entry(params, &hdev->pend_le_conns, action) {\n\t\tif (add_to_accept_list(req, params, &num_entries, allow_rpa))\n\t\t\treturn 0x00;\n\t}\n\n\t \n\tlist_for_each_entry(params, &hdev->pend_le_reports, action) {\n\t\tif (add_to_accept_list(req, params, &num_entries, allow_rpa))\n\t\t\treturn 0x00;\n\t}\n\n\t \n\tif (!idr_is_empty(&hdev->adv_monitors_idr) && !hdev->suspended &&\n\t    hci_get_adv_monitor_offload_ext(hdev) == HCI_ADV_MONITOR_EXT_NONE &&\n\t    hdev->interleave_scan_state != INTERLEAVE_SCAN_ALLOWLIST)\n\t\treturn 0x00;\n\n\t \n\treturn 0x01;\n}\n\nstatic bool scan_use_rpa(struct hci_dev *hdev)\n{\n\treturn hci_dev_test_flag(hdev, HCI_PRIVACY);\n}\n\nstatic void hci_req_start_scan(struct hci_request *req, u8 type, u16 interval,\n\t\t\t       u16 window, u8 own_addr_type, u8 filter_policy,\n\t\t\t       bool filter_dup, bool addr_resolv)\n{\n\tstruct hci_dev *hdev = req->hdev;\n\n\tif (hdev->scanning_paused) {\n\t\tbt_dev_dbg(hdev, \"Scanning is paused for suspend\");\n\t\treturn;\n\t}\n\n\tif (use_ll_privacy(hdev) && addr_resolv) {\n\t\tu8 enable = 0x01;\n\n\t\thci_req_add(req, HCI_OP_LE_SET_ADDR_RESOLV_ENABLE, 1, &enable);\n\t}\n\n\t \n\tif (use_ext_scan(hdev)) {\n\t\tstruct hci_cp_le_set_ext_scan_params *ext_param_cp;\n\t\tstruct hci_cp_le_set_ext_scan_enable ext_enable_cp;\n\t\tstruct hci_cp_le_scan_phy_params *phy_params;\n\t\tu8 data[sizeof(*ext_param_cp) + sizeof(*phy_params) * 2];\n\t\tu32 plen;\n\n\t\text_param_cp = (void *)data;\n\t\tphy_params = (void *)ext_param_cp->data;\n\n\t\tmemset(ext_param_cp, 0, sizeof(*ext_param_cp));\n\t\text_param_cp->own_addr_type = own_addr_type;\n\t\text_param_cp->filter_policy = filter_policy;\n\n\t\tplen = sizeof(*ext_param_cp);\n\n\t\tif (scan_1m(hdev) || scan_2m(hdev)) {\n\t\t\text_param_cp->scanning_phys |= LE_SCAN_PHY_1M;\n\n\t\t\tmemset(phy_params, 0, sizeof(*phy_params));\n\t\t\tphy_params->type = type;\n\t\t\tphy_params->interval = cpu_to_le16(interval);\n\t\t\tphy_params->window = cpu_to_le16(window);\n\n\t\t\tplen += sizeof(*phy_params);\n\t\t\tphy_params++;\n\t\t}\n\n\t\tif (scan_coded(hdev)) {\n\t\t\text_param_cp->scanning_phys |= LE_SCAN_PHY_CODED;\n\n\t\t\tmemset(phy_params, 0, sizeof(*phy_params));\n\t\t\tphy_params->type = type;\n\t\t\tphy_params->interval = cpu_to_le16(interval);\n\t\t\tphy_params->window = cpu_to_le16(window);\n\n\t\t\tplen += sizeof(*phy_params);\n\t\t\tphy_params++;\n\t\t}\n\n\t\thci_req_add(req, HCI_OP_LE_SET_EXT_SCAN_PARAMS,\n\t\t\t    plen, ext_param_cp);\n\n\t\tmemset(&ext_enable_cp, 0, sizeof(ext_enable_cp));\n\t\text_enable_cp.enable = LE_SCAN_ENABLE;\n\t\text_enable_cp.filter_dup = filter_dup;\n\n\t\thci_req_add(req, HCI_OP_LE_SET_EXT_SCAN_ENABLE,\n\t\t\t    sizeof(ext_enable_cp), &ext_enable_cp);\n\t} else {\n\t\tstruct hci_cp_le_set_scan_param param_cp;\n\t\tstruct hci_cp_le_set_scan_enable enable_cp;\n\n\t\tmemset(&param_cp, 0, sizeof(param_cp));\n\t\tparam_cp.type = type;\n\t\tparam_cp.interval = cpu_to_le16(interval);\n\t\tparam_cp.window = cpu_to_le16(window);\n\t\tparam_cp.own_address_type = own_addr_type;\n\t\tparam_cp.filter_policy = filter_policy;\n\t\thci_req_add(req, HCI_OP_LE_SET_SCAN_PARAM, sizeof(param_cp),\n\t\t\t    &param_cp);\n\n\t\tmemset(&enable_cp, 0, sizeof(enable_cp));\n\t\tenable_cp.enable = LE_SCAN_ENABLE;\n\t\tenable_cp.filter_dup = filter_dup;\n\t\thci_req_add(req, HCI_OP_LE_SET_SCAN_ENABLE, sizeof(enable_cp),\n\t\t\t    &enable_cp);\n\t}\n}\n\nstatic void set_random_addr(struct hci_request *req, bdaddr_t *rpa);\nstatic int hci_update_random_address(struct hci_request *req,\n\t\t\t\t     bool require_privacy, bool use_rpa,\n\t\t\t\t     u8 *own_addr_type)\n{\n\tstruct hci_dev *hdev = req->hdev;\n\tint err;\n\n\t \n\tif (use_rpa) {\n\t\t \n\t\tif (use_ll_privacy(hdev))\n\t\t\t*own_addr_type = ADDR_LE_DEV_RANDOM_RESOLVED;\n\t\telse\n\t\t\t*own_addr_type = ADDR_LE_DEV_RANDOM;\n\n\t\tif (rpa_valid(hdev))\n\t\t\treturn 0;\n\n\t\terr = smp_generate_rpa(hdev, hdev->irk, &hdev->rpa);\n\t\tif (err < 0) {\n\t\t\tbt_dev_err(hdev, \"failed to generate new RPA\");\n\t\t\treturn err;\n\t\t}\n\n\t\tset_random_addr(req, &hdev->rpa);\n\n\t\treturn 0;\n\t}\n\n\t \n\tif (require_privacy) {\n\t\tbdaddr_t nrpa;\n\n\t\twhile (true) {\n\t\t\t \n\t\t\tget_random_bytes(&nrpa, 6);\n\t\t\tnrpa.b[5] &= 0x3f;\n\n\t\t\t \n\t\t\tif (bacmp(&hdev->bdaddr, &nrpa))\n\t\t\t\tbreak;\n\t\t}\n\n\t\t*own_addr_type = ADDR_LE_DEV_RANDOM;\n\t\tset_random_addr(req, &nrpa);\n\t\treturn 0;\n\t}\n\n\t \n\tif (hci_dev_test_flag(hdev, HCI_FORCE_STATIC_ADDR) ||\n\t    !bacmp(&hdev->bdaddr, BDADDR_ANY) ||\n\t    (!hci_dev_test_flag(hdev, HCI_BREDR_ENABLED) &&\n\t     bacmp(&hdev->static_addr, BDADDR_ANY))) {\n\t\t*own_addr_type = ADDR_LE_DEV_RANDOM;\n\t\tif (bacmp(&hdev->static_addr, &hdev->random_addr))\n\t\t\thci_req_add(req, HCI_OP_LE_SET_RANDOM_ADDR, 6,\n\t\t\t\t    &hdev->static_addr);\n\t\treturn 0;\n\t}\n\n\t \n\t*own_addr_type = ADDR_LE_DEV_PUBLIC;\n\n\treturn 0;\n}\n\n \nvoid hci_req_add_le_passive_scan(struct hci_request *req)\n{\n\tstruct hci_dev *hdev = req->hdev;\n\tu8 own_addr_type;\n\tu8 filter_policy;\n\tu16 window, interval;\n\t \n\tu8 filter_dup = LE_SCAN_FILTER_DUP_ENABLE;\n\t \n\tbool addr_resolv = true;\n\n\tif (hdev->scanning_paused) {\n\t\tbt_dev_dbg(hdev, \"Scanning is paused for suspend\");\n\t\treturn;\n\t}\n\n\t \n\tif (hci_update_random_address(req, false, scan_use_rpa(hdev),\n\t\t\t\t      &own_addr_type))\n\t\treturn;\n\n\tif (hdev->enable_advmon_interleave_scan &&\n\t    __hci_update_interleaved_scan(hdev))\n\t\treturn;\n\n\tbt_dev_dbg(hdev, \"interleave state %d\", hdev->interleave_scan_state);\n\t \n\tfilter_policy = update_accept_list(req);\n\n\t \n\tif (hci_dev_test_flag(hdev, HCI_PRIVACY) &&\n\t    (hdev->le_features[0] & HCI_LE_EXT_SCAN_POLICY))\n\t\tfilter_policy |= 0x02;\n\n\tif (hdev->suspended) {\n\t\twindow = hdev->le_scan_window_suspend;\n\t\tinterval = hdev->le_scan_int_suspend;\n\t} else if (hci_is_le_conn_scanning(hdev)) {\n\t\twindow = hdev->le_scan_window_connect;\n\t\tinterval = hdev->le_scan_int_connect;\n\t} else if (hci_is_adv_monitoring(hdev)) {\n\t\twindow = hdev->le_scan_window_adv_monitor;\n\t\tinterval = hdev->le_scan_int_adv_monitor;\n\n\t\t \n\t\tfilter_dup = LE_SCAN_FILTER_DUP_DISABLE;\n\t} else {\n\t\twindow = hdev->le_scan_window;\n\t\tinterval = hdev->le_scan_interval;\n\t}\n\n\tbt_dev_dbg(hdev, \"LE passive scan with accept list = %d\",\n\t\t   filter_policy);\n\thci_req_start_scan(req, LE_SCAN_PASSIVE, interval, window,\n\t\t\t   own_addr_type, filter_policy, filter_dup,\n\t\t\t   addr_resolv);\n}\n\nstatic int hci_req_add_le_interleaved_scan(struct hci_request *req,\n\t\t\t\t\t   unsigned long opt)\n{\n\tstruct hci_dev *hdev = req->hdev;\n\tint ret = 0;\n\n\thci_dev_lock(hdev);\n\n\tif (hci_dev_test_flag(hdev, HCI_LE_SCAN))\n\t\thci_req_add_le_scan_disable(req, false);\n\thci_req_add_le_passive_scan(req);\n\n\tswitch (hdev->interleave_scan_state) {\n\tcase INTERLEAVE_SCAN_ALLOWLIST:\n\t\tbt_dev_dbg(hdev, \"next state: allowlist\");\n\t\thdev->interleave_scan_state = INTERLEAVE_SCAN_NO_FILTER;\n\t\tbreak;\n\tcase INTERLEAVE_SCAN_NO_FILTER:\n\t\tbt_dev_dbg(hdev, \"next state: no filter\");\n\t\thdev->interleave_scan_state = INTERLEAVE_SCAN_ALLOWLIST;\n\t\tbreak;\n\tcase INTERLEAVE_SCAN_NONE:\n\t\tBT_ERR(\"unexpected error\");\n\t\tret = -1;\n\t}\n\n\thci_dev_unlock(hdev);\n\n\treturn ret;\n}\n\nstatic void interleave_scan_work(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev,\n\t\t\t\t\t    interleave_scan.work);\n\tu8 status;\n\tunsigned long timeout;\n\n\tif (hdev->interleave_scan_state == INTERLEAVE_SCAN_ALLOWLIST) {\n\t\ttimeout = msecs_to_jiffies(hdev->advmon_allowlist_duration);\n\t} else if (hdev->interleave_scan_state == INTERLEAVE_SCAN_NO_FILTER) {\n\t\ttimeout = msecs_to_jiffies(hdev->advmon_no_filter_duration);\n\t} else {\n\t\tbt_dev_err(hdev, \"unexpected error\");\n\t\treturn;\n\t}\n\n\thci_req_sync(hdev, hci_req_add_le_interleaved_scan, 0,\n\t\t     HCI_CMD_TIMEOUT, &status);\n\n\t \n\tif (is_interleave_scanning(hdev))\n\t\tqueue_delayed_work(hdev->req_workqueue,\n\t\t\t\t   &hdev->interleave_scan, timeout);\n}\n\nstatic void set_random_addr(struct hci_request *req, bdaddr_t *rpa)\n{\n\tstruct hci_dev *hdev = req->hdev;\n\n\t \n\tif (hci_dev_test_flag(hdev, HCI_LE_ADV) ||\n\t    hci_lookup_le_connect(hdev)) {\n\t\tbt_dev_dbg(hdev, \"Deferring random address update\");\n\t\thci_dev_set_flag(hdev, HCI_RPA_EXPIRED);\n\t\treturn;\n\t}\n\n\thci_req_add(req, HCI_OP_LE_SET_RANDOM_ADDR, 6, rpa);\n}\n\nvoid hci_request_setup(struct hci_dev *hdev)\n{\n\tINIT_DELAYED_WORK(&hdev->interleave_scan, interleave_scan_work);\n}\n\nvoid hci_request_cancel_all(struct hci_dev *hdev)\n{\n\t__hci_cmd_sync_cancel(hdev, ENODEV);\n\n\tcancel_interleave_scan(hdev);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}