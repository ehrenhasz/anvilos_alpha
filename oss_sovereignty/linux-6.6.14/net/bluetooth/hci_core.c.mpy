{
  "module_name": "hci_core.c",
  "hash_id": "35f53a9e2a0969ba94e8e3c94de15374385ccfb514552e90a0e9b280c592ab3c",
  "original_prompt": "Ingested from linux-6.6.14/net/bluetooth/hci_core.c",
  "human_readable_source": " \n\n \n\n#include <linux/export.h>\n#include <linux/rfkill.h>\n#include <linux/debugfs.h>\n#include <linux/crypto.h>\n#include <linux/kcov.h>\n#include <linux/property.h>\n#include <linux/suspend.h>\n#include <linux/wait.h>\n#include <asm/unaligned.h>\n\n#include <net/bluetooth/bluetooth.h>\n#include <net/bluetooth/hci_core.h>\n#include <net/bluetooth/l2cap.h>\n#include <net/bluetooth/mgmt.h>\n\n#include \"hci_request.h\"\n#include \"hci_debugfs.h\"\n#include \"smp.h\"\n#include \"leds.h\"\n#include \"msft.h\"\n#include \"aosp.h\"\n#include \"hci_codec.h\"\n\nstatic void hci_rx_work(struct work_struct *work);\nstatic void hci_cmd_work(struct work_struct *work);\nstatic void hci_tx_work(struct work_struct *work);\n\n \nLIST_HEAD(hci_dev_list);\nDEFINE_RWLOCK(hci_dev_list_lock);\n\n \nLIST_HEAD(hci_cb_list);\nDEFINE_MUTEX(hci_cb_list_lock);\n\n \nstatic DEFINE_IDA(hci_index_ida);\n\nstatic int hci_scan_req(struct hci_request *req, unsigned long opt)\n{\n\t__u8 scan = opt;\n\n\tBT_DBG(\"%s %x\", req->hdev->name, scan);\n\n\t \n\thci_req_add(req, HCI_OP_WRITE_SCAN_ENABLE, 1, &scan);\n\treturn 0;\n}\n\nstatic int hci_auth_req(struct hci_request *req, unsigned long opt)\n{\n\t__u8 auth = opt;\n\n\tBT_DBG(\"%s %x\", req->hdev->name, auth);\n\n\t \n\thci_req_add(req, HCI_OP_WRITE_AUTH_ENABLE, 1, &auth);\n\treturn 0;\n}\n\nstatic int hci_encrypt_req(struct hci_request *req, unsigned long opt)\n{\n\t__u8 encrypt = opt;\n\n\tBT_DBG(\"%s %x\", req->hdev->name, encrypt);\n\n\t \n\thci_req_add(req, HCI_OP_WRITE_ENCRYPT_MODE, 1, &encrypt);\n\treturn 0;\n}\n\nstatic int hci_linkpol_req(struct hci_request *req, unsigned long opt)\n{\n\t__le16 policy = cpu_to_le16(opt);\n\n\tBT_DBG(\"%s %x\", req->hdev->name, policy);\n\n\t \n\thci_req_add(req, HCI_OP_WRITE_DEF_LINK_POLICY, 2, &policy);\n\treturn 0;\n}\n\n \nstruct hci_dev *hci_dev_get(int index)\n{\n\tstruct hci_dev *hdev = NULL, *d;\n\n\tBT_DBG(\"%d\", index);\n\n\tif (index < 0)\n\t\treturn NULL;\n\n\tread_lock(&hci_dev_list_lock);\n\tlist_for_each_entry(d, &hci_dev_list, list) {\n\t\tif (d->id == index) {\n\t\t\thdev = hci_dev_hold(d);\n\t\t\tbreak;\n\t\t}\n\t}\n\tread_unlock(&hci_dev_list_lock);\n\treturn hdev;\n}\n\n \n\nbool hci_discovery_active(struct hci_dev *hdev)\n{\n\tstruct discovery_state *discov = &hdev->discovery;\n\n\tswitch (discov->state) {\n\tcase DISCOVERY_FINDING:\n\tcase DISCOVERY_RESOLVING:\n\t\treturn true;\n\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nvoid hci_discovery_set_state(struct hci_dev *hdev, int state)\n{\n\tint old_state = hdev->discovery.state;\n\n\tBT_DBG(\"%s state %u -> %u\", hdev->name, hdev->discovery.state, state);\n\n\tif (old_state == state)\n\t\treturn;\n\n\thdev->discovery.state = state;\n\n\tswitch (state) {\n\tcase DISCOVERY_STOPPED:\n\t\thci_update_passive_scan(hdev);\n\n\t\tif (old_state != DISCOVERY_STARTING)\n\t\t\tmgmt_discovering(hdev, 0);\n\t\tbreak;\n\tcase DISCOVERY_STARTING:\n\t\tbreak;\n\tcase DISCOVERY_FINDING:\n\t\tmgmt_discovering(hdev, 1);\n\t\tbreak;\n\tcase DISCOVERY_RESOLVING:\n\t\tbreak;\n\tcase DISCOVERY_STOPPING:\n\t\tbreak;\n\t}\n}\n\nvoid hci_inquiry_cache_flush(struct hci_dev *hdev)\n{\n\tstruct discovery_state *cache = &hdev->discovery;\n\tstruct inquiry_entry *p, *n;\n\n\tlist_for_each_entry_safe(p, n, &cache->all, all) {\n\t\tlist_del(&p->all);\n\t\tkfree(p);\n\t}\n\n\tINIT_LIST_HEAD(&cache->unknown);\n\tINIT_LIST_HEAD(&cache->resolve);\n}\n\nstruct inquiry_entry *hci_inquiry_cache_lookup(struct hci_dev *hdev,\n\t\t\t\t\t       bdaddr_t *bdaddr)\n{\n\tstruct discovery_state *cache = &hdev->discovery;\n\tstruct inquiry_entry *e;\n\n\tBT_DBG(\"cache %p, %pMR\", cache, bdaddr);\n\n\tlist_for_each_entry(e, &cache->all, all) {\n\t\tif (!bacmp(&e->data.bdaddr, bdaddr))\n\t\t\treturn e;\n\t}\n\n\treturn NULL;\n}\n\nstruct inquiry_entry *hci_inquiry_cache_lookup_unknown(struct hci_dev *hdev,\n\t\t\t\t\t\t       bdaddr_t *bdaddr)\n{\n\tstruct discovery_state *cache = &hdev->discovery;\n\tstruct inquiry_entry *e;\n\n\tBT_DBG(\"cache %p, %pMR\", cache, bdaddr);\n\n\tlist_for_each_entry(e, &cache->unknown, list) {\n\t\tif (!bacmp(&e->data.bdaddr, bdaddr))\n\t\t\treturn e;\n\t}\n\n\treturn NULL;\n}\n\nstruct inquiry_entry *hci_inquiry_cache_lookup_resolve(struct hci_dev *hdev,\n\t\t\t\t\t\t       bdaddr_t *bdaddr,\n\t\t\t\t\t\t       int state)\n{\n\tstruct discovery_state *cache = &hdev->discovery;\n\tstruct inquiry_entry *e;\n\n\tBT_DBG(\"cache %p bdaddr %pMR state %d\", cache, bdaddr, state);\n\n\tlist_for_each_entry(e, &cache->resolve, list) {\n\t\tif (!bacmp(bdaddr, BDADDR_ANY) && e->name_state == state)\n\t\t\treturn e;\n\t\tif (!bacmp(&e->data.bdaddr, bdaddr))\n\t\t\treturn e;\n\t}\n\n\treturn NULL;\n}\n\nvoid hci_inquiry_cache_update_resolve(struct hci_dev *hdev,\n\t\t\t\t      struct inquiry_entry *ie)\n{\n\tstruct discovery_state *cache = &hdev->discovery;\n\tstruct list_head *pos = &cache->resolve;\n\tstruct inquiry_entry *p;\n\n\tlist_del(&ie->list);\n\n\tlist_for_each_entry(p, &cache->resolve, list) {\n\t\tif (p->name_state != NAME_PENDING &&\n\t\t    abs(p->data.rssi) >= abs(ie->data.rssi))\n\t\t\tbreak;\n\t\tpos = &p->list;\n\t}\n\n\tlist_add(&ie->list, pos);\n}\n\nu32 hci_inquiry_cache_update(struct hci_dev *hdev, struct inquiry_data *data,\n\t\t\t     bool name_known)\n{\n\tstruct discovery_state *cache = &hdev->discovery;\n\tstruct inquiry_entry *ie;\n\tu32 flags = 0;\n\n\tBT_DBG(\"cache %p, %pMR\", cache, &data->bdaddr);\n\n\thci_remove_remote_oob_data(hdev, &data->bdaddr, BDADDR_BREDR);\n\n\tif (!data->ssp_mode)\n\t\tflags |= MGMT_DEV_FOUND_LEGACY_PAIRING;\n\n\tie = hci_inquiry_cache_lookup(hdev, &data->bdaddr);\n\tif (ie) {\n\t\tif (!ie->data.ssp_mode)\n\t\t\tflags |= MGMT_DEV_FOUND_LEGACY_PAIRING;\n\n\t\tif (ie->name_state == NAME_NEEDED &&\n\t\t    data->rssi != ie->data.rssi) {\n\t\t\tie->data.rssi = data->rssi;\n\t\t\thci_inquiry_cache_update_resolve(hdev, ie);\n\t\t}\n\n\t\tgoto update;\n\t}\n\n\t \n\tie = kzalloc(sizeof(*ie), GFP_KERNEL);\n\tif (!ie) {\n\t\tflags |= MGMT_DEV_FOUND_CONFIRM_NAME;\n\t\tgoto done;\n\t}\n\n\tlist_add(&ie->all, &cache->all);\n\n\tif (name_known) {\n\t\tie->name_state = NAME_KNOWN;\n\t} else {\n\t\tie->name_state = NAME_NOT_KNOWN;\n\t\tlist_add(&ie->list, &cache->unknown);\n\t}\n\nupdate:\n\tif (name_known && ie->name_state != NAME_KNOWN &&\n\t    ie->name_state != NAME_PENDING) {\n\t\tie->name_state = NAME_KNOWN;\n\t\tlist_del(&ie->list);\n\t}\n\n\tmemcpy(&ie->data, data, sizeof(*data));\n\tie->timestamp = jiffies;\n\tcache->timestamp = jiffies;\n\n\tif (ie->name_state == NAME_NOT_KNOWN)\n\t\tflags |= MGMT_DEV_FOUND_CONFIRM_NAME;\n\ndone:\n\treturn flags;\n}\n\nstatic int inquiry_cache_dump(struct hci_dev *hdev, int num, __u8 *buf)\n{\n\tstruct discovery_state *cache = &hdev->discovery;\n\tstruct inquiry_info *info = (struct inquiry_info *) buf;\n\tstruct inquiry_entry *e;\n\tint copied = 0;\n\n\tlist_for_each_entry(e, &cache->all, all) {\n\t\tstruct inquiry_data *data = &e->data;\n\n\t\tif (copied >= num)\n\t\t\tbreak;\n\n\t\tbacpy(&info->bdaddr, &data->bdaddr);\n\t\tinfo->pscan_rep_mode\t= data->pscan_rep_mode;\n\t\tinfo->pscan_period_mode\t= data->pscan_period_mode;\n\t\tinfo->pscan_mode\t= data->pscan_mode;\n\t\tmemcpy(info->dev_class, data->dev_class, 3);\n\t\tinfo->clock_offset\t= data->clock_offset;\n\n\t\tinfo++;\n\t\tcopied++;\n\t}\n\n\tBT_DBG(\"cache %p, copied %d\", cache, copied);\n\treturn copied;\n}\n\nstatic int hci_inq_req(struct hci_request *req, unsigned long opt)\n{\n\tstruct hci_inquiry_req *ir = (struct hci_inquiry_req *) opt;\n\tstruct hci_dev *hdev = req->hdev;\n\tstruct hci_cp_inquiry cp;\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\tif (test_bit(HCI_INQUIRY, &hdev->flags))\n\t\treturn 0;\n\n\t \n\tmemcpy(&cp.lap, &ir->lap, 3);\n\tcp.length  = ir->length;\n\tcp.num_rsp = ir->num_rsp;\n\thci_req_add(req, HCI_OP_INQUIRY, sizeof(cp), &cp);\n\n\treturn 0;\n}\n\nint hci_inquiry(void __user *arg)\n{\n\t__u8 __user *ptr = arg;\n\tstruct hci_inquiry_req ir;\n\tstruct hci_dev *hdev;\n\tint err = 0, do_inquiry = 0, max_rsp;\n\tlong timeo;\n\t__u8 *buf;\n\n\tif (copy_from_user(&ir, ptr, sizeof(ir)))\n\t\treturn -EFAULT;\n\n\thdev = hci_dev_get(ir.dev_id);\n\tif (!hdev)\n\t\treturn -ENODEV;\n\n\tif (hci_dev_test_flag(hdev, HCI_USER_CHANNEL)) {\n\t\terr = -EBUSY;\n\t\tgoto done;\n\t}\n\n\tif (hci_dev_test_flag(hdev, HCI_UNCONFIGURED)) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto done;\n\t}\n\n\tif (hdev->dev_type != HCI_PRIMARY) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto done;\n\t}\n\n\tif (!hci_dev_test_flag(hdev, HCI_BREDR_ENABLED)) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto done;\n\t}\n\n\t \n\tif (ir.length > 60) {\n\t\terr = -EINVAL;\n\t\tgoto done;\n\t}\n\n\thci_dev_lock(hdev);\n\tif (inquiry_cache_age(hdev) > INQUIRY_CACHE_AGE_MAX ||\n\t    inquiry_cache_empty(hdev) || ir.flags & IREQ_CACHE_FLUSH) {\n\t\thci_inquiry_cache_flush(hdev);\n\t\tdo_inquiry = 1;\n\t}\n\thci_dev_unlock(hdev);\n\n\ttimeo = ir.length * msecs_to_jiffies(2000);\n\n\tif (do_inquiry) {\n\t\terr = hci_req_sync(hdev, hci_inq_req, (unsigned long) &ir,\n\t\t\t\t   timeo, NULL);\n\t\tif (err < 0)\n\t\t\tgoto done;\n\n\t\t \n\t\tif (wait_on_bit(&hdev->flags, HCI_INQUIRY,\n\t\t\t\tTASK_INTERRUPTIBLE)) {\n\t\t\terr = -EINTR;\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t \n\tmax_rsp = (ir.num_rsp == 0) ? 255 : ir.num_rsp;\n\n\t \n\tbuf = kmalloc_array(max_rsp, sizeof(struct inquiry_info), GFP_KERNEL);\n\tif (!buf) {\n\t\terr = -ENOMEM;\n\t\tgoto done;\n\t}\n\n\thci_dev_lock(hdev);\n\tir.num_rsp = inquiry_cache_dump(hdev, max_rsp, buf);\n\thci_dev_unlock(hdev);\n\n\tBT_DBG(\"num_rsp %d\", ir.num_rsp);\n\n\tif (!copy_to_user(ptr, &ir, sizeof(ir))) {\n\t\tptr += sizeof(ir);\n\t\tif (copy_to_user(ptr, buf, sizeof(struct inquiry_info) *\n\t\t\t\t ir.num_rsp))\n\t\t\terr = -EFAULT;\n\t} else\n\t\terr = -EFAULT;\n\n\tkfree(buf);\n\ndone:\n\thci_dev_put(hdev);\n\treturn err;\n}\n\nstatic int hci_dev_do_open(struct hci_dev *hdev)\n{\n\tint ret = 0;\n\n\tBT_DBG(\"%s %p\", hdev->name, hdev);\n\n\thci_req_sync_lock(hdev);\n\n\tret = hci_dev_open_sync(hdev);\n\n\thci_req_sync_unlock(hdev);\n\treturn ret;\n}\n\n \n\nint hci_dev_open(__u16 dev)\n{\n\tstruct hci_dev *hdev;\n\tint err;\n\n\thdev = hci_dev_get(dev);\n\tif (!hdev)\n\t\treturn -ENODEV;\n\n\t \n\tif (hci_dev_test_flag(hdev, HCI_UNCONFIGURED) &&\n\t    !hci_dev_test_flag(hdev, HCI_USER_CHANNEL)) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto done;\n\t}\n\n\t \n\tif (hci_dev_test_and_clear_flag(hdev, HCI_AUTO_OFF))\n\t\tcancel_delayed_work(&hdev->power_off);\n\n\t \n\tflush_workqueue(hdev->req_workqueue);\n\n\t \n\tif (!hci_dev_test_flag(hdev, HCI_USER_CHANNEL) &&\n\t    !hci_dev_test_flag(hdev, HCI_MGMT))\n\t\thci_dev_set_flag(hdev, HCI_BONDABLE);\n\n\terr = hci_dev_do_open(hdev);\n\ndone:\n\thci_dev_put(hdev);\n\treturn err;\n}\n\nint hci_dev_do_close(struct hci_dev *hdev)\n{\n\tint err;\n\n\tBT_DBG(\"%s %p\", hdev->name, hdev);\n\n\thci_req_sync_lock(hdev);\n\n\terr = hci_dev_close_sync(hdev);\n\n\thci_req_sync_unlock(hdev);\n\n\treturn err;\n}\n\nint hci_dev_close(__u16 dev)\n{\n\tstruct hci_dev *hdev;\n\tint err;\n\n\thdev = hci_dev_get(dev);\n\tif (!hdev)\n\t\treturn -ENODEV;\n\n\tif (hci_dev_test_flag(hdev, HCI_USER_CHANNEL)) {\n\t\terr = -EBUSY;\n\t\tgoto done;\n\t}\n\n\tcancel_work_sync(&hdev->power_on);\n\tif (hci_dev_test_and_clear_flag(hdev, HCI_AUTO_OFF))\n\t\tcancel_delayed_work(&hdev->power_off);\n\n\terr = hci_dev_do_close(hdev);\n\ndone:\n\thci_dev_put(hdev);\n\treturn err;\n}\n\nstatic int hci_dev_do_reset(struct hci_dev *hdev)\n{\n\tint ret;\n\n\tBT_DBG(\"%s %p\", hdev->name, hdev);\n\n\thci_req_sync_lock(hdev);\n\n\t \n\tskb_queue_purge(&hdev->rx_q);\n\tskb_queue_purge(&hdev->cmd_q);\n\n\t \n\thci_dev_set_flag(hdev, HCI_CMD_DRAIN_WORKQUEUE);\n\t \n\tsynchronize_rcu();\n\t \n\tcancel_delayed_work(&hdev->cmd_timer);\n\tcancel_delayed_work(&hdev->ncmd_timer);\n\n\t \n\tdrain_workqueue(hdev->workqueue);\n\n\thci_dev_lock(hdev);\n\thci_inquiry_cache_flush(hdev);\n\thci_conn_hash_flush(hdev);\n\thci_dev_unlock(hdev);\n\n\tif (hdev->flush)\n\t\thdev->flush(hdev);\n\n\thci_dev_clear_flag(hdev, HCI_CMD_DRAIN_WORKQUEUE);\n\n\tatomic_set(&hdev->cmd_cnt, 1);\n\thdev->acl_cnt = 0;\n\thdev->sco_cnt = 0;\n\thdev->le_cnt = 0;\n\thdev->iso_cnt = 0;\n\n\tret = hci_reset_sync(hdev);\n\n\thci_req_sync_unlock(hdev);\n\treturn ret;\n}\n\nint hci_dev_reset(__u16 dev)\n{\n\tstruct hci_dev *hdev;\n\tint err;\n\n\thdev = hci_dev_get(dev);\n\tif (!hdev)\n\t\treturn -ENODEV;\n\n\tif (!test_bit(HCI_UP, &hdev->flags)) {\n\t\terr = -ENETDOWN;\n\t\tgoto done;\n\t}\n\n\tif (hci_dev_test_flag(hdev, HCI_USER_CHANNEL)) {\n\t\terr = -EBUSY;\n\t\tgoto done;\n\t}\n\n\tif (hci_dev_test_flag(hdev, HCI_UNCONFIGURED)) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto done;\n\t}\n\n\terr = hci_dev_do_reset(hdev);\n\ndone:\n\thci_dev_put(hdev);\n\treturn err;\n}\n\nint hci_dev_reset_stat(__u16 dev)\n{\n\tstruct hci_dev *hdev;\n\tint ret = 0;\n\n\thdev = hci_dev_get(dev);\n\tif (!hdev)\n\t\treturn -ENODEV;\n\n\tif (hci_dev_test_flag(hdev, HCI_USER_CHANNEL)) {\n\t\tret = -EBUSY;\n\t\tgoto done;\n\t}\n\n\tif (hci_dev_test_flag(hdev, HCI_UNCONFIGURED)) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto done;\n\t}\n\n\tmemset(&hdev->stat, 0, sizeof(struct hci_dev_stats));\n\ndone:\n\thci_dev_put(hdev);\n\treturn ret;\n}\n\nstatic void hci_update_passive_scan_state(struct hci_dev *hdev, u8 scan)\n{\n\tbool conn_changed, discov_changed;\n\n\tBT_DBG(\"%s scan 0x%02x\", hdev->name, scan);\n\n\tif ((scan & SCAN_PAGE))\n\t\tconn_changed = !hci_dev_test_and_set_flag(hdev,\n\t\t\t\t\t\t\t  HCI_CONNECTABLE);\n\telse\n\t\tconn_changed = hci_dev_test_and_clear_flag(hdev,\n\t\t\t\t\t\t\t   HCI_CONNECTABLE);\n\n\tif ((scan & SCAN_INQUIRY)) {\n\t\tdiscov_changed = !hci_dev_test_and_set_flag(hdev,\n\t\t\t\t\t\t\t    HCI_DISCOVERABLE);\n\t} else {\n\t\thci_dev_clear_flag(hdev, HCI_LIMITED_DISCOVERABLE);\n\t\tdiscov_changed = hci_dev_test_and_clear_flag(hdev,\n\t\t\t\t\t\t\t     HCI_DISCOVERABLE);\n\t}\n\n\tif (!hci_dev_test_flag(hdev, HCI_MGMT))\n\t\treturn;\n\n\tif (conn_changed || discov_changed) {\n\t\t \n\t\thci_dev_set_flag(hdev, HCI_BREDR_ENABLED);\n\n\t\tif (hci_dev_test_flag(hdev, HCI_LE_ENABLED))\n\t\t\thci_update_adv_data(hdev, hdev->cur_adv_instance);\n\n\t\tmgmt_new_settings(hdev);\n\t}\n}\n\nint hci_dev_cmd(unsigned int cmd, void __user *arg)\n{\n\tstruct hci_dev *hdev;\n\tstruct hci_dev_req dr;\n\tint err = 0;\n\n\tif (copy_from_user(&dr, arg, sizeof(dr)))\n\t\treturn -EFAULT;\n\n\thdev = hci_dev_get(dr.dev_id);\n\tif (!hdev)\n\t\treturn -ENODEV;\n\n\tif (hci_dev_test_flag(hdev, HCI_USER_CHANNEL)) {\n\t\terr = -EBUSY;\n\t\tgoto done;\n\t}\n\n\tif (hci_dev_test_flag(hdev, HCI_UNCONFIGURED)) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto done;\n\t}\n\n\tif (hdev->dev_type != HCI_PRIMARY) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto done;\n\t}\n\n\tif (!hci_dev_test_flag(hdev, HCI_BREDR_ENABLED)) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto done;\n\t}\n\n\tswitch (cmd) {\n\tcase HCISETAUTH:\n\t\terr = hci_req_sync(hdev, hci_auth_req, dr.dev_opt,\n\t\t\t\t   HCI_INIT_TIMEOUT, NULL);\n\t\tbreak;\n\n\tcase HCISETENCRYPT:\n\t\tif (!lmp_encrypt_capable(hdev)) {\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!test_bit(HCI_AUTH, &hdev->flags)) {\n\t\t\t \n\t\t\terr = hci_req_sync(hdev, hci_auth_req, dr.dev_opt,\n\t\t\t\t\t   HCI_INIT_TIMEOUT, NULL);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\n\t\terr = hci_req_sync(hdev, hci_encrypt_req, dr.dev_opt,\n\t\t\t\t   HCI_INIT_TIMEOUT, NULL);\n\t\tbreak;\n\n\tcase HCISETSCAN:\n\t\terr = hci_req_sync(hdev, hci_scan_req, dr.dev_opt,\n\t\t\t\t   HCI_INIT_TIMEOUT, NULL);\n\n\t\t \n\t\tif (!err)\n\t\t\thci_update_passive_scan_state(hdev, dr.dev_opt);\n\t\tbreak;\n\n\tcase HCISETLINKPOL:\n\t\terr = hci_req_sync(hdev, hci_linkpol_req, dr.dev_opt,\n\t\t\t\t   HCI_INIT_TIMEOUT, NULL);\n\t\tbreak;\n\n\tcase HCISETLINKMODE:\n\t\thdev->link_mode = ((__u16) dr.dev_opt) &\n\t\t\t\t\t(HCI_LM_MASTER | HCI_LM_ACCEPT);\n\t\tbreak;\n\n\tcase HCISETPTYPE:\n\t\tif (hdev->pkt_type == (__u16) dr.dev_opt)\n\t\t\tbreak;\n\n\t\thdev->pkt_type = (__u16) dr.dev_opt;\n\t\tmgmt_phy_configuration_changed(hdev, NULL);\n\t\tbreak;\n\n\tcase HCISETACLMTU:\n\t\thdev->acl_mtu  = *((__u16 *) &dr.dev_opt + 1);\n\t\thdev->acl_pkts = *((__u16 *) &dr.dev_opt + 0);\n\t\tbreak;\n\n\tcase HCISETSCOMTU:\n\t\thdev->sco_mtu  = *((__u16 *) &dr.dev_opt + 1);\n\t\thdev->sco_pkts = *((__u16 *) &dr.dev_opt + 0);\n\t\tbreak;\n\n\tdefault:\n\t\terr = -EINVAL;\n\t\tbreak;\n\t}\n\ndone:\n\thci_dev_put(hdev);\n\treturn err;\n}\n\nint hci_get_dev_list(void __user *arg)\n{\n\tstruct hci_dev *hdev;\n\tstruct hci_dev_list_req *dl;\n\tstruct hci_dev_req *dr;\n\tint n = 0, size, err;\n\t__u16 dev_num;\n\n\tif (get_user(dev_num, (__u16 __user *) arg))\n\t\treturn -EFAULT;\n\n\tif (!dev_num || dev_num > (PAGE_SIZE * 2) / sizeof(*dr))\n\t\treturn -EINVAL;\n\n\tsize = sizeof(*dl) + dev_num * sizeof(*dr);\n\n\tdl = kzalloc(size, GFP_KERNEL);\n\tif (!dl)\n\t\treturn -ENOMEM;\n\n\tdr = dl->dev_req;\n\n\tread_lock(&hci_dev_list_lock);\n\tlist_for_each_entry(hdev, &hci_dev_list, list) {\n\t\tunsigned long flags = hdev->flags;\n\n\t\t \n\t\tif (hci_dev_test_flag(hdev, HCI_AUTO_OFF))\n\t\t\tflags &= ~BIT(HCI_UP);\n\n\t\t(dr + n)->dev_id  = hdev->id;\n\t\t(dr + n)->dev_opt = flags;\n\n\t\tif (++n >= dev_num)\n\t\t\tbreak;\n\t}\n\tread_unlock(&hci_dev_list_lock);\n\n\tdl->dev_num = n;\n\tsize = sizeof(*dl) + n * sizeof(*dr);\n\n\terr = copy_to_user(arg, dl, size);\n\tkfree(dl);\n\n\treturn err ? -EFAULT : 0;\n}\n\nint hci_get_dev_info(void __user *arg)\n{\n\tstruct hci_dev *hdev;\n\tstruct hci_dev_info di;\n\tunsigned long flags;\n\tint err = 0;\n\n\tif (copy_from_user(&di, arg, sizeof(di)))\n\t\treturn -EFAULT;\n\n\thdev = hci_dev_get(di.dev_id);\n\tif (!hdev)\n\t\treturn -ENODEV;\n\n\t \n\tif (hci_dev_test_flag(hdev, HCI_AUTO_OFF))\n\t\tflags = hdev->flags & ~BIT(HCI_UP);\n\telse\n\t\tflags = hdev->flags;\n\n\tstrcpy(di.name, hdev->name);\n\tdi.bdaddr   = hdev->bdaddr;\n\tdi.type     = (hdev->bus & 0x0f) | ((hdev->dev_type & 0x03) << 4);\n\tdi.flags    = flags;\n\tdi.pkt_type = hdev->pkt_type;\n\tif (lmp_bredr_capable(hdev)) {\n\t\tdi.acl_mtu  = hdev->acl_mtu;\n\t\tdi.acl_pkts = hdev->acl_pkts;\n\t\tdi.sco_mtu  = hdev->sco_mtu;\n\t\tdi.sco_pkts = hdev->sco_pkts;\n\t} else {\n\t\tdi.acl_mtu  = hdev->le_mtu;\n\t\tdi.acl_pkts = hdev->le_pkts;\n\t\tdi.sco_mtu  = 0;\n\t\tdi.sco_pkts = 0;\n\t}\n\tdi.link_policy = hdev->link_policy;\n\tdi.link_mode   = hdev->link_mode;\n\n\tmemcpy(&di.stat, &hdev->stat, sizeof(di.stat));\n\tmemcpy(&di.features, &hdev->features, sizeof(di.features));\n\n\tif (copy_to_user(arg, &di, sizeof(di)))\n\t\terr = -EFAULT;\n\n\thci_dev_put(hdev);\n\n\treturn err;\n}\n\n \n\nstatic int hci_rfkill_set_block(void *data, bool blocked)\n{\n\tstruct hci_dev *hdev = data;\n\n\tBT_DBG(\"%p name %s blocked %d\", hdev, hdev->name, blocked);\n\n\tif (hci_dev_test_flag(hdev, HCI_USER_CHANNEL))\n\t\treturn -EBUSY;\n\n\tif (blocked) {\n\t\thci_dev_set_flag(hdev, HCI_RFKILLED);\n\t\tif (!hci_dev_test_flag(hdev, HCI_SETUP) &&\n\t\t    !hci_dev_test_flag(hdev, HCI_CONFIG))\n\t\t\thci_dev_do_close(hdev);\n\t} else {\n\t\thci_dev_clear_flag(hdev, HCI_RFKILLED);\n\t}\n\n\treturn 0;\n}\n\nstatic const struct rfkill_ops hci_rfkill_ops = {\n\t.set_block = hci_rfkill_set_block,\n};\n\nstatic void hci_power_on(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev, power_on);\n\tint err;\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\tif (test_bit(HCI_UP, &hdev->flags) &&\n\t    hci_dev_test_flag(hdev, HCI_MGMT) &&\n\t    hci_dev_test_and_clear_flag(hdev, HCI_AUTO_OFF)) {\n\t\tcancel_delayed_work(&hdev->power_off);\n\t\terr = hci_powered_update_sync(hdev);\n\t\tmgmt_power_on(hdev, err);\n\t\treturn;\n\t}\n\n\terr = hci_dev_do_open(hdev);\n\tif (err < 0) {\n\t\thci_dev_lock(hdev);\n\t\tmgmt_set_powered_failed(hdev, err);\n\t\thci_dev_unlock(hdev);\n\t\treturn;\n\t}\n\n\t \n\tif (hci_dev_test_flag(hdev, HCI_RFKILLED) ||\n\t    hci_dev_test_flag(hdev, HCI_UNCONFIGURED) ||\n\t    (hdev->dev_type == HCI_PRIMARY &&\n\t     !bacmp(&hdev->bdaddr, BDADDR_ANY) &&\n\t     !bacmp(&hdev->static_addr, BDADDR_ANY))) {\n\t\thci_dev_clear_flag(hdev, HCI_AUTO_OFF);\n\t\thci_dev_do_close(hdev);\n\t} else if (hci_dev_test_flag(hdev, HCI_AUTO_OFF)) {\n\t\tqueue_delayed_work(hdev->req_workqueue, &hdev->power_off,\n\t\t\t\t   HCI_AUTO_OFF_TIMEOUT);\n\t}\n\n\tif (hci_dev_test_and_clear_flag(hdev, HCI_SETUP)) {\n\t\t \n\t\tif (hci_dev_test_flag(hdev, HCI_UNCONFIGURED))\n\t\t\tset_bit(HCI_RAW, &hdev->flags);\n\n\t\t \n\t\tmgmt_index_added(hdev);\n\t} else if (hci_dev_test_and_clear_flag(hdev, HCI_CONFIG)) {\n\t\t \n\t\tif (!hci_dev_test_flag(hdev, HCI_UNCONFIGURED))\n\t\t\tclear_bit(HCI_RAW, &hdev->flags);\n\n\t\t \n\t\tmgmt_index_added(hdev);\n\t}\n}\n\nstatic void hci_power_off(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev,\n\t\t\t\t\t    power_off.work);\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\thci_dev_do_close(hdev);\n}\n\nstatic void hci_error_reset(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev, error_reset);\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\tif (hdev->hw_error)\n\t\thdev->hw_error(hdev, hdev->hw_error_code);\n\telse\n\t\tbt_dev_err(hdev, \"hardware error 0x%2.2x\", hdev->hw_error_code);\n\n\tif (hci_dev_do_close(hdev))\n\t\treturn;\n\n\thci_dev_do_open(hdev);\n}\n\nvoid hci_uuids_clear(struct hci_dev *hdev)\n{\n\tstruct bt_uuid *uuid, *tmp;\n\n\tlist_for_each_entry_safe(uuid, tmp, &hdev->uuids, list) {\n\t\tlist_del(&uuid->list);\n\t\tkfree(uuid);\n\t}\n}\n\nvoid hci_link_keys_clear(struct hci_dev *hdev)\n{\n\tstruct link_key *key, *tmp;\n\n\tlist_for_each_entry_safe(key, tmp, &hdev->link_keys, list) {\n\t\tlist_del_rcu(&key->list);\n\t\tkfree_rcu(key, rcu);\n\t}\n}\n\nvoid hci_smp_ltks_clear(struct hci_dev *hdev)\n{\n\tstruct smp_ltk *k, *tmp;\n\n\tlist_for_each_entry_safe(k, tmp, &hdev->long_term_keys, list) {\n\t\tlist_del_rcu(&k->list);\n\t\tkfree_rcu(k, rcu);\n\t}\n}\n\nvoid hci_smp_irks_clear(struct hci_dev *hdev)\n{\n\tstruct smp_irk *k, *tmp;\n\n\tlist_for_each_entry_safe(k, tmp, &hdev->identity_resolving_keys, list) {\n\t\tlist_del_rcu(&k->list);\n\t\tkfree_rcu(k, rcu);\n\t}\n}\n\nvoid hci_blocked_keys_clear(struct hci_dev *hdev)\n{\n\tstruct blocked_key *b, *tmp;\n\n\tlist_for_each_entry_safe(b, tmp, &hdev->blocked_keys, list) {\n\t\tlist_del_rcu(&b->list);\n\t\tkfree_rcu(b, rcu);\n\t}\n}\n\nbool hci_is_blocked_key(struct hci_dev *hdev, u8 type, u8 val[16])\n{\n\tbool blocked = false;\n\tstruct blocked_key *b;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(b, &hdev->blocked_keys, list) {\n\t\tif (b->type == type && !memcmp(b->val, val, sizeof(b->val))) {\n\t\t\tblocked = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\trcu_read_unlock();\n\treturn blocked;\n}\n\nstruct link_key *hci_find_link_key(struct hci_dev *hdev, bdaddr_t *bdaddr)\n{\n\tstruct link_key *k;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(k, &hdev->link_keys, list) {\n\t\tif (bacmp(bdaddr, &k->bdaddr) == 0) {\n\t\t\trcu_read_unlock();\n\n\t\t\tif (hci_is_blocked_key(hdev,\n\t\t\t\t\t       HCI_BLOCKED_KEY_TYPE_LINKKEY,\n\t\t\t\t\t       k->val)) {\n\t\t\t\tbt_dev_warn_ratelimited(hdev,\n\t\t\t\t\t\t\t\"Link key blocked for %pMR\",\n\t\t\t\t\t\t\t&k->bdaddr);\n\t\t\t\treturn NULL;\n\t\t\t}\n\n\t\t\treturn k;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn NULL;\n}\n\nstatic bool hci_persistent_key(struct hci_dev *hdev, struct hci_conn *conn,\n\t\t\t       u8 key_type, u8 old_key_type)\n{\n\t \n\tif (key_type < 0x03)\n\t\treturn true;\n\n\t \n\tif (key_type == HCI_LK_DEBUG_COMBINATION)\n\t\treturn false;\n\n\t \n\tif (key_type == HCI_LK_CHANGED_COMBINATION && old_key_type == 0xff)\n\t\treturn false;\n\n\t \n\tif (!conn)\n\t\treturn true;\n\n\t \n\tif (conn->type == LE_LINK)\n\t\treturn true;\n\n\t \n\tif (conn->auth_type > 0x01 && conn->remote_auth > 0x01)\n\t\treturn true;\n\n\t \n\tif (conn->auth_type == 0x02 || conn->auth_type == 0x03)\n\t\treturn true;\n\n\t \n\tif (conn->remote_auth == 0x02 || conn->remote_auth == 0x03)\n\t\treturn true;\n\n\t \n\treturn false;\n}\n\nstatic u8 ltk_role(u8 type)\n{\n\tif (type == SMP_LTK)\n\t\treturn HCI_ROLE_MASTER;\n\n\treturn HCI_ROLE_SLAVE;\n}\n\nstruct smp_ltk *hci_find_ltk(struct hci_dev *hdev, bdaddr_t *bdaddr,\n\t\t\t     u8 addr_type, u8 role)\n{\n\tstruct smp_ltk *k;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(k, &hdev->long_term_keys, list) {\n\t\tif (addr_type != k->bdaddr_type || bacmp(bdaddr, &k->bdaddr))\n\t\t\tcontinue;\n\n\t\tif (smp_ltk_is_sc(k) || ltk_role(k->type) == role) {\n\t\t\trcu_read_unlock();\n\n\t\t\tif (hci_is_blocked_key(hdev, HCI_BLOCKED_KEY_TYPE_LTK,\n\t\t\t\t\t       k->val)) {\n\t\t\t\tbt_dev_warn_ratelimited(hdev,\n\t\t\t\t\t\t\t\"LTK blocked for %pMR\",\n\t\t\t\t\t\t\t&k->bdaddr);\n\t\t\t\treturn NULL;\n\t\t\t}\n\n\t\t\treturn k;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn NULL;\n}\n\nstruct smp_irk *hci_find_irk_by_rpa(struct hci_dev *hdev, bdaddr_t *rpa)\n{\n\tstruct smp_irk *irk_to_return = NULL;\n\tstruct smp_irk *irk;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(irk, &hdev->identity_resolving_keys, list) {\n\t\tif (!bacmp(&irk->rpa, rpa)) {\n\t\t\tirk_to_return = irk;\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\tlist_for_each_entry_rcu(irk, &hdev->identity_resolving_keys, list) {\n\t\tif (smp_irk_matches(hdev, irk->val, rpa)) {\n\t\t\tbacpy(&irk->rpa, rpa);\n\t\t\tirk_to_return = irk;\n\t\t\tgoto done;\n\t\t}\n\t}\n\ndone:\n\tif (irk_to_return && hci_is_blocked_key(hdev, HCI_BLOCKED_KEY_TYPE_IRK,\n\t\t\t\t\t\tirk_to_return->val)) {\n\t\tbt_dev_warn_ratelimited(hdev, \"Identity key blocked for %pMR\",\n\t\t\t\t\t&irk_to_return->bdaddr);\n\t\tirk_to_return = NULL;\n\t}\n\n\trcu_read_unlock();\n\n\treturn irk_to_return;\n}\n\nstruct smp_irk *hci_find_irk_by_addr(struct hci_dev *hdev, bdaddr_t *bdaddr,\n\t\t\t\t     u8 addr_type)\n{\n\tstruct smp_irk *irk_to_return = NULL;\n\tstruct smp_irk *irk;\n\n\t \n\tif (addr_type == ADDR_LE_DEV_RANDOM && (bdaddr->b[5] & 0xc0) != 0xc0)\n\t\treturn NULL;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(irk, &hdev->identity_resolving_keys, list) {\n\t\tif (addr_type == irk->addr_type &&\n\t\t    bacmp(bdaddr, &irk->bdaddr) == 0) {\n\t\t\tirk_to_return = irk;\n\t\t\tgoto done;\n\t\t}\n\t}\n\ndone:\n\n\tif (irk_to_return && hci_is_blocked_key(hdev, HCI_BLOCKED_KEY_TYPE_IRK,\n\t\t\t\t\t\tirk_to_return->val)) {\n\t\tbt_dev_warn_ratelimited(hdev, \"Identity key blocked for %pMR\",\n\t\t\t\t\t&irk_to_return->bdaddr);\n\t\tirk_to_return = NULL;\n\t}\n\n\trcu_read_unlock();\n\n\treturn irk_to_return;\n}\n\nstruct link_key *hci_add_link_key(struct hci_dev *hdev, struct hci_conn *conn,\n\t\t\t\t  bdaddr_t *bdaddr, u8 *val, u8 type,\n\t\t\t\t  u8 pin_len, bool *persistent)\n{\n\tstruct link_key *key, *old_key;\n\tu8 old_key_type;\n\n\told_key = hci_find_link_key(hdev, bdaddr);\n\tif (old_key) {\n\t\told_key_type = old_key->type;\n\t\tkey = old_key;\n\t} else {\n\t\told_key_type = conn ? conn->key_type : 0xff;\n\t\tkey = kzalloc(sizeof(*key), GFP_KERNEL);\n\t\tif (!key)\n\t\t\treturn NULL;\n\t\tlist_add_rcu(&key->list, &hdev->link_keys);\n\t}\n\n\tBT_DBG(\"%s key for %pMR type %u\", hdev->name, bdaddr, type);\n\n\t \n\tif (type == HCI_LK_CHANGED_COMBINATION &&\n\t    (!conn || conn->remote_auth == 0xff) && old_key_type == 0xff) {\n\t\ttype = HCI_LK_COMBINATION;\n\t\tif (conn)\n\t\t\tconn->key_type = type;\n\t}\n\n\tbacpy(&key->bdaddr, bdaddr);\n\tmemcpy(key->val, val, HCI_LINK_KEY_SIZE);\n\tkey->pin_len = pin_len;\n\n\tif (type == HCI_LK_CHANGED_COMBINATION)\n\t\tkey->type = old_key_type;\n\telse\n\t\tkey->type = type;\n\n\tif (persistent)\n\t\t*persistent = hci_persistent_key(hdev, conn, type,\n\t\t\t\t\t\t old_key_type);\n\n\treturn key;\n}\n\nstruct smp_ltk *hci_add_ltk(struct hci_dev *hdev, bdaddr_t *bdaddr,\n\t\t\t    u8 addr_type, u8 type, u8 authenticated,\n\t\t\t    u8 tk[16], u8 enc_size, __le16 ediv, __le64 rand)\n{\n\tstruct smp_ltk *key, *old_key;\n\tu8 role = ltk_role(type);\n\n\told_key = hci_find_ltk(hdev, bdaddr, addr_type, role);\n\tif (old_key)\n\t\tkey = old_key;\n\telse {\n\t\tkey = kzalloc(sizeof(*key), GFP_KERNEL);\n\t\tif (!key)\n\t\t\treturn NULL;\n\t\tlist_add_rcu(&key->list, &hdev->long_term_keys);\n\t}\n\n\tbacpy(&key->bdaddr, bdaddr);\n\tkey->bdaddr_type = addr_type;\n\tmemcpy(key->val, tk, sizeof(key->val));\n\tkey->authenticated = authenticated;\n\tkey->ediv = ediv;\n\tkey->rand = rand;\n\tkey->enc_size = enc_size;\n\tkey->type = type;\n\n\treturn key;\n}\n\nstruct smp_irk *hci_add_irk(struct hci_dev *hdev, bdaddr_t *bdaddr,\n\t\t\t    u8 addr_type, u8 val[16], bdaddr_t *rpa)\n{\n\tstruct smp_irk *irk;\n\n\tirk = hci_find_irk_by_addr(hdev, bdaddr, addr_type);\n\tif (!irk) {\n\t\tirk = kzalloc(sizeof(*irk), GFP_KERNEL);\n\t\tif (!irk)\n\t\t\treturn NULL;\n\n\t\tbacpy(&irk->bdaddr, bdaddr);\n\t\tirk->addr_type = addr_type;\n\n\t\tlist_add_rcu(&irk->list, &hdev->identity_resolving_keys);\n\t}\n\n\tmemcpy(irk->val, val, 16);\n\tbacpy(&irk->rpa, rpa);\n\n\treturn irk;\n}\n\nint hci_remove_link_key(struct hci_dev *hdev, bdaddr_t *bdaddr)\n{\n\tstruct link_key *key;\n\n\tkey = hci_find_link_key(hdev, bdaddr);\n\tif (!key)\n\t\treturn -ENOENT;\n\n\tBT_DBG(\"%s removing %pMR\", hdev->name, bdaddr);\n\n\tlist_del_rcu(&key->list);\n\tkfree_rcu(key, rcu);\n\n\treturn 0;\n}\n\nint hci_remove_ltk(struct hci_dev *hdev, bdaddr_t *bdaddr, u8 bdaddr_type)\n{\n\tstruct smp_ltk *k, *tmp;\n\tint removed = 0;\n\n\tlist_for_each_entry_safe(k, tmp, &hdev->long_term_keys, list) {\n\t\tif (bacmp(bdaddr, &k->bdaddr) || k->bdaddr_type != bdaddr_type)\n\t\t\tcontinue;\n\n\t\tBT_DBG(\"%s removing %pMR\", hdev->name, bdaddr);\n\n\t\tlist_del_rcu(&k->list);\n\t\tkfree_rcu(k, rcu);\n\t\tremoved++;\n\t}\n\n\treturn removed ? 0 : -ENOENT;\n}\n\nvoid hci_remove_irk(struct hci_dev *hdev, bdaddr_t *bdaddr, u8 addr_type)\n{\n\tstruct smp_irk *k, *tmp;\n\n\tlist_for_each_entry_safe(k, tmp, &hdev->identity_resolving_keys, list) {\n\t\tif (bacmp(bdaddr, &k->bdaddr) || k->addr_type != addr_type)\n\t\t\tcontinue;\n\n\t\tBT_DBG(\"%s removing %pMR\", hdev->name, bdaddr);\n\n\t\tlist_del_rcu(&k->list);\n\t\tkfree_rcu(k, rcu);\n\t}\n}\n\nbool hci_bdaddr_is_paired(struct hci_dev *hdev, bdaddr_t *bdaddr, u8 type)\n{\n\tstruct smp_ltk *k;\n\tstruct smp_irk *irk;\n\tu8 addr_type;\n\n\tif (type == BDADDR_BREDR) {\n\t\tif (hci_find_link_key(hdev, bdaddr))\n\t\t\treturn true;\n\t\treturn false;\n\t}\n\n\t \n\tif (type == BDADDR_LE_PUBLIC)\n\t\taddr_type = ADDR_LE_DEV_PUBLIC;\n\telse\n\t\taddr_type = ADDR_LE_DEV_RANDOM;\n\n\tirk = hci_get_irk(hdev, bdaddr, addr_type);\n\tif (irk) {\n\t\tbdaddr = &irk->bdaddr;\n\t\taddr_type = irk->addr_type;\n\t}\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(k, &hdev->long_term_keys, list) {\n\t\tif (k->bdaddr_type == addr_type && !bacmp(bdaddr, &k->bdaddr)) {\n\t\t\trcu_read_unlock();\n\t\t\treturn true;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn false;\n}\n\n \nstatic void hci_cmd_timeout(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev,\n\t\t\t\t\t    cmd_timer.work);\n\n\tif (hdev->sent_cmd) {\n\t\tstruct hci_command_hdr *sent = (void *) hdev->sent_cmd->data;\n\t\tu16 opcode = __le16_to_cpu(sent->opcode);\n\n\t\tbt_dev_err(hdev, \"command 0x%4.4x tx timeout\", opcode);\n\t} else {\n\t\tbt_dev_err(hdev, \"command tx timeout\");\n\t}\n\n\tif (hdev->cmd_timeout)\n\t\thdev->cmd_timeout(hdev);\n\n\tatomic_set(&hdev->cmd_cnt, 1);\n\tqueue_work(hdev->workqueue, &hdev->cmd_work);\n}\n\n \nstatic void hci_ncmd_timeout(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev,\n\t\t\t\t\t    ncmd_timer.work);\n\n\tbt_dev_err(hdev, \"Controller not accepting commands anymore: ncmd = 0\");\n\n\t \n\tif (test_bit(HCI_INIT, &hdev->flags))\n\t\treturn;\n\n\t \n\thci_reset_dev(hdev);\n}\n\nstruct oob_data *hci_find_remote_oob_data(struct hci_dev *hdev,\n\t\t\t\t\t  bdaddr_t *bdaddr, u8 bdaddr_type)\n{\n\tstruct oob_data *data;\n\n\tlist_for_each_entry(data, &hdev->remote_oob_data, list) {\n\t\tif (bacmp(bdaddr, &data->bdaddr) != 0)\n\t\t\tcontinue;\n\t\tif (data->bdaddr_type != bdaddr_type)\n\t\t\tcontinue;\n\t\treturn data;\n\t}\n\n\treturn NULL;\n}\n\nint hci_remove_remote_oob_data(struct hci_dev *hdev, bdaddr_t *bdaddr,\n\t\t\t       u8 bdaddr_type)\n{\n\tstruct oob_data *data;\n\n\tdata = hci_find_remote_oob_data(hdev, bdaddr, bdaddr_type);\n\tif (!data)\n\t\treturn -ENOENT;\n\n\tBT_DBG(\"%s removing %pMR (%u)\", hdev->name, bdaddr, bdaddr_type);\n\n\tlist_del(&data->list);\n\tkfree(data);\n\n\treturn 0;\n}\n\nvoid hci_remote_oob_data_clear(struct hci_dev *hdev)\n{\n\tstruct oob_data *data, *n;\n\n\tlist_for_each_entry_safe(data, n, &hdev->remote_oob_data, list) {\n\t\tlist_del(&data->list);\n\t\tkfree(data);\n\t}\n}\n\nint hci_add_remote_oob_data(struct hci_dev *hdev, bdaddr_t *bdaddr,\n\t\t\t    u8 bdaddr_type, u8 *hash192, u8 *rand192,\n\t\t\t    u8 *hash256, u8 *rand256)\n{\n\tstruct oob_data *data;\n\n\tdata = hci_find_remote_oob_data(hdev, bdaddr, bdaddr_type);\n\tif (!data) {\n\t\tdata = kmalloc(sizeof(*data), GFP_KERNEL);\n\t\tif (!data)\n\t\t\treturn -ENOMEM;\n\n\t\tbacpy(&data->bdaddr, bdaddr);\n\t\tdata->bdaddr_type = bdaddr_type;\n\t\tlist_add(&data->list, &hdev->remote_oob_data);\n\t}\n\n\tif (hash192 && rand192) {\n\t\tmemcpy(data->hash192, hash192, sizeof(data->hash192));\n\t\tmemcpy(data->rand192, rand192, sizeof(data->rand192));\n\t\tif (hash256 && rand256)\n\t\t\tdata->present = 0x03;\n\t} else {\n\t\tmemset(data->hash192, 0, sizeof(data->hash192));\n\t\tmemset(data->rand192, 0, sizeof(data->rand192));\n\t\tif (hash256 && rand256)\n\t\t\tdata->present = 0x02;\n\t\telse\n\t\t\tdata->present = 0x00;\n\t}\n\n\tif (hash256 && rand256) {\n\t\tmemcpy(data->hash256, hash256, sizeof(data->hash256));\n\t\tmemcpy(data->rand256, rand256, sizeof(data->rand256));\n\t} else {\n\t\tmemset(data->hash256, 0, sizeof(data->hash256));\n\t\tmemset(data->rand256, 0, sizeof(data->rand256));\n\t\tif (hash192 && rand192)\n\t\t\tdata->present = 0x01;\n\t}\n\n\tBT_DBG(\"%s for %pMR\", hdev->name, bdaddr);\n\n\treturn 0;\n}\n\n \nstruct adv_info *hci_find_adv_instance(struct hci_dev *hdev, u8 instance)\n{\n\tstruct adv_info *adv_instance;\n\n\tlist_for_each_entry(adv_instance, &hdev->adv_instances, list) {\n\t\tif (adv_instance->instance == instance)\n\t\t\treturn adv_instance;\n\t}\n\n\treturn NULL;\n}\n\n \nstruct adv_info *hci_get_next_instance(struct hci_dev *hdev, u8 instance)\n{\n\tstruct adv_info *cur_instance;\n\n\tcur_instance = hci_find_adv_instance(hdev, instance);\n\tif (!cur_instance)\n\t\treturn NULL;\n\n\tif (cur_instance == list_last_entry(&hdev->adv_instances,\n\t\t\t\t\t    struct adv_info, list))\n\t\treturn list_first_entry(&hdev->adv_instances,\n\t\t\t\t\t\t struct adv_info, list);\n\telse\n\t\treturn list_next_entry(cur_instance, list);\n}\n\n \nint hci_remove_adv_instance(struct hci_dev *hdev, u8 instance)\n{\n\tstruct adv_info *adv_instance;\n\n\tadv_instance = hci_find_adv_instance(hdev, instance);\n\tif (!adv_instance)\n\t\treturn -ENOENT;\n\n\tBT_DBG(\"%s removing %dMR\", hdev->name, instance);\n\n\tif (hdev->cur_adv_instance == instance) {\n\t\tif (hdev->adv_instance_timeout) {\n\t\t\tcancel_delayed_work(&hdev->adv_instance_expire);\n\t\t\thdev->adv_instance_timeout = 0;\n\t\t}\n\t\thdev->cur_adv_instance = 0x00;\n\t}\n\n\tcancel_delayed_work_sync(&adv_instance->rpa_expired_cb);\n\n\tlist_del(&adv_instance->list);\n\tkfree(adv_instance);\n\n\thdev->adv_instance_cnt--;\n\n\treturn 0;\n}\n\nvoid hci_adv_instances_set_rpa_expired(struct hci_dev *hdev, bool rpa_expired)\n{\n\tstruct adv_info *adv_instance, *n;\n\n\tlist_for_each_entry_safe(adv_instance, n, &hdev->adv_instances, list)\n\t\tadv_instance->rpa_expired = rpa_expired;\n}\n\n \nvoid hci_adv_instances_clear(struct hci_dev *hdev)\n{\n\tstruct adv_info *adv_instance, *n;\n\n\tif (hdev->adv_instance_timeout) {\n\t\tcancel_delayed_work(&hdev->adv_instance_expire);\n\t\thdev->adv_instance_timeout = 0;\n\t}\n\n\tlist_for_each_entry_safe(adv_instance, n, &hdev->adv_instances, list) {\n\t\tcancel_delayed_work_sync(&adv_instance->rpa_expired_cb);\n\t\tlist_del(&adv_instance->list);\n\t\tkfree(adv_instance);\n\t}\n\n\thdev->adv_instance_cnt = 0;\n\thdev->cur_adv_instance = 0x00;\n}\n\nstatic void adv_instance_rpa_expired(struct work_struct *work)\n{\n\tstruct adv_info *adv_instance = container_of(work, struct adv_info,\n\t\t\t\t\t\t     rpa_expired_cb.work);\n\n\tBT_DBG(\"\");\n\n\tadv_instance->rpa_expired = true;\n}\n\n \nstruct adv_info *hci_add_adv_instance(struct hci_dev *hdev, u8 instance,\n\t\t\t\t      u32 flags, u16 adv_data_len, u8 *adv_data,\n\t\t\t\t      u16 scan_rsp_len, u8 *scan_rsp_data,\n\t\t\t\t      u16 timeout, u16 duration, s8 tx_power,\n\t\t\t\t      u32 min_interval, u32 max_interval,\n\t\t\t\t      u8 mesh_handle)\n{\n\tstruct adv_info *adv;\n\n\tadv = hci_find_adv_instance(hdev, instance);\n\tif (adv) {\n\t\tmemset(adv->adv_data, 0, sizeof(adv->adv_data));\n\t\tmemset(adv->scan_rsp_data, 0, sizeof(adv->scan_rsp_data));\n\t\tmemset(adv->per_adv_data, 0, sizeof(adv->per_adv_data));\n\t} else {\n\t\tif (hdev->adv_instance_cnt >= hdev->le_num_of_adv_sets ||\n\t\t    instance < 1 || instance > hdev->le_num_of_adv_sets + 1)\n\t\t\treturn ERR_PTR(-EOVERFLOW);\n\n\t\tadv = kzalloc(sizeof(*adv), GFP_KERNEL);\n\t\tif (!adv)\n\t\t\treturn ERR_PTR(-ENOMEM);\n\n\t\tadv->pending = true;\n\t\tadv->instance = instance;\n\t\tlist_add(&adv->list, &hdev->adv_instances);\n\t\thdev->adv_instance_cnt++;\n\t}\n\n\tadv->flags = flags;\n\tadv->min_interval = min_interval;\n\tadv->max_interval = max_interval;\n\tadv->tx_power = tx_power;\n\t \n\tadv->mesh = mesh_handle;\n\n\thci_set_adv_instance_data(hdev, instance, adv_data_len, adv_data,\n\t\t\t\t  scan_rsp_len, scan_rsp_data);\n\n\tadv->timeout = timeout;\n\tadv->remaining_time = timeout;\n\n\tif (duration == 0)\n\t\tadv->duration = hdev->def_multi_adv_rotation_duration;\n\telse\n\t\tadv->duration = duration;\n\n\tINIT_DELAYED_WORK(&adv->rpa_expired_cb, adv_instance_rpa_expired);\n\n\tBT_DBG(\"%s for %dMR\", hdev->name, instance);\n\n\treturn adv;\n}\n\n \nstruct adv_info *hci_add_per_instance(struct hci_dev *hdev, u8 instance,\n\t\t\t\t      u32 flags, u8 data_len, u8 *data,\n\t\t\t\t      u32 min_interval, u32 max_interval)\n{\n\tstruct adv_info *adv;\n\n\tadv = hci_add_adv_instance(hdev, instance, flags, 0, NULL, 0, NULL,\n\t\t\t\t   0, 0, HCI_ADV_TX_POWER_NO_PREFERENCE,\n\t\t\t\t   min_interval, max_interval, 0);\n\tif (IS_ERR(adv))\n\t\treturn adv;\n\n\tadv->periodic = true;\n\tadv->per_adv_data_len = data_len;\n\n\tif (data)\n\t\tmemcpy(adv->per_adv_data, data, data_len);\n\n\treturn adv;\n}\n\n \nint hci_set_adv_instance_data(struct hci_dev *hdev, u8 instance,\n\t\t\t      u16 adv_data_len, u8 *adv_data,\n\t\t\t      u16 scan_rsp_len, u8 *scan_rsp_data)\n{\n\tstruct adv_info *adv;\n\n\tadv = hci_find_adv_instance(hdev, instance);\n\n\t \n\tif (!adv)\n\t\treturn -ENOENT;\n\n\tif (adv_data_len && ADV_DATA_CMP(adv, adv_data, adv_data_len)) {\n\t\tmemset(adv->adv_data, 0, sizeof(adv->adv_data));\n\t\tmemcpy(adv->adv_data, adv_data, adv_data_len);\n\t\tadv->adv_data_len = adv_data_len;\n\t\tadv->adv_data_changed = true;\n\t}\n\n\tif (scan_rsp_len && SCAN_RSP_CMP(adv, scan_rsp_data, scan_rsp_len)) {\n\t\tmemset(adv->scan_rsp_data, 0, sizeof(adv->scan_rsp_data));\n\t\tmemcpy(adv->scan_rsp_data, scan_rsp_data, scan_rsp_len);\n\t\tadv->scan_rsp_len = scan_rsp_len;\n\t\tadv->scan_rsp_changed = true;\n\t}\n\n\t \n\tif (((adv->flags & MGMT_ADV_FLAG_APPEARANCE) && hdev->appearance) ||\n\t    adv->flags & MGMT_ADV_FLAG_LOCAL_NAME)\n\t\tadv->scan_rsp_changed = true;\n\n\treturn 0;\n}\n\n \nu32 hci_adv_instance_flags(struct hci_dev *hdev, u8 instance)\n{\n\tu32 flags;\n\tstruct adv_info *adv;\n\n\tif (instance == 0x00) {\n\t\t \n\t\tflags = MGMT_ADV_FLAG_TX_POWER | MGMT_ADV_FLAG_MANAGED_FLAGS;\n\n\t\t \n\t\tif (hci_dev_test_flag(hdev, HCI_ADVERTISING_CONNECTABLE))\n\t\t\tflags |= MGMT_ADV_FLAG_CONNECTABLE;\n\n\t\tif (hci_dev_test_flag(hdev, HCI_LIMITED_DISCOVERABLE))\n\t\t\tflags |= MGMT_ADV_FLAG_LIMITED_DISCOV;\n\t\telse if (hci_dev_test_flag(hdev, HCI_DISCOVERABLE))\n\t\t\tflags |= MGMT_ADV_FLAG_DISCOV;\n\n\t\treturn flags;\n\t}\n\n\tadv = hci_find_adv_instance(hdev, instance);\n\n\t \n\tif (!adv)\n\t\treturn 0;\n\n\treturn adv->flags;\n}\n\nbool hci_adv_instance_is_scannable(struct hci_dev *hdev, u8 instance)\n{\n\tstruct adv_info *adv;\n\n\t \n\tif (instance == 0x00)\n\t\treturn true;\n\n\tadv = hci_find_adv_instance(hdev, instance);\n\tif (!adv)\n\t\treturn false;\n\n\tif (adv->flags & MGMT_ADV_FLAG_APPEARANCE ||\n\t    adv->flags & MGMT_ADV_FLAG_LOCAL_NAME)\n\t\treturn true;\n\n\treturn adv->scan_rsp_len ? true : false;\n}\n\n \nvoid hci_adv_monitors_clear(struct hci_dev *hdev)\n{\n\tstruct adv_monitor *monitor;\n\tint handle;\n\n\tidr_for_each_entry(&hdev->adv_monitors_idr, monitor, handle)\n\t\thci_free_adv_monitor(hdev, monitor);\n\n\tidr_destroy(&hdev->adv_monitors_idr);\n}\n\n \nvoid hci_free_adv_monitor(struct hci_dev *hdev, struct adv_monitor *monitor)\n{\n\tstruct adv_pattern *pattern;\n\tstruct adv_pattern *tmp;\n\n\tif (!monitor)\n\t\treturn;\n\n\tlist_for_each_entry_safe(pattern, tmp, &monitor->patterns, list) {\n\t\tlist_del(&pattern->list);\n\t\tkfree(pattern);\n\t}\n\n\tif (monitor->handle)\n\t\tidr_remove(&hdev->adv_monitors_idr, monitor->handle);\n\n\tif (monitor->state != ADV_MONITOR_STATE_NOT_REGISTERED) {\n\t\thdev->adv_monitors_cnt--;\n\t\tmgmt_adv_monitor_removed(hdev, monitor->handle);\n\t}\n\n\tkfree(monitor);\n}\n\n \nint hci_add_adv_monitor(struct hci_dev *hdev, struct adv_monitor *monitor)\n{\n\tint min, max, handle;\n\tint status = 0;\n\n\tif (!monitor)\n\t\treturn -EINVAL;\n\n\thci_dev_lock(hdev);\n\n\tmin = HCI_MIN_ADV_MONITOR_HANDLE;\n\tmax = HCI_MIN_ADV_MONITOR_HANDLE + HCI_MAX_ADV_MONITOR_NUM_HANDLES;\n\thandle = idr_alloc(&hdev->adv_monitors_idr, monitor, min, max,\n\t\t\t   GFP_KERNEL);\n\n\thci_dev_unlock(hdev);\n\n\tif (handle < 0)\n\t\treturn handle;\n\n\tmonitor->handle = handle;\n\n\tif (!hdev_is_powered(hdev))\n\t\treturn status;\n\n\tswitch (hci_get_adv_monitor_offload_ext(hdev)) {\n\tcase HCI_ADV_MONITOR_EXT_NONE:\n\t\tbt_dev_dbg(hdev, \"add monitor %d status %d\",\n\t\t\t   monitor->handle, status);\n\t\t \n\t\tbreak;\n\n\tcase HCI_ADV_MONITOR_EXT_MSFT:\n\t\tstatus = msft_add_monitor_pattern(hdev, monitor);\n\t\tbt_dev_dbg(hdev, \"add monitor %d msft status %d\",\n\t\t\t   handle, status);\n\t\tbreak;\n\t}\n\n\treturn status;\n}\n\n \nstatic int hci_remove_adv_monitor(struct hci_dev *hdev,\n\t\t\t\t  struct adv_monitor *monitor)\n{\n\tint status = 0;\n\tint handle;\n\n\tswitch (hci_get_adv_monitor_offload_ext(hdev)) {\n\tcase HCI_ADV_MONITOR_EXT_NONE:  \n\t\tbt_dev_dbg(hdev, \"remove monitor %d status %d\",\n\t\t\t   monitor->handle, status);\n\t\tgoto free_monitor;\n\n\tcase HCI_ADV_MONITOR_EXT_MSFT:\n\t\thandle = monitor->handle;\n\t\tstatus = msft_remove_monitor(hdev, monitor);\n\t\tbt_dev_dbg(hdev, \"remove monitor %d msft status %d\",\n\t\t\t   handle, status);\n\t\tbreak;\n\t}\n\n\t \n\tif (status == -ENOENT)\n\t\tgoto free_monitor;\n\n\treturn status;\n\nfree_monitor:\n\tif (status == -ENOENT)\n\t\tbt_dev_warn(hdev, \"Removing monitor with no matching handle %d\",\n\t\t\t    monitor->handle);\n\thci_free_adv_monitor(hdev, monitor);\n\n\treturn status;\n}\n\n \nint hci_remove_single_adv_monitor(struct hci_dev *hdev, u16 handle)\n{\n\tstruct adv_monitor *monitor = idr_find(&hdev->adv_monitors_idr, handle);\n\n\tif (!monitor)\n\t\treturn -EINVAL;\n\n\treturn hci_remove_adv_monitor(hdev, monitor);\n}\n\n \nint hci_remove_all_adv_monitor(struct hci_dev *hdev)\n{\n\tstruct adv_monitor *monitor;\n\tint idr_next_id = 0;\n\tint status = 0;\n\n\twhile (1) {\n\t\tmonitor = idr_get_next(&hdev->adv_monitors_idr, &idr_next_id);\n\t\tif (!monitor)\n\t\t\tbreak;\n\n\t\tstatus = hci_remove_adv_monitor(hdev, monitor);\n\t\tif (status)\n\t\t\treturn status;\n\n\t\tidr_next_id++;\n\t}\n\n\treturn status;\n}\n\n \nbool hci_is_adv_monitoring(struct hci_dev *hdev)\n{\n\treturn !idr_is_empty(&hdev->adv_monitors_idr);\n}\n\nint hci_get_adv_monitor_offload_ext(struct hci_dev *hdev)\n{\n\tif (msft_monitor_supported(hdev))\n\t\treturn HCI_ADV_MONITOR_EXT_MSFT;\n\n\treturn HCI_ADV_MONITOR_EXT_NONE;\n}\n\nstruct bdaddr_list *hci_bdaddr_list_lookup(struct list_head *bdaddr_list,\n\t\t\t\t\t bdaddr_t *bdaddr, u8 type)\n{\n\tstruct bdaddr_list *b;\n\n\tlist_for_each_entry(b, bdaddr_list, list) {\n\t\tif (!bacmp(&b->bdaddr, bdaddr) && b->bdaddr_type == type)\n\t\t\treturn b;\n\t}\n\n\treturn NULL;\n}\n\nstruct bdaddr_list_with_irk *hci_bdaddr_list_lookup_with_irk(\n\t\t\t\tstruct list_head *bdaddr_list, bdaddr_t *bdaddr,\n\t\t\t\tu8 type)\n{\n\tstruct bdaddr_list_with_irk *b;\n\n\tlist_for_each_entry(b, bdaddr_list, list) {\n\t\tif (!bacmp(&b->bdaddr, bdaddr) && b->bdaddr_type == type)\n\t\t\treturn b;\n\t}\n\n\treturn NULL;\n}\n\nstruct bdaddr_list_with_flags *\nhci_bdaddr_list_lookup_with_flags(struct list_head *bdaddr_list,\n\t\t\t\t  bdaddr_t *bdaddr, u8 type)\n{\n\tstruct bdaddr_list_with_flags *b;\n\n\tlist_for_each_entry(b, bdaddr_list, list) {\n\t\tif (!bacmp(&b->bdaddr, bdaddr) && b->bdaddr_type == type)\n\t\t\treturn b;\n\t}\n\n\treturn NULL;\n}\n\nvoid hci_bdaddr_list_clear(struct list_head *bdaddr_list)\n{\n\tstruct bdaddr_list *b, *n;\n\n\tlist_for_each_entry_safe(b, n, bdaddr_list, list) {\n\t\tlist_del(&b->list);\n\t\tkfree(b);\n\t}\n}\n\nint hci_bdaddr_list_add(struct list_head *list, bdaddr_t *bdaddr, u8 type)\n{\n\tstruct bdaddr_list *entry;\n\n\tif (!bacmp(bdaddr, BDADDR_ANY))\n\t\treturn -EBADF;\n\n\tif (hci_bdaddr_list_lookup(list, bdaddr, type))\n\t\treturn -EEXIST;\n\n\tentry = kzalloc(sizeof(*entry), GFP_KERNEL);\n\tif (!entry)\n\t\treturn -ENOMEM;\n\n\tbacpy(&entry->bdaddr, bdaddr);\n\tentry->bdaddr_type = type;\n\n\tlist_add(&entry->list, list);\n\n\treturn 0;\n}\n\nint hci_bdaddr_list_add_with_irk(struct list_head *list, bdaddr_t *bdaddr,\n\t\t\t\t\tu8 type, u8 *peer_irk, u8 *local_irk)\n{\n\tstruct bdaddr_list_with_irk *entry;\n\n\tif (!bacmp(bdaddr, BDADDR_ANY))\n\t\treturn -EBADF;\n\n\tif (hci_bdaddr_list_lookup(list, bdaddr, type))\n\t\treturn -EEXIST;\n\n\tentry = kzalloc(sizeof(*entry), GFP_KERNEL);\n\tif (!entry)\n\t\treturn -ENOMEM;\n\n\tbacpy(&entry->bdaddr, bdaddr);\n\tentry->bdaddr_type = type;\n\n\tif (peer_irk)\n\t\tmemcpy(entry->peer_irk, peer_irk, 16);\n\n\tif (local_irk)\n\t\tmemcpy(entry->local_irk, local_irk, 16);\n\n\tlist_add(&entry->list, list);\n\n\treturn 0;\n}\n\nint hci_bdaddr_list_add_with_flags(struct list_head *list, bdaddr_t *bdaddr,\n\t\t\t\t   u8 type, u32 flags)\n{\n\tstruct bdaddr_list_with_flags *entry;\n\n\tif (!bacmp(bdaddr, BDADDR_ANY))\n\t\treturn -EBADF;\n\n\tif (hci_bdaddr_list_lookup(list, bdaddr, type))\n\t\treturn -EEXIST;\n\n\tentry = kzalloc(sizeof(*entry), GFP_KERNEL);\n\tif (!entry)\n\t\treturn -ENOMEM;\n\n\tbacpy(&entry->bdaddr, bdaddr);\n\tentry->bdaddr_type = type;\n\tentry->flags = flags;\n\n\tlist_add(&entry->list, list);\n\n\treturn 0;\n}\n\nint hci_bdaddr_list_del(struct list_head *list, bdaddr_t *bdaddr, u8 type)\n{\n\tstruct bdaddr_list *entry;\n\n\tif (!bacmp(bdaddr, BDADDR_ANY)) {\n\t\thci_bdaddr_list_clear(list);\n\t\treturn 0;\n\t}\n\n\tentry = hci_bdaddr_list_lookup(list, bdaddr, type);\n\tif (!entry)\n\t\treturn -ENOENT;\n\n\tlist_del(&entry->list);\n\tkfree(entry);\n\n\treturn 0;\n}\n\nint hci_bdaddr_list_del_with_irk(struct list_head *list, bdaddr_t *bdaddr,\n\t\t\t\t\t\t\tu8 type)\n{\n\tstruct bdaddr_list_with_irk *entry;\n\n\tif (!bacmp(bdaddr, BDADDR_ANY)) {\n\t\thci_bdaddr_list_clear(list);\n\t\treturn 0;\n\t}\n\n\tentry = hci_bdaddr_list_lookup_with_irk(list, bdaddr, type);\n\tif (!entry)\n\t\treturn -ENOENT;\n\n\tlist_del(&entry->list);\n\tkfree(entry);\n\n\treturn 0;\n}\n\nint hci_bdaddr_list_del_with_flags(struct list_head *list, bdaddr_t *bdaddr,\n\t\t\t\t   u8 type)\n{\n\tstruct bdaddr_list_with_flags *entry;\n\n\tif (!bacmp(bdaddr, BDADDR_ANY)) {\n\t\thci_bdaddr_list_clear(list);\n\t\treturn 0;\n\t}\n\n\tentry = hci_bdaddr_list_lookup_with_flags(list, bdaddr, type);\n\tif (!entry)\n\t\treturn -ENOENT;\n\n\tlist_del(&entry->list);\n\tkfree(entry);\n\n\treturn 0;\n}\n\n \nstruct hci_conn_params *hci_conn_params_lookup(struct hci_dev *hdev,\n\t\t\t\t\t       bdaddr_t *addr, u8 addr_type)\n{\n\tstruct hci_conn_params *params;\n\n\tlist_for_each_entry(params, &hdev->le_conn_params, list) {\n\t\tif (bacmp(&params->addr, addr) == 0 &&\n\t\t    params->addr_type == addr_type) {\n\t\t\treturn params;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\n \nstruct hci_conn_params *hci_pend_le_action_lookup(struct list_head *list,\n\t\t\t\t\t\t  bdaddr_t *addr, u8 addr_type)\n{\n\tstruct hci_conn_params *param;\n\n\trcu_read_lock();\n\n\tlist_for_each_entry_rcu(param, list, action) {\n\t\tif (bacmp(&param->addr, addr) == 0 &&\n\t\t    param->addr_type == addr_type) {\n\t\t\trcu_read_unlock();\n\t\t\treturn param;\n\t\t}\n\t}\n\n\trcu_read_unlock();\n\n\treturn NULL;\n}\n\n \nvoid hci_pend_le_list_del_init(struct hci_conn_params *param)\n{\n\tif (list_empty(&param->action))\n\t\treturn;\n\n\tlist_del_rcu(&param->action);\n\tsynchronize_rcu();\n\tINIT_LIST_HEAD(&param->action);\n}\n\n \nvoid hci_pend_le_list_add(struct hci_conn_params *param,\n\t\t\t  struct list_head *list)\n{\n\tlist_add_rcu(&param->action, list);\n}\n\n \nstruct hci_conn_params *hci_conn_params_add(struct hci_dev *hdev,\n\t\t\t\t\t    bdaddr_t *addr, u8 addr_type)\n{\n\tstruct hci_conn_params *params;\n\n\tparams = hci_conn_params_lookup(hdev, addr, addr_type);\n\tif (params)\n\t\treturn params;\n\n\tparams = kzalloc(sizeof(*params), GFP_KERNEL);\n\tif (!params) {\n\t\tbt_dev_err(hdev, \"out of memory\");\n\t\treturn NULL;\n\t}\n\n\tbacpy(&params->addr, addr);\n\tparams->addr_type = addr_type;\n\n\tlist_add(&params->list, &hdev->le_conn_params);\n\tINIT_LIST_HEAD(&params->action);\n\n\tparams->conn_min_interval = hdev->le_conn_min_interval;\n\tparams->conn_max_interval = hdev->le_conn_max_interval;\n\tparams->conn_latency = hdev->le_conn_latency;\n\tparams->supervision_timeout = hdev->le_supv_timeout;\n\tparams->auto_connect = HCI_AUTO_CONN_DISABLED;\n\n\tBT_DBG(\"addr %pMR (type %u)\", addr, addr_type);\n\n\treturn params;\n}\n\nvoid hci_conn_params_free(struct hci_conn_params *params)\n{\n\thci_pend_le_list_del_init(params);\n\n\tif (params->conn) {\n\t\thci_conn_drop(params->conn);\n\t\thci_conn_put(params->conn);\n\t}\n\n\tlist_del(&params->list);\n\tkfree(params);\n}\n\n \nvoid hci_conn_params_del(struct hci_dev *hdev, bdaddr_t *addr, u8 addr_type)\n{\n\tstruct hci_conn_params *params;\n\n\tparams = hci_conn_params_lookup(hdev, addr, addr_type);\n\tif (!params)\n\t\treturn;\n\n\thci_conn_params_free(params);\n\n\thci_update_passive_scan(hdev);\n\n\tBT_DBG(\"addr %pMR (type %u)\", addr, addr_type);\n}\n\n \nvoid hci_conn_params_clear_disabled(struct hci_dev *hdev)\n{\n\tstruct hci_conn_params *params, *tmp;\n\n\tlist_for_each_entry_safe(params, tmp, &hdev->le_conn_params, list) {\n\t\tif (params->auto_connect != HCI_AUTO_CONN_DISABLED)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (params->explicit_connect) {\n\t\t\tparams->auto_connect = HCI_AUTO_CONN_EXPLICIT;\n\t\t\tcontinue;\n\t\t}\n\n\t\thci_conn_params_free(params);\n\t}\n\n\tBT_DBG(\"All LE disabled connection parameters were removed\");\n}\n\n \nstatic void hci_conn_params_clear_all(struct hci_dev *hdev)\n{\n\tstruct hci_conn_params *params, *tmp;\n\n\tlist_for_each_entry_safe(params, tmp, &hdev->le_conn_params, list)\n\t\thci_conn_params_free(params);\n\n\tBT_DBG(\"All LE connection parameters were removed\");\n}\n\n \nvoid hci_copy_identity_address(struct hci_dev *hdev, bdaddr_t *bdaddr,\n\t\t\t       u8 *bdaddr_type)\n{\n\tif (hci_dev_test_flag(hdev, HCI_FORCE_STATIC_ADDR) ||\n\t    !bacmp(&hdev->bdaddr, BDADDR_ANY) ||\n\t    (!hci_dev_test_flag(hdev, HCI_BREDR_ENABLED) &&\n\t     bacmp(&hdev->static_addr, BDADDR_ANY))) {\n\t\tbacpy(bdaddr, &hdev->static_addr);\n\t\t*bdaddr_type = ADDR_LE_DEV_RANDOM;\n\t} else {\n\t\tbacpy(bdaddr, &hdev->bdaddr);\n\t\t*bdaddr_type = ADDR_LE_DEV_PUBLIC;\n\t}\n}\n\nstatic void hci_clear_wake_reason(struct hci_dev *hdev)\n{\n\thci_dev_lock(hdev);\n\n\thdev->wake_reason = 0;\n\tbacpy(&hdev->wake_addr, BDADDR_ANY);\n\thdev->wake_addr_type = 0;\n\n\thci_dev_unlock(hdev);\n}\n\nstatic int hci_suspend_notifier(struct notifier_block *nb, unsigned long action,\n\t\t\t\tvoid *data)\n{\n\tstruct hci_dev *hdev =\n\t\tcontainer_of(nb, struct hci_dev, suspend_notifier);\n\tint ret = 0;\n\n\t \n\tif (hci_dev_test_flag(hdev, HCI_USER_CHANNEL))\n\t\treturn NOTIFY_DONE;\n\n\t \n\thci_dev_hold(hdev);\n\n\tif (action == PM_SUSPEND_PREPARE)\n\t\tret = hci_suspend_dev(hdev);\n\telse if (action == PM_POST_SUSPEND)\n\t\tret = hci_resume_dev(hdev);\n\n\tif (ret)\n\t\tbt_dev_err(hdev, \"Suspend notifier action (%lu) failed: %d\",\n\t\t\t   action, ret);\n\n\thci_dev_put(hdev);\n\treturn NOTIFY_DONE;\n}\n\n \nstruct hci_dev *hci_alloc_dev_priv(int sizeof_priv)\n{\n\tstruct hci_dev *hdev;\n\tunsigned int alloc_size;\n\n\talloc_size = sizeof(*hdev);\n\tif (sizeof_priv) {\n\t\t \n\t\talloc_size += sizeof_priv;\n\t}\n\n\thdev = kzalloc(alloc_size, GFP_KERNEL);\n\tif (!hdev)\n\t\treturn NULL;\n\n\thdev->pkt_type  = (HCI_DM1 | HCI_DH1 | HCI_HV1);\n\thdev->esco_type = (ESCO_HV1);\n\thdev->link_mode = (HCI_LM_ACCEPT);\n\thdev->num_iac = 0x01;\t\t \n\thdev->io_capability = 0x03;\t \n\thdev->manufacturer = 0xffff;\t \n\thdev->inq_tx_power = HCI_TX_POWER_INVALID;\n\thdev->adv_tx_power = HCI_TX_POWER_INVALID;\n\thdev->adv_instance_cnt = 0;\n\thdev->cur_adv_instance = 0x00;\n\thdev->adv_instance_timeout = 0;\n\n\thdev->advmon_allowlist_duration = 300;\n\thdev->advmon_no_filter_duration = 500;\n\thdev->enable_advmon_interleave_scan = 0x00;\t \n\n\thdev->sniff_max_interval = 800;\n\thdev->sniff_min_interval = 80;\n\n\thdev->le_adv_channel_map = 0x07;\n\thdev->le_adv_min_interval = 0x0800;\n\thdev->le_adv_max_interval = 0x0800;\n\thdev->le_scan_interval = 0x0060;\n\thdev->le_scan_window = 0x0030;\n\thdev->le_scan_int_suspend = 0x0400;\n\thdev->le_scan_window_suspend = 0x0012;\n\thdev->le_scan_int_discovery = DISCOV_LE_SCAN_INT;\n\thdev->le_scan_window_discovery = DISCOV_LE_SCAN_WIN;\n\thdev->le_scan_int_adv_monitor = 0x0060;\n\thdev->le_scan_window_adv_monitor = 0x0030;\n\thdev->le_scan_int_connect = 0x0060;\n\thdev->le_scan_window_connect = 0x0060;\n\thdev->le_conn_min_interval = 0x0018;\n\thdev->le_conn_max_interval = 0x0028;\n\thdev->le_conn_latency = 0x0000;\n\thdev->le_supv_timeout = 0x002a;\n\thdev->le_def_tx_len = 0x001b;\n\thdev->le_def_tx_time = 0x0148;\n\thdev->le_max_tx_len = 0x001b;\n\thdev->le_max_tx_time = 0x0148;\n\thdev->le_max_rx_len = 0x001b;\n\thdev->le_max_rx_time = 0x0148;\n\thdev->le_max_key_size = SMP_MAX_ENC_KEY_SIZE;\n\thdev->le_min_key_size = SMP_MIN_ENC_KEY_SIZE;\n\thdev->le_tx_def_phys = HCI_LE_SET_PHY_1M;\n\thdev->le_rx_def_phys = HCI_LE_SET_PHY_1M;\n\thdev->le_num_of_adv_sets = HCI_MAX_ADV_INSTANCES;\n\thdev->def_multi_adv_rotation_duration = HCI_DEFAULT_ADV_DURATION;\n\thdev->def_le_autoconnect_timeout = HCI_LE_AUTOCONN_TIMEOUT;\n\thdev->min_le_tx_power = HCI_TX_POWER_INVALID;\n\thdev->max_le_tx_power = HCI_TX_POWER_INVALID;\n\n\thdev->rpa_timeout = HCI_DEFAULT_RPA_TIMEOUT;\n\thdev->discov_interleaved_timeout = DISCOV_INTERLEAVED_TIMEOUT;\n\thdev->conn_info_min_age = DEFAULT_CONN_INFO_MIN_AGE;\n\thdev->conn_info_max_age = DEFAULT_CONN_INFO_MAX_AGE;\n\thdev->auth_payload_timeout = DEFAULT_AUTH_PAYLOAD_TIMEOUT;\n\thdev->min_enc_key_size = HCI_MIN_ENC_KEY_SIZE;\n\n\t \n\thdev->def_page_scan_type = PAGE_SCAN_TYPE_STANDARD;\n\thdev->def_page_scan_int = 0x0800;\n\thdev->def_page_scan_window = 0x0012;\n\n\tmutex_init(&hdev->lock);\n\tmutex_init(&hdev->req_lock);\n\n\tida_init(&hdev->unset_handle_ida);\n\n\tINIT_LIST_HEAD(&hdev->mesh_pending);\n\tINIT_LIST_HEAD(&hdev->mgmt_pending);\n\tINIT_LIST_HEAD(&hdev->reject_list);\n\tINIT_LIST_HEAD(&hdev->accept_list);\n\tINIT_LIST_HEAD(&hdev->uuids);\n\tINIT_LIST_HEAD(&hdev->link_keys);\n\tINIT_LIST_HEAD(&hdev->long_term_keys);\n\tINIT_LIST_HEAD(&hdev->identity_resolving_keys);\n\tINIT_LIST_HEAD(&hdev->remote_oob_data);\n\tINIT_LIST_HEAD(&hdev->le_accept_list);\n\tINIT_LIST_HEAD(&hdev->le_resolv_list);\n\tINIT_LIST_HEAD(&hdev->le_conn_params);\n\tINIT_LIST_HEAD(&hdev->pend_le_conns);\n\tINIT_LIST_HEAD(&hdev->pend_le_reports);\n\tINIT_LIST_HEAD(&hdev->conn_hash.list);\n\tINIT_LIST_HEAD(&hdev->adv_instances);\n\tINIT_LIST_HEAD(&hdev->blocked_keys);\n\tINIT_LIST_HEAD(&hdev->monitored_devices);\n\n\tINIT_LIST_HEAD(&hdev->local_codecs);\n\tINIT_WORK(&hdev->rx_work, hci_rx_work);\n\tINIT_WORK(&hdev->cmd_work, hci_cmd_work);\n\tINIT_WORK(&hdev->tx_work, hci_tx_work);\n\tINIT_WORK(&hdev->power_on, hci_power_on);\n\tINIT_WORK(&hdev->error_reset, hci_error_reset);\n\n\thci_cmd_sync_init(hdev);\n\n\tINIT_DELAYED_WORK(&hdev->power_off, hci_power_off);\n\n\tskb_queue_head_init(&hdev->rx_q);\n\tskb_queue_head_init(&hdev->cmd_q);\n\tskb_queue_head_init(&hdev->raw_q);\n\n\tinit_waitqueue_head(&hdev->req_wait_q);\n\n\tINIT_DELAYED_WORK(&hdev->cmd_timer, hci_cmd_timeout);\n\tINIT_DELAYED_WORK(&hdev->ncmd_timer, hci_ncmd_timeout);\n\n\thci_devcd_setup(hdev);\n\thci_request_setup(hdev);\n\n\thci_init_sysfs(hdev);\n\tdiscovery_init(hdev);\n\n\treturn hdev;\n}\nEXPORT_SYMBOL(hci_alloc_dev_priv);\n\n \nvoid hci_free_dev(struct hci_dev *hdev)\n{\n\t \n\tput_device(&hdev->dev);\n}\nEXPORT_SYMBOL(hci_free_dev);\n\n \nint hci_register_dev(struct hci_dev *hdev)\n{\n\tint id, error;\n\n\tif (!hdev->open || !hdev->close || !hdev->send)\n\t\treturn -EINVAL;\n\n\t \n\tswitch (hdev->dev_type) {\n\tcase HCI_PRIMARY:\n\t\tid = ida_simple_get(&hci_index_ida, 0, HCI_MAX_ID, GFP_KERNEL);\n\t\tbreak;\n\tcase HCI_AMP:\n\t\tid = ida_simple_get(&hci_index_ida, 1, HCI_MAX_ID, GFP_KERNEL);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (id < 0)\n\t\treturn id;\n\n\terror = dev_set_name(&hdev->dev, \"hci%u\", id);\n\tif (error)\n\t\treturn error;\n\n\thdev->name = dev_name(&hdev->dev);\n\thdev->id = id;\n\n\tBT_DBG(\"%p name %s bus %d\", hdev, hdev->name, hdev->bus);\n\n\thdev->workqueue = alloc_ordered_workqueue(\"%s\", WQ_HIGHPRI, hdev->name);\n\tif (!hdev->workqueue) {\n\t\terror = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\thdev->req_workqueue = alloc_ordered_workqueue(\"%s\", WQ_HIGHPRI,\n\t\t\t\t\t\t      hdev->name);\n\tif (!hdev->req_workqueue) {\n\t\tdestroy_workqueue(hdev->workqueue);\n\t\terror = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tif (!IS_ERR_OR_NULL(bt_debugfs))\n\t\thdev->debugfs = debugfs_create_dir(hdev->name, bt_debugfs);\n\n\terror = device_add(&hdev->dev);\n\tif (error < 0)\n\t\tgoto err_wqueue;\n\n\thci_leds_init(hdev);\n\n\thdev->rfkill = rfkill_alloc(hdev->name, &hdev->dev,\n\t\t\t\t    RFKILL_TYPE_BLUETOOTH, &hci_rfkill_ops,\n\t\t\t\t    hdev);\n\tif (hdev->rfkill) {\n\t\tif (rfkill_register(hdev->rfkill) < 0) {\n\t\t\trfkill_destroy(hdev->rfkill);\n\t\t\thdev->rfkill = NULL;\n\t\t}\n\t}\n\n\tif (hdev->rfkill && rfkill_blocked(hdev->rfkill))\n\t\thci_dev_set_flag(hdev, HCI_RFKILLED);\n\n\thci_dev_set_flag(hdev, HCI_SETUP);\n\thci_dev_set_flag(hdev, HCI_AUTO_OFF);\n\n\tif (hdev->dev_type == HCI_PRIMARY) {\n\t\t \n\t\thci_dev_set_flag(hdev, HCI_BREDR_ENABLED);\n\t}\n\n\twrite_lock(&hci_dev_list_lock);\n\tlist_add(&hdev->list, &hci_dev_list);\n\twrite_unlock(&hci_dev_list_lock);\n\n\t \n\tif (test_bit(HCI_QUIRK_RAW_DEVICE, &hdev->quirks))\n\t\thci_dev_set_flag(hdev, HCI_UNCONFIGURED);\n\n\t \n\tif (hdev->wakeup)\n\t\thdev->conn_flags |= HCI_CONN_FLAG_REMOTE_WAKEUP;\n\n\thci_sock_dev_event(hdev, HCI_DEV_REG);\n\thci_dev_hold(hdev);\n\n\terror = hci_register_suspend_notifier(hdev);\n\tif (error)\n\t\tBT_WARN(\"register suspend notifier failed error:%d\\n\", error);\n\n\tqueue_work(hdev->req_workqueue, &hdev->power_on);\n\n\tidr_init(&hdev->adv_monitors_idr);\n\tmsft_register(hdev);\n\n\treturn id;\n\nerr_wqueue:\n\tdebugfs_remove_recursive(hdev->debugfs);\n\tdestroy_workqueue(hdev->workqueue);\n\tdestroy_workqueue(hdev->req_workqueue);\nerr:\n\tida_simple_remove(&hci_index_ida, hdev->id);\n\n\treturn error;\n}\nEXPORT_SYMBOL(hci_register_dev);\n\n \nvoid hci_unregister_dev(struct hci_dev *hdev)\n{\n\tBT_DBG(\"%p name %s bus %d\", hdev, hdev->name, hdev->bus);\n\n\tmutex_lock(&hdev->unregister_lock);\n\thci_dev_set_flag(hdev, HCI_UNREGISTER);\n\tmutex_unlock(&hdev->unregister_lock);\n\n\twrite_lock(&hci_dev_list_lock);\n\tlist_del(&hdev->list);\n\twrite_unlock(&hci_dev_list_lock);\n\n\tcancel_work_sync(&hdev->power_on);\n\n\thci_cmd_sync_clear(hdev);\n\n\thci_unregister_suspend_notifier(hdev);\n\n\tmsft_unregister(hdev);\n\n\thci_dev_do_close(hdev);\n\n\tif (!test_bit(HCI_INIT, &hdev->flags) &&\n\t    !hci_dev_test_flag(hdev, HCI_SETUP) &&\n\t    !hci_dev_test_flag(hdev, HCI_CONFIG)) {\n\t\thci_dev_lock(hdev);\n\t\tmgmt_index_removed(hdev);\n\t\thci_dev_unlock(hdev);\n\t}\n\n\t \n\tBUG_ON(!list_empty(&hdev->mgmt_pending));\n\n\thci_sock_dev_event(hdev, HCI_DEV_UNREG);\n\n\tif (hdev->rfkill) {\n\t\trfkill_unregister(hdev->rfkill);\n\t\trfkill_destroy(hdev->rfkill);\n\t}\n\n\tdevice_del(&hdev->dev);\n\t \n\thci_dev_put(hdev);\n}\nEXPORT_SYMBOL(hci_unregister_dev);\n\n \nvoid hci_release_dev(struct hci_dev *hdev)\n{\n\tdebugfs_remove_recursive(hdev->debugfs);\n\tkfree_const(hdev->hw_info);\n\tkfree_const(hdev->fw_info);\n\n\tdestroy_workqueue(hdev->workqueue);\n\tdestroy_workqueue(hdev->req_workqueue);\n\n\thci_dev_lock(hdev);\n\thci_bdaddr_list_clear(&hdev->reject_list);\n\thci_bdaddr_list_clear(&hdev->accept_list);\n\thci_uuids_clear(hdev);\n\thci_link_keys_clear(hdev);\n\thci_smp_ltks_clear(hdev);\n\thci_smp_irks_clear(hdev);\n\thci_remote_oob_data_clear(hdev);\n\thci_adv_instances_clear(hdev);\n\thci_adv_monitors_clear(hdev);\n\thci_bdaddr_list_clear(&hdev->le_accept_list);\n\thci_bdaddr_list_clear(&hdev->le_resolv_list);\n\thci_conn_params_clear_all(hdev);\n\thci_discovery_filter_clear(hdev);\n\thci_blocked_keys_clear(hdev);\n\thci_codec_list_clear(&hdev->local_codecs);\n\thci_dev_unlock(hdev);\n\n\tida_destroy(&hdev->unset_handle_ida);\n\tida_simple_remove(&hci_index_ida, hdev->id);\n\tkfree_skb(hdev->sent_cmd);\n\tkfree_skb(hdev->recv_event);\n\tkfree(hdev);\n}\nEXPORT_SYMBOL(hci_release_dev);\n\nint hci_register_suspend_notifier(struct hci_dev *hdev)\n{\n\tint ret = 0;\n\n\tif (!hdev->suspend_notifier.notifier_call &&\n\t    !test_bit(HCI_QUIRK_NO_SUSPEND_NOTIFIER, &hdev->quirks)) {\n\t\thdev->suspend_notifier.notifier_call = hci_suspend_notifier;\n\t\tret = register_pm_notifier(&hdev->suspend_notifier);\n\t}\n\n\treturn ret;\n}\n\nint hci_unregister_suspend_notifier(struct hci_dev *hdev)\n{\n\tint ret = 0;\n\n\tif (hdev->suspend_notifier.notifier_call) {\n\t\tret = unregister_pm_notifier(&hdev->suspend_notifier);\n\t\tif (!ret)\n\t\t\thdev->suspend_notifier.notifier_call = NULL;\n\t}\n\n\treturn ret;\n}\n\n \nint hci_suspend_dev(struct hci_dev *hdev)\n{\n\tint ret;\n\n\tbt_dev_dbg(hdev, \"\");\n\n\t \n\tif (!hdev_is_powered(hdev) ||\n\t    hci_dev_test_flag(hdev, HCI_UNREGISTER))\n\t\treturn 0;\n\n\t \n\tif (mgmt_powering_down(hdev))\n\t\treturn 0;\n\n\t \n\t__hci_cmd_sync_cancel(hdev, -EHOSTDOWN);\n\n\thci_req_sync_lock(hdev);\n\tret = hci_suspend_sync(hdev);\n\thci_req_sync_unlock(hdev);\n\n\thci_clear_wake_reason(hdev);\n\tmgmt_suspending(hdev, hdev->suspend_state);\n\n\thci_sock_dev_event(hdev, HCI_DEV_SUSPEND);\n\treturn ret;\n}\nEXPORT_SYMBOL(hci_suspend_dev);\n\n \nint hci_resume_dev(struct hci_dev *hdev)\n{\n\tint ret;\n\n\tbt_dev_dbg(hdev, \"\");\n\n\t \n\tif (!hdev_is_powered(hdev) ||\n\t    hci_dev_test_flag(hdev, HCI_UNREGISTER))\n\t\treturn 0;\n\n\t \n\tif (mgmt_powering_down(hdev))\n\t\treturn 0;\n\n\thci_req_sync_lock(hdev);\n\tret = hci_resume_sync(hdev);\n\thci_req_sync_unlock(hdev);\n\n\tmgmt_resuming(hdev, hdev->wake_reason, &hdev->wake_addr,\n\t\t      hdev->wake_addr_type);\n\n\thci_sock_dev_event(hdev, HCI_DEV_RESUME);\n\treturn ret;\n}\nEXPORT_SYMBOL(hci_resume_dev);\n\n \nint hci_reset_dev(struct hci_dev *hdev)\n{\n\tstatic const u8 hw_err[] = { HCI_EV_HARDWARE_ERROR, 0x01, 0x00 };\n\tstruct sk_buff *skb;\n\n\tskb = bt_skb_alloc(3, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\thci_skb_pkt_type(skb) = HCI_EVENT_PKT;\n\tskb_put_data(skb, hw_err, 3);\n\n\tbt_dev_err(hdev, \"Injecting HCI hardware error event\");\n\n\t \n\treturn hci_recv_frame(hdev, skb);\n}\nEXPORT_SYMBOL(hci_reset_dev);\n\n \nint hci_recv_frame(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\tif (!hdev || (!test_bit(HCI_UP, &hdev->flags)\n\t\t      && !test_bit(HCI_INIT, &hdev->flags))) {\n\t\tkfree_skb(skb);\n\t\treturn -ENXIO;\n\t}\n\n\tswitch (hci_skb_pkt_type(skb)) {\n\tcase HCI_EVENT_PKT:\n\t\tbreak;\n\tcase HCI_ACLDATA_PKT:\n\t\t \n\t\tif (hci_conn_num(hdev, ISO_LINK)) {\n\t\t\t__u16 handle = __le16_to_cpu(hci_acl_hdr(skb)->handle);\n\t\t\t__u8 type;\n\n\t\t\ttype = hci_conn_lookup_type(hdev, hci_handle(handle));\n\t\t\tif (type == ISO_LINK)\n\t\t\t\thci_skb_pkt_type(skb) = HCI_ISODATA_PKT;\n\t\t}\n\t\tbreak;\n\tcase HCI_SCODATA_PKT:\n\t\tbreak;\n\tcase HCI_ISODATA_PKT:\n\t\tbreak;\n\tdefault:\n\t\tkfree_skb(skb);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tbt_cb(skb)->incoming = 1;\n\n\t \n\t__net_timestamp(skb);\n\n\tskb_queue_tail(&hdev->rx_q, skb);\n\tqueue_work(hdev->workqueue, &hdev->rx_work);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(hci_recv_frame);\n\n \nint hci_recv_diag(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\t \n\thci_skb_pkt_type(skb) = HCI_DIAG_PKT;\n\n\t \n\t__net_timestamp(skb);\n\n\tskb_queue_tail(&hdev->rx_q, skb);\n\tqueue_work(hdev->workqueue, &hdev->rx_work);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(hci_recv_diag);\n\nvoid hci_set_hw_info(struct hci_dev *hdev, const char *fmt, ...)\n{\n\tva_list vargs;\n\n\tva_start(vargs, fmt);\n\tkfree_const(hdev->hw_info);\n\thdev->hw_info = kvasprintf_const(GFP_KERNEL, fmt, vargs);\n\tva_end(vargs);\n}\nEXPORT_SYMBOL(hci_set_hw_info);\n\nvoid hci_set_fw_info(struct hci_dev *hdev, const char *fmt, ...)\n{\n\tva_list vargs;\n\n\tva_start(vargs, fmt);\n\tkfree_const(hdev->fw_info);\n\thdev->fw_info = kvasprintf_const(GFP_KERNEL, fmt, vargs);\n\tva_end(vargs);\n}\nEXPORT_SYMBOL(hci_set_fw_info);\n\n \n\nint hci_register_cb(struct hci_cb *cb)\n{\n\tBT_DBG(\"%p name %s\", cb, cb->name);\n\n\tmutex_lock(&hci_cb_list_lock);\n\tlist_add_tail(&cb->list, &hci_cb_list);\n\tmutex_unlock(&hci_cb_list_lock);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(hci_register_cb);\n\nint hci_unregister_cb(struct hci_cb *cb)\n{\n\tBT_DBG(\"%p name %s\", cb, cb->name);\n\n\tmutex_lock(&hci_cb_list_lock);\n\tlist_del(&cb->list);\n\tmutex_unlock(&hci_cb_list_lock);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(hci_unregister_cb);\n\nstatic int hci_send_frame(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\tint err;\n\n\tBT_DBG(\"%s type %d len %d\", hdev->name, hci_skb_pkt_type(skb),\n\t       skb->len);\n\n\t \n\t__net_timestamp(skb);\n\n\t \n\thci_send_to_monitor(hdev, skb);\n\n\tif (atomic_read(&hdev->promisc)) {\n\t\t \n\t\thci_send_to_sock(hdev, skb);\n\t}\n\n\t \n\tskb_orphan(skb);\n\n\tif (!test_bit(HCI_RUNNING, &hdev->flags)) {\n\t\tkfree_skb(skb);\n\t\treturn -EINVAL;\n\t}\n\n\terr = hdev->send(hdev, skb);\n\tif (err < 0) {\n\t\tbt_dev_err(hdev, \"sending frame failed (%d)\", err);\n\t\tkfree_skb(skb);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\n \nint hci_send_cmd(struct hci_dev *hdev, __u16 opcode, __u32 plen,\n\t\t const void *param)\n{\n\tstruct sk_buff *skb;\n\n\tBT_DBG(\"%s opcode 0x%4.4x plen %d\", hdev->name, opcode, plen);\n\n\tskb = hci_prepare_cmd(hdev, opcode, plen, param);\n\tif (!skb) {\n\t\tbt_dev_err(hdev, \"no memory for command\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tbt_cb(skb)->hci.req_flags |= HCI_REQ_START;\n\n\tskb_queue_tail(&hdev->cmd_q, skb);\n\tqueue_work(hdev->workqueue, &hdev->cmd_work);\n\n\treturn 0;\n}\n\nint __hci_cmd_send(struct hci_dev *hdev, u16 opcode, u32 plen,\n\t\t   const void *param)\n{\n\tstruct sk_buff *skb;\n\n\tif (hci_opcode_ogf(opcode) != 0x3f) {\n\t\t \n\t\tbt_dev_err(hdev, \"unresponded command not supported\");\n\t\treturn -EINVAL;\n\t}\n\n\tskb = hci_prepare_cmd(hdev, opcode, plen, param);\n\tif (!skb) {\n\t\tbt_dev_err(hdev, \"no memory for command (opcode 0x%4.4x)\",\n\t\t\t   opcode);\n\t\treturn -ENOMEM;\n\t}\n\n\thci_send_frame(hdev, skb);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(__hci_cmd_send);\n\n \nvoid *hci_sent_cmd_data(struct hci_dev *hdev, __u16 opcode)\n{\n\tstruct hci_command_hdr *hdr;\n\n\tif (!hdev->sent_cmd)\n\t\treturn NULL;\n\n\thdr = (void *) hdev->sent_cmd->data;\n\n\tif (hdr->opcode != cpu_to_le16(opcode))\n\t\treturn NULL;\n\n\tBT_DBG(\"%s opcode 0x%4.4x\", hdev->name, opcode);\n\n\treturn hdev->sent_cmd->data + HCI_COMMAND_HDR_SIZE;\n}\n\n \nvoid *hci_recv_event_data(struct hci_dev *hdev, __u8 event)\n{\n\tstruct hci_event_hdr *hdr;\n\tint offset;\n\n\tif (!hdev->recv_event)\n\t\treturn NULL;\n\n\thdr = (void *)hdev->recv_event->data;\n\toffset = sizeof(*hdr);\n\n\tif (hdr->evt != event) {\n\t\t \n\t\tif (hdr->evt == HCI_EV_LE_META) {\n\t\t\tstruct hci_ev_le_meta *ev;\n\n\t\t\tev = (void *)hdev->recv_event->data + offset;\n\t\t\toffset += sizeof(*ev);\n\t\t\tif (ev->subevent == event)\n\t\t\t\tgoto found;\n\t\t}\n\t\treturn NULL;\n\t}\n\nfound:\n\tbt_dev_dbg(hdev, \"event 0x%2.2x\", event);\n\n\treturn hdev->recv_event->data + offset;\n}\n\n \nstatic void hci_add_acl_hdr(struct sk_buff *skb, __u16 handle, __u16 flags)\n{\n\tstruct hci_acl_hdr *hdr;\n\tint len = skb->len;\n\n\tskb_push(skb, HCI_ACL_HDR_SIZE);\n\tskb_reset_transport_header(skb);\n\thdr = (struct hci_acl_hdr *)skb_transport_header(skb);\n\thdr->handle = cpu_to_le16(hci_handle_pack(handle, flags));\n\thdr->dlen   = cpu_to_le16(len);\n}\n\nstatic void hci_queue_acl(struct hci_chan *chan, struct sk_buff_head *queue,\n\t\t\t  struct sk_buff *skb, __u16 flags)\n{\n\tstruct hci_conn *conn = chan->conn;\n\tstruct hci_dev *hdev = conn->hdev;\n\tstruct sk_buff *list;\n\n\tskb->len = skb_headlen(skb);\n\tskb->data_len = 0;\n\n\thci_skb_pkt_type(skb) = HCI_ACLDATA_PKT;\n\n\tswitch (hdev->dev_type) {\n\tcase HCI_PRIMARY:\n\t\thci_add_acl_hdr(skb, conn->handle, flags);\n\t\tbreak;\n\tcase HCI_AMP:\n\t\thci_add_acl_hdr(skb, chan->handle, flags);\n\t\tbreak;\n\tdefault:\n\t\tbt_dev_err(hdev, \"unknown dev_type %d\", hdev->dev_type);\n\t\treturn;\n\t}\n\n\tlist = skb_shinfo(skb)->frag_list;\n\tif (!list) {\n\t\t \n\t\tBT_DBG(\"%s nonfrag skb %p len %d\", hdev->name, skb, skb->len);\n\n\t\tskb_queue_tail(queue, skb);\n\t} else {\n\t\t \n\t\tBT_DBG(\"%s frag %p len %d\", hdev->name, skb, skb->len);\n\n\t\tskb_shinfo(skb)->frag_list = NULL;\n\n\t\t \n\t\tspin_lock_bh(&queue->lock);\n\n\t\t__skb_queue_tail(queue, skb);\n\n\t\tflags &= ~ACL_START;\n\t\tflags |= ACL_CONT;\n\t\tdo {\n\t\t\tskb = list; list = list->next;\n\n\t\t\thci_skb_pkt_type(skb) = HCI_ACLDATA_PKT;\n\t\t\thci_add_acl_hdr(skb, conn->handle, flags);\n\n\t\t\tBT_DBG(\"%s frag %p len %d\", hdev->name, skb, skb->len);\n\n\t\t\t__skb_queue_tail(queue, skb);\n\t\t} while (list);\n\n\t\tspin_unlock_bh(&queue->lock);\n\t}\n}\n\nvoid hci_send_acl(struct hci_chan *chan, struct sk_buff *skb, __u16 flags)\n{\n\tstruct hci_dev *hdev = chan->conn->hdev;\n\n\tBT_DBG(\"%s chan %p flags 0x%4.4x\", hdev->name, chan, flags);\n\n\thci_queue_acl(chan, &chan->data_q, skb, flags);\n\n\tqueue_work(hdev->workqueue, &hdev->tx_work);\n}\n\n \nvoid hci_send_sco(struct hci_conn *conn, struct sk_buff *skb)\n{\n\tstruct hci_dev *hdev = conn->hdev;\n\tstruct hci_sco_hdr hdr;\n\n\tBT_DBG(\"%s len %d\", hdev->name, skb->len);\n\n\thdr.handle = cpu_to_le16(conn->handle);\n\thdr.dlen   = skb->len;\n\n\tskb_push(skb, HCI_SCO_HDR_SIZE);\n\tskb_reset_transport_header(skb);\n\tmemcpy(skb_transport_header(skb), &hdr, HCI_SCO_HDR_SIZE);\n\n\thci_skb_pkt_type(skb) = HCI_SCODATA_PKT;\n\n\tskb_queue_tail(&conn->data_q, skb);\n\tqueue_work(hdev->workqueue, &hdev->tx_work);\n}\n\n \nstatic void hci_add_iso_hdr(struct sk_buff *skb, __u16 handle, __u8 flags)\n{\n\tstruct hci_iso_hdr *hdr;\n\tint len = skb->len;\n\n\tskb_push(skb, HCI_ISO_HDR_SIZE);\n\tskb_reset_transport_header(skb);\n\thdr = (struct hci_iso_hdr *)skb_transport_header(skb);\n\thdr->handle = cpu_to_le16(hci_handle_pack(handle, flags));\n\thdr->dlen   = cpu_to_le16(len);\n}\n\nstatic void hci_queue_iso(struct hci_conn *conn, struct sk_buff_head *queue,\n\t\t\t  struct sk_buff *skb)\n{\n\tstruct hci_dev *hdev = conn->hdev;\n\tstruct sk_buff *list;\n\t__u16 flags;\n\n\tskb->len = skb_headlen(skb);\n\tskb->data_len = 0;\n\n\thci_skb_pkt_type(skb) = HCI_ISODATA_PKT;\n\n\tlist = skb_shinfo(skb)->frag_list;\n\n\tflags = hci_iso_flags_pack(list ? ISO_START : ISO_SINGLE, 0x00);\n\thci_add_iso_hdr(skb, conn->handle, flags);\n\n\tif (!list) {\n\t\t \n\t\tBT_DBG(\"%s nonfrag skb %p len %d\", hdev->name, skb, skb->len);\n\n\t\tskb_queue_tail(queue, skb);\n\t} else {\n\t\t \n\t\tBT_DBG(\"%s frag %p len %d\", hdev->name, skb, skb->len);\n\n\t\tskb_shinfo(skb)->frag_list = NULL;\n\n\t\t__skb_queue_tail(queue, skb);\n\n\t\tdo {\n\t\t\tskb = list; list = list->next;\n\n\t\t\thci_skb_pkt_type(skb) = HCI_ISODATA_PKT;\n\t\t\tflags = hci_iso_flags_pack(list ? ISO_CONT : ISO_END,\n\t\t\t\t\t\t   0x00);\n\t\t\thci_add_iso_hdr(skb, conn->handle, flags);\n\n\t\t\tBT_DBG(\"%s frag %p len %d\", hdev->name, skb, skb->len);\n\n\t\t\t__skb_queue_tail(queue, skb);\n\t\t} while (list);\n\t}\n}\n\nvoid hci_send_iso(struct hci_conn *conn, struct sk_buff *skb)\n{\n\tstruct hci_dev *hdev = conn->hdev;\n\n\tBT_DBG(\"%s len %d\", hdev->name, skb->len);\n\n\thci_queue_iso(conn, &conn->data_q, skb);\n\n\tqueue_work(hdev->workqueue, &hdev->tx_work);\n}\n\n \n\n \nstatic inline void hci_quote_sent(struct hci_conn *conn, int num, int *quote)\n{\n\tstruct hci_dev *hdev;\n\tint cnt, q;\n\n\tif (!conn) {\n\t\t*quote = 0;\n\t\treturn;\n\t}\n\n\thdev = conn->hdev;\n\n\tswitch (conn->type) {\n\tcase ACL_LINK:\n\t\tcnt = hdev->acl_cnt;\n\t\tbreak;\n\tcase AMP_LINK:\n\t\tcnt = hdev->block_cnt;\n\t\tbreak;\n\tcase SCO_LINK:\n\tcase ESCO_LINK:\n\t\tcnt = hdev->sco_cnt;\n\t\tbreak;\n\tcase LE_LINK:\n\t\tcnt = hdev->le_mtu ? hdev->le_cnt : hdev->acl_cnt;\n\t\tbreak;\n\tcase ISO_LINK:\n\t\tcnt = hdev->iso_mtu ? hdev->iso_cnt :\n\t\t\thdev->le_mtu ? hdev->le_cnt : hdev->acl_cnt;\n\t\tbreak;\n\tdefault:\n\t\tcnt = 0;\n\t\tbt_dev_err(hdev, \"unknown link type %d\", conn->type);\n\t}\n\n\tq = cnt / num;\n\t*quote = q ? q : 1;\n}\n\nstatic struct hci_conn *hci_low_sent(struct hci_dev *hdev, __u8 type,\n\t\t\t\t     int *quote)\n{\n\tstruct hci_conn_hash *h = &hdev->conn_hash;\n\tstruct hci_conn *conn = NULL, *c;\n\tunsigned int num = 0, min = ~0;\n\n\t \n\n\trcu_read_lock();\n\n\tlist_for_each_entry_rcu(c, &h->list, list) {\n\t\tif (c->type != type || skb_queue_empty(&c->data_q))\n\t\t\tcontinue;\n\n\t\tif (c->state != BT_CONNECTED && c->state != BT_CONFIG)\n\t\t\tcontinue;\n\n\t\tnum++;\n\n\t\tif (c->sent < min) {\n\t\t\tmin  = c->sent;\n\t\t\tconn = c;\n\t\t}\n\n\t\tif (hci_conn_num(hdev, type) == num)\n\t\t\tbreak;\n\t}\n\n\trcu_read_unlock();\n\n\thci_quote_sent(conn, num, quote);\n\n\tBT_DBG(\"conn %p quote %d\", conn, *quote);\n\treturn conn;\n}\n\nstatic void hci_link_tx_to(struct hci_dev *hdev, __u8 type)\n{\n\tstruct hci_conn_hash *h = &hdev->conn_hash;\n\tstruct hci_conn *c;\n\n\tbt_dev_err(hdev, \"link tx timeout\");\n\n\trcu_read_lock();\n\n\t \n\tlist_for_each_entry_rcu(c, &h->list, list) {\n\t\tif (c->type == type && c->sent) {\n\t\t\tbt_dev_err(hdev, \"killing stalled connection %pMR\",\n\t\t\t\t   &c->dst);\n\t\t\t \n\t\t\trcu_read_unlock();\n\t\t\thci_disconnect(c, HCI_ERROR_REMOTE_USER_TERM);\n\t\t\trcu_read_lock();\n\t\t}\n\t}\n\n\trcu_read_unlock();\n}\n\nstatic struct hci_chan *hci_chan_sent(struct hci_dev *hdev, __u8 type,\n\t\t\t\t      int *quote)\n{\n\tstruct hci_conn_hash *h = &hdev->conn_hash;\n\tstruct hci_chan *chan = NULL;\n\tunsigned int num = 0, min = ~0, cur_prio = 0;\n\tstruct hci_conn *conn;\n\tint conn_num = 0;\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\trcu_read_lock();\n\n\tlist_for_each_entry_rcu(conn, &h->list, list) {\n\t\tstruct hci_chan *tmp;\n\n\t\tif (conn->type != type)\n\t\t\tcontinue;\n\n\t\tif (conn->state != BT_CONNECTED && conn->state != BT_CONFIG)\n\t\t\tcontinue;\n\n\t\tconn_num++;\n\n\t\tlist_for_each_entry_rcu(tmp, &conn->chan_list, list) {\n\t\t\tstruct sk_buff *skb;\n\n\t\t\tif (skb_queue_empty(&tmp->data_q))\n\t\t\t\tcontinue;\n\n\t\t\tskb = skb_peek(&tmp->data_q);\n\t\t\tif (skb->priority < cur_prio)\n\t\t\t\tcontinue;\n\n\t\t\tif (skb->priority > cur_prio) {\n\t\t\t\tnum = 0;\n\t\t\t\tmin = ~0;\n\t\t\t\tcur_prio = skb->priority;\n\t\t\t}\n\n\t\t\tnum++;\n\n\t\t\tif (conn->sent < min) {\n\t\t\t\tmin  = conn->sent;\n\t\t\t\tchan = tmp;\n\t\t\t}\n\t\t}\n\n\t\tif (hci_conn_num(hdev, type) == conn_num)\n\t\t\tbreak;\n\t}\n\n\trcu_read_unlock();\n\n\tif (!chan)\n\t\treturn NULL;\n\n\thci_quote_sent(chan->conn, num, quote);\n\n\tBT_DBG(\"chan %p quote %d\", chan, *quote);\n\treturn chan;\n}\n\nstatic void hci_prio_recalculate(struct hci_dev *hdev, __u8 type)\n{\n\tstruct hci_conn_hash *h = &hdev->conn_hash;\n\tstruct hci_conn *conn;\n\tint num = 0;\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\trcu_read_lock();\n\n\tlist_for_each_entry_rcu(conn, &h->list, list) {\n\t\tstruct hci_chan *chan;\n\n\t\tif (conn->type != type)\n\t\t\tcontinue;\n\n\t\tif (conn->state != BT_CONNECTED && conn->state != BT_CONFIG)\n\t\t\tcontinue;\n\n\t\tnum++;\n\n\t\tlist_for_each_entry_rcu(chan, &conn->chan_list, list) {\n\t\t\tstruct sk_buff *skb;\n\n\t\t\tif (chan->sent) {\n\t\t\t\tchan->sent = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (skb_queue_empty(&chan->data_q))\n\t\t\t\tcontinue;\n\n\t\t\tskb = skb_peek(&chan->data_q);\n\t\t\tif (skb->priority >= HCI_PRIO_MAX - 1)\n\t\t\t\tcontinue;\n\n\t\t\tskb->priority = HCI_PRIO_MAX - 1;\n\n\t\t\tBT_DBG(\"chan %p skb %p promoted to %d\", chan, skb,\n\t\t\t       skb->priority);\n\t\t}\n\n\t\tif (hci_conn_num(hdev, type) == num)\n\t\t\tbreak;\n\t}\n\n\trcu_read_unlock();\n\n}\n\nstatic inline int __get_blocks(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\t \n\treturn DIV_ROUND_UP(skb->len - HCI_ACL_HDR_SIZE, hdev->block_len);\n}\n\nstatic void __check_timeout(struct hci_dev *hdev, unsigned int cnt, u8 type)\n{\n\tunsigned long last_tx;\n\n\tif (hci_dev_test_flag(hdev, HCI_UNCONFIGURED))\n\t\treturn;\n\n\tswitch (type) {\n\tcase LE_LINK:\n\t\tlast_tx = hdev->le_last_tx;\n\t\tbreak;\n\tdefault:\n\t\tlast_tx = hdev->acl_last_tx;\n\t\tbreak;\n\t}\n\n\t \n\tif (!cnt && time_after(jiffies, last_tx + HCI_ACL_TX_TIMEOUT))\n\t\thci_link_tx_to(hdev, type);\n}\n\n \nstatic void hci_sched_sco(struct hci_dev *hdev)\n{\n\tstruct hci_conn *conn;\n\tstruct sk_buff *skb;\n\tint quote;\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\tif (!hci_conn_num(hdev, SCO_LINK))\n\t\treturn;\n\n\twhile (hdev->sco_cnt && (conn = hci_low_sent(hdev, SCO_LINK, &quote))) {\n\t\twhile (quote-- && (skb = skb_dequeue(&conn->data_q))) {\n\t\t\tBT_DBG(\"skb %p len %d\", skb, skb->len);\n\t\t\thci_send_frame(hdev, skb);\n\n\t\t\tconn->sent++;\n\t\t\tif (conn->sent == ~0)\n\t\t\t\tconn->sent = 0;\n\t\t}\n\t}\n}\n\nstatic void hci_sched_esco(struct hci_dev *hdev)\n{\n\tstruct hci_conn *conn;\n\tstruct sk_buff *skb;\n\tint quote;\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\tif (!hci_conn_num(hdev, ESCO_LINK))\n\t\treturn;\n\n\twhile (hdev->sco_cnt && (conn = hci_low_sent(hdev, ESCO_LINK,\n\t\t\t\t\t\t     &quote))) {\n\t\twhile (quote-- && (skb = skb_dequeue(&conn->data_q))) {\n\t\t\tBT_DBG(\"skb %p len %d\", skb, skb->len);\n\t\t\thci_send_frame(hdev, skb);\n\n\t\t\tconn->sent++;\n\t\t\tif (conn->sent == ~0)\n\t\t\t\tconn->sent = 0;\n\t\t}\n\t}\n}\n\nstatic void hci_sched_acl_pkt(struct hci_dev *hdev)\n{\n\tunsigned int cnt = hdev->acl_cnt;\n\tstruct hci_chan *chan;\n\tstruct sk_buff *skb;\n\tint quote;\n\n\t__check_timeout(hdev, cnt, ACL_LINK);\n\n\twhile (hdev->acl_cnt &&\n\t       (chan = hci_chan_sent(hdev, ACL_LINK, &quote))) {\n\t\tu32 priority = (skb_peek(&chan->data_q))->priority;\n\t\twhile (quote-- && (skb = skb_peek(&chan->data_q))) {\n\t\t\tBT_DBG(\"chan %p skb %p len %d priority %u\", chan, skb,\n\t\t\t       skb->len, skb->priority);\n\n\t\t\t \n\t\t\tif (skb->priority < priority)\n\t\t\t\tbreak;\n\n\t\t\tskb = skb_dequeue(&chan->data_q);\n\n\t\t\thci_conn_enter_active_mode(chan->conn,\n\t\t\t\t\t\t   bt_cb(skb)->force_active);\n\n\t\t\thci_send_frame(hdev, skb);\n\t\t\thdev->acl_last_tx = jiffies;\n\n\t\t\thdev->acl_cnt--;\n\t\t\tchan->sent++;\n\t\t\tchan->conn->sent++;\n\n\t\t\t \n\t\t\thci_sched_sco(hdev);\n\t\t\thci_sched_esco(hdev);\n\t\t}\n\t}\n\n\tif (cnt != hdev->acl_cnt)\n\t\thci_prio_recalculate(hdev, ACL_LINK);\n}\n\nstatic void hci_sched_acl_blk(struct hci_dev *hdev)\n{\n\tunsigned int cnt = hdev->block_cnt;\n\tstruct hci_chan *chan;\n\tstruct sk_buff *skb;\n\tint quote;\n\tu8 type;\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\tif (hdev->dev_type == HCI_AMP)\n\t\ttype = AMP_LINK;\n\telse\n\t\ttype = ACL_LINK;\n\n\t__check_timeout(hdev, cnt, type);\n\n\twhile (hdev->block_cnt > 0 &&\n\t       (chan = hci_chan_sent(hdev, type, &quote))) {\n\t\tu32 priority = (skb_peek(&chan->data_q))->priority;\n\t\twhile (quote > 0 && (skb = skb_peek(&chan->data_q))) {\n\t\t\tint blocks;\n\n\t\t\tBT_DBG(\"chan %p skb %p len %d priority %u\", chan, skb,\n\t\t\t       skb->len, skb->priority);\n\n\t\t\t \n\t\t\tif (skb->priority < priority)\n\t\t\t\tbreak;\n\n\t\t\tskb = skb_dequeue(&chan->data_q);\n\n\t\t\tblocks = __get_blocks(hdev, skb);\n\t\t\tif (blocks > hdev->block_cnt)\n\t\t\t\treturn;\n\n\t\t\thci_conn_enter_active_mode(chan->conn,\n\t\t\t\t\t\t   bt_cb(skb)->force_active);\n\n\t\t\thci_send_frame(hdev, skb);\n\t\t\thdev->acl_last_tx = jiffies;\n\n\t\t\thdev->block_cnt -= blocks;\n\t\t\tquote -= blocks;\n\n\t\t\tchan->sent += blocks;\n\t\t\tchan->conn->sent += blocks;\n\t\t}\n\t}\n\n\tif (cnt != hdev->block_cnt)\n\t\thci_prio_recalculate(hdev, type);\n}\n\nstatic void hci_sched_acl(struct hci_dev *hdev)\n{\n\tBT_DBG(\"%s\", hdev->name);\n\n\t \n\tif (!hci_conn_num(hdev, ACL_LINK) && hdev->dev_type == HCI_PRIMARY)\n\t\treturn;\n\n\t \n\tif (!hci_conn_num(hdev, AMP_LINK) && hdev->dev_type == HCI_AMP)\n\t\treturn;\n\n\tswitch (hdev->flow_ctl_mode) {\n\tcase HCI_FLOW_CTL_MODE_PACKET_BASED:\n\t\thci_sched_acl_pkt(hdev);\n\t\tbreak;\n\n\tcase HCI_FLOW_CTL_MODE_BLOCK_BASED:\n\t\thci_sched_acl_blk(hdev);\n\t\tbreak;\n\t}\n}\n\nstatic void hci_sched_le(struct hci_dev *hdev)\n{\n\tstruct hci_chan *chan;\n\tstruct sk_buff *skb;\n\tint quote, cnt, tmp;\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\tif (!hci_conn_num(hdev, LE_LINK))\n\t\treturn;\n\n\tcnt = hdev->le_pkts ? hdev->le_cnt : hdev->acl_cnt;\n\n\t__check_timeout(hdev, cnt, LE_LINK);\n\n\ttmp = cnt;\n\twhile (cnt && (chan = hci_chan_sent(hdev, LE_LINK, &quote))) {\n\t\tu32 priority = (skb_peek(&chan->data_q))->priority;\n\t\twhile (quote-- && (skb = skb_peek(&chan->data_q))) {\n\t\t\tBT_DBG(\"chan %p skb %p len %d priority %u\", chan, skb,\n\t\t\t       skb->len, skb->priority);\n\n\t\t\t \n\t\t\tif (skb->priority < priority)\n\t\t\t\tbreak;\n\n\t\t\tskb = skb_dequeue(&chan->data_q);\n\n\t\t\thci_send_frame(hdev, skb);\n\t\t\thdev->le_last_tx = jiffies;\n\n\t\t\tcnt--;\n\t\t\tchan->sent++;\n\t\t\tchan->conn->sent++;\n\n\t\t\t \n\t\t\thci_sched_sco(hdev);\n\t\t\thci_sched_esco(hdev);\n\t\t}\n\t}\n\n\tif (hdev->le_pkts)\n\t\thdev->le_cnt = cnt;\n\telse\n\t\thdev->acl_cnt = cnt;\n\n\tif (cnt != tmp)\n\t\thci_prio_recalculate(hdev, LE_LINK);\n}\n\n \nstatic void hci_sched_iso(struct hci_dev *hdev)\n{\n\tstruct hci_conn *conn;\n\tstruct sk_buff *skb;\n\tint quote, *cnt;\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\tif (!hci_conn_num(hdev, ISO_LINK))\n\t\treturn;\n\n\tcnt = hdev->iso_pkts ? &hdev->iso_cnt :\n\t\thdev->le_pkts ? &hdev->le_cnt : &hdev->acl_cnt;\n\twhile (*cnt && (conn = hci_low_sent(hdev, ISO_LINK, &quote))) {\n\t\twhile (quote-- && (skb = skb_dequeue(&conn->data_q))) {\n\t\t\tBT_DBG(\"skb %p len %d\", skb, skb->len);\n\t\t\thci_send_frame(hdev, skb);\n\n\t\t\tconn->sent++;\n\t\t\tif (conn->sent == ~0)\n\t\t\t\tconn->sent = 0;\n\t\t\t(*cnt)--;\n\t\t}\n\t}\n}\n\nstatic void hci_tx_work(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev, tx_work);\n\tstruct sk_buff *skb;\n\n\tBT_DBG(\"%s acl %d sco %d le %d iso %d\", hdev->name, hdev->acl_cnt,\n\t       hdev->sco_cnt, hdev->le_cnt, hdev->iso_cnt);\n\n\tif (!hci_dev_test_flag(hdev, HCI_USER_CHANNEL)) {\n\t\t \n\t\thci_sched_sco(hdev);\n\t\thci_sched_esco(hdev);\n\t\thci_sched_iso(hdev);\n\t\thci_sched_acl(hdev);\n\t\thci_sched_le(hdev);\n\t}\n\n\t \n\twhile ((skb = skb_dequeue(&hdev->raw_q)))\n\t\thci_send_frame(hdev, skb);\n}\n\n \n\n \nstatic void hci_acldata_packet(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\tstruct hci_acl_hdr *hdr = (void *) skb->data;\n\tstruct hci_conn *conn;\n\t__u16 handle, flags;\n\n\tskb_pull(skb, HCI_ACL_HDR_SIZE);\n\n\thandle = __le16_to_cpu(hdr->handle);\n\tflags  = hci_flags(handle);\n\thandle = hci_handle(handle);\n\n\tBT_DBG(\"%s len %d handle 0x%4.4x flags 0x%4.4x\", hdev->name, skb->len,\n\t       handle, flags);\n\n\thdev->stat.acl_rx++;\n\n\thci_dev_lock(hdev);\n\tconn = hci_conn_hash_lookup_handle(hdev, handle);\n\thci_dev_unlock(hdev);\n\n\tif (conn) {\n\t\thci_conn_enter_active_mode(conn, BT_POWER_FORCE_ACTIVE_OFF);\n\n\t\t \n\t\tl2cap_recv_acldata(conn, skb, flags);\n\t\treturn;\n\t} else {\n\t\tbt_dev_err(hdev, \"ACL packet for unknown connection handle %d\",\n\t\t\t   handle);\n\t}\n\n\tkfree_skb(skb);\n}\n\n \nstatic void hci_scodata_packet(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\tstruct hci_sco_hdr *hdr = (void *) skb->data;\n\tstruct hci_conn *conn;\n\t__u16 handle, flags;\n\n\tskb_pull(skb, HCI_SCO_HDR_SIZE);\n\n\thandle = __le16_to_cpu(hdr->handle);\n\tflags  = hci_flags(handle);\n\thandle = hci_handle(handle);\n\n\tBT_DBG(\"%s len %d handle 0x%4.4x flags 0x%4.4x\", hdev->name, skb->len,\n\t       handle, flags);\n\n\thdev->stat.sco_rx++;\n\n\thci_dev_lock(hdev);\n\tconn = hci_conn_hash_lookup_handle(hdev, handle);\n\thci_dev_unlock(hdev);\n\n\tif (conn) {\n\t\t \n\t\thci_skb_pkt_status(skb) = flags & 0x03;\n\t\tsco_recv_scodata(conn, skb);\n\t\treturn;\n\t} else {\n\t\tbt_dev_err_ratelimited(hdev, \"SCO packet for unknown connection handle %d\",\n\t\t\t\t       handle);\n\t}\n\n\tkfree_skb(skb);\n}\n\nstatic void hci_isodata_packet(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\tstruct hci_iso_hdr *hdr;\n\tstruct hci_conn *conn;\n\t__u16 handle, flags;\n\n\thdr = skb_pull_data(skb, sizeof(*hdr));\n\tif (!hdr) {\n\t\tbt_dev_err(hdev, \"ISO packet too small\");\n\t\tgoto drop;\n\t}\n\n\thandle = __le16_to_cpu(hdr->handle);\n\tflags  = hci_flags(handle);\n\thandle = hci_handle(handle);\n\n\tbt_dev_dbg(hdev, \"len %d handle 0x%4.4x flags 0x%4.4x\", skb->len,\n\t\t   handle, flags);\n\n\thci_dev_lock(hdev);\n\tconn = hci_conn_hash_lookup_handle(hdev, handle);\n\thci_dev_unlock(hdev);\n\n\tif (!conn) {\n\t\tbt_dev_err(hdev, \"ISO packet for unknown connection handle %d\",\n\t\t\t   handle);\n\t\tgoto drop;\n\t}\n\n\t \n\tiso_recv(conn, skb, flags);\n\treturn;\n\ndrop:\n\tkfree_skb(skb);\n}\n\nstatic bool hci_req_is_complete(struct hci_dev *hdev)\n{\n\tstruct sk_buff *skb;\n\n\tskb = skb_peek(&hdev->cmd_q);\n\tif (!skb)\n\t\treturn true;\n\n\treturn (bt_cb(skb)->hci.req_flags & HCI_REQ_START);\n}\n\nstatic void hci_resend_last(struct hci_dev *hdev)\n{\n\tstruct hci_command_hdr *sent;\n\tstruct sk_buff *skb;\n\tu16 opcode;\n\n\tif (!hdev->sent_cmd)\n\t\treturn;\n\n\tsent = (void *) hdev->sent_cmd->data;\n\topcode = __le16_to_cpu(sent->opcode);\n\tif (opcode == HCI_OP_RESET)\n\t\treturn;\n\n\tskb = skb_clone(hdev->sent_cmd, GFP_KERNEL);\n\tif (!skb)\n\t\treturn;\n\n\tskb_queue_head(&hdev->cmd_q, skb);\n\tqueue_work(hdev->workqueue, &hdev->cmd_work);\n}\n\nvoid hci_req_cmd_complete(struct hci_dev *hdev, u16 opcode, u8 status,\n\t\t\t  hci_req_complete_t *req_complete,\n\t\t\t  hci_req_complete_skb_t *req_complete_skb)\n{\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\n\tBT_DBG(\"opcode 0x%04x status 0x%02x\", opcode, status);\n\n\t \n\tif (!hci_sent_cmd_data(hdev, opcode)) {\n\t\t \n\t\tif (test_bit(HCI_INIT, &hdev->flags) && opcode == HCI_OP_RESET)\n\t\t\thci_resend_last(hdev);\n\n\t\treturn;\n\t}\n\n\t \n\thci_dev_clear_flag(hdev, HCI_CMD_PENDING);\n\n\t \n\tif (!status && !hci_req_is_complete(hdev))\n\t\treturn;\n\n\t \n\tif (bt_cb(hdev->sent_cmd)->hci.req_flags & HCI_REQ_SKB) {\n\t\t*req_complete_skb = bt_cb(hdev->sent_cmd)->hci.req_complete_skb;\n\t\treturn;\n\t}\n\n\tif (bt_cb(hdev->sent_cmd)->hci.req_complete) {\n\t\t*req_complete = bt_cb(hdev->sent_cmd)->hci.req_complete;\n\t\treturn;\n\t}\n\n\t \n\tspin_lock_irqsave(&hdev->cmd_q.lock, flags);\n\twhile ((skb = __skb_dequeue(&hdev->cmd_q))) {\n\t\tif (bt_cb(skb)->hci.req_flags & HCI_REQ_START) {\n\t\t\t__skb_queue_head(&hdev->cmd_q, skb);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (bt_cb(skb)->hci.req_flags & HCI_REQ_SKB)\n\t\t\t*req_complete_skb = bt_cb(skb)->hci.req_complete_skb;\n\t\telse\n\t\t\t*req_complete = bt_cb(skb)->hci.req_complete;\n\t\tdev_kfree_skb_irq(skb);\n\t}\n\tspin_unlock_irqrestore(&hdev->cmd_q.lock, flags);\n}\n\nstatic void hci_rx_work(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev, rx_work);\n\tstruct sk_buff *skb;\n\n\tBT_DBG(\"%s\", hdev->name);\n\n\t \n\tfor (; (skb = skb_dequeue(&hdev->rx_q)); kcov_remote_stop()) {\n\t\tkcov_remote_start_common(skb_get_kcov_handle(skb));\n\n\t\t \n\t\thci_send_to_monitor(hdev, skb);\n\n\t\tif (atomic_read(&hdev->promisc)) {\n\t\t\t \n\t\t\thci_send_to_sock(hdev, skb);\n\t\t}\n\n\t\t \n\t\tif (hci_dev_test_flag(hdev, HCI_USER_CHANNEL) &&\n\t\t    !test_bit(HCI_INIT, &hdev->flags)) {\n\t\t\tkfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (test_bit(HCI_INIT, &hdev->flags)) {\n\t\t\t \n\t\t\tswitch (hci_skb_pkt_type(skb)) {\n\t\t\tcase HCI_ACLDATA_PKT:\n\t\t\tcase HCI_SCODATA_PKT:\n\t\t\tcase HCI_ISODATA_PKT:\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tswitch (hci_skb_pkt_type(skb)) {\n\t\tcase HCI_EVENT_PKT:\n\t\t\tBT_DBG(\"%s Event packet\", hdev->name);\n\t\t\thci_event_packet(hdev, skb);\n\t\t\tbreak;\n\n\t\tcase HCI_ACLDATA_PKT:\n\t\t\tBT_DBG(\"%s ACL data packet\", hdev->name);\n\t\t\thci_acldata_packet(hdev, skb);\n\t\t\tbreak;\n\n\t\tcase HCI_SCODATA_PKT:\n\t\t\tBT_DBG(\"%s SCO data packet\", hdev->name);\n\t\t\thci_scodata_packet(hdev, skb);\n\t\t\tbreak;\n\n\t\tcase HCI_ISODATA_PKT:\n\t\t\tBT_DBG(\"%s ISO data packet\", hdev->name);\n\t\t\thci_isodata_packet(hdev, skb);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tkfree_skb(skb);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void hci_cmd_work(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev, cmd_work);\n\tstruct sk_buff *skb;\n\n\tBT_DBG(\"%s cmd_cnt %d cmd queued %d\", hdev->name,\n\t       atomic_read(&hdev->cmd_cnt), skb_queue_len(&hdev->cmd_q));\n\n\t \n\tif (atomic_read(&hdev->cmd_cnt)) {\n\t\tskb = skb_dequeue(&hdev->cmd_q);\n\t\tif (!skb)\n\t\t\treturn;\n\n\t\tkfree_skb(hdev->sent_cmd);\n\n\t\thdev->sent_cmd = skb_clone(skb, GFP_KERNEL);\n\t\tif (hdev->sent_cmd) {\n\t\t\tint res;\n\t\t\tif (hci_req_status_pend(hdev))\n\t\t\t\thci_dev_set_flag(hdev, HCI_CMD_PENDING);\n\t\t\tatomic_dec(&hdev->cmd_cnt);\n\n\t\t\tres = hci_send_frame(hdev, skb);\n\t\t\tif (res < 0)\n\t\t\t\t__hci_cmd_sync_cancel(hdev, -res);\n\n\t\t\trcu_read_lock();\n\t\t\tif (test_bit(HCI_RESET, &hdev->flags) ||\n\t\t\t    hci_dev_test_flag(hdev, HCI_CMD_DRAIN_WORKQUEUE))\n\t\t\t\tcancel_delayed_work(&hdev->cmd_timer);\n\t\t\telse\n\t\t\t\tqueue_delayed_work(hdev->workqueue, &hdev->cmd_timer,\n\t\t\t\t\t\t   HCI_CMD_TIMEOUT);\n\t\t\trcu_read_unlock();\n\t\t} else {\n\t\t\tskb_queue_head(&hdev->cmd_q, skb);\n\t\t\tqueue_work(hdev->workqueue, &hdev->cmd_work);\n\t\t}\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}