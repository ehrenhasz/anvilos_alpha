{
  "module_name": "coredump.c",
  "hash_id": "7530536a0f4ab6853256b1d37b2cb9ca473a7fa4024f6763c77268c52763a4b0",
  "original_prompt": "Ingested from linux-6.6.14/net/bluetooth/coredump.c",
  "human_readable_source": "\n \n\n#include <linux/devcoredump.h>\n\n#include <asm/unaligned.h>\n#include <net/bluetooth/bluetooth.h>\n#include <net/bluetooth/hci_core.h>\n\nenum hci_devcoredump_pkt_type {\n\tHCI_DEVCOREDUMP_PKT_INIT,\n\tHCI_DEVCOREDUMP_PKT_SKB,\n\tHCI_DEVCOREDUMP_PKT_PATTERN,\n\tHCI_DEVCOREDUMP_PKT_COMPLETE,\n\tHCI_DEVCOREDUMP_PKT_ABORT,\n};\n\nstruct hci_devcoredump_skb_cb {\n\tu16 pkt_type;\n};\n\nstruct hci_devcoredump_skb_pattern {\n\tu8 pattern;\n\tu32 len;\n} __packed;\n\n#define hci_dmp_cb(skb)\t((struct hci_devcoredump_skb_cb *)((skb)->cb))\n\n#define DBG_UNEXPECTED_STATE() \\\n\tbt_dev_dbg(hdev, \\\n\t\t   \"Unexpected packet (%d) for state (%d). \", \\\n\t\t   hci_dmp_cb(skb)->pkt_type, hdev->dump.state)\n\n#define MAX_DEVCOREDUMP_HDR_SIZE\t512\t \n\nstatic int hci_devcd_update_hdr_state(char *buf, size_t size, int state)\n{\n\tint len = 0;\n\n\tif (!buf)\n\t\treturn 0;\n\n\tlen = scnprintf(buf, size, \"Bluetooth devcoredump\\nState: %d\\n\", state);\n\n\treturn len + 1;  \n}\n\n \nstatic int hci_devcd_update_state(struct hci_dev *hdev, int state)\n{\n\tbt_dev_dbg(hdev, \"Updating devcoredump state from %d to %d.\",\n\t\t   hdev->dump.state, state);\n\n\thdev->dump.state = state;\n\n\treturn hci_devcd_update_hdr_state(hdev->dump.head,\n\t\t\t\t\t  hdev->dump.alloc_size, state);\n}\n\nstatic int hci_devcd_mkheader(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\tchar dump_start[] = \"--- Start dump ---\\n\";\n\tchar hdr[80];\n\tint hdr_len;\n\n\thdr_len = hci_devcd_update_hdr_state(hdr, sizeof(hdr),\n\t\t\t\t\t     HCI_DEVCOREDUMP_IDLE);\n\tskb_put_data(skb, hdr, hdr_len);\n\n\tif (hdev->dump.dmp_hdr)\n\t\thdev->dump.dmp_hdr(hdev, skb);\n\n\tskb_put_data(skb, dump_start, strlen(dump_start));\n\n\treturn skb->len;\n}\n\n \nstatic void hci_devcd_notify(struct hci_dev *hdev, int state)\n{\n\tif (hdev->dump.notify_change)\n\t\thdev->dump.notify_change(hdev, state);\n}\n\n \nvoid hci_devcd_reset(struct hci_dev *hdev)\n{\n\thdev->dump.head = NULL;\n\thdev->dump.tail = NULL;\n\thdev->dump.alloc_size = 0;\n\n\thci_devcd_update_state(hdev, HCI_DEVCOREDUMP_IDLE);\n\n\tcancel_delayed_work(&hdev->dump.dump_timeout);\n\tskb_queue_purge(&hdev->dump.dump_q);\n}\n\n \nstatic void hci_devcd_free(struct hci_dev *hdev)\n{\n\tvfree(hdev->dump.head);\n\n\thci_devcd_reset(hdev);\n}\n\n \nstatic int hci_devcd_alloc(struct hci_dev *hdev, u32 size)\n{\n\thdev->dump.head = vmalloc(size);\n\tif (!hdev->dump.head)\n\t\treturn -ENOMEM;\n\n\thdev->dump.alloc_size = size;\n\thdev->dump.tail = hdev->dump.head;\n\thdev->dump.end = hdev->dump.head + size;\n\n\thci_devcd_update_state(hdev, HCI_DEVCOREDUMP_IDLE);\n\n\treturn 0;\n}\n\n \nstatic bool hci_devcd_copy(struct hci_dev *hdev, char *buf, u32 size)\n{\n\tif (hdev->dump.tail + size > hdev->dump.end)\n\t\treturn false;\n\n\tmemcpy(hdev->dump.tail, buf, size);\n\thdev->dump.tail += size;\n\n\treturn true;\n}\n\n \nstatic bool hci_devcd_memset(struct hci_dev *hdev, u8 pattern, u32 len)\n{\n\tif (hdev->dump.tail + len > hdev->dump.end)\n\t\treturn false;\n\n\tmemset(hdev->dump.tail, pattern, len);\n\thdev->dump.tail += len;\n\n\treturn true;\n}\n\n \nstatic int hci_devcd_prepare(struct hci_dev *hdev, u32 dump_size)\n{\n\tstruct sk_buff *skb;\n\tint dump_hdr_size;\n\tint err = 0;\n\n\tskb = alloc_skb(MAX_DEVCOREDUMP_HDR_SIZE, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tdump_hdr_size = hci_devcd_mkheader(hdev, skb);\n\n\tif (hci_devcd_alloc(hdev, dump_hdr_size + dump_size)) {\n\t\terr = -ENOMEM;\n\t\tgoto hdr_free;\n\t}\n\n\t \n\tif (!hci_devcd_copy(hdev, skb->data, skb->len)) {\n\t\tbt_dev_err(hdev, \"Failed to insert header\");\n\t\thci_devcd_free(hdev);\n\n\t\terr = -ENOMEM;\n\t\tgoto hdr_free;\n\t}\n\nhdr_free:\n\tkfree_skb(skb);\n\n\treturn err;\n}\n\nstatic void hci_devcd_handle_pkt_init(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\tu32 dump_size;\n\n\tif (hdev->dump.state != HCI_DEVCOREDUMP_IDLE) {\n\t\tDBG_UNEXPECTED_STATE();\n\t\treturn;\n\t}\n\n\tif (skb->len != sizeof(dump_size)) {\n\t\tbt_dev_dbg(hdev, \"Invalid dump init pkt\");\n\t\treturn;\n\t}\n\n\tdump_size = get_unaligned_le32(skb_pull_data(skb, 4));\n\tif (!dump_size) {\n\t\tbt_dev_err(hdev, \"Zero size dump init pkt\");\n\t\treturn;\n\t}\n\n\tif (hci_devcd_prepare(hdev, dump_size)) {\n\t\tbt_dev_err(hdev, \"Failed to prepare for dump\");\n\t\treturn;\n\t}\n\n\thci_devcd_update_state(hdev, HCI_DEVCOREDUMP_ACTIVE);\n\tqueue_delayed_work(hdev->workqueue, &hdev->dump.dump_timeout,\n\t\t\t   hdev->dump.timeout);\n}\n\nstatic void hci_devcd_handle_pkt_skb(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\tif (hdev->dump.state != HCI_DEVCOREDUMP_ACTIVE) {\n\t\tDBG_UNEXPECTED_STATE();\n\t\treturn;\n\t}\n\n\tif (!hci_devcd_copy(hdev, skb->data, skb->len))\n\t\tbt_dev_dbg(hdev, \"Failed to insert skb\");\n}\n\nstatic void hci_devcd_handle_pkt_pattern(struct hci_dev *hdev,\n\t\t\t\t\t struct sk_buff *skb)\n{\n\tstruct hci_devcoredump_skb_pattern *pattern;\n\n\tif (hdev->dump.state != HCI_DEVCOREDUMP_ACTIVE) {\n\t\tDBG_UNEXPECTED_STATE();\n\t\treturn;\n\t}\n\n\tif (skb->len != sizeof(*pattern)) {\n\t\tbt_dev_dbg(hdev, \"Invalid pattern skb\");\n\t\treturn;\n\t}\n\n\tpattern = skb_pull_data(skb, sizeof(*pattern));\n\n\tif (!hci_devcd_memset(hdev, pattern->pattern, pattern->len))\n\t\tbt_dev_dbg(hdev, \"Failed to set pattern\");\n}\n\nstatic void hci_devcd_handle_pkt_complete(struct hci_dev *hdev,\n\t\t\t\t\t  struct sk_buff *skb)\n{\n\tu32 dump_size;\n\n\tif (hdev->dump.state != HCI_DEVCOREDUMP_ACTIVE) {\n\t\tDBG_UNEXPECTED_STATE();\n\t\treturn;\n\t}\n\n\thci_devcd_update_state(hdev, HCI_DEVCOREDUMP_DONE);\n\tdump_size = hdev->dump.tail - hdev->dump.head;\n\n\tbt_dev_dbg(hdev, \"complete with size %u (expect %zu)\", dump_size,\n\t\t   hdev->dump.alloc_size);\n\n\tdev_coredumpv(&hdev->dev, hdev->dump.head, dump_size, GFP_KERNEL);\n}\n\nstatic void hci_devcd_handle_pkt_abort(struct hci_dev *hdev,\n\t\t\t\t       struct sk_buff *skb)\n{\n\tu32 dump_size;\n\n\tif (hdev->dump.state != HCI_DEVCOREDUMP_ACTIVE) {\n\t\tDBG_UNEXPECTED_STATE();\n\t\treturn;\n\t}\n\n\thci_devcd_update_state(hdev, HCI_DEVCOREDUMP_ABORT);\n\tdump_size = hdev->dump.tail - hdev->dump.head;\n\n\tbt_dev_dbg(hdev, \"aborted with size %u (expect %zu)\", dump_size,\n\t\t   hdev->dump.alloc_size);\n\n\t \n\tdev_coredumpv(&hdev->dev, hdev->dump.head, dump_size, GFP_KERNEL);\n}\n\n \nvoid hci_devcd_rx(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev, dump.dump_rx);\n\tstruct sk_buff *skb;\n\tint start_state;\n\n\twhile ((skb = skb_dequeue(&hdev->dump.dump_q))) {\n\t\t \n\t\tif (hdev->dump.state == HCI_DEVCOREDUMP_TIMEOUT) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn;\n\t\t}\n\n\t\thci_dev_lock(hdev);\n\t\tstart_state = hdev->dump.state;\n\n\t\tswitch (hci_dmp_cb(skb)->pkt_type) {\n\t\tcase HCI_DEVCOREDUMP_PKT_INIT:\n\t\t\thci_devcd_handle_pkt_init(hdev, skb);\n\t\t\tbreak;\n\n\t\tcase HCI_DEVCOREDUMP_PKT_SKB:\n\t\t\thci_devcd_handle_pkt_skb(hdev, skb);\n\t\t\tbreak;\n\n\t\tcase HCI_DEVCOREDUMP_PKT_PATTERN:\n\t\t\thci_devcd_handle_pkt_pattern(hdev, skb);\n\t\t\tbreak;\n\n\t\tcase HCI_DEVCOREDUMP_PKT_COMPLETE:\n\t\t\thci_devcd_handle_pkt_complete(hdev, skb);\n\t\t\tbreak;\n\n\t\tcase HCI_DEVCOREDUMP_PKT_ABORT:\n\t\t\thci_devcd_handle_pkt_abort(hdev, skb);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbt_dev_dbg(hdev, \"Unknown packet (%d) for state (%d). \",\n\t\t\t\t   hci_dmp_cb(skb)->pkt_type, hdev->dump.state);\n\t\t\tbreak;\n\t\t}\n\n\t\thci_dev_unlock(hdev);\n\t\tkfree_skb(skb);\n\n\t\t \n\t\tif (start_state != hdev->dump.state)\n\t\t\thci_devcd_notify(hdev, hdev->dump.state);\n\n\t\t \n\t\thci_dev_lock(hdev);\n\t\tif (hdev->dump.state == HCI_DEVCOREDUMP_DONE ||\n\t\t    hdev->dump.state == HCI_DEVCOREDUMP_ABORT)\n\t\t\thci_devcd_reset(hdev);\n\t\thci_dev_unlock(hdev);\n\t}\n}\nEXPORT_SYMBOL(hci_devcd_rx);\n\nvoid hci_devcd_timeout(struct work_struct *work)\n{\n\tstruct hci_dev *hdev = container_of(work, struct hci_dev,\n\t\t\t\t\t    dump.dump_timeout.work);\n\tu32 dump_size;\n\n\thci_devcd_notify(hdev, HCI_DEVCOREDUMP_TIMEOUT);\n\n\thci_dev_lock(hdev);\n\n\tcancel_work(&hdev->dump.dump_rx);\n\n\thci_devcd_update_state(hdev, HCI_DEVCOREDUMP_TIMEOUT);\n\n\tdump_size = hdev->dump.tail - hdev->dump.head;\n\tbt_dev_dbg(hdev, \"timeout with size %u (expect %zu)\", dump_size,\n\t\t   hdev->dump.alloc_size);\n\n\t \n\tdev_coredumpv(&hdev->dev, hdev->dump.head, dump_size, GFP_KERNEL);\n\n\thci_devcd_reset(hdev);\n\n\thci_dev_unlock(hdev);\n}\nEXPORT_SYMBOL(hci_devcd_timeout);\n\nint hci_devcd_register(struct hci_dev *hdev, coredump_t coredump,\n\t\t       dmp_hdr_t dmp_hdr, notify_change_t notify_change)\n{\n\t \n\tif (!coredump || !dmp_hdr)\n\t\treturn -EINVAL;\n\n\thci_dev_lock(hdev);\n\thdev->dump.coredump = coredump;\n\thdev->dump.dmp_hdr = dmp_hdr;\n\thdev->dump.notify_change = notify_change;\n\thdev->dump.supported = true;\n\thdev->dump.timeout = DEVCOREDUMP_TIMEOUT;\n\thci_dev_unlock(hdev);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(hci_devcd_register);\n\nstatic inline bool hci_devcd_enabled(struct hci_dev *hdev)\n{\n\treturn hdev->dump.supported;\n}\n\nint hci_devcd_init(struct hci_dev *hdev, u32 dump_size)\n{\n\tstruct sk_buff *skb;\n\n\tif (!hci_devcd_enabled(hdev))\n\t\treturn -EOPNOTSUPP;\n\n\tskb = alloc_skb(sizeof(dump_size), GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\thci_dmp_cb(skb)->pkt_type = HCI_DEVCOREDUMP_PKT_INIT;\n\tput_unaligned_le32(dump_size, skb_put(skb, 4));\n\n\tskb_queue_tail(&hdev->dump.dump_q, skb);\n\tqueue_work(hdev->workqueue, &hdev->dump.dump_rx);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(hci_devcd_init);\n\nint hci_devcd_append(struct hci_dev *hdev, struct sk_buff *skb)\n{\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tif (!hci_devcd_enabled(hdev)) {\n\t\tkfree_skb(skb);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\thci_dmp_cb(skb)->pkt_type = HCI_DEVCOREDUMP_PKT_SKB;\n\n\tskb_queue_tail(&hdev->dump.dump_q, skb);\n\tqueue_work(hdev->workqueue, &hdev->dump.dump_rx);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(hci_devcd_append);\n\nint hci_devcd_append_pattern(struct hci_dev *hdev, u8 pattern, u32 len)\n{\n\tstruct hci_devcoredump_skb_pattern p;\n\tstruct sk_buff *skb;\n\n\tif (!hci_devcd_enabled(hdev))\n\t\treturn -EOPNOTSUPP;\n\n\tskb = alloc_skb(sizeof(p), GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tp.pattern = pattern;\n\tp.len = len;\n\n\thci_dmp_cb(skb)->pkt_type = HCI_DEVCOREDUMP_PKT_PATTERN;\n\tskb_put_data(skb, &p, sizeof(p));\n\n\tskb_queue_tail(&hdev->dump.dump_q, skb);\n\tqueue_work(hdev->workqueue, &hdev->dump.dump_rx);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(hci_devcd_append_pattern);\n\nint hci_devcd_complete(struct hci_dev *hdev)\n{\n\tstruct sk_buff *skb;\n\n\tif (!hci_devcd_enabled(hdev))\n\t\treturn -EOPNOTSUPP;\n\n\tskb = alloc_skb(0, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\thci_dmp_cb(skb)->pkt_type = HCI_DEVCOREDUMP_PKT_COMPLETE;\n\n\tskb_queue_tail(&hdev->dump.dump_q, skb);\n\tqueue_work(hdev->workqueue, &hdev->dump.dump_rx);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(hci_devcd_complete);\n\nint hci_devcd_abort(struct hci_dev *hdev)\n{\n\tstruct sk_buff *skb;\n\n\tif (!hci_devcd_enabled(hdev))\n\t\treturn -EOPNOTSUPP;\n\n\tskb = alloc_skb(0, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\thci_dmp_cb(skb)->pkt_type = HCI_DEVCOREDUMP_PKT_ABORT;\n\n\tskb_queue_tail(&hdev->dump.dump_q, skb);\n\tqueue_work(hdev->workqueue, &hdev->dump.dump_rx);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(hci_devcd_abort);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}