{
  "module_name": "output.c",
  "hash_id": "e5d1b88052e2a35d09d069e1059b761ca66be80a222a17336f7d3337f0400fb0",
  "original_prompt": "Ingested from linux-6.6.14/net/dccp/output.c",
  "human_readable_source": "\n \n\n#include <linux/dccp.h>\n#include <linux/kernel.h>\n#include <linux/skbuff.h>\n#include <linux/slab.h>\n#include <linux/sched/signal.h>\n\n#include <net/inet_sock.h>\n#include <net/sock.h>\n\n#include \"ackvec.h\"\n#include \"ccid.h\"\n#include \"dccp.h\"\n\nstatic inline void dccp_event_ack_sent(struct sock *sk)\n{\n\tinet_csk_clear_xmit_timer(sk, ICSK_TIME_DACK);\n}\n\n \nstatic struct sk_buff *dccp_skb_entail(struct sock *sk, struct sk_buff *skb)\n{\n\tskb_set_owner_w(skb, sk);\n\tWARN_ON(sk->sk_send_head);\n\tsk->sk_send_head = skb;\n\treturn skb_clone(sk->sk_send_head, gfp_any());\n}\n\n \nstatic int dccp_transmit_skb(struct sock *sk, struct sk_buff *skb)\n{\n\tif (likely(skb != NULL)) {\n\t\tstruct inet_sock *inet = inet_sk(sk);\n\t\tconst struct inet_connection_sock *icsk = inet_csk(sk);\n\t\tstruct dccp_sock *dp = dccp_sk(sk);\n\t\tstruct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);\n\t\tstruct dccp_hdr *dh;\n\t\t \n\t\tconst u32 dccp_header_size = sizeof(*dh) +\n\t\t\t\t\t     sizeof(struct dccp_hdr_ext) +\n\t\t\t\t\t  dccp_packet_hdr_len(dcb->dccpd_type);\n\t\tint err, set_ack = 1;\n\t\tu64 ackno = dp->dccps_gsr;\n\t\t \n\t\tdcb->dccpd_seq = ADD48(dp->dccps_gss, 1);\n\n\t\tswitch (dcb->dccpd_type) {\n\t\tcase DCCP_PKT_DATA:\n\t\t\tset_ack = 0;\n\t\t\tfallthrough;\n\t\tcase DCCP_PKT_DATAACK:\n\t\tcase DCCP_PKT_RESET:\n\t\t\tbreak;\n\n\t\tcase DCCP_PKT_REQUEST:\n\t\t\tset_ack = 0;\n\t\t\t \n\t\t\tif (icsk->icsk_retransmits == 0)\n\t\t\t\tdcb->dccpd_seq = dp->dccps_iss;\n\t\t\tfallthrough;\n\n\t\tcase DCCP_PKT_SYNC:\n\t\tcase DCCP_PKT_SYNCACK:\n\t\t\tackno = dcb->dccpd_ack_seq;\n\t\t\tfallthrough;\n\t\tdefault:\n\t\t\t \n\t\t\tWARN_ON(skb->sk);\n\t\t\tskb_set_owner_w(skb, sk);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (dccp_insert_options(sk, skb)) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -EPROTO;\n\t\t}\n\n\n\t\t \n\t\tdh = dccp_zeroed_hdr(skb, dccp_header_size);\n\t\tdh->dccph_type\t= dcb->dccpd_type;\n\t\tdh->dccph_sport\t= inet->inet_sport;\n\t\tdh->dccph_dport\t= inet->inet_dport;\n\t\tdh->dccph_doff\t= (dccp_header_size + dcb->dccpd_opt_len) / 4;\n\t\tdh->dccph_ccval\t= dcb->dccpd_ccval;\n\t\tdh->dccph_cscov = dp->dccps_pcslen;\n\t\t \n\t\tdh->dccph_x\t= 1;\n\n\t\tdccp_update_gss(sk, dcb->dccpd_seq);\n\t\tdccp_hdr_set_seq(dh, dp->dccps_gss);\n\t\tif (set_ack)\n\t\t\tdccp_hdr_set_ack(dccp_hdr_ack_bits(skb), ackno);\n\n\t\tswitch (dcb->dccpd_type) {\n\t\tcase DCCP_PKT_REQUEST:\n\t\t\tdccp_hdr_request(skb)->dccph_req_service =\n\t\t\t\t\t\t\tdp->dccps_service;\n\t\t\t \n\t\t\tdp->dccps_awl = dp->dccps_iss;\n\t\t\tbreak;\n\t\tcase DCCP_PKT_RESET:\n\t\t\tdccp_hdr_reset(skb)->dccph_reset_code =\n\t\t\t\t\t\t\tdcb->dccpd_reset_code;\n\t\t\tbreak;\n\t\t}\n\n\t\ticsk->icsk_af_ops->send_check(sk, skb);\n\n\t\tif (set_ack)\n\t\t\tdccp_event_ack_sent(sk);\n\n\t\tDCCP_INC_STATS(DCCP_MIB_OUTSEGS);\n\n\t\terr = icsk->icsk_af_ops->queue_xmit(sk, skb, &inet->cork.fl);\n\t\treturn net_xmit_eval(err);\n\t}\n\treturn -ENOBUFS;\n}\n\n \nstatic u32 dccp_determine_ccmps(const struct dccp_sock *dp)\n{\n\tconst struct ccid *tx_ccid = dp->dccps_hc_tx_ccid;\n\n\tif (tx_ccid == NULL || tx_ccid->ccid_ops == NULL)\n\t\treturn 0;\n\treturn tx_ccid->ccid_ops->ccid_ccmps;\n}\n\nunsigned int dccp_sync_mss(struct sock *sk, u32 pmtu)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct dccp_sock *dp = dccp_sk(sk);\n\tu32 ccmps = dccp_determine_ccmps(dp);\n\tu32 cur_mps = ccmps ? min(pmtu, ccmps) : pmtu;\n\n\t \n\tcur_mps -= (icsk->icsk_af_ops->net_header_len + icsk->icsk_ext_hdr_len +\n\t\t    sizeof(struct dccp_hdr) + sizeof(struct dccp_hdr_ext));\n\n\t \n\tcur_mps -= roundup(1 + 6 + 10 + dp->dccps_send_ndp_count * 8 + 6 +\n\t\t\t   (dp->dccps_hc_rx_ackvec ? DCCPAV_MIN_OPTLEN : 0), 4);\n\n\t \n\ticsk->icsk_pmtu_cookie = pmtu;\n\tWRITE_ONCE(dp->dccps_mss_cache, cur_mps);\n\n\treturn cur_mps;\n}\n\nEXPORT_SYMBOL_GPL(dccp_sync_mss);\n\nvoid dccp_write_space(struct sock *sk)\n{\n\tstruct socket_wq *wq;\n\n\trcu_read_lock();\n\twq = rcu_dereference(sk->sk_wq);\n\tif (skwq_has_sleeper(wq))\n\t\twake_up_interruptible(&wq->wait);\n\t \n\tif (sock_writeable(sk))\n\t\tsk_wake_async(sk, SOCK_WAKE_SPACE, POLL_OUT);\n\n\trcu_read_unlock();\n}\n\n \nstatic int dccp_wait_for_ccid(struct sock *sk, unsigned long delay)\n{\n\tDEFINE_WAIT(wait);\n\tlong remaining;\n\n\tprepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);\n\tsk->sk_write_pending++;\n\trelease_sock(sk);\n\n\tremaining = schedule_timeout(delay);\n\n\tlock_sock(sk);\n\tsk->sk_write_pending--;\n\tfinish_wait(sk_sleep(sk), &wait);\n\n\tif (signal_pending(current) || sk->sk_err)\n\t\treturn -1;\n\treturn remaining;\n}\n\n \nstatic void dccp_xmit_packet(struct sock *sk)\n{\n\tint err, len;\n\tstruct dccp_sock *dp = dccp_sk(sk);\n\tstruct sk_buff *skb = dccp_qpolicy_pop(sk);\n\n\tif (unlikely(skb == NULL))\n\t\treturn;\n\tlen = skb->len;\n\n\tif (sk->sk_state == DCCP_PARTOPEN) {\n\t\tconst u32 cur_mps = dp->dccps_mss_cache - DCCP_FEATNEG_OVERHEAD;\n\t\t \n\t\tif (!list_empty(&dp->dccps_featneg) && len > cur_mps) {\n\t\t\tDCCP_WARN(\"Payload too large (%d) for featneg.\\n\", len);\n\t\t\tdccp_send_ack(sk);\n\t\t\tdccp_feat_list_purge(&dp->dccps_featneg);\n\t\t}\n\n\t\tinet_csk_schedule_ack(sk);\n\t\tinet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,\n\t\t\t\t\t      inet_csk(sk)->icsk_rto,\n\t\t\t\t\t      DCCP_RTO_MAX);\n\t\tDCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_DATAACK;\n\t} else if (dccp_ack_pending(sk)) {\n\t\tDCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_DATAACK;\n\t} else {\n\t\tDCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_DATA;\n\t}\n\n\terr = dccp_transmit_skb(sk, skb);\n\tif (err)\n\t\tdccp_pr_debug(\"transmit_skb() returned err=%d\\n\", err);\n\t \n\tccid_hc_tx_packet_sent(dp->dccps_hc_tx_ccid, sk, len);\n\n\t \n\tif (dp->dccps_sync_scheduled)\n\t\tdccp_send_sync(sk, dp->dccps_gsr, DCCP_PKT_SYNC);\n}\n\n \nvoid dccp_flush_write_queue(struct sock *sk, long *time_budget)\n{\n\tstruct dccp_sock *dp = dccp_sk(sk);\n\tstruct sk_buff *skb;\n\tlong delay, rc;\n\n\twhile (*time_budget > 0 && (skb = skb_peek(&sk->sk_write_queue))) {\n\t\trc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);\n\n\t\tswitch (ccid_packet_dequeue_eval(rc)) {\n\t\tcase CCID_PACKET_WILL_DEQUEUE_LATER:\n\t\t\t \n\t\t\tDCCP_WARN(\"CCID did not manage to send all packets\\n\");\n\t\t\treturn;\n\t\tcase CCID_PACKET_DELAY:\n\t\t\tdelay = msecs_to_jiffies(rc);\n\t\t\tif (delay > *time_budget)\n\t\t\t\treturn;\n\t\t\trc = dccp_wait_for_ccid(sk, delay);\n\t\t\tif (rc < 0)\n\t\t\t\treturn;\n\t\t\t*time_budget -= (delay - rc);\n\t\t\t \n\t\t\tbreak;\n\t\tcase CCID_PACKET_SEND_AT_ONCE:\n\t\t\tdccp_xmit_packet(sk);\n\t\t\tbreak;\n\t\tcase CCID_PACKET_ERR:\n\t\t\tskb_dequeue(&sk->sk_write_queue);\n\t\t\tkfree_skb(skb);\n\t\t\tdccp_pr_debug(\"packet discarded due to err=%ld\\n\", rc);\n\t\t}\n\t}\n}\n\nvoid dccp_write_xmit(struct sock *sk)\n{\n\tstruct dccp_sock *dp = dccp_sk(sk);\n\tstruct sk_buff *skb;\n\n\twhile ((skb = dccp_qpolicy_top(sk))) {\n\t\tint rc = ccid_hc_tx_send_packet(dp->dccps_hc_tx_ccid, sk, skb);\n\n\t\tswitch (ccid_packet_dequeue_eval(rc)) {\n\t\tcase CCID_PACKET_WILL_DEQUEUE_LATER:\n\t\t\treturn;\n\t\tcase CCID_PACKET_DELAY:\n\t\t\tsk_reset_timer(sk, &dp->dccps_xmit_timer,\n\t\t\t\t       jiffies + msecs_to_jiffies(rc));\n\t\t\treturn;\n\t\tcase CCID_PACKET_SEND_AT_ONCE:\n\t\t\tdccp_xmit_packet(sk);\n\t\t\tbreak;\n\t\tcase CCID_PACKET_ERR:\n\t\t\tdccp_qpolicy_drop(sk, skb);\n\t\t\tdccp_pr_debug(\"packet discarded due to err=%d\\n\", rc);\n\t\t}\n\t}\n}\n\n \nint dccp_retransmit_skb(struct sock *sk)\n{\n\tWARN_ON(sk->sk_send_head == NULL);\n\n\tif (inet_csk(sk)->icsk_af_ops->rebuild_header(sk) != 0)\n\t\treturn -EHOSTUNREACH;  \n\n\t \n\tinet_csk(sk)->icsk_retransmits++;\n\n\treturn dccp_transmit_skb(sk, skb_clone(sk->sk_send_head, GFP_ATOMIC));\n}\n\nstruct sk_buff *dccp_make_response(const struct sock *sk, struct dst_entry *dst,\n\t\t\t\t   struct request_sock *req)\n{\n\tstruct dccp_hdr *dh;\n\tstruct dccp_request_sock *dreq;\n\tconst u32 dccp_header_size = sizeof(struct dccp_hdr) +\n\t\t\t\t     sizeof(struct dccp_hdr_ext) +\n\t\t\t\t     sizeof(struct dccp_hdr_response);\n\tstruct sk_buff *skb;\n\n\t \n\tskb = sock_wmalloc((struct sock *)sk, MAX_DCCP_HEADER, 1,\n\t\t\t   GFP_ATOMIC);\n\tif (!skb)\n\t\treturn NULL;\n\n\tskb_reserve(skb, MAX_DCCP_HEADER);\n\n\tskb_dst_set(skb, dst_clone(dst));\n\n\tdreq = dccp_rsk(req);\n\tif (inet_rsk(req)->acked)\t \n\t\tdccp_inc_seqno(&dreq->dreq_gss);\n\tDCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_RESPONSE;\n\tDCCP_SKB_CB(skb)->dccpd_seq  = dreq->dreq_gss;\n\n\t \n\tif (dccp_feat_server_ccid_dependencies(dreq))\n\t\tgoto response_failed;\n\n\tif (dccp_insert_options_rsk(dreq, skb))\n\t\tgoto response_failed;\n\n\t \n\tdh = dccp_zeroed_hdr(skb, dccp_header_size);\n\n\tdh->dccph_sport\t= htons(inet_rsk(req)->ir_num);\n\tdh->dccph_dport\t= inet_rsk(req)->ir_rmt_port;\n\tdh->dccph_doff\t= (dccp_header_size +\n\t\t\t   DCCP_SKB_CB(skb)->dccpd_opt_len) / 4;\n\tdh->dccph_type\t= DCCP_PKT_RESPONSE;\n\tdh->dccph_x\t= 1;\n\tdccp_hdr_set_seq(dh, dreq->dreq_gss);\n\tdccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dreq->dreq_gsr);\n\tdccp_hdr_response(skb)->dccph_resp_service = dreq->dreq_service;\n\n\tdccp_csum_outgoing(skb);\n\n\t \n\tinet_rsk(req)->acked = 1;\n\tDCCP_INC_STATS(DCCP_MIB_OUTSEGS);\n\treturn skb;\nresponse_failed:\n\tkfree_skb(skb);\n\treturn NULL;\n}\n\nEXPORT_SYMBOL_GPL(dccp_make_response);\n\n \nstruct sk_buff *dccp_ctl_make_reset(struct sock *sk, struct sk_buff *rcv_skb)\n{\n\tstruct dccp_hdr *rxdh = dccp_hdr(rcv_skb), *dh;\n\tstruct dccp_skb_cb *dcb = DCCP_SKB_CB(rcv_skb);\n\tconst u32 dccp_hdr_reset_len = sizeof(struct dccp_hdr) +\n\t\t\t\t       sizeof(struct dccp_hdr_ext) +\n\t\t\t\t       sizeof(struct dccp_hdr_reset);\n\tstruct dccp_hdr_reset *dhr;\n\tstruct sk_buff *skb;\n\n\tskb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);\n\tif (skb == NULL)\n\t\treturn NULL;\n\n\tskb_reserve(skb, sk->sk_prot->max_header);\n\n\t \n\tdh = dccp_zeroed_hdr(skb, dccp_hdr_reset_len);\n\tdh->dccph_type\t= DCCP_PKT_RESET;\n\tdh->dccph_sport\t= rxdh->dccph_dport;\n\tdh->dccph_dport\t= rxdh->dccph_sport;\n\tdh->dccph_doff\t= dccp_hdr_reset_len / 4;\n\tdh->dccph_x\t= 1;\n\n\tdhr = dccp_hdr_reset(skb);\n\tdhr->dccph_reset_code = dcb->dccpd_reset_code;\n\n\tswitch (dcb->dccpd_reset_code) {\n\tcase DCCP_RESET_CODE_PACKET_ERROR:\n\t\tdhr->dccph_reset_data[0] = rxdh->dccph_type;\n\t\tbreak;\n\tcase DCCP_RESET_CODE_OPTION_ERROR:\n\tcase DCCP_RESET_CODE_MANDATORY_ERROR:\n\t\tmemcpy(dhr->dccph_reset_data, dcb->dccpd_reset_data, 3);\n\t\tbreak;\n\t}\n\t \n\tif (dcb->dccpd_ack_seq != DCCP_PKT_WITHOUT_ACK_SEQ)\n\t\tdccp_hdr_set_seq(dh, ADD48(dcb->dccpd_ack_seq, 1));\n\tdccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dcb->dccpd_seq);\n\n\tdccp_csum_outgoing(skb);\n\treturn skb;\n}\n\nEXPORT_SYMBOL_GPL(dccp_ctl_make_reset);\n\n \nint dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)\n{\n\tstruct sk_buff *skb;\n\t \n\tint err = inet_csk(sk)->icsk_af_ops->rebuild_header(sk);\n\n\tif (err != 0)\n\t\treturn err;\n\n\tskb = sock_wmalloc(sk, sk->sk_prot->max_header, 1, GFP_ATOMIC);\n\tif (skb == NULL)\n\t\treturn -ENOBUFS;\n\n\t \n\tskb_reserve(skb, sk->sk_prot->max_header);\n\tDCCP_SKB_CB(skb)->dccpd_type\t   = DCCP_PKT_RESET;\n\tDCCP_SKB_CB(skb)->dccpd_reset_code = code;\n\n\treturn dccp_transmit_skb(sk, skb);\n}\n\n \nint dccp_connect(struct sock *sk)\n{\n\tstruct sk_buff *skb;\n\tstruct dccp_sock *dp = dccp_sk(sk);\n\tstruct dst_entry *dst = __sk_dst_get(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\n\tsk->sk_err = 0;\n\tsock_reset_flag(sk, SOCK_DONE);\n\n\tdccp_sync_mss(sk, dst_mtu(dst));\n\n\t \n\tif (dccp_feat_finalise_settings(dccp_sk(sk)))\n\t\treturn -EPROTO;\n\n\t \n\tdp->dccps_gar = dp->dccps_iss;\n\n\tskb = alloc_skb(sk->sk_prot->max_header, sk->sk_allocation);\n\tif (unlikely(skb == NULL))\n\t\treturn -ENOBUFS;\n\n\t \n\tskb_reserve(skb, sk->sk_prot->max_header);\n\n\tDCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_REQUEST;\n\n\tdccp_transmit_skb(sk, dccp_skb_entail(sk, skb));\n\tDCCP_INC_STATS(DCCP_MIB_ACTIVEOPENS);\n\n\t \n\ticsk->icsk_retransmits = 0;\n\tinet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,\n\t\t\t\t  icsk->icsk_rto, DCCP_RTO_MAX);\n\treturn 0;\n}\n\nEXPORT_SYMBOL_GPL(dccp_connect);\n\nvoid dccp_send_ack(struct sock *sk)\n{\n\t \n\tif (sk->sk_state != DCCP_CLOSED) {\n\t\tstruct sk_buff *skb = alloc_skb(sk->sk_prot->max_header,\n\t\t\t\t\t\tGFP_ATOMIC);\n\n\t\tif (skb == NULL) {\n\t\t\tinet_csk_schedule_ack(sk);\n\t\t\tinet_csk(sk)->icsk_ack.ato = TCP_ATO_MIN;\n\t\t\tinet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,\n\t\t\t\t\t\t  TCP_DELACK_MAX,\n\t\t\t\t\t\t  DCCP_RTO_MAX);\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tskb_reserve(skb, sk->sk_prot->max_header);\n\t\tDCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_ACK;\n\t\tdccp_transmit_skb(sk, skb);\n\t}\n}\n\nEXPORT_SYMBOL_GPL(dccp_send_ack);\n\n#if 0\n \nvoid dccp_send_delayed_ack(struct sock *sk)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\t \n\tunsigned long timeout = jiffies + 2 * HZ;\n\n\t \n\tif (icsk->icsk_ack.pending & ICSK_ACK_TIMER) {\n\t\t \n\t\tif (icsk->icsk_ack.blocked) {\n\t\t\tdccp_send_ack(sk);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!time_before(timeout, icsk->icsk_ack.timeout))\n\t\t\ttimeout = icsk->icsk_ack.timeout;\n\t}\n\ticsk->icsk_ack.pending |= ICSK_ACK_SCHED | ICSK_ACK_TIMER;\n\ticsk->icsk_ack.timeout = timeout;\n\tsk_reset_timer(sk, &icsk->icsk_delack_timer, timeout);\n}\n#endif\n\nvoid dccp_send_sync(struct sock *sk, const u64 ackno,\n\t\t    const enum dccp_pkt_type pkt_type)\n{\n\t \n\tstruct sk_buff *skb = alloc_skb(sk->sk_prot->max_header, GFP_ATOMIC);\n\n\tif (skb == NULL) {\n\t\t \n\t\tDCCP_CRIT(\"could not send %s\", dccp_packet_name(pkt_type));\n\t\treturn;\n\t}\n\n\t \n\tskb_reserve(skb, sk->sk_prot->max_header);\n\tDCCP_SKB_CB(skb)->dccpd_type = pkt_type;\n\tDCCP_SKB_CB(skb)->dccpd_ack_seq = ackno;\n\n\t \n\tdccp_sk(sk)->dccps_sync_scheduled = 0;\n\n\tdccp_transmit_skb(sk, skb);\n}\n\nEXPORT_SYMBOL_GPL(dccp_send_sync);\n\n \nvoid dccp_send_close(struct sock *sk, const int active)\n{\n\tstruct dccp_sock *dp = dccp_sk(sk);\n\tstruct sk_buff *skb;\n\tconst gfp_t prio = active ? GFP_KERNEL : GFP_ATOMIC;\n\n\tskb = alloc_skb(sk->sk_prot->max_header, prio);\n\tif (skb == NULL)\n\t\treturn;\n\n\t \n\tskb_reserve(skb, sk->sk_prot->max_header);\n\tif (dp->dccps_role == DCCP_ROLE_SERVER && !dp->dccps_server_timewait)\n\t\tDCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_CLOSEREQ;\n\telse\n\t\tDCCP_SKB_CB(skb)->dccpd_type = DCCP_PKT_CLOSE;\n\n\tif (active) {\n\t\tskb = dccp_skb_entail(sk, skb);\n\t\t \n\t\tinet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,\n\t\t\t\t\t  DCCP_TIMEOUT_INIT, DCCP_RTO_MAX);\n\t}\n\tdccp_transmit_skb(sk, skb);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}