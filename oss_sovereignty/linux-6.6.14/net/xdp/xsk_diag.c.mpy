{
  "module_name": "xsk_diag.c",
  "hash_id": "50abb220369f3a515f3008a0c3c716cbedd1fcb3c5eaacb854dd975738ed8ea7",
  "original_prompt": "Ingested from linux-6.6.14/net/xdp/xsk_diag.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <net/xdp_sock.h>\n#include <linux/xdp_diag.h>\n#include <linux/sock_diag.h>\n\n#include \"xsk_queue.h\"\n#include \"xsk.h\"\n\nstatic int xsk_diag_put_info(const struct xdp_sock *xs, struct sk_buff *nlskb)\n{\n\tstruct xdp_diag_info di = {};\n\n\tdi.ifindex = xs->dev ? xs->dev->ifindex : 0;\n\tdi.queue_id = xs->queue_id;\n\treturn nla_put(nlskb, XDP_DIAG_INFO, sizeof(di), &di);\n}\n\nstatic int xsk_diag_put_ring(const struct xsk_queue *queue, int nl_type,\n\t\t\t     struct sk_buff *nlskb)\n{\n\tstruct xdp_diag_ring dr = {};\n\n\tdr.entries = queue->nentries;\n\treturn nla_put(nlskb, nl_type, sizeof(dr), &dr);\n}\n\nstatic int xsk_diag_put_rings_cfg(const struct xdp_sock *xs,\n\t\t\t\t  struct sk_buff *nlskb)\n{\n\tint err = 0;\n\n\tif (xs->rx)\n\t\terr = xsk_diag_put_ring(xs->rx, XDP_DIAG_RX_RING, nlskb);\n\tif (!err && xs->tx)\n\t\terr = xsk_diag_put_ring(xs->tx, XDP_DIAG_TX_RING, nlskb);\n\treturn err;\n}\n\nstatic int xsk_diag_put_umem(const struct xdp_sock *xs, struct sk_buff *nlskb)\n{\n\tstruct xsk_buff_pool *pool = xs->pool;\n\tstruct xdp_umem *umem = xs->umem;\n\tstruct xdp_diag_umem du = {};\n\tint err;\n\n\tif (!umem)\n\t\treturn 0;\n\n\tdu.id = umem->id;\n\tdu.size = umem->size;\n\tdu.num_pages = umem->npgs;\n\tdu.chunk_size = umem->chunk_size;\n\tdu.headroom = umem->headroom;\n\tdu.ifindex = (pool && pool->netdev) ? pool->netdev->ifindex : 0;\n\tdu.queue_id = pool ? pool->queue_id : 0;\n\tdu.flags = 0;\n\tif (umem->zc)\n\t\tdu.flags |= XDP_DU_F_ZEROCOPY;\n\tdu.refs = refcount_read(&umem->users);\n\n\terr = nla_put(nlskb, XDP_DIAG_UMEM, sizeof(du), &du);\n\tif (!err && pool && pool->fq)\n\t\terr = xsk_diag_put_ring(pool->fq,\n\t\t\t\t\tXDP_DIAG_UMEM_FILL_RING, nlskb);\n\tif (!err && pool && pool->cq)\n\t\terr = xsk_diag_put_ring(pool->cq,\n\t\t\t\t\tXDP_DIAG_UMEM_COMPLETION_RING, nlskb);\n\treturn err;\n}\n\nstatic int xsk_diag_put_stats(const struct xdp_sock *xs, struct sk_buff *nlskb)\n{\n\tstruct xdp_diag_stats du = {};\n\n\tdu.n_rx_dropped = xs->rx_dropped;\n\tdu.n_rx_invalid = xskq_nb_invalid_descs(xs->rx);\n\tdu.n_rx_full = xs->rx_queue_full;\n\tdu.n_fill_ring_empty = xs->pool ? xskq_nb_queue_empty_descs(xs->pool->fq) : 0;\n\tdu.n_tx_invalid = xskq_nb_invalid_descs(xs->tx);\n\tdu.n_tx_ring_empty = xskq_nb_queue_empty_descs(xs->tx);\n\treturn nla_put(nlskb, XDP_DIAG_STATS, sizeof(du), &du);\n}\n\nstatic int xsk_diag_fill(struct sock *sk, struct sk_buff *nlskb,\n\t\t\t struct xdp_diag_req *req,\n\t\t\t struct user_namespace *user_ns,\n\t\t\t u32 portid, u32 seq, u32 flags, int sk_ino)\n{\n\tstruct xdp_sock *xs = xdp_sk(sk);\n\tstruct xdp_diag_msg *msg;\n\tstruct nlmsghdr *nlh;\n\n\tnlh = nlmsg_put(nlskb, portid, seq, SOCK_DIAG_BY_FAMILY, sizeof(*msg),\n\t\t\tflags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tmsg = nlmsg_data(nlh);\n\tmemset(msg, 0, sizeof(*msg));\n\tmsg->xdiag_family = AF_XDP;\n\tmsg->xdiag_type = sk->sk_type;\n\tmsg->xdiag_ino = sk_ino;\n\tsock_diag_save_cookie(sk, msg->xdiag_cookie);\n\n\tmutex_lock(&xs->mutex);\n\tif (READ_ONCE(xs->state) == XSK_UNBOUND)\n\t\tgoto out_nlmsg_trim;\n\n\tif ((req->xdiag_show & XDP_SHOW_INFO) && xsk_diag_put_info(xs, nlskb))\n\t\tgoto out_nlmsg_trim;\n\n\tif ((req->xdiag_show & XDP_SHOW_INFO) &&\n\t    nla_put_u32(nlskb, XDP_DIAG_UID,\n\t\t\tfrom_kuid_munged(user_ns, sock_i_uid(sk))))\n\t\tgoto out_nlmsg_trim;\n\n\tif ((req->xdiag_show & XDP_SHOW_RING_CFG) &&\n\t    xsk_diag_put_rings_cfg(xs, nlskb))\n\t\tgoto out_nlmsg_trim;\n\n\tif ((req->xdiag_show & XDP_SHOW_UMEM) &&\n\t    xsk_diag_put_umem(xs, nlskb))\n\t\tgoto out_nlmsg_trim;\n\n\tif ((req->xdiag_show & XDP_SHOW_MEMINFO) &&\n\t    sock_diag_put_meminfo(sk, nlskb, XDP_DIAG_MEMINFO))\n\t\tgoto out_nlmsg_trim;\n\n\tif ((req->xdiag_show & XDP_SHOW_STATS) &&\n\t    xsk_diag_put_stats(xs, nlskb))\n\t\tgoto out_nlmsg_trim;\n\n\tmutex_unlock(&xs->mutex);\n\tnlmsg_end(nlskb, nlh);\n\treturn 0;\n\nout_nlmsg_trim:\n\tmutex_unlock(&xs->mutex);\n\tnlmsg_cancel(nlskb, nlh);\n\treturn -EMSGSIZE;\n}\n\nstatic int xsk_diag_dump(struct sk_buff *nlskb, struct netlink_callback *cb)\n{\n\tstruct xdp_diag_req *req = nlmsg_data(cb->nlh);\n\tstruct net *net = sock_net(nlskb->sk);\n\tint num = 0, s_num = cb->args[0];\n\tstruct sock *sk;\n\n\tmutex_lock(&net->xdp.lock);\n\n\tsk_for_each(sk, &net->xdp.list) {\n\t\tif (!net_eq(sock_net(sk), net))\n\t\t\tcontinue;\n\t\tif (num++ < s_num)\n\t\t\tcontinue;\n\n\t\tif (xsk_diag_fill(sk, nlskb, req,\n\t\t\t\t  sk_user_ns(NETLINK_CB(cb->skb).sk),\n\t\t\t\t  NETLINK_CB(cb->skb).portid,\n\t\t\t\t  cb->nlh->nlmsg_seq, NLM_F_MULTI,\n\t\t\t\t  sock_i_ino(sk)) < 0) {\n\t\t\tnum--;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmutex_unlock(&net->xdp.lock);\n\tcb->args[0] = num;\n\treturn nlskb->len;\n}\n\nstatic int xsk_diag_handler_dump(struct sk_buff *nlskb, struct nlmsghdr *hdr)\n{\n\tstruct netlink_dump_control c = { .dump = xsk_diag_dump };\n\tint hdrlen = sizeof(struct xdp_diag_req);\n\tstruct net *net = sock_net(nlskb->sk);\n\n\tif (nlmsg_len(hdr) < hdrlen)\n\t\treturn -EINVAL;\n\n\tif (!(hdr->nlmsg_flags & NLM_F_DUMP))\n\t\treturn -EOPNOTSUPP;\n\n\treturn netlink_dump_start(net->diag_nlsk, nlskb, hdr, &c);\n}\n\nstatic const struct sock_diag_handler xsk_diag_handler = {\n\t.family = AF_XDP,\n\t.dump = xsk_diag_handler_dump,\n};\n\nstatic int __init xsk_diag_init(void)\n{\n\treturn sock_diag_register(&xsk_diag_handler);\n}\n\nstatic void __exit xsk_diag_exit(void)\n{\n\tsock_diag_unregister(&xsk_diag_handler);\n}\n\nmodule_init(xsk_diag_init);\nmodule_exit(xsk_diag_exit);\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_NET_PF_PROTO_TYPE(PF_NETLINK, NETLINK_SOCK_DIAG, AF_XDP);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}