{
  "module_name": "rdma.c",
  "hash_id": "e246c665c6f8770ebd8f7c63589c1af10fbab07f6c26a357ebd810f81c611334",
  "original_prompt": "Ingested from linux-6.6.14/net/rds/rdma.c",
  "human_readable_source": " \n#include <linux/pagemap.h>\n#include <linux/slab.h>\n#include <linux/rbtree.h>\n#include <linux/dma-mapping.h>  \n\n#include \"rds.h\"\n\n \n\n \nstatic unsigned int rds_pages_in_vec(struct rds_iovec *vec)\n{\n\tif ((vec->addr + vec->bytes <= vec->addr) ||\n\t    (vec->bytes > (u64)UINT_MAX))\n\t\treturn 0;\n\n\treturn ((vec->addr + vec->bytes + PAGE_SIZE - 1) >> PAGE_SHIFT) -\n\t\t(vec->addr >> PAGE_SHIFT);\n}\n\nstatic struct rds_mr *rds_mr_tree_walk(struct rb_root *root, u64 key,\n\t\t\t\t       struct rds_mr *insert)\n{\n\tstruct rb_node **p = &root->rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct rds_mr *mr;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tmr = rb_entry(parent, struct rds_mr, r_rb_node);\n\n\t\tif (key < mr->r_key)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (key > mr->r_key)\n\t\t\tp = &(*p)->rb_right;\n\t\telse\n\t\t\treturn mr;\n\t}\n\n\tif (insert) {\n\t\trb_link_node(&insert->r_rb_node, parent, p);\n\t\trb_insert_color(&insert->r_rb_node, root);\n\t\tkref_get(&insert->r_kref);\n\t}\n\treturn NULL;\n}\n\n \nstatic void rds_destroy_mr(struct rds_mr *mr)\n{\n\tstruct rds_sock *rs = mr->r_sock;\n\tvoid *trans_private = NULL;\n\tunsigned long flags;\n\n\trdsdebug(\"RDS: destroy mr key is %x refcnt %u\\n\",\n\t\t mr->r_key, kref_read(&mr->r_kref));\n\n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tif (!RB_EMPTY_NODE(&mr->r_rb_node))\n\t\trb_erase(&mr->r_rb_node, &rs->rs_rdma_keys);\n\ttrans_private = mr->r_trans_private;\n\tmr->r_trans_private = NULL;\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tif (trans_private)\n\t\tmr->r_trans->free_mr(trans_private, mr->r_invalidate);\n}\n\nvoid __rds_put_mr_final(struct kref *kref)\n{\n\tstruct rds_mr *mr = container_of(kref, struct rds_mr, r_kref);\n\n\trds_destroy_mr(mr);\n\tkfree(mr);\n}\n\n \nvoid rds_rdma_drop_keys(struct rds_sock *rs)\n{\n\tstruct rds_mr *mr;\n\tstruct rb_node *node;\n\tunsigned long flags;\n\n\t \n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\twhile ((node = rb_first(&rs->rs_rdma_keys))) {\n\t\tmr = rb_entry(node, struct rds_mr, r_rb_node);\n\t\tif (mr->r_trans == rs->rs_transport)\n\t\t\tmr->r_invalidate = 0;\n\t\trb_erase(&mr->r_rb_node, &rs->rs_rdma_keys);\n\t\tRB_CLEAR_NODE(&mr->r_rb_node);\n\t\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\t\tkref_put(&mr->r_kref, __rds_put_mr_final);\n\t\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\t}\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tif (rs->rs_transport && rs->rs_transport->flush_mrs)\n\t\trs->rs_transport->flush_mrs();\n}\n\n \nstatic int rds_pin_pages(unsigned long user_addr, unsigned int nr_pages,\n\t\t\tstruct page **pages, int write)\n{\n\tunsigned int gup_flags = FOLL_LONGTERM;\n\tint ret;\n\n\tif (write)\n\t\tgup_flags |= FOLL_WRITE;\n\n\tret = pin_user_pages_fast(user_addr, nr_pages, gup_flags, pages);\n\tif (ret >= 0 && ret < nr_pages) {\n\t\tunpin_user_pages(pages, ret);\n\t\tret = -EFAULT;\n\t}\n\n\treturn ret;\n}\n\nstatic int __rds_rdma_map(struct rds_sock *rs, struct rds_get_mr_args *args,\n\t\t\t  u64 *cookie_ret, struct rds_mr **mr_ret,\n\t\t\t  struct rds_conn_path *cp)\n{\n\tstruct rds_mr *mr = NULL, *found;\n\tstruct scatterlist *sg = NULL;\n\tunsigned int nr_pages;\n\tstruct page **pages = NULL;\n\tvoid *trans_private;\n\tunsigned long flags;\n\trds_rdma_cookie_t cookie;\n\tunsigned int nents = 0;\n\tint need_odp = 0;\n\tlong i;\n\tint ret;\n\n\tif (ipv6_addr_any(&rs->rs_bound_addr) || !rs->rs_transport) {\n\t\tret = -ENOTCONN;  \n\t\tgoto out;\n\t}\n\n\tif (!rs->rs_transport->get_mr) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\t \n\tif (((args->vec.addr + args->vec.bytes) < args->vec.addr) ||\n\t    PAGE_ALIGN(args->vec.addr + args->vec.bytes) <\n\t\t    (args->vec.addr + args->vec.bytes)) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!can_do_mlock()) {\n\t\tret = -EPERM;\n\t\tgoto out;\n\t}\n\n\tnr_pages = rds_pages_in_vec(&args->vec);\n\tif (nr_pages == 0) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t \n\tif ((nr_pages - 1) > (RDS_MAX_MSG_SIZE >> PAGE_SHIFT)) {\n\t\tret = -EMSGSIZE;\n\t\tgoto out;\n\t}\n\n\trdsdebug(\"RDS: get_mr addr %llx len %llu nr_pages %u\\n\",\n\t\targs->vec.addr, args->vec.bytes, nr_pages);\n\n\t \n\tpages = kcalloc(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!pages) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmr = kzalloc(sizeof(struct rds_mr), GFP_KERNEL);\n\tif (!mr) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tkref_init(&mr->r_kref);\n\tRB_CLEAR_NODE(&mr->r_rb_node);\n\tmr->r_trans = rs->rs_transport;\n\tmr->r_sock = rs;\n\n\tif (args->flags & RDS_RDMA_USE_ONCE)\n\t\tmr->r_use_once = 1;\n\tif (args->flags & RDS_RDMA_INVALIDATE)\n\t\tmr->r_invalidate = 1;\n\tif (args->flags & RDS_RDMA_READWRITE)\n\t\tmr->r_write = 1;\n\n\t \n\tret = rds_pin_pages(args->vec.addr, nr_pages, pages, 1);\n\tif (ret == -EOPNOTSUPP) {\n\t\tneed_odp = 1;\n\t} else if (ret <= 0) {\n\t\tgoto out;\n\t} else {\n\t\tnents = ret;\n\t\tsg = kmalloc_array(nents, sizeof(*sg), GFP_KERNEL);\n\t\tif (!sg) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tWARN_ON(!nents);\n\t\tsg_init_table(sg, nents);\n\n\t\t \n\t\tfor (i = 0 ; i < nents; i++)\n\t\t\tsg_set_page(&sg[i], pages[i], PAGE_SIZE, 0);\n\n\t\trdsdebug(\"RDS: trans_private nents is %u\\n\", nents);\n\t}\n\t \n\ttrans_private = rs->rs_transport->get_mr(\n\t\tsg, nents, rs, &mr->r_key, cp ? cp->cp_conn : NULL,\n\t\targs->vec.addr, args->vec.bytes,\n\t\tneed_odp ? ODP_ZEROBASED : ODP_NOT_NEEDED);\n\n\tif (IS_ERR(trans_private)) {\n\t\t \n\t\tif (!need_odp) {\n\t\t\tunpin_user_pages(pages, nr_pages);\n\t\t\tkfree(sg);\n\t\t}\n\t\tret = PTR_ERR(trans_private);\n\t\tgoto out;\n\t}\n\n\tmr->r_trans_private = trans_private;\n\n\trdsdebug(\"RDS: get_mr put_user key is %x cookie_addr %p\\n\",\n\t       mr->r_key, (void *)(unsigned long) args->cookie_addr);\n\n\t \n\tif (need_odp)\n\t\tcookie = rds_rdma_make_cookie(mr->r_key, 0);\n\telse\n\t\tcookie = rds_rdma_make_cookie(mr->r_key,\n\t\t\t\t\t      args->vec.addr & ~PAGE_MASK);\n\tif (cookie_ret)\n\t\t*cookie_ret = cookie;\n\n\tif (args->cookie_addr &&\n\t    put_user(cookie, (u64 __user *)(unsigned long)args->cookie_addr)) {\n\t\tif (!need_odp) {\n\t\t\tunpin_user_pages(pages, nr_pages);\n\t\t\tkfree(sg);\n\t\t}\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\t \n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tfound = rds_mr_tree_walk(&rs->rs_rdma_keys, mr->r_key, mr);\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tBUG_ON(found && found != mr);\n\n\trdsdebug(\"RDS: get_mr key is %x\\n\", mr->r_key);\n\tif (mr_ret) {\n\t\tkref_get(&mr->r_kref);\n\t\t*mr_ret = mr;\n\t}\n\n\tret = 0;\nout:\n\tkfree(pages);\n\tif (mr)\n\t\tkref_put(&mr->r_kref, __rds_put_mr_final);\n\treturn ret;\n}\n\nint rds_get_mr(struct rds_sock *rs, sockptr_t optval, int optlen)\n{\n\tstruct rds_get_mr_args args;\n\n\tif (optlen != sizeof(struct rds_get_mr_args))\n\t\treturn -EINVAL;\n\n\tif (copy_from_sockptr(&args, optval, sizeof(struct rds_get_mr_args)))\n\t\treturn -EFAULT;\n\n\treturn __rds_rdma_map(rs, &args, NULL, NULL, NULL);\n}\n\nint rds_get_mr_for_dest(struct rds_sock *rs, sockptr_t optval, int optlen)\n{\n\tstruct rds_get_mr_for_dest_args args;\n\tstruct rds_get_mr_args new_args;\n\n\tif (optlen != sizeof(struct rds_get_mr_for_dest_args))\n\t\treturn -EINVAL;\n\n\tif (copy_from_sockptr(&args, optval,\n\t\t\t   sizeof(struct rds_get_mr_for_dest_args)))\n\t\treturn -EFAULT;\n\n\t \n\tnew_args.vec = args.vec;\n\tnew_args.cookie_addr = args.cookie_addr;\n\tnew_args.flags = args.flags;\n\n\treturn __rds_rdma_map(rs, &new_args, NULL, NULL, NULL);\n}\n\n \nint rds_free_mr(struct rds_sock *rs, sockptr_t optval, int optlen)\n{\n\tstruct rds_free_mr_args args;\n\tstruct rds_mr *mr;\n\tunsigned long flags;\n\n\tif (optlen != sizeof(struct rds_free_mr_args))\n\t\treturn -EINVAL;\n\n\tif (copy_from_sockptr(&args, optval, sizeof(struct rds_free_mr_args)))\n\t\treturn -EFAULT;\n\n\t \n\tif (args.cookie == 0) {\n\t\tif (!rs->rs_transport || !rs->rs_transport->flush_mrs)\n\t\t\treturn -EINVAL;\n\t\trs->rs_transport->flush_mrs();\n\t\treturn 0;\n\t}\n\n\t \n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tmr = rds_mr_tree_walk(&rs->rs_rdma_keys, rds_rdma_cookie_key(args.cookie), NULL);\n\tif (mr) {\n\t\trb_erase(&mr->r_rb_node, &rs->rs_rdma_keys);\n\t\tRB_CLEAR_NODE(&mr->r_rb_node);\n\t\tif (args.flags & RDS_RDMA_INVALIDATE)\n\t\t\tmr->r_invalidate = 1;\n\t}\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tif (!mr)\n\t\treturn -EINVAL;\n\n\tkref_put(&mr->r_kref, __rds_put_mr_final);\n\treturn 0;\n}\n\n \nvoid rds_rdma_unuse(struct rds_sock *rs, u32 r_key, int force)\n{\n\tstruct rds_mr *mr;\n\tunsigned long flags;\n\tint zot_me = 0;\n\n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tmr = rds_mr_tree_walk(&rs->rs_rdma_keys, r_key, NULL);\n\tif (!mr) {\n\t\tpr_debug(\"rds: trying to unuse MR with unknown r_key %u!\\n\",\n\t\t\t r_key);\n\t\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\t\treturn;\n\t}\n\n\t \n\tkref_get(&mr->r_kref);\n\n\t \n\tif (mr->r_use_once || force) {\n\t\trb_erase(&mr->r_rb_node, &rs->rs_rdma_keys);\n\t\tRB_CLEAR_NODE(&mr->r_rb_node);\n\t\tzot_me = 1;\n\t}\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\t \n\tif (mr->r_trans->sync_mr)\n\t\tmr->r_trans->sync_mr(mr->r_trans_private, DMA_FROM_DEVICE);\n\n\t \n\tkref_put(&mr->r_kref, __rds_put_mr_final);\n\n\t \n\tif (zot_me)\n\t\tkref_put(&mr->r_kref, __rds_put_mr_final);\n}\n\nvoid rds_rdma_free_op(struct rm_rdma_op *ro)\n{\n\tunsigned int i;\n\n\tif (ro->op_odp_mr) {\n\t\tkref_put(&ro->op_odp_mr->r_kref, __rds_put_mr_final);\n\t} else {\n\t\tfor (i = 0; i < ro->op_nents; i++) {\n\t\t\tstruct page *page = sg_page(&ro->op_sg[i]);\n\n\t\t\t \n\t\t\tunpin_user_pages_dirty_lock(&page, 1, !ro->op_write);\n\t\t}\n\t}\n\n\tkfree(ro->op_notifier);\n\tro->op_notifier = NULL;\n\tro->op_active = 0;\n\tro->op_odp_mr = NULL;\n}\n\nvoid rds_atomic_free_op(struct rm_atomic_op *ao)\n{\n\tstruct page *page = sg_page(ao->op_sg);\n\n\t \n\tunpin_user_pages_dirty_lock(&page, 1, true);\n\n\tkfree(ao->op_notifier);\n\tao->op_notifier = NULL;\n\tao->op_active = 0;\n}\n\n\n \nstatic int rds_rdma_pages(struct rds_iovec iov[], int nr_iovecs)\n{\n\tint tot_pages = 0;\n\tunsigned int nr_pages;\n\tunsigned int i;\n\n\t \n\tfor (i = 0; i < nr_iovecs; i++) {\n\t\tnr_pages = rds_pages_in_vec(&iov[i]);\n\t\tif (nr_pages == 0)\n\t\t\treturn -EINVAL;\n\n\t\ttot_pages += nr_pages;\n\n\t\t \n\t\tif (tot_pages < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn tot_pages;\n}\n\nint rds_rdma_extra_size(struct rds_rdma_args *args,\n\t\t\tstruct rds_iov_vector *iov)\n{\n\tstruct rds_iovec *vec;\n\tstruct rds_iovec __user *local_vec;\n\tint tot_pages = 0;\n\tunsigned int nr_pages;\n\tunsigned int i;\n\n\tlocal_vec = (struct rds_iovec __user *)(unsigned long) args->local_vec_addr;\n\n\tif (args->nr_local == 0)\n\t\treturn -EINVAL;\n\n\tif (args->nr_local > UIO_MAXIOV)\n\t\treturn -EMSGSIZE;\n\n\tiov->iov = kcalloc(args->nr_local,\n\t\t\t   sizeof(struct rds_iovec),\n\t\t\t   GFP_KERNEL);\n\tif (!iov->iov)\n\t\treturn -ENOMEM;\n\n\tvec = &iov->iov[0];\n\n\tif (copy_from_user(vec, local_vec, args->nr_local *\n\t\t\t   sizeof(struct rds_iovec)))\n\t\treturn -EFAULT;\n\tiov->len = args->nr_local;\n\n\t \n\tfor (i = 0; i < args->nr_local; i++, vec++) {\n\n\t\tnr_pages = rds_pages_in_vec(vec);\n\t\tif (nr_pages == 0)\n\t\t\treturn -EINVAL;\n\n\t\ttot_pages += nr_pages;\n\n\t\t \n\t\tif (tot_pages < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn tot_pages * sizeof(struct scatterlist);\n}\n\n \nint rds_cmsg_rdma_args(struct rds_sock *rs, struct rds_message *rm,\n\t\t       struct cmsghdr *cmsg,\n\t\t       struct rds_iov_vector *vec)\n{\n\tstruct rds_rdma_args *args;\n\tstruct rm_rdma_op *op = &rm->rdma;\n\tint nr_pages;\n\tunsigned int nr_bytes;\n\tstruct page **pages = NULL;\n\tstruct rds_iovec *iovs;\n\tunsigned int i, j;\n\tint ret = 0;\n\tbool odp_supported = true;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_rdma_args))\n\t    || rm->rdma.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\tif (ipv6_addr_any(&rs->rs_bound_addr)) {\n\t\tret = -ENOTCONN;  \n\t\tgoto out_ret;\n\t}\n\n\tif (args->nr_local > UIO_MAXIOV) {\n\t\tret = -EMSGSIZE;\n\t\tgoto out_ret;\n\t}\n\n\tif (vec->len != args->nr_local) {\n\t\tret = -EINVAL;\n\t\tgoto out_ret;\n\t}\n\t \n\tif (args->nr_local != 1)\n\t\todp_supported = false;\n\n\tiovs = vec->iov;\n\n\tnr_pages = rds_rdma_pages(iovs, args->nr_local);\n\tif (nr_pages < 0) {\n\t\tret = -EINVAL;\n\t\tgoto out_ret;\n\t}\n\n\tpages = kcalloc(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!pages) {\n\t\tret = -ENOMEM;\n\t\tgoto out_ret;\n\t}\n\n\top->op_write = !!(args->flags & RDS_RDMA_READWRITE);\n\top->op_fence = !!(args->flags & RDS_RDMA_FENCE);\n\top->op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\top->op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\top->op_active = 1;\n\top->op_recverr = rs->rs_recverr;\n\top->op_odp_mr = NULL;\n\n\tWARN_ON(!nr_pages);\n\top->op_sg = rds_message_alloc_sgs(rm, nr_pages);\n\tif (IS_ERR(op->op_sg)) {\n\t\tret = PTR_ERR(op->op_sg);\n\t\tgoto out_pages;\n\t}\n\n\tif (op->op_notify || op->op_recverr) {\n\t\t \n\t\top->op_notifier = kmalloc(sizeof(struct rds_notifier), GFP_KERNEL);\n\t\tif (!op->op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_pages;\n\t\t}\n\t\top->op_notifier->n_user_token = args->user_token;\n\t\top->op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\t \n\top->op_rkey = rds_rdma_cookie_key(args->cookie);\n\top->op_remote_addr = args->remote_vec.addr + rds_rdma_cookie_offset(args->cookie);\n\n\tnr_bytes = 0;\n\n\trdsdebug(\"RDS: rdma prepare nr_local %llu rva %llx rkey %x\\n\",\n\t       (unsigned long long)args->nr_local,\n\t       (unsigned long long)args->remote_vec.addr,\n\t       op->op_rkey);\n\n\tfor (i = 0; i < args->nr_local; i++) {\n\t\tstruct rds_iovec *iov = &iovs[i];\n\t\t \n\t\tunsigned int nr = rds_pages_in_vec(iov);\n\n\t\trs->rs_user_addr = iov->addr;\n\t\trs->rs_user_bytes = iov->bytes;\n\n\t\t \n\t\tret = rds_pin_pages(iov->addr, nr, pages, !op->op_write);\n\t\tif ((!odp_supported && ret <= 0) ||\n\t\t    (odp_supported && ret <= 0 && ret != -EOPNOTSUPP))\n\t\t\tgoto out_pages;\n\n\t\tif (ret == -EOPNOTSUPP) {\n\t\t\tstruct rds_mr *local_odp_mr;\n\n\t\t\tif (!rs->rs_transport->get_mr) {\n\t\t\t\tret = -EOPNOTSUPP;\n\t\t\t\tgoto out_pages;\n\t\t\t}\n\t\t\tlocal_odp_mr =\n\t\t\t\tkzalloc(sizeof(*local_odp_mr), GFP_KERNEL);\n\t\t\tif (!local_odp_mr) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out_pages;\n\t\t\t}\n\t\t\tRB_CLEAR_NODE(&local_odp_mr->r_rb_node);\n\t\t\tkref_init(&local_odp_mr->r_kref);\n\t\t\tlocal_odp_mr->r_trans = rs->rs_transport;\n\t\t\tlocal_odp_mr->r_sock = rs;\n\t\t\tlocal_odp_mr->r_trans_private =\n\t\t\t\trs->rs_transport->get_mr(\n\t\t\t\t\tNULL, 0, rs, &local_odp_mr->r_key, NULL,\n\t\t\t\t\tiov->addr, iov->bytes, ODP_VIRTUAL);\n\t\t\tif (IS_ERR(local_odp_mr->r_trans_private)) {\n\t\t\t\tret = PTR_ERR(local_odp_mr->r_trans_private);\n\t\t\t\trdsdebug(\"get_mr ret %d %p\\\"\", ret,\n\t\t\t\t\t local_odp_mr->r_trans_private);\n\t\t\t\tkfree(local_odp_mr);\n\t\t\t\tret = -EOPNOTSUPP;\n\t\t\t\tgoto out_pages;\n\t\t\t}\n\t\t\trdsdebug(\"Need odp; local_odp_mr %p trans_private %p\\n\",\n\t\t\t\t local_odp_mr, local_odp_mr->r_trans_private);\n\t\t\top->op_odp_mr = local_odp_mr;\n\t\t\top->op_odp_addr = iov->addr;\n\t\t}\n\n\t\trdsdebug(\"RDS: nr_bytes %u nr %u iov->bytes %llu iov->addr %llx\\n\",\n\t\t\t nr_bytes, nr, iov->bytes, iov->addr);\n\n\t\tnr_bytes += iov->bytes;\n\n\t\tfor (j = 0; j < nr; j++) {\n\t\t\tunsigned int offset = iov->addr & ~PAGE_MASK;\n\t\t\tstruct scatterlist *sg;\n\n\t\t\tsg = &op->op_sg[op->op_nents + j];\n\t\t\tsg_set_page(sg, pages[j],\n\t\t\t\t\tmin_t(unsigned int, iov->bytes, PAGE_SIZE - offset),\n\t\t\t\t\toffset);\n\n\t\t\tsg_dma_len(sg) = sg->length;\n\t\t\trdsdebug(\"RDS: sg->offset %x sg->len %x iov->addr %llx iov->bytes %llu\\n\",\n\t\t\t       sg->offset, sg->length, iov->addr, iov->bytes);\n\n\t\t\tiov->addr += sg->length;\n\t\t\tiov->bytes -= sg->length;\n\t\t}\n\n\t\top->op_nents += nr;\n\t}\n\n\tif (nr_bytes > args->remote_vec.bytes) {\n\t\trdsdebug(\"RDS nr_bytes %u remote_bytes %u do not match\\n\",\n\t\t\t\tnr_bytes,\n\t\t\t\t(unsigned int) args->remote_vec.bytes);\n\t\tret = -EINVAL;\n\t\tgoto out_pages;\n\t}\n\top->op_bytes = nr_bytes;\n\tret = 0;\n\nout_pages:\n\tkfree(pages);\nout_ret:\n\tif (ret)\n\t\trds_rdma_free_op(op);\n\telse\n\t\trds_stats_inc(s_send_rdma);\n\n\treturn ret;\n}\n\n \nint rds_cmsg_rdma_dest(struct rds_sock *rs, struct rds_message *rm,\n\t\t\t  struct cmsghdr *cmsg)\n{\n\tunsigned long flags;\n\tstruct rds_mr *mr;\n\tu32 r_key;\n\tint err = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(rds_rdma_cookie_t)) ||\n\t    rm->m_rdma_cookie != 0)\n\t\treturn -EINVAL;\n\n\tmemcpy(&rm->m_rdma_cookie, CMSG_DATA(cmsg), sizeof(rm->m_rdma_cookie));\n\n\t \n\tr_key = rds_rdma_cookie_key(rm->m_rdma_cookie);\n\n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tmr = rds_mr_tree_walk(&rs->rs_rdma_keys, r_key, NULL);\n\tif (!mr)\n\t\terr = -EINVAL;\t \n\telse\n\t\tkref_get(&mr->r_kref);\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tif (mr) {\n\t\tmr->r_trans->sync_mr(mr->r_trans_private,\n\t\t\t\t     DMA_TO_DEVICE);\n\t\trm->rdma.op_rdma_mr = mr;\n\t}\n\treturn err;\n}\n\n \nint rds_cmsg_rdma_map(struct rds_sock *rs, struct rds_message *rm,\n\t\t\t  struct cmsghdr *cmsg)\n{\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_get_mr_args)) ||\n\t    rm->m_rdma_cookie != 0)\n\t\treturn -EINVAL;\n\n\treturn __rds_rdma_map(rs, CMSG_DATA(cmsg), &rm->m_rdma_cookie,\n\t\t\t      &rm->rdma.op_rdma_mr, rm->m_conn_path);\n}\n\n \nint rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t \n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG();  \n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (IS_ERR(rm->atomic.op_sg)) {\n\t\tret = PTR_ERR(rm->atomic.op_sg);\n\t\tgoto err;\n\t}\n\n\t \n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t \n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tunpin_user_page(page);\n\trm->atomic.op_active = 0;\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}