{
  "module_name": "ib.h",
  "hash_id": "db7894a0383f077282e0dfb7cb7d04dca1eb8eeb5eb3eb59ef4514e4b3ec653b",
  "original_prompt": "Ingested from linux-6.6.14/net/rds/ib.h",
  "human_readable_source": " \n#ifndef _RDS_IB_H\n#define _RDS_IB_H\n\n#include <rdma/ib_verbs.h>\n#include <rdma/rdma_cm.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/slab.h>\n#include \"rds.h\"\n#include \"rdma_transport.h\"\n\n#define RDS_IB_MAX_SGE\t\t\t8\n#define RDS_IB_RECV_SGE \t\t2\n\n#define RDS_IB_DEFAULT_RECV_WR\t\t1024\n#define RDS_IB_DEFAULT_SEND_WR\t\t256\n#define RDS_IB_DEFAULT_FR_WR\t\t512\n\n#define RDS_IB_DEFAULT_RETRY_COUNT\t1\n\n#define RDS_IB_SUPPORTED_PROTOCOLS\t0x00000003\t \n\n#define RDS_IB_RECYCLE_BATCH_COUNT\t32\n\n#define RDS_IB_WC_MAX\t\t\t32\n\nextern struct rw_semaphore rds_ib_devices_lock;\nextern struct list_head rds_ib_devices;\n\n \nstruct rds_page_frag {\n\tstruct list_head\tf_item;\n\tstruct list_head\tf_cache_entry;\n\tstruct scatterlist\tf_sg;\n};\n\nstruct rds_ib_incoming {\n\tstruct list_head\tii_frags;\n\tstruct list_head\tii_cache_entry;\n\tstruct rds_incoming\tii_inc;\n};\n\nstruct rds_ib_cache_head {\n\tstruct list_head *first;\n\tunsigned long count;\n};\n\nstruct rds_ib_refill_cache {\n\tstruct rds_ib_cache_head __percpu *percpu;\n\tstruct list_head\t *xfer;\n\tstruct list_head\t *ready;\n};\n\n \nstruct rds_ib_conn_priv_cmn {\n\tu8\t\t\tricpc_protocol_major;\n\tu8\t\t\tricpc_protocol_minor;\n\t__be16\t\t\tricpc_protocol_minor_mask;\t \n\tu8\t\t\tricpc_dp_toss;\n\tu8\t\t\tripc_reserved1;\n\t__be16\t\t\tripc_reserved2;\n\t__be64\t\t\tricpc_ack_seq;\n\t__be32\t\t\tricpc_credit;\t \n};\n\nstruct rds_ib_connect_private {\n\t \n\t__be32\t\t\t\tdp_saddr;\n\t__be32\t\t\t\tdp_daddr;\n\tstruct rds_ib_conn_priv_cmn\tdp_cmn;\n};\n\nstruct rds6_ib_connect_private {\n\t \n\tstruct in6_addr\t\t\tdp_saddr;\n\tstruct in6_addr\t\t\tdp_daddr;\n\tstruct rds_ib_conn_priv_cmn\tdp_cmn;\n};\n\n#define dp_protocol_major\tdp_cmn.ricpc_protocol_major\n#define dp_protocol_minor\tdp_cmn.ricpc_protocol_minor\n#define dp_protocol_minor_mask\tdp_cmn.ricpc_protocol_minor_mask\n#define dp_ack_seq\t\tdp_cmn.ricpc_ack_seq\n#define dp_credit\t\tdp_cmn.ricpc_credit\n\nunion rds_ib_conn_priv {\n\tstruct rds_ib_connect_private\tricp_v4;\n\tstruct rds6_ib_connect_private\tricp_v6;\n};\n\nstruct rds_ib_send_work {\n\tvoid\t\t\t*s_op;\n\tunion {\n\t\tstruct ib_send_wr\ts_wr;\n\t\tstruct ib_rdma_wr\ts_rdma_wr;\n\t\tstruct ib_atomic_wr\ts_atomic_wr;\n\t};\n\tstruct ib_sge\t\ts_sge[RDS_IB_MAX_SGE];\n\tunsigned long\t\ts_queued;\n};\n\nstruct rds_ib_recv_work {\n\tstruct rds_ib_incoming \t*r_ibinc;\n\tstruct rds_page_frag\t*r_frag;\n\tstruct ib_recv_wr\tr_wr;\n\tstruct ib_sge\t\tr_sge[2];\n};\n\nstruct rds_ib_work_ring {\n\tu32\t\tw_nr;\n\tu32\t\tw_alloc_ptr;\n\tu32\t\tw_alloc_ctr;\n\tu32\t\tw_free_ptr;\n\tatomic_t\tw_free_ctr;\n};\n\n \nstruct rds_ib_ack_state {\n\tu64\t\tack_next;\n\tu64\t\tack_recv;\n\tunsigned int\tack_required:1;\n\tunsigned int\tack_next_valid:1;\n\tunsigned int\tack_recv_valid:1;\n};\n\n\nstruct rds_ib_device;\n\nstruct rds_ib_connection {\n\n\tstruct list_head\tib_node;\n\tstruct rds_ib_device\t*rds_ibdev;\n\tstruct rds_connection\t*conn;\n\n\t \n\tstruct rdma_cm_id\t*i_cm_id;\n\tstruct ib_pd\t\t*i_pd;\n\tstruct ib_cq\t\t*i_send_cq;\n\tstruct ib_cq\t\t*i_recv_cq;\n\tstruct ib_wc\t\ti_send_wc[RDS_IB_WC_MAX];\n\tstruct ib_wc\t\ti_recv_wc[RDS_IB_WC_MAX];\n\n\t \n\tatomic_t\t\ti_fastreg_wrs;\n\tatomic_t\t\ti_fastreg_inuse_count;\n\n\t \n\tstruct tasklet_struct\ti_send_tasklet;\n\tstruct tasklet_struct\ti_recv_tasklet;\n\n\t \n\tstruct rds_ib_work_ring\ti_send_ring;\n\tstruct rm_data_op\t*i_data_op;\n\tstruct rds_header\t**i_send_hdrs;\n\tdma_addr_t\t\t*i_send_hdrs_dma;\n\tstruct rds_ib_send_work *i_sends;\n\tatomic_t\t\ti_signaled_sends;\n\n\t \n\tstruct mutex\t\ti_recv_mutex;\n\tstruct rds_ib_work_ring\ti_recv_ring;\n\tstruct rds_ib_incoming\t*i_ibinc;\n\tu32\t\t\ti_recv_data_rem;\n\tstruct rds_header\t**i_recv_hdrs;\n\tdma_addr_t\t\t*i_recv_hdrs_dma;\n\tstruct rds_ib_recv_work *i_recvs;\n\tu64\t\t\ti_ack_recv;\t \n\tstruct rds_ib_refill_cache i_cache_incs;\n\tstruct rds_ib_refill_cache i_cache_frags;\n\tatomic_t\t\ti_cache_allocs;\n\n\t \n\tunsigned long\t\ti_ack_flags;\n#ifdef KERNEL_HAS_ATOMIC64\n\tatomic64_t\t\ti_ack_next;\t \n#else\n\tspinlock_t\t\ti_ack_lock;\t \n\tu64\t\t\ti_ack_next;\t \n#endif\n\tstruct rds_header\t*i_ack;\n\tstruct ib_send_wr\ti_ack_wr;\n\tstruct ib_sge\t\ti_ack_sge;\n\tdma_addr_t\t\ti_ack_dma;\n\tunsigned long\t\ti_ack_queued;\n\n\t \n\tatomic_t\t\ti_credits;\n\n\t \n\tunsigned int\t\ti_flowctl:1;\t \n\n\t \n\tunsigned int\t\ti_unsignaled_wrs;\n\n\t \n\tbool\t\t\ti_active_side;\n\tatomic_t\t\ti_cq_quiesce;\n\n\t \n\tint\t\t\ti_scq_vector;\n\tint\t\t\ti_rcq_vector;\n\tu8\t\t\ti_sl;\n};\n\n \n#define IB_GET_SEND_CREDITS(v)\t((v) & 0xffff)\n#define IB_GET_POST_CREDITS(v)\t((v) >> 16)\n#define IB_SET_SEND_CREDITS(v)\t((v) & 0xffff)\n#define IB_SET_POST_CREDITS(v)\t((v) << 16)\n\nstruct rds_ib_ipaddr {\n\tstruct list_head\tlist;\n\t__be32\t\t\tipaddr;\n\tstruct rcu_head\t\trcu;\n};\n\nenum {\n\tRDS_IB_MR_8K_POOL,\n\tRDS_IB_MR_1M_POOL,\n};\n\nstruct rds_ib_device {\n\tstruct list_head\tlist;\n\tstruct list_head\tipaddr_list;\n\tstruct list_head\tconn_list;\n\tstruct ib_device\t*dev;\n\tstruct ib_pd\t\t*pd;\n\tu8\t\t\todp_capable:1;\n\n\tunsigned int\t\tmax_mrs;\n\tstruct rds_ib_mr_pool\t*mr_1m_pool;\n\tstruct rds_ib_mr_pool   *mr_8k_pool;\n\tunsigned int\t\tmax_8k_mrs;\n\tunsigned int\t\tmax_1m_mrs;\n\tint\t\t\tmax_sge;\n\tunsigned int\t\tmax_wrs;\n\tunsigned int\t\tmax_initiator_depth;\n\tunsigned int\t\tmax_responder_resources;\n\tspinlock_t\t\tspinlock;\t \n\trefcount_t\t\trefcount;\n\tstruct work_struct\tfree_work;\n\tint\t\t\t*vector_load;\n};\n\n#define rdsibdev_to_node(rdsibdev) ibdev_to_node(rdsibdev->dev)\n\n \n#define IB_ACK_IN_FLIGHT\t0\n#define IB_ACK_REQUESTED\t1\n\n \n#define RDS_IB_ACK_WR_ID\t(~(u64) 0)\n\nstruct rds_ib_statistics {\n\tuint64_t\ts_ib_connect_raced;\n\tuint64_t\ts_ib_listen_closed_stale;\n\tuint64_t\ts_ib_evt_handler_call;\n\tuint64_t\ts_ib_tasklet_call;\n\tuint64_t\ts_ib_tx_cq_event;\n\tuint64_t\ts_ib_tx_ring_full;\n\tuint64_t\ts_ib_tx_throttle;\n\tuint64_t\ts_ib_tx_sg_mapping_failure;\n\tuint64_t\ts_ib_tx_stalled;\n\tuint64_t\ts_ib_tx_credit_updates;\n\tuint64_t\ts_ib_rx_cq_event;\n\tuint64_t\ts_ib_rx_ring_empty;\n\tuint64_t\ts_ib_rx_refill_from_cq;\n\tuint64_t\ts_ib_rx_refill_from_thread;\n\tuint64_t\ts_ib_rx_alloc_limit;\n\tuint64_t\ts_ib_rx_total_frags;\n\tuint64_t\ts_ib_rx_total_incs;\n\tuint64_t\ts_ib_rx_credit_updates;\n\tuint64_t\ts_ib_ack_sent;\n\tuint64_t\ts_ib_ack_send_failure;\n\tuint64_t\ts_ib_ack_send_delayed;\n\tuint64_t\ts_ib_ack_send_piggybacked;\n\tuint64_t\ts_ib_ack_received;\n\tuint64_t\ts_ib_rdma_mr_8k_alloc;\n\tuint64_t\ts_ib_rdma_mr_8k_free;\n\tuint64_t\ts_ib_rdma_mr_8k_used;\n\tuint64_t\ts_ib_rdma_mr_8k_pool_flush;\n\tuint64_t\ts_ib_rdma_mr_8k_pool_wait;\n\tuint64_t\ts_ib_rdma_mr_8k_pool_depleted;\n\tuint64_t\ts_ib_rdma_mr_1m_alloc;\n\tuint64_t\ts_ib_rdma_mr_1m_free;\n\tuint64_t\ts_ib_rdma_mr_1m_used;\n\tuint64_t\ts_ib_rdma_mr_1m_pool_flush;\n\tuint64_t\ts_ib_rdma_mr_1m_pool_wait;\n\tuint64_t\ts_ib_rdma_mr_1m_pool_depleted;\n\tuint64_t\ts_ib_rdma_mr_8k_reused;\n\tuint64_t\ts_ib_rdma_mr_1m_reused;\n\tuint64_t\ts_ib_atomic_cswp;\n\tuint64_t\ts_ib_atomic_fadd;\n\tuint64_t\ts_ib_recv_added_to_cache;\n\tuint64_t\ts_ib_recv_removed_from_cache;\n};\n\nextern struct workqueue_struct *rds_ib_wq;\n\n \nstatic inline void rds_ib_dma_sync_sg_for_cpu(struct ib_device *dev,\n\t\t\t\t\t      struct scatterlist *sglist,\n\t\t\t\t\t      unsigned int sg_dma_len,\n\t\t\t\t\t      int direction)\n{\n\tstruct scatterlist *sg;\n\tunsigned int i;\n\n\tfor_each_sg(sglist, sg, sg_dma_len, i) {\n\t\tib_dma_sync_single_for_cpu(dev, sg_dma_address(sg),\n\t\t\t\t\t   sg_dma_len(sg), direction);\n\t}\n}\n#define ib_dma_sync_sg_for_cpu\trds_ib_dma_sync_sg_for_cpu\n\nstatic inline void rds_ib_dma_sync_sg_for_device(struct ib_device *dev,\n\t\t\t\t\t\t struct scatterlist *sglist,\n\t\t\t\t\t\t unsigned int sg_dma_len,\n\t\t\t\t\t\t int direction)\n{\n\tstruct scatterlist *sg;\n\tunsigned int i;\n\n\tfor_each_sg(sglist, sg, sg_dma_len, i) {\n\t\tib_dma_sync_single_for_device(dev, sg_dma_address(sg),\n\t\t\t\t\t      sg_dma_len(sg), direction);\n\t}\n}\n#define ib_dma_sync_sg_for_device\trds_ib_dma_sync_sg_for_device\n\n\n \nextern struct rds_transport rds_ib_transport;\nstruct rds_ib_device *rds_ib_get_client_data(struct ib_device *device);\nvoid rds_ib_dev_put(struct rds_ib_device *rds_ibdev);\nextern struct ib_client rds_ib_client;\n\nextern unsigned int rds_ib_retry_count;\n\nextern spinlock_t ib_nodev_conns_lock;\nextern struct list_head ib_nodev_conns;\n\n \nint rds_ib_conn_alloc(struct rds_connection *conn, gfp_t gfp);\nvoid rds_ib_conn_free(void *arg);\nint rds_ib_conn_path_connect(struct rds_conn_path *cp);\nvoid rds_ib_conn_path_shutdown(struct rds_conn_path *cp);\nvoid rds_ib_state_change(struct sock *sk);\nint rds_ib_listen_init(void);\nvoid rds_ib_listen_stop(void);\n__printf(2, 3)\nvoid __rds_ib_conn_error(struct rds_connection *conn, const char *, ...);\nint rds_ib_cm_handle_connect(struct rdma_cm_id *cm_id,\n\t\t\t     struct rdma_cm_event *event, bool isv6);\nint rds_ib_cm_initiate_connect(struct rdma_cm_id *cm_id, bool isv6);\nvoid rds_ib_cm_connect_complete(struct rds_connection *conn,\n\t\t\t\tstruct rdma_cm_event *event);\n\n#define rds_ib_conn_error(conn, fmt...) \\\n\t__rds_ib_conn_error(conn, KERN_WARNING \"RDS/IB: \" fmt)\n\n \nint rds_ib_update_ipaddr(struct rds_ib_device *rds_ibdev,\n\t\t\t struct in6_addr *ipaddr);\nvoid rds_ib_add_conn(struct rds_ib_device *rds_ibdev, struct rds_connection *conn);\nvoid rds_ib_remove_conn(struct rds_ib_device *rds_ibdev, struct rds_connection *conn);\nvoid rds_ib_destroy_nodev_conns(void);\nvoid rds_ib_mr_cqe_handler(struct rds_ib_connection *ic, struct ib_wc *wc);\n\n \nint rds_ib_recv_init(void);\nvoid rds_ib_recv_exit(void);\nint rds_ib_recv_path(struct rds_conn_path *conn);\nint rds_ib_recv_alloc_caches(struct rds_ib_connection *ic, gfp_t gfp);\nvoid rds_ib_recv_free_caches(struct rds_ib_connection *ic);\nvoid rds_ib_recv_refill(struct rds_connection *conn, int prefill, gfp_t gfp);\nvoid rds_ib_inc_free(struct rds_incoming *inc);\nint rds_ib_inc_copy_to_user(struct rds_incoming *inc, struct iov_iter *to);\nvoid rds_ib_recv_cqe_handler(struct rds_ib_connection *ic, struct ib_wc *wc,\n\t\t\t     struct rds_ib_ack_state *state);\nvoid rds_ib_recv_tasklet_fn(unsigned long data);\nvoid rds_ib_recv_init_ring(struct rds_ib_connection *ic);\nvoid rds_ib_recv_clear_ring(struct rds_ib_connection *ic);\nvoid rds_ib_recv_init_ack(struct rds_ib_connection *ic);\nvoid rds_ib_attempt_ack(struct rds_ib_connection *ic);\nvoid rds_ib_ack_send_complete(struct rds_ib_connection *ic);\nu64 rds_ib_piggyb_ack(struct rds_ib_connection *ic);\nvoid rds_ib_set_ack(struct rds_ib_connection *ic, u64 seq, int ack_required);\n\n \nvoid rds_ib_ring_init(struct rds_ib_work_ring *ring, u32 nr);\nvoid rds_ib_ring_resize(struct rds_ib_work_ring *ring, u32 nr);\nu32 rds_ib_ring_alloc(struct rds_ib_work_ring *ring, u32 val, u32 *pos);\nvoid rds_ib_ring_free(struct rds_ib_work_ring *ring, u32 val);\nvoid rds_ib_ring_unalloc(struct rds_ib_work_ring *ring, u32 val);\nint rds_ib_ring_empty(struct rds_ib_work_ring *ring);\nint rds_ib_ring_low(struct rds_ib_work_ring *ring);\nu32 rds_ib_ring_oldest(struct rds_ib_work_ring *ring);\nu32 rds_ib_ring_completed(struct rds_ib_work_ring *ring, u32 wr_id, u32 oldest);\nextern wait_queue_head_t rds_ib_ring_empty_wait;\n\n \nvoid rds_ib_xmit_path_complete(struct rds_conn_path *cp);\nint rds_ib_xmit(struct rds_connection *conn, struct rds_message *rm,\n\t\tunsigned int hdr_off, unsigned int sg, unsigned int off);\nvoid rds_ib_send_cqe_handler(struct rds_ib_connection *ic, struct ib_wc *wc);\nvoid rds_ib_send_init_ring(struct rds_ib_connection *ic);\nvoid rds_ib_send_clear_ring(struct rds_ib_connection *ic);\nint rds_ib_xmit_rdma(struct rds_connection *conn, struct rm_rdma_op *op);\nvoid rds_ib_send_add_credits(struct rds_connection *conn, unsigned int credits);\nvoid rds_ib_advertise_credits(struct rds_connection *conn, unsigned int posted);\nint rds_ib_send_grab_credits(struct rds_ib_connection *ic, u32 wanted,\n\t\t\t     u32 *adv_credits, int need_posted, int max_posted);\nint rds_ib_xmit_atomic(struct rds_connection *conn, struct rm_atomic_op *op);\n\n \nDECLARE_PER_CPU_SHARED_ALIGNED(struct rds_ib_statistics, rds_ib_stats);\n#define rds_ib_stats_inc(member) rds_stats_inc_which(rds_ib_stats, member)\n#define rds_ib_stats_add(member, count) \\\n\t\trds_stats_add_which(rds_ib_stats, member, count)\nunsigned int rds_ib_stats_info_copy(struct rds_info_iterator *iter,\n\t\t\t\t    unsigned int avail);\n\n \nint rds_ib_sysctl_init(void);\nvoid rds_ib_sysctl_exit(void);\nextern unsigned long rds_ib_sysctl_max_send_wr;\nextern unsigned long rds_ib_sysctl_max_recv_wr;\nextern unsigned long rds_ib_sysctl_max_unsig_wrs;\nextern unsigned long rds_ib_sysctl_max_unsig_bytes;\nextern unsigned long rds_ib_sysctl_max_recv_allocation;\nextern unsigned int rds_ib_sysctl_flow_control;\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}