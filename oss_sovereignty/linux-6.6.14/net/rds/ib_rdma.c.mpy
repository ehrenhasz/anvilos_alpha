{
  "module_name": "ib_rdma.c",
  "hash_id": "3d2b062186f50c25f71a9420d6e840d3ec07c7935d818a69cdb1252295b52cc5",
  "original_prompt": "Ingested from linux-6.6.14/net/rds/ib_rdma.c",
  "human_readable_source": " \n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/rculist.h>\n#include <linux/llist.h>\n\n#include \"rds_single_path.h\"\n#include \"ib_mr.h\"\n#include \"rds.h\"\n\nstruct workqueue_struct *rds_ib_mr_wq;\nstruct rds_ib_dereg_odp_mr {\n\tstruct work_struct work;\n\tstruct ib_mr *mr;\n};\n\nstatic void rds_ib_odp_mr_worker(struct work_struct *work);\n\nstatic struct rds_ib_device *rds_ib_get_device(__be32 ipaddr)\n{\n\tstruct rds_ib_device *rds_ibdev;\n\tstruct rds_ib_ipaddr *i_ipaddr;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(rds_ibdev, &rds_ib_devices, list) {\n\t\tlist_for_each_entry_rcu(i_ipaddr, &rds_ibdev->ipaddr_list, list) {\n\t\t\tif (i_ipaddr->ipaddr == ipaddr) {\n\t\t\t\trefcount_inc(&rds_ibdev->refcount);\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn rds_ibdev;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn NULL;\n}\n\nstatic int rds_ib_add_ipaddr(struct rds_ib_device *rds_ibdev, __be32 ipaddr)\n{\n\tstruct rds_ib_ipaddr *i_ipaddr;\n\n\ti_ipaddr = kmalloc(sizeof *i_ipaddr, GFP_KERNEL);\n\tif (!i_ipaddr)\n\t\treturn -ENOMEM;\n\n\ti_ipaddr->ipaddr = ipaddr;\n\n\tspin_lock_irq(&rds_ibdev->spinlock);\n\tlist_add_tail_rcu(&i_ipaddr->list, &rds_ibdev->ipaddr_list);\n\tspin_unlock_irq(&rds_ibdev->spinlock);\n\n\treturn 0;\n}\n\nstatic void rds_ib_remove_ipaddr(struct rds_ib_device *rds_ibdev, __be32 ipaddr)\n{\n\tstruct rds_ib_ipaddr *i_ipaddr;\n\tstruct rds_ib_ipaddr *to_free = NULL;\n\n\n\tspin_lock_irq(&rds_ibdev->spinlock);\n\tlist_for_each_entry_rcu(i_ipaddr, &rds_ibdev->ipaddr_list, list) {\n\t\tif (i_ipaddr->ipaddr == ipaddr) {\n\t\t\tlist_del_rcu(&i_ipaddr->list);\n\t\t\tto_free = i_ipaddr;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irq(&rds_ibdev->spinlock);\n\n\tif (to_free)\n\t\tkfree_rcu(to_free, rcu);\n}\n\nint rds_ib_update_ipaddr(struct rds_ib_device *rds_ibdev,\n\t\t\t struct in6_addr *ipaddr)\n{\n\tstruct rds_ib_device *rds_ibdev_old;\n\n\trds_ibdev_old = rds_ib_get_device(ipaddr->s6_addr32[3]);\n\tif (!rds_ibdev_old)\n\t\treturn rds_ib_add_ipaddr(rds_ibdev, ipaddr->s6_addr32[3]);\n\n\tif (rds_ibdev_old != rds_ibdev) {\n\t\trds_ib_remove_ipaddr(rds_ibdev_old, ipaddr->s6_addr32[3]);\n\t\trds_ib_dev_put(rds_ibdev_old);\n\t\treturn rds_ib_add_ipaddr(rds_ibdev, ipaddr->s6_addr32[3]);\n\t}\n\trds_ib_dev_put(rds_ibdev_old);\n\n\treturn 0;\n}\n\nvoid rds_ib_add_conn(struct rds_ib_device *rds_ibdev, struct rds_connection *conn)\n{\n\tstruct rds_ib_connection *ic = conn->c_transport_data;\n\n\t \n\tspin_lock_irq(&ib_nodev_conns_lock);\n\tBUG_ON(list_empty(&ib_nodev_conns));\n\tBUG_ON(list_empty(&ic->ib_node));\n\tlist_del(&ic->ib_node);\n\n\tspin_lock(&rds_ibdev->spinlock);\n\tlist_add_tail(&ic->ib_node, &rds_ibdev->conn_list);\n\tspin_unlock(&rds_ibdev->spinlock);\n\tspin_unlock_irq(&ib_nodev_conns_lock);\n\n\tic->rds_ibdev = rds_ibdev;\n\trefcount_inc(&rds_ibdev->refcount);\n}\n\nvoid rds_ib_remove_conn(struct rds_ib_device *rds_ibdev, struct rds_connection *conn)\n{\n\tstruct rds_ib_connection *ic = conn->c_transport_data;\n\n\t \n\tspin_lock(&ib_nodev_conns_lock);\n\n\tspin_lock_irq(&rds_ibdev->spinlock);\n\tBUG_ON(list_empty(&ic->ib_node));\n\tlist_del(&ic->ib_node);\n\tspin_unlock_irq(&rds_ibdev->spinlock);\n\n\tlist_add_tail(&ic->ib_node, &ib_nodev_conns);\n\n\tspin_unlock(&ib_nodev_conns_lock);\n\n\tic->rds_ibdev = NULL;\n\trds_ib_dev_put(rds_ibdev);\n}\n\nvoid rds_ib_destroy_nodev_conns(void)\n{\n\tstruct rds_ib_connection *ic, *_ic;\n\tLIST_HEAD(tmp_list);\n\n\t \n\tspin_lock_irq(&ib_nodev_conns_lock);\n\tlist_splice(&ib_nodev_conns, &tmp_list);\n\tspin_unlock_irq(&ib_nodev_conns_lock);\n\n\tlist_for_each_entry_safe(ic, _ic, &tmp_list, ib_node)\n\t\trds_conn_destroy(ic->conn);\n}\n\nvoid rds_ib_get_mr_info(struct rds_ib_device *rds_ibdev, struct rds_info_rdma_connection *iinfo)\n{\n\tstruct rds_ib_mr_pool *pool_1m = rds_ibdev->mr_1m_pool;\n\n\tiinfo->rdma_mr_max = pool_1m->max_items;\n\tiinfo->rdma_mr_size = pool_1m->max_pages;\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\nvoid rds6_ib_get_mr_info(struct rds_ib_device *rds_ibdev,\n\t\t\t struct rds6_info_rdma_connection *iinfo6)\n{\n\tstruct rds_ib_mr_pool *pool_1m = rds_ibdev->mr_1m_pool;\n\n\tiinfo6->rdma_mr_max = pool_1m->max_items;\n\tiinfo6->rdma_mr_size = pool_1m->max_pages;\n}\n#endif\n\nstruct rds_ib_mr *rds_ib_reuse_mr(struct rds_ib_mr_pool *pool)\n{\n\tstruct rds_ib_mr *ibmr = NULL;\n\tstruct llist_node *ret;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&pool->clean_lock, flags);\n\tret = llist_del_first(&pool->clean_list);\n\tspin_unlock_irqrestore(&pool->clean_lock, flags);\n\tif (ret) {\n\t\tibmr = llist_entry(ret, struct rds_ib_mr, llnode);\n\t\tif (pool->pool_type == RDS_IB_MR_8K_POOL)\n\t\t\trds_ib_stats_inc(s_ib_rdma_mr_8k_reused);\n\t\telse\n\t\t\trds_ib_stats_inc(s_ib_rdma_mr_1m_reused);\n\t}\n\n\treturn ibmr;\n}\n\nvoid rds_ib_sync_mr(void *trans_private, int direction)\n{\n\tstruct rds_ib_mr *ibmr = trans_private;\n\tstruct rds_ib_device *rds_ibdev = ibmr->device;\n\n\tif (ibmr->odp)\n\t\treturn;\n\n\tswitch (direction) {\n\tcase DMA_FROM_DEVICE:\n\t\tib_dma_sync_sg_for_cpu(rds_ibdev->dev, ibmr->sg,\n\t\t\tibmr->sg_dma_len, DMA_BIDIRECTIONAL);\n\t\tbreak;\n\tcase DMA_TO_DEVICE:\n\t\tib_dma_sync_sg_for_device(rds_ibdev->dev, ibmr->sg,\n\t\t\tibmr->sg_dma_len, DMA_BIDIRECTIONAL);\n\t\tbreak;\n\t}\n}\n\nvoid __rds_ib_teardown_mr(struct rds_ib_mr *ibmr)\n{\n\tstruct rds_ib_device *rds_ibdev = ibmr->device;\n\n\tif (ibmr->sg_dma_len) {\n\t\tib_dma_unmap_sg(rds_ibdev->dev,\n\t\t\t\tibmr->sg, ibmr->sg_len,\n\t\t\t\tDMA_BIDIRECTIONAL);\n\t\tibmr->sg_dma_len = 0;\n\t}\n\n\t \n\tif (ibmr->sg_len) {\n\t\tunsigned int i;\n\n\t\tfor (i = 0; i < ibmr->sg_len; ++i) {\n\t\t\tstruct page *page = sg_page(&ibmr->sg[i]);\n\n\t\t\t \n\t\t\tWARN_ON(!page->mapping && irqs_disabled());\n\t\t\tset_page_dirty(page);\n\t\t\tput_page(page);\n\t\t}\n\t\tkfree(ibmr->sg);\n\n\t\tibmr->sg = NULL;\n\t\tibmr->sg_len = 0;\n\t}\n}\n\nvoid rds_ib_teardown_mr(struct rds_ib_mr *ibmr)\n{\n\tunsigned int pinned = ibmr->sg_len;\n\n\t__rds_ib_teardown_mr(ibmr);\n\tif (pinned) {\n\t\tstruct rds_ib_mr_pool *pool = ibmr->pool;\n\n\t\tatomic_sub(pinned, &pool->free_pinned);\n\t}\n}\n\nstatic inline unsigned int rds_ib_flush_goal(struct rds_ib_mr_pool *pool, int free_all)\n{\n\tunsigned int item_count;\n\n\titem_count = atomic_read(&pool->item_count);\n\tif (free_all)\n\t\treturn item_count;\n\n\treturn 0;\n}\n\n \nstatic unsigned int llist_append_to_list(struct llist_head *llist,\n\t\t\t\t\t struct list_head *list)\n{\n\tstruct rds_ib_mr *ibmr;\n\tstruct llist_node *node;\n\tstruct llist_node *next;\n\tunsigned int count = 0;\n\n\tnode = llist_del_all(llist);\n\twhile (node) {\n\t\tnext = node->next;\n\t\tibmr = llist_entry(node, struct rds_ib_mr, llnode);\n\t\tlist_add_tail(&ibmr->unmap_list, list);\n\t\tnode = next;\n\t\tcount++;\n\t}\n\treturn count;\n}\n\n \nstatic void list_to_llist_nodes(struct list_head *list,\n\t\t\t\tstruct llist_node **nodes_head,\n\t\t\t\tstruct llist_node **nodes_tail)\n{\n\tstruct rds_ib_mr *ibmr;\n\tstruct llist_node *cur = NULL;\n\tstruct llist_node **next = nodes_head;\n\n\tlist_for_each_entry(ibmr, list, unmap_list) {\n\t\tcur = &ibmr->llnode;\n\t\t*next = cur;\n\t\tnext = &cur->next;\n\t}\n\t*next = NULL;\n\t*nodes_tail = cur;\n}\n\n \nint rds_ib_flush_mr_pool(struct rds_ib_mr_pool *pool,\n\t\t\t int free_all, struct rds_ib_mr **ibmr_ret)\n{\n\tstruct rds_ib_mr *ibmr;\n\tstruct llist_node *clean_nodes;\n\tstruct llist_node *clean_tail;\n\tLIST_HEAD(unmap_list);\n\tunsigned long unpinned = 0;\n\tunsigned int nfreed = 0, dirty_to_clean = 0, free_goal;\n\n\tif (pool->pool_type == RDS_IB_MR_8K_POOL)\n\t\trds_ib_stats_inc(s_ib_rdma_mr_8k_pool_flush);\n\telse\n\t\trds_ib_stats_inc(s_ib_rdma_mr_1m_pool_flush);\n\n\tif (ibmr_ret) {\n\t\tDEFINE_WAIT(wait);\n\t\twhile (!mutex_trylock(&pool->flush_lock)) {\n\t\t\tibmr = rds_ib_reuse_mr(pool);\n\t\t\tif (ibmr) {\n\t\t\t\t*ibmr_ret = ibmr;\n\t\t\t\tfinish_wait(&pool->flush_wait, &wait);\n\t\t\t\tgoto out_nolock;\n\t\t\t}\n\n\t\t\tprepare_to_wait(&pool->flush_wait, &wait,\n\t\t\t\t\tTASK_UNINTERRUPTIBLE);\n\t\t\tif (llist_empty(&pool->clean_list))\n\t\t\t\tschedule();\n\n\t\t\tibmr = rds_ib_reuse_mr(pool);\n\t\t\tif (ibmr) {\n\t\t\t\t*ibmr_ret = ibmr;\n\t\t\t\tfinish_wait(&pool->flush_wait, &wait);\n\t\t\t\tgoto out_nolock;\n\t\t\t}\n\t\t}\n\t\tfinish_wait(&pool->flush_wait, &wait);\n\t} else\n\t\tmutex_lock(&pool->flush_lock);\n\n\tif (ibmr_ret) {\n\t\tibmr = rds_ib_reuse_mr(pool);\n\t\tif (ibmr) {\n\t\t\t*ibmr_ret = ibmr;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tdirty_to_clean = llist_append_to_list(&pool->drop_list, &unmap_list);\n\tdirty_to_clean += llist_append_to_list(&pool->free_list, &unmap_list);\n\tif (free_all) {\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&pool->clean_lock, flags);\n\t\tllist_append_to_list(&pool->clean_list, &unmap_list);\n\t\tspin_unlock_irqrestore(&pool->clean_lock, flags);\n\t}\n\n\tfree_goal = rds_ib_flush_goal(pool, free_all);\n\n\tif (list_empty(&unmap_list))\n\t\tgoto out;\n\n\trds_ib_unreg_frmr(&unmap_list, &nfreed, &unpinned, free_goal);\n\n\tif (!list_empty(&unmap_list)) {\n\t\tunsigned long flags;\n\n\t\tlist_to_llist_nodes(&unmap_list, &clean_nodes, &clean_tail);\n\t\tif (ibmr_ret) {\n\t\t\t*ibmr_ret = llist_entry(clean_nodes, struct rds_ib_mr, llnode);\n\t\t\tclean_nodes = clean_nodes->next;\n\t\t}\n\t\t \n\t\tif (clean_nodes) {\n\t\t\tspin_lock_irqsave(&pool->clean_lock, flags);\n\t\t\tllist_add_batch(clean_nodes, clean_tail,\n\t\t\t\t\t&pool->clean_list);\n\t\t\tspin_unlock_irqrestore(&pool->clean_lock, flags);\n\t\t}\n\t}\n\n\tatomic_sub(unpinned, &pool->free_pinned);\n\tatomic_sub(dirty_to_clean, &pool->dirty_count);\n\tatomic_sub(nfreed, &pool->item_count);\n\nout:\n\tmutex_unlock(&pool->flush_lock);\n\tif (waitqueue_active(&pool->flush_wait))\n\t\twake_up(&pool->flush_wait);\nout_nolock:\n\treturn 0;\n}\n\nstruct rds_ib_mr *rds_ib_try_reuse_ibmr(struct rds_ib_mr_pool *pool)\n{\n\tstruct rds_ib_mr *ibmr = NULL;\n\tint iter = 0;\n\n\twhile (1) {\n\t\tibmr = rds_ib_reuse_mr(pool);\n\t\tif (ibmr)\n\t\t\treturn ibmr;\n\n\t\tif (atomic_inc_return(&pool->item_count) <= pool->max_items)\n\t\t\tbreak;\n\n\t\tatomic_dec(&pool->item_count);\n\n\t\tif (++iter > 2) {\n\t\t\tif (pool->pool_type == RDS_IB_MR_8K_POOL)\n\t\t\t\trds_ib_stats_inc(s_ib_rdma_mr_8k_pool_depleted);\n\t\t\telse\n\t\t\t\trds_ib_stats_inc(s_ib_rdma_mr_1m_pool_depleted);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (pool->pool_type == RDS_IB_MR_8K_POOL)\n\t\t\trds_ib_stats_inc(s_ib_rdma_mr_8k_pool_wait);\n\t\telse\n\t\t\trds_ib_stats_inc(s_ib_rdma_mr_1m_pool_wait);\n\n\t\trds_ib_flush_mr_pool(pool, 0, &ibmr);\n\t\tif (ibmr)\n\t\t\treturn ibmr;\n\t}\n\n\treturn NULL;\n}\n\nstatic void rds_ib_mr_pool_flush_worker(struct work_struct *work)\n{\n\tstruct rds_ib_mr_pool *pool = container_of(work, struct rds_ib_mr_pool, flush_worker.work);\n\n\trds_ib_flush_mr_pool(pool, 0, NULL);\n}\n\nvoid rds_ib_free_mr(void *trans_private, int invalidate)\n{\n\tstruct rds_ib_mr *ibmr = trans_private;\n\tstruct rds_ib_mr_pool *pool = ibmr->pool;\n\tstruct rds_ib_device *rds_ibdev = ibmr->device;\n\n\trdsdebug(\"RDS/IB: free_mr nents %u\\n\", ibmr->sg_len);\n\n\tif (ibmr->odp) {\n\t\t \n\t\tINIT_DELAYED_WORK(&ibmr->work, rds_ib_odp_mr_worker);\n\t\tqueue_delayed_work(rds_ib_mr_wq, &ibmr->work, 0);\n\t\treturn;\n\t}\n\n\t \n\trds_ib_free_frmr_list(ibmr);\n\n\tatomic_add(ibmr->sg_len, &pool->free_pinned);\n\tatomic_inc(&pool->dirty_count);\n\n\t \n\tif (atomic_read(&pool->free_pinned) >= pool->max_free_pinned ||\n\t    atomic_read(&pool->dirty_count) >= pool->max_items / 5)\n\t\tqueue_delayed_work(rds_ib_mr_wq, &pool->flush_worker, 10);\n\n\tif (invalidate) {\n\t\tif (likely(!in_interrupt())) {\n\t\t\trds_ib_flush_mr_pool(pool, 0, NULL);\n\t\t} else {\n\t\t\t \n\t\t\tqueue_delayed_work(rds_ib_mr_wq,\n\t\t\t\t\t   &pool->flush_worker, 10);\n\t\t}\n\t}\n\n\trds_ib_dev_put(rds_ibdev);\n}\n\nvoid rds_ib_flush_mrs(void)\n{\n\tstruct rds_ib_device *rds_ibdev;\n\n\tdown_read(&rds_ib_devices_lock);\n\tlist_for_each_entry(rds_ibdev, &rds_ib_devices, list) {\n\t\tif (rds_ibdev->mr_8k_pool)\n\t\t\trds_ib_flush_mr_pool(rds_ibdev->mr_8k_pool, 0, NULL);\n\n\t\tif (rds_ibdev->mr_1m_pool)\n\t\t\trds_ib_flush_mr_pool(rds_ibdev->mr_1m_pool, 0, NULL);\n\t}\n\tup_read(&rds_ib_devices_lock);\n}\n\nu32 rds_ib_get_lkey(void *trans_private)\n{\n\tstruct rds_ib_mr *ibmr = trans_private;\n\n\treturn ibmr->u.mr->lkey;\n}\n\nvoid *rds_ib_get_mr(struct scatterlist *sg, unsigned long nents,\n\t\t    struct rds_sock *rs, u32 *key_ret,\n\t\t    struct rds_connection *conn,\n\t\t    u64 start, u64 length, int need_odp)\n{\n\tstruct rds_ib_device *rds_ibdev;\n\tstruct rds_ib_mr *ibmr = NULL;\n\tstruct rds_ib_connection *ic = NULL;\n\tint ret;\n\n\trds_ibdev = rds_ib_get_device(rs->rs_bound_addr.s6_addr32[3]);\n\tif (!rds_ibdev) {\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tif (need_odp == ODP_ZEROBASED || need_odp == ODP_VIRTUAL) {\n\t\tu64 virt_addr = need_odp == ODP_ZEROBASED ? 0 : start;\n\t\tint access_flags =\n\t\t\t(IB_ACCESS_LOCAL_WRITE | IB_ACCESS_REMOTE_READ |\n\t\t\t IB_ACCESS_REMOTE_WRITE | IB_ACCESS_REMOTE_ATOMIC |\n\t\t\t IB_ACCESS_ON_DEMAND);\n\t\tstruct ib_sge sge = {};\n\t\tstruct ib_mr *ib_mr;\n\n\t\tif (!rds_ibdev->odp_capable) {\n\t\t\tret = -EOPNOTSUPP;\n\t\t\tgoto out;\n\t\t}\n\n\t\tib_mr = ib_reg_user_mr(rds_ibdev->pd, start, length, virt_addr,\n\t\t\t\t       access_flags);\n\n\t\tif (IS_ERR(ib_mr)) {\n\t\t\trdsdebug(\"rds_ib_get_user_mr returned %d\\n\",\n\t\t\t\t IS_ERR(ib_mr));\n\t\t\tret = PTR_ERR(ib_mr);\n\t\t\tgoto out;\n\t\t}\n\t\tif (key_ret)\n\t\t\t*key_ret = ib_mr->rkey;\n\n\t\tibmr = kzalloc(sizeof(*ibmr), GFP_KERNEL);\n\t\tif (!ibmr) {\n\t\t\tib_dereg_mr(ib_mr);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tibmr->u.mr = ib_mr;\n\t\tibmr->odp = 1;\n\n\t\tsge.addr = virt_addr;\n\t\tsge.length = length;\n\t\tsge.lkey = ib_mr->lkey;\n\n\t\tib_advise_mr(rds_ibdev->pd,\n\t\t\t     IB_UVERBS_ADVISE_MR_ADVICE_PREFETCH_WRITE,\n\t\t\t     IB_UVERBS_ADVISE_MR_FLAG_FLUSH, &sge, 1);\n\t\treturn ibmr;\n\t}\n\n\tif (conn)\n\t\tic = conn->c_transport_data;\n\n\tif (!rds_ibdev->mr_8k_pool || !rds_ibdev->mr_1m_pool) {\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tibmr = rds_ib_reg_frmr(rds_ibdev, ic, sg, nents, key_ret);\n\tif (IS_ERR(ibmr)) {\n\t\tret = PTR_ERR(ibmr);\n\t\tpr_warn(\"RDS/IB: rds_ib_get_mr failed (errno=%d)\\n\", ret);\n\t} else {\n\t\treturn ibmr;\n\t}\n\n out:\n\tif (rds_ibdev)\n\t\trds_ib_dev_put(rds_ibdev);\n\n\treturn ERR_PTR(ret);\n}\n\nvoid rds_ib_destroy_mr_pool(struct rds_ib_mr_pool *pool)\n{\n\tcancel_delayed_work_sync(&pool->flush_worker);\n\trds_ib_flush_mr_pool(pool, 1, NULL);\n\tWARN_ON(atomic_read(&pool->item_count));\n\tWARN_ON(atomic_read(&pool->free_pinned));\n\tkfree(pool);\n}\n\nstruct rds_ib_mr_pool *rds_ib_create_mr_pool(struct rds_ib_device *rds_ibdev,\n\t\t\t\t\t     int pool_type)\n{\n\tstruct rds_ib_mr_pool *pool;\n\n\tpool = kzalloc(sizeof(*pool), GFP_KERNEL);\n\tif (!pool)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tpool->pool_type = pool_type;\n\tinit_llist_head(&pool->free_list);\n\tinit_llist_head(&pool->drop_list);\n\tinit_llist_head(&pool->clean_list);\n\tspin_lock_init(&pool->clean_lock);\n\tmutex_init(&pool->flush_lock);\n\tinit_waitqueue_head(&pool->flush_wait);\n\tINIT_DELAYED_WORK(&pool->flush_worker, rds_ib_mr_pool_flush_worker);\n\n\tif (pool_type == RDS_IB_MR_1M_POOL) {\n\t\t \n\t\tpool->max_pages = RDS_MR_1M_MSG_SIZE + 1;\n\t\tpool->max_items = rds_ibdev->max_1m_mrs;\n\t} else {\n\t\t \n\t\tpool->max_pages = RDS_MR_8K_MSG_SIZE + 1;\n\t\tpool->max_items = rds_ibdev->max_8k_mrs;\n\t}\n\n\tpool->max_free_pinned = pool->max_items * pool->max_pages / 4;\n\tpool->max_items_soft = rds_ibdev->max_mrs * 3 / 4;\n\n\treturn pool;\n}\n\nint rds_ib_mr_init(void)\n{\n\trds_ib_mr_wq = alloc_workqueue(\"rds_mr_flushd\", WQ_MEM_RECLAIM, 0);\n\tif (!rds_ib_mr_wq)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\n \nvoid rds_ib_mr_exit(void)\n{\n\tdestroy_workqueue(rds_ib_mr_wq);\n}\n\nstatic void rds_ib_odp_mr_worker(struct work_struct  *work)\n{\n\tstruct rds_ib_mr *ibmr;\n\n\tibmr = container_of(work, struct rds_ib_mr, work.work);\n\tib_dereg_mr(ibmr->u.mr);\n\tkfree(ibmr);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}