{
  "module_name": "datapath.c",
  "hash_id": "0036b9307302aaeb16cd6da0b0364b38162ca42b5bb0ee56dbb4739fcb576762",
  "original_prompt": "Ingested from linux-6.6.14/net/openvswitch/datapath.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/if_arp.h>\n#include <linux/if_vlan.h>\n#include <linux/in.h>\n#include <linux/ip.h>\n#include <linux/jhash.h>\n#include <linux/delay.h>\n#include <linux/time.h>\n#include <linux/etherdevice.h>\n#include <linux/genetlink.h>\n#include <linux/kernel.h>\n#include <linux/kthread.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/rcupdate.h>\n#include <linux/tcp.h>\n#include <linux/udp.h>\n#include <linux/ethtool.h>\n#include <linux/wait.h>\n#include <asm/div64.h>\n#include <linux/highmem.h>\n#include <linux/netfilter_bridge.h>\n#include <linux/netfilter_ipv4.h>\n#include <linux/inetdevice.h>\n#include <linux/list.h>\n#include <linux/openvswitch.h>\n#include <linux/rculist.h>\n#include <linux/dmi.h>\n#include <net/genetlink.h>\n#include <net/gso.h>\n#include <net/net_namespace.h>\n#include <net/netns/generic.h>\n#include <net/pkt_cls.h>\n\n#include \"datapath.h\"\n#include \"drop.h\"\n#include \"flow.h\"\n#include \"flow_table.h\"\n#include \"flow_netlink.h\"\n#include \"meter.h\"\n#include \"openvswitch_trace.h\"\n#include \"vport-internal_dev.h\"\n#include \"vport-netdev.h\"\n\nunsigned int ovs_net_id __read_mostly;\n\nstatic struct genl_family dp_packet_genl_family;\nstatic struct genl_family dp_flow_genl_family;\nstatic struct genl_family dp_datapath_genl_family;\n\nstatic const struct nla_policy flow_policy[];\n\nstatic const struct genl_multicast_group ovs_dp_flow_multicast_group = {\n\t.name = OVS_FLOW_MCGROUP,\n};\n\nstatic const struct genl_multicast_group ovs_dp_datapath_multicast_group = {\n\t.name = OVS_DATAPATH_MCGROUP,\n};\n\nstatic const struct genl_multicast_group ovs_dp_vport_multicast_group = {\n\t.name = OVS_VPORT_MCGROUP,\n};\n\n \nstatic bool ovs_must_notify(struct genl_family *family, struct genl_info *info,\n\t\t\t    unsigned int group)\n{\n\treturn info->nlhdr->nlmsg_flags & NLM_F_ECHO ||\n\t       genl_has_listeners(family, genl_info_net(info), group);\n}\n\nstatic void ovs_notify(struct genl_family *family,\n\t\t       struct sk_buff *skb, struct genl_info *info)\n{\n\tgenl_notify(family, skb, info, 0, GFP_KERNEL);\n}\n\n \n\nstatic DEFINE_MUTEX(ovs_mutex);\n\nvoid ovs_lock(void)\n{\n\tmutex_lock(&ovs_mutex);\n}\n\nvoid ovs_unlock(void)\n{\n\tmutex_unlock(&ovs_mutex);\n}\n\n#ifdef CONFIG_LOCKDEP\nint lockdep_ovsl_is_held(void)\n{\n\tif (debug_locks)\n\t\treturn lockdep_is_held(&ovs_mutex);\n\telse\n\t\treturn 1;\n}\n#endif\n\nstatic struct vport *new_vport(const struct vport_parms *);\nstatic int queue_gso_packets(struct datapath *dp, struct sk_buff *,\n\t\t\t     const struct sw_flow_key *,\n\t\t\t     const struct dp_upcall_info *,\n\t\t\t     uint32_t cutlen);\nstatic int queue_userspace_packet(struct datapath *dp, struct sk_buff *,\n\t\t\t\t  const struct sw_flow_key *,\n\t\t\t\t  const struct dp_upcall_info *,\n\t\t\t\t  uint32_t cutlen);\n\nstatic void ovs_dp_masks_rebalance(struct work_struct *work);\n\nstatic int ovs_dp_set_upcall_portids(struct datapath *, const struct nlattr *);\n\n \nconst char *ovs_dp_name(const struct datapath *dp)\n{\n\tstruct vport *vport = ovs_vport_ovsl_rcu(dp, OVSP_LOCAL);\n\treturn ovs_vport_name(vport);\n}\n\nstatic int get_dpifindex(const struct datapath *dp)\n{\n\tstruct vport *local;\n\tint ifindex;\n\n\trcu_read_lock();\n\n\tlocal = ovs_vport_rcu(dp, OVSP_LOCAL);\n\tif (local)\n\t\tifindex = local->dev->ifindex;\n\telse\n\t\tifindex = 0;\n\n\trcu_read_unlock();\n\n\treturn ifindex;\n}\n\nstatic void destroy_dp_rcu(struct rcu_head *rcu)\n{\n\tstruct datapath *dp = container_of(rcu, struct datapath, rcu);\n\n\tovs_flow_tbl_destroy(&dp->table);\n\tfree_percpu(dp->stats_percpu);\n\tkfree(dp->ports);\n\tovs_meters_exit(dp);\n\tkfree(rcu_dereference_raw(dp->upcall_portids));\n\tkfree(dp);\n}\n\nstatic struct hlist_head *vport_hash_bucket(const struct datapath *dp,\n\t\t\t\t\t    u16 port_no)\n{\n\treturn &dp->ports[port_no & (DP_VPORT_HASH_BUCKETS - 1)];\n}\n\n \nstruct vport *ovs_lookup_vport(const struct datapath *dp, u16 port_no)\n{\n\tstruct vport *vport;\n\tstruct hlist_head *head;\n\n\thead = vport_hash_bucket(dp, port_no);\n\thlist_for_each_entry_rcu(vport, head, dp_hash_node,\n\t\t\t\t lockdep_ovsl_is_held()) {\n\t\tif (vport->port_no == port_no)\n\t\t\treturn vport;\n\t}\n\treturn NULL;\n}\n\n \nstatic struct vport *new_vport(const struct vport_parms *parms)\n{\n\tstruct vport *vport;\n\n\tvport = ovs_vport_add(parms);\n\tif (!IS_ERR(vport)) {\n\t\tstruct datapath *dp = parms->dp;\n\t\tstruct hlist_head *head = vport_hash_bucket(dp, vport->port_no);\n\n\t\thlist_add_head_rcu(&vport->dp_hash_node, head);\n\t}\n\treturn vport;\n}\n\nstatic void ovs_vport_update_upcall_stats(struct sk_buff *skb,\n\t\t\t\t\t  const struct dp_upcall_info *upcall_info,\n\t\t\t\t\t  bool upcall_result)\n{\n\tstruct vport *p = OVS_CB(skb)->input_vport;\n\tstruct vport_upcall_stats_percpu *stats;\n\n\tif (upcall_info->cmd != OVS_PACKET_CMD_MISS &&\n\t    upcall_info->cmd != OVS_PACKET_CMD_ACTION)\n\t\treturn;\n\n\tstats = this_cpu_ptr(p->upcall_stats);\n\tu64_stats_update_begin(&stats->syncp);\n\tif (upcall_result)\n\t\tu64_stats_inc(&stats->n_success);\n\telse\n\t\tu64_stats_inc(&stats->n_fail);\n\tu64_stats_update_end(&stats->syncp);\n}\n\nvoid ovs_dp_detach_port(struct vport *p)\n{\n\tASSERT_OVSL();\n\n\t \n\thlist_del_rcu(&p->dp_hash_node);\n\n\t \n\tovs_vport_del(p);\n}\n\n \nvoid ovs_dp_process_packet(struct sk_buff *skb, struct sw_flow_key *key)\n{\n\tconst struct vport *p = OVS_CB(skb)->input_vport;\n\tstruct datapath *dp = p->dp;\n\tstruct sw_flow *flow;\n\tstruct sw_flow_actions *sf_acts;\n\tstruct dp_stats_percpu *stats;\n\tu64 *stats_counter;\n\tu32 n_mask_hit;\n\tu32 n_cache_hit;\n\tint error;\n\n\tstats = this_cpu_ptr(dp->stats_percpu);\n\n\t \n\tflow = ovs_flow_tbl_lookup_stats(&dp->table, key, skb_get_hash(skb),\n\t\t\t\t\t &n_mask_hit, &n_cache_hit);\n\tif (unlikely(!flow)) {\n\t\tstruct dp_upcall_info upcall;\n\n\t\tmemset(&upcall, 0, sizeof(upcall));\n\t\tupcall.cmd = OVS_PACKET_CMD_MISS;\n\n\t\tif (dp->user_features & OVS_DP_F_DISPATCH_UPCALL_PER_CPU)\n\t\t\tupcall.portid =\n\t\t\t    ovs_dp_get_upcall_portid(dp, smp_processor_id());\n\t\telse\n\t\t\tupcall.portid = ovs_vport_find_upcall_portid(p, skb);\n\n\t\tupcall.mru = OVS_CB(skb)->mru;\n\t\terror = ovs_dp_upcall(dp, skb, key, &upcall, 0);\n\t\tswitch (error) {\n\t\tcase 0:\n\t\tcase -EAGAIN:\n\t\tcase -ERESTARTSYS:\n\t\tcase -EINTR:\n\t\t\tconsume_skb(skb);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tkfree_skb(skb);\n\t\t\tbreak;\n\t\t}\n\t\tstats_counter = &stats->n_missed;\n\t\tgoto out;\n\t}\n\n\tovs_flow_stats_update(flow, key->tp.flags, skb);\n\tsf_acts = rcu_dereference(flow->sf_acts);\n\terror = ovs_execute_actions(dp, skb, sf_acts, key);\n\tif (unlikely(error))\n\t\tnet_dbg_ratelimited(\"ovs: action execution error on datapath %s: %d\\n\",\n\t\t\t\t    ovs_dp_name(dp), error);\n\n\tstats_counter = &stats->n_hit;\n\nout:\n\t \n\tu64_stats_update_begin(&stats->syncp);\n\t(*stats_counter)++;\n\tstats->n_mask_hit += n_mask_hit;\n\tstats->n_cache_hit += n_cache_hit;\n\tu64_stats_update_end(&stats->syncp);\n}\n\nint ovs_dp_upcall(struct datapath *dp, struct sk_buff *skb,\n\t\t  const struct sw_flow_key *key,\n\t\t  const struct dp_upcall_info *upcall_info,\n\t\t  uint32_t cutlen)\n{\n\tstruct dp_stats_percpu *stats;\n\tint err;\n\n\tif (trace_ovs_dp_upcall_enabled())\n\t\ttrace_ovs_dp_upcall(dp, skb, key, upcall_info);\n\n\tif (upcall_info->portid == 0) {\n\t\terr = -ENOTCONN;\n\t\tgoto err;\n\t}\n\n\tif (!skb_is_gso(skb))\n\t\terr = queue_userspace_packet(dp, skb, key, upcall_info, cutlen);\n\telse\n\t\terr = queue_gso_packets(dp, skb, key, upcall_info, cutlen);\n\n\tovs_vport_update_upcall_stats(skb, upcall_info, !err);\n\tif (err)\n\t\tgoto err;\n\n\treturn 0;\n\nerr:\n\tstats = this_cpu_ptr(dp->stats_percpu);\n\n\tu64_stats_update_begin(&stats->syncp);\n\tstats->n_lost++;\n\tu64_stats_update_end(&stats->syncp);\n\n\treturn err;\n}\n\nstatic int queue_gso_packets(struct datapath *dp, struct sk_buff *skb,\n\t\t\t     const struct sw_flow_key *key,\n\t\t\t     const struct dp_upcall_info *upcall_info,\n\t\t\t     uint32_t cutlen)\n{\n\tunsigned int gso_type = skb_shinfo(skb)->gso_type;\n\tstruct sw_flow_key later_key;\n\tstruct sk_buff *segs, *nskb;\n\tint err;\n\n\tBUILD_BUG_ON(sizeof(*OVS_CB(skb)) > SKB_GSO_CB_OFFSET);\n\tsegs = __skb_gso_segment(skb, NETIF_F_SG, false);\n\tif (IS_ERR(segs))\n\t\treturn PTR_ERR(segs);\n\tif (segs == NULL)\n\t\treturn -EINVAL;\n\n\tif (gso_type & SKB_GSO_UDP) {\n\t\t \n\t\tlater_key = *key;\n\t\tlater_key.ip.frag = OVS_FRAG_TYPE_LATER;\n\t}\n\n\t \n\tskb_list_walk_safe(segs, skb, nskb) {\n\t\tif (gso_type & SKB_GSO_UDP && skb != segs)\n\t\t\tkey = &later_key;\n\n\t\terr = queue_userspace_packet(dp, skb, key, upcall_info, cutlen);\n\t\tif (err)\n\t\t\tbreak;\n\n\t}\n\n\t \n\tskb_list_walk_safe(segs, skb, nskb) {\n\t\tif (err)\n\t\t\tkfree_skb(skb);\n\t\telse\n\t\t\tconsume_skb(skb);\n\t}\n\treturn err;\n}\n\nstatic size_t upcall_msg_size(const struct dp_upcall_info *upcall_info,\n\t\t\t      unsigned int hdrlen, int actions_attrlen)\n{\n\tsize_t size = NLMSG_ALIGN(sizeof(struct ovs_header))\n\t\t+ nla_total_size(hdrlen)  \n\t\t+ nla_total_size(ovs_key_attr_size())  \n\t\t+ nla_total_size(sizeof(unsigned int))  \n\t\t+ nla_total_size(sizeof(u64));  \n\n\t \n\tif (upcall_info->userdata)\n\t\tsize += NLA_ALIGN(upcall_info->userdata->nla_len);\n\n\t \n\tif (upcall_info->egress_tun_info)\n\t\tsize += nla_total_size(ovs_tun_key_attr_size());\n\n\t \n\tif (upcall_info->actions_len)\n\t\tsize += nla_total_size(actions_attrlen);\n\n\t \n\tif (upcall_info->mru)\n\t\tsize += nla_total_size(sizeof(upcall_info->mru));\n\n\treturn size;\n}\n\nstatic void pad_packet(struct datapath *dp, struct sk_buff *skb)\n{\n\tif (!(dp->user_features & OVS_DP_F_UNALIGNED)) {\n\t\tsize_t plen = NLA_ALIGN(skb->len) - skb->len;\n\n\t\tif (plen > 0)\n\t\t\tskb_put_zero(skb, plen);\n\t}\n}\n\nstatic int queue_userspace_packet(struct datapath *dp, struct sk_buff *skb,\n\t\t\t\t  const struct sw_flow_key *key,\n\t\t\t\t  const struct dp_upcall_info *upcall_info,\n\t\t\t\t  uint32_t cutlen)\n{\n\tstruct ovs_header *upcall;\n\tstruct sk_buff *nskb = NULL;\n\tstruct sk_buff *user_skb = NULL;  \n\tstruct nlattr *nla;\n\tsize_t len;\n\tunsigned int hlen;\n\tint err, dp_ifindex;\n\tu64 hash;\n\n\tdp_ifindex = get_dpifindex(dp);\n\tif (!dp_ifindex)\n\t\treturn -ENODEV;\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\tnskb = skb_clone(skb, GFP_ATOMIC);\n\t\tif (!nskb)\n\t\t\treturn -ENOMEM;\n\n\t\tnskb = __vlan_hwaccel_push_inside(nskb);\n\t\tif (!nskb)\n\t\t\treturn -ENOMEM;\n\n\t\tskb = nskb;\n\t}\n\n\tif (nla_attr_size(skb->len) > USHRT_MAX) {\n\t\terr = -EFBIG;\n\t\tgoto out;\n\t}\n\n\t \n\tif (skb->ip_summed == CHECKSUM_PARTIAL &&\n\t    (err = skb_csum_hwoffload_help(skb, 0)))\n\t\tgoto out;\n\n\t \n\tif (dp->user_features & OVS_DP_F_UNALIGNED)\n\t\thlen = skb_zerocopy_headlen(skb);\n\telse\n\t\thlen = skb->len;\n\n\tlen = upcall_msg_size(upcall_info, hlen - cutlen,\n\t\t\t      OVS_CB(skb)->acts_origlen);\n\tuser_skb = genlmsg_new(len, GFP_ATOMIC);\n\tif (!user_skb) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tupcall = genlmsg_put(user_skb, 0, 0, &dp_packet_genl_family,\n\t\t\t     0, upcall_info->cmd);\n\tif (!upcall) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\tupcall->dp_ifindex = dp_ifindex;\n\n\terr = ovs_nla_put_key(key, key, OVS_PACKET_ATTR_KEY, false, user_skb);\n\tif (err)\n\t\tgoto out;\n\n\tif (upcall_info->userdata)\n\t\t__nla_put(user_skb, OVS_PACKET_ATTR_USERDATA,\n\t\t\t  nla_len(upcall_info->userdata),\n\t\t\t  nla_data(upcall_info->userdata));\n\n\tif (upcall_info->egress_tun_info) {\n\t\tnla = nla_nest_start_noflag(user_skb,\n\t\t\t\t\t    OVS_PACKET_ATTR_EGRESS_TUN_KEY);\n\t\tif (!nla) {\n\t\t\terr = -EMSGSIZE;\n\t\t\tgoto out;\n\t\t}\n\t\terr = ovs_nla_put_tunnel_info(user_skb,\n\t\t\t\t\t      upcall_info->egress_tun_info);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tnla_nest_end(user_skb, nla);\n\t}\n\n\tif (upcall_info->actions_len) {\n\t\tnla = nla_nest_start_noflag(user_skb, OVS_PACKET_ATTR_ACTIONS);\n\t\tif (!nla) {\n\t\t\terr = -EMSGSIZE;\n\t\t\tgoto out;\n\t\t}\n\t\terr = ovs_nla_put_actions(upcall_info->actions,\n\t\t\t\t\t  upcall_info->actions_len,\n\t\t\t\t\t  user_skb);\n\t\tif (!err)\n\t\t\tnla_nest_end(user_skb, nla);\n\t\telse\n\t\t\tnla_nest_cancel(user_skb, nla);\n\t}\n\n\t \n\tif (upcall_info->mru &&\n\t    nla_put_u16(user_skb, OVS_PACKET_ATTR_MRU, upcall_info->mru)) {\n\t\terr = -ENOBUFS;\n\t\tgoto out;\n\t}\n\n\t \n\tif (cutlen > 0 &&\n\t    nla_put_u32(user_skb, OVS_PACKET_ATTR_LEN, skb->len)) {\n\t\terr = -ENOBUFS;\n\t\tgoto out;\n\t}\n\n\t \n\thash = skb_get_hash_raw(skb);\n\tif (skb->sw_hash)\n\t\thash |= OVS_PACKET_HASH_SW_BIT;\n\n\tif (skb->l4_hash)\n\t\thash |= OVS_PACKET_HASH_L4_BIT;\n\n\tif (nla_put(user_skb, OVS_PACKET_ATTR_HASH, sizeof (u64), &hash)) {\n\t\terr = -ENOBUFS;\n\t\tgoto out;\n\t}\n\n\t \n\tif (!(nla = nla_reserve(user_skb, OVS_PACKET_ATTR_PACKET, 0))) {\n\t\terr = -ENOBUFS;\n\t\tgoto out;\n\t}\n\tnla->nla_len = nla_attr_size(skb->len - cutlen);\n\n\terr = skb_zerocopy(user_skb, skb, skb->len - cutlen, hlen);\n\tif (err)\n\t\tgoto out;\n\n\t \n\tpad_packet(dp, user_skb);\n\n\t((struct nlmsghdr *) user_skb->data)->nlmsg_len = user_skb->len;\n\n\terr = genlmsg_unicast(ovs_dp_get_net(dp), user_skb, upcall_info->portid);\n\tuser_skb = NULL;\nout:\n\tif (err)\n\t\tskb_tx_error(skb);\n\tconsume_skb(user_skb);\n\tconsume_skb(nskb);\n\n\treturn err;\n}\n\nstatic int ovs_packet_cmd_execute(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct ovs_header *ovs_header = genl_info_userhdr(info);\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr **a = info->attrs;\n\tstruct sw_flow_actions *acts;\n\tstruct sk_buff *packet;\n\tstruct sw_flow *flow;\n\tstruct sw_flow_actions *sf_acts;\n\tstruct datapath *dp;\n\tstruct vport *input_vport;\n\tu16 mru = 0;\n\tu64 hash;\n\tint len;\n\tint err;\n\tbool log = !a[OVS_PACKET_ATTR_PROBE];\n\n\terr = -EINVAL;\n\tif (!a[OVS_PACKET_ATTR_PACKET] || !a[OVS_PACKET_ATTR_KEY] ||\n\t    !a[OVS_PACKET_ATTR_ACTIONS])\n\t\tgoto err;\n\n\tlen = nla_len(a[OVS_PACKET_ATTR_PACKET]);\n\tpacket = __dev_alloc_skb(NET_IP_ALIGN + len, GFP_KERNEL);\n\terr = -ENOMEM;\n\tif (!packet)\n\t\tgoto err;\n\tskb_reserve(packet, NET_IP_ALIGN);\n\n\tnla_memcpy(__skb_put(packet, len), a[OVS_PACKET_ATTR_PACKET], len);\n\n\t \n\tif (a[OVS_PACKET_ATTR_MRU]) {\n\t\tmru = nla_get_u16(a[OVS_PACKET_ATTR_MRU]);\n\t\tpacket->ignore_df = 1;\n\t}\n\tOVS_CB(packet)->mru = mru;\n\n\tif (a[OVS_PACKET_ATTR_HASH]) {\n\t\thash = nla_get_u64(a[OVS_PACKET_ATTR_HASH]);\n\n\t\t__skb_set_hash(packet, hash & 0xFFFFFFFFULL,\n\t\t\t       !!(hash & OVS_PACKET_HASH_SW_BIT),\n\t\t\t       !!(hash & OVS_PACKET_HASH_L4_BIT));\n\t}\n\n\t \n\tflow = ovs_flow_alloc();\n\terr = PTR_ERR(flow);\n\tif (IS_ERR(flow))\n\t\tgoto err_kfree_skb;\n\n\terr = ovs_flow_key_extract_userspace(net, a[OVS_PACKET_ATTR_KEY],\n\t\t\t\t\t     packet, &flow->key, log);\n\tif (err)\n\t\tgoto err_flow_free;\n\n\terr = ovs_nla_copy_actions(net, a[OVS_PACKET_ATTR_ACTIONS],\n\t\t\t\t   &flow->key, &acts, log);\n\tif (err)\n\t\tgoto err_flow_free;\n\n\trcu_assign_pointer(flow->sf_acts, acts);\n\tpacket->priority = flow->key.phy.priority;\n\tpacket->mark = flow->key.phy.skb_mark;\n\n\trcu_read_lock();\n\tdp = get_dp_rcu(net, ovs_header->dp_ifindex);\n\terr = -ENODEV;\n\tif (!dp)\n\t\tgoto err_unlock;\n\n\tinput_vport = ovs_vport_rcu(dp, flow->key.phy.in_port);\n\tif (!input_vport)\n\t\tinput_vport = ovs_vport_rcu(dp, OVSP_LOCAL);\n\n\tif (!input_vport)\n\t\tgoto err_unlock;\n\n\tpacket->dev = input_vport->dev;\n\tOVS_CB(packet)->input_vport = input_vport;\n\tsf_acts = rcu_dereference(flow->sf_acts);\n\n\tlocal_bh_disable();\n\terr = ovs_execute_actions(dp, packet, sf_acts, &flow->key);\n\tlocal_bh_enable();\n\trcu_read_unlock();\n\n\tovs_flow_free(flow, false);\n\treturn err;\n\nerr_unlock:\n\trcu_read_unlock();\nerr_flow_free:\n\tovs_flow_free(flow, false);\nerr_kfree_skb:\n\tkfree_skb(packet);\nerr:\n\treturn err;\n}\n\nstatic const struct nla_policy packet_policy[OVS_PACKET_ATTR_MAX + 1] = {\n\t[OVS_PACKET_ATTR_PACKET] = { .len = ETH_HLEN },\n\t[OVS_PACKET_ATTR_KEY] = { .type = NLA_NESTED },\n\t[OVS_PACKET_ATTR_ACTIONS] = { .type = NLA_NESTED },\n\t[OVS_PACKET_ATTR_PROBE] = { .type = NLA_FLAG },\n\t[OVS_PACKET_ATTR_MRU] = { .type = NLA_U16 },\n\t[OVS_PACKET_ATTR_HASH] = { .type = NLA_U64 },\n};\n\nstatic const struct genl_small_ops dp_packet_genl_ops[] = {\n\t{ .cmd = OVS_PACKET_CMD_EXECUTE,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = GENL_UNS_ADMIN_PERM,  \n\t  .doit = ovs_packet_cmd_execute\n\t}\n};\n\nstatic struct genl_family dp_packet_genl_family __ro_after_init = {\n\t.hdrsize = sizeof(struct ovs_header),\n\t.name = OVS_PACKET_FAMILY,\n\t.version = OVS_PACKET_VERSION,\n\t.maxattr = OVS_PACKET_ATTR_MAX,\n\t.policy = packet_policy,\n\t.netnsok = true,\n\t.parallel_ops = true,\n\t.small_ops = dp_packet_genl_ops,\n\t.n_small_ops = ARRAY_SIZE(dp_packet_genl_ops),\n\t.resv_start_op = OVS_PACKET_CMD_EXECUTE + 1,\n\t.module = THIS_MODULE,\n};\n\nstatic void get_dp_stats(const struct datapath *dp, struct ovs_dp_stats *stats,\n\t\t\t struct ovs_dp_megaflow_stats *mega_stats)\n{\n\tint i;\n\n\tmemset(mega_stats, 0, sizeof(*mega_stats));\n\n\tstats->n_flows = ovs_flow_tbl_count(&dp->table);\n\tmega_stats->n_masks = ovs_flow_tbl_num_masks(&dp->table);\n\n\tstats->n_hit = stats->n_missed = stats->n_lost = 0;\n\n\tfor_each_possible_cpu(i) {\n\t\tconst struct dp_stats_percpu *percpu_stats;\n\t\tstruct dp_stats_percpu local_stats;\n\t\tunsigned int start;\n\n\t\tpercpu_stats = per_cpu_ptr(dp->stats_percpu, i);\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&percpu_stats->syncp);\n\t\t\tlocal_stats = *percpu_stats;\n\t\t} while (u64_stats_fetch_retry(&percpu_stats->syncp, start));\n\n\t\tstats->n_hit += local_stats.n_hit;\n\t\tstats->n_missed += local_stats.n_missed;\n\t\tstats->n_lost += local_stats.n_lost;\n\t\tmega_stats->n_mask_hit += local_stats.n_mask_hit;\n\t\tmega_stats->n_cache_hit += local_stats.n_cache_hit;\n\t}\n}\n\nstatic bool should_fill_key(const struct sw_flow_id *sfid, uint32_t ufid_flags)\n{\n\treturn ovs_identifier_is_ufid(sfid) &&\n\t       !(ufid_flags & OVS_UFID_F_OMIT_KEY);\n}\n\nstatic bool should_fill_mask(uint32_t ufid_flags)\n{\n\treturn !(ufid_flags & OVS_UFID_F_OMIT_MASK);\n}\n\nstatic bool should_fill_actions(uint32_t ufid_flags)\n{\n\treturn !(ufid_flags & OVS_UFID_F_OMIT_ACTIONS);\n}\n\nstatic size_t ovs_flow_cmd_msg_size(const struct sw_flow_actions *acts,\n\t\t\t\t    const struct sw_flow_id *sfid,\n\t\t\t\t    uint32_t ufid_flags)\n{\n\tsize_t len = NLMSG_ALIGN(sizeof(struct ovs_header));\n\n\t \n\tif (sfid && ovs_identifier_is_ufid(sfid))\n\t\tlen += nla_total_size(sfid->ufid_len);\n\telse\n\t\tlen += nla_total_size(ovs_key_attr_size());\n\n\t \n\tif (!sfid || should_fill_key(sfid, ufid_flags))\n\t\tlen += nla_total_size(ovs_key_attr_size());\n\n\t \n\tif (should_fill_mask(ufid_flags))\n\t\tlen += nla_total_size(ovs_key_attr_size());\n\n\t \n\tif (should_fill_actions(ufid_flags))\n\t\tlen += nla_total_size(acts->orig_len);\n\n\treturn len\n\t\t+ nla_total_size_64bit(sizeof(struct ovs_flow_stats))  \n\t\t+ nla_total_size(1)  \n\t\t+ nla_total_size_64bit(8);  \n}\n\n \nstatic int ovs_flow_cmd_fill_stats(const struct sw_flow *flow,\n\t\t\t\t   struct sk_buff *skb)\n{\n\tstruct ovs_flow_stats stats;\n\t__be16 tcp_flags;\n\tunsigned long used;\n\n\tovs_flow_stats_get(flow, &stats, &used, &tcp_flags);\n\n\tif (used &&\n\t    nla_put_u64_64bit(skb, OVS_FLOW_ATTR_USED, ovs_flow_used_time(used),\n\t\t\t      OVS_FLOW_ATTR_PAD))\n\t\treturn -EMSGSIZE;\n\n\tif (stats.n_packets &&\n\t    nla_put_64bit(skb, OVS_FLOW_ATTR_STATS,\n\t\t\t  sizeof(struct ovs_flow_stats), &stats,\n\t\t\t  OVS_FLOW_ATTR_PAD))\n\t\treturn -EMSGSIZE;\n\n\tif ((u8)ntohs(tcp_flags) &&\n\t     nla_put_u8(skb, OVS_FLOW_ATTR_TCP_FLAGS, (u8)ntohs(tcp_flags)))\n\t\treturn -EMSGSIZE;\n\n\treturn 0;\n}\n\n \nstatic int ovs_flow_cmd_fill_actions(const struct sw_flow *flow,\n\t\t\t\t     struct sk_buff *skb, int skb_orig_len)\n{\n\tstruct nlattr *start;\n\tint err;\n\n\t \n\tstart = nla_nest_start_noflag(skb, OVS_FLOW_ATTR_ACTIONS);\n\tif (start) {\n\t\tconst struct sw_flow_actions *sf_acts;\n\n\t\tsf_acts = rcu_dereference_ovsl(flow->sf_acts);\n\t\terr = ovs_nla_put_actions(sf_acts->actions,\n\t\t\t\t\t  sf_acts->actions_len, skb);\n\n\t\tif (!err)\n\t\t\tnla_nest_end(skb, start);\n\t\telse {\n\t\t\tif (skb_orig_len)\n\t\t\t\treturn err;\n\n\t\t\tnla_nest_cancel(skb, start);\n\t\t}\n\t} else if (skb_orig_len) {\n\t\treturn -EMSGSIZE;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int ovs_flow_cmd_fill_info(const struct sw_flow *flow, int dp_ifindex,\n\t\t\t\t  struct sk_buff *skb, u32 portid,\n\t\t\t\t  u32 seq, u32 flags, u8 cmd, u32 ufid_flags)\n{\n\tconst int skb_orig_len = skb->len;\n\tstruct ovs_header *ovs_header;\n\tint err;\n\n\tovs_header = genlmsg_put(skb, portid, seq, &dp_flow_genl_family,\n\t\t\t\t flags, cmd);\n\tif (!ovs_header)\n\t\treturn -EMSGSIZE;\n\n\tovs_header->dp_ifindex = dp_ifindex;\n\n\terr = ovs_nla_put_identifier(flow, skb);\n\tif (err)\n\t\tgoto error;\n\n\tif (should_fill_key(&flow->id, ufid_flags)) {\n\t\terr = ovs_nla_put_masked_key(flow, skb);\n\t\tif (err)\n\t\t\tgoto error;\n\t}\n\n\tif (should_fill_mask(ufid_flags)) {\n\t\terr = ovs_nla_put_mask(flow, skb);\n\t\tif (err)\n\t\t\tgoto error;\n\t}\n\n\terr = ovs_flow_cmd_fill_stats(flow, skb);\n\tif (err)\n\t\tgoto error;\n\n\tif (should_fill_actions(ufid_flags)) {\n\t\terr = ovs_flow_cmd_fill_actions(flow, skb, skb_orig_len);\n\t\tif (err)\n\t\t\tgoto error;\n\t}\n\n\tgenlmsg_end(skb, ovs_header);\n\treturn 0;\n\nerror:\n\tgenlmsg_cancel(skb, ovs_header);\n\treturn err;\n}\n\n \nstatic struct sk_buff *ovs_flow_cmd_alloc_info(const struct sw_flow_actions *acts,\n\t\t\t\t\t       const struct sw_flow_id *sfid,\n\t\t\t\t\t       struct genl_info *info,\n\t\t\t\t\t       bool always,\n\t\t\t\t\t       uint32_t ufid_flags)\n{\n\tstruct sk_buff *skb;\n\tsize_t len;\n\n\tif (!always && !ovs_must_notify(&dp_flow_genl_family, info, 0))\n\t\treturn NULL;\n\n\tlen = ovs_flow_cmd_msg_size(acts, sfid, ufid_flags);\n\tskb = genlmsg_new(len, GFP_KERNEL);\n\tif (!skb)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\treturn skb;\n}\n\n \nstatic struct sk_buff *ovs_flow_cmd_build_info(const struct sw_flow *flow,\n\t\t\t\t\t       int dp_ifindex,\n\t\t\t\t\t       struct genl_info *info, u8 cmd,\n\t\t\t\t\t       bool always, u32 ufid_flags)\n{\n\tstruct sk_buff *skb;\n\tint retval;\n\n\tskb = ovs_flow_cmd_alloc_info(ovsl_dereference(flow->sf_acts),\n\t\t\t\t      &flow->id, info, always, ufid_flags);\n\tif (IS_ERR_OR_NULL(skb))\n\t\treturn skb;\n\n\tretval = ovs_flow_cmd_fill_info(flow, dp_ifindex, skb,\n\t\t\t\t\tinfo->snd_portid, info->snd_seq, 0,\n\t\t\t\t\tcmd, ufid_flags);\n\tif (WARN_ON_ONCE(retval < 0)) {\n\t\tkfree_skb(skb);\n\t\tskb = ERR_PTR(retval);\n\t}\n\treturn skb;\n}\n\nstatic int ovs_flow_cmd_new(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr **a = info->attrs;\n\tstruct ovs_header *ovs_header = genl_info_userhdr(info);\n\tstruct sw_flow *flow = NULL, *new_flow;\n\tstruct sw_flow_mask mask;\n\tstruct sk_buff *reply;\n\tstruct datapath *dp;\n\tstruct sw_flow_key *key;\n\tstruct sw_flow_actions *acts;\n\tstruct sw_flow_match match;\n\tu32 ufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);\n\tint error;\n\tbool log = !a[OVS_FLOW_ATTR_PROBE];\n\n\t \n\terror = -EINVAL;\n\tif (!a[OVS_FLOW_ATTR_KEY]) {\n\t\tOVS_NLERR(log, \"Flow key attr not present in new flow.\");\n\t\tgoto error;\n\t}\n\tif (!a[OVS_FLOW_ATTR_ACTIONS]) {\n\t\tOVS_NLERR(log, \"Flow actions attr not present in new flow.\");\n\t\tgoto error;\n\t}\n\n\t \n\tnew_flow = ovs_flow_alloc();\n\tif (IS_ERR(new_flow)) {\n\t\terror = PTR_ERR(new_flow);\n\t\tgoto error;\n\t}\n\n\t \n\tkey = kzalloc(sizeof(*key), GFP_KERNEL);\n\tif (!key) {\n\t\terror = -ENOMEM;\n\t\tgoto err_kfree_flow;\n\t}\n\n\tovs_match_init(&match, key, false, &mask);\n\terror = ovs_nla_get_match(net, &match, a[OVS_FLOW_ATTR_KEY],\n\t\t\t\t  a[OVS_FLOW_ATTR_MASK], log);\n\tif (error)\n\t\tgoto err_kfree_key;\n\n\tovs_flow_mask_key(&new_flow->key, key, true, &mask);\n\n\t \n\terror = ovs_nla_get_identifier(&new_flow->id, a[OVS_FLOW_ATTR_UFID],\n\t\t\t\t       key, log);\n\tif (error)\n\t\tgoto err_kfree_key;\n\n\t \n\terror = ovs_nla_copy_actions(net, a[OVS_FLOW_ATTR_ACTIONS],\n\t\t\t\t     &new_flow->key, &acts, log);\n\tif (error) {\n\t\tOVS_NLERR(log, \"Flow actions may not be safe on all matching packets.\");\n\t\tgoto err_kfree_key;\n\t}\n\n\treply = ovs_flow_cmd_alloc_info(acts, &new_flow->id, info, false,\n\t\t\t\t\tufid_flags);\n\tif (IS_ERR(reply)) {\n\t\terror = PTR_ERR(reply);\n\t\tgoto err_kfree_acts;\n\t}\n\n\tovs_lock();\n\tdp = get_dp(net, ovs_header->dp_ifindex);\n\tif (unlikely(!dp)) {\n\t\terror = -ENODEV;\n\t\tgoto err_unlock_ovs;\n\t}\n\n\t \n\tif (ovs_identifier_is_ufid(&new_flow->id))\n\t\tflow = ovs_flow_tbl_lookup_ufid(&dp->table, &new_flow->id);\n\tif (!flow)\n\t\tflow = ovs_flow_tbl_lookup(&dp->table, key);\n\tif (likely(!flow)) {\n\t\trcu_assign_pointer(new_flow->sf_acts, acts);\n\n\t\t \n\t\terror = ovs_flow_tbl_insert(&dp->table, new_flow, &mask);\n\t\tif (unlikely(error)) {\n\t\t\tacts = NULL;\n\t\t\tgoto err_unlock_ovs;\n\t\t}\n\n\t\tif (unlikely(reply)) {\n\t\t\terror = ovs_flow_cmd_fill_info(new_flow,\n\t\t\t\t\t\t       ovs_header->dp_ifindex,\n\t\t\t\t\t\t       reply, info->snd_portid,\n\t\t\t\t\t\t       info->snd_seq, 0,\n\t\t\t\t\t\t       OVS_FLOW_CMD_NEW,\n\t\t\t\t\t\t       ufid_flags);\n\t\t\tBUG_ON(error < 0);\n\t\t}\n\t\tovs_unlock();\n\t} else {\n\t\tstruct sw_flow_actions *old_acts;\n\n\t\t \n\t\tif (unlikely(info->nlhdr->nlmsg_flags & (NLM_F_CREATE\n\t\t\t\t\t\t\t | NLM_F_EXCL))) {\n\t\t\terror = -EEXIST;\n\t\t\tgoto err_unlock_ovs;\n\t\t}\n\t\t \n\t\tif (unlikely(!ovs_flow_cmp(flow, &match))) {\n\t\t\tif (ovs_identifier_is_key(&flow->id))\n\t\t\t\tflow = ovs_flow_tbl_lookup_exact(&dp->table,\n\t\t\t\t\t\t\t\t &match);\n\t\t\telse  \n\t\t\t\tflow = NULL;\n\t\t\tif (!flow) {\n\t\t\t\terror = -ENOENT;\n\t\t\t\tgoto err_unlock_ovs;\n\t\t\t}\n\t\t}\n\t\t \n\t\told_acts = ovsl_dereference(flow->sf_acts);\n\t\trcu_assign_pointer(flow->sf_acts, acts);\n\n\t\tif (unlikely(reply)) {\n\t\t\terror = ovs_flow_cmd_fill_info(flow,\n\t\t\t\t\t\t       ovs_header->dp_ifindex,\n\t\t\t\t\t\t       reply, info->snd_portid,\n\t\t\t\t\t\t       info->snd_seq, 0,\n\t\t\t\t\t\t       OVS_FLOW_CMD_NEW,\n\t\t\t\t\t\t       ufid_flags);\n\t\t\tBUG_ON(error < 0);\n\t\t}\n\t\tovs_unlock();\n\n\t\tovs_nla_free_flow_actions_rcu(old_acts);\n\t\tovs_flow_free(new_flow, false);\n\t}\n\n\tif (reply)\n\t\tovs_notify(&dp_flow_genl_family, reply, info);\n\n\tkfree(key);\n\treturn 0;\n\nerr_unlock_ovs:\n\tovs_unlock();\n\tkfree_skb(reply);\nerr_kfree_acts:\n\tovs_nla_free_flow_actions(acts);\nerr_kfree_key:\n\tkfree(key);\nerr_kfree_flow:\n\tovs_flow_free(new_flow, false);\nerror:\n\treturn error;\n}\n\n \nstatic noinline_for_stack\nstruct sw_flow_actions *get_flow_actions(struct net *net,\n\t\t\t\t\t const struct nlattr *a,\n\t\t\t\t\t const struct sw_flow_key *key,\n\t\t\t\t\t const struct sw_flow_mask *mask,\n\t\t\t\t\t bool log)\n{\n\tstruct sw_flow_actions *acts;\n\tstruct sw_flow_key masked_key;\n\tint error;\n\n\tovs_flow_mask_key(&masked_key, key, true, mask);\n\terror = ovs_nla_copy_actions(net, a, &masked_key, &acts, log);\n\tif (error) {\n\t\tOVS_NLERR(log,\n\t\t\t  \"Actions may not be safe on all matching packets\");\n\t\treturn ERR_PTR(error);\n\t}\n\n\treturn acts;\n}\n\n \nstatic noinline_for_stack int\novs_nla_init_match_and_action(struct net *net,\n\t\t\t      struct sw_flow_match *match,\n\t\t\t      struct sw_flow_key *key,\n\t\t\t      struct nlattr **a,\n\t\t\t      struct sw_flow_actions **acts,\n\t\t\t      bool log)\n{\n\tstruct sw_flow_mask mask;\n\tint error = 0;\n\n\tif (a[OVS_FLOW_ATTR_KEY]) {\n\t\tovs_match_init(match, key, true, &mask);\n\t\terror = ovs_nla_get_match(net, match, a[OVS_FLOW_ATTR_KEY],\n\t\t\t\t\t  a[OVS_FLOW_ATTR_MASK], log);\n\t\tif (error)\n\t\t\tgoto error;\n\t}\n\n\tif (a[OVS_FLOW_ATTR_ACTIONS]) {\n\t\tif (!a[OVS_FLOW_ATTR_KEY]) {\n\t\t\tOVS_NLERR(log,\n\t\t\t\t  \"Flow key attribute not present in set flow.\");\n\t\t\terror = -EINVAL;\n\t\t\tgoto error;\n\t\t}\n\n\t\t*acts = get_flow_actions(net, a[OVS_FLOW_ATTR_ACTIONS], key,\n\t\t\t\t\t &mask, log);\n\t\tif (IS_ERR(*acts)) {\n\t\t\terror = PTR_ERR(*acts);\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\t \nerror:\n\tmatch->mask = NULL;\n\treturn error;\n}\n\nstatic int ovs_flow_cmd_set(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr **a = info->attrs;\n\tstruct ovs_header *ovs_header = genl_info_userhdr(info);\n\tstruct sw_flow_key key;\n\tstruct sw_flow *flow;\n\tstruct sk_buff *reply = NULL;\n\tstruct datapath *dp;\n\tstruct sw_flow_actions *old_acts = NULL, *acts = NULL;\n\tstruct sw_flow_match match;\n\tstruct sw_flow_id sfid;\n\tu32 ufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);\n\tint error = 0;\n\tbool log = !a[OVS_FLOW_ATTR_PROBE];\n\tbool ufid_present;\n\n\tufid_present = ovs_nla_get_ufid(&sfid, a[OVS_FLOW_ATTR_UFID], log);\n\tif (!a[OVS_FLOW_ATTR_KEY] && !ufid_present) {\n\t\tOVS_NLERR(log,\n\t\t\t  \"Flow set message rejected, Key attribute missing.\");\n\t\treturn -EINVAL;\n\t}\n\n\terror = ovs_nla_init_match_and_action(net, &match, &key, a,\n\t\t\t\t\t      &acts, log);\n\tif (error)\n\t\tgoto error;\n\n\tif (acts) {\n\t\t \n\t\treply = ovs_flow_cmd_alloc_info(acts, &sfid, info, false,\n\t\t\t\t\t\tufid_flags);\n\t\tif (IS_ERR(reply)) {\n\t\t\terror = PTR_ERR(reply);\n\t\t\tgoto err_kfree_acts;\n\t\t}\n\t}\n\n\tovs_lock();\n\tdp = get_dp(net, ovs_header->dp_ifindex);\n\tif (unlikely(!dp)) {\n\t\terror = -ENODEV;\n\t\tgoto err_unlock_ovs;\n\t}\n\t \n\tif (ufid_present)\n\t\tflow = ovs_flow_tbl_lookup_ufid(&dp->table, &sfid);\n\telse\n\t\tflow = ovs_flow_tbl_lookup_exact(&dp->table, &match);\n\tif (unlikely(!flow)) {\n\t\terror = -ENOENT;\n\t\tgoto err_unlock_ovs;\n\t}\n\n\t \n\tif (likely(acts)) {\n\t\told_acts = ovsl_dereference(flow->sf_acts);\n\t\trcu_assign_pointer(flow->sf_acts, acts);\n\n\t\tif (unlikely(reply)) {\n\t\t\terror = ovs_flow_cmd_fill_info(flow,\n\t\t\t\t\t\t       ovs_header->dp_ifindex,\n\t\t\t\t\t\t       reply, info->snd_portid,\n\t\t\t\t\t\t       info->snd_seq, 0,\n\t\t\t\t\t\t       OVS_FLOW_CMD_SET,\n\t\t\t\t\t\t       ufid_flags);\n\t\t\tBUG_ON(error < 0);\n\t\t}\n\t} else {\n\t\t \n\t\treply = ovs_flow_cmd_build_info(flow, ovs_header->dp_ifindex,\n\t\t\t\t\t\tinfo, OVS_FLOW_CMD_SET, false,\n\t\t\t\t\t\tufid_flags);\n\n\t\tif (IS_ERR(reply)) {\n\t\t\terror = PTR_ERR(reply);\n\t\t\tgoto err_unlock_ovs;\n\t\t}\n\t}\n\n\t \n\tif (a[OVS_FLOW_ATTR_CLEAR])\n\t\tovs_flow_stats_clear(flow);\n\tovs_unlock();\n\n\tif (reply)\n\t\tovs_notify(&dp_flow_genl_family, reply, info);\n\tif (old_acts)\n\t\tovs_nla_free_flow_actions_rcu(old_acts);\n\n\treturn 0;\n\nerr_unlock_ovs:\n\tovs_unlock();\n\tkfree_skb(reply);\nerr_kfree_acts:\n\tovs_nla_free_flow_actions(acts);\nerror:\n\treturn error;\n}\n\nstatic int ovs_flow_cmd_get(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct nlattr **a = info->attrs;\n\tstruct ovs_header *ovs_header = genl_info_userhdr(info);\n\tstruct net *net = sock_net(skb->sk);\n\tstruct sw_flow_key key;\n\tstruct sk_buff *reply;\n\tstruct sw_flow *flow;\n\tstruct datapath *dp;\n\tstruct sw_flow_match match;\n\tstruct sw_flow_id ufid;\n\tu32 ufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);\n\tint err = 0;\n\tbool log = !a[OVS_FLOW_ATTR_PROBE];\n\tbool ufid_present;\n\n\tufid_present = ovs_nla_get_ufid(&ufid, a[OVS_FLOW_ATTR_UFID], log);\n\tif (a[OVS_FLOW_ATTR_KEY]) {\n\t\tovs_match_init(&match, &key, true, NULL);\n\t\terr = ovs_nla_get_match(net, &match, a[OVS_FLOW_ATTR_KEY], NULL,\n\t\t\t\t\tlog);\n\t} else if (!ufid_present) {\n\t\tOVS_NLERR(log,\n\t\t\t  \"Flow get message rejected, Key attribute missing.\");\n\t\terr = -EINVAL;\n\t}\n\tif (err)\n\t\treturn err;\n\n\tovs_lock();\n\tdp = get_dp(sock_net(skb->sk), ovs_header->dp_ifindex);\n\tif (!dp) {\n\t\terr = -ENODEV;\n\t\tgoto unlock;\n\t}\n\n\tif (ufid_present)\n\t\tflow = ovs_flow_tbl_lookup_ufid(&dp->table, &ufid);\n\telse\n\t\tflow = ovs_flow_tbl_lookup_exact(&dp->table, &match);\n\tif (!flow) {\n\t\terr = -ENOENT;\n\t\tgoto unlock;\n\t}\n\n\treply = ovs_flow_cmd_build_info(flow, ovs_header->dp_ifindex, info,\n\t\t\t\t\tOVS_FLOW_CMD_GET, true, ufid_flags);\n\tif (IS_ERR(reply)) {\n\t\terr = PTR_ERR(reply);\n\t\tgoto unlock;\n\t}\n\n\tovs_unlock();\n\treturn genlmsg_reply(reply, info);\nunlock:\n\tovs_unlock();\n\treturn err;\n}\n\nstatic int ovs_flow_cmd_del(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct nlattr **a = info->attrs;\n\tstruct ovs_header *ovs_header = genl_info_userhdr(info);\n\tstruct net *net = sock_net(skb->sk);\n\tstruct sw_flow_key key;\n\tstruct sk_buff *reply;\n\tstruct sw_flow *flow = NULL;\n\tstruct datapath *dp;\n\tstruct sw_flow_match match;\n\tstruct sw_flow_id ufid;\n\tu32 ufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);\n\tint err;\n\tbool log = !a[OVS_FLOW_ATTR_PROBE];\n\tbool ufid_present;\n\n\tufid_present = ovs_nla_get_ufid(&ufid, a[OVS_FLOW_ATTR_UFID], log);\n\tif (a[OVS_FLOW_ATTR_KEY]) {\n\t\tovs_match_init(&match, &key, true, NULL);\n\t\terr = ovs_nla_get_match(net, &match, a[OVS_FLOW_ATTR_KEY],\n\t\t\t\t\tNULL, log);\n\t\tif (unlikely(err))\n\t\t\treturn err;\n\t}\n\n\tovs_lock();\n\tdp = get_dp(sock_net(skb->sk), ovs_header->dp_ifindex);\n\tif (unlikely(!dp)) {\n\t\terr = -ENODEV;\n\t\tgoto unlock;\n\t}\n\n\tif (unlikely(!a[OVS_FLOW_ATTR_KEY] && !ufid_present)) {\n\t\terr = ovs_flow_tbl_flush(&dp->table);\n\t\tgoto unlock;\n\t}\n\n\tif (ufid_present)\n\t\tflow = ovs_flow_tbl_lookup_ufid(&dp->table, &ufid);\n\telse\n\t\tflow = ovs_flow_tbl_lookup_exact(&dp->table, &match);\n\tif (unlikely(!flow)) {\n\t\terr = -ENOENT;\n\t\tgoto unlock;\n\t}\n\n\tovs_flow_tbl_remove(&dp->table, flow);\n\tovs_unlock();\n\n\treply = ovs_flow_cmd_alloc_info((const struct sw_flow_actions __force *) flow->sf_acts,\n\t\t\t\t\t&flow->id, info, false, ufid_flags);\n\tif (likely(reply)) {\n\t\tif (!IS_ERR(reply)) {\n\t\t\trcu_read_lock();\t \n\t\t\terr = ovs_flow_cmd_fill_info(flow, ovs_header->dp_ifindex,\n\t\t\t\t\t\t     reply, info->snd_portid,\n\t\t\t\t\t\t     info->snd_seq, 0,\n\t\t\t\t\t\t     OVS_FLOW_CMD_DEL,\n\t\t\t\t\t\t     ufid_flags);\n\t\t\trcu_read_unlock();\n\t\t\tif (WARN_ON_ONCE(err < 0)) {\n\t\t\t\tkfree_skb(reply);\n\t\t\t\tgoto out_free;\n\t\t\t}\n\n\t\t\tovs_notify(&dp_flow_genl_family, reply, info);\n\t\t} else {\n\t\t\tnetlink_set_err(sock_net(skb->sk)->genl_sock, 0, 0,\n\t\t\t\t\tPTR_ERR(reply));\n\t\t}\n\t}\n\nout_free:\n\tovs_flow_free(flow, true);\n\treturn 0;\nunlock:\n\tovs_unlock();\n\treturn err;\n}\n\nstatic int ovs_flow_cmd_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct nlattr *a[__OVS_FLOW_ATTR_MAX];\n\tstruct ovs_header *ovs_header = genlmsg_data(nlmsg_data(cb->nlh));\n\tstruct table_instance *ti;\n\tstruct datapath *dp;\n\tu32 ufid_flags;\n\tint err;\n\n\terr = genlmsg_parse_deprecated(cb->nlh, &dp_flow_genl_family, a,\n\t\t\t\t       OVS_FLOW_ATTR_MAX, flow_policy, NULL);\n\tif (err)\n\t\treturn err;\n\tufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);\n\n\trcu_read_lock();\n\tdp = get_dp_rcu(sock_net(skb->sk), ovs_header->dp_ifindex);\n\tif (!dp) {\n\t\trcu_read_unlock();\n\t\treturn -ENODEV;\n\t}\n\n\tti = rcu_dereference(dp->table.ti);\n\tfor (;;) {\n\t\tstruct sw_flow *flow;\n\t\tu32 bucket, obj;\n\n\t\tbucket = cb->args[0];\n\t\tobj = cb->args[1];\n\t\tflow = ovs_flow_tbl_dump_next(ti, &bucket, &obj);\n\t\tif (!flow)\n\t\t\tbreak;\n\n\t\tif (ovs_flow_cmd_fill_info(flow, ovs_header->dp_ifindex, skb,\n\t\t\t\t\t   NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t   cb->nlh->nlmsg_seq, NLM_F_MULTI,\n\t\t\t\t\t   OVS_FLOW_CMD_GET, ufid_flags) < 0)\n\t\t\tbreak;\n\n\t\tcb->args[0] = bucket;\n\t\tcb->args[1] = obj;\n\t}\n\trcu_read_unlock();\n\treturn skb->len;\n}\n\nstatic const struct nla_policy flow_policy[OVS_FLOW_ATTR_MAX + 1] = {\n\t[OVS_FLOW_ATTR_KEY] = { .type = NLA_NESTED },\n\t[OVS_FLOW_ATTR_MASK] = { .type = NLA_NESTED },\n\t[OVS_FLOW_ATTR_ACTIONS] = { .type = NLA_NESTED },\n\t[OVS_FLOW_ATTR_CLEAR] = { .type = NLA_FLAG },\n\t[OVS_FLOW_ATTR_PROBE] = { .type = NLA_FLAG },\n\t[OVS_FLOW_ATTR_UFID] = { .type = NLA_UNSPEC, .len = 1 },\n\t[OVS_FLOW_ATTR_UFID_FLAGS] = { .type = NLA_U32 },\n};\n\nstatic const struct genl_small_ops dp_flow_genl_ops[] = {\n\t{ .cmd = OVS_FLOW_CMD_NEW,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = GENL_UNS_ADMIN_PERM,  \n\t  .doit = ovs_flow_cmd_new\n\t},\n\t{ .cmd = OVS_FLOW_CMD_DEL,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = GENL_UNS_ADMIN_PERM,  \n\t  .doit = ovs_flow_cmd_del\n\t},\n\t{ .cmd = OVS_FLOW_CMD_GET,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = 0,\t\t     \n\t  .doit = ovs_flow_cmd_get,\n\t  .dumpit = ovs_flow_cmd_dump\n\t},\n\t{ .cmd = OVS_FLOW_CMD_SET,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = GENL_UNS_ADMIN_PERM,  \n\t  .doit = ovs_flow_cmd_set,\n\t},\n};\n\nstatic struct genl_family dp_flow_genl_family __ro_after_init = {\n\t.hdrsize = sizeof(struct ovs_header),\n\t.name = OVS_FLOW_FAMILY,\n\t.version = OVS_FLOW_VERSION,\n\t.maxattr = OVS_FLOW_ATTR_MAX,\n\t.policy = flow_policy,\n\t.netnsok = true,\n\t.parallel_ops = true,\n\t.small_ops = dp_flow_genl_ops,\n\t.n_small_ops = ARRAY_SIZE(dp_flow_genl_ops),\n\t.resv_start_op = OVS_FLOW_CMD_SET + 1,\n\t.mcgrps = &ovs_dp_flow_multicast_group,\n\t.n_mcgrps = 1,\n\t.module = THIS_MODULE,\n};\n\nstatic size_t ovs_dp_cmd_msg_size(void)\n{\n\tsize_t msgsize = NLMSG_ALIGN(sizeof(struct ovs_header));\n\n\tmsgsize += nla_total_size(IFNAMSIZ);\n\tmsgsize += nla_total_size_64bit(sizeof(struct ovs_dp_stats));\n\tmsgsize += nla_total_size_64bit(sizeof(struct ovs_dp_megaflow_stats));\n\tmsgsize += nla_total_size(sizeof(u32));  \n\tmsgsize += nla_total_size(sizeof(u32));  \n\tmsgsize += nla_total_size(sizeof(u32) * nr_cpu_ids);  \n\n\treturn msgsize;\n}\n\n \nstatic int ovs_dp_cmd_fill_info(struct datapath *dp, struct sk_buff *skb,\n\t\t\t\tu32 portid, u32 seq, u32 flags, u8 cmd)\n{\n\tstruct ovs_header *ovs_header;\n\tstruct ovs_dp_stats dp_stats;\n\tstruct ovs_dp_megaflow_stats dp_megaflow_stats;\n\tstruct dp_nlsk_pids *pids = ovsl_dereference(dp->upcall_portids);\n\tint err, pids_len;\n\n\tovs_header = genlmsg_put(skb, portid, seq, &dp_datapath_genl_family,\n\t\t\t\t flags, cmd);\n\tif (!ovs_header)\n\t\tgoto error;\n\n\tovs_header->dp_ifindex = get_dpifindex(dp);\n\n\terr = nla_put_string(skb, OVS_DP_ATTR_NAME, ovs_dp_name(dp));\n\tif (err)\n\t\tgoto nla_put_failure;\n\n\tget_dp_stats(dp, &dp_stats, &dp_megaflow_stats);\n\tif (nla_put_64bit(skb, OVS_DP_ATTR_STATS, sizeof(struct ovs_dp_stats),\n\t\t\t  &dp_stats, OVS_DP_ATTR_PAD))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_64bit(skb, OVS_DP_ATTR_MEGAFLOW_STATS,\n\t\t\t  sizeof(struct ovs_dp_megaflow_stats),\n\t\t\t  &dp_megaflow_stats, OVS_DP_ATTR_PAD))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u32(skb, OVS_DP_ATTR_USER_FEATURES, dp->user_features))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u32(skb, OVS_DP_ATTR_MASKS_CACHE_SIZE,\n\t\t\tovs_flow_tbl_masks_cache_size(&dp->table)))\n\t\tgoto nla_put_failure;\n\n\tif (dp->user_features & OVS_DP_F_DISPATCH_UPCALL_PER_CPU && pids) {\n\t\tpids_len = min(pids->n_pids, nr_cpu_ids) * sizeof(u32);\n\t\tif (nla_put(skb, OVS_DP_ATTR_PER_CPU_PIDS, pids_len, &pids->pids))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tgenlmsg_end(skb, ovs_header);\n\treturn 0;\n\nnla_put_failure:\n\tgenlmsg_cancel(skb, ovs_header);\nerror:\n\treturn -EMSGSIZE;\n}\n\nstatic struct sk_buff *ovs_dp_cmd_alloc_info(void)\n{\n\treturn genlmsg_new(ovs_dp_cmd_msg_size(), GFP_KERNEL);\n}\n\n \nstatic struct datapath *lookup_datapath(struct net *net,\n\t\t\t\t\tconst struct ovs_header *ovs_header,\n\t\t\t\t\tstruct nlattr *a[OVS_DP_ATTR_MAX + 1])\n{\n\tstruct datapath *dp;\n\n\tif (!a[OVS_DP_ATTR_NAME])\n\t\tdp = get_dp(net, ovs_header->dp_ifindex);\n\telse {\n\t\tstruct vport *vport;\n\n\t\tvport = ovs_vport_locate(net, nla_data(a[OVS_DP_ATTR_NAME]));\n\t\tdp = vport && vport->port_no == OVSP_LOCAL ? vport->dp : NULL;\n\t}\n\treturn dp ? dp : ERR_PTR(-ENODEV);\n}\n\nstatic void ovs_dp_reset_user_features(struct sk_buff *skb,\n\t\t\t\t       struct genl_info *info)\n{\n\tstruct datapath *dp;\n\n\tdp = lookup_datapath(sock_net(skb->sk), genl_info_userhdr(info),\n\t\t\t     info->attrs);\n\tif (IS_ERR(dp))\n\t\treturn;\n\n\tpr_warn(\"%s: Dropping previously announced user features\\n\",\n\t\tovs_dp_name(dp));\n\tdp->user_features = 0;\n}\n\nstatic int ovs_dp_set_upcall_portids(struct datapath *dp,\n\t\t\t      const struct nlattr *ids)\n{\n\tstruct dp_nlsk_pids *old, *dp_nlsk_pids;\n\n\tif (!nla_len(ids) || nla_len(ids) % sizeof(u32))\n\t\treturn -EINVAL;\n\n\told = ovsl_dereference(dp->upcall_portids);\n\n\tdp_nlsk_pids = kmalloc(sizeof(*dp_nlsk_pids) + nla_len(ids),\n\t\t\t       GFP_KERNEL);\n\tif (!dp_nlsk_pids)\n\t\treturn -ENOMEM;\n\n\tdp_nlsk_pids->n_pids = nla_len(ids) / sizeof(u32);\n\tnla_memcpy(dp_nlsk_pids->pids, ids, nla_len(ids));\n\n\trcu_assign_pointer(dp->upcall_portids, dp_nlsk_pids);\n\n\tkfree_rcu(old, rcu);\n\n\treturn 0;\n}\n\nu32 ovs_dp_get_upcall_portid(const struct datapath *dp, uint32_t cpu_id)\n{\n\tstruct dp_nlsk_pids *dp_nlsk_pids;\n\n\tdp_nlsk_pids = rcu_dereference(dp->upcall_portids);\n\n\tif (dp_nlsk_pids) {\n\t\tif (cpu_id < dp_nlsk_pids->n_pids) {\n\t\t\treturn dp_nlsk_pids->pids[cpu_id];\n\t\t} else if (dp_nlsk_pids->n_pids > 0 &&\n\t\t\t   cpu_id >= dp_nlsk_pids->n_pids) {\n\t\t\t \n\t\t\tpr_info_ratelimited(\"cpu_id mismatch with handler threads\");\n\t\t\treturn dp_nlsk_pids->pids[cpu_id %\n\t\t\t\t\t\t  dp_nlsk_pids->n_pids];\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\treturn 0;\n\t}\n}\n\nstatic int ovs_dp_change(struct datapath *dp, struct nlattr *a[])\n{\n\tu32 user_features = 0, old_features = dp->user_features;\n\tint err;\n\n\tif (a[OVS_DP_ATTR_USER_FEATURES]) {\n\t\tuser_features = nla_get_u32(a[OVS_DP_ATTR_USER_FEATURES]);\n\n\t\tif (user_features & ~(OVS_DP_F_VPORT_PIDS |\n\t\t\t\t      OVS_DP_F_UNALIGNED |\n\t\t\t\t      OVS_DP_F_TC_RECIRC_SHARING |\n\t\t\t\t      OVS_DP_F_DISPATCH_UPCALL_PER_CPU))\n\t\t\treturn -EOPNOTSUPP;\n\n#if !IS_ENABLED(CONFIG_NET_TC_SKB_EXT)\n\t\tif (user_features & OVS_DP_F_TC_RECIRC_SHARING)\n\t\t\treturn -EOPNOTSUPP;\n#endif\n\t}\n\n\tif (a[OVS_DP_ATTR_MASKS_CACHE_SIZE]) {\n\t\tint err;\n\t\tu32 cache_size;\n\n\t\tcache_size = nla_get_u32(a[OVS_DP_ATTR_MASKS_CACHE_SIZE]);\n\t\terr = ovs_flow_tbl_masks_cache_resize(&dp->table, cache_size);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tdp->user_features = user_features;\n\n\tif (dp->user_features & OVS_DP_F_DISPATCH_UPCALL_PER_CPU &&\n\t    a[OVS_DP_ATTR_PER_CPU_PIDS]) {\n\t\t \n\t\terr = ovs_dp_set_upcall_portids(dp,\n\t\t\t\t\t\ta[OVS_DP_ATTR_PER_CPU_PIDS]);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif ((dp->user_features & OVS_DP_F_TC_RECIRC_SHARING) &&\n\t    !(old_features & OVS_DP_F_TC_RECIRC_SHARING))\n\t\ttc_skb_ext_tc_enable();\n\telse if (!(dp->user_features & OVS_DP_F_TC_RECIRC_SHARING) &&\n\t\t (old_features & OVS_DP_F_TC_RECIRC_SHARING))\n\t\ttc_skb_ext_tc_disable();\n\n\treturn 0;\n}\n\nstatic int ovs_dp_stats_init(struct datapath *dp)\n{\n\tdp->stats_percpu = netdev_alloc_pcpu_stats(struct dp_stats_percpu);\n\tif (!dp->stats_percpu)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic int ovs_dp_vport_init(struct datapath *dp)\n{\n\tint i;\n\n\tdp->ports = kmalloc_array(DP_VPORT_HASH_BUCKETS,\n\t\t\t\t  sizeof(struct hlist_head),\n\t\t\t\t  GFP_KERNEL);\n\tif (!dp->ports)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < DP_VPORT_HASH_BUCKETS; i++)\n\t\tINIT_HLIST_HEAD(&dp->ports[i]);\n\n\treturn 0;\n}\n\nstatic int ovs_dp_cmd_new(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct nlattr **a = info->attrs;\n\tstruct vport_parms parms;\n\tstruct sk_buff *reply;\n\tstruct datapath *dp;\n\tstruct vport *vport;\n\tstruct ovs_net *ovs_net;\n\tint err;\n\n\terr = -EINVAL;\n\tif (!a[OVS_DP_ATTR_NAME] || !a[OVS_DP_ATTR_UPCALL_PID])\n\t\tgoto err;\n\n\treply = ovs_dp_cmd_alloc_info();\n\tif (!reply)\n\t\treturn -ENOMEM;\n\n\terr = -ENOMEM;\n\tdp = kzalloc(sizeof(*dp), GFP_KERNEL);\n\tif (dp == NULL)\n\t\tgoto err_destroy_reply;\n\n\tovs_dp_set_net(dp, sock_net(skb->sk));\n\n\t \n\terr = ovs_flow_tbl_init(&dp->table);\n\tif (err)\n\t\tgoto err_destroy_dp;\n\n\terr = ovs_dp_stats_init(dp);\n\tif (err)\n\t\tgoto err_destroy_table;\n\n\terr = ovs_dp_vport_init(dp);\n\tif (err)\n\t\tgoto err_destroy_stats;\n\n\terr = ovs_meters_init(dp);\n\tif (err)\n\t\tgoto err_destroy_ports;\n\n\t \n\tparms.name = nla_data(a[OVS_DP_ATTR_NAME]);\n\tparms.type = OVS_VPORT_TYPE_INTERNAL;\n\tparms.options = NULL;\n\tparms.dp = dp;\n\tparms.port_no = OVSP_LOCAL;\n\tparms.upcall_portids = a[OVS_DP_ATTR_UPCALL_PID];\n\tparms.desired_ifindex = a[OVS_DP_ATTR_IFINDEX]\n\t\t? nla_get_s32(a[OVS_DP_ATTR_IFINDEX]) : 0;\n\n\t \n\tovs_lock();\n\n\terr = ovs_dp_change(dp, a);\n\tif (err)\n\t\tgoto err_unlock_and_destroy_meters;\n\n\tvport = new_vport(&parms);\n\tif (IS_ERR(vport)) {\n\t\terr = PTR_ERR(vport);\n\t\tif (err == -EBUSY)\n\t\t\terr = -EEXIST;\n\n\t\tif (err == -EEXIST) {\n\t\t\t \n\t\t\tif (info->genlhdr->version < OVS_DP_VER_FEATURES)\n\t\t\t\tovs_dp_reset_user_features(skb, info);\n\t\t}\n\n\t\tgoto err_destroy_portids;\n\t}\n\n\terr = ovs_dp_cmd_fill_info(dp, reply, info->snd_portid,\n\t\t\t\t   info->snd_seq, 0, OVS_DP_CMD_NEW);\n\tBUG_ON(err < 0);\n\n\tovs_net = net_generic(ovs_dp_get_net(dp), ovs_net_id);\n\tlist_add_tail_rcu(&dp->list_node, &ovs_net->dps);\n\n\tovs_unlock();\n\n\tovs_notify(&dp_datapath_genl_family, reply, info);\n\treturn 0;\n\nerr_destroy_portids:\n\tkfree(rcu_dereference_raw(dp->upcall_portids));\nerr_unlock_and_destroy_meters:\n\tovs_unlock();\n\tovs_meters_exit(dp);\nerr_destroy_ports:\n\tkfree(dp->ports);\nerr_destroy_stats:\n\tfree_percpu(dp->stats_percpu);\nerr_destroy_table:\n\tovs_flow_tbl_destroy(&dp->table);\nerr_destroy_dp:\n\tkfree(dp);\nerr_destroy_reply:\n\tkfree_skb(reply);\nerr:\n\treturn err;\n}\n\n \nstatic void __dp_destroy(struct datapath *dp)\n{\n\tstruct flow_table *table = &dp->table;\n\tint i;\n\n\tif (dp->user_features & OVS_DP_F_TC_RECIRC_SHARING)\n\t\ttc_skb_ext_tc_disable();\n\n\tfor (i = 0; i < DP_VPORT_HASH_BUCKETS; i++) {\n\t\tstruct vport *vport;\n\t\tstruct hlist_node *n;\n\n\t\thlist_for_each_entry_safe(vport, n, &dp->ports[i], dp_hash_node)\n\t\t\tif (vport->port_no != OVSP_LOCAL)\n\t\t\t\tovs_dp_detach_port(vport);\n\t}\n\n\tlist_del_rcu(&dp->list_node);\n\n\t \n\tovs_dp_detach_port(ovs_vport_ovsl(dp, OVSP_LOCAL));\n\n\t \n\ttable_instance_flow_flush(table, ovsl_dereference(table->ti),\n\t\t\t\t  ovsl_dereference(table->ufid_ti));\n\n\t \n\tcall_rcu(&dp->rcu, destroy_dp_rcu);\n}\n\nstatic int ovs_dp_cmd_del(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct sk_buff *reply;\n\tstruct datapath *dp;\n\tint err;\n\n\treply = ovs_dp_cmd_alloc_info();\n\tif (!reply)\n\t\treturn -ENOMEM;\n\n\tovs_lock();\n\tdp = lookup_datapath(sock_net(skb->sk), genl_info_userhdr(info),\n\t\t\t     info->attrs);\n\terr = PTR_ERR(dp);\n\tif (IS_ERR(dp))\n\t\tgoto err_unlock_free;\n\n\terr = ovs_dp_cmd_fill_info(dp, reply, info->snd_portid,\n\t\t\t\t   info->snd_seq, 0, OVS_DP_CMD_DEL);\n\tBUG_ON(err < 0);\n\n\t__dp_destroy(dp);\n\tovs_unlock();\n\n\tovs_notify(&dp_datapath_genl_family, reply, info);\n\n\treturn 0;\n\nerr_unlock_free:\n\tovs_unlock();\n\tkfree_skb(reply);\n\treturn err;\n}\n\nstatic int ovs_dp_cmd_set(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct sk_buff *reply;\n\tstruct datapath *dp;\n\tint err;\n\n\treply = ovs_dp_cmd_alloc_info();\n\tif (!reply)\n\t\treturn -ENOMEM;\n\n\tovs_lock();\n\tdp = lookup_datapath(sock_net(skb->sk), genl_info_userhdr(info),\n\t\t\t     info->attrs);\n\terr = PTR_ERR(dp);\n\tif (IS_ERR(dp))\n\t\tgoto err_unlock_free;\n\n\terr = ovs_dp_change(dp, info->attrs);\n\tif (err)\n\t\tgoto err_unlock_free;\n\n\terr = ovs_dp_cmd_fill_info(dp, reply, info->snd_portid,\n\t\t\t\t   info->snd_seq, 0, OVS_DP_CMD_SET);\n\tBUG_ON(err < 0);\n\n\tovs_unlock();\n\tovs_notify(&dp_datapath_genl_family, reply, info);\n\n\treturn 0;\n\nerr_unlock_free:\n\tovs_unlock();\n\tkfree_skb(reply);\n\treturn err;\n}\n\nstatic int ovs_dp_cmd_get(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct sk_buff *reply;\n\tstruct datapath *dp;\n\tint err;\n\n\treply = ovs_dp_cmd_alloc_info();\n\tif (!reply)\n\t\treturn -ENOMEM;\n\n\tovs_lock();\n\tdp = lookup_datapath(sock_net(skb->sk), genl_info_userhdr(info),\n\t\t\t     info->attrs);\n\tif (IS_ERR(dp)) {\n\t\terr = PTR_ERR(dp);\n\t\tgoto err_unlock_free;\n\t}\n\terr = ovs_dp_cmd_fill_info(dp, reply, info->snd_portid,\n\t\t\t\t   info->snd_seq, 0, OVS_DP_CMD_GET);\n\tBUG_ON(err < 0);\n\tovs_unlock();\n\n\treturn genlmsg_reply(reply, info);\n\nerr_unlock_free:\n\tovs_unlock();\n\tkfree_skb(reply);\n\treturn err;\n}\n\nstatic int ovs_dp_cmd_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct ovs_net *ovs_net = net_generic(sock_net(skb->sk), ovs_net_id);\n\tstruct datapath *dp;\n\tint skip = cb->args[0];\n\tint i = 0;\n\n\tovs_lock();\n\tlist_for_each_entry(dp, &ovs_net->dps, list_node) {\n\t\tif (i >= skip &&\n\t\t    ovs_dp_cmd_fill_info(dp, skb, NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t cb->nlh->nlmsg_seq, NLM_F_MULTI,\n\t\t\t\t\t OVS_DP_CMD_GET) < 0)\n\t\t\tbreak;\n\t\ti++;\n\t}\n\tovs_unlock();\n\n\tcb->args[0] = i;\n\n\treturn skb->len;\n}\n\nstatic const struct nla_policy datapath_policy[OVS_DP_ATTR_MAX + 1] = {\n\t[OVS_DP_ATTR_NAME] = { .type = NLA_NUL_STRING, .len = IFNAMSIZ - 1 },\n\t[OVS_DP_ATTR_UPCALL_PID] = { .type = NLA_U32 },\n\t[OVS_DP_ATTR_USER_FEATURES] = { .type = NLA_U32 },\n\t[OVS_DP_ATTR_MASKS_CACHE_SIZE] =  NLA_POLICY_RANGE(NLA_U32, 0,\n\t\tPCPU_MIN_UNIT_SIZE / sizeof(struct mask_cache_entry)),\n\t[OVS_DP_ATTR_IFINDEX] = NLA_POLICY_MIN(NLA_S32, 0),\n};\n\nstatic const struct genl_small_ops dp_datapath_genl_ops[] = {\n\t{ .cmd = OVS_DP_CMD_NEW,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = GENL_UNS_ADMIN_PERM,  \n\t  .doit = ovs_dp_cmd_new\n\t},\n\t{ .cmd = OVS_DP_CMD_DEL,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = GENL_UNS_ADMIN_PERM,  \n\t  .doit = ovs_dp_cmd_del\n\t},\n\t{ .cmd = OVS_DP_CMD_GET,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = 0,\t\t     \n\t  .doit = ovs_dp_cmd_get,\n\t  .dumpit = ovs_dp_cmd_dump\n\t},\n\t{ .cmd = OVS_DP_CMD_SET,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = GENL_UNS_ADMIN_PERM,  \n\t  .doit = ovs_dp_cmd_set,\n\t},\n};\n\nstatic struct genl_family dp_datapath_genl_family __ro_after_init = {\n\t.hdrsize = sizeof(struct ovs_header),\n\t.name = OVS_DATAPATH_FAMILY,\n\t.version = OVS_DATAPATH_VERSION,\n\t.maxattr = OVS_DP_ATTR_MAX,\n\t.policy = datapath_policy,\n\t.netnsok = true,\n\t.parallel_ops = true,\n\t.small_ops = dp_datapath_genl_ops,\n\t.n_small_ops = ARRAY_SIZE(dp_datapath_genl_ops),\n\t.resv_start_op = OVS_DP_CMD_SET + 1,\n\t.mcgrps = &ovs_dp_datapath_multicast_group,\n\t.n_mcgrps = 1,\n\t.module = THIS_MODULE,\n};\n\n \nstatic int ovs_vport_cmd_fill_info(struct vport *vport, struct sk_buff *skb,\n\t\t\t\t   struct net *net, u32 portid, u32 seq,\n\t\t\t\t   u32 flags, u8 cmd, gfp_t gfp)\n{\n\tstruct ovs_header *ovs_header;\n\tstruct ovs_vport_stats vport_stats;\n\tint err;\n\n\tovs_header = genlmsg_put(skb, portid, seq, &dp_vport_genl_family,\n\t\t\t\t flags, cmd);\n\tif (!ovs_header)\n\t\treturn -EMSGSIZE;\n\n\tovs_header->dp_ifindex = get_dpifindex(vport->dp);\n\n\tif (nla_put_u32(skb, OVS_VPORT_ATTR_PORT_NO, vport->port_no) ||\n\t    nla_put_u32(skb, OVS_VPORT_ATTR_TYPE, vport->ops->type) ||\n\t    nla_put_string(skb, OVS_VPORT_ATTR_NAME,\n\t\t\t   ovs_vport_name(vport)) ||\n\t    nla_put_u32(skb, OVS_VPORT_ATTR_IFINDEX, vport->dev->ifindex))\n\t\tgoto nla_put_failure;\n\n\tif (!net_eq(net, dev_net(vport->dev))) {\n\t\tint id = peernet2id_alloc(net, dev_net(vport->dev), gfp);\n\n\t\tif (nla_put_s32(skb, OVS_VPORT_ATTR_NETNSID, id))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tovs_vport_get_stats(vport, &vport_stats);\n\tif (nla_put_64bit(skb, OVS_VPORT_ATTR_STATS,\n\t\t\t  sizeof(struct ovs_vport_stats), &vport_stats,\n\t\t\t  OVS_VPORT_ATTR_PAD))\n\t\tgoto nla_put_failure;\n\n\tif (ovs_vport_get_upcall_stats(vport, skb))\n\t\tgoto nla_put_failure;\n\n\tif (ovs_vport_get_upcall_portids(vport, skb))\n\t\tgoto nla_put_failure;\n\n\terr = ovs_vport_get_options(vport, skb);\n\tif (err == -EMSGSIZE)\n\t\tgoto error;\n\n\tgenlmsg_end(skb, ovs_header);\n\treturn 0;\n\nnla_put_failure:\n\terr = -EMSGSIZE;\nerror:\n\tgenlmsg_cancel(skb, ovs_header);\n\treturn err;\n}\n\nstatic struct sk_buff *ovs_vport_cmd_alloc_info(void)\n{\n\treturn nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\n}\n\n \nstruct sk_buff *ovs_vport_cmd_build_info(struct vport *vport, struct net *net,\n\t\t\t\t\t u32 portid, u32 seq, u8 cmd)\n{\n\tstruct sk_buff *skb;\n\tint retval;\n\n\tskb = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\n\tif (!skb)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tretval = ovs_vport_cmd_fill_info(vport, skb, net, portid, seq, 0, cmd,\n\t\t\t\t\t GFP_KERNEL);\n\tBUG_ON(retval < 0);\n\n\treturn skb;\n}\n\n \nstatic struct vport *lookup_vport(struct net *net,\n\t\t\t\t  const struct ovs_header *ovs_header,\n\t\t\t\t  struct nlattr *a[OVS_VPORT_ATTR_MAX + 1])\n{\n\tstruct datapath *dp;\n\tstruct vport *vport;\n\n\tif (a[OVS_VPORT_ATTR_IFINDEX])\n\t\treturn ERR_PTR(-EOPNOTSUPP);\n\tif (a[OVS_VPORT_ATTR_NAME]) {\n\t\tvport = ovs_vport_locate(net, nla_data(a[OVS_VPORT_ATTR_NAME]));\n\t\tif (!vport)\n\t\t\treturn ERR_PTR(-ENODEV);\n\t\tif (ovs_header->dp_ifindex &&\n\t\t    ovs_header->dp_ifindex != get_dpifindex(vport->dp))\n\t\t\treturn ERR_PTR(-ENODEV);\n\t\treturn vport;\n\t} else if (a[OVS_VPORT_ATTR_PORT_NO]) {\n\t\tu32 port_no = nla_get_u32(a[OVS_VPORT_ATTR_PORT_NO]);\n\n\t\tif (port_no >= DP_MAX_PORTS)\n\t\t\treturn ERR_PTR(-EFBIG);\n\n\t\tdp = get_dp(net, ovs_header->dp_ifindex);\n\t\tif (!dp)\n\t\t\treturn ERR_PTR(-ENODEV);\n\n\t\tvport = ovs_vport_ovsl_rcu(dp, port_no);\n\t\tif (!vport)\n\t\t\treturn ERR_PTR(-ENODEV);\n\t\treturn vport;\n\t} else\n\t\treturn ERR_PTR(-EINVAL);\n\n}\n\nstatic unsigned int ovs_get_max_headroom(struct datapath *dp)\n{\n\tunsigned int dev_headroom, max_headroom = 0;\n\tstruct net_device *dev;\n\tstruct vport *vport;\n\tint i;\n\n\tfor (i = 0; i < DP_VPORT_HASH_BUCKETS; i++) {\n\t\thlist_for_each_entry_rcu(vport, &dp->ports[i], dp_hash_node,\n\t\t\t\t\t lockdep_ovsl_is_held()) {\n\t\t\tdev = vport->dev;\n\t\t\tdev_headroom = netdev_get_fwd_headroom(dev);\n\t\t\tif (dev_headroom > max_headroom)\n\t\t\t\tmax_headroom = dev_headroom;\n\t\t}\n\t}\n\n\treturn max_headroom;\n}\n\n \nstatic void ovs_update_headroom(struct datapath *dp, unsigned int new_headroom)\n{\n\tstruct vport *vport;\n\tint i;\n\n\tdp->max_headroom = new_headroom;\n\tfor (i = 0; i < DP_VPORT_HASH_BUCKETS; i++) {\n\t\thlist_for_each_entry_rcu(vport, &dp->ports[i], dp_hash_node,\n\t\t\t\t\t lockdep_ovsl_is_held())\n\t\t\tnetdev_set_rx_headroom(vport->dev, new_headroom);\n\t}\n}\n\nstatic int ovs_vport_cmd_new(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct nlattr **a = info->attrs;\n\tstruct ovs_header *ovs_header = genl_info_userhdr(info);\n\tstruct vport_parms parms;\n\tstruct sk_buff *reply;\n\tstruct vport *vport;\n\tstruct datapath *dp;\n\tunsigned int new_headroom;\n\tu32 port_no;\n\tint err;\n\n\tif (!a[OVS_VPORT_ATTR_NAME] || !a[OVS_VPORT_ATTR_TYPE] ||\n\t    !a[OVS_VPORT_ATTR_UPCALL_PID])\n\t\treturn -EINVAL;\n\n\tparms.type = nla_get_u32(a[OVS_VPORT_ATTR_TYPE]);\n\n\tif (a[OVS_VPORT_ATTR_IFINDEX] && parms.type != OVS_VPORT_TYPE_INTERNAL)\n\t\treturn -EOPNOTSUPP;\n\n\tport_no = a[OVS_VPORT_ATTR_PORT_NO]\n\t\t? nla_get_u32(a[OVS_VPORT_ATTR_PORT_NO]) : 0;\n\tif (port_no >= DP_MAX_PORTS)\n\t\treturn -EFBIG;\n\n\treply = ovs_vport_cmd_alloc_info();\n\tif (!reply)\n\t\treturn -ENOMEM;\n\n\tovs_lock();\nrestart:\n\tdp = get_dp(sock_net(skb->sk), ovs_header->dp_ifindex);\n\terr = -ENODEV;\n\tif (!dp)\n\t\tgoto exit_unlock_free;\n\n\tif (port_no) {\n\t\tvport = ovs_vport_ovsl(dp, port_no);\n\t\terr = -EBUSY;\n\t\tif (vport)\n\t\t\tgoto exit_unlock_free;\n\t} else {\n\t\tfor (port_no = 1; ; port_no++) {\n\t\t\tif (port_no >= DP_MAX_PORTS) {\n\t\t\t\terr = -EFBIG;\n\t\t\t\tgoto exit_unlock_free;\n\t\t\t}\n\t\t\tvport = ovs_vport_ovsl(dp, port_no);\n\t\t\tif (!vport)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tparms.name = nla_data(a[OVS_VPORT_ATTR_NAME]);\n\tparms.options = a[OVS_VPORT_ATTR_OPTIONS];\n\tparms.dp = dp;\n\tparms.port_no = port_no;\n\tparms.upcall_portids = a[OVS_VPORT_ATTR_UPCALL_PID];\n\tparms.desired_ifindex = a[OVS_VPORT_ATTR_IFINDEX]\n\t\t? nla_get_s32(a[OVS_VPORT_ATTR_IFINDEX]) : 0;\n\n\tvport = new_vport(&parms);\n\terr = PTR_ERR(vport);\n\tif (IS_ERR(vport)) {\n\t\tif (err == -EAGAIN)\n\t\t\tgoto restart;\n\t\tgoto exit_unlock_free;\n\t}\n\n\terr = ovs_vport_cmd_fill_info(vport, reply, genl_info_net(info),\n\t\t\t\t      info->snd_portid, info->snd_seq, 0,\n\t\t\t\t      OVS_VPORT_CMD_NEW, GFP_KERNEL);\n\n\tnew_headroom = netdev_get_fwd_headroom(vport->dev);\n\n\tif (new_headroom > dp->max_headroom)\n\t\tovs_update_headroom(dp, new_headroom);\n\telse\n\t\tnetdev_set_rx_headroom(vport->dev, dp->max_headroom);\n\n\tBUG_ON(err < 0);\n\tovs_unlock();\n\n\tovs_notify(&dp_vport_genl_family, reply, info);\n\treturn 0;\n\nexit_unlock_free:\n\tovs_unlock();\n\tkfree_skb(reply);\n\treturn err;\n}\n\nstatic int ovs_vport_cmd_set(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct nlattr **a = info->attrs;\n\tstruct sk_buff *reply;\n\tstruct vport *vport;\n\tint err;\n\n\treply = ovs_vport_cmd_alloc_info();\n\tif (!reply)\n\t\treturn -ENOMEM;\n\n\tovs_lock();\n\tvport = lookup_vport(sock_net(skb->sk), genl_info_userhdr(info), a);\n\terr = PTR_ERR(vport);\n\tif (IS_ERR(vport))\n\t\tgoto exit_unlock_free;\n\n\tif (a[OVS_VPORT_ATTR_TYPE] &&\n\t    nla_get_u32(a[OVS_VPORT_ATTR_TYPE]) != vport->ops->type) {\n\t\terr = -EINVAL;\n\t\tgoto exit_unlock_free;\n\t}\n\n\tif (a[OVS_VPORT_ATTR_OPTIONS]) {\n\t\terr = ovs_vport_set_options(vport, a[OVS_VPORT_ATTR_OPTIONS]);\n\t\tif (err)\n\t\t\tgoto exit_unlock_free;\n\t}\n\n\n\tif (a[OVS_VPORT_ATTR_UPCALL_PID]) {\n\t\tstruct nlattr *ids = a[OVS_VPORT_ATTR_UPCALL_PID];\n\n\t\terr = ovs_vport_set_upcall_portids(vport, ids);\n\t\tif (err)\n\t\t\tgoto exit_unlock_free;\n\t}\n\n\terr = ovs_vport_cmd_fill_info(vport, reply, genl_info_net(info),\n\t\t\t\t      info->snd_portid, info->snd_seq, 0,\n\t\t\t\t      OVS_VPORT_CMD_SET, GFP_KERNEL);\n\tBUG_ON(err < 0);\n\n\tovs_unlock();\n\tovs_notify(&dp_vport_genl_family, reply, info);\n\treturn 0;\n\nexit_unlock_free:\n\tovs_unlock();\n\tkfree_skb(reply);\n\treturn err;\n}\n\nstatic int ovs_vport_cmd_del(struct sk_buff *skb, struct genl_info *info)\n{\n\tbool update_headroom = false;\n\tstruct nlattr **a = info->attrs;\n\tstruct sk_buff *reply;\n\tstruct datapath *dp;\n\tstruct vport *vport;\n\tunsigned int new_headroom;\n\tint err;\n\n\treply = ovs_vport_cmd_alloc_info();\n\tif (!reply)\n\t\treturn -ENOMEM;\n\n\tovs_lock();\n\tvport = lookup_vport(sock_net(skb->sk), genl_info_userhdr(info), a);\n\terr = PTR_ERR(vport);\n\tif (IS_ERR(vport))\n\t\tgoto exit_unlock_free;\n\n\tif (vport->port_no == OVSP_LOCAL) {\n\t\terr = -EINVAL;\n\t\tgoto exit_unlock_free;\n\t}\n\n\terr = ovs_vport_cmd_fill_info(vport, reply, genl_info_net(info),\n\t\t\t\t      info->snd_portid, info->snd_seq, 0,\n\t\t\t\t      OVS_VPORT_CMD_DEL, GFP_KERNEL);\n\tBUG_ON(err < 0);\n\n\t \n\tdp = vport->dp;\n\tif (netdev_get_fwd_headroom(vport->dev) == dp->max_headroom)\n\t\tupdate_headroom = true;\n\n\tnetdev_reset_rx_headroom(vport->dev);\n\tovs_dp_detach_port(vport);\n\n\tif (update_headroom) {\n\t\tnew_headroom = ovs_get_max_headroom(dp);\n\n\t\tif (new_headroom < dp->max_headroom)\n\t\t\tovs_update_headroom(dp, new_headroom);\n\t}\n\tovs_unlock();\n\n\tovs_notify(&dp_vport_genl_family, reply, info);\n\treturn 0;\n\nexit_unlock_free:\n\tovs_unlock();\n\tkfree_skb(reply);\n\treturn err;\n}\n\nstatic int ovs_vport_cmd_get(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct nlattr **a = info->attrs;\n\tstruct ovs_header *ovs_header = genl_info_userhdr(info);\n\tstruct sk_buff *reply;\n\tstruct vport *vport;\n\tint err;\n\n\treply = ovs_vport_cmd_alloc_info();\n\tif (!reply)\n\t\treturn -ENOMEM;\n\n\trcu_read_lock();\n\tvport = lookup_vport(sock_net(skb->sk), ovs_header, a);\n\terr = PTR_ERR(vport);\n\tif (IS_ERR(vport))\n\t\tgoto exit_unlock_free;\n\terr = ovs_vport_cmd_fill_info(vport, reply, genl_info_net(info),\n\t\t\t\t      info->snd_portid, info->snd_seq, 0,\n\t\t\t\t      OVS_VPORT_CMD_GET, GFP_ATOMIC);\n\tBUG_ON(err < 0);\n\trcu_read_unlock();\n\n\treturn genlmsg_reply(reply, info);\n\nexit_unlock_free:\n\trcu_read_unlock();\n\tkfree_skb(reply);\n\treturn err;\n}\n\nstatic int ovs_vport_cmd_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct ovs_header *ovs_header = genlmsg_data(nlmsg_data(cb->nlh));\n\tstruct datapath *dp;\n\tint bucket = cb->args[0], skip = cb->args[1];\n\tint i, j = 0;\n\n\trcu_read_lock();\n\tdp = get_dp_rcu(sock_net(skb->sk), ovs_header->dp_ifindex);\n\tif (!dp) {\n\t\trcu_read_unlock();\n\t\treturn -ENODEV;\n\t}\n\tfor (i = bucket; i < DP_VPORT_HASH_BUCKETS; i++) {\n\t\tstruct vport *vport;\n\n\t\tj = 0;\n\t\thlist_for_each_entry_rcu(vport, &dp->ports[i], dp_hash_node) {\n\t\t\tif (j >= skip &&\n\t\t\t    ovs_vport_cmd_fill_info(vport, skb,\n\t\t\t\t\t\t    sock_net(skb->sk),\n\t\t\t\t\t\t    NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t\t    cb->nlh->nlmsg_seq,\n\t\t\t\t\t\t    NLM_F_MULTI,\n\t\t\t\t\t\t    OVS_VPORT_CMD_GET,\n\t\t\t\t\t\t    GFP_ATOMIC) < 0)\n\t\t\t\tgoto out;\n\n\t\t\tj++;\n\t\t}\n\t\tskip = 0;\n\t}\nout:\n\trcu_read_unlock();\n\n\tcb->args[0] = i;\n\tcb->args[1] = j;\n\n\treturn skb->len;\n}\n\nstatic void ovs_dp_masks_rebalance(struct work_struct *work)\n{\n\tstruct ovs_net *ovs_net = container_of(work, struct ovs_net,\n\t\t\t\t\t       masks_rebalance.work);\n\tstruct datapath *dp;\n\n\tovs_lock();\n\n\tlist_for_each_entry(dp, &ovs_net->dps, list_node)\n\t\tovs_flow_masks_rebalance(&dp->table);\n\n\tovs_unlock();\n\n\tschedule_delayed_work(&ovs_net->masks_rebalance,\n\t\t\t      msecs_to_jiffies(DP_MASKS_REBALANCE_INTERVAL));\n}\n\nstatic const struct nla_policy vport_policy[OVS_VPORT_ATTR_MAX + 1] = {\n\t[OVS_VPORT_ATTR_NAME] = { .type = NLA_NUL_STRING, .len = IFNAMSIZ - 1 },\n\t[OVS_VPORT_ATTR_STATS] = { .len = sizeof(struct ovs_vport_stats) },\n\t[OVS_VPORT_ATTR_PORT_NO] = { .type = NLA_U32 },\n\t[OVS_VPORT_ATTR_TYPE] = { .type = NLA_U32 },\n\t[OVS_VPORT_ATTR_UPCALL_PID] = { .type = NLA_UNSPEC },\n\t[OVS_VPORT_ATTR_OPTIONS] = { .type = NLA_NESTED },\n\t[OVS_VPORT_ATTR_IFINDEX] = NLA_POLICY_MIN(NLA_S32, 0),\n\t[OVS_VPORT_ATTR_NETNSID] = { .type = NLA_S32 },\n\t[OVS_VPORT_ATTR_UPCALL_STATS] = { .type = NLA_NESTED },\n};\n\nstatic const struct genl_small_ops dp_vport_genl_ops[] = {\n\t{ .cmd = OVS_VPORT_CMD_NEW,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = GENL_UNS_ADMIN_PERM,  \n\t  .doit = ovs_vport_cmd_new\n\t},\n\t{ .cmd = OVS_VPORT_CMD_DEL,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = GENL_UNS_ADMIN_PERM,  \n\t  .doit = ovs_vport_cmd_del\n\t},\n\t{ .cmd = OVS_VPORT_CMD_GET,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = 0,\t\t     \n\t  .doit = ovs_vport_cmd_get,\n\t  .dumpit = ovs_vport_cmd_dump\n\t},\n\t{ .cmd = OVS_VPORT_CMD_SET,\n\t  .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t  .flags = GENL_UNS_ADMIN_PERM,  \n\t  .doit = ovs_vport_cmd_set,\n\t},\n};\n\nstruct genl_family dp_vport_genl_family __ro_after_init = {\n\t.hdrsize = sizeof(struct ovs_header),\n\t.name = OVS_VPORT_FAMILY,\n\t.version = OVS_VPORT_VERSION,\n\t.maxattr = OVS_VPORT_ATTR_MAX,\n\t.policy = vport_policy,\n\t.netnsok = true,\n\t.parallel_ops = true,\n\t.small_ops = dp_vport_genl_ops,\n\t.n_small_ops = ARRAY_SIZE(dp_vport_genl_ops),\n\t.resv_start_op = OVS_VPORT_CMD_SET + 1,\n\t.mcgrps = &ovs_dp_vport_multicast_group,\n\t.n_mcgrps = 1,\n\t.module = THIS_MODULE,\n};\n\nstatic struct genl_family * const dp_genl_families[] = {\n\t&dp_datapath_genl_family,\n\t&dp_vport_genl_family,\n\t&dp_flow_genl_family,\n\t&dp_packet_genl_family,\n\t&dp_meter_genl_family,\n#if\tIS_ENABLED(CONFIG_NETFILTER_CONNCOUNT)\n\t&dp_ct_limit_genl_family,\n#endif\n};\n\nstatic void dp_unregister_genl(int n_families)\n{\n\tint i;\n\n\tfor (i = 0; i < n_families; i++)\n\t\tgenl_unregister_family(dp_genl_families[i]);\n}\n\nstatic int __init dp_register_genl(void)\n{\n\tint err;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(dp_genl_families); i++) {\n\n\t\terr = genl_register_family(dp_genl_families[i]);\n\t\tif (err)\n\t\t\tgoto error;\n\t}\n\n\treturn 0;\n\nerror:\n\tdp_unregister_genl(i);\n\treturn err;\n}\n\nstatic int __net_init ovs_init_net(struct net *net)\n{\n\tstruct ovs_net *ovs_net = net_generic(net, ovs_net_id);\n\tint err;\n\n\tINIT_LIST_HEAD(&ovs_net->dps);\n\tINIT_WORK(&ovs_net->dp_notify_work, ovs_dp_notify_wq);\n\tINIT_DELAYED_WORK(&ovs_net->masks_rebalance, ovs_dp_masks_rebalance);\n\n\terr = ovs_ct_init(net);\n\tif (err)\n\t\treturn err;\n\n\tschedule_delayed_work(&ovs_net->masks_rebalance,\n\t\t\t      msecs_to_jiffies(DP_MASKS_REBALANCE_INTERVAL));\n\treturn 0;\n}\n\nstatic void __net_exit list_vports_from_net(struct net *net, struct net *dnet,\n\t\t\t\t\t    struct list_head *head)\n{\n\tstruct ovs_net *ovs_net = net_generic(net, ovs_net_id);\n\tstruct datapath *dp;\n\n\tlist_for_each_entry(dp, &ovs_net->dps, list_node) {\n\t\tint i;\n\n\t\tfor (i = 0; i < DP_VPORT_HASH_BUCKETS; i++) {\n\t\t\tstruct vport *vport;\n\n\t\t\thlist_for_each_entry(vport, &dp->ports[i], dp_hash_node) {\n\t\t\t\tif (vport->ops->type != OVS_VPORT_TYPE_INTERNAL)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tif (dev_net(vport->dev) == dnet)\n\t\t\t\t\tlist_add(&vport->detach_list, head);\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void __net_exit ovs_exit_net(struct net *dnet)\n{\n\tstruct datapath *dp, *dp_next;\n\tstruct ovs_net *ovs_net = net_generic(dnet, ovs_net_id);\n\tstruct vport *vport, *vport_next;\n\tstruct net *net;\n\tLIST_HEAD(head);\n\n\tovs_lock();\n\n\tovs_ct_exit(dnet);\n\n\tlist_for_each_entry_safe(dp, dp_next, &ovs_net->dps, list_node)\n\t\t__dp_destroy(dp);\n\n\tdown_read(&net_rwsem);\n\tfor_each_net(net)\n\t\tlist_vports_from_net(net, dnet, &head);\n\tup_read(&net_rwsem);\n\n\t \n\tlist_for_each_entry_safe(vport, vport_next, &head, detach_list) {\n\t\tlist_del(&vport->detach_list);\n\t\tovs_dp_detach_port(vport);\n\t}\n\n\tovs_unlock();\n\n\tcancel_delayed_work_sync(&ovs_net->masks_rebalance);\n\tcancel_work_sync(&ovs_net->dp_notify_work);\n}\n\nstatic struct pernet_operations ovs_net_ops = {\n\t.init = ovs_init_net,\n\t.exit = ovs_exit_net,\n\t.id   = &ovs_net_id,\n\t.size = sizeof(struct ovs_net),\n};\n\nstatic const char * const ovs_drop_reasons[] = {\n#define S(x)\t(#x),\n\tOVS_DROP_REASONS(S)\n#undef S\n};\n\nstatic struct drop_reason_list drop_reason_list_ovs = {\n\t.reasons = ovs_drop_reasons,\n\t.n_reasons = ARRAY_SIZE(ovs_drop_reasons),\n};\n\nstatic int __init dp_init(void)\n{\n\tint err;\n\n\tBUILD_BUG_ON(sizeof(struct ovs_skb_cb) >\n\t\t     sizeof_field(struct sk_buff, cb));\n\n\tpr_info(\"Open vSwitch switching datapath\\n\");\n\n\terr = action_fifos_init();\n\tif (err)\n\t\tgoto error;\n\n\terr = ovs_internal_dev_rtnl_link_register();\n\tif (err)\n\t\tgoto error_action_fifos_exit;\n\n\terr = ovs_flow_init();\n\tif (err)\n\t\tgoto error_unreg_rtnl_link;\n\n\terr = ovs_vport_init();\n\tif (err)\n\t\tgoto error_flow_exit;\n\n\terr = register_pernet_device(&ovs_net_ops);\n\tif (err)\n\t\tgoto error_vport_exit;\n\n\terr = register_netdevice_notifier(&ovs_dp_device_notifier);\n\tif (err)\n\t\tgoto error_netns_exit;\n\n\terr = ovs_netdev_init();\n\tif (err)\n\t\tgoto error_unreg_notifier;\n\n\terr = dp_register_genl();\n\tif (err < 0)\n\t\tgoto error_unreg_netdev;\n\n\tdrop_reasons_register_subsys(SKB_DROP_REASON_SUBSYS_OPENVSWITCH,\n\t\t\t\t     &drop_reason_list_ovs);\n\n\treturn 0;\n\nerror_unreg_netdev:\n\tovs_netdev_exit();\nerror_unreg_notifier:\n\tunregister_netdevice_notifier(&ovs_dp_device_notifier);\nerror_netns_exit:\n\tunregister_pernet_device(&ovs_net_ops);\nerror_vport_exit:\n\tovs_vport_exit();\nerror_flow_exit:\n\tovs_flow_exit();\nerror_unreg_rtnl_link:\n\tovs_internal_dev_rtnl_link_unregister();\nerror_action_fifos_exit:\n\taction_fifos_exit();\nerror:\n\treturn err;\n}\n\nstatic void dp_cleanup(void)\n{\n\tdp_unregister_genl(ARRAY_SIZE(dp_genl_families));\n\tovs_netdev_exit();\n\tunregister_netdevice_notifier(&ovs_dp_device_notifier);\n\tunregister_pernet_device(&ovs_net_ops);\n\tdrop_reasons_unregister_subsys(SKB_DROP_REASON_SUBSYS_OPENVSWITCH);\n\trcu_barrier();\n\tovs_vport_exit();\n\tovs_flow_exit();\n\tovs_internal_dev_rtnl_link_unregister();\n\taction_fifos_exit();\n}\n\nmodule_init(dp_init);\nmodule_exit(dp_cleanup);\n\nMODULE_DESCRIPTION(\"Open vSwitch switching datapath\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_GENL_FAMILY(OVS_DATAPATH_FAMILY);\nMODULE_ALIAS_GENL_FAMILY(OVS_VPORT_FAMILY);\nMODULE_ALIAS_GENL_FAMILY(OVS_FLOW_FAMILY);\nMODULE_ALIAS_GENL_FAMILY(OVS_PACKET_FAMILY);\nMODULE_ALIAS_GENL_FAMILY(OVS_METER_FAMILY);\nMODULE_ALIAS_GENL_FAMILY(OVS_CT_LIMIT_FAMILY);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}