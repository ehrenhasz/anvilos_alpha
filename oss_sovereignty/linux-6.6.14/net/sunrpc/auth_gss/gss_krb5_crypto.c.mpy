{
  "module_name": "gss_krb5_crypto.c",
  "hash_id": "a80118571370294f795258d034ef7ea275079beb75bd236a4af434a3ad4e4417",
  "original_prompt": "Ingested from linux-6.6.14/net/sunrpc/auth_gss/gss_krb5_crypto.c",
  "human_readable_source": " \n\n \n\n#include <crypto/algapi.h>\n#include <crypto/hash.h>\n#include <crypto/skcipher.h>\n#include <linux/err.h>\n#include <linux/types.h>\n#include <linux/mm.h>\n#include <linux/scatterlist.h>\n#include <linux/highmem.h>\n#include <linux/pagemap.h>\n#include <linux/random.h>\n#include <linux/sunrpc/gss_krb5.h>\n#include <linux/sunrpc/xdr.h>\n#include <kunit/visibility.h>\n\n#include \"gss_krb5_internal.h\"\n\n#if IS_ENABLED(CONFIG_SUNRPC_DEBUG)\n# define RPCDBG_FACILITY        RPCDBG_AUTH\n#endif\n\n \nvoid krb5_make_confounder(u8 *p, int conflen)\n{\n\tget_random_bytes(p, conflen);\n}\n\n \nu32\nkrb5_encrypt(\n\tstruct crypto_sync_skcipher *tfm,\n\tvoid * iv,\n\tvoid * in,\n\tvoid * out,\n\tint length)\n{\n\tu32 ret = -EINVAL;\n\tstruct scatterlist sg[1];\n\tu8 local_iv[GSS_KRB5_MAX_BLOCKSIZE] = {0};\n\tSYNC_SKCIPHER_REQUEST_ON_STACK(req, tfm);\n\n\tif (length % crypto_sync_skcipher_blocksize(tfm) != 0)\n\t\tgoto out;\n\n\tif (crypto_sync_skcipher_ivsize(tfm) > GSS_KRB5_MAX_BLOCKSIZE) {\n\t\tdprintk(\"RPC:       gss_k5encrypt: tfm iv size too large %d\\n\",\n\t\t\tcrypto_sync_skcipher_ivsize(tfm));\n\t\tgoto out;\n\t}\n\n\tif (iv)\n\t\tmemcpy(local_iv, iv, crypto_sync_skcipher_ivsize(tfm));\n\n\tmemcpy(out, in, length);\n\tsg_init_one(sg, out, length);\n\n\tskcipher_request_set_sync_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg, sg, length, local_iv);\n\n\tret = crypto_skcipher_encrypt(req);\n\tskcipher_request_zero(req);\nout:\n\tdprintk(\"RPC:       krb5_encrypt returns %d\\n\", ret);\n\treturn ret;\n}\n\n \nu32\nkrb5_decrypt(\n     struct crypto_sync_skcipher *tfm,\n     void * iv,\n     void * in,\n     void * out,\n     int length)\n{\n\tu32 ret = -EINVAL;\n\tstruct scatterlist sg[1];\n\tu8 local_iv[GSS_KRB5_MAX_BLOCKSIZE] = {0};\n\tSYNC_SKCIPHER_REQUEST_ON_STACK(req, tfm);\n\n\tif (length % crypto_sync_skcipher_blocksize(tfm) != 0)\n\t\tgoto out;\n\n\tif (crypto_sync_skcipher_ivsize(tfm) > GSS_KRB5_MAX_BLOCKSIZE) {\n\t\tdprintk(\"RPC:       gss_k5decrypt: tfm iv size too large %d\\n\",\n\t\t\tcrypto_sync_skcipher_ivsize(tfm));\n\t\tgoto out;\n\t}\n\tif (iv)\n\t\tmemcpy(local_iv, iv, crypto_sync_skcipher_ivsize(tfm));\n\n\tmemcpy(out, in, length);\n\tsg_init_one(sg, out, length);\n\n\tskcipher_request_set_sync_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg, sg, length, local_iv);\n\n\tret = crypto_skcipher_decrypt(req);\n\tskcipher_request_zero(req);\nout:\n\tdprintk(\"RPC:       gss_k5decrypt returns %d\\n\",ret);\n\treturn ret;\n}\n\nstatic int\nchecksummer(struct scatterlist *sg, void *data)\n{\n\tstruct ahash_request *req = data;\n\n\tahash_request_set_crypt(req, sg, NULL, sg->length);\n\n\treturn crypto_ahash_update(req);\n}\n\n \nu32\nmake_checksum(struct krb5_ctx *kctx, char *header, int hdrlen,\n\t      struct xdr_buf *body, int body_offset, u8 *cksumkey,\n\t      unsigned int usage, struct xdr_netobj *cksumout)\n{\n\tstruct crypto_ahash *tfm;\n\tstruct ahash_request *req;\n\tstruct scatterlist              sg[1];\n\tint err = -1;\n\tu8 *checksumdata;\n\tunsigned int checksumlen;\n\n\tif (cksumout->len < kctx->gk5e->cksumlength) {\n\t\tdprintk(\"%s: checksum buffer length, %u, too small for %s\\n\",\n\t\t\t__func__, cksumout->len, kctx->gk5e->name);\n\t\treturn GSS_S_FAILURE;\n\t}\n\n\tchecksumdata = kmalloc(GSS_KRB5_MAX_CKSUM_LEN, GFP_KERNEL);\n\tif (checksumdata == NULL)\n\t\treturn GSS_S_FAILURE;\n\n\ttfm = crypto_alloc_ahash(kctx->gk5e->cksum_name, 0, CRYPTO_ALG_ASYNC);\n\tif (IS_ERR(tfm))\n\t\tgoto out_free_cksum;\n\n\treq = ahash_request_alloc(tfm, GFP_KERNEL);\n\tif (!req)\n\t\tgoto out_free_ahash;\n\n\tahash_request_set_callback(req, CRYPTO_TFM_REQ_MAY_SLEEP, NULL, NULL);\n\n\tchecksumlen = crypto_ahash_digestsize(tfm);\n\n\tif (cksumkey != NULL) {\n\t\terr = crypto_ahash_setkey(tfm, cksumkey,\n\t\t\t\t\t  kctx->gk5e->keylength);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\terr = crypto_ahash_init(req);\n\tif (err)\n\t\tgoto out;\n\tsg_init_one(sg, header, hdrlen);\n\tahash_request_set_crypt(req, sg, NULL, hdrlen);\n\terr = crypto_ahash_update(req);\n\tif (err)\n\t\tgoto out;\n\terr = xdr_process_buf(body, body_offset, body->len - body_offset,\n\t\t\t      checksummer, req);\n\tif (err)\n\t\tgoto out;\n\tahash_request_set_crypt(req, NULL, checksumdata, 0);\n\terr = crypto_ahash_final(req);\n\tif (err)\n\t\tgoto out;\n\n\tswitch (kctx->gk5e->ctype) {\n\tcase CKSUMTYPE_RSA_MD5:\n\t\terr = krb5_encrypt(kctx->seq, NULL, checksumdata,\n\t\t\t\t   checksumdata, checksumlen);\n\t\tif (err)\n\t\t\tgoto out;\n\t\tmemcpy(cksumout->data,\n\t\t       checksumdata + checksumlen - kctx->gk5e->cksumlength,\n\t\t       kctx->gk5e->cksumlength);\n\t\tbreak;\n\tcase CKSUMTYPE_HMAC_SHA1_DES3:\n\t\tmemcpy(cksumout->data, checksumdata, kctx->gk5e->cksumlength);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t\tbreak;\n\t}\n\tcksumout->len = kctx->gk5e->cksumlength;\nout:\n\tahash_request_free(req);\nout_free_ahash:\n\tcrypto_free_ahash(tfm);\nout_free_cksum:\n\tkfree(checksumdata);\n\treturn err ? GSS_S_FAILURE : 0;\n}\n\n \nu32\ngss_krb5_checksum(struct crypto_ahash *tfm, char *header, int hdrlen,\n\t\t  const struct xdr_buf *body, int body_offset,\n\t\t  struct xdr_netobj *cksumout)\n{\n\tstruct ahash_request *req;\n\tint err = -ENOMEM;\n\tu8 *checksumdata;\n\n\tchecksumdata = kmalloc(crypto_ahash_digestsize(tfm), GFP_KERNEL);\n\tif (!checksumdata)\n\t\treturn GSS_S_FAILURE;\n\n\treq = ahash_request_alloc(tfm, GFP_KERNEL);\n\tif (!req)\n\t\tgoto out_free_cksum;\n\tahash_request_set_callback(req, CRYPTO_TFM_REQ_MAY_SLEEP, NULL, NULL);\n\terr = crypto_ahash_init(req);\n\tif (err)\n\t\tgoto out_free_ahash;\n\n\t \n\terr = xdr_process_buf(body, body_offset, body->len - body_offset,\n\t\t\t      checksummer, req);\n\tif (err)\n\t\tgoto out_free_ahash;\n\tif (header) {\n\t\tstruct scatterlist sg[1];\n\n\t\tsg_init_one(sg, header, hdrlen);\n\t\tahash_request_set_crypt(req, sg, NULL, hdrlen);\n\t\terr = crypto_ahash_update(req);\n\t\tif (err)\n\t\t\tgoto out_free_ahash;\n\t}\n\n\tahash_request_set_crypt(req, NULL, checksumdata, 0);\n\terr = crypto_ahash_final(req);\n\tif (err)\n\t\tgoto out_free_ahash;\n\n\tmemcpy(cksumout->data, checksumdata,\n\t       min_t(int, cksumout->len, crypto_ahash_digestsize(tfm)));\n\nout_free_ahash:\n\tahash_request_free(req);\nout_free_cksum:\n\tkfree_sensitive(checksumdata);\n\treturn err ? GSS_S_FAILURE : GSS_S_COMPLETE;\n}\nEXPORT_SYMBOL_IF_KUNIT(gss_krb5_checksum);\n\nstruct encryptor_desc {\n\tu8 iv[GSS_KRB5_MAX_BLOCKSIZE];\n\tstruct skcipher_request *req;\n\tint pos;\n\tstruct xdr_buf *outbuf;\n\tstruct page **pages;\n\tstruct scatterlist infrags[4];\n\tstruct scatterlist outfrags[4];\n\tint fragno;\n\tint fraglen;\n};\n\nstatic int\nencryptor(struct scatterlist *sg, void *data)\n{\n\tstruct encryptor_desc *desc = data;\n\tstruct xdr_buf *outbuf = desc->outbuf;\n\tstruct crypto_sync_skcipher *tfm =\n\t\tcrypto_sync_skcipher_reqtfm(desc->req);\n\tstruct page *in_page;\n\tint thislen = desc->fraglen + sg->length;\n\tint fraglen, ret;\n\tint page_pos;\n\n\t \n\tBUG_ON(desc->fragno > 3);\n\n\tpage_pos = desc->pos - outbuf->head[0].iov_len;\n\tif (page_pos >= 0 && page_pos < outbuf->page_len) {\n\t\t \n\t\tint i = (page_pos + outbuf->page_base) >> PAGE_SHIFT;\n\t\tin_page = desc->pages[i];\n\t} else {\n\t\tin_page = sg_page(sg);\n\t}\n\tsg_set_page(&desc->infrags[desc->fragno], in_page, sg->length,\n\t\t    sg->offset);\n\tsg_set_page(&desc->outfrags[desc->fragno], sg_page(sg), sg->length,\n\t\t    sg->offset);\n\tdesc->fragno++;\n\tdesc->fraglen += sg->length;\n\tdesc->pos += sg->length;\n\n\tfraglen = thislen & (crypto_sync_skcipher_blocksize(tfm) - 1);\n\tthislen -= fraglen;\n\n\tif (thislen == 0)\n\t\treturn 0;\n\n\tsg_mark_end(&desc->infrags[desc->fragno - 1]);\n\tsg_mark_end(&desc->outfrags[desc->fragno - 1]);\n\n\tskcipher_request_set_crypt(desc->req, desc->infrags, desc->outfrags,\n\t\t\t\t   thislen, desc->iv);\n\n\tret = crypto_skcipher_encrypt(desc->req);\n\tif (ret)\n\t\treturn ret;\n\n\tsg_init_table(desc->infrags, 4);\n\tsg_init_table(desc->outfrags, 4);\n\n\tif (fraglen) {\n\t\tsg_set_page(&desc->outfrags[0], sg_page(sg), fraglen,\n\t\t\t\tsg->offset + sg->length - fraglen);\n\t\tdesc->infrags[0] = desc->outfrags[0];\n\t\tsg_assign_page(&desc->infrags[0], in_page);\n\t\tdesc->fragno = 1;\n\t\tdesc->fraglen = fraglen;\n\t} else {\n\t\tdesc->fragno = 0;\n\t\tdesc->fraglen = 0;\n\t}\n\treturn 0;\n}\n\nint\ngss_encrypt_xdr_buf(struct crypto_sync_skcipher *tfm, struct xdr_buf *buf,\n\t\t    int offset, struct page **pages)\n{\n\tint ret;\n\tstruct encryptor_desc desc;\n\tSYNC_SKCIPHER_REQUEST_ON_STACK(req, tfm);\n\n\tBUG_ON((buf->len - offset) % crypto_sync_skcipher_blocksize(tfm) != 0);\n\n\tskcipher_request_set_sync_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\n\tmemset(desc.iv, 0, sizeof(desc.iv));\n\tdesc.req = req;\n\tdesc.pos = offset;\n\tdesc.outbuf = buf;\n\tdesc.pages = pages;\n\tdesc.fragno = 0;\n\tdesc.fraglen = 0;\n\n\tsg_init_table(desc.infrags, 4);\n\tsg_init_table(desc.outfrags, 4);\n\n\tret = xdr_process_buf(buf, offset, buf->len - offset, encryptor, &desc);\n\tskcipher_request_zero(req);\n\treturn ret;\n}\n\nstruct decryptor_desc {\n\tu8 iv[GSS_KRB5_MAX_BLOCKSIZE];\n\tstruct skcipher_request *req;\n\tstruct scatterlist frags[4];\n\tint fragno;\n\tint fraglen;\n};\n\nstatic int\ndecryptor(struct scatterlist *sg, void *data)\n{\n\tstruct decryptor_desc *desc = data;\n\tint thislen = desc->fraglen + sg->length;\n\tstruct crypto_sync_skcipher *tfm =\n\t\tcrypto_sync_skcipher_reqtfm(desc->req);\n\tint fraglen, ret;\n\n\t \n\tBUG_ON(desc->fragno > 3);\n\tsg_set_page(&desc->frags[desc->fragno], sg_page(sg), sg->length,\n\t\t    sg->offset);\n\tdesc->fragno++;\n\tdesc->fraglen += sg->length;\n\n\tfraglen = thislen & (crypto_sync_skcipher_blocksize(tfm) - 1);\n\tthislen -= fraglen;\n\n\tif (thislen == 0)\n\t\treturn 0;\n\n\tsg_mark_end(&desc->frags[desc->fragno - 1]);\n\n\tskcipher_request_set_crypt(desc->req, desc->frags, desc->frags,\n\t\t\t\t   thislen, desc->iv);\n\n\tret = crypto_skcipher_decrypt(desc->req);\n\tif (ret)\n\t\treturn ret;\n\n\tsg_init_table(desc->frags, 4);\n\n\tif (fraglen) {\n\t\tsg_set_page(&desc->frags[0], sg_page(sg), fraglen,\n\t\t\t\tsg->offset + sg->length - fraglen);\n\t\tdesc->fragno = 1;\n\t\tdesc->fraglen = fraglen;\n\t} else {\n\t\tdesc->fragno = 0;\n\t\tdesc->fraglen = 0;\n\t}\n\treturn 0;\n}\n\nint\ngss_decrypt_xdr_buf(struct crypto_sync_skcipher *tfm, struct xdr_buf *buf,\n\t\t    int offset)\n{\n\tint ret;\n\tstruct decryptor_desc desc;\n\tSYNC_SKCIPHER_REQUEST_ON_STACK(req, tfm);\n\n\t \n\tBUG_ON((buf->len - offset) % crypto_sync_skcipher_blocksize(tfm) != 0);\n\n\tskcipher_request_set_sync_tfm(req, tfm);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\n\tmemset(desc.iv, 0, sizeof(desc.iv));\n\tdesc.req = req;\n\tdesc.fragno = 0;\n\tdesc.fraglen = 0;\n\n\tsg_init_table(desc.frags, 4);\n\n\tret = xdr_process_buf(buf, offset, buf->len - offset, decryptor, &desc);\n\tskcipher_request_zero(req);\n\treturn ret;\n}\n\n \n\nint\nxdr_extend_head(struct xdr_buf *buf, unsigned int base, unsigned int shiftlen)\n{\n\tu8 *p;\n\n\tif (shiftlen == 0)\n\t\treturn 0;\n\n\tBUG_ON(shiftlen > RPC_MAX_AUTH_SIZE);\n\n\tp = buf->head[0].iov_base + base;\n\n\tmemmove(p + shiftlen, p, buf->head[0].iov_len - base);\n\n\tbuf->head[0].iov_len += shiftlen;\n\tbuf->len += shiftlen;\n\n\treturn 0;\n}\n\nstatic u32\ngss_krb5_cts_crypt(struct crypto_sync_skcipher *cipher, struct xdr_buf *buf,\n\t\t   u32 offset, u8 *iv, struct page **pages, int encrypt)\n{\n\tu32 ret;\n\tstruct scatterlist sg[1];\n\tSYNC_SKCIPHER_REQUEST_ON_STACK(req, cipher);\n\tu8 *data;\n\tstruct page **save_pages;\n\tu32 len = buf->len - offset;\n\n\tif (len > GSS_KRB5_MAX_BLOCKSIZE * 2) {\n\t\tWARN_ON(0);\n\t\treturn -ENOMEM;\n\t}\n\tdata = kmalloc(GSS_KRB5_MAX_BLOCKSIZE * 2, GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\t \n\tsave_pages = buf->pages;\n\tif (encrypt)\n\t\tbuf->pages = pages;\n\n\tret = read_bytes_from_xdr_buf(buf, offset, data, len);\n\tbuf->pages = save_pages;\n\tif (ret)\n\t\tgoto out;\n\n\tsg_init_one(sg, data, len);\n\n\tskcipher_request_set_sync_tfm(req, cipher);\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, sg, sg, len, iv);\n\n\tif (encrypt)\n\t\tret = crypto_skcipher_encrypt(req);\n\telse\n\t\tret = crypto_skcipher_decrypt(req);\n\n\tskcipher_request_zero(req);\n\n\tif (ret)\n\t\tgoto out;\n\n\tret = write_bytes_to_xdr_buf(buf, offset, data, len);\n\n#if IS_ENABLED(CONFIG_KUNIT)\n\t \n\tif (encrypt)\n\t\tmemcpy(iv, data, crypto_sync_skcipher_ivsize(cipher));\n#endif\n\nout:\n\tkfree(data);\n\treturn ret;\n}\n\n \nVISIBLE_IF_KUNIT\nint krb5_cbc_cts_encrypt(struct crypto_sync_skcipher *cts_tfm,\n\t\t\t struct crypto_sync_skcipher *cbc_tfm,\n\t\t\t u32 offset, struct xdr_buf *buf, struct page **pages,\n\t\t\t u8 *iv, unsigned int ivsize)\n{\n\tu32 blocksize, nbytes, nblocks, cbcbytes;\n\tstruct encryptor_desc desc;\n\tint err;\n\n\tblocksize = crypto_sync_skcipher_blocksize(cts_tfm);\n\tnbytes = buf->len - offset;\n\tnblocks = (nbytes + blocksize - 1) / blocksize;\n\tcbcbytes = 0;\n\tif (nblocks > 2)\n\t\tcbcbytes = (nblocks - 2) * blocksize;\n\n\tmemset(desc.iv, 0, sizeof(desc.iv));\n\n\t \n\tif (cbcbytes) {\n\t\tSYNC_SKCIPHER_REQUEST_ON_STACK(req, cbc_tfm);\n\n\t\tdesc.pos = offset;\n\t\tdesc.fragno = 0;\n\t\tdesc.fraglen = 0;\n\t\tdesc.pages = pages;\n\t\tdesc.outbuf = buf;\n\t\tdesc.req = req;\n\n\t\tskcipher_request_set_sync_tfm(req, cbc_tfm);\n\t\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\n\t\tsg_init_table(desc.infrags, 4);\n\t\tsg_init_table(desc.outfrags, 4);\n\n\t\terr = xdr_process_buf(buf, offset, cbcbytes, encryptor, &desc);\n\t\tskcipher_request_zero(req);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\t \n\terr = gss_krb5_cts_crypt(cts_tfm, buf, offset + cbcbytes,\n\t\t\t\t desc.iv, pages, 1);\n\tif (err)\n\t\treturn err;\n\n\tif (unlikely(iv))\n\t\tmemcpy(iv, desc.iv, ivsize);\n\treturn 0;\n}\nEXPORT_SYMBOL_IF_KUNIT(krb5_cbc_cts_encrypt);\n\n \nVISIBLE_IF_KUNIT\nint krb5_cbc_cts_decrypt(struct crypto_sync_skcipher *cts_tfm,\n\t\t\t struct crypto_sync_skcipher *cbc_tfm,\n\t\t\t u32 offset, struct xdr_buf *buf)\n{\n\tu32 blocksize, nblocks, cbcbytes;\n\tstruct decryptor_desc desc;\n\tint err;\n\n\tblocksize = crypto_sync_skcipher_blocksize(cts_tfm);\n\tnblocks = (buf->len + blocksize - 1) / blocksize;\n\tcbcbytes = 0;\n\tif (nblocks > 2)\n\t\tcbcbytes = (nblocks - 2) * blocksize;\n\n\tmemset(desc.iv, 0, sizeof(desc.iv));\n\n\t \n\tif (cbcbytes) {\n\t\tSYNC_SKCIPHER_REQUEST_ON_STACK(req, cbc_tfm);\n\n\t\tdesc.fragno = 0;\n\t\tdesc.fraglen = 0;\n\t\tdesc.req = req;\n\n\t\tskcipher_request_set_sync_tfm(req, cbc_tfm);\n\t\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\n\t\tsg_init_table(desc.frags, 4);\n\n\t\terr = xdr_process_buf(buf, 0, cbcbytes, decryptor, &desc);\n\t\tskcipher_request_zero(req);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\t \n\treturn gss_krb5_cts_crypt(cts_tfm, buf, cbcbytes, desc.iv, NULL, 0);\n}\nEXPORT_SYMBOL_IF_KUNIT(krb5_cbc_cts_decrypt);\n\nu32\ngss_krb5_aes_encrypt(struct krb5_ctx *kctx, u32 offset,\n\t\t     struct xdr_buf *buf, struct page **pages)\n{\n\tu32 err;\n\tstruct xdr_netobj hmac;\n\tu8 *ecptr;\n\tstruct crypto_sync_skcipher *cipher, *aux_cipher;\n\tstruct crypto_ahash *ahash;\n\tstruct page **save_pages;\n\tunsigned int conflen;\n\n\tif (kctx->initiate) {\n\t\tcipher = kctx->initiator_enc;\n\t\taux_cipher = kctx->initiator_enc_aux;\n\t\tahash = kctx->initiator_integ;\n\t} else {\n\t\tcipher = kctx->acceptor_enc;\n\t\taux_cipher = kctx->acceptor_enc_aux;\n\t\tahash = kctx->acceptor_integ;\n\t}\n\tconflen = crypto_sync_skcipher_blocksize(cipher);\n\n\t \n\toffset += GSS_KRB5_TOK_HDR_LEN;\n\tif (xdr_extend_head(buf, offset, conflen))\n\t\treturn GSS_S_FAILURE;\n\tkrb5_make_confounder(buf->head[0].iov_base + offset, conflen);\n\toffset -= GSS_KRB5_TOK_HDR_LEN;\n\n\tif (buf->tail[0].iov_base != NULL) {\n\t\tecptr = buf->tail[0].iov_base + buf->tail[0].iov_len;\n\t} else {\n\t\tbuf->tail[0].iov_base = buf->head[0].iov_base\n\t\t\t\t\t\t\t+ buf->head[0].iov_len;\n\t\tbuf->tail[0].iov_len = 0;\n\t\tecptr = buf->tail[0].iov_base;\n\t}\n\n\t \n\tmemcpy(ecptr, buf->head[0].iov_base + offset, GSS_KRB5_TOK_HDR_LEN);\n\tbuf->tail[0].iov_len += GSS_KRB5_TOK_HDR_LEN;\n\tbuf->len += GSS_KRB5_TOK_HDR_LEN;\n\n\thmac.len = kctx->gk5e->cksumlength;\n\thmac.data = buf->tail[0].iov_base + buf->tail[0].iov_len;\n\n\t \n\tsave_pages = buf->pages;\n\tbuf->pages = pages;\n\n\terr = gss_krb5_checksum(ahash, NULL, 0, buf,\n\t\t\t\toffset + GSS_KRB5_TOK_HDR_LEN, &hmac);\n\tbuf->pages = save_pages;\n\tif (err)\n\t\treturn GSS_S_FAILURE;\n\n\terr = krb5_cbc_cts_encrypt(cipher, aux_cipher,\n\t\t\t\t   offset + GSS_KRB5_TOK_HDR_LEN,\n\t\t\t\t   buf, pages, NULL, 0);\n\tif (err)\n\t\treturn GSS_S_FAILURE;\n\n\t \n\tbuf->tail[0].iov_len += kctx->gk5e->cksumlength;\n\tbuf->len += kctx->gk5e->cksumlength;\n\n\treturn GSS_S_COMPLETE;\n}\n\nu32\ngss_krb5_aes_decrypt(struct krb5_ctx *kctx, u32 offset, u32 len,\n\t\t     struct xdr_buf *buf, u32 *headskip, u32 *tailskip)\n{\n\tstruct crypto_sync_skcipher *cipher, *aux_cipher;\n\tstruct crypto_ahash *ahash;\n\tstruct xdr_netobj our_hmac_obj;\n\tu8 our_hmac[GSS_KRB5_MAX_CKSUM_LEN];\n\tu8 pkt_hmac[GSS_KRB5_MAX_CKSUM_LEN];\n\tstruct xdr_buf subbuf;\n\tu32 ret = 0;\n\n\tif (kctx->initiate) {\n\t\tcipher = kctx->acceptor_enc;\n\t\taux_cipher = kctx->acceptor_enc_aux;\n\t\tahash = kctx->acceptor_integ;\n\t} else {\n\t\tcipher = kctx->initiator_enc;\n\t\taux_cipher = kctx->initiator_enc_aux;\n\t\tahash = kctx->initiator_integ;\n\t}\n\n\t \n\txdr_buf_subsegment(buf, &subbuf, offset + GSS_KRB5_TOK_HDR_LEN,\n\t\t\t\t    (len - offset - GSS_KRB5_TOK_HDR_LEN -\n\t\t\t\t     kctx->gk5e->cksumlength));\n\n\tret = krb5_cbc_cts_decrypt(cipher, aux_cipher, 0, &subbuf);\n\tif (ret)\n\t\tgoto out_err;\n\n\tour_hmac_obj.len = kctx->gk5e->cksumlength;\n\tour_hmac_obj.data = our_hmac;\n\tret = gss_krb5_checksum(ahash, NULL, 0, &subbuf, 0, &our_hmac_obj);\n\tif (ret)\n\t\tgoto out_err;\n\n\t \n\tret = read_bytes_from_xdr_buf(buf, len - kctx->gk5e->cksumlength,\n\t\t\t\t      pkt_hmac, kctx->gk5e->cksumlength);\n\tif (ret)\n\t\tgoto out_err;\n\n\tif (crypto_memneq(pkt_hmac, our_hmac, kctx->gk5e->cksumlength) != 0) {\n\t\tret = GSS_S_BAD_SIG;\n\t\tgoto out_err;\n\t}\n\t*headskip = crypto_sync_skcipher_blocksize(cipher);\n\t*tailskip = kctx->gk5e->cksumlength;\nout_err:\n\tif (ret && ret != GSS_S_BAD_SIG)\n\t\tret = GSS_S_FAILURE;\n\treturn ret;\n}\n\n \nVISIBLE_IF_KUNIT\nu32 krb5_etm_checksum(struct crypto_sync_skcipher *cipher,\n\t\t      struct crypto_ahash *tfm, const struct xdr_buf *body,\n\t\t      int body_offset, struct xdr_netobj *cksumout)\n{\n\tunsigned int ivsize = crypto_sync_skcipher_ivsize(cipher);\n\tstruct ahash_request *req;\n\tstruct scatterlist sg[1];\n\tu8 *iv, *checksumdata;\n\tint err = -ENOMEM;\n\n\tchecksumdata = kmalloc(crypto_ahash_digestsize(tfm), GFP_KERNEL);\n\tif (!checksumdata)\n\t\treturn GSS_S_FAILURE;\n\t \n\tiv = kzalloc(ivsize, GFP_KERNEL);\n\tif (!iv)\n\t\tgoto out_free_mem;\n\n\treq = ahash_request_alloc(tfm, GFP_KERNEL);\n\tif (!req)\n\t\tgoto out_free_mem;\n\tahash_request_set_callback(req, CRYPTO_TFM_REQ_MAY_SLEEP, NULL, NULL);\n\terr = crypto_ahash_init(req);\n\tif (err)\n\t\tgoto out_free_ahash;\n\n\tsg_init_one(sg, iv, ivsize);\n\tahash_request_set_crypt(req, sg, NULL, ivsize);\n\terr = crypto_ahash_update(req);\n\tif (err)\n\t\tgoto out_free_ahash;\n\terr = xdr_process_buf(body, body_offset, body->len - body_offset,\n\t\t\t      checksummer, req);\n\tif (err)\n\t\tgoto out_free_ahash;\n\n\tahash_request_set_crypt(req, NULL, checksumdata, 0);\n\terr = crypto_ahash_final(req);\n\tif (err)\n\t\tgoto out_free_ahash;\n\tmemcpy(cksumout->data, checksumdata, cksumout->len);\n\nout_free_ahash:\n\tahash_request_free(req);\nout_free_mem:\n\tkfree(iv);\n\tkfree_sensitive(checksumdata);\n\treturn err ? GSS_S_FAILURE : GSS_S_COMPLETE;\n}\nEXPORT_SYMBOL_IF_KUNIT(krb5_etm_checksum);\n\n \nu32\nkrb5_etm_encrypt(struct krb5_ctx *kctx, u32 offset,\n\t\t struct xdr_buf *buf, struct page **pages)\n{\n\tstruct crypto_sync_skcipher *cipher, *aux_cipher;\n\tstruct crypto_ahash *ahash;\n\tstruct xdr_netobj hmac;\n\tunsigned int conflen;\n\tu8 *ecptr;\n\tu32 err;\n\n\tif (kctx->initiate) {\n\t\tcipher = kctx->initiator_enc;\n\t\taux_cipher = kctx->initiator_enc_aux;\n\t\tahash = kctx->initiator_integ;\n\t} else {\n\t\tcipher = kctx->acceptor_enc;\n\t\taux_cipher = kctx->acceptor_enc_aux;\n\t\tahash = kctx->acceptor_integ;\n\t}\n\tconflen = crypto_sync_skcipher_blocksize(cipher);\n\n\toffset += GSS_KRB5_TOK_HDR_LEN;\n\tif (xdr_extend_head(buf, offset, conflen))\n\t\treturn GSS_S_FAILURE;\n\tkrb5_make_confounder(buf->head[0].iov_base + offset, conflen);\n\toffset -= GSS_KRB5_TOK_HDR_LEN;\n\n\tif (buf->tail[0].iov_base) {\n\t\tecptr = buf->tail[0].iov_base + buf->tail[0].iov_len;\n\t} else {\n\t\tbuf->tail[0].iov_base = buf->head[0].iov_base\n\t\t\t\t\t\t\t+ buf->head[0].iov_len;\n\t\tbuf->tail[0].iov_len = 0;\n\t\tecptr = buf->tail[0].iov_base;\n\t}\n\n\tmemcpy(ecptr, buf->head[0].iov_base + offset, GSS_KRB5_TOK_HDR_LEN);\n\tbuf->tail[0].iov_len += GSS_KRB5_TOK_HDR_LEN;\n\tbuf->len += GSS_KRB5_TOK_HDR_LEN;\n\n\terr = krb5_cbc_cts_encrypt(cipher, aux_cipher,\n\t\t\t\t   offset + GSS_KRB5_TOK_HDR_LEN,\n\t\t\t\t   buf, pages, NULL, 0);\n\tif (err)\n\t\treturn GSS_S_FAILURE;\n\n\thmac.data = buf->tail[0].iov_base + buf->tail[0].iov_len;\n\thmac.len = kctx->gk5e->cksumlength;\n\terr = krb5_etm_checksum(cipher, ahash,\n\t\t\t\tbuf, offset + GSS_KRB5_TOK_HDR_LEN, &hmac);\n\tif (err)\n\t\tgoto out_err;\n\tbuf->tail[0].iov_len += kctx->gk5e->cksumlength;\n\tbuf->len += kctx->gk5e->cksumlength;\n\n\treturn GSS_S_COMPLETE;\n\nout_err:\n\treturn GSS_S_FAILURE;\n}\n\n \nu32\nkrb5_etm_decrypt(struct krb5_ctx *kctx, u32 offset, u32 len,\n\t\t struct xdr_buf *buf, u32 *headskip, u32 *tailskip)\n{\n\tstruct crypto_sync_skcipher *cipher, *aux_cipher;\n\tu8 our_hmac[GSS_KRB5_MAX_CKSUM_LEN];\n\tu8 pkt_hmac[GSS_KRB5_MAX_CKSUM_LEN];\n\tstruct xdr_netobj our_hmac_obj;\n\tstruct crypto_ahash *ahash;\n\tstruct xdr_buf subbuf;\n\tu32 ret = 0;\n\n\tif (kctx->initiate) {\n\t\tcipher = kctx->acceptor_enc;\n\t\taux_cipher = kctx->acceptor_enc_aux;\n\t\tahash = kctx->acceptor_integ;\n\t} else {\n\t\tcipher = kctx->initiator_enc;\n\t\taux_cipher = kctx->initiator_enc_aux;\n\t\tahash = kctx->initiator_integ;\n\t}\n\n\t \n\txdr_buf_subsegment(buf, &subbuf, offset + GSS_KRB5_TOK_HDR_LEN,\n\t\t\t   (len - offset - GSS_KRB5_TOK_HDR_LEN -\n\t\t\t    kctx->gk5e->cksumlength));\n\n\tour_hmac_obj.data = our_hmac;\n\tour_hmac_obj.len = kctx->gk5e->cksumlength;\n\tret = krb5_etm_checksum(cipher, ahash, &subbuf, 0, &our_hmac_obj);\n\tif (ret)\n\t\tgoto out_err;\n\tret = read_bytes_from_xdr_buf(buf, len - kctx->gk5e->cksumlength,\n\t\t\t\t      pkt_hmac, kctx->gk5e->cksumlength);\n\tif (ret)\n\t\tgoto out_err;\n\tif (crypto_memneq(pkt_hmac, our_hmac, kctx->gk5e->cksumlength) != 0) {\n\t\tret = GSS_S_BAD_SIG;\n\t\tgoto out_err;\n\t}\n\n\tret = krb5_cbc_cts_decrypt(cipher, aux_cipher, 0, &subbuf);\n\tif (ret) {\n\t\tret = GSS_S_FAILURE;\n\t\tgoto out_err;\n\t}\n\n\t*headskip = crypto_sync_skcipher_blocksize(cipher);\n\t*tailskip = kctx->gk5e->cksumlength;\n\treturn GSS_S_COMPLETE;\n\nout_err:\n\tif (ret != GSS_S_BAD_SIG)\n\t\tret = GSS_S_FAILURE;\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}