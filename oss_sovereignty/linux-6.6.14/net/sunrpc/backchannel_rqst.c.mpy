{
  "module_name": "backchannel_rqst.c",
  "hash_id": "4402cdbfa8f88cff607a11795dc15ef449f523272ffa30fddedd2f82b1129506",
  "original_prompt": "Ingested from linux-6.6.14/net/sunrpc/backchannel_rqst.c",
  "human_readable_source": "\n \n\n#include <linux/tcp.h>\n#include <linux/slab.h>\n#include <linux/sunrpc/xprt.h>\n#include <linux/export.h>\n#include <linux/sunrpc/bc_xprt.h>\n\n#if IS_ENABLED(CONFIG_SUNRPC_DEBUG)\n#define RPCDBG_FACILITY\tRPCDBG_TRANS\n#endif\n\n#define BC_MAX_SLOTS\t64U\n\nunsigned int xprt_bc_max_slots(struct rpc_xprt *xprt)\n{\n\treturn BC_MAX_SLOTS;\n}\n\n \nstatic inline int xprt_need_to_requeue(struct rpc_xprt *xprt)\n{\n\treturn xprt->bc_alloc_count < xprt->bc_alloc_max;\n}\n\n \nstatic void xprt_free_allocation(struct rpc_rqst *req)\n{\n\tstruct xdr_buf *xbufp;\n\n\tdprintk(\"RPC:        free allocations for req= %p\\n\", req);\n\tWARN_ON_ONCE(test_bit(RPC_BC_PA_IN_USE, &req->rq_bc_pa_state));\n\txbufp = &req->rq_rcv_buf;\n\tfree_page((unsigned long)xbufp->head[0].iov_base);\n\txbufp = &req->rq_snd_buf;\n\tfree_page((unsigned long)xbufp->head[0].iov_base);\n\tkfree(req);\n}\n\nstatic void xprt_bc_reinit_xdr_buf(struct xdr_buf *buf)\n{\n\tbuf->head[0].iov_len = PAGE_SIZE;\n\tbuf->tail[0].iov_len = 0;\n\tbuf->pages = NULL;\n\tbuf->page_len = 0;\n\tbuf->flags = 0;\n\tbuf->len = 0;\n\tbuf->buflen = PAGE_SIZE;\n}\n\nstatic int xprt_alloc_xdr_buf(struct xdr_buf *buf, gfp_t gfp_flags)\n{\n\tstruct page *page;\n\t \n\tpage = alloc_page(gfp_flags);\n\tif (page == NULL)\n\t\treturn -ENOMEM;\n\txdr_buf_init(buf, page_address(page), PAGE_SIZE);\n\treturn 0;\n}\n\nstatic struct rpc_rqst *xprt_alloc_bc_req(struct rpc_xprt *xprt)\n{\n\tgfp_t gfp_flags = GFP_KERNEL | __GFP_NORETRY | __GFP_NOWARN;\n\tstruct rpc_rqst *req;\n\n\t \n\treq = kzalloc(sizeof(*req), gfp_flags);\n\tif (req == NULL)\n\t\treturn NULL;\n\n\treq->rq_xprt = xprt;\n\tINIT_LIST_HEAD(&req->rq_bc_list);\n\n\t \n\tif (xprt_alloc_xdr_buf(&req->rq_rcv_buf, gfp_flags) < 0) {\n\t\tprintk(KERN_ERR \"Failed to create bc receive xbuf\\n\");\n\t\tgoto out_free;\n\t}\n\treq->rq_rcv_buf.len = PAGE_SIZE;\n\n\t \n\tif (xprt_alloc_xdr_buf(&req->rq_snd_buf, gfp_flags) < 0) {\n\t\tprintk(KERN_ERR \"Failed to create bc snd xbuf\\n\");\n\t\tgoto out_free;\n\t}\n\treturn req;\nout_free:\n\txprt_free_allocation(req);\n\treturn NULL;\n}\n\n \nint xprt_setup_backchannel(struct rpc_xprt *xprt, unsigned int min_reqs)\n{\n\tif (!xprt->ops->bc_setup)\n\t\treturn 0;\n\treturn xprt->ops->bc_setup(xprt, min_reqs);\n}\nEXPORT_SYMBOL_GPL(xprt_setup_backchannel);\n\nint xprt_setup_bc(struct rpc_xprt *xprt, unsigned int min_reqs)\n{\n\tstruct rpc_rqst *req;\n\tstruct list_head tmp_list;\n\tint i;\n\n\tdprintk(\"RPC:       setup backchannel transport\\n\");\n\n\tif (min_reqs > BC_MAX_SLOTS)\n\t\tmin_reqs = BC_MAX_SLOTS;\n\n\t \n\tINIT_LIST_HEAD(&tmp_list);\n\tfor (i = 0; i < min_reqs; i++) {\n\t\t \n\t\treq = xprt_alloc_bc_req(xprt);\n\t\tif (req == NULL) {\n\t\t\tprintk(KERN_ERR \"Failed to create bc rpc_rqst\\n\");\n\t\t\tgoto out_free;\n\t\t}\n\n\t\t \n\t\tdprintk(\"RPC:       adding req= %p\\n\", req);\n\t\tlist_add(&req->rq_bc_pa_list, &tmp_list);\n\t}\n\n\t \n\tspin_lock(&xprt->bc_pa_lock);\n\tlist_splice(&tmp_list, &xprt->bc_pa_list);\n\txprt->bc_alloc_count += min_reqs;\n\txprt->bc_alloc_max += min_reqs;\n\tatomic_add(min_reqs, &xprt->bc_slot_count);\n\tspin_unlock(&xprt->bc_pa_lock);\n\n\tdprintk(\"RPC:       setup backchannel transport done\\n\");\n\treturn 0;\n\nout_free:\n\t \n\twhile (!list_empty(&tmp_list)) {\n\t\treq = list_first_entry(&tmp_list,\n\t\t\t\tstruct rpc_rqst,\n\t\t\t\trq_bc_pa_list);\n\t\tlist_del(&req->rq_bc_pa_list);\n\t\txprt_free_allocation(req);\n\t}\n\n\tdprintk(\"RPC:       setup backchannel transport failed\\n\");\n\treturn -ENOMEM;\n}\n\n \nvoid xprt_destroy_backchannel(struct rpc_xprt *xprt, unsigned int max_reqs)\n{\n\tif (xprt->ops->bc_destroy)\n\t\txprt->ops->bc_destroy(xprt, max_reqs);\n}\nEXPORT_SYMBOL_GPL(xprt_destroy_backchannel);\n\nvoid xprt_destroy_bc(struct rpc_xprt *xprt, unsigned int max_reqs)\n{\n\tstruct rpc_rqst *req = NULL, *tmp = NULL;\n\n\tdprintk(\"RPC:        destroy backchannel transport\\n\");\n\n\tif (max_reqs == 0)\n\t\tgoto out;\n\n\tspin_lock_bh(&xprt->bc_pa_lock);\n\txprt->bc_alloc_max -= min(max_reqs, xprt->bc_alloc_max);\n\tlist_for_each_entry_safe(req, tmp, &xprt->bc_pa_list, rq_bc_pa_list) {\n\t\tdprintk(\"RPC:        req=%p\\n\", req);\n\t\tlist_del(&req->rq_bc_pa_list);\n\t\txprt_free_allocation(req);\n\t\txprt->bc_alloc_count--;\n\t\tatomic_dec(&xprt->bc_slot_count);\n\t\tif (--max_reqs == 0)\n\t\t\tbreak;\n\t}\n\tspin_unlock_bh(&xprt->bc_pa_lock);\n\nout:\n\tdprintk(\"RPC:        backchannel list empty= %s\\n\",\n\t\tlist_empty(&xprt->bc_pa_list) ? \"true\" : \"false\");\n}\n\nstatic struct rpc_rqst *xprt_get_bc_request(struct rpc_xprt *xprt, __be32 xid,\n\t\tstruct rpc_rqst *new)\n{\n\tstruct rpc_rqst *req = NULL;\n\n\tdprintk(\"RPC:       allocate a backchannel request\\n\");\n\tif (list_empty(&xprt->bc_pa_list)) {\n\t\tif (!new)\n\t\t\tgoto not_found;\n\t\tif (atomic_read(&xprt->bc_slot_count) >= BC_MAX_SLOTS)\n\t\t\tgoto not_found;\n\t\tlist_add_tail(&new->rq_bc_pa_list, &xprt->bc_pa_list);\n\t\txprt->bc_alloc_count++;\n\t\tatomic_inc(&xprt->bc_slot_count);\n\t}\n\treq = list_first_entry(&xprt->bc_pa_list, struct rpc_rqst,\n\t\t\t\trq_bc_pa_list);\n\treq->rq_reply_bytes_recvd = 0;\n\tmemcpy(&req->rq_private_buf, &req->rq_rcv_buf,\n\t\t\tsizeof(req->rq_private_buf));\n\treq->rq_xid = xid;\n\treq->rq_connect_cookie = xprt->connect_cookie;\n\tdprintk(\"RPC:       backchannel req=%p\\n\", req);\nnot_found:\n\treturn req;\n}\n\n \nvoid xprt_free_bc_request(struct rpc_rqst *req)\n{\n\tstruct rpc_xprt *xprt = req->rq_xprt;\n\n\txprt->ops->bc_free_rqst(req);\n}\n\nvoid xprt_free_bc_rqst(struct rpc_rqst *req)\n{\n\tstruct rpc_xprt *xprt = req->rq_xprt;\n\n\tdprintk(\"RPC:       free backchannel req=%p\\n\", req);\n\n\treq->rq_connect_cookie = xprt->connect_cookie - 1;\n\tsmp_mb__before_atomic();\n\tclear_bit(RPC_BC_PA_IN_USE, &req->rq_bc_pa_state);\n\tsmp_mb__after_atomic();\n\n\t \n\tspin_lock_bh(&xprt->bc_pa_lock);\n\tif (xprt_need_to_requeue(xprt)) {\n\t\txprt_bc_reinit_xdr_buf(&req->rq_snd_buf);\n\t\txprt_bc_reinit_xdr_buf(&req->rq_rcv_buf);\n\t\treq->rq_rcv_buf.len = PAGE_SIZE;\n\t\tlist_add_tail(&req->rq_bc_pa_list, &xprt->bc_pa_list);\n\t\txprt->bc_alloc_count++;\n\t\tatomic_inc(&xprt->bc_slot_count);\n\t\treq = NULL;\n\t}\n\tspin_unlock_bh(&xprt->bc_pa_lock);\n\tif (req != NULL) {\n\t\t \n\t\tdprintk(\"RPC:       Last session removed req=%p\\n\", req);\n\t\txprt_free_allocation(req);\n\t}\n\txprt_put(xprt);\n}\n\n \nstruct rpc_rqst *xprt_lookup_bc_request(struct rpc_xprt *xprt, __be32 xid)\n{\n\tstruct rpc_rqst *req, *new = NULL;\n\n\tdo {\n\t\tspin_lock(&xprt->bc_pa_lock);\n\t\tlist_for_each_entry(req, &xprt->bc_pa_list, rq_bc_pa_list) {\n\t\t\tif (req->rq_connect_cookie != xprt->connect_cookie)\n\t\t\t\tcontinue;\n\t\t\tif (req->rq_xid == xid)\n\t\t\t\tgoto found;\n\t\t}\n\t\treq = xprt_get_bc_request(xprt, xid, new);\nfound:\n\t\tspin_unlock(&xprt->bc_pa_lock);\n\t\tif (new) {\n\t\t\tif (req != new)\n\t\t\t\txprt_free_allocation(new);\n\t\t\tbreak;\n\t\t} else if (req)\n\t\t\tbreak;\n\t\tnew = xprt_alloc_bc_req(xprt);\n\t} while (new);\n\treturn req;\n}\n\n \nvoid xprt_complete_bc_request(struct rpc_rqst *req, uint32_t copied)\n{\n\tstruct rpc_xprt *xprt = req->rq_xprt;\n\tstruct svc_serv *bc_serv = xprt->bc_serv;\n\n\tspin_lock(&xprt->bc_pa_lock);\n\tlist_del(&req->rq_bc_pa_list);\n\txprt->bc_alloc_count--;\n\tspin_unlock(&xprt->bc_pa_lock);\n\n\treq->rq_private_buf.len = copied;\n\tset_bit(RPC_BC_PA_IN_USE, &req->rq_bc_pa_state);\n\n\tdprintk(\"RPC:       add callback request to list\\n\");\n\txprt_get(xprt);\n\tspin_lock(&bc_serv->sv_cb_lock);\n\tlist_add(&req->rq_bc_list, &bc_serv->sv_cb_list);\n\twake_up(&bc_serv->sv_cb_waitq);\n\tspin_unlock(&bc_serv->sv_cb_lock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}