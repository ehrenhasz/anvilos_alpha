{
  "module_name": "kcmsock.c",
  "hash_id": "d19aec41a002205d1b96b381c2f267ed34aec52b174d8f28466cca383410b5d3",
  "original_prompt": "Ingested from linux-6.6.14/net/kcm/kcmsock.c",
  "human_readable_source": "\n \n\n#include <linux/bpf.h>\n#include <linux/errno.h>\n#include <linux/errqueue.h>\n#include <linux/file.h>\n#include <linux/filter.h>\n#include <linux/in.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/net.h>\n#include <linux/netdevice.h>\n#include <linux/poll.h>\n#include <linux/rculist.h>\n#include <linux/skbuff.h>\n#include <linux/socket.h>\n#include <linux/uaccess.h>\n#include <linux/workqueue.h>\n#include <linux/syscalls.h>\n#include <linux/sched/signal.h>\n\n#include <net/kcm.h>\n#include <net/netns/generic.h>\n#include <net/sock.h>\n#include <uapi/linux/kcm.h>\n#include <trace/events/sock.h>\n\nunsigned int kcm_net_id;\n\nstatic struct kmem_cache *kcm_psockp __read_mostly;\nstatic struct kmem_cache *kcm_muxp __read_mostly;\nstatic struct workqueue_struct *kcm_wq;\n\nstatic inline struct kcm_sock *kcm_sk(const struct sock *sk)\n{\n\treturn (struct kcm_sock *)sk;\n}\n\nstatic inline struct kcm_tx_msg *kcm_tx_msg(struct sk_buff *skb)\n{\n\treturn (struct kcm_tx_msg *)skb->cb;\n}\n\nstatic void report_csk_error(struct sock *csk, int err)\n{\n\tcsk->sk_err = EPIPE;\n\tsk_error_report(csk);\n}\n\nstatic void kcm_abort_tx_psock(struct kcm_psock *psock, int err,\n\t\t\t       bool wakeup_kcm)\n{\n\tstruct sock *csk = psock->sk;\n\tstruct kcm_mux *mux = psock->mux;\n\n\t \n\n\tspin_lock_bh(&mux->lock);\n\n\tif (psock->tx_stopped) {\n\t\tspin_unlock_bh(&mux->lock);\n\t\treturn;\n\t}\n\n\tpsock->tx_stopped = 1;\n\tKCM_STATS_INCR(psock->stats.tx_aborts);\n\n\tif (!psock->tx_kcm) {\n\t\t \n\t\tlist_del(&psock->psock_avail_list);\n\t} else if (wakeup_kcm) {\n\t\t \n\t\tsmp_mb();\n\n\t\tqueue_work(kcm_wq, &psock->tx_kcm->tx_work);\n\t}\n\n\tspin_unlock_bh(&mux->lock);\n\n\t \n\treport_csk_error(csk, err);\n}\n\n \nstatic void kcm_update_rx_mux_stats(struct kcm_mux *mux,\n\t\t\t\t    struct kcm_psock *psock)\n{\n\tSTRP_STATS_ADD(mux->stats.rx_bytes,\n\t\t       psock->strp.stats.bytes -\n\t\t       psock->saved_rx_bytes);\n\tmux->stats.rx_msgs +=\n\t\tpsock->strp.stats.msgs - psock->saved_rx_msgs;\n\tpsock->saved_rx_msgs = psock->strp.stats.msgs;\n\tpsock->saved_rx_bytes = psock->strp.stats.bytes;\n}\n\nstatic void kcm_update_tx_mux_stats(struct kcm_mux *mux,\n\t\t\t\t    struct kcm_psock *psock)\n{\n\tKCM_STATS_ADD(mux->stats.tx_bytes,\n\t\t      psock->stats.tx_bytes - psock->saved_tx_bytes);\n\tmux->stats.tx_msgs +=\n\t\tpsock->stats.tx_msgs - psock->saved_tx_msgs;\n\tpsock->saved_tx_msgs = psock->stats.tx_msgs;\n\tpsock->saved_tx_bytes = psock->stats.tx_bytes;\n}\n\nstatic int kcm_queue_rcv_skb(struct sock *sk, struct sk_buff *skb);\n\n \nstatic void kcm_rcv_ready(struct kcm_sock *kcm)\n{\n\tstruct kcm_mux *mux = kcm->mux;\n\tstruct kcm_psock *psock;\n\tstruct sk_buff *skb;\n\n\tif (unlikely(kcm->rx_wait || kcm->rx_psock || kcm->rx_disabled))\n\t\treturn;\n\n\twhile (unlikely((skb = __skb_dequeue(&mux->rx_hold_queue)))) {\n\t\tif (kcm_queue_rcv_skb(&kcm->sk, skb)) {\n\t\t\t \n\t\t\tskb_queue_head(&mux->rx_hold_queue, skb);\n\t\t\tWARN_ON(!sk_rmem_alloc_get(&kcm->sk));\n\t\t\treturn;\n\t\t}\n\t}\n\n\twhile (!list_empty(&mux->psocks_ready)) {\n\t\tpsock = list_first_entry(&mux->psocks_ready, struct kcm_psock,\n\t\t\t\t\t psock_ready_list);\n\n\t\tif (kcm_queue_rcv_skb(&kcm->sk, psock->ready_rx_msg)) {\n\t\t\t \n\t\t\tWARN_ON(!sk_rmem_alloc_get(&kcm->sk));\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tlist_del(&psock->psock_ready_list);\n\t\tpsock->ready_rx_msg = NULL;\n\t\t \n\t\tsmp_mb();\n\n\t\tstrp_unpause(&psock->strp);\n\t\tstrp_check_rcv(&psock->strp);\n\t}\n\n\t \n\tlist_add_tail(&kcm->wait_rx_list,\n\t\t      &kcm->mux->kcm_rx_waiters);\n\t \n\tWRITE_ONCE(kcm->rx_wait, true);\n}\n\nstatic void kcm_rfree(struct sk_buff *skb)\n{\n\tstruct sock *sk = skb->sk;\n\tstruct kcm_sock *kcm = kcm_sk(sk);\n\tstruct kcm_mux *mux = kcm->mux;\n\tunsigned int len = skb->truesize;\n\n\tsk_mem_uncharge(sk, len);\n\tatomic_sub(len, &sk->sk_rmem_alloc);\n\n\t \n\tsmp_mb__after_atomic();\n\n\tif (!READ_ONCE(kcm->rx_wait) && !READ_ONCE(kcm->rx_psock) &&\n\t    sk_rmem_alloc_get(sk) < sk->sk_rcvlowat) {\n\t\tspin_lock_bh(&mux->rx_lock);\n\t\tkcm_rcv_ready(kcm);\n\t\tspin_unlock_bh(&mux->rx_lock);\n\t}\n}\n\nstatic int kcm_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct sk_buff_head *list = &sk->sk_receive_queue;\n\n\tif (atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf)\n\t\treturn -ENOMEM;\n\n\tif (!sk_rmem_schedule(sk, skb, skb->truesize))\n\t\treturn -ENOBUFS;\n\n\tskb->dev = NULL;\n\n\tskb_orphan(skb);\n\tskb->sk = sk;\n\tskb->destructor = kcm_rfree;\n\tatomic_add(skb->truesize, &sk->sk_rmem_alloc);\n\tsk_mem_charge(sk, skb->truesize);\n\n\tskb_queue_tail(list, skb);\n\n\tif (!sock_flag(sk, SOCK_DEAD))\n\t\tsk->sk_data_ready(sk);\n\n\treturn 0;\n}\n\n \nstatic void requeue_rx_msgs(struct kcm_mux *mux, struct sk_buff_head *head)\n{\n\tstruct sk_buff *skb;\n\tstruct kcm_sock *kcm;\n\n\twhile ((skb = skb_dequeue(head))) {\n\t\t \n\t\tskb->destructor = sock_rfree;\n\t\tskb_orphan(skb);\ntry_again:\n\t\tif (list_empty(&mux->kcm_rx_waiters)) {\n\t\t\tskb_queue_tail(&mux->rx_hold_queue, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tkcm = list_first_entry(&mux->kcm_rx_waiters,\n\t\t\t\t       struct kcm_sock, wait_rx_list);\n\n\t\tif (kcm_queue_rcv_skb(&kcm->sk, skb)) {\n\t\t\t \n\t\t\tlist_del(&kcm->wait_rx_list);\n\t\t\t \n\t\t\tWRITE_ONCE(kcm->rx_wait, false);\n\n\t\t\t \n\t\t\tsmp_wmb();\n\n\t\t\tgoto try_again;\n\t\t}\n\t}\n}\n\n \nstatic struct kcm_sock *reserve_rx_kcm(struct kcm_psock *psock,\n\t\t\t\t       struct sk_buff *head)\n{\n\tstruct kcm_mux *mux = psock->mux;\n\tstruct kcm_sock *kcm;\n\n\tWARN_ON(psock->ready_rx_msg);\n\n\tif (psock->rx_kcm)\n\t\treturn psock->rx_kcm;\n\n\tspin_lock_bh(&mux->rx_lock);\n\n\tif (psock->rx_kcm) {\n\t\tspin_unlock_bh(&mux->rx_lock);\n\t\treturn psock->rx_kcm;\n\t}\n\n\tkcm_update_rx_mux_stats(mux, psock);\n\n\tif (list_empty(&mux->kcm_rx_waiters)) {\n\t\tpsock->ready_rx_msg = head;\n\t\tstrp_pause(&psock->strp);\n\t\tlist_add_tail(&psock->psock_ready_list,\n\t\t\t      &mux->psocks_ready);\n\t\tspin_unlock_bh(&mux->rx_lock);\n\t\treturn NULL;\n\t}\n\n\tkcm = list_first_entry(&mux->kcm_rx_waiters,\n\t\t\t       struct kcm_sock, wait_rx_list);\n\tlist_del(&kcm->wait_rx_list);\n\t \n\tWRITE_ONCE(kcm->rx_wait, false);\n\n\tpsock->rx_kcm = kcm;\n\t \n\tWRITE_ONCE(kcm->rx_psock, psock);\n\n\tspin_unlock_bh(&mux->rx_lock);\n\n\treturn kcm;\n}\n\nstatic void kcm_done(struct kcm_sock *kcm);\n\nstatic void kcm_done_work(struct work_struct *w)\n{\n\tkcm_done(container_of(w, struct kcm_sock, done_work));\n}\n\n \nstatic void unreserve_rx_kcm(struct kcm_psock *psock,\n\t\t\t     bool rcv_ready)\n{\n\tstruct kcm_sock *kcm = psock->rx_kcm;\n\tstruct kcm_mux *mux = psock->mux;\n\n\tif (!kcm)\n\t\treturn;\n\n\tspin_lock_bh(&mux->rx_lock);\n\n\tpsock->rx_kcm = NULL;\n\t \n\tWRITE_ONCE(kcm->rx_psock, NULL);\n\n\t \n\tsmp_mb();\n\n\tif (unlikely(kcm->done)) {\n\t\tspin_unlock_bh(&mux->rx_lock);\n\n\t\t \n\t\tINIT_WORK(&kcm->done_work, kcm_done_work);\n\t\tschedule_work(&kcm->done_work);\n\t\treturn;\n\t}\n\n\tif (unlikely(kcm->rx_disabled)) {\n\t\trequeue_rx_msgs(mux, &kcm->sk.sk_receive_queue);\n\t} else if (rcv_ready || unlikely(!sk_rmem_alloc_get(&kcm->sk))) {\n\t\t \n\t\tkcm_rcv_ready(kcm);\n\t}\n\tspin_unlock_bh(&mux->rx_lock);\n}\n\n \nstatic void psock_data_ready(struct sock *sk)\n{\n\tstruct kcm_psock *psock;\n\n\ttrace_sk_data_ready(sk);\n\n\tread_lock_bh(&sk->sk_callback_lock);\n\n\tpsock = (struct kcm_psock *)sk->sk_user_data;\n\tif (likely(psock))\n\t\tstrp_data_ready(&psock->strp);\n\n\tread_unlock_bh(&sk->sk_callback_lock);\n}\n\n \nstatic void kcm_rcv_strparser(struct strparser *strp, struct sk_buff *skb)\n{\n\tstruct kcm_psock *psock = container_of(strp, struct kcm_psock, strp);\n\tstruct kcm_sock *kcm;\n\ntry_queue:\n\tkcm = reserve_rx_kcm(psock, skb);\n\tif (!kcm) {\n\t\t  \n\t\treturn;\n\t}\n\n\tif (kcm_queue_rcv_skb(&kcm->sk, skb)) {\n\t\t \n\t\tunreserve_rx_kcm(psock, false);\n\t\tgoto try_queue;\n\t}\n}\n\nstatic int kcm_parse_func_strparser(struct strparser *strp, struct sk_buff *skb)\n{\n\tstruct kcm_psock *psock = container_of(strp, struct kcm_psock, strp);\n\tstruct bpf_prog *prog = psock->bpf_prog;\n\tint res;\n\n\tres = bpf_prog_run_pin_on_cpu(prog, skb);\n\treturn res;\n}\n\nstatic int kcm_read_sock_done(struct strparser *strp, int err)\n{\n\tstruct kcm_psock *psock = container_of(strp, struct kcm_psock, strp);\n\n\tunreserve_rx_kcm(psock, true);\n\n\treturn err;\n}\n\nstatic void psock_state_change(struct sock *sk)\n{\n\t \n\n\treport_csk_error(sk, EPIPE);\n}\n\nstatic void psock_write_space(struct sock *sk)\n{\n\tstruct kcm_psock *psock;\n\tstruct kcm_mux *mux;\n\tstruct kcm_sock *kcm;\n\n\tread_lock_bh(&sk->sk_callback_lock);\n\n\tpsock = (struct kcm_psock *)sk->sk_user_data;\n\tif (unlikely(!psock))\n\t\tgoto out;\n\tmux = psock->mux;\n\n\tspin_lock_bh(&mux->lock);\n\n\t \n\tkcm = psock->tx_kcm;\n\tif (kcm && !unlikely(kcm->tx_stopped))\n\t\tqueue_work(kcm_wq, &kcm->tx_work);\n\n\tspin_unlock_bh(&mux->lock);\nout:\n\tread_unlock_bh(&sk->sk_callback_lock);\n}\n\nstatic void unreserve_psock(struct kcm_sock *kcm);\n\n \nstatic struct kcm_psock *reserve_psock(struct kcm_sock *kcm)\n{\n\tstruct kcm_mux *mux = kcm->mux;\n\tstruct kcm_psock *psock;\n\n\tpsock = kcm->tx_psock;\n\n\tsmp_rmb();  \n\n\tif (psock) {\n\t\tWARN_ON(kcm->tx_wait);\n\t\tif (unlikely(psock->tx_stopped))\n\t\t\tunreserve_psock(kcm);\n\t\telse\n\t\t\treturn kcm->tx_psock;\n\t}\n\n\tspin_lock_bh(&mux->lock);\n\n\t \n\tpsock = kcm->tx_psock;\n\tif (unlikely(psock)) {\n\t\tWARN_ON(kcm->tx_wait);\n\t\tspin_unlock_bh(&mux->lock);\n\t\treturn kcm->tx_psock;\n\t}\n\n\tif (!list_empty(&mux->psocks_avail)) {\n\t\tpsock = list_first_entry(&mux->psocks_avail,\n\t\t\t\t\t struct kcm_psock,\n\t\t\t\t\t psock_avail_list);\n\t\tlist_del(&psock->psock_avail_list);\n\t\tif (kcm->tx_wait) {\n\t\t\tlist_del(&kcm->wait_psock_list);\n\t\t\tkcm->tx_wait = false;\n\t\t}\n\t\tkcm->tx_psock = psock;\n\t\tpsock->tx_kcm = kcm;\n\t\tKCM_STATS_INCR(psock->stats.reserved);\n\t} else if (!kcm->tx_wait) {\n\t\tlist_add_tail(&kcm->wait_psock_list,\n\t\t\t      &mux->kcm_tx_waiters);\n\t\tkcm->tx_wait = true;\n\t}\n\n\tspin_unlock_bh(&mux->lock);\n\n\treturn psock;\n}\n\n \nstatic void psock_now_avail(struct kcm_psock *psock)\n{\n\tstruct kcm_mux *mux = psock->mux;\n\tstruct kcm_sock *kcm;\n\n\tif (list_empty(&mux->kcm_tx_waiters)) {\n\t\tlist_add_tail(&psock->psock_avail_list,\n\t\t\t      &mux->psocks_avail);\n\t} else {\n\t\tkcm = list_first_entry(&mux->kcm_tx_waiters,\n\t\t\t\t       struct kcm_sock,\n\t\t\t\t       wait_psock_list);\n\t\tlist_del(&kcm->wait_psock_list);\n\t\tkcm->tx_wait = false;\n\t\tpsock->tx_kcm = kcm;\n\n\t\t \n\t\tsmp_mb();\n\n\t\tkcm->tx_psock = psock;\n\t\tKCM_STATS_INCR(psock->stats.reserved);\n\t\tqueue_work(kcm_wq, &kcm->tx_work);\n\t}\n}\n\n \nstatic void unreserve_psock(struct kcm_sock *kcm)\n{\n\tstruct kcm_psock *psock;\n\tstruct kcm_mux *mux = kcm->mux;\n\n\tspin_lock_bh(&mux->lock);\n\n\tpsock = kcm->tx_psock;\n\n\tif (WARN_ON(!psock)) {\n\t\tspin_unlock_bh(&mux->lock);\n\t\treturn;\n\t}\n\n\tsmp_rmb();  \n\n\tkcm_update_tx_mux_stats(mux, psock);\n\n\tWARN_ON(kcm->tx_wait);\n\n\tkcm->tx_psock = NULL;\n\tpsock->tx_kcm = NULL;\n\tKCM_STATS_INCR(psock->stats.unreserved);\n\n\tif (unlikely(psock->tx_stopped)) {\n\t\tif (psock->done) {\n\t\t\t \n\t\t\tlist_del(&psock->psock_list);\n\t\t\tmux->psocks_cnt--;\n\t\t\tsock_put(psock->sk);\n\t\t\tfput(psock->sk->sk_socket->file);\n\t\t\tkmem_cache_free(kcm_psockp, psock);\n\t\t}\n\n\t\t \n\n\t\tspin_unlock_bh(&mux->lock);\n\n\t\treturn;\n\t}\n\n\tpsock_now_avail(psock);\n\n\tspin_unlock_bh(&mux->lock);\n}\n\nstatic void kcm_report_tx_retry(struct kcm_sock *kcm)\n{\n\tstruct kcm_mux *mux = kcm->mux;\n\n\tspin_lock_bh(&mux->lock);\n\tKCM_STATS_INCR(mux->stats.tx_retries);\n\tspin_unlock_bh(&mux->lock);\n}\n\n \nstatic int kcm_write_msgs(struct kcm_sock *kcm)\n{\n\tunsigned int total_sent = 0;\n\tstruct sock *sk = &kcm->sk;\n\tstruct kcm_psock *psock;\n\tstruct sk_buff *head;\n\tint ret = 0;\n\n\tkcm->tx_wait_more = false;\n\tpsock = kcm->tx_psock;\n\tif (unlikely(psock && psock->tx_stopped)) {\n\t\t \n\t\tunreserve_psock(kcm);\n\t\tkcm_report_tx_retry(kcm);\n\t\tif (skb_queue_empty(&sk->sk_write_queue))\n\t\t\treturn 0;\n\n\t\tkcm_tx_msg(skb_peek(&sk->sk_write_queue))->started_tx = false;\n\t}\n\nretry:\n\twhile ((head = skb_peek(&sk->sk_write_queue))) {\n\t\tstruct msghdr msg = {\n\t\t\t.msg_flags = MSG_DONTWAIT | MSG_SPLICE_PAGES,\n\t\t};\n\t\tstruct kcm_tx_msg *txm = kcm_tx_msg(head);\n\t\tstruct sk_buff *skb;\n\t\tunsigned int msize;\n\t\tint i;\n\n\t\tif (!txm->started_tx) {\n\t\t\tpsock = reserve_psock(kcm);\n\t\t\tif (!psock)\n\t\t\t\tgoto out;\n\t\t\tskb = head;\n\t\t\ttxm->frag_offset = 0;\n\t\t\ttxm->sent = 0;\n\t\t\ttxm->started_tx = true;\n\t\t} else {\n\t\t\tif (WARN_ON(!psock)) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tskb = txm->frag_skb;\n\t\t}\n\n\t\tif (WARN_ON(!skb_shinfo(skb)->nr_frags)) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tmsize = 0;\n\t\tfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++)\n\t\t\tmsize += skb_shinfo(skb)->frags[i].bv_len;\n\n\t\tiov_iter_bvec(&msg.msg_iter, ITER_SOURCE,\n\t\t\t      skb_shinfo(skb)->frags, skb_shinfo(skb)->nr_frags,\n\t\t\t      msize);\n\t\tiov_iter_advance(&msg.msg_iter, txm->frag_offset);\n\n\t\tdo {\n\t\t\tret = sock_sendmsg(psock->sk->sk_socket, &msg);\n\t\t\tif (ret <= 0) {\n\t\t\t\tif (ret == -EAGAIN) {\n\t\t\t\t\t \n\t\t\t\t\ttxm->frag_skb = skb;\n\t\t\t\t\tret = 0;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tkcm_abort_tx_psock(psock, ret ? -ret : EPIPE,\n\t\t\t\t\t\t   true);\n\t\t\t\tunreserve_psock(kcm);\n\t\t\t\tpsock = NULL;\n\n\t\t\t\ttxm->started_tx = false;\n\t\t\t\tkcm_report_tx_retry(kcm);\n\t\t\t\tret = 0;\n\t\t\t\tgoto retry;\n\t\t\t}\n\n\t\t\ttxm->sent += ret;\n\t\t\ttxm->frag_offset += ret;\n\t\t\tKCM_STATS_ADD(psock->stats.tx_bytes, ret);\n\t\t} while (msg.msg_iter.count > 0);\n\n\t\tif (skb == head) {\n\t\t\tif (skb_has_frag_list(skb)) {\n\t\t\t\ttxm->frag_skb = skb_shinfo(skb)->frag_list;\n\t\t\t\ttxm->frag_offset = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else if (skb->next) {\n\t\t\ttxm->frag_skb = skb->next;\n\t\t\ttxm->frag_offset = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tsk->sk_wmem_queued -= txm->sent;\n\t\ttotal_sent += txm->sent;\n\t\tskb_dequeue(&sk->sk_write_queue);\n\t\tkfree_skb(head);\n\t\tKCM_STATS_INCR(psock->stats.tx_msgs);\n\t}\nout:\n\tif (!head) {\n\t\t \n\t\tWARN_ON(!skb_queue_empty(&sk->sk_write_queue));\n\t\tif (psock)\n\t\t\tunreserve_psock(kcm);\n\t}\n\n\t \n\tsk->sk_write_space(sk);\n\n\treturn total_sent ? : ret;\n}\n\nstatic void kcm_tx_work(struct work_struct *w)\n{\n\tstruct kcm_sock *kcm = container_of(w, struct kcm_sock, tx_work);\n\tstruct sock *sk = &kcm->sk;\n\tint err;\n\n\tlock_sock(sk);\n\n\t \n\terr = kcm_write_msgs(kcm);\n\tif (err < 0) {\n\t\t \n\t\tpr_warn(\"KCM: Hard failure on kcm_write_msgs %d\\n\", err);\n\t\treport_csk_error(&kcm->sk, -err);\n\t\tgoto out;\n\t}\n\n\t \n\tif (likely(sk->sk_socket) &&\n\t    test_bit(SOCK_NOSPACE, &sk->sk_socket->flags)) {\n\t\tclear_bit(SOCK_NOSPACE, &sk->sk_socket->flags);\n\t\tsk->sk_write_space(sk);\n\t}\n\nout:\n\trelease_sock(sk);\n}\n\nstatic void kcm_push(struct kcm_sock *kcm)\n{\n\tif (kcm->tx_wait_more)\n\t\tkcm_write_msgs(kcm);\n}\n\nstatic int kcm_sendmsg(struct socket *sock, struct msghdr *msg, size_t len)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct kcm_sock *kcm = kcm_sk(sk);\n\tstruct sk_buff *skb = NULL, *head = NULL;\n\tsize_t copy, copied = 0;\n\tlong timeo = sock_sndtimeo(sk, msg->msg_flags & MSG_DONTWAIT);\n\tint eor = (sock->type == SOCK_DGRAM) ?\n\t\t  !(msg->msg_flags & MSG_MORE) : !!(msg->msg_flags & MSG_EOR);\n\tint err = -EPIPE;\n\n\tlock_sock(sk);\n\n\t \n\tsk_clear_bit(SOCKWQ_ASYNC_NOSPACE, sk);\n\n\tif (sk->sk_err)\n\t\tgoto out_error;\n\n\tif (kcm->seq_skb) {\n\t\t \n\t\thead = kcm->seq_skb;\n\t\tskb = kcm_tx_msg(head)->last_skb;\n\t\tgoto start;\n\t}\n\n\t \n\tif (!sk_stream_memory_free(sk)) {\n\t\tkcm_push(kcm);\n\t\tset_bit(SOCK_NOSPACE, &sk->sk_socket->flags);\n\t\terr = sk_stream_wait_memory(sk, &timeo);\n\t\tif (err)\n\t\t\tgoto out_error;\n\t}\n\n\tif (msg_data_left(msg)) {\n\t\t \n\t\thead = alloc_skb(0, sk->sk_allocation);\n\t\twhile (!head) {\n\t\t\tkcm_push(kcm);\n\t\t\terr = sk_stream_wait_memory(sk, &timeo);\n\t\t\tif (err)\n\t\t\t\tgoto out_error;\n\n\t\t\thead = alloc_skb(0, sk->sk_allocation);\n\t\t}\n\n\t\tskb = head;\n\n\t\t \n\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t}\n\nstart:\n\twhile (msg_data_left(msg)) {\n\t\tbool merge = true;\n\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\tgoto wait_for_memory;\n\n\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t      pfrag->offset)) {\n\t\t\tif (i == MAX_SKB_FRAGS) {\n\t\t\t\tstruct sk_buff *tskb;\n\n\t\t\t\ttskb = alloc_skb(0, sk->sk_allocation);\n\t\t\t\tif (!tskb)\n\t\t\t\t\tgoto wait_for_memory;\n\n\t\t\t\tif (head == skb)\n\t\t\t\t\tskb_shinfo(head)->frag_list = tskb;\n\t\t\t\telse\n\t\t\t\t\tskb->next = tskb;\n\n\t\t\t\tskb = tskb;\n\t\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmerge = false;\n\t\t}\n\n\t\tif (msg->msg_flags & MSG_SPLICE_PAGES) {\n\t\t\tcopy = msg_data_left(msg);\n\t\t\tif (!sk_wmem_schedule(sk, copy))\n\t\t\t\tgoto wait_for_memory;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0) {\n\t\t\t\tif (err == -EMSGSIZE)\n\t\t\t\t\tgoto wait_for_memory;\n\t\t\t\tgoto out_error;\n\t\t\t}\n\n\t\t\tcopy = err;\n\t\t\tskb_shinfo(skb)->flags |= SKBFL_SHARED_FRAG;\n\t\t\tsk_wmem_queued_add(sk, copy);\n\t\t\tsk_mem_charge(sk, copy);\n\n\t\t\tif (head != skb)\n\t\t\t\thead->truesize += copy;\n\t\t} else {\n\t\t\tcopy = min_t(int, msg_data_left(msg),\n\t\t\t\t     pfrag->size - pfrag->offset);\n\t\t\tif (!sk_wmem_schedule(sk, copy))\n\t\t\t\tgoto wait_for_memory;\n\n\t\t\terr = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,\n\t\t\t\t\t\t       pfrag->page,\n\t\t\t\t\t\t       pfrag->offset,\n\t\t\t\t\t\t       copy);\n\t\t\tif (err)\n\t\t\t\tgoto out_error;\n\n\t\t\t \n\t\t\tif (merge) {\n\t\t\t\tskb_frag_size_add(\n\t\t\t\t\t&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\t} else {\n\t\t\t\tskb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t   pfrag->offset, copy);\n\t\t\t\tget_page(pfrag->page);\n\t\t\t}\n\n\t\t\tpfrag->offset += copy;\n\t\t}\n\n\t\tcopied += copy;\n\t\tif (head != skb) {\n\t\t\thead->len += copy;\n\t\t\thead->data_len += copy;\n\t\t}\n\n\t\tcontinue;\n\nwait_for_memory:\n\t\tkcm_push(kcm);\n\t\terr = sk_stream_wait_memory(sk, &timeo);\n\t\tif (err)\n\t\t\tgoto out_error;\n\t}\n\n\tif (eor) {\n\t\tbool not_busy = skb_queue_empty(&sk->sk_write_queue);\n\n\t\tif (head) {\n\t\t\t \n\t\t\t__skb_queue_tail(&sk->sk_write_queue, head);\n\t\t\tkcm->seq_skb = NULL;\n\t\t\tKCM_STATS_INCR(kcm->stats.tx_msgs);\n\t\t}\n\n\t\tif (msg->msg_flags & MSG_BATCH) {\n\t\t\tkcm->tx_wait_more = true;\n\t\t} else if (kcm->tx_wait_more || not_busy) {\n\t\t\terr = kcm_write_msgs(kcm);\n\t\t\tif (err < 0) {\n\t\t\t\t \n\t\t\t\tpr_warn(\"KCM: Hard failure on kcm_write_msgs\\n\");\n\t\t\t\treport_csk_error(&kcm->sk, -err);\n\t\t\t}\n\t\t}\n\t} else {\n\t\t \npartial_message:\n\t\tif (head) {\n\t\t\tkcm->seq_skb = head;\n\t\t\tkcm_tx_msg(head)->last_skb = skb;\n\t\t}\n\t}\n\n\tKCM_STATS_ADD(kcm->stats.tx_bytes, copied);\n\n\trelease_sock(sk);\n\treturn copied;\n\nout_error:\n\tkcm_push(kcm);\n\n\tif (sock->type == SOCK_SEQPACKET) {\n\t\t \n\t\tif (copied)\n\t\t\tgoto partial_message;\n\t\tif (head != kcm->seq_skb)\n\t\t\tkfree_skb(head);\n\t} else {\n\t\tkfree_skb(head);\n\t\tkcm->seq_skb = NULL;\n\t}\n\n\terr = sk_stream_error(sk, msg->msg_flags, err);\n\n\t \n\tif (unlikely(skb_queue_len(&sk->sk_write_queue) == 0 && err == -EAGAIN))\n\t\tsk->sk_write_space(sk);\n\n\trelease_sock(sk);\n\treturn err;\n}\n\nstatic void kcm_splice_eof(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct kcm_sock *kcm = kcm_sk(sk);\n\n\tif (skb_queue_empty_lockless(&sk->sk_write_queue))\n\t\treturn;\n\n\tlock_sock(sk);\n\tkcm_write_msgs(kcm);\n\trelease_sock(sk);\n}\n\nstatic int kcm_recvmsg(struct socket *sock, struct msghdr *msg,\n\t\t       size_t len, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct kcm_sock *kcm = kcm_sk(sk);\n\tint err = 0;\n\tstruct strp_msg *stm;\n\tint copied = 0;\n\tstruct sk_buff *skb;\n\n\tskb = skb_recv_datagram(sk, flags, &err);\n\tif (!skb)\n\t\tgoto out;\n\n\t \n\n\tstm = strp_msg(skb);\n\n\tif (len > stm->full_len)\n\t\tlen = stm->full_len;\n\n\terr = skb_copy_datagram_msg(skb, stm->offset, msg, len);\n\tif (err < 0)\n\t\tgoto out;\n\n\tcopied = len;\n\tif (likely(!(flags & MSG_PEEK))) {\n\t\tKCM_STATS_ADD(kcm->stats.rx_bytes, copied);\n\t\tif (copied < stm->full_len) {\n\t\t\tif (sock->type == SOCK_DGRAM) {\n\t\t\t\t \n\t\t\t\tmsg->msg_flags |= MSG_TRUNC;\n\t\t\t\tgoto msg_finished;\n\t\t\t}\n\t\t\tstm->offset += copied;\n\t\t\tstm->full_len -= copied;\n\t\t} else {\nmsg_finished:\n\t\t\t \n\t\t\tmsg->msg_flags |= MSG_EOR;\n\t\t\tKCM_STATS_INCR(kcm->stats.rx_msgs);\n\t\t}\n\t}\n\nout:\n\tskb_free_datagram(sk, skb);\n\treturn copied ? : err;\n}\n\nstatic ssize_t kcm_splice_read(struct socket *sock, loff_t *ppos,\n\t\t\t       struct pipe_inode_info *pipe, size_t len,\n\t\t\t       unsigned int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct kcm_sock *kcm = kcm_sk(sk);\n\tstruct strp_msg *stm;\n\tint err = 0;\n\tssize_t copied;\n\tstruct sk_buff *skb;\n\n\t \n\n\tskb = skb_recv_datagram(sk, flags, &err);\n\tif (!skb)\n\t\tgoto err_out;\n\n\t \n\n\tstm = strp_msg(skb);\n\n\tif (len > stm->full_len)\n\t\tlen = stm->full_len;\n\n\tcopied = skb_splice_bits(skb, sk, stm->offset, pipe, len, flags);\n\tif (copied < 0) {\n\t\terr = copied;\n\t\tgoto err_out;\n\t}\n\n\tKCM_STATS_ADD(kcm->stats.rx_bytes, copied);\n\n\tstm->offset += copied;\n\tstm->full_len -= copied;\n\n\t \n\n\tskb_free_datagram(sk, skb);\n\treturn copied;\n\nerr_out:\n\tskb_free_datagram(sk, skb);\n\treturn err;\n}\n\n \nstatic void kcm_recv_disable(struct kcm_sock *kcm)\n{\n\tstruct kcm_mux *mux = kcm->mux;\n\n\tif (kcm->rx_disabled)\n\t\treturn;\n\n\tspin_lock_bh(&mux->rx_lock);\n\n\tkcm->rx_disabled = 1;\n\n\t \n\tif (!kcm->rx_psock) {\n\t\tif (kcm->rx_wait) {\n\t\t\tlist_del(&kcm->wait_rx_list);\n\t\t\t \n\t\t\tWRITE_ONCE(kcm->rx_wait, false);\n\t\t}\n\n\t\trequeue_rx_msgs(mux, &kcm->sk.sk_receive_queue);\n\t}\n\n\tspin_unlock_bh(&mux->rx_lock);\n}\n\n \nstatic void kcm_recv_enable(struct kcm_sock *kcm)\n{\n\tstruct kcm_mux *mux = kcm->mux;\n\n\tif (!kcm->rx_disabled)\n\t\treturn;\n\n\tspin_lock_bh(&mux->rx_lock);\n\n\tkcm->rx_disabled = 0;\n\tkcm_rcv_ready(kcm);\n\n\tspin_unlock_bh(&mux->rx_lock);\n}\n\nstatic int kcm_setsockopt(struct socket *sock, int level, int optname,\n\t\t\t  sockptr_t optval, unsigned int optlen)\n{\n\tstruct kcm_sock *kcm = kcm_sk(sock->sk);\n\tint val, valbool;\n\tint err = 0;\n\n\tif (level != SOL_KCM)\n\t\treturn -ENOPROTOOPT;\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (copy_from_sockptr(&val, optval, sizeof(int)))\n\t\treturn -EFAULT;\n\n\tvalbool = val ? 1 : 0;\n\n\tswitch (optname) {\n\tcase KCM_RECV_DISABLE:\n\t\tlock_sock(&kcm->sk);\n\t\tif (valbool)\n\t\t\tkcm_recv_disable(kcm);\n\t\telse\n\t\t\tkcm_recv_enable(kcm);\n\t\trelease_sock(&kcm->sk);\n\t\tbreak;\n\tdefault:\n\t\terr = -ENOPROTOOPT;\n\t}\n\n\treturn err;\n}\n\nstatic int kcm_getsockopt(struct socket *sock, int level, int optname,\n\t\t\t  char __user *optval, int __user *optlen)\n{\n\tstruct kcm_sock *kcm = kcm_sk(sock->sk);\n\tint val, len;\n\n\tif (level != SOL_KCM)\n\t\treturn -ENOPROTOOPT;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\n\tlen = min_t(unsigned int, len, sizeof(int));\n\tif (len < 0)\n\t\treturn -EINVAL;\n\n\tswitch (optname) {\n\tcase KCM_RECV_DISABLE:\n\t\tval = kcm->rx_disabled;\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOPROTOOPT;\n\t}\n\n\tif (put_user(len, optlen))\n\t\treturn -EFAULT;\n\tif (copy_to_user(optval, &val, len))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic void init_kcm_sock(struct kcm_sock *kcm, struct kcm_mux *mux)\n{\n\tstruct kcm_sock *tkcm;\n\tstruct list_head *head;\n\tint index = 0;\n\n\t \n\tkcm->sk.sk_state = TCP_ESTABLISHED;\n\n\t \n\tkcm->mux = mux;\n\tspin_lock_bh(&mux->lock);\n\n\thead = &mux->kcm_socks;\n\tlist_for_each_entry(tkcm, &mux->kcm_socks, kcm_sock_list) {\n\t\tif (tkcm->index != index)\n\t\t\tbreak;\n\t\thead = &tkcm->kcm_sock_list;\n\t\tindex++;\n\t}\n\n\tlist_add(&kcm->kcm_sock_list, head);\n\tkcm->index = index;\n\n\tmux->kcm_socks_cnt++;\n\tspin_unlock_bh(&mux->lock);\n\n\tINIT_WORK(&kcm->tx_work, kcm_tx_work);\n\n\tspin_lock_bh(&mux->rx_lock);\n\tkcm_rcv_ready(kcm);\n\tspin_unlock_bh(&mux->rx_lock);\n}\n\nstatic int kcm_attach(struct socket *sock, struct socket *csock,\n\t\t      struct bpf_prog *prog)\n{\n\tstruct kcm_sock *kcm = kcm_sk(sock->sk);\n\tstruct kcm_mux *mux = kcm->mux;\n\tstruct sock *csk;\n\tstruct kcm_psock *psock = NULL, *tpsock;\n\tstruct list_head *head;\n\tint index = 0;\n\tstatic const struct strp_callbacks cb = {\n\t\t.rcv_msg = kcm_rcv_strparser,\n\t\t.parse_msg = kcm_parse_func_strparser,\n\t\t.read_sock_done = kcm_read_sock_done,\n\t};\n\tint err = 0;\n\n\tcsk = csock->sk;\n\tif (!csk)\n\t\treturn -EINVAL;\n\n\tlock_sock(csk);\n\n\t \n\tif ((csk->sk_family != AF_INET && csk->sk_family != AF_INET6) ||\n\t    csk->sk_protocol != IPPROTO_TCP) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\t \n\tif (csk->sk_state == TCP_LISTEN || csk->sk_state == TCP_CLOSE) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tpsock = kmem_cache_zalloc(kcm_psockp, GFP_KERNEL);\n\tif (!psock) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tpsock->mux = mux;\n\tpsock->sk = csk;\n\tpsock->bpf_prog = prog;\n\n\twrite_lock_bh(&csk->sk_callback_lock);\n\n\t \n\tif (csk->sk_user_data) {\n\t\twrite_unlock_bh(&csk->sk_callback_lock);\n\t\tkmem_cache_free(kcm_psockp, psock);\n\t\terr = -EALREADY;\n\t\tgoto out;\n\t}\n\n\terr = strp_init(&psock->strp, csk, &cb);\n\tif (err) {\n\t\twrite_unlock_bh(&csk->sk_callback_lock);\n\t\tkmem_cache_free(kcm_psockp, psock);\n\t\tgoto out;\n\t}\n\n\tpsock->save_data_ready = csk->sk_data_ready;\n\tpsock->save_write_space = csk->sk_write_space;\n\tpsock->save_state_change = csk->sk_state_change;\n\tcsk->sk_user_data = psock;\n\tcsk->sk_data_ready = psock_data_ready;\n\tcsk->sk_write_space = psock_write_space;\n\tcsk->sk_state_change = psock_state_change;\n\n\twrite_unlock_bh(&csk->sk_callback_lock);\n\n\tsock_hold(csk);\n\n\t \n\tspin_lock_bh(&mux->lock);\n\thead = &mux->psocks;\n\tlist_for_each_entry(tpsock, &mux->psocks, psock_list) {\n\t\tif (tpsock->index != index)\n\t\t\tbreak;\n\t\thead = &tpsock->psock_list;\n\t\tindex++;\n\t}\n\n\tlist_add(&psock->psock_list, head);\n\tpsock->index = index;\n\n\tKCM_STATS_INCR(mux->stats.psock_attach);\n\tmux->psocks_cnt++;\n\tpsock_now_avail(psock);\n\tspin_unlock_bh(&mux->lock);\n\n\t \n\tstrp_check_rcv(&psock->strp);\n\nout:\n\trelease_sock(csk);\n\n\treturn err;\n}\n\nstatic int kcm_attach_ioctl(struct socket *sock, struct kcm_attach *info)\n{\n\tstruct socket *csock;\n\tstruct bpf_prog *prog;\n\tint err;\n\n\tcsock = sockfd_lookup(info->fd, &err);\n\tif (!csock)\n\t\treturn -ENOENT;\n\n\tprog = bpf_prog_get_type(info->bpf_fd, BPF_PROG_TYPE_SOCKET_FILTER);\n\tif (IS_ERR(prog)) {\n\t\terr = PTR_ERR(prog);\n\t\tgoto out;\n\t}\n\n\terr = kcm_attach(sock, csock, prog);\n\tif (err) {\n\t\tbpf_prog_put(prog);\n\t\tgoto out;\n\t}\n\n\t \n\n\treturn 0;\nout:\n\tsockfd_put(csock);\n\treturn err;\n}\n\nstatic void kcm_unattach(struct kcm_psock *psock)\n{\n\tstruct sock *csk = psock->sk;\n\tstruct kcm_mux *mux = psock->mux;\n\n\tlock_sock(csk);\n\n\t \n\twrite_lock_bh(&csk->sk_callback_lock);\n\tcsk->sk_user_data = NULL;\n\tcsk->sk_data_ready = psock->save_data_ready;\n\tcsk->sk_write_space = psock->save_write_space;\n\tcsk->sk_state_change = psock->save_state_change;\n\tstrp_stop(&psock->strp);\n\n\tif (WARN_ON(psock->rx_kcm)) {\n\t\twrite_unlock_bh(&csk->sk_callback_lock);\n\t\trelease_sock(csk);\n\t\treturn;\n\t}\n\n\tspin_lock_bh(&mux->rx_lock);\n\n\t \n\tif (psock->ready_rx_msg) {\n\t\tlist_del(&psock->psock_ready_list);\n\t\tkfree_skb(psock->ready_rx_msg);\n\t\tpsock->ready_rx_msg = NULL;\n\t\tKCM_STATS_INCR(mux->stats.rx_ready_drops);\n\t}\n\n\tspin_unlock_bh(&mux->rx_lock);\n\n\twrite_unlock_bh(&csk->sk_callback_lock);\n\n\t \n\trelease_sock(csk);\n\tstrp_done(&psock->strp);\n\tlock_sock(csk);\n\n\tbpf_prog_put(psock->bpf_prog);\n\n\tspin_lock_bh(&mux->lock);\n\n\taggregate_psock_stats(&psock->stats, &mux->aggregate_psock_stats);\n\tsave_strp_stats(&psock->strp, &mux->aggregate_strp_stats);\n\n\tKCM_STATS_INCR(mux->stats.psock_unattach);\n\n\tif (psock->tx_kcm) {\n\t\t \n\t\tKCM_STATS_INCR(mux->stats.psock_unattach_rsvd);\n\t\tspin_unlock_bh(&mux->lock);\n\n\t\t \n\t\tkcm_abort_tx_psock(psock, EPIPE, false);\n\n\t\tspin_lock_bh(&mux->lock);\n\t\tif (!psock->tx_kcm) {\n\t\t\t \n\t\t\tgoto no_reserved;\n\t\t}\n\t\tpsock->done = 1;\n\n\t\t \n\t\tsmp_mb();\n\n\t\t \n\t\tqueue_work(kcm_wq, &psock->tx_kcm->tx_work);\n\t\tspin_unlock_bh(&mux->lock);\n\t} else {\nno_reserved:\n\t\tif (!psock->tx_stopped)\n\t\t\tlist_del(&psock->psock_avail_list);\n\t\tlist_del(&psock->psock_list);\n\t\tmux->psocks_cnt--;\n\t\tspin_unlock_bh(&mux->lock);\n\n\t\tsock_put(csk);\n\t\tfput(csk->sk_socket->file);\n\t\tkmem_cache_free(kcm_psockp, psock);\n\t}\n\n\trelease_sock(csk);\n}\n\nstatic int kcm_unattach_ioctl(struct socket *sock, struct kcm_unattach *info)\n{\n\tstruct kcm_sock *kcm = kcm_sk(sock->sk);\n\tstruct kcm_mux *mux = kcm->mux;\n\tstruct kcm_psock *psock;\n\tstruct socket *csock;\n\tstruct sock *csk;\n\tint err;\n\n\tcsock = sockfd_lookup(info->fd, &err);\n\tif (!csock)\n\t\treturn -ENOENT;\n\n\tcsk = csock->sk;\n\tif (!csk) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\terr = -ENOENT;\n\n\tspin_lock_bh(&mux->lock);\n\n\tlist_for_each_entry(psock, &mux->psocks, psock_list) {\n\t\tif (psock->sk != csk)\n\t\t\tcontinue;\n\n\t\t \n\n\t\tif (psock->unattaching || WARN_ON(psock->done)) {\n\t\t\terr = -EALREADY;\n\t\t\tbreak;\n\t\t}\n\n\t\tpsock->unattaching = 1;\n\n\t\tspin_unlock_bh(&mux->lock);\n\n\t\t \n\t\tkcm_unattach(psock);\n\n\t\terr = 0;\n\t\tgoto out;\n\t}\n\n\tspin_unlock_bh(&mux->lock);\n\nout:\n\tsockfd_put(csock);\n\treturn err;\n}\n\nstatic struct proto kcm_proto = {\n\t.name\t= \"KCM\",\n\t.owner\t= THIS_MODULE,\n\t.obj_size = sizeof(struct kcm_sock),\n};\n\n \nstatic struct file *kcm_clone(struct socket *osock)\n{\n\tstruct socket *newsock;\n\tstruct sock *newsk;\n\n\tnewsock = sock_alloc();\n\tif (!newsock)\n\t\treturn ERR_PTR(-ENFILE);\n\n\tnewsock->type = osock->type;\n\tnewsock->ops = osock->ops;\n\n\t__module_get(newsock->ops->owner);\n\n\tnewsk = sk_alloc(sock_net(osock->sk), PF_KCM, GFP_KERNEL,\n\t\t\t &kcm_proto, false);\n\tif (!newsk) {\n\t\tsock_release(newsock);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tsock_init_data(newsock, newsk);\n\tinit_kcm_sock(kcm_sk(newsk), kcm_sk(osock->sk)->mux);\n\n\treturn sock_alloc_file(newsock, 0, osock->sk->sk_prot_creator->name);\n}\n\nstatic int kcm_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)\n{\n\tint err;\n\n\tswitch (cmd) {\n\tcase SIOCKCMATTACH: {\n\t\tstruct kcm_attach info;\n\n\t\tif (copy_from_user(&info, (void __user *)arg, sizeof(info)))\n\t\t\treturn -EFAULT;\n\n\t\terr = kcm_attach_ioctl(sock, &info);\n\n\t\tbreak;\n\t}\n\tcase SIOCKCMUNATTACH: {\n\t\tstruct kcm_unattach info;\n\n\t\tif (copy_from_user(&info, (void __user *)arg, sizeof(info)))\n\t\t\treturn -EFAULT;\n\n\t\terr = kcm_unattach_ioctl(sock, &info);\n\n\t\tbreak;\n\t}\n\tcase SIOCKCMCLONE: {\n\t\tstruct kcm_clone info;\n\t\tstruct file *file;\n\n\t\tinfo.fd = get_unused_fd_flags(0);\n\t\tif (unlikely(info.fd < 0))\n\t\t\treturn info.fd;\n\n\t\tfile = kcm_clone(sock);\n\t\tif (IS_ERR(file)) {\n\t\t\tput_unused_fd(info.fd);\n\t\t\treturn PTR_ERR(file);\n\t\t}\n\t\tif (copy_to_user((void __user *)arg, &info,\n\t\t\t\t sizeof(info))) {\n\t\t\tput_unused_fd(info.fd);\n\t\t\tfput(file);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tfd_install(info.fd, file);\n\t\terr = 0;\n\t\tbreak;\n\t}\n\tdefault:\n\t\terr = -ENOIOCTLCMD;\n\t\tbreak;\n\t}\n\n\treturn err;\n}\n\nstatic void free_mux(struct rcu_head *rcu)\n{\n\tstruct kcm_mux *mux = container_of(rcu,\n\t    struct kcm_mux, rcu);\n\n\tkmem_cache_free(kcm_muxp, mux);\n}\n\nstatic void release_mux(struct kcm_mux *mux)\n{\n\tstruct kcm_net *knet = mux->knet;\n\tstruct kcm_psock *psock, *tmp_psock;\n\n\t \n\tlist_for_each_entry_safe(psock, tmp_psock,\n\t\t\t\t &mux->psocks, psock_list) {\n\t\tif (!WARN_ON(psock->unattaching))\n\t\t\tkcm_unattach(psock);\n\t}\n\n\tif (WARN_ON(mux->psocks_cnt))\n\t\treturn;\n\n\t__skb_queue_purge(&mux->rx_hold_queue);\n\n\tmutex_lock(&knet->mutex);\n\taggregate_mux_stats(&mux->stats, &knet->aggregate_mux_stats);\n\taggregate_psock_stats(&mux->aggregate_psock_stats,\n\t\t\t      &knet->aggregate_psock_stats);\n\taggregate_strp_stats(&mux->aggregate_strp_stats,\n\t\t\t     &knet->aggregate_strp_stats);\n\tlist_del_rcu(&mux->kcm_mux_list);\n\tknet->count--;\n\tmutex_unlock(&knet->mutex);\n\n\tcall_rcu(&mux->rcu, free_mux);\n}\n\nstatic void kcm_done(struct kcm_sock *kcm)\n{\n\tstruct kcm_mux *mux = kcm->mux;\n\tstruct sock *sk = &kcm->sk;\n\tint socks_cnt;\n\n\tspin_lock_bh(&mux->rx_lock);\n\tif (kcm->rx_psock) {\n\t\t \n\t\tWARN_ON(kcm->done);\n\t\tkcm->rx_disabled = 1;\n\t\tkcm->done = 1;\n\t\tspin_unlock_bh(&mux->rx_lock);\n\t\treturn;\n\t}\n\n\tif (kcm->rx_wait) {\n\t\tlist_del(&kcm->wait_rx_list);\n\t\t \n\t\tWRITE_ONCE(kcm->rx_wait, false);\n\t}\n\t \n\trequeue_rx_msgs(mux, &sk->sk_receive_queue);\n\n\tspin_unlock_bh(&mux->rx_lock);\n\n\tif (WARN_ON(sk_rmem_alloc_get(sk)))\n\t\treturn;\n\n\t \n\tspin_lock_bh(&mux->lock);\n\n\tlist_del(&kcm->kcm_sock_list);\n\tmux->kcm_socks_cnt--;\n\tsocks_cnt = mux->kcm_socks_cnt;\n\n\tspin_unlock_bh(&mux->lock);\n\n\tif (!socks_cnt) {\n\t\t \n\t\trelease_mux(mux);\n\t}\n\n\tWARN_ON(kcm->rx_wait);\n\n\tsock_put(&kcm->sk);\n}\n\n \nstatic int kcm_release(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct kcm_sock *kcm;\n\tstruct kcm_mux *mux;\n\tstruct kcm_psock *psock;\n\n\tif (!sk)\n\t\treturn 0;\n\n\tkcm = kcm_sk(sk);\n\tmux = kcm->mux;\n\n\tlock_sock(sk);\n\tsock_orphan(sk);\n\tkfree_skb(kcm->seq_skb);\n\n\t \n\t__skb_queue_purge(&sk->sk_write_queue);\n\n\t \n\tkcm->tx_stopped = 1;\n\n\trelease_sock(sk);\n\n\tspin_lock_bh(&mux->lock);\n\tif (kcm->tx_wait) {\n\t\t \n\t\tlist_del(&kcm->wait_psock_list);\n\t\tkcm->tx_wait = false;\n\t}\n\tspin_unlock_bh(&mux->lock);\n\n\t \n\tcancel_work_sync(&kcm->tx_work);\n\n\tlock_sock(sk);\n\tpsock = kcm->tx_psock;\n\tif (psock) {\n\t\t \n\t\tkcm_abort_tx_psock(psock, EPIPE, false);\n\t\tunreserve_psock(kcm);\n\t}\n\trelease_sock(sk);\n\n\tWARN_ON(kcm->tx_wait);\n\tWARN_ON(kcm->tx_psock);\n\n\tsock->sk = NULL;\n\n\tkcm_done(kcm);\n\n\treturn 0;\n}\n\nstatic const struct proto_ops kcm_dgram_ops = {\n\t.family =\tPF_KCM,\n\t.owner =\tTHIS_MODULE,\n\t.release =\tkcm_release,\n\t.bind =\t\tsock_no_bind,\n\t.connect =\tsock_no_connect,\n\t.socketpair =\tsock_no_socketpair,\n\t.accept =\tsock_no_accept,\n\t.getname =\tsock_no_getname,\n\t.poll =\t\tdatagram_poll,\n\t.ioctl =\tkcm_ioctl,\n\t.listen =\tsock_no_listen,\n\t.shutdown =\tsock_no_shutdown,\n\t.setsockopt =\tkcm_setsockopt,\n\t.getsockopt =\tkcm_getsockopt,\n\t.sendmsg =\tkcm_sendmsg,\n\t.recvmsg =\tkcm_recvmsg,\n\t.mmap =\t\tsock_no_mmap,\n\t.splice_eof =\tkcm_splice_eof,\n};\n\nstatic const struct proto_ops kcm_seqpacket_ops = {\n\t.family =\tPF_KCM,\n\t.owner =\tTHIS_MODULE,\n\t.release =\tkcm_release,\n\t.bind =\t\tsock_no_bind,\n\t.connect =\tsock_no_connect,\n\t.socketpair =\tsock_no_socketpair,\n\t.accept =\tsock_no_accept,\n\t.getname =\tsock_no_getname,\n\t.poll =\t\tdatagram_poll,\n\t.ioctl =\tkcm_ioctl,\n\t.listen =\tsock_no_listen,\n\t.shutdown =\tsock_no_shutdown,\n\t.setsockopt =\tkcm_setsockopt,\n\t.getsockopt =\tkcm_getsockopt,\n\t.sendmsg =\tkcm_sendmsg,\n\t.recvmsg =\tkcm_recvmsg,\n\t.mmap =\t\tsock_no_mmap,\n\t.splice_eof =\tkcm_splice_eof,\n\t.splice_read =\tkcm_splice_read,\n};\n\n \nstatic int kcm_create(struct net *net, struct socket *sock,\n\t\t      int protocol, int kern)\n{\n\tstruct kcm_net *knet = net_generic(net, kcm_net_id);\n\tstruct sock *sk;\n\tstruct kcm_mux *mux;\n\n\tswitch (sock->type) {\n\tcase SOCK_DGRAM:\n\t\tsock->ops = &kcm_dgram_ops;\n\t\tbreak;\n\tcase SOCK_SEQPACKET:\n\t\tsock->ops = &kcm_seqpacket_ops;\n\t\tbreak;\n\tdefault:\n\t\treturn -ESOCKTNOSUPPORT;\n\t}\n\n\tif (protocol != KCMPROTO_CONNECTED)\n\t\treturn -EPROTONOSUPPORT;\n\n\tsk = sk_alloc(net, PF_KCM, GFP_KERNEL, &kcm_proto, kern);\n\tif (!sk)\n\t\treturn -ENOMEM;\n\n\t \n\tmux = kmem_cache_zalloc(kcm_muxp, GFP_KERNEL);\n\tif (!mux) {\n\t\tsk_free(sk);\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock_init(&mux->lock);\n\tspin_lock_init(&mux->rx_lock);\n\tINIT_LIST_HEAD(&mux->kcm_socks);\n\tINIT_LIST_HEAD(&mux->kcm_rx_waiters);\n\tINIT_LIST_HEAD(&mux->kcm_tx_waiters);\n\n\tINIT_LIST_HEAD(&mux->psocks);\n\tINIT_LIST_HEAD(&mux->psocks_ready);\n\tINIT_LIST_HEAD(&mux->psocks_avail);\n\n\tmux->knet = knet;\n\n\t \n\tmutex_lock(&knet->mutex);\n\tlist_add_rcu(&mux->kcm_mux_list, &knet->mux_list);\n\tknet->count++;\n\tmutex_unlock(&knet->mutex);\n\n\tskb_queue_head_init(&mux->rx_hold_queue);\n\n\t \n\tsock_init_data(sock, sk);\n\tinit_kcm_sock(kcm_sk(sk), mux);\n\n\treturn 0;\n}\n\nstatic const struct net_proto_family kcm_family_ops = {\n\t.family = PF_KCM,\n\t.create = kcm_create,\n\t.owner  = THIS_MODULE,\n};\n\nstatic __net_init int kcm_init_net(struct net *net)\n{\n\tstruct kcm_net *knet = net_generic(net, kcm_net_id);\n\n\tINIT_LIST_HEAD_RCU(&knet->mux_list);\n\tmutex_init(&knet->mutex);\n\n\treturn 0;\n}\n\nstatic __net_exit void kcm_exit_net(struct net *net)\n{\n\tstruct kcm_net *knet = net_generic(net, kcm_net_id);\n\n\t \n\tWARN_ON(!list_empty(&knet->mux_list));\n\n\tmutex_destroy(&knet->mutex);\n}\n\nstatic struct pernet_operations kcm_net_ops = {\n\t.init = kcm_init_net,\n\t.exit = kcm_exit_net,\n\t.id   = &kcm_net_id,\n\t.size = sizeof(struct kcm_net),\n};\n\nstatic int __init kcm_init(void)\n{\n\tint err = -ENOMEM;\n\n\tkcm_muxp = kmem_cache_create(\"kcm_mux_cache\",\n\t\t\t\t     sizeof(struct kcm_mux), 0,\n\t\t\t\t     SLAB_HWCACHE_ALIGN, NULL);\n\tif (!kcm_muxp)\n\t\tgoto fail;\n\n\tkcm_psockp = kmem_cache_create(\"kcm_psock_cache\",\n\t\t\t\t       sizeof(struct kcm_psock), 0,\n\t\t\t\t\tSLAB_HWCACHE_ALIGN, NULL);\n\tif (!kcm_psockp)\n\t\tgoto fail;\n\n\tkcm_wq = create_singlethread_workqueue(\"kkcmd\");\n\tif (!kcm_wq)\n\t\tgoto fail;\n\n\terr = proto_register(&kcm_proto, 1);\n\tif (err)\n\t\tgoto fail;\n\n\terr = register_pernet_device(&kcm_net_ops);\n\tif (err)\n\t\tgoto net_ops_fail;\n\n\terr = sock_register(&kcm_family_ops);\n\tif (err)\n\t\tgoto sock_register_fail;\n\n\terr = kcm_proc_init();\n\tif (err)\n\t\tgoto proc_init_fail;\n\n\treturn 0;\n\nproc_init_fail:\n\tsock_unregister(PF_KCM);\n\nsock_register_fail:\n\tunregister_pernet_device(&kcm_net_ops);\n\nnet_ops_fail:\n\tproto_unregister(&kcm_proto);\n\nfail:\n\tkmem_cache_destroy(kcm_muxp);\n\tkmem_cache_destroy(kcm_psockp);\n\n\tif (kcm_wq)\n\t\tdestroy_workqueue(kcm_wq);\n\n\treturn err;\n}\n\nstatic void __exit kcm_exit(void)\n{\n\tkcm_proc_exit();\n\tsock_unregister(PF_KCM);\n\tunregister_pernet_device(&kcm_net_ops);\n\tproto_unregister(&kcm_proto);\n\tdestroy_workqueue(kcm_wq);\n\n\tkmem_cache_destroy(kcm_muxp);\n\tkmem_cache_destroy(kcm_psockp);\n}\n\nmodule_init(kcm_init);\nmodule_exit(kcm_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_NETPROTO(PF_KCM);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}