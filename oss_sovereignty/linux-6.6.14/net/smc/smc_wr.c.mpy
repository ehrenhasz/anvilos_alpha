{
  "module_name": "smc_wr.c",
  "hash_id": "2c1d25e92427ecfc6223ab09cd2b3609956f8499a39e9e95a762405601a71068",
  "original_prompt": "Ingested from linux-6.6.14/net/smc/smc_wr.c",
  "human_readable_source": "\n \n\n#include <linux/atomic.h>\n#include <linux/hashtable.h>\n#include <linux/wait.h>\n#include <rdma/ib_verbs.h>\n#include <asm/div64.h>\n\n#include \"smc.h\"\n#include \"smc_wr.h\"\n\n#define SMC_WR_MAX_POLL_CQE 10\t \n\n#define SMC_WR_RX_HASH_BITS 4\nstatic DEFINE_HASHTABLE(smc_wr_rx_hash, SMC_WR_RX_HASH_BITS);\nstatic DEFINE_SPINLOCK(smc_wr_rx_hash_lock);\n\nstruct smc_wr_tx_pend {\t \n\tu64\t\t\twr_id;\t\t \n\tsmc_wr_tx_handler\thandler;\n\tenum ib_wc_status\twc_status;\t \n\tstruct smc_link\t\t*link;\n\tu32\t\t\tidx;\n\tstruct smc_wr_tx_pend_priv priv;\n\tu8\t\t\tcompl_requested;\n};\n\n \n\n \n\n \nstatic inline bool smc_wr_is_tx_pend(struct smc_link *link)\n{\n\treturn !bitmap_empty(link->wr_tx_mask, link->wr_tx_cnt);\n}\n\n \nvoid smc_wr_tx_wait_no_pending_sends(struct smc_link *link)\n{\n\twait_event(link->wr_tx_wait, !smc_wr_is_tx_pend(link));\n}\n\nstatic inline int smc_wr_tx_find_pending_index(struct smc_link *link, u64 wr_id)\n{\n\tu32 i;\n\n\tfor (i = 0; i < link->wr_tx_cnt; i++) {\n\t\tif (link->wr_tx_pends[i].wr_id == wr_id)\n\t\t\treturn i;\n\t}\n\treturn link->wr_tx_cnt;\n}\n\nstatic inline void smc_wr_tx_process_cqe(struct ib_wc *wc)\n{\n\tstruct smc_wr_tx_pend pnd_snd;\n\tstruct smc_link *link;\n\tu32 pnd_snd_idx;\n\n\tlink = wc->qp->qp_context;\n\n\tif (wc->opcode == IB_WC_REG_MR) {\n\t\tif (wc->status)\n\t\t\tlink->wr_reg_state = FAILED;\n\t\telse\n\t\t\tlink->wr_reg_state = CONFIRMED;\n\t\tsmc_wr_wakeup_reg_wait(link);\n\t\treturn;\n\t}\n\n\tpnd_snd_idx = smc_wr_tx_find_pending_index(link, wc->wr_id);\n\tif (pnd_snd_idx == link->wr_tx_cnt) {\n\t\tif (link->lgr->smc_version != SMC_V2 ||\n\t\t    link->wr_tx_v2_pend->wr_id != wc->wr_id)\n\t\t\treturn;\n\t\tlink->wr_tx_v2_pend->wc_status = wc->status;\n\t\tmemcpy(&pnd_snd, link->wr_tx_v2_pend, sizeof(pnd_snd));\n\t\t \n\t\tmemset(link->wr_tx_v2_pend, 0,\n\t\t       sizeof(*link->wr_tx_v2_pend));\n\t\tmemset(link->lgr->wr_tx_buf_v2, 0,\n\t\t       sizeof(*link->lgr->wr_tx_buf_v2));\n\t} else {\n\t\tlink->wr_tx_pends[pnd_snd_idx].wc_status = wc->status;\n\t\tif (link->wr_tx_pends[pnd_snd_idx].compl_requested)\n\t\t\tcomplete(&link->wr_tx_compl[pnd_snd_idx]);\n\t\tmemcpy(&pnd_snd, &link->wr_tx_pends[pnd_snd_idx],\n\t\t       sizeof(pnd_snd));\n\t\t \n\t\tmemset(&link->wr_tx_pends[pnd_snd_idx], 0,\n\t\t       sizeof(link->wr_tx_pends[pnd_snd_idx]));\n\t\tmemset(&link->wr_tx_bufs[pnd_snd_idx], 0,\n\t\t       sizeof(link->wr_tx_bufs[pnd_snd_idx]));\n\t\tif (!test_and_clear_bit(pnd_snd_idx, link->wr_tx_mask))\n\t\t\treturn;\n\t}\n\n\tif (wc->status) {\n\t\tif (link->lgr->smc_version == SMC_V2) {\n\t\t\tmemset(link->wr_tx_v2_pend, 0,\n\t\t\t       sizeof(*link->wr_tx_v2_pend));\n\t\t\tmemset(link->lgr->wr_tx_buf_v2, 0,\n\t\t\t       sizeof(*link->lgr->wr_tx_buf_v2));\n\t\t}\n\t\t \n\t\tsmcr_link_down_cond_sched(link);\n\t}\n\tif (pnd_snd.handler)\n\t\tpnd_snd.handler(&pnd_snd.priv, link, wc->status);\n\twake_up(&link->wr_tx_wait);\n}\n\nstatic void smc_wr_tx_tasklet_fn(struct tasklet_struct *t)\n{\n\tstruct smc_ib_device *dev = from_tasklet(dev, t, send_tasklet);\n\tstruct ib_wc wc[SMC_WR_MAX_POLL_CQE];\n\tint i = 0, rc;\n\tint polled = 0;\n\nagain:\n\tpolled++;\n\tdo {\n\t\tmemset(&wc, 0, sizeof(wc));\n\t\trc = ib_poll_cq(dev->roce_cq_send, SMC_WR_MAX_POLL_CQE, wc);\n\t\tif (polled == 1) {\n\t\t\tib_req_notify_cq(dev->roce_cq_send,\n\t\t\t\t\t IB_CQ_NEXT_COMP |\n\t\t\t\t\t IB_CQ_REPORT_MISSED_EVENTS);\n\t\t}\n\t\tif (!rc)\n\t\t\tbreak;\n\t\tfor (i = 0; i < rc; i++)\n\t\t\tsmc_wr_tx_process_cqe(&wc[i]);\n\t} while (rc > 0);\n\tif (polled == 1)\n\t\tgoto again;\n}\n\nvoid smc_wr_tx_cq_handler(struct ib_cq *ib_cq, void *cq_context)\n{\n\tstruct smc_ib_device *dev = (struct smc_ib_device *)cq_context;\n\n\ttasklet_schedule(&dev->send_tasklet);\n}\n\n \n\nstatic inline int smc_wr_tx_get_free_slot_index(struct smc_link *link, u32 *idx)\n{\n\t*idx = link->wr_tx_cnt;\n\tif (!smc_link_sendable(link))\n\t\treturn -ENOLINK;\n\tfor_each_clear_bit(*idx, link->wr_tx_mask, link->wr_tx_cnt) {\n\t\tif (!test_and_set_bit(*idx, link->wr_tx_mask))\n\t\t\treturn 0;\n\t}\n\t*idx = link->wr_tx_cnt;\n\treturn -EBUSY;\n}\n\n \nint smc_wr_tx_get_free_slot(struct smc_link *link,\n\t\t\t    smc_wr_tx_handler handler,\n\t\t\t    struct smc_wr_buf **wr_buf,\n\t\t\t    struct smc_rdma_wr **wr_rdma_buf,\n\t\t\t    struct smc_wr_tx_pend_priv **wr_pend_priv)\n{\n\tstruct smc_link_group *lgr = smc_get_lgr(link);\n\tstruct smc_wr_tx_pend *wr_pend;\n\tu32 idx = link->wr_tx_cnt;\n\tstruct ib_send_wr *wr_ib;\n\tu64 wr_id;\n\tint rc;\n\n\t*wr_buf = NULL;\n\t*wr_pend_priv = NULL;\n\tif (in_softirq() || lgr->terminating) {\n\t\trc = smc_wr_tx_get_free_slot_index(link, &idx);\n\t\tif (rc)\n\t\t\treturn rc;\n\t} else {\n\t\trc = wait_event_interruptible_timeout(\n\t\t\tlink->wr_tx_wait,\n\t\t\t!smc_link_sendable(link) ||\n\t\t\tlgr->terminating ||\n\t\t\t(smc_wr_tx_get_free_slot_index(link, &idx) != -EBUSY),\n\t\t\tSMC_WR_TX_WAIT_FREE_SLOT_TIME);\n\t\tif (!rc) {\n\t\t\t \n\t\t\tsmcr_link_down_cond_sched(link);\n\t\t\treturn -EPIPE;\n\t\t}\n\t\tif (idx == link->wr_tx_cnt)\n\t\t\treturn -EPIPE;\n\t}\n\twr_id = smc_wr_tx_get_next_wr_id(link);\n\twr_pend = &link->wr_tx_pends[idx];\n\twr_pend->wr_id = wr_id;\n\twr_pend->handler = handler;\n\twr_pend->link = link;\n\twr_pend->idx = idx;\n\twr_ib = &link->wr_tx_ibs[idx];\n\twr_ib->wr_id = wr_id;\n\t*wr_buf = &link->wr_tx_bufs[idx];\n\tif (wr_rdma_buf)\n\t\t*wr_rdma_buf = &link->wr_tx_rdmas[idx];\n\t*wr_pend_priv = &wr_pend->priv;\n\treturn 0;\n}\n\nint smc_wr_tx_get_v2_slot(struct smc_link *link,\n\t\t\t  smc_wr_tx_handler handler,\n\t\t\t  struct smc_wr_v2_buf **wr_buf,\n\t\t\t  struct smc_wr_tx_pend_priv **wr_pend_priv)\n{\n\tstruct smc_wr_tx_pend *wr_pend;\n\tstruct ib_send_wr *wr_ib;\n\tu64 wr_id;\n\n\tif (link->wr_tx_v2_pend->idx == link->wr_tx_cnt)\n\t\treturn -EBUSY;\n\n\t*wr_buf = NULL;\n\t*wr_pend_priv = NULL;\n\twr_id = smc_wr_tx_get_next_wr_id(link);\n\twr_pend = link->wr_tx_v2_pend;\n\twr_pend->wr_id = wr_id;\n\twr_pend->handler = handler;\n\twr_pend->link = link;\n\twr_pend->idx = link->wr_tx_cnt;\n\twr_ib = link->wr_tx_v2_ib;\n\twr_ib->wr_id = wr_id;\n\t*wr_buf = link->lgr->wr_tx_buf_v2;\n\t*wr_pend_priv = &wr_pend->priv;\n\treturn 0;\n}\n\nint smc_wr_tx_put_slot(struct smc_link *link,\n\t\t       struct smc_wr_tx_pend_priv *wr_pend_priv)\n{\n\tstruct smc_wr_tx_pend *pend;\n\n\tpend = container_of(wr_pend_priv, struct smc_wr_tx_pend, priv);\n\tif (pend->idx < link->wr_tx_cnt) {\n\t\tu32 idx = pend->idx;\n\n\t\t \n\t\tmemset(&link->wr_tx_pends[idx], 0,\n\t\t       sizeof(link->wr_tx_pends[idx]));\n\t\tmemset(&link->wr_tx_bufs[idx], 0,\n\t\t       sizeof(link->wr_tx_bufs[idx]));\n\t\ttest_and_clear_bit(idx, link->wr_tx_mask);\n\t\twake_up(&link->wr_tx_wait);\n\t\treturn 1;\n\t} else if (link->lgr->smc_version == SMC_V2 &&\n\t\t   pend->idx == link->wr_tx_cnt) {\n\t\t \n\t\tmemset(&link->wr_tx_v2_pend, 0,\n\t\t       sizeof(link->wr_tx_v2_pend));\n\t\tmemset(&link->lgr->wr_tx_buf_v2, 0,\n\t\t       sizeof(link->lgr->wr_tx_buf_v2));\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n \nint smc_wr_tx_send(struct smc_link *link, struct smc_wr_tx_pend_priv *priv)\n{\n\tstruct smc_wr_tx_pend *pend;\n\tint rc;\n\n\tib_req_notify_cq(link->smcibdev->roce_cq_send,\n\t\t\t IB_CQ_NEXT_COMP | IB_CQ_REPORT_MISSED_EVENTS);\n\tpend = container_of(priv, struct smc_wr_tx_pend, priv);\n\trc = ib_post_send(link->roce_qp, &link->wr_tx_ibs[pend->idx], NULL);\n\tif (rc) {\n\t\tsmc_wr_tx_put_slot(link, priv);\n\t\tsmcr_link_down_cond_sched(link);\n\t}\n\treturn rc;\n}\n\nint smc_wr_tx_v2_send(struct smc_link *link, struct smc_wr_tx_pend_priv *priv,\n\t\t      int len)\n{\n\tint rc;\n\n\tlink->wr_tx_v2_ib->sg_list[0].length = len;\n\tib_req_notify_cq(link->smcibdev->roce_cq_send,\n\t\t\t IB_CQ_NEXT_COMP | IB_CQ_REPORT_MISSED_EVENTS);\n\trc = ib_post_send(link->roce_qp, link->wr_tx_v2_ib, NULL);\n\tif (rc) {\n\t\tsmc_wr_tx_put_slot(link, priv);\n\t\tsmcr_link_down_cond_sched(link);\n\t}\n\treturn rc;\n}\n\n \nint smc_wr_tx_send_wait(struct smc_link *link, struct smc_wr_tx_pend_priv *priv,\n\t\t\tunsigned long timeout)\n{\n\tstruct smc_wr_tx_pend *pend;\n\tu32 pnd_idx;\n\tint rc;\n\n\tpend = container_of(priv, struct smc_wr_tx_pend, priv);\n\tpend->compl_requested = 1;\n\tpnd_idx = pend->idx;\n\tinit_completion(&link->wr_tx_compl[pnd_idx]);\n\n\trc = smc_wr_tx_send(link, priv);\n\tif (rc)\n\t\treturn rc;\n\t \n\trc = wait_for_completion_interruptible_timeout(\n\t\t\t\t\t&link->wr_tx_compl[pnd_idx], timeout);\n\tif (rc <= 0)\n\t\trc = -ENODATA;\n\tif (rc > 0)\n\t\trc = 0;\n\treturn rc;\n}\n\n \nint smc_wr_reg_send(struct smc_link *link, struct ib_mr *mr)\n{\n\tint rc;\n\n\tib_req_notify_cq(link->smcibdev->roce_cq_send,\n\t\t\t IB_CQ_NEXT_COMP | IB_CQ_REPORT_MISSED_EVENTS);\n\tlink->wr_reg_state = POSTED;\n\tlink->wr_reg.wr.wr_id = (u64)(uintptr_t)mr;\n\tlink->wr_reg.mr = mr;\n\tlink->wr_reg.key = mr->rkey;\n\trc = ib_post_send(link->roce_qp, &link->wr_reg.wr, NULL);\n\tif (rc)\n\t\treturn rc;\n\n\tpercpu_ref_get(&link->wr_reg_refs);\n\trc = wait_event_interruptible_timeout(link->wr_reg_wait,\n\t\t\t\t\t      (link->wr_reg_state != POSTED),\n\t\t\t\t\t      SMC_WR_REG_MR_WAIT_TIME);\n\tpercpu_ref_put(&link->wr_reg_refs);\n\tif (!rc) {\n\t\t \n\t\tsmcr_link_down_cond_sched(link);\n\t\treturn -EPIPE;\n\t}\n\tif (rc == -ERESTARTSYS)\n\t\treturn -EINTR;\n\tswitch (link->wr_reg_state) {\n\tcase CONFIRMED:\n\t\trc = 0;\n\t\tbreak;\n\tcase FAILED:\n\t\trc = -EIO;\n\t\tbreak;\n\tcase POSTED:\n\t\trc = -EPIPE;\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\n \n\nint smc_wr_rx_register_handler(struct smc_wr_rx_handler *handler)\n{\n\tstruct smc_wr_rx_handler *h_iter;\n\tint rc = 0;\n\n\tspin_lock(&smc_wr_rx_hash_lock);\n\thash_for_each_possible(smc_wr_rx_hash, h_iter, list, handler->type) {\n\t\tif (h_iter->type == handler->type) {\n\t\t\trc = -EEXIST;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\thash_add(smc_wr_rx_hash, &handler->list, handler->type);\nout_unlock:\n\tspin_unlock(&smc_wr_rx_hash_lock);\n\treturn rc;\n}\n\n \nstatic inline void smc_wr_rx_demultiplex(struct ib_wc *wc)\n{\n\tstruct smc_link *link = (struct smc_link *)wc->qp->qp_context;\n\tstruct smc_wr_rx_handler *handler;\n\tstruct smc_wr_rx_hdr *wr_rx;\n\tu64 temp_wr_id;\n\tu32 index;\n\n\tif (wc->byte_len < sizeof(*wr_rx))\n\t\treturn;  \n\ttemp_wr_id = wc->wr_id;\n\tindex = do_div(temp_wr_id, link->wr_rx_cnt);\n\twr_rx = (struct smc_wr_rx_hdr *)&link->wr_rx_bufs[index];\n\thash_for_each_possible(smc_wr_rx_hash, handler, list, wr_rx->type) {\n\t\tif (handler->type == wr_rx->type)\n\t\t\thandler->handler(wc, wr_rx);\n\t}\n}\n\nstatic inline void smc_wr_rx_process_cqes(struct ib_wc wc[], int num)\n{\n\tstruct smc_link *link;\n\tint i;\n\n\tfor (i = 0; i < num; i++) {\n\t\tlink = wc[i].qp->qp_context;\n\t\tlink->wr_rx_id_compl = wc[i].wr_id;\n\t\tif (wc[i].status == IB_WC_SUCCESS) {\n\t\t\tlink->wr_rx_tstamp = jiffies;\n\t\t\tsmc_wr_rx_demultiplex(&wc[i]);\n\t\t\tsmc_wr_rx_post(link);  \n\t\t} else {\n\t\t\t \n\t\t\tswitch (wc[i].status) {\n\t\t\tcase IB_WC_RETRY_EXC_ERR:\n\t\t\tcase IB_WC_RNR_RETRY_EXC_ERR:\n\t\t\tcase IB_WC_WR_FLUSH_ERR:\n\t\t\t\tsmcr_link_down_cond_sched(link);\n\t\t\t\tif (link->wr_rx_id_compl == link->wr_rx_id)\n\t\t\t\t\twake_up(&link->wr_rx_empty_wait);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tsmc_wr_rx_post(link);  \n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void smc_wr_rx_tasklet_fn(struct tasklet_struct *t)\n{\n\tstruct smc_ib_device *dev = from_tasklet(dev, t, recv_tasklet);\n\tstruct ib_wc wc[SMC_WR_MAX_POLL_CQE];\n\tint polled = 0;\n\tint rc;\n\nagain:\n\tpolled++;\n\tdo {\n\t\tmemset(&wc, 0, sizeof(wc));\n\t\trc = ib_poll_cq(dev->roce_cq_recv, SMC_WR_MAX_POLL_CQE, wc);\n\t\tif (polled == 1) {\n\t\t\tib_req_notify_cq(dev->roce_cq_recv,\n\t\t\t\t\t IB_CQ_SOLICITED_MASK\n\t\t\t\t\t | IB_CQ_REPORT_MISSED_EVENTS);\n\t\t}\n\t\tif (!rc)\n\t\t\tbreak;\n\t\tsmc_wr_rx_process_cqes(&wc[0], rc);\n\t} while (rc > 0);\n\tif (polled == 1)\n\t\tgoto again;\n}\n\nvoid smc_wr_rx_cq_handler(struct ib_cq *ib_cq, void *cq_context)\n{\n\tstruct smc_ib_device *dev = (struct smc_ib_device *)cq_context;\n\n\ttasklet_schedule(&dev->recv_tasklet);\n}\n\nint smc_wr_rx_post_init(struct smc_link *link)\n{\n\tu32 i;\n\tint rc = 0;\n\n\tfor (i = 0; i < link->wr_rx_cnt; i++)\n\t\trc = smc_wr_rx_post(link);\n\treturn rc;\n}\n\n \n\nvoid smc_wr_remember_qp_attr(struct smc_link *lnk)\n{\n\tstruct ib_qp_attr *attr = &lnk->qp_attr;\n\tstruct ib_qp_init_attr init_attr;\n\n\tmemset(attr, 0, sizeof(*attr));\n\tmemset(&init_attr, 0, sizeof(init_attr));\n\tib_query_qp(lnk->roce_qp, attr,\n\t\t    IB_QP_STATE |\n\t\t    IB_QP_CUR_STATE |\n\t\t    IB_QP_PKEY_INDEX |\n\t\t    IB_QP_PORT |\n\t\t    IB_QP_QKEY |\n\t\t    IB_QP_AV |\n\t\t    IB_QP_PATH_MTU |\n\t\t    IB_QP_TIMEOUT |\n\t\t    IB_QP_RETRY_CNT |\n\t\t    IB_QP_RNR_RETRY |\n\t\t    IB_QP_RQ_PSN |\n\t\t    IB_QP_ALT_PATH |\n\t\t    IB_QP_MIN_RNR_TIMER |\n\t\t    IB_QP_SQ_PSN |\n\t\t    IB_QP_PATH_MIG_STATE |\n\t\t    IB_QP_CAP |\n\t\t    IB_QP_DEST_QPN,\n\t\t    &init_attr);\n\n\tlnk->wr_tx_cnt = min_t(size_t, SMC_WR_BUF_CNT,\n\t\t\t       lnk->qp_attr.cap.max_send_wr);\n\tlnk->wr_rx_cnt = min_t(size_t, SMC_WR_BUF_CNT * 3,\n\t\t\t       lnk->qp_attr.cap.max_recv_wr);\n}\n\nstatic void smc_wr_init_sge(struct smc_link *lnk)\n{\n\tint sges_per_buf = (lnk->lgr->smc_version == SMC_V2) ? 2 : 1;\n\tbool send_inline = (lnk->qp_attr.cap.max_inline_data > SMC_WR_TX_SIZE);\n\tu32 i;\n\n\tfor (i = 0; i < lnk->wr_tx_cnt; i++) {\n\t\tlnk->wr_tx_sges[i].addr = send_inline ? (uintptr_t)(&lnk->wr_tx_bufs[i]) :\n\t\t\tlnk->wr_tx_dma_addr + i * SMC_WR_BUF_SIZE;\n\t\tlnk->wr_tx_sges[i].length = SMC_WR_TX_SIZE;\n\t\tlnk->wr_tx_sges[i].lkey = lnk->roce_pd->local_dma_lkey;\n\t\tlnk->wr_tx_rdma_sges[i].tx_rdma_sge[0].wr_tx_rdma_sge[0].lkey =\n\t\t\tlnk->roce_pd->local_dma_lkey;\n\t\tlnk->wr_tx_rdma_sges[i].tx_rdma_sge[0].wr_tx_rdma_sge[1].lkey =\n\t\t\tlnk->roce_pd->local_dma_lkey;\n\t\tlnk->wr_tx_rdma_sges[i].tx_rdma_sge[1].wr_tx_rdma_sge[0].lkey =\n\t\t\tlnk->roce_pd->local_dma_lkey;\n\t\tlnk->wr_tx_rdma_sges[i].tx_rdma_sge[1].wr_tx_rdma_sge[1].lkey =\n\t\t\tlnk->roce_pd->local_dma_lkey;\n\t\tlnk->wr_tx_ibs[i].next = NULL;\n\t\tlnk->wr_tx_ibs[i].sg_list = &lnk->wr_tx_sges[i];\n\t\tlnk->wr_tx_ibs[i].num_sge = 1;\n\t\tlnk->wr_tx_ibs[i].opcode = IB_WR_SEND;\n\t\tlnk->wr_tx_ibs[i].send_flags =\n\t\t\tIB_SEND_SIGNALED | IB_SEND_SOLICITED;\n\t\tif (send_inline)\n\t\t\tlnk->wr_tx_ibs[i].send_flags |= IB_SEND_INLINE;\n\t\tlnk->wr_tx_rdmas[i].wr_tx_rdma[0].wr.opcode = IB_WR_RDMA_WRITE;\n\t\tlnk->wr_tx_rdmas[i].wr_tx_rdma[1].wr.opcode = IB_WR_RDMA_WRITE;\n\t\tlnk->wr_tx_rdmas[i].wr_tx_rdma[0].wr.sg_list =\n\t\t\tlnk->wr_tx_rdma_sges[i].tx_rdma_sge[0].wr_tx_rdma_sge;\n\t\tlnk->wr_tx_rdmas[i].wr_tx_rdma[1].wr.sg_list =\n\t\t\tlnk->wr_tx_rdma_sges[i].tx_rdma_sge[1].wr_tx_rdma_sge;\n\t}\n\n\tif (lnk->lgr->smc_version == SMC_V2) {\n\t\tlnk->wr_tx_v2_sge->addr = lnk->wr_tx_v2_dma_addr;\n\t\tlnk->wr_tx_v2_sge->length = SMC_WR_BUF_V2_SIZE;\n\t\tlnk->wr_tx_v2_sge->lkey = lnk->roce_pd->local_dma_lkey;\n\n\t\tlnk->wr_tx_v2_ib->next = NULL;\n\t\tlnk->wr_tx_v2_ib->sg_list = lnk->wr_tx_v2_sge;\n\t\tlnk->wr_tx_v2_ib->num_sge = 1;\n\t\tlnk->wr_tx_v2_ib->opcode = IB_WR_SEND;\n\t\tlnk->wr_tx_v2_ib->send_flags =\n\t\t\tIB_SEND_SIGNALED | IB_SEND_SOLICITED;\n\t}\n\n\t \n\tfor (i = 0; i < lnk->wr_rx_cnt; i++) {\n\t\tint x = i * sges_per_buf;\n\n\t\tlnk->wr_rx_sges[x].addr =\n\t\t\tlnk->wr_rx_dma_addr + i * SMC_WR_BUF_SIZE;\n\t\tlnk->wr_rx_sges[x].length = SMC_WR_TX_SIZE;\n\t\tlnk->wr_rx_sges[x].lkey = lnk->roce_pd->local_dma_lkey;\n\t\tif (lnk->lgr->smc_version == SMC_V2) {\n\t\t\tlnk->wr_rx_sges[x + 1].addr =\n\t\t\t\t\tlnk->wr_rx_v2_dma_addr + SMC_WR_TX_SIZE;\n\t\t\tlnk->wr_rx_sges[x + 1].length =\n\t\t\t\t\tSMC_WR_BUF_V2_SIZE - SMC_WR_TX_SIZE;\n\t\t\tlnk->wr_rx_sges[x + 1].lkey =\n\t\t\t\t\tlnk->roce_pd->local_dma_lkey;\n\t\t}\n\t\tlnk->wr_rx_ibs[i].next = NULL;\n\t\tlnk->wr_rx_ibs[i].sg_list = &lnk->wr_rx_sges[x];\n\t\tlnk->wr_rx_ibs[i].num_sge = sges_per_buf;\n\t}\n\tlnk->wr_reg.wr.next = NULL;\n\tlnk->wr_reg.wr.num_sge = 0;\n\tlnk->wr_reg.wr.send_flags = IB_SEND_SIGNALED;\n\tlnk->wr_reg.wr.opcode = IB_WR_REG_MR;\n\tlnk->wr_reg.access = IB_ACCESS_LOCAL_WRITE | IB_ACCESS_REMOTE_WRITE;\n}\n\nvoid smc_wr_free_link(struct smc_link *lnk)\n{\n\tstruct ib_device *ibdev;\n\n\tif (!lnk->smcibdev)\n\t\treturn;\n\tibdev = lnk->smcibdev->ibdev;\n\n\tsmc_wr_drain_cq(lnk);\n\tsmc_wr_wakeup_reg_wait(lnk);\n\tsmc_wr_wakeup_tx_wait(lnk);\n\n\tsmc_wr_tx_wait_no_pending_sends(lnk);\n\tpercpu_ref_kill(&lnk->wr_reg_refs);\n\twait_for_completion(&lnk->reg_ref_comp);\n\tpercpu_ref_kill(&lnk->wr_tx_refs);\n\twait_for_completion(&lnk->tx_ref_comp);\n\n\tif (lnk->wr_rx_dma_addr) {\n\t\tib_dma_unmap_single(ibdev, lnk->wr_rx_dma_addr,\n\t\t\t\t    SMC_WR_BUF_SIZE * lnk->wr_rx_cnt,\n\t\t\t\t    DMA_FROM_DEVICE);\n\t\tlnk->wr_rx_dma_addr = 0;\n\t}\n\tif (lnk->wr_rx_v2_dma_addr) {\n\t\tib_dma_unmap_single(ibdev, lnk->wr_rx_v2_dma_addr,\n\t\t\t\t    SMC_WR_BUF_V2_SIZE,\n\t\t\t\t    DMA_FROM_DEVICE);\n\t\tlnk->wr_rx_v2_dma_addr = 0;\n\t}\n\tif (lnk->wr_tx_dma_addr) {\n\t\tib_dma_unmap_single(ibdev, lnk->wr_tx_dma_addr,\n\t\t\t\t    SMC_WR_BUF_SIZE * lnk->wr_tx_cnt,\n\t\t\t\t    DMA_TO_DEVICE);\n\t\tlnk->wr_tx_dma_addr = 0;\n\t}\n\tif (lnk->wr_tx_v2_dma_addr) {\n\t\tib_dma_unmap_single(ibdev, lnk->wr_tx_v2_dma_addr,\n\t\t\t\t    SMC_WR_BUF_V2_SIZE,\n\t\t\t\t    DMA_TO_DEVICE);\n\t\tlnk->wr_tx_v2_dma_addr = 0;\n\t}\n}\n\nvoid smc_wr_free_lgr_mem(struct smc_link_group *lgr)\n{\n\tif (lgr->smc_version < SMC_V2)\n\t\treturn;\n\n\tkfree(lgr->wr_rx_buf_v2);\n\tlgr->wr_rx_buf_v2 = NULL;\n\tkfree(lgr->wr_tx_buf_v2);\n\tlgr->wr_tx_buf_v2 = NULL;\n}\n\nvoid smc_wr_free_link_mem(struct smc_link *lnk)\n{\n\tkfree(lnk->wr_tx_v2_ib);\n\tlnk->wr_tx_v2_ib = NULL;\n\tkfree(lnk->wr_tx_v2_sge);\n\tlnk->wr_tx_v2_sge = NULL;\n\tkfree(lnk->wr_tx_v2_pend);\n\tlnk->wr_tx_v2_pend = NULL;\n\tkfree(lnk->wr_tx_compl);\n\tlnk->wr_tx_compl = NULL;\n\tkfree(lnk->wr_tx_pends);\n\tlnk->wr_tx_pends = NULL;\n\tbitmap_free(lnk->wr_tx_mask);\n\tlnk->wr_tx_mask = NULL;\n\tkfree(lnk->wr_tx_sges);\n\tlnk->wr_tx_sges = NULL;\n\tkfree(lnk->wr_tx_rdma_sges);\n\tlnk->wr_tx_rdma_sges = NULL;\n\tkfree(lnk->wr_rx_sges);\n\tlnk->wr_rx_sges = NULL;\n\tkfree(lnk->wr_tx_rdmas);\n\tlnk->wr_tx_rdmas = NULL;\n\tkfree(lnk->wr_rx_ibs);\n\tlnk->wr_rx_ibs = NULL;\n\tkfree(lnk->wr_tx_ibs);\n\tlnk->wr_tx_ibs = NULL;\n\tkfree(lnk->wr_tx_bufs);\n\tlnk->wr_tx_bufs = NULL;\n\tkfree(lnk->wr_rx_bufs);\n\tlnk->wr_rx_bufs = NULL;\n}\n\nint smc_wr_alloc_lgr_mem(struct smc_link_group *lgr)\n{\n\tif (lgr->smc_version < SMC_V2)\n\t\treturn 0;\n\n\tlgr->wr_rx_buf_v2 = kzalloc(SMC_WR_BUF_V2_SIZE, GFP_KERNEL);\n\tif (!lgr->wr_rx_buf_v2)\n\t\treturn -ENOMEM;\n\tlgr->wr_tx_buf_v2 = kzalloc(SMC_WR_BUF_V2_SIZE, GFP_KERNEL);\n\tif (!lgr->wr_tx_buf_v2) {\n\t\tkfree(lgr->wr_rx_buf_v2);\n\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\nint smc_wr_alloc_link_mem(struct smc_link *link)\n{\n\tint sges_per_buf = link->lgr->smc_version == SMC_V2 ? 2 : 1;\n\n\t \n\tlink->wr_tx_bufs = kcalloc(SMC_WR_BUF_CNT, SMC_WR_BUF_SIZE, GFP_KERNEL);\n\tif (!link->wr_tx_bufs)\n\t\tgoto no_mem;\n\tlink->wr_rx_bufs = kcalloc(SMC_WR_BUF_CNT * 3, SMC_WR_BUF_SIZE,\n\t\t\t\t   GFP_KERNEL);\n\tif (!link->wr_rx_bufs)\n\t\tgoto no_mem_wr_tx_bufs;\n\tlink->wr_tx_ibs = kcalloc(SMC_WR_BUF_CNT, sizeof(link->wr_tx_ibs[0]),\n\t\t\t\t  GFP_KERNEL);\n\tif (!link->wr_tx_ibs)\n\t\tgoto no_mem_wr_rx_bufs;\n\tlink->wr_rx_ibs = kcalloc(SMC_WR_BUF_CNT * 3,\n\t\t\t\t  sizeof(link->wr_rx_ibs[0]),\n\t\t\t\t  GFP_KERNEL);\n\tif (!link->wr_rx_ibs)\n\t\tgoto no_mem_wr_tx_ibs;\n\tlink->wr_tx_rdmas = kcalloc(SMC_WR_BUF_CNT,\n\t\t\t\t    sizeof(link->wr_tx_rdmas[0]),\n\t\t\t\t    GFP_KERNEL);\n\tif (!link->wr_tx_rdmas)\n\t\tgoto no_mem_wr_rx_ibs;\n\tlink->wr_tx_rdma_sges = kcalloc(SMC_WR_BUF_CNT,\n\t\t\t\t\tsizeof(link->wr_tx_rdma_sges[0]),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!link->wr_tx_rdma_sges)\n\t\tgoto no_mem_wr_tx_rdmas;\n\tlink->wr_tx_sges = kcalloc(SMC_WR_BUF_CNT, sizeof(link->wr_tx_sges[0]),\n\t\t\t\t   GFP_KERNEL);\n\tif (!link->wr_tx_sges)\n\t\tgoto no_mem_wr_tx_rdma_sges;\n\tlink->wr_rx_sges = kcalloc(SMC_WR_BUF_CNT * 3,\n\t\t\t\t   sizeof(link->wr_rx_sges[0]) * sges_per_buf,\n\t\t\t\t   GFP_KERNEL);\n\tif (!link->wr_rx_sges)\n\t\tgoto no_mem_wr_tx_sges;\n\tlink->wr_tx_mask = bitmap_zalloc(SMC_WR_BUF_CNT, GFP_KERNEL);\n\tif (!link->wr_tx_mask)\n\t\tgoto no_mem_wr_rx_sges;\n\tlink->wr_tx_pends = kcalloc(SMC_WR_BUF_CNT,\n\t\t\t\t    sizeof(link->wr_tx_pends[0]),\n\t\t\t\t    GFP_KERNEL);\n\tif (!link->wr_tx_pends)\n\t\tgoto no_mem_wr_tx_mask;\n\tlink->wr_tx_compl = kcalloc(SMC_WR_BUF_CNT,\n\t\t\t\t    sizeof(link->wr_tx_compl[0]),\n\t\t\t\t    GFP_KERNEL);\n\tif (!link->wr_tx_compl)\n\t\tgoto no_mem_wr_tx_pends;\n\n\tif (link->lgr->smc_version == SMC_V2) {\n\t\tlink->wr_tx_v2_ib = kzalloc(sizeof(*link->wr_tx_v2_ib),\n\t\t\t\t\t    GFP_KERNEL);\n\t\tif (!link->wr_tx_v2_ib)\n\t\t\tgoto no_mem_tx_compl;\n\t\tlink->wr_tx_v2_sge = kzalloc(sizeof(*link->wr_tx_v2_sge),\n\t\t\t\t\t     GFP_KERNEL);\n\t\tif (!link->wr_tx_v2_sge)\n\t\t\tgoto no_mem_v2_ib;\n\t\tlink->wr_tx_v2_pend = kzalloc(sizeof(*link->wr_tx_v2_pend),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!link->wr_tx_v2_pend)\n\t\t\tgoto no_mem_v2_sge;\n\t}\n\treturn 0;\n\nno_mem_v2_sge:\n\tkfree(link->wr_tx_v2_sge);\nno_mem_v2_ib:\n\tkfree(link->wr_tx_v2_ib);\nno_mem_tx_compl:\n\tkfree(link->wr_tx_compl);\nno_mem_wr_tx_pends:\n\tkfree(link->wr_tx_pends);\nno_mem_wr_tx_mask:\n\tkfree(link->wr_tx_mask);\nno_mem_wr_rx_sges:\n\tkfree(link->wr_rx_sges);\nno_mem_wr_tx_sges:\n\tkfree(link->wr_tx_sges);\nno_mem_wr_tx_rdma_sges:\n\tkfree(link->wr_tx_rdma_sges);\nno_mem_wr_tx_rdmas:\n\tkfree(link->wr_tx_rdmas);\nno_mem_wr_rx_ibs:\n\tkfree(link->wr_rx_ibs);\nno_mem_wr_tx_ibs:\n\tkfree(link->wr_tx_ibs);\nno_mem_wr_rx_bufs:\n\tkfree(link->wr_rx_bufs);\nno_mem_wr_tx_bufs:\n\tkfree(link->wr_tx_bufs);\nno_mem:\n\treturn -ENOMEM;\n}\n\nvoid smc_wr_remove_dev(struct smc_ib_device *smcibdev)\n{\n\ttasklet_kill(&smcibdev->recv_tasklet);\n\ttasklet_kill(&smcibdev->send_tasklet);\n}\n\nvoid smc_wr_add_dev(struct smc_ib_device *smcibdev)\n{\n\ttasklet_setup(&smcibdev->recv_tasklet, smc_wr_rx_tasklet_fn);\n\ttasklet_setup(&smcibdev->send_tasklet, smc_wr_tx_tasklet_fn);\n}\n\nstatic void smcr_wr_tx_refs_free(struct percpu_ref *ref)\n{\n\tstruct smc_link *lnk = container_of(ref, struct smc_link, wr_tx_refs);\n\n\tcomplete(&lnk->tx_ref_comp);\n}\n\nstatic void smcr_wr_reg_refs_free(struct percpu_ref *ref)\n{\n\tstruct smc_link *lnk = container_of(ref, struct smc_link, wr_reg_refs);\n\n\tcomplete(&lnk->reg_ref_comp);\n}\n\nint smc_wr_create_link(struct smc_link *lnk)\n{\n\tstruct ib_device *ibdev = lnk->smcibdev->ibdev;\n\tint rc = 0;\n\n\tsmc_wr_tx_set_wr_id(&lnk->wr_tx_id, 0);\n\tlnk->wr_rx_id = 0;\n\tlnk->wr_rx_dma_addr = ib_dma_map_single(\n\t\tibdev, lnk->wr_rx_bufs,\tSMC_WR_BUF_SIZE * lnk->wr_rx_cnt,\n\t\tDMA_FROM_DEVICE);\n\tif (ib_dma_mapping_error(ibdev, lnk->wr_rx_dma_addr)) {\n\t\tlnk->wr_rx_dma_addr = 0;\n\t\trc = -EIO;\n\t\tgoto out;\n\t}\n\tif (lnk->lgr->smc_version == SMC_V2) {\n\t\tlnk->wr_rx_v2_dma_addr = ib_dma_map_single(ibdev,\n\t\t\tlnk->lgr->wr_rx_buf_v2, SMC_WR_BUF_V2_SIZE,\n\t\t\tDMA_FROM_DEVICE);\n\t\tif (ib_dma_mapping_error(ibdev, lnk->wr_rx_v2_dma_addr)) {\n\t\t\tlnk->wr_rx_v2_dma_addr = 0;\n\t\t\trc = -EIO;\n\t\t\tgoto dma_unmap;\n\t\t}\n\t\tlnk->wr_tx_v2_dma_addr = ib_dma_map_single(ibdev,\n\t\t\tlnk->lgr->wr_tx_buf_v2, SMC_WR_BUF_V2_SIZE,\n\t\t\tDMA_TO_DEVICE);\n\t\tif (ib_dma_mapping_error(ibdev, lnk->wr_tx_v2_dma_addr)) {\n\t\t\tlnk->wr_tx_v2_dma_addr = 0;\n\t\t\trc = -EIO;\n\t\t\tgoto dma_unmap;\n\t\t}\n\t}\n\tlnk->wr_tx_dma_addr = ib_dma_map_single(\n\t\tibdev, lnk->wr_tx_bufs,\tSMC_WR_BUF_SIZE * lnk->wr_tx_cnt,\n\t\tDMA_TO_DEVICE);\n\tif (ib_dma_mapping_error(ibdev, lnk->wr_tx_dma_addr)) {\n\t\trc = -EIO;\n\t\tgoto dma_unmap;\n\t}\n\tsmc_wr_init_sge(lnk);\n\tbitmap_zero(lnk->wr_tx_mask, SMC_WR_BUF_CNT);\n\tinit_waitqueue_head(&lnk->wr_tx_wait);\n\trc = percpu_ref_init(&lnk->wr_tx_refs, smcr_wr_tx_refs_free, 0, GFP_KERNEL);\n\tif (rc)\n\t\tgoto dma_unmap;\n\tinit_completion(&lnk->tx_ref_comp);\n\tinit_waitqueue_head(&lnk->wr_reg_wait);\n\trc = percpu_ref_init(&lnk->wr_reg_refs, smcr_wr_reg_refs_free, 0, GFP_KERNEL);\n\tif (rc)\n\t\tgoto dma_unmap;\n\tinit_completion(&lnk->reg_ref_comp);\n\tinit_waitqueue_head(&lnk->wr_rx_empty_wait);\n\treturn rc;\n\ndma_unmap:\n\tif (lnk->wr_rx_v2_dma_addr) {\n\t\tib_dma_unmap_single(ibdev, lnk->wr_rx_v2_dma_addr,\n\t\t\t\t    SMC_WR_BUF_V2_SIZE,\n\t\t\t\t    DMA_FROM_DEVICE);\n\t\tlnk->wr_rx_v2_dma_addr = 0;\n\t}\n\tif (lnk->wr_tx_v2_dma_addr) {\n\t\tib_dma_unmap_single(ibdev, lnk->wr_tx_v2_dma_addr,\n\t\t\t\t    SMC_WR_BUF_V2_SIZE,\n\t\t\t\t    DMA_TO_DEVICE);\n\t\tlnk->wr_tx_v2_dma_addr = 0;\n\t}\n\tib_dma_unmap_single(ibdev, lnk->wr_rx_dma_addr,\n\t\t\t    SMC_WR_BUF_SIZE * lnk->wr_rx_cnt,\n\t\t\t    DMA_FROM_DEVICE);\n\tlnk->wr_rx_dma_addr = 0;\nout:\n\treturn rc;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}