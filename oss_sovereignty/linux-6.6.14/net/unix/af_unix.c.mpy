{
  "module_name": "af_unix.c",
  "hash_id": "97e3f79b87082031d04dc30d66a4b6547c7d48f7b214cfbeb806e789f1b26eac",
  "original_prompt": "Ingested from linux-6.6.14/net/unix/af_unix.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/signal.h>\n#include <linux/sched/signal.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/stat.h>\n#include <linux/dcache.h>\n#include <linux/namei.h>\n#include <linux/socket.h>\n#include <linux/un.h>\n#include <linux/fcntl.h>\n#include <linux/filter.h>\n#include <linux/termios.h>\n#include <linux/sockios.h>\n#include <linux/net.h>\n#include <linux/in.h>\n#include <linux/fs.h>\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/skbuff.h>\n#include <linux/netdevice.h>\n#include <net/net_namespace.h>\n#include <net/sock.h>\n#include <net/tcp_states.h>\n#include <net/af_unix.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <net/scm.h>\n#include <linux/init.h>\n#include <linux/poll.h>\n#include <linux/rtnetlink.h>\n#include <linux/mount.h>\n#include <net/checksum.h>\n#include <linux/security.h>\n#include <linux/splice.h>\n#include <linux/freezer.h>\n#include <linux/file.h>\n#include <linux/btf_ids.h>\n\n#include \"scm.h\"\n\nstatic atomic_long_t unix_nr_socks;\nstatic struct hlist_head bsd_socket_buckets[UNIX_HASH_SIZE / 2];\nstatic spinlock_t bsd_socket_locks[UNIX_HASH_SIZE / 2];\n\n \n\nstatic unsigned int unix_unbound_hash(struct sock *sk)\n{\n\tunsigned long hash = (unsigned long)sk;\n\n\thash ^= hash >> 16;\n\thash ^= hash >> 8;\n\thash ^= sk->sk_type;\n\n\treturn hash & UNIX_HASH_MOD;\n}\n\nstatic unsigned int unix_bsd_hash(struct inode *i)\n{\n\treturn i->i_ino & UNIX_HASH_MOD;\n}\n\nstatic unsigned int unix_abstract_hash(struct sockaddr_un *sunaddr,\n\t\t\t\t       int addr_len, int type)\n{\n\t__wsum csum = csum_partial(sunaddr, addr_len, 0);\n\tunsigned int hash;\n\n\thash = (__force unsigned int)csum_fold(csum);\n\thash ^= hash >> 8;\n\thash ^= type;\n\n\treturn UNIX_HASH_MOD + 1 + (hash & UNIX_HASH_MOD);\n}\n\nstatic void unix_table_double_lock(struct net *net,\n\t\t\t\t   unsigned int hash1, unsigned int hash2)\n{\n\tif (hash1 == hash2) {\n\t\tspin_lock(&net->unx.table.locks[hash1]);\n\t\treturn;\n\t}\n\n\tif (hash1 > hash2)\n\t\tswap(hash1, hash2);\n\n\tspin_lock(&net->unx.table.locks[hash1]);\n\tspin_lock_nested(&net->unx.table.locks[hash2], SINGLE_DEPTH_NESTING);\n}\n\nstatic void unix_table_double_unlock(struct net *net,\n\t\t\t\t     unsigned int hash1, unsigned int hash2)\n{\n\tif (hash1 == hash2) {\n\t\tspin_unlock(&net->unx.table.locks[hash1]);\n\t\treturn;\n\t}\n\n\tspin_unlock(&net->unx.table.locks[hash1]);\n\tspin_unlock(&net->unx.table.locks[hash2]);\n}\n\n#ifdef CONFIG_SECURITY_NETWORK\nstatic void unix_get_secdata(struct scm_cookie *scm, struct sk_buff *skb)\n{\n\tUNIXCB(skb).secid = scm->secid;\n}\n\nstatic inline void unix_set_secdata(struct scm_cookie *scm, struct sk_buff *skb)\n{\n\tscm->secid = UNIXCB(skb).secid;\n}\n\nstatic inline bool unix_secdata_eq(struct scm_cookie *scm, struct sk_buff *skb)\n{\n\treturn (scm->secid == UNIXCB(skb).secid);\n}\n#else\nstatic inline void unix_get_secdata(struct scm_cookie *scm, struct sk_buff *skb)\n{ }\n\nstatic inline void unix_set_secdata(struct scm_cookie *scm, struct sk_buff *skb)\n{ }\n\nstatic inline bool unix_secdata_eq(struct scm_cookie *scm, struct sk_buff *skb)\n{\n\treturn true;\n}\n#endif  \n\nstatic inline int unix_our_peer(struct sock *sk, struct sock *osk)\n{\n\treturn unix_peer(osk) == sk;\n}\n\nstatic inline int unix_may_send(struct sock *sk, struct sock *osk)\n{\n\treturn unix_peer(osk) == NULL || unix_our_peer(sk, osk);\n}\n\nstatic inline int unix_recvq_full(const struct sock *sk)\n{\n\treturn skb_queue_len(&sk->sk_receive_queue) > sk->sk_max_ack_backlog;\n}\n\nstatic inline int unix_recvq_full_lockless(const struct sock *sk)\n{\n\treturn skb_queue_len_lockless(&sk->sk_receive_queue) >\n\t\tREAD_ONCE(sk->sk_max_ack_backlog);\n}\n\nstruct sock *unix_peer_get(struct sock *s)\n{\n\tstruct sock *peer;\n\n\tunix_state_lock(s);\n\tpeer = unix_peer(s);\n\tif (peer)\n\t\tsock_hold(peer);\n\tunix_state_unlock(s);\n\treturn peer;\n}\nEXPORT_SYMBOL_GPL(unix_peer_get);\n\nstatic struct unix_address *unix_create_addr(struct sockaddr_un *sunaddr,\n\t\t\t\t\t     int addr_len)\n{\n\tstruct unix_address *addr;\n\n\taddr = kmalloc(sizeof(*addr) + addr_len, GFP_KERNEL);\n\tif (!addr)\n\t\treturn NULL;\n\n\trefcount_set(&addr->refcnt, 1);\n\taddr->len = addr_len;\n\tmemcpy(addr->name, sunaddr, addr_len);\n\n\treturn addr;\n}\n\nstatic inline void unix_release_addr(struct unix_address *addr)\n{\n\tif (refcount_dec_and_test(&addr->refcnt))\n\t\tkfree(addr);\n}\n\n \n\nstatic int unix_validate_addr(struct sockaddr_un *sunaddr, int addr_len)\n{\n\tif (addr_len <= offsetof(struct sockaddr_un, sun_path) ||\n\t    addr_len > sizeof(*sunaddr))\n\t\treturn -EINVAL;\n\n\tif (sunaddr->sun_family != AF_UNIX)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int unix_mkname_bsd(struct sockaddr_un *sunaddr, int addr_len)\n{\n\tstruct sockaddr_storage *addr = (struct sockaddr_storage *)sunaddr;\n\tshort offset = offsetof(struct sockaddr_storage, __data);\n\n\tBUILD_BUG_ON(offset != offsetof(struct sockaddr_un, sun_path));\n\n\t \n\taddr->__data[addr_len - offset] = 0;\n\n\t \n\treturn strlen(addr->__data) + offset + 1;\n}\n\nstatic void __unix_remove_socket(struct sock *sk)\n{\n\tsk_del_node_init(sk);\n}\n\nstatic void __unix_insert_socket(struct net *net, struct sock *sk)\n{\n\tDEBUG_NET_WARN_ON_ONCE(!sk_unhashed(sk));\n\tsk_add_node(sk, &net->unx.table.buckets[sk->sk_hash]);\n}\n\nstatic void __unix_set_addr_hash(struct net *net, struct sock *sk,\n\t\t\t\t struct unix_address *addr, unsigned int hash)\n{\n\t__unix_remove_socket(sk);\n\tsmp_store_release(&unix_sk(sk)->addr, addr);\n\n\tsk->sk_hash = hash;\n\t__unix_insert_socket(net, sk);\n}\n\nstatic void unix_remove_socket(struct net *net, struct sock *sk)\n{\n\tspin_lock(&net->unx.table.locks[sk->sk_hash]);\n\t__unix_remove_socket(sk);\n\tspin_unlock(&net->unx.table.locks[sk->sk_hash]);\n}\n\nstatic void unix_insert_unbound_socket(struct net *net, struct sock *sk)\n{\n\tspin_lock(&net->unx.table.locks[sk->sk_hash]);\n\t__unix_insert_socket(net, sk);\n\tspin_unlock(&net->unx.table.locks[sk->sk_hash]);\n}\n\nstatic void unix_insert_bsd_socket(struct sock *sk)\n{\n\tspin_lock(&bsd_socket_locks[sk->sk_hash]);\n\tsk_add_bind_node(sk, &bsd_socket_buckets[sk->sk_hash]);\n\tspin_unlock(&bsd_socket_locks[sk->sk_hash]);\n}\n\nstatic void unix_remove_bsd_socket(struct sock *sk)\n{\n\tif (!hlist_unhashed(&sk->sk_bind_node)) {\n\t\tspin_lock(&bsd_socket_locks[sk->sk_hash]);\n\t\t__sk_del_bind_node(sk);\n\t\tspin_unlock(&bsd_socket_locks[sk->sk_hash]);\n\n\t\tsk_node_init(&sk->sk_bind_node);\n\t}\n}\n\nstatic struct sock *__unix_find_socket_byname(struct net *net,\n\t\t\t\t\t      struct sockaddr_un *sunname,\n\t\t\t\t\t      int len, unsigned int hash)\n{\n\tstruct sock *s;\n\n\tsk_for_each(s, &net->unx.table.buckets[hash]) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tif (u->addr->len == len &&\n\t\t    !memcmp(u->addr->name, sunname, len))\n\t\t\treturn s;\n\t}\n\treturn NULL;\n}\n\nstatic inline struct sock *unix_find_socket_byname(struct net *net,\n\t\t\t\t\t\t   struct sockaddr_un *sunname,\n\t\t\t\t\t\t   int len, unsigned int hash)\n{\n\tstruct sock *s;\n\n\tspin_lock(&net->unx.table.locks[hash]);\n\ts = __unix_find_socket_byname(net, sunname, len, hash);\n\tif (s)\n\t\tsock_hold(s);\n\tspin_unlock(&net->unx.table.locks[hash]);\n\treturn s;\n}\n\nstatic struct sock *unix_find_socket_byinode(struct inode *i)\n{\n\tunsigned int hash = unix_bsd_hash(i);\n\tstruct sock *s;\n\n\tspin_lock(&bsd_socket_locks[hash]);\n\tsk_for_each_bound(s, &bsd_socket_buckets[hash]) {\n\t\tstruct dentry *dentry = unix_sk(s)->path.dentry;\n\n\t\tif (dentry && d_backing_inode(dentry) == i) {\n\t\t\tsock_hold(s);\n\t\t\tspin_unlock(&bsd_socket_locks[hash]);\n\t\t\treturn s;\n\t\t}\n\t}\n\tspin_unlock(&bsd_socket_locks[hash]);\n\treturn NULL;\n}\n\n \n\nstatic int unix_dgram_peer_wake_relay(wait_queue_entry_t *q, unsigned mode, int flags,\n\t\t\t\t      void *key)\n{\n\tstruct unix_sock *u;\n\twait_queue_head_t *u_sleep;\n\n\tu = container_of(q, struct unix_sock, peer_wake);\n\n\t__remove_wait_queue(&unix_sk(u->peer_wake.private)->peer_wait,\n\t\t\t    q);\n\tu->peer_wake.private = NULL;\n\n\t \n\tu_sleep = sk_sleep(&u->sk);\n\tif (u_sleep)\n\t\twake_up_interruptible_poll(u_sleep, key_to_poll(key));\n\n\treturn 0;\n}\n\nstatic int unix_dgram_peer_wake_connect(struct sock *sk, struct sock *other)\n{\n\tstruct unix_sock *u, *u_other;\n\tint rc;\n\n\tu = unix_sk(sk);\n\tu_other = unix_sk(other);\n\trc = 0;\n\tspin_lock(&u_other->peer_wait.lock);\n\n\tif (!u->peer_wake.private) {\n\t\tu->peer_wake.private = other;\n\t\t__add_wait_queue(&u_other->peer_wait, &u->peer_wake);\n\n\t\trc = 1;\n\t}\n\n\tspin_unlock(&u_other->peer_wait.lock);\n\treturn rc;\n}\n\nstatic void unix_dgram_peer_wake_disconnect(struct sock *sk,\n\t\t\t\t\t    struct sock *other)\n{\n\tstruct unix_sock *u, *u_other;\n\n\tu = unix_sk(sk);\n\tu_other = unix_sk(other);\n\tspin_lock(&u_other->peer_wait.lock);\n\n\tif (u->peer_wake.private == other) {\n\t\t__remove_wait_queue(&u_other->peer_wait, &u->peer_wake);\n\t\tu->peer_wake.private = NULL;\n\t}\n\n\tspin_unlock(&u_other->peer_wait.lock);\n}\n\nstatic void unix_dgram_peer_wake_disconnect_wakeup(struct sock *sk,\n\t\t\t\t\t\t   struct sock *other)\n{\n\tunix_dgram_peer_wake_disconnect(sk, other);\n\twake_up_interruptible_poll(sk_sleep(sk),\n\t\t\t\t   EPOLLOUT |\n\t\t\t\t   EPOLLWRNORM |\n\t\t\t\t   EPOLLWRBAND);\n}\n\n \nstatic int unix_dgram_peer_wake_me(struct sock *sk, struct sock *other)\n{\n\tint connected;\n\n\tconnected = unix_dgram_peer_wake_connect(sk, other);\n\n\t \n\tif (unix_recvq_full_lockless(other) && !sock_flag(other, SOCK_DEAD))\n\t\treturn 1;\n\n\tif (connected)\n\t\tunix_dgram_peer_wake_disconnect(sk, other);\n\n\treturn 0;\n}\n\nstatic int unix_writable(const struct sock *sk)\n{\n\treturn sk->sk_state != TCP_LISTEN &&\n\t       (refcount_read(&sk->sk_wmem_alloc) << 2) <= sk->sk_sndbuf;\n}\n\nstatic void unix_write_space(struct sock *sk)\n{\n\tstruct socket_wq *wq;\n\n\trcu_read_lock();\n\tif (unix_writable(sk)) {\n\t\twq = rcu_dereference(sk->sk_wq);\n\t\tif (skwq_has_sleeper(wq))\n\t\t\twake_up_interruptible_sync_poll(&wq->wait,\n\t\t\t\tEPOLLOUT | EPOLLWRNORM | EPOLLWRBAND);\n\t\tsk_wake_async(sk, SOCK_WAKE_SPACE, POLL_OUT);\n\t}\n\trcu_read_unlock();\n}\n\n \nstatic void unix_dgram_disconnected(struct sock *sk, struct sock *other)\n{\n\tif (!skb_queue_empty(&sk->sk_receive_queue)) {\n\t\tskb_queue_purge(&sk->sk_receive_queue);\n\t\twake_up_interruptible_all(&unix_sk(sk)->peer_wait);\n\n\t\t \n\t\tif (!sock_flag(other, SOCK_DEAD) && unix_peer(other) == sk) {\n\t\t\tWRITE_ONCE(other->sk_err, ECONNRESET);\n\t\t\tsk_error_report(other);\n\t\t}\n\t}\n\tother->sk_state = TCP_CLOSE;\n}\n\nstatic void unix_sock_destructor(struct sock *sk)\n{\n\tstruct unix_sock *u = unix_sk(sk);\n\n\tskb_queue_purge(&sk->sk_receive_queue);\n\n\tDEBUG_NET_WARN_ON_ONCE(refcount_read(&sk->sk_wmem_alloc));\n\tDEBUG_NET_WARN_ON_ONCE(!sk_unhashed(sk));\n\tDEBUG_NET_WARN_ON_ONCE(sk->sk_socket);\n\tif (!sock_flag(sk, SOCK_DEAD)) {\n\t\tpr_info(\"Attempt to release alive unix socket: %p\\n\", sk);\n\t\treturn;\n\t}\n\n\tif (u->addr)\n\t\tunix_release_addr(u->addr);\n\n\tatomic_long_dec(&unix_nr_socks);\n\tsock_prot_inuse_add(sock_net(sk), sk->sk_prot, -1);\n#ifdef UNIX_REFCNT_DEBUG\n\tpr_debug(\"UNIX %p is destroyed, %ld are still alive.\\n\", sk,\n\t\tatomic_long_read(&unix_nr_socks));\n#endif\n}\n\nstatic void unix_release_sock(struct sock *sk, int embrion)\n{\n\tstruct unix_sock *u = unix_sk(sk);\n\tstruct sock *skpair;\n\tstruct sk_buff *skb;\n\tstruct path path;\n\tint state;\n\n\tunix_remove_socket(sock_net(sk), sk);\n\tunix_remove_bsd_socket(sk);\n\n\t \n\tunix_state_lock(sk);\n\tsock_orphan(sk);\n\tWRITE_ONCE(sk->sk_shutdown, SHUTDOWN_MASK);\n\tpath\t     = u->path;\n\tu->path.dentry = NULL;\n\tu->path.mnt = NULL;\n\tstate = sk->sk_state;\n\tsk->sk_state = TCP_CLOSE;\n\n\tskpair = unix_peer(sk);\n\tunix_peer(sk) = NULL;\n\n\tunix_state_unlock(sk);\n\n#if IS_ENABLED(CONFIG_AF_UNIX_OOB)\n\tif (u->oob_skb) {\n\t\tkfree_skb(u->oob_skb);\n\t\tu->oob_skb = NULL;\n\t}\n#endif\n\n\twake_up_interruptible_all(&u->peer_wait);\n\n\tif (skpair != NULL) {\n\t\tif (sk->sk_type == SOCK_STREAM || sk->sk_type == SOCK_SEQPACKET) {\n\t\t\tunix_state_lock(skpair);\n\t\t\t \n\t\t\tWRITE_ONCE(skpair->sk_shutdown, SHUTDOWN_MASK);\n\t\t\tif (!skb_queue_empty(&sk->sk_receive_queue) || embrion)\n\t\t\t\tWRITE_ONCE(skpair->sk_err, ECONNRESET);\n\t\t\tunix_state_unlock(skpair);\n\t\t\tskpair->sk_state_change(skpair);\n\t\t\tsk_wake_async(skpair, SOCK_WAKE_WAITD, POLL_HUP);\n\t\t}\n\n\t\tunix_dgram_peer_wake_disconnect(sk, skpair);\n\t\tsock_put(skpair);  \n\t}\n\n\t \n\n\twhile ((skb = skb_dequeue(&sk->sk_receive_queue)) != NULL) {\n\t\tif (state == TCP_LISTEN)\n\t\t\tunix_release_sock(skb->sk, 1);\n\t\t \n\t\tUNIXCB(skb).consumed = skb->len;\n\t\tkfree_skb(skb);\n\t}\n\n\tif (path.dentry)\n\t\tpath_put(&path);\n\n\tsock_put(sk);\n\n\t \n\n\t \n\n\tif (READ_ONCE(unix_tot_inflight))\n\t\tunix_gc();\t\t \n}\n\nstatic void init_peercred(struct sock *sk)\n{\n\tconst struct cred *old_cred;\n\tstruct pid *old_pid;\n\n\tspin_lock(&sk->sk_peer_lock);\n\told_pid = sk->sk_peer_pid;\n\told_cred = sk->sk_peer_cred;\n\tsk->sk_peer_pid  = get_pid(task_tgid(current));\n\tsk->sk_peer_cred = get_current_cred();\n\tspin_unlock(&sk->sk_peer_lock);\n\n\tput_pid(old_pid);\n\tput_cred(old_cred);\n}\n\nstatic void copy_peercred(struct sock *sk, struct sock *peersk)\n{\n\tconst struct cred *old_cred;\n\tstruct pid *old_pid;\n\n\tif (sk < peersk) {\n\t\tspin_lock(&sk->sk_peer_lock);\n\t\tspin_lock_nested(&peersk->sk_peer_lock, SINGLE_DEPTH_NESTING);\n\t} else {\n\t\tspin_lock(&peersk->sk_peer_lock);\n\t\tspin_lock_nested(&sk->sk_peer_lock, SINGLE_DEPTH_NESTING);\n\t}\n\told_pid = sk->sk_peer_pid;\n\told_cred = sk->sk_peer_cred;\n\tsk->sk_peer_pid  = get_pid(peersk->sk_peer_pid);\n\tsk->sk_peer_cred = get_cred(peersk->sk_peer_cred);\n\n\tspin_unlock(&sk->sk_peer_lock);\n\tspin_unlock(&peersk->sk_peer_lock);\n\n\tput_pid(old_pid);\n\tput_cred(old_cred);\n}\n\nstatic int unix_listen(struct socket *sock, int backlog)\n{\n\tint err;\n\tstruct sock *sk = sock->sk;\n\tstruct unix_sock *u = unix_sk(sk);\n\n\terr = -EOPNOTSUPP;\n\tif (sock->type != SOCK_STREAM && sock->type != SOCK_SEQPACKET)\n\t\tgoto out;\t \n\terr = -EINVAL;\n\tif (!u->addr)\n\t\tgoto out;\t \n\tunix_state_lock(sk);\n\tif (sk->sk_state != TCP_CLOSE && sk->sk_state != TCP_LISTEN)\n\t\tgoto out_unlock;\n\tif (backlog > sk->sk_max_ack_backlog)\n\t\twake_up_interruptible_all(&u->peer_wait);\n\tsk->sk_max_ack_backlog\t= backlog;\n\tsk->sk_state\t\t= TCP_LISTEN;\n\t \n\tinit_peercred(sk);\n\terr = 0;\n\nout_unlock:\n\tunix_state_unlock(sk);\nout:\n\treturn err;\n}\n\nstatic int unix_release(struct socket *);\nstatic int unix_bind(struct socket *, struct sockaddr *, int);\nstatic int unix_stream_connect(struct socket *, struct sockaddr *,\n\t\t\t       int addr_len, int flags);\nstatic int unix_socketpair(struct socket *, struct socket *);\nstatic int unix_accept(struct socket *, struct socket *, int, bool);\nstatic int unix_getname(struct socket *, struct sockaddr *, int);\nstatic __poll_t unix_poll(struct file *, struct socket *, poll_table *);\nstatic __poll_t unix_dgram_poll(struct file *, struct socket *,\n\t\t\t\t    poll_table *);\nstatic int unix_ioctl(struct socket *, unsigned int, unsigned long);\n#ifdef CONFIG_COMPAT\nstatic int unix_compat_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg);\n#endif\nstatic int unix_shutdown(struct socket *, int);\nstatic int unix_stream_sendmsg(struct socket *, struct msghdr *, size_t);\nstatic int unix_stream_recvmsg(struct socket *, struct msghdr *, size_t, int);\nstatic ssize_t unix_stream_splice_read(struct socket *,  loff_t *ppos,\n\t\t\t\t       struct pipe_inode_info *, size_t size,\n\t\t\t\t       unsigned int flags);\nstatic int unix_dgram_sendmsg(struct socket *, struct msghdr *, size_t);\nstatic int unix_dgram_recvmsg(struct socket *, struct msghdr *, size_t, int);\nstatic int unix_read_skb(struct sock *sk, skb_read_actor_t recv_actor);\nstatic int unix_stream_read_skb(struct sock *sk, skb_read_actor_t recv_actor);\nstatic int unix_dgram_connect(struct socket *, struct sockaddr *,\n\t\t\t      int, int);\nstatic int unix_seqpacket_sendmsg(struct socket *, struct msghdr *, size_t);\nstatic int unix_seqpacket_recvmsg(struct socket *, struct msghdr *, size_t,\n\t\t\t\t  int);\n\nstatic int unix_set_peek_off(struct sock *sk, int val)\n{\n\tstruct unix_sock *u = unix_sk(sk);\n\n\tif (mutex_lock_interruptible(&u->iolock))\n\t\treturn -EINTR;\n\n\tWRITE_ONCE(sk->sk_peek_off, val);\n\tmutex_unlock(&u->iolock);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_PROC_FS\nstatic int unix_count_nr_fds(struct sock *sk)\n{\n\tstruct sk_buff *skb;\n\tstruct unix_sock *u;\n\tint nr_fds = 0;\n\n\tspin_lock(&sk->sk_receive_queue.lock);\n\tskb = skb_peek(&sk->sk_receive_queue);\n\twhile (skb) {\n\t\tu = unix_sk(skb->sk);\n\t\tnr_fds += atomic_read(&u->scm_stat.nr_fds);\n\t\tskb = skb_peek_next(skb, &sk->sk_receive_queue);\n\t}\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\treturn nr_fds;\n}\n\nstatic void unix_show_fdinfo(struct seq_file *m, struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tunsigned char s_state;\n\tstruct unix_sock *u;\n\tint nr_fds = 0;\n\n\tif (sk) {\n\t\ts_state = READ_ONCE(sk->sk_state);\n\t\tu = unix_sk(sk);\n\n\t\t \n\t\tif (sock->type == SOCK_DGRAM || s_state == TCP_ESTABLISHED)\n\t\t\tnr_fds = atomic_read(&u->scm_stat.nr_fds);\n\t\telse if (s_state == TCP_LISTEN)\n\t\t\tnr_fds = unix_count_nr_fds(sk);\n\n\t\tseq_printf(m, \"scm_fds: %u\\n\", nr_fds);\n\t}\n}\n#else\n#define unix_show_fdinfo NULL\n#endif\n\nstatic const struct proto_ops unix_stream_ops = {\n\t.family =\tPF_UNIX,\n\t.owner =\tTHIS_MODULE,\n\t.release =\tunix_release,\n\t.bind =\t\tunix_bind,\n\t.connect =\tunix_stream_connect,\n\t.socketpair =\tunix_socketpair,\n\t.accept =\tunix_accept,\n\t.getname =\tunix_getname,\n\t.poll =\t\tunix_poll,\n\t.ioctl =\tunix_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl =\tunix_compat_ioctl,\n#endif\n\t.listen =\tunix_listen,\n\t.shutdown =\tunix_shutdown,\n\t.sendmsg =\tunix_stream_sendmsg,\n\t.recvmsg =\tunix_stream_recvmsg,\n\t.read_skb =\tunix_stream_read_skb,\n\t.mmap =\t\tsock_no_mmap,\n\t.splice_read =\tunix_stream_splice_read,\n\t.set_peek_off =\tunix_set_peek_off,\n\t.show_fdinfo =\tunix_show_fdinfo,\n};\n\nstatic const struct proto_ops unix_dgram_ops = {\n\t.family =\tPF_UNIX,\n\t.owner =\tTHIS_MODULE,\n\t.release =\tunix_release,\n\t.bind =\t\tunix_bind,\n\t.connect =\tunix_dgram_connect,\n\t.socketpair =\tunix_socketpair,\n\t.accept =\tsock_no_accept,\n\t.getname =\tunix_getname,\n\t.poll =\t\tunix_dgram_poll,\n\t.ioctl =\tunix_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl =\tunix_compat_ioctl,\n#endif\n\t.listen =\tsock_no_listen,\n\t.shutdown =\tunix_shutdown,\n\t.sendmsg =\tunix_dgram_sendmsg,\n\t.read_skb =\tunix_read_skb,\n\t.recvmsg =\tunix_dgram_recvmsg,\n\t.mmap =\t\tsock_no_mmap,\n\t.set_peek_off =\tunix_set_peek_off,\n\t.show_fdinfo =\tunix_show_fdinfo,\n};\n\nstatic const struct proto_ops unix_seqpacket_ops = {\n\t.family =\tPF_UNIX,\n\t.owner =\tTHIS_MODULE,\n\t.release =\tunix_release,\n\t.bind =\t\tunix_bind,\n\t.connect =\tunix_stream_connect,\n\t.socketpair =\tunix_socketpair,\n\t.accept =\tunix_accept,\n\t.getname =\tunix_getname,\n\t.poll =\t\tunix_dgram_poll,\n\t.ioctl =\tunix_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl =\tunix_compat_ioctl,\n#endif\n\t.listen =\tunix_listen,\n\t.shutdown =\tunix_shutdown,\n\t.sendmsg =\tunix_seqpacket_sendmsg,\n\t.recvmsg =\tunix_seqpacket_recvmsg,\n\t.mmap =\t\tsock_no_mmap,\n\t.set_peek_off =\tunix_set_peek_off,\n\t.show_fdinfo =\tunix_show_fdinfo,\n};\n\nstatic void unix_close(struct sock *sk, long timeout)\n{\n\t \n}\n\nstatic void unix_unhash(struct sock *sk)\n{\n\t \n}\n\nstatic bool unix_bpf_bypass_getsockopt(int level, int optname)\n{\n\tif (level == SOL_SOCKET) {\n\t\tswitch (optname) {\n\t\tcase SO_PEERPIDFD:\n\t\t\treturn true;\n\t\tdefault:\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn false;\n}\n\nstruct proto unix_dgram_proto = {\n\t.name\t\t\t= \"UNIX\",\n\t.owner\t\t\t= THIS_MODULE,\n\t.obj_size\t\t= sizeof(struct unix_sock),\n\t.close\t\t\t= unix_close,\n\t.bpf_bypass_getsockopt\t= unix_bpf_bypass_getsockopt,\n#ifdef CONFIG_BPF_SYSCALL\n\t.psock_update_sk_prot\t= unix_dgram_bpf_update_proto,\n#endif\n};\n\nstruct proto unix_stream_proto = {\n\t.name\t\t\t= \"UNIX-STREAM\",\n\t.owner\t\t\t= THIS_MODULE,\n\t.obj_size\t\t= sizeof(struct unix_sock),\n\t.close\t\t\t= unix_close,\n\t.unhash\t\t\t= unix_unhash,\n\t.bpf_bypass_getsockopt\t= unix_bpf_bypass_getsockopt,\n#ifdef CONFIG_BPF_SYSCALL\n\t.psock_update_sk_prot\t= unix_stream_bpf_update_proto,\n#endif\n};\n\nstatic struct sock *unix_create1(struct net *net, struct socket *sock, int kern, int type)\n{\n\tstruct unix_sock *u;\n\tstruct sock *sk;\n\tint err;\n\n\tatomic_long_inc(&unix_nr_socks);\n\tif (atomic_long_read(&unix_nr_socks) > 2 * get_max_files()) {\n\t\terr = -ENFILE;\n\t\tgoto err;\n\t}\n\n\tif (type == SOCK_STREAM)\n\t\tsk = sk_alloc(net, PF_UNIX, GFP_KERNEL, &unix_stream_proto, kern);\n\telse  \n\t\tsk = sk_alloc(net, PF_UNIX, GFP_KERNEL, &unix_dgram_proto, kern);\n\n\tif (!sk) {\n\t\terr = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tsock_init_data(sock, sk);\n\n\tsk->sk_hash\t\t= unix_unbound_hash(sk);\n\tsk->sk_allocation\t= GFP_KERNEL_ACCOUNT;\n\tsk->sk_write_space\t= unix_write_space;\n\tsk->sk_max_ack_backlog\t= net->unx.sysctl_max_dgram_qlen;\n\tsk->sk_destruct\t\t= unix_sock_destructor;\n\tu\t  = unix_sk(sk);\n\tu->path.dentry = NULL;\n\tu->path.mnt = NULL;\n\tspin_lock_init(&u->lock);\n\tatomic_long_set(&u->inflight, 0);\n\tINIT_LIST_HEAD(&u->link);\n\tmutex_init(&u->iolock);  \n\tmutex_init(&u->bindlock);  \n\tinit_waitqueue_head(&u->peer_wait);\n\tinit_waitqueue_func_entry(&u->peer_wake, unix_dgram_peer_wake_relay);\n\tmemset(&u->scm_stat, 0, sizeof(struct scm_stat));\n\tunix_insert_unbound_socket(net, sk);\n\n\tsock_prot_inuse_add(net, sk->sk_prot, 1);\n\n\treturn sk;\n\nerr:\n\tatomic_long_dec(&unix_nr_socks);\n\treturn ERR_PTR(err);\n}\n\nstatic int unix_create(struct net *net, struct socket *sock, int protocol,\n\t\t       int kern)\n{\n\tstruct sock *sk;\n\n\tif (protocol && protocol != PF_UNIX)\n\t\treturn -EPROTONOSUPPORT;\n\n\tsock->state = SS_UNCONNECTED;\n\n\tswitch (sock->type) {\n\tcase SOCK_STREAM:\n\t\tsock->ops = &unix_stream_ops;\n\t\tbreak;\n\t\t \n\tcase SOCK_RAW:\n\t\tsock->type = SOCK_DGRAM;\n\t\tfallthrough;\n\tcase SOCK_DGRAM:\n\t\tsock->ops = &unix_dgram_ops;\n\t\tbreak;\n\tcase SOCK_SEQPACKET:\n\t\tsock->ops = &unix_seqpacket_ops;\n\t\tbreak;\n\tdefault:\n\t\treturn -ESOCKTNOSUPPORT;\n\t}\n\n\tsk = unix_create1(net, sock, kern, sock->type);\n\tif (IS_ERR(sk))\n\t\treturn PTR_ERR(sk);\n\n\treturn 0;\n}\n\nstatic int unix_release(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\n\tif (!sk)\n\t\treturn 0;\n\n\tsk->sk_prot->close(sk, 0);\n\tunix_release_sock(sk, 0);\n\tsock->sk = NULL;\n\n\treturn 0;\n}\n\nstatic struct sock *unix_find_bsd(struct sockaddr_un *sunaddr, int addr_len,\n\t\t\t\t  int type)\n{\n\tstruct inode *inode;\n\tstruct path path;\n\tstruct sock *sk;\n\tint err;\n\n\tunix_mkname_bsd(sunaddr, addr_len);\n\terr = kern_path(sunaddr->sun_path, LOOKUP_FOLLOW, &path);\n\tif (err)\n\t\tgoto fail;\n\n\terr = path_permission(&path, MAY_WRITE);\n\tif (err)\n\t\tgoto path_put;\n\n\terr = -ECONNREFUSED;\n\tinode = d_backing_inode(path.dentry);\n\tif (!S_ISSOCK(inode->i_mode))\n\t\tgoto path_put;\n\n\tsk = unix_find_socket_byinode(inode);\n\tif (!sk)\n\t\tgoto path_put;\n\n\terr = -EPROTOTYPE;\n\tif (sk->sk_type == type)\n\t\ttouch_atime(&path);\n\telse\n\t\tgoto sock_put;\n\n\tpath_put(&path);\n\n\treturn sk;\n\nsock_put:\n\tsock_put(sk);\npath_put:\n\tpath_put(&path);\nfail:\n\treturn ERR_PTR(err);\n}\n\nstatic struct sock *unix_find_abstract(struct net *net,\n\t\t\t\t       struct sockaddr_un *sunaddr,\n\t\t\t\t       int addr_len, int type)\n{\n\tunsigned int hash = unix_abstract_hash(sunaddr, addr_len, type);\n\tstruct dentry *dentry;\n\tstruct sock *sk;\n\n\tsk = unix_find_socket_byname(net, sunaddr, addr_len, hash);\n\tif (!sk)\n\t\treturn ERR_PTR(-ECONNREFUSED);\n\n\tdentry = unix_sk(sk)->path.dentry;\n\tif (dentry)\n\t\ttouch_atime(&unix_sk(sk)->path);\n\n\treturn sk;\n}\n\nstatic struct sock *unix_find_other(struct net *net,\n\t\t\t\t    struct sockaddr_un *sunaddr,\n\t\t\t\t    int addr_len, int type)\n{\n\tstruct sock *sk;\n\n\tif (sunaddr->sun_path[0])\n\t\tsk = unix_find_bsd(sunaddr, addr_len, type);\n\telse\n\t\tsk = unix_find_abstract(net, sunaddr, addr_len, type);\n\n\treturn sk;\n}\n\nstatic int unix_autobind(struct sock *sk)\n{\n\tunsigned int new_hash, old_hash = sk->sk_hash;\n\tstruct unix_sock *u = unix_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tstruct unix_address *addr;\n\tu32 lastnum, ordernum;\n\tint err;\n\n\terr = mutex_lock_interruptible(&u->bindlock);\n\tif (err)\n\t\treturn err;\n\n\tif (u->addr)\n\t\tgoto out;\n\n\terr = -ENOMEM;\n\taddr = kzalloc(sizeof(*addr) +\n\t\t       offsetof(struct sockaddr_un, sun_path) + 16, GFP_KERNEL);\n\tif (!addr)\n\t\tgoto out;\n\n\taddr->len = offsetof(struct sockaddr_un, sun_path) + 6;\n\taddr->name->sun_family = AF_UNIX;\n\trefcount_set(&addr->refcnt, 1);\n\n\tordernum = get_random_u32();\n\tlastnum = ordernum & 0xFFFFF;\nretry:\n\tordernum = (ordernum + 1) & 0xFFFFF;\n\tsprintf(addr->name->sun_path + 1, \"%05x\", ordernum);\n\n\tnew_hash = unix_abstract_hash(addr->name, addr->len, sk->sk_type);\n\tunix_table_double_lock(net, old_hash, new_hash);\n\n\tif (__unix_find_socket_byname(net, addr->name, addr->len, new_hash)) {\n\t\tunix_table_double_unlock(net, old_hash, new_hash);\n\n\t\t \n\t\tcond_resched();\n\n\t\tif (ordernum == lastnum) {\n\t\t\t \n\t\t\terr = -ENOSPC;\n\t\t\tunix_release_addr(addr);\n\t\t\tgoto out;\n\t\t}\n\n\t\tgoto retry;\n\t}\n\n\t__unix_set_addr_hash(net, sk, addr, new_hash);\n\tunix_table_double_unlock(net, old_hash, new_hash);\n\terr = 0;\n\nout:\tmutex_unlock(&u->bindlock);\n\treturn err;\n}\n\nstatic int unix_bind_bsd(struct sock *sk, struct sockaddr_un *sunaddr,\n\t\t\t int addr_len)\n{\n\tumode_t mode = S_IFSOCK |\n\t       (SOCK_INODE(sk->sk_socket)->i_mode & ~current_umask());\n\tunsigned int new_hash, old_hash = sk->sk_hash;\n\tstruct unix_sock *u = unix_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tstruct mnt_idmap *idmap;\n\tstruct unix_address *addr;\n\tstruct dentry *dentry;\n\tstruct path parent;\n\tint err;\n\n\taddr_len = unix_mkname_bsd(sunaddr, addr_len);\n\taddr = unix_create_addr(sunaddr, addr_len);\n\tif (!addr)\n\t\treturn -ENOMEM;\n\n\t \n\tdentry = kern_path_create(AT_FDCWD, addr->name->sun_path, &parent, 0);\n\tif (IS_ERR(dentry)) {\n\t\terr = PTR_ERR(dentry);\n\t\tgoto out;\n\t}\n\n\t \n\tidmap = mnt_idmap(parent.mnt);\n\terr = security_path_mknod(&parent, dentry, mode, 0);\n\tif (!err)\n\t\terr = vfs_mknod(idmap, d_inode(parent.dentry), dentry, mode, 0);\n\tif (err)\n\t\tgoto out_path;\n\terr = mutex_lock_interruptible(&u->bindlock);\n\tif (err)\n\t\tgoto out_unlink;\n\tif (u->addr)\n\t\tgoto out_unlock;\n\n\tnew_hash = unix_bsd_hash(d_backing_inode(dentry));\n\tunix_table_double_lock(net, old_hash, new_hash);\n\tu->path.mnt = mntget(parent.mnt);\n\tu->path.dentry = dget(dentry);\n\t__unix_set_addr_hash(net, sk, addr, new_hash);\n\tunix_table_double_unlock(net, old_hash, new_hash);\n\tunix_insert_bsd_socket(sk);\n\tmutex_unlock(&u->bindlock);\n\tdone_path_create(&parent, dentry);\n\treturn 0;\n\nout_unlock:\n\tmutex_unlock(&u->bindlock);\n\terr = -EINVAL;\nout_unlink:\n\t \n\tvfs_unlink(idmap, d_inode(parent.dentry), dentry, NULL);\nout_path:\n\tdone_path_create(&parent, dentry);\nout:\n\tunix_release_addr(addr);\n\treturn err == -EEXIST ? -EADDRINUSE : err;\n}\n\nstatic int unix_bind_abstract(struct sock *sk, struct sockaddr_un *sunaddr,\n\t\t\t      int addr_len)\n{\n\tunsigned int new_hash, old_hash = sk->sk_hash;\n\tstruct unix_sock *u = unix_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tstruct unix_address *addr;\n\tint err;\n\n\taddr = unix_create_addr(sunaddr, addr_len);\n\tif (!addr)\n\t\treturn -ENOMEM;\n\n\terr = mutex_lock_interruptible(&u->bindlock);\n\tif (err)\n\t\tgoto out;\n\n\tif (u->addr) {\n\t\terr = -EINVAL;\n\t\tgoto out_mutex;\n\t}\n\n\tnew_hash = unix_abstract_hash(addr->name, addr->len, sk->sk_type);\n\tunix_table_double_lock(net, old_hash, new_hash);\n\n\tif (__unix_find_socket_byname(net, addr->name, addr->len, new_hash))\n\t\tgoto out_spin;\n\n\t__unix_set_addr_hash(net, sk, addr, new_hash);\n\tunix_table_double_unlock(net, old_hash, new_hash);\n\tmutex_unlock(&u->bindlock);\n\treturn 0;\n\nout_spin:\n\tunix_table_double_unlock(net, old_hash, new_hash);\n\terr = -EADDRINUSE;\nout_mutex:\n\tmutex_unlock(&u->bindlock);\nout:\n\tunix_release_addr(addr);\n\treturn err;\n}\n\nstatic int unix_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct sockaddr_un *sunaddr = (struct sockaddr_un *)uaddr;\n\tstruct sock *sk = sock->sk;\n\tint err;\n\n\tif (addr_len == offsetof(struct sockaddr_un, sun_path) &&\n\t    sunaddr->sun_family == AF_UNIX)\n\t\treturn unix_autobind(sk);\n\n\terr = unix_validate_addr(sunaddr, addr_len);\n\tif (err)\n\t\treturn err;\n\n\tif (sunaddr->sun_path[0])\n\t\terr = unix_bind_bsd(sk, sunaddr, addr_len);\n\telse\n\t\terr = unix_bind_abstract(sk, sunaddr, addr_len);\n\n\treturn err;\n}\n\nstatic void unix_state_double_lock(struct sock *sk1, struct sock *sk2)\n{\n\tif (unlikely(sk1 == sk2) || !sk2) {\n\t\tunix_state_lock(sk1);\n\t\treturn;\n\t}\n\tif (sk1 < sk2) {\n\t\tunix_state_lock(sk1);\n\t\tunix_state_lock_nested(sk2);\n\t} else {\n\t\tunix_state_lock(sk2);\n\t\tunix_state_lock_nested(sk1);\n\t}\n}\n\nstatic void unix_state_double_unlock(struct sock *sk1, struct sock *sk2)\n{\n\tif (unlikely(sk1 == sk2) || !sk2) {\n\t\tunix_state_unlock(sk1);\n\t\treturn;\n\t}\n\tunix_state_unlock(sk1);\n\tunix_state_unlock(sk2);\n}\n\nstatic int unix_dgram_connect(struct socket *sock, struct sockaddr *addr,\n\t\t\t      int alen, int flags)\n{\n\tstruct sockaddr_un *sunaddr = (struct sockaddr_un *)addr;\n\tstruct sock *sk = sock->sk;\n\tstruct sock *other;\n\tint err;\n\n\terr = -EINVAL;\n\tif (alen < offsetofend(struct sockaddr, sa_family))\n\t\tgoto out;\n\n\tif (addr->sa_family != AF_UNSPEC) {\n\t\terr = unix_validate_addr(sunaddr, alen);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tif ((test_bit(SOCK_PASSCRED, &sock->flags) ||\n\t\t     test_bit(SOCK_PASSPIDFD, &sock->flags)) &&\n\t\t    !unix_sk(sk)->addr) {\n\t\t\terr = unix_autobind(sk);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t}\n\nrestart:\n\t\tother = unix_find_other(sock_net(sk), sunaddr, alen, sock->type);\n\t\tif (IS_ERR(other)) {\n\t\t\terr = PTR_ERR(other);\n\t\t\tgoto out;\n\t\t}\n\n\t\tunix_state_double_lock(sk, other);\n\n\t\t \n\t\tif (sock_flag(other, SOCK_DEAD)) {\n\t\t\tunix_state_double_unlock(sk, other);\n\t\t\tsock_put(other);\n\t\t\tgoto restart;\n\t\t}\n\n\t\terr = -EPERM;\n\t\tif (!unix_may_send(sk, other))\n\t\t\tgoto out_unlock;\n\n\t\terr = security_unix_may_send(sk->sk_socket, other->sk_socket);\n\t\tif (err)\n\t\t\tgoto out_unlock;\n\n\t\tsk->sk_state = other->sk_state = TCP_ESTABLISHED;\n\t} else {\n\t\t \n\t\tother = NULL;\n\t\tunix_state_double_lock(sk, other);\n\t}\n\n\t \n\tif (unix_peer(sk)) {\n\t\tstruct sock *old_peer = unix_peer(sk);\n\n\t\tunix_peer(sk) = other;\n\t\tif (!other)\n\t\t\tsk->sk_state = TCP_CLOSE;\n\t\tunix_dgram_peer_wake_disconnect_wakeup(sk, old_peer);\n\n\t\tunix_state_double_unlock(sk, other);\n\n\t\tif (other != old_peer)\n\t\t\tunix_dgram_disconnected(sk, old_peer);\n\t\tsock_put(old_peer);\n\t} else {\n\t\tunix_peer(sk) = other;\n\t\tunix_state_double_unlock(sk, other);\n\t}\n\n\treturn 0;\n\nout_unlock:\n\tunix_state_double_unlock(sk, other);\n\tsock_put(other);\nout:\n\treturn err;\n}\n\nstatic long unix_wait_for_peer(struct sock *other, long timeo)\n\t__releases(&unix_sk(other)->lock)\n{\n\tstruct unix_sock *u = unix_sk(other);\n\tint sched;\n\tDEFINE_WAIT(wait);\n\n\tprepare_to_wait_exclusive(&u->peer_wait, &wait, TASK_INTERRUPTIBLE);\n\n\tsched = !sock_flag(other, SOCK_DEAD) &&\n\t\t!(other->sk_shutdown & RCV_SHUTDOWN) &&\n\t\tunix_recvq_full_lockless(other);\n\n\tunix_state_unlock(other);\n\n\tif (sched)\n\t\ttimeo = schedule_timeout(timeo);\n\n\tfinish_wait(&u->peer_wait, &wait);\n\treturn timeo;\n}\n\nstatic int unix_stream_connect(struct socket *sock, struct sockaddr *uaddr,\n\t\t\t       int addr_len, int flags)\n{\n\tstruct sockaddr_un *sunaddr = (struct sockaddr_un *)uaddr;\n\tstruct sock *sk = sock->sk, *newsk = NULL, *other = NULL;\n\tstruct unix_sock *u = unix_sk(sk), *newu, *otheru;\n\tstruct net *net = sock_net(sk);\n\tstruct sk_buff *skb = NULL;\n\tlong timeo;\n\tint err;\n\tint st;\n\n\terr = unix_validate_addr(sunaddr, addr_len);\n\tif (err)\n\t\tgoto out;\n\n\tif ((test_bit(SOCK_PASSCRED, &sock->flags) ||\n\t     test_bit(SOCK_PASSPIDFD, &sock->flags)) && !u->addr) {\n\t\terr = unix_autobind(sk);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, flags & O_NONBLOCK);\n\n\t \n\n\t \n\tnewsk = unix_create1(net, NULL, 0, sock->type);\n\tif (IS_ERR(newsk)) {\n\t\terr = PTR_ERR(newsk);\n\t\tnewsk = NULL;\n\t\tgoto out;\n\t}\n\n\terr = -ENOMEM;\n\n\t \n\tskb = sock_wmalloc(newsk, 1, 0, GFP_KERNEL);\n\tif (skb == NULL)\n\t\tgoto out;\n\nrestart:\n\t \n\tother = unix_find_other(net, sunaddr, addr_len, sk->sk_type);\n\tif (IS_ERR(other)) {\n\t\terr = PTR_ERR(other);\n\t\tother = NULL;\n\t\tgoto out;\n\t}\n\n\t \n\tunix_state_lock(other);\n\n\t \n\tif (sock_flag(other, SOCK_DEAD)) {\n\t\tunix_state_unlock(other);\n\t\tsock_put(other);\n\t\tgoto restart;\n\t}\n\n\terr = -ECONNREFUSED;\n\tif (other->sk_state != TCP_LISTEN)\n\t\tgoto out_unlock;\n\tif (other->sk_shutdown & RCV_SHUTDOWN)\n\t\tgoto out_unlock;\n\n\tif (unix_recvq_full(other)) {\n\t\terr = -EAGAIN;\n\t\tif (!timeo)\n\t\t\tgoto out_unlock;\n\n\t\ttimeo = unix_wait_for_peer(other, timeo);\n\n\t\terr = sock_intr_errno(timeo);\n\t\tif (signal_pending(current))\n\t\t\tgoto out;\n\t\tsock_put(other);\n\t\tgoto restart;\n\t}\n\n\t \n\tst = sk->sk_state;\n\n\tswitch (st) {\n\tcase TCP_CLOSE:\n\t\t \n\t\tbreak;\n\tcase TCP_ESTABLISHED:\n\t\t \n\t\terr = -EISCONN;\n\t\tgoto out_unlock;\n\tdefault:\n\t\terr = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\tunix_state_lock_nested(sk);\n\n\tif (sk->sk_state != st) {\n\t\tunix_state_unlock(sk);\n\t\tunix_state_unlock(other);\n\t\tsock_put(other);\n\t\tgoto restart;\n\t}\n\n\terr = security_unix_stream_connect(sk, other, newsk);\n\tif (err) {\n\t\tunix_state_unlock(sk);\n\t\tgoto out_unlock;\n\t}\n\n\t \n\n\tsock_hold(sk);\n\tunix_peer(newsk)\t= sk;\n\tnewsk->sk_state\t\t= TCP_ESTABLISHED;\n\tnewsk->sk_type\t\t= sk->sk_type;\n\tinit_peercred(newsk);\n\tnewu = unix_sk(newsk);\n\tRCU_INIT_POINTER(newsk->sk_wq, &newu->peer_wq);\n\totheru = unix_sk(other);\n\n\t \n\tif (otheru->path.dentry) {\n\t\tpath_get(&otheru->path);\n\t\tnewu->path = otheru->path;\n\t}\n\trefcount_inc(&otheru->addr->refcnt);\n\tsmp_store_release(&newu->addr, otheru->addr);\n\n\t \n\tcopy_peercred(sk, other);\n\n\tsock->state\t= SS_CONNECTED;\n\tsk->sk_state\t= TCP_ESTABLISHED;\n\tsock_hold(newsk);\n\n\tsmp_mb__after_atomic();\t \n\tunix_peer(sk)\t= newsk;\n\n\tunix_state_unlock(sk);\n\n\t \n\tspin_lock(&other->sk_receive_queue.lock);\n\t__skb_queue_tail(&other->sk_receive_queue, skb);\n\tspin_unlock(&other->sk_receive_queue.lock);\n\tunix_state_unlock(other);\n\tother->sk_data_ready(other);\n\tsock_put(other);\n\treturn 0;\n\nout_unlock:\n\tif (other)\n\t\tunix_state_unlock(other);\n\nout:\n\tkfree_skb(skb);\n\tif (newsk)\n\t\tunix_release_sock(newsk, 0);\n\tif (other)\n\t\tsock_put(other);\n\treturn err;\n}\n\nstatic int unix_socketpair(struct socket *socka, struct socket *sockb)\n{\n\tstruct sock *ska = socka->sk, *skb = sockb->sk;\n\n\t \n\tsock_hold(ska);\n\tsock_hold(skb);\n\tunix_peer(ska) = skb;\n\tunix_peer(skb) = ska;\n\tinit_peercred(ska);\n\tinit_peercred(skb);\n\n\tska->sk_state = TCP_ESTABLISHED;\n\tskb->sk_state = TCP_ESTABLISHED;\n\tsocka->state  = SS_CONNECTED;\n\tsockb->state  = SS_CONNECTED;\n\treturn 0;\n}\n\nstatic void unix_sock_inherit_flags(const struct socket *old,\n\t\t\t\t    struct socket *new)\n{\n\tif (test_bit(SOCK_PASSCRED, &old->flags))\n\t\tset_bit(SOCK_PASSCRED, &new->flags);\n\tif (test_bit(SOCK_PASSPIDFD, &old->flags))\n\t\tset_bit(SOCK_PASSPIDFD, &new->flags);\n\tif (test_bit(SOCK_PASSSEC, &old->flags))\n\t\tset_bit(SOCK_PASSSEC, &new->flags);\n}\n\nstatic int unix_accept(struct socket *sock, struct socket *newsock, int flags,\n\t\t       bool kern)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct sock *tsk;\n\tstruct sk_buff *skb;\n\tint err;\n\n\terr = -EOPNOTSUPP;\n\tif (sock->type != SOCK_STREAM && sock->type != SOCK_SEQPACKET)\n\t\tgoto out;\n\n\terr = -EINVAL;\n\tif (sk->sk_state != TCP_LISTEN)\n\t\tgoto out;\n\n\t \n\n\tskb = skb_recv_datagram(sk, (flags & O_NONBLOCK) ? MSG_DONTWAIT : 0,\n\t\t\t\t&err);\n\tif (!skb) {\n\t\t \n\t\tif (err == 0)\n\t\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\ttsk = skb->sk;\n\tskb_free_datagram(sk, skb);\n\twake_up_interruptible(&unix_sk(sk)->peer_wait);\n\n\t \n\tunix_state_lock(tsk);\n\tnewsock->state = SS_CONNECTED;\n\tunix_sock_inherit_flags(sock, newsock);\n\tsock_graft(tsk, newsock);\n\tunix_state_unlock(tsk);\n\treturn 0;\n\nout:\n\treturn err;\n}\n\n\nstatic int unix_getname(struct socket *sock, struct sockaddr *uaddr, int peer)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct unix_address *addr;\n\tDECLARE_SOCKADDR(struct sockaddr_un *, sunaddr, uaddr);\n\tint err = 0;\n\n\tif (peer) {\n\t\tsk = unix_peer_get(sk);\n\n\t\terr = -ENOTCONN;\n\t\tif (!sk)\n\t\t\tgoto out;\n\t\terr = 0;\n\t} else {\n\t\tsock_hold(sk);\n\t}\n\n\taddr = smp_load_acquire(&unix_sk(sk)->addr);\n\tif (!addr) {\n\t\tsunaddr->sun_family = AF_UNIX;\n\t\tsunaddr->sun_path[0] = 0;\n\t\terr = offsetof(struct sockaddr_un, sun_path);\n\t} else {\n\t\terr = addr->len;\n\t\tmemcpy(sunaddr, addr->name, addr->len);\n\t}\n\tsock_put(sk);\nout:\n\treturn err;\n}\n\nstatic void unix_peek_fds(struct scm_cookie *scm, struct sk_buff *skb)\n{\n\tscm->fp = scm_fp_dup(UNIXCB(skb).fp);\n\n\t \n\tspin_lock(&unix_gc_lock);\n\tspin_unlock(&unix_gc_lock);\n}\n\nstatic int unix_scm_to_skb(struct scm_cookie *scm, struct sk_buff *skb, bool send_fds)\n{\n\tint err = 0;\n\n\tUNIXCB(skb).pid  = get_pid(scm->pid);\n\tUNIXCB(skb).uid = scm->creds.uid;\n\tUNIXCB(skb).gid = scm->creds.gid;\n\tUNIXCB(skb).fp = NULL;\n\tunix_get_secdata(scm, skb);\n\tif (scm->fp && send_fds)\n\t\terr = unix_attach_fds(scm, skb);\n\n\tskb->destructor = unix_destruct_scm;\n\treturn err;\n}\n\nstatic bool unix_passcred_enabled(const struct socket *sock,\n\t\t\t\t  const struct sock *other)\n{\n\treturn test_bit(SOCK_PASSCRED, &sock->flags) ||\n\t       test_bit(SOCK_PASSPIDFD, &sock->flags) ||\n\t       !other->sk_socket ||\n\t       test_bit(SOCK_PASSCRED, &other->sk_socket->flags) ||\n\t       test_bit(SOCK_PASSPIDFD, &other->sk_socket->flags);\n}\n\n \nstatic void maybe_add_creds(struct sk_buff *skb, const struct socket *sock,\n\t\t\t    const struct sock *other)\n{\n\tif (UNIXCB(skb).pid)\n\t\treturn;\n\tif (unix_passcred_enabled(sock, other)) {\n\t\tUNIXCB(skb).pid  = get_pid(task_tgid(current));\n\t\tcurrent_uid_gid(&UNIXCB(skb).uid, &UNIXCB(skb).gid);\n\t}\n}\n\nstatic bool unix_skb_scm_eq(struct sk_buff *skb,\n\t\t\t    struct scm_cookie *scm)\n{\n\treturn UNIXCB(skb).pid == scm->pid &&\n\t       uid_eq(UNIXCB(skb).uid, scm->creds.uid) &&\n\t       gid_eq(UNIXCB(skb).gid, scm->creds.gid) &&\n\t       unix_secdata_eq(scm, skb);\n}\n\nstatic void scm_stat_add(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct scm_fp_list *fp = UNIXCB(skb).fp;\n\tstruct unix_sock *u = unix_sk(sk);\n\n\tif (unlikely(fp && fp->count))\n\t\tatomic_add(fp->count, &u->scm_stat.nr_fds);\n}\n\nstatic void scm_stat_del(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct scm_fp_list *fp = UNIXCB(skb).fp;\n\tstruct unix_sock *u = unix_sk(sk);\n\n\tif (unlikely(fp && fp->count))\n\t\tatomic_sub(fp->count, &u->scm_stat.nr_fds);\n}\n\n \n\nstatic int unix_dgram_sendmsg(struct socket *sock, struct msghdr *msg,\n\t\t\t      size_t len)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_un *, sunaddr, msg->msg_name);\n\tstruct sock *sk = sock->sk, *other = NULL;\n\tstruct unix_sock *u = unix_sk(sk);\n\tstruct scm_cookie scm;\n\tstruct sk_buff *skb;\n\tint data_len = 0;\n\tint sk_locked;\n\tlong timeo;\n\tint err;\n\n\twait_for_unix_gc();\n\terr = scm_send(sock, msg, &scm, false);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = -EOPNOTSUPP;\n\tif (msg->msg_flags&MSG_OOB)\n\t\tgoto out;\n\n\tif (msg->msg_namelen) {\n\t\terr = unix_validate_addr(sunaddr, msg->msg_namelen);\n\t\tif (err)\n\t\t\tgoto out;\n\t} else {\n\t\tsunaddr = NULL;\n\t\terr = -ENOTCONN;\n\t\tother = unix_peer_get(sk);\n\t\tif (!other)\n\t\t\tgoto out;\n\t}\n\n\tif ((test_bit(SOCK_PASSCRED, &sock->flags) ||\n\t     test_bit(SOCK_PASSPIDFD, &sock->flags)) && !u->addr) {\n\t\terr = unix_autobind(sk);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\terr = -EMSGSIZE;\n\tif (len > sk->sk_sndbuf - 32)\n\t\tgoto out;\n\n\tif (len > SKB_MAX_ALLOC) {\n\t\tdata_len = min_t(size_t,\n\t\t\t\t len - SKB_MAX_ALLOC,\n\t\t\t\t MAX_SKB_FRAGS * PAGE_SIZE);\n\t\tdata_len = PAGE_ALIGN(data_len);\n\n\t\tBUILD_BUG_ON(SKB_MAX_ALLOC < PAGE_SIZE);\n\t}\n\n\tskb = sock_alloc_send_pskb(sk, len - data_len, data_len,\n\t\t\t\t   msg->msg_flags & MSG_DONTWAIT, &err,\n\t\t\t\t   PAGE_ALLOC_COSTLY_ORDER);\n\tif (skb == NULL)\n\t\tgoto out;\n\n\terr = unix_scm_to_skb(&scm, skb, true);\n\tif (err < 0)\n\t\tgoto out_free;\n\n\tskb_put(skb, len - data_len);\n\tskb->data_len = data_len;\n\tskb->len = len;\n\terr = skb_copy_datagram_from_iter(skb, 0, &msg->msg_iter, len);\n\tif (err)\n\t\tgoto out_free;\n\n\ttimeo = sock_sndtimeo(sk, msg->msg_flags & MSG_DONTWAIT);\n\nrestart:\n\tif (!other) {\n\t\terr = -ECONNRESET;\n\t\tif (sunaddr == NULL)\n\t\t\tgoto out_free;\n\n\t\tother = unix_find_other(sock_net(sk), sunaddr, msg->msg_namelen,\n\t\t\t\t\tsk->sk_type);\n\t\tif (IS_ERR(other)) {\n\t\t\terr = PTR_ERR(other);\n\t\t\tother = NULL;\n\t\t\tgoto out_free;\n\t\t}\n\t}\n\n\tif (sk_filter(other, skb) < 0) {\n\t\t \n\t\terr = len;\n\t\tgoto out_free;\n\t}\n\n\tsk_locked = 0;\n\tunix_state_lock(other);\nrestart_locked:\n\terr = -EPERM;\n\tif (!unix_may_send(sk, other))\n\t\tgoto out_unlock;\n\n\tif (unlikely(sock_flag(other, SOCK_DEAD))) {\n\t\t \n\t\tunix_state_unlock(other);\n\t\tsock_put(other);\n\n\t\tif (!sk_locked)\n\t\t\tunix_state_lock(sk);\n\n\t\terr = 0;\n\t\tif (sk->sk_type == SOCK_SEQPACKET) {\n\t\t\t \n\t\t\tunix_state_unlock(sk);\n\t\t\terr = -EPIPE;\n\t\t} else if (unix_peer(sk) == other) {\n\t\t\tunix_peer(sk) = NULL;\n\t\t\tunix_dgram_peer_wake_disconnect_wakeup(sk, other);\n\n\t\t\tsk->sk_state = TCP_CLOSE;\n\t\t\tunix_state_unlock(sk);\n\n\t\t\tunix_dgram_disconnected(sk, other);\n\t\t\tsock_put(other);\n\t\t\terr = -ECONNREFUSED;\n\t\t} else {\n\t\t\tunix_state_unlock(sk);\n\t\t}\n\n\t\tother = NULL;\n\t\tif (err)\n\t\t\tgoto out_free;\n\t\tgoto restart;\n\t}\n\n\terr = -EPIPE;\n\tif (other->sk_shutdown & RCV_SHUTDOWN)\n\t\tgoto out_unlock;\n\n\tif (sk->sk_type != SOCK_SEQPACKET) {\n\t\terr = security_unix_may_send(sk->sk_socket, other->sk_socket);\n\t\tif (err)\n\t\t\tgoto out_unlock;\n\t}\n\n\t \n\tif (other != sk &&\n\t    unlikely(unix_peer(other) != sk &&\n\t    unix_recvq_full_lockless(other))) {\n\t\tif (timeo) {\n\t\t\ttimeo = unix_wait_for_peer(other, timeo);\n\n\t\t\terr = sock_intr_errno(timeo);\n\t\t\tif (signal_pending(current))\n\t\t\t\tgoto out_free;\n\n\t\t\tgoto restart;\n\t\t}\n\n\t\tif (!sk_locked) {\n\t\t\tunix_state_unlock(other);\n\t\t\tunix_state_double_lock(sk, other);\n\t\t}\n\n\t\tif (unix_peer(sk) != other ||\n\t\t    unix_dgram_peer_wake_me(sk, other)) {\n\t\t\terr = -EAGAIN;\n\t\t\tsk_locked = 1;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\tif (!sk_locked) {\n\t\t\tsk_locked = 1;\n\t\t\tgoto restart_locked;\n\t\t}\n\t}\n\n\tif (unlikely(sk_locked))\n\t\tunix_state_unlock(sk);\n\n\tif (sock_flag(other, SOCK_RCVTSTAMP))\n\t\t__net_timestamp(skb);\n\tmaybe_add_creds(skb, sock, other);\n\tscm_stat_add(other, skb);\n\tskb_queue_tail(&other->sk_receive_queue, skb);\n\tunix_state_unlock(other);\n\tother->sk_data_ready(other);\n\tsock_put(other);\n\tscm_destroy(&scm);\n\treturn len;\n\nout_unlock:\n\tif (sk_locked)\n\t\tunix_state_unlock(sk);\n\tunix_state_unlock(other);\nout_free:\n\tkfree_skb(skb);\nout:\n\tif (other)\n\t\tsock_put(other);\n\tscm_destroy(&scm);\n\treturn err;\n}\n\n \n#define UNIX_SKB_FRAGS_SZ (PAGE_SIZE << get_order(32768))\n\n#if IS_ENABLED(CONFIG_AF_UNIX_OOB)\nstatic int queue_oob(struct socket *sock, struct msghdr *msg, struct sock *other,\n\t\t     struct scm_cookie *scm, bool fds_sent)\n{\n\tstruct unix_sock *ousk = unix_sk(other);\n\tstruct sk_buff *skb;\n\tint err = 0;\n\n\tskb = sock_alloc_send_skb(sock->sk, 1, msg->msg_flags & MSG_DONTWAIT, &err);\n\n\tif (!skb)\n\t\treturn err;\n\n\terr = unix_scm_to_skb(scm, skb, !fds_sent);\n\tif (err < 0) {\n\t\tkfree_skb(skb);\n\t\treturn err;\n\t}\n\tskb_put(skb, 1);\n\terr = skb_copy_datagram_from_iter(skb, 0, &msg->msg_iter, 1);\n\n\tif (err) {\n\t\tkfree_skb(skb);\n\t\treturn err;\n\t}\n\n\tunix_state_lock(other);\n\n\tif (sock_flag(other, SOCK_DEAD) ||\n\t    (other->sk_shutdown & RCV_SHUTDOWN)) {\n\t\tunix_state_unlock(other);\n\t\tkfree_skb(skb);\n\t\treturn -EPIPE;\n\t}\n\n\tmaybe_add_creds(skb, sock, other);\n\tskb_get(skb);\n\n\tif (ousk->oob_skb)\n\t\tconsume_skb(ousk->oob_skb);\n\n\tWRITE_ONCE(ousk->oob_skb, skb);\n\n\tscm_stat_add(other, skb);\n\tskb_queue_tail(&other->sk_receive_queue, skb);\n\tsk_send_sigurg(other);\n\tunix_state_unlock(other);\n\tother->sk_data_ready(other);\n\n\treturn err;\n}\n#endif\n\nstatic int unix_stream_sendmsg(struct socket *sock, struct msghdr *msg,\n\t\t\t       size_t len)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct sock *other = NULL;\n\tint err, size;\n\tstruct sk_buff *skb;\n\tint sent = 0;\n\tstruct scm_cookie scm;\n\tbool fds_sent = false;\n\tint data_len;\n\n\twait_for_unix_gc();\n\terr = scm_send(sock, msg, &scm, false);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = -EOPNOTSUPP;\n\tif (msg->msg_flags & MSG_OOB) {\n#if IS_ENABLED(CONFIG_AF_UNIX_OOB)\n\t\tif (len)\n\t\t\tlen--;\n\t\telse\n#endif\n\t\t\tgoto out_err;\n\t}\n\n\tif (msg->msg_namelen) {\n\t\terr = sk->sk_state == TCP_ESTABLISHED ? -EISCONN : -EOPNOTSUPP;\n\t\tgoto out_err;\n\t} else {\n\t\terr = -ENOTCONN;\n\t\tother = unix_peer(sk);\n\t\tif (!other)\n\t\t\tgoto out_err;\n\t}\n\n\tif (sk->sk_shutdown & SEND_SHUTDOWN)\n\t\tgoto pipe_err;\n\n\twhile (sent < len) {\n\t\tsize = len - sent;\n\n\t\tif (unlikely(msg->msg_flags & MSG_SPLICE_PAGES)) {\n\t\t\tskb = sock_alloc_send_pskb(sk, 0, 0,\n\t\t\t\t\t\t   msg->msg_flags & MSG_DONTWAIT,\n\t\t\t\t\t\t   &err, 0);\n\t\t} else {\n\t\t\t \n\t\t\tsize = min_t(int, size, (sk->sk_sndbuf >> 1) - 64);\n\n\t\t\t \n\t\t\tsize = min_t(int, size, SKB_MAX_HEAD(0) + UNIX_SKB_FRAGS_SZ);\n\n\t\t\tdata_len = max_t(int, 0, size - SKB_MAX_HEAD(0));\n\n\t\t\tdata_len = min_t(size_t, size, PAGE_ALIGN(data_len));\n\n\t\t\tskb = sock_alloc_send_pskb(sk, size - data_len, data_len,\n\t\t\t\t\t\t   msg->msg_flags & MSG_DONTWAIT, &err,\n\t\t\t\t\t\t   get_order(UNIX_SKB_FRAGS_SZ));\n\t\t}\n\t\tif (!skb)\n\t\t\tgoto out_err;\n\n\t\t \n\t\terr = unix_scm_to_skb(&scm, skb, !fds_sent);\n\t\tif (err < 0) {\n\t\t\tkfree_skb(skb);\n\t\t\tgoto out_err;\n\t\t}\n\t\tfds_sent = true;\n\n\t\tif (unlikely(msg->msg_flags & MSG_SPLICE_PAGES)) {\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, size,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tsize = err;\n\t\t\trefcount_add(size, &sk->sk_wmem_alloc);\n\t\t} else {\n\t\t\tskb_put(skb, size - data_len);\n\t\t\tskb->data_len = data_len;\n\t\t\tskb->len = size;\n\t\t\terr = skb_copy_datagram_from_iter(skb, 0, &msg->msg_iter, size);\n\t\t\tif (err) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tunix_state_lock(other);\n\n\t\tif (sock_flag(other, SOCK_DEAD) ||\n\t\t    (other->sk_shutdown & RCV_SHUTDOWN))\n\t\t\tgoto pipe_err_free;\n\n\t\tmaybe_add_creds(skb, sock, other);\n\t\tscm_stat_add(other, skb);\n\t\tskb_queue_tail(&other->sk_receive_queue, skb);\n\t\tunix_state_unlock(other);\n\t\tother->sk_data_ready(other);\n\t\tsent += size;\n\t}\n\n#if IS_ENABLED(CONFIG_AF_UNIX_OOB)\n\tif (msg->msg_flags & MSG_OOB) {\n\t\terr = queue_oob(sock, msg, other, &scm, fds_sent);\n\t\tif (err)\n\t\t\tgoto out_err;\n\t\tsent++;\n\t}\n#endif\n\n\tscm_destroy(&scm);\n\n\treturn sent;\n\npipe_err_free:\n\tunix_state_unlock(other);\n\tkfree_skb(skb);\npipe_err:\n\tif (sent == 0 && !(msg->msg_flags&MSG_NOSIGNAL))\n\t\tsend_sig(SIGPIPE, current, 0);\n\terr = -EPIPE;\nout_err:\n\tscm_destroy(&scm);\n\treturn sent ? : err;\n}\n\nstatic int unix_seqpacket_sendmsg(struct socket *sock, struct msghdr *msg,\n\t\t\t\t  size_t len)\n{\n\tint err;\n\tstruct sock *sk = sock->sk;\n\n\terr = sock_error(sk);\n\tif (err)\n\t\treturn err;\n\n\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\treturn -ENOTCONN;\n\n\tif (msg->msg_namelen)\n\t\tmsg->msg_namelen = 0;\n\n\treturn unix_dgram_sendmsg(sock, msg, len);\n}\n\nstatic int unix_seqpacket_recvmsg(struct socket *sock, struct msghdr *msg,\n\t\t\t\t  size_t size, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\n\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\treturn -ENOTCONN;\n\n\treturn unix_dgram_recvmsg(sock, msg, size, flags);\n}\n\nstatic void unix_copy_addr(struct msghdr *msg, struct sock *sk)\n{\n\tstruct unix_address *addr = smp_load_acquire(&unix_sk(sk)->addr);\n\n\tif (addr) {\n\t\tmsg->msg_namelen = addr->len;\n\t\tmemcpy(msg->msg_name, addr->name, addr->len);\n\t}\n}\n\nint __unix_dgram_recvmsg(struct sock *sk, struct msghdr *msg, size_t size,\n\t\t\t int flags)\n{\n\tstruct scm_cookie scm;\n\tstruct socket *sock = sk->sk_socket;\n\tstruct unix_sock *u = unix_sk(sk);\n\tstruct sk_buff *skb, *last;\n\tlong timeo;\n\tint skip;\n\tint err;\n\n\terr = -EOPNOTSUPP;\n\tif (flags&MSG_OOB)\n\t\tgoto out;\n\n\ttimeo = sock_rcvtimeo(sk, flags & MSG_DONTWAIT);\n\n\tdo {\n\t\tmutex_lock(&u->iolock);\n\n\t\tskip = sk_peek_offset(sk, flags);\n\t\tskb = __skb_try_recv_datagram(sk, &sk->sk_receive_queue, flags,\n\t\t\t\t\t      &skip, &err, &last);\n\t\tif (skb) {\n\t\t\tif (!(flags & MSG_PEEK))\n\t\t\t\tscm_stat_del(sk, skb);\n\t\t\tbreak;\n\t\t}\n\n\t\tmutex_unlock(&u->iolock);\n\n\t\tif (err != -EAGAIN)\n\t\t\tbreak;\n\t} while (timeo &&\n\t\t !__skb_wait_for_more_packets(sk, &sk->sk_receive_queue,\n\t\t\t\t\t      &err, &timeo, last));\n\n\tif (!skb) {  \n\t\tunix_state_lock(sk);\n\t\t \n\t\tif (sk->sk_type == SOCK_SEQPACKET && err == -EAGAIN &&\n\t\t    (sk->sk_shutdown & RCV_SHUTDOWN))\n\t\t\terr = 0;\n\t\tunix_state_unlock(sk);\n\t\tgoto out;\n\t}\n\n\tif (wq_has_sleeper(&u->peer_wait))\n\t\twake_up_interruptible_sync_poll(&u->peer_wait,\n\t\t\t\t\t\tEPOLLOUT | EPOLLWRNORM |\n\t\t\t\t\t\tEPOLLWRBAND);\n\n\tif (msg->msg_name)\n\t\tunix_copy_addr(msg, skb->sk);\n\n\tif (size > skb->len - skip)\n\t\tsize = skb->len - skip;\n\telse if (size < skb->len - skip)\n\t\tmsg->msg_flags |= MSG_TRUNC;\n\n\terr = skb_copy_datagram_msg(skb, skip, msg, size);\n\tif (err)\n\t\tgoto out_free;\n\n\tif (sock_flag(sk, SOCK_RCVTSTAMP))\n\t\t__sock_recv_timestamp(msg, sk, skb);\n\n\tmemset(&scm, 0, sizeof(scm));\n\n\tscm_set_cred(&scm, UNIXCB(skb).pid, UNIXCB(skb).uid, UNIXCB(skb).gid);\n\tunix_set_secdata(&scm, skb);\n\n\tif (!(flags & MSG_PEEK)) {\n\t\tif (UNIXCB(skb).fp)\n\t\t\tunix_detach_fds(&scm, skb);\n\n\t\tsk_peek_offset_bwd(sk, skb->len);\n\t} else {\n\t\t \n\n\t\tsk_peek_offset_fwd(sk, size);\n\n\t\tif (UNIXCB(skb).fp)\n\t\t\tunix_peek_fds(&scm, skb);\n\t}\n\terr = (flags & MSG_TRUNC) ? skb->len - skip : size;\n\n\tscm_recv_unix(sock, msg, &scm, flags);\n\nout_free:\n\tskb_free_datagram(sk, skb);\n\tmutex_unlock(&u->iolock);\nout:\n\treturn err;\n}\n\nstatic int unix_dgram_recvmsg(struct socket *sock, struct msghdr *msg, size_t size,\n\t\t\t      int flags)\n{\n\tstruct sock *sk = sock->sk;\n\n#ifdef CONFIG_BPF_SYSCALL\n\tconst struct proto *prot = READ_ONCE(sk->sk_prot);\n\n\tif (prot != &unix_dgram_proto)\n\t\treturn prot->recvmsg(sk, msg, size, flags, NULL);\n#endif\n\treturn __unix_dgram_recvmsg(sk, msg, size, flags);\n}\n\nstatic int unix_read_skb(struct sock *sk, skb_read_actor_t recv_actor)\n{\n\tstruct unix_sock *u = unix_sk(sk);\n\tstruct sk_buff *skb;\n\tint err;\n\n\tmutex_lock(&u->iolock);\n\tskb = skb_recv_datagram(sk, MSG_DONTWAIT, &err);\n\tmutex_unlock(&u->iolock);\n\tif (!skb)\n\t\treturn err;\n\n\treturn recv_actor(sk, skb);\n}\n\n \nstatic long unix_stream_data_wait(struct sock *sk, long timeo,\n\t\t\t\t  struct sk_buff *last, unsigned int last_len,\n\t\t\t\t  bool freezable)\n{\n\tunsigned int state = TASK_INTERRUPTIBLE | freezable * TASK_FREEZABLE;\n\tstruct sk_buff *tail;\n\tDEFINE_WAIT(wait);\n\n\tunix_state_lock(sk);\n\n\tfor (;;) {\n\t\tprepare_to_wait(sk_sleep(sk), &wait, state);\n\n\t\ttail = skb_peek_tail(&sk->sk_receive_queue);\n\t\tif (tail != last ||\n\t\t    (tail && tail->len != last_len) ||\n\t\t    sk->sk_err ||\n\t\t    (sk->sk_shutdown & RCV_SHUTDOWN) ||\n\t\t    signal_pending(current) ||\n\t\t    !timeo)\n\t\t\tbreak;\n\n\t\tsk_set_bit(SOCKWQ_ASYNC_WAITDATA, sk);\n\t\tunix_state_unlock(sk);\n\t\ttimeo = schedule_timeout(timeo);\n\t\tunix_state_lock(sk);\n\n\t\tif (sock_flag(sk, SOCK_DEAD))\n\t\t\tbreak;\n\n\t\tsk_clear_bit(SOCKWQ_ASYNC_WAITDATA, sk);\n\t}\n\n\tfinish_wait(sk_sleep(sk), &wait);\n\tunix_state_unlock(sk);\n\treturn timeo;\n}\n\nstatic unsigned int unix_skb_len(const struct sk_buff *skb)\n{\n\treturn skb->len - UNIXCB(skb).consumed;\n}\n\nstruct unix_stream_read_state {\n\tint (*recv_actor)(struct sk_buff *, int, int,\n\t\t\t  struct unix_stream_read_state *);\n\tstruct socket *socket;\n\tstruct msghdr *msg;\n\tstruct pipe_inode_info *pipe;\n\tsize_t size;\n\tint flags;\n\tunsigned int splice_flags;\n};\n\n#if IS_ENABLED(CONFIG_AF_UNIX_OOB)\nstatic int unix_stream_recv_urg(struct unix_stream_read_state *state)\n{\n\tstruct socket *sock = state->socket;\n\tstruct sock *sk = sock->sk;\n\tstruct unix_sock *u = unix_sk(sk);\n\tint chunk = 1;\n\tstruct sk_buff *oob_skb;\n\n\tmutex_lock(&u->iolock);\n\tunix_state_lock(sk);\n\n\tif (sock_flag(sk, SOCK_URGINLINE) || !u->oob_skb) {\n\t\tunix_state_unlock(sk);\n\t\tmutex_unlock(&u->iolock);\n\t\treturn -EINVAL;\n\t}\n\n\toob_skb = u->oob_skb;\n\n\tif (!(state->flags & MSG_PEEK))\n\t\tWRITE_ONCE(u->oob_skb, NULL);\n\telse\n\t\tskb_get(oob_skb);\n\tunix_state_unlock(sk);\n\n\tchunk = state->recv_actor(oob_skb, 0, chunk, state);\n\n\tif (!(state->flags & MSG_PEEK))\n\t\tUNIXCB(oob_skb).consumed += 1;\n\n\tconsume_skb(oob_skb);\n\n\tmutex_unlock(&u->iolock);\n\n\tif (chunk < 0)\n\t\treturn -EFAULT;\n\n\tstate->msg->msg_flags |= MSG_OOB;\n\treturn 1;\n}\n\nstatic struct sk_buff *manage_oob(struct sk_buff *skb, struct sock *sk,\n\t\t\t\t  int flags, int copied)\n{\n\tstruct unix_sock *u = unix_sk(sk);\n\n\tif (!unix_skb_len(skb) && !(flags & MSG_PEEK)) {\n\t\tskb_unlink(skb, &sk->sk_receive_queue);\n\t\tconsume_skb(skb);\n\t\tskb = NULL;\n\t} else {\n\t\tif (skb == u->oob_skb) {\n\t\t\tif (copied) {\n\t\t\t\tskb = NULL;\n\t\t\t} else if (sock_flag(sk, SOCK_URGINLINE)) {\n\t\t\t\tif (!(flags & MSG_PEEK)) {\n\t\t\t\t\tWRITE_ONCE(u->oob_skb, NULL);\n\t\t\t\t\tconsume_skb(skb);\n\t\t\t\t}\n\t\t\t} else if (!(flags & MSG_PEEK)) {\n\t\t\t\tskb_unlink(skb, &sk->sk_receive_queue);\n\t\t\t\tconsume_skb(skb);\n\t\t\t\tskb = skb_peek(&sk->sk_receive_queue);\n\t\t\t}\n\t\t}\n\t}\n\treturn skb;\n}\n#endif\n\nstatic int unix_stream_read_skb(struct sock *sk, skb_read_actor_t recv_actor)\n{\n\tif (unlikely(sk->sk_state != TCP_ESTABLISHED))\n\t\treturn -ENOTCONN;\n\n\treturn unix_read_skb(sk, recv_actor);\n}\n\nstatic int unix_stream_read_generic(struct unix_stream_read_state *state,\n\t\t\t\t    bool freezable)\n{\n\tstruct scm_cookie scm;\n\tstruct socket *sock = state->socket;\n\tstruct sock *sk = sock->sk;\n\tstruct unix_sock *u = unix_sk(sk);\n\tint copied = 0;\n\tint flags = state->flags;\n\tint noblock = flags & MSG_DONTWAIT;\n\tbool check_creds = false;\n\tint target;\n\tint err = 0;\n\tlong timeo;\n\tint skip;\n\tsize_t size = state->size;\n\tunsigned int last_len;\n\n\tif (unlikely(sk->sk_state != TCP_ESTABLISHED)) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (unlikely(flags & MSG_OOB)) {\n\t\terr = -EOPNOTSUPP;\n#if IS_ENABLED(CONFIG_AF_UNIX_OOB)\n\t\terr = unix_stream_recv_urg(state);\n#endif\n\t\tgoto out;\n\t}\n\n\ttarget = sock_rcvlowat(sk, flags & MSG_WAITALL, size);\n\ttimeo = sock_rcvtimeo(sk, noblock);\n\n\tmemset(&scm, 0, sizeof(scm));\n\n\t \n\tmutex_lock(&u->iolock);\n\n\tskip = max(sk_peek_offset(sk, flags), 0);\n\n\tdo {\n\t\tint chunk;\n\t\tbool drop_skb;\n\t\tstruct sk_buff *skb, *last;\n\nredo:\n\t\tunix_state_lock(sk);\n\t\tif (sock_flag(sk, SOCK_DEAD)) {\n\t\t\terr = -ECONNRESET;\n\t\t\tgoto unlock;\n\t\t}\n\t\tlast = skb = skb_peek(&sk->sk_receive_queue);\n\t\tlast_len = last ? last->len : 0;\n\n#if IS_ENABLED(CONFIG_AF_UNIX_OOB)\n\t\tif (skb) {\n\t\t\tskb = manage_oob(skb, sk, flags, copied);\n\t\t\tif (!skb) {\n\t\t\t\tunix_state_unlock(sk);\n\t\t\t\tif (copied)\n\t\t\t\t\tbreak;\n\t\t\t\tgoto redo;\n\t\t\t}\n\t\t}\n#endif\nagain:\n\t\tif (skb == NULL) {\n\t\t\tif (copied >= target)\n\t\t\t\tgoto unlock;\n\n\t\t\t \n\n\t\t\terr = sock_error(sk);\n\t\t\tif (err)\n\t\t\t\tgoto unlock;\n\t\t\tif (sk->sk_shutdown & RCV_SHUTDOWN)\n\t\t\t\tgoto unlock;\n\n\t\t\tunix_state_unlock(sk);\n\t\t\tif (!timeo) {\n\t\t\t\terr = -EAGAIN;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tmutex_unlock(&u->iolock);\n\n\t\t\ttimeo = unix_stream_data_wait(sk, timeo, last,\n\t\t\t\t\t\t      last_len, freezable);\n\n\t\t\tif (signal_pending(current)) {\n\t\t\t\terr = sock_intr_errno(timeo);\n\t\t\t\tscm_destroy(&scm);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tmutex_lock(&u->iolock);\n\t\t\tgoto redo;\nunlock:\n\t\t\tunix_state_unlock(sk);\n\t\t\tbreak;\n\t\t}\n\n\t\twhile (skip >= unix_skb_len(skb)) {\n\t\t\tskip -= unix_skb_len(skb);\n\t\t\tlast = skb;\n\t\t\tlast_len = skb->len;\n\t\t\tskb = skb_peek_next(skb, &sk->sk_receive_queue);\n\t\t\tif (!skb)\n\t\t\t\tgoto again;\n\t\t}\n\n\t\tunix_state_unlock(sk);\n\n\t\tif (check_creds) {\n\t\t\t \n\t\t\tif (!unix_skb_scm_eq(skb, &scm))\n\t\t\t\tbreak;\n\t\t} else if (test_bit(SOCK_PASSCRED, &sock->flags) ||\n\t\t\t   test_bit(SOCK_PASSPIDFD, &sock->flags)) {\n\t\t\t \n\t\t\tscm_set_cred(&scm, UNIXCB(skb).pid, UNIXCB(skb).uid, UNIXCB(skb).gid);\n\t\t\tunix_set_secdata(&scm, skb);\n\t\t\tcheck_creds = true;\n\t\t}\n\n\t\t \n\t\tif (state->msg && state->msg->msg_name) {\n\t\t\tDECLARE_SOCKADDR(struct sockaddr_un *, sunaddr,\n\t\t\t\t\t state->msg->msg_name);\n\t\t\tunix_copy_addr(state->msg, skb->sk);\n\t\t\tsunaddr = NULL;\n\t\t}\n\n\t\tchunk = min_t(unsigned int, unix_skb_len(skb) - skip, size);\n\t\tskb_get(skb);\n\t\tchunk = state->recv_actor(skb, skip, chunk, state);\n\t\tdrop_skb = !unix_skb_len(skb);\n\t\t \n\t\tconsume_skb(skb);\n\t\tif (chunk < 0) {\n\t\t\tif (copied == 0)\n\t\t\t\tcopied = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tcopied += chunk;\n\t\tsize -= chunk;\n\n\t\tif (drop_skb) {\n\t\t\t \n\t\t\terr = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (!(flags & MSG_PEEK)) {\n\t\t\tUNIXCB(skb).consumed += chunk;\n\n\t\t\tsk_peek_offset_bwd(sk, chunk);\n\n\t\t\tif (UNIXCB(skb).fp) {\n\t\t\t\tscm_stat_del(sk, skb);\n\t\t\t\tunix_detach_fds(&scm, skb);\n\t\t\t}\n\n\t\t\tif (unix_skb_len(skb))\n\t\t\t\tbreak;\n\n\t\t\tskb_unlink(skb, &sk->sk_receive_queue);\n\t\t\tconsume_skb(skb);\n\n\t\t\tif (scm.fp)\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\t \n\t\t\tif (UNIXCB(skb).fp)\n\t\t\t\tunix_peek_fds(&scm, skb);\n\n\t\t\tsk_peek_offset_fwd(sk, chunk);\n\n\t\t\tif (UNIXCB(skb).fp)\n\t\t\t\tbreak;\n\n\t\t\tskip = 0;\n\t\t\tlast = skb;\n\t\t\tlast_len = skb->len;\n\t\t\tunix_state_lock(sk);\n\t\t\tskb = skb_peek_next(skb, &sk->sk_receive_queue);\n\t\t\tif (skb)\n\t\t\t\tgoto again;\n\t\t\tunix_state_unlock(sk);\n\t\t\tbreak;\n\t\t}\n\t} while (size);\n\n\tmutex_unlock(&u->iolock);\n\tif (state->msg)\n\t\tscm_recv_unix(sock, state->msg, &scm, flags);\n\telse\n\t\tscm_destroy(&scm);\nout:\n\treturn copied ? : err;\n}\n\nstatic int unix_stream_read_actor(struct sk_buff *skb,\n\t\t\t\t  int skip, int chunk,\n\t\t\t\t  struct unix_stream_read_state *state)\n{\n\tint ret;\n\n\tret = skb_copy_datagram_msg(skb, UNIXCB(skb).consumed + skip,\n\t\t\t\t    state->msg, chunk);\n\treturn ret ?: chunk;\n}\n\nint __unix_stream_recvmsg(struct sock *sk, struct msghdr *msg,\n\t\t\t  size_t size, int flags)\n{\n\tstruct unix_stream_read_state state = {\n\t\t.recv_actor = unix_stream_read_actor,\n\t\t.socket = sk->sk_socket,\n\t\t.msg = msg,\n\t\t.size = size,\n\t\t.flags = flags\n\t};\n\n\treturn unix_stream_read_generic(&state, true);\n}\n\nstatic int unix_stream_recvmsg(struct socket *sock, struct msghdr *msg,\n\t\t\t       size_t size, int flags)\n{\n\tstruct unix_stream_read_state state = {\n\t\t.recv_actor = unix_stream_read_actor,\n\t\t.socket = sock,\n\t\t.msg = msg,\n\t\t.size = size,\n\t\t.flags = flags\n\t};\n\n#ifdef CONFIG_BPF_SYSCALL\n\tstruct sock *sk = sock->sk;\n\tconst struct proto *prot = READ_ONCE(sk->sk_prot);\n\n\tif (prot != &unix_stream_proto)\n\t\treturn prot->recvmsg(sk, msg, size, flags, NULL);\n#endif\n\treturn unix_stream_read_generic(&state, true);\n}\n\nstatic int unix_stream_splice_actor(struct sk_buff *skb,\n\t\t\t\t    int skip, int chunk,\n\t\t\t\t    struct unix_stream_read_state *state)\n{\n\treturn skb_splice_bits(skb, state->socket->sk,\n\t\t\t       UNIXCB(skb).consumed + skip,\n\t\t\t       state->pipe, chunk, state->splice_flags);\n}\n\nstatic ssize_t unix_stream_splice_read(struct socket *sock,  loff_t *ppos,\n\t\t\t\t       struct pipe_inode_info *pipe,\n\t\t\t\t       size_t size, unsigned int flags)\n{\n\tstruct unix_stream_read_state state = {\n\t\t.recv_actor = unix_stream_splice_actor,\n\t\t.socket = sock,\n\t\t.pipe = pipe,\n\t\t.size = size,\n\t\t.splice_flags = flags,\n\t};\n\n\tif (unlikely(*ppos))\n\t\treturn -ESPIPE;\n\n\tif (sock->file->f_flags & O_NONBLOCK ||\n\t    flags & SPLICE_F_NONBLOCK)\n\t\tstate.flags = MSG_DONTWAIT;\n\n\treturn unix_stream_read_generic(&state, false);\n}\n\nstatic int unix_shutdown(struct socket *sock, int mode)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct sock *other;\n\n\tif (mode < SHUT_RD || mode > SHUT_RDWR)\n\t\treturn -EINVAL;\n\t \n\t++mode;\n\n\tunix_state_lock(sk);\n\tWRITE_ONCE(sk->sk_shutdown, sk->sk_shutdown | mode);\n\tother = unix_peer(sk);\n\tif (other)\n\t\tsock_hold(other);\n\tunix_state_unlock(sk);\n\tsk->sk_state_change(sk);\n\n\tif (other &&\n\t\t(sk->sk_type == SOCK_STREAM || sk->sk_type == SOCK_SEQPACKET)) {\n\n\t\tint peer_mode = 0;\n\t\tconst struct proto *prot = READ_ONCE(other->sk_prot);\n\n\t\tif (prot->unhash)\n\t\t\tprot->unhash(other);\n\t\tif (mode&RCV_SHUTDOWN)\n\t\t\tpeer_mode |= SEND_SHUTDOWN;\n\t\tif (mode&SEND_SHUTDOWN)\n\t\t\tpeer_mode |= RCV_SHUTDOWN;\n\t\tunix_state_lock(other);\n\t\tWRITE_ONCE(other->sk_shutdown, other->sk_shutdown | peer_mode);\n\t\tunix_state_unlock(other);\n\t\tother->sk_state_change(other);\n\t\tif (peer_mode == SHUTDOWN_MASK)\n\t\t\tsk_wake_async(other, SOCK_WAKE_WAITD, POLL_HUP);\n\t\telse if (peer_mode & RCV_SHUTDOWN)\n\t\t\tsk_wake_async(other, SOCK_WAKE_WAITD, POLL_IN);\n\t}\n\tif (other)\n\t\tsock_put(other);\n\n\treturn 0;\n}\n\nlong unix_inq_len(struct sock *sk)\n{\n\tstruct sk_buff *skb;\n\tlong amount = 0;\n\n\tif (sk->sk_state == TCP_LISTEN)\n\t\treturn -EINVAL;\n\n\tspin_lock(&sk->sk_receive_queue.lock);\n\tif (sk->sk_type == SOCK_STREAM ||\n\t    sk->sk_type == SOCK_SEQPACKET) {\n\t\tskb_queue_walk(&sk->sk_receive_queue, skb)\n\t\t\tamount += unix_skb_len(skb);\n\t} else {\n\t\tskb = skb_peek(&sk->sk_receive_queue);\n\t\tif (skb)\n\t\t\tamount = skb->len;\n\t}\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\treturn amount;\n}\nEXPORT_SYMBOL_GPL(unix_inq_len);\n\nlong unix_outq_len(struct sock *sk)\n{\n\treturn sk_wmem_alloc_get(sk);\n}\nEXPORT_SYMBOL_GPL(unix_outq_len);\n\nstatic int unix_open_file(struct sock *sk)\n{\n\tstruct path path;\n\tstruct file *f;\n\tint fd;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!smp_load_acquire(&unix_sk(sk)->addr))\n\t\treturn -ENOENT;\n\n\tpath = unix_sk(sk)->path;\n\tif (!path.dentry)\n\t\treturn -ENOENT;\n\n\tpath_get(&path);\n\n\tfd = get_unused_fd_flags(O_CLOEXEC);\n\tif (fd < 0)\n\t\tgoto out;\n\n\tf = dentry_open(&path, O_PATH, current_cred());\n\tif (IS_ERR(f)) {\n\t\tput_unused_fd(fd);\n\t\tfd = PTR_ERR(f);\n\t\tgoto out;\n\t}\n\n\tfd_install(fd, f);\nout:\n\tpath_put(&path);\n\n\treturn fd;\n}\n\nstatic int unix_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)\n{\n\tstruct sock *sk = sock->sk;\n\tlong amount = 0;\n\tint err;\n\n\tswitch (cmd) {\n\tcase SIOCOUTQ:\n\t\tamount = unix_outq_len(sk);\n\t\terr = put_user(amount, (int __user *)arg);\n\t\tbreak;\n\tcase SIOCINQ:\n\t\tamount = unix_inq_len(sk);\n\t\tif (amount < 0)\n\t\t\terr = amount;\n\t\telse\n\t\t\terr = put_user(amount, (int __user *)arg);\n\t\tbreak;\n\tcase SIOCUNIXFILE:\n\t\terr = unix_open_file(sk);\n\t\tbreak;\n#if IS_ENABLED(CONFIG_AF_UNIX_OOB)\n\tcase SIOCATMARK:\n\t\t{\n\t\t\tstruct sk_buff *skb;\n\t\t\tint answ = 0;\n\n\t\t\tskb = skb_peek(&sk->sk_receive_queue);\n\t\t\tif (skb && skb == READ_ONCE(unix_sk(sk)->oob_skb))\n\t\t\t\tansw = 1;\n\t\t\terr = put_user(answ, (int __user *)arg);\n\t\t}\n\t\tbreak;\n#endif\n\tdefault:\n\t\terr = -ENOIOCTLCMD;\n\t\tbreak;\n\t}\n\treturn err;\n}\n\n#ifdef CONFIG_COMPAT\nstatic int unix_compat_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)\n{\n\treturn unix_ioctl(sock, cmd, (unsigned long)compat_ptr(arg));\n}\n#endif\n\nstatic __poll_t unix_poll(struct file *file, struct socket *sock, poll_table *wait)\n{\n\tstruct sock *sk = sock->sk;\n\t__poll_t mask;\n\tu8 shutdown;\n\n\tsock_poll_wait(file, sock, wait);\n\tmask = 0;\n\tshutdown = READ_ONCE(sk->sk_shutdown);\n\n\t \n\tif (READ_ONCE(sk->sk_err))\n\t\tmask |= EPOLLERR;\n\tif (shutdown == SHUTDOWN_MASK)\n\t\tmask |= EPOLLHUP;\n\tif (shutdown & RCV_SHUTDOWN)\n\t\tmask |= EPOLLRDHUP | EPOLLIN | EPOLLRDNORM;\n\n\t \n\tif (!skb_queue_empty_lockless(&sk->sk_receive_queue))\n\t\tmask |= EPOLLIN | EPOLLRDNORM;\n\tif (sk_is_readable(sk))\n\t\tmask |= EPOLLIN | EPOLLRDNORM;\n#if IS_ENABLED(CONFIG_AF_UNIX_OOB)\n\tif (READ_ONCE(unix_sk(sk)->oob_skb))\n\t\tmask |= EPOLLPRI;\n#endif\n\n\t \n\tif ((sk->sk_type == SOCK_STREAM || sk->sk_type == SOCK_SEQPACKET) &&\n\t    sk->sk_state == TCP_CLOSE)\n\t\tmask |= EPOLLHUP;\n\n\t \n\tif (unix_writable(sk))\n\t\tmask |= EPOLLOUT | EPOLLWRNORM | EPOLLWRBAND;\n\n\treturn mask;\n}\n\nstatic __poll_t unix_dgram_poll(struct file *file, struct socket *sock,\n\t\t\t\t    poll_table *wait)\n{\n\tstruct sock *sk = sock->sk, *other;\n\tunsigned int writable;\n\t__poll_t mask;\n\tu8 shutdown;\n\n\tsock_poll_wait(file, sock, wait);\n\tmask = 0;\n\tshutdown = READ_ONCE(sk->sk_shutdown);\n\n\t \n\tif (READ_ONCE(sk->sk_err) ||\n\t    !skb_queue_empty_lockless(&sk->sk_error_queue))\n\t\tmask |= EPOLLERR |\n\t\t\t(sock_flag(sk, SOCK_SELECT_ERR_QUEUE) ? EPOLLPRI : 0);\n\n\tif (shutdown & RCV_SHUTDOWN)\n\t\tmask |= EPOLLRDHUP | EPOLLIN | EPOLLRDNORM;\n\tif (shutdown == SHUTDOWN_MASK)\n\t\tmask |= EPOLLHUP;\n\n\t \n\tif (!skb_queue_empty_lockless(&sk->sk_receive_queue))\n\t\tmask |= EPOLLIN | EPOLLRDNORM;\n\tif (sk_is_readable(sk))\n\t\tmask |= EPOLLIN | EPOLLRDNORM;\n\n\t \n\tif (sk->sk_type == SOCK_SEQPACKET) {\n\t\tif (sk->sk_state == TCP_CLOSE)\n\t\t\tmask |= EPOLLHUP;\n\t\t \n\t\tif (sk->sk_state == TCP_SYN_SENT)\n\t\t\treturn mask;\n\t}\n\n\t \n\tif (!(poll_requested_events(wait) & (EPOLLWRBAND|EPOLLWRNORM|EPOLLOUT)))\n\t\treturn mask;\n\n\twritable = unix_writable(sk);\n\tif (writable) {\n\t\tunix_state_lock(sk);\n\n\t\tother = unix_peer(sk);\n\t\tif (other && unix_peer(other) != sk &&\n\t\t    unix_recvq_full_lockless(other) &&\n\t\t    unix_dgram_peer_wake_me(sk, other))\n\t\t\twritable = 0;\n\n\t\tunix_state_unlock(sk);\n\t}\n\n\tif (writable)\n\t\tmask |= EPOLLOUT | EPOLLWRNORM | EPOLLWRBAND;\n\telse\n\t\tsk_set_bit(SOCKWQ_ASYNC_NOSPACE, sk);\n\n\treturn mask;\n}\n\n#ifdef CONFIG_PROC_FS\n\n#define BUCKET_SPACE (BITS_PER_LONG - (UNIX_HASH_BITS + 1) - 1)\n\n#define get_bucket(x) ((x) >> BUCKET_SPACE)\n#define get_offset(x) ((x) & ((1UL << BUCKET_SPACE) - 1))\n#define set_bucket_offset(b, o) ((b) << BUCKET_SPACE | (o))\n\nstatic struct sock *unix_from_bucket(struct seq_file *seq, loff_t *pos)\n{\n\tunsigned long offset = get_offset(*pos);\n\tunsigned long bucket = get_bucket(*pos);\n\tunsigned long count = 0;\n\tstruct sock *sk;\n\n\tfor (sk = sk_head(&seq_file_net(seq)->unx.table.buckets[bucket]);\n\t     sk; sk = sk_next(sk)) {\n\t\tif (++count == offset)\n\t\t\tbreak;\n\t}\n\n\treturn sk;\n}\n\nstatic struct sock *unix_get_first(struct seq_file *seq, loff_t *pos)\n{\n\tunsigned long bucket = get_bucket(*pos);\n\tstruct net *net = seq_file_net(seq);\n\tstruct sock *sk;\n\n\twhile (bucket < UNIX_HASH_SIZE) {\n\t\tspin_lock(&net->unx.table.locks[bucket]);\n\n\t\tsk = unix_from_bucket(seq, pos);\n\t\tif (sk)\n\t\t\treturn sk;\n\n\t\tspin_unlock(&net->unx.table.locks[bucket]);\n\n\t\t*pos = set_bucket_offset(++bucket, 1);\n\t}\n\n\treturn NULL;\n}\n\nstatic struct sock *unix_get_next(struct seq_file *seq, struct sock *sk,\n\t\t\t\t  loff_t *pos)\n{\n\tunsigned long bucket = get_bucket(*pos);\n\n\tsk = sk_next(sk);\n\tif (sk)\n\t\treturn sk;\n\n\n\tspin_unlock(&seq_file_net(seq)->unx.table.locks[bucket]);\n\n\t*pos = set_bucket_offset(++bucket, 1);\n\n\treturn unix_get_first(seq, pos);\n}\n\nstatic void *unix_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tif (!*pos)\n\t\treturn SEQ_START_TOKEN;\n\n\treturn unix_get_first(seq, pos);\n}\n\nstatic void *unix_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\t++*pos;\n\n\tif (v == SEQ_START_TOKEN)\n\t\treturn unix_get_first(seq, pos);\n\n\treturn unix_get_next(seq, v, pos);\n}\n\nstatic void unix_seq_stop(struct seq_file *seq, void *v)\n{\n\tstruct sock *sk = v;\n\n\tif (sk)\n\t\tspin_unlock(&seq_file_net(seq)->unx.table.locks[sk->sk_hash]);\n}\n\nstatic int unix_seq_show(struct seq_file *seq, void *v)\n{\n\n\tif (v == SEQ_START_TOKEN)\n\t\tseq_puts(seq, \"Num       RefCount Protocol Flags    Type St \"\n\t\t\t \"Inode Path\\n\");\n\telse {\n\t\tstruct sock *s = v;\n\t\tstruct unix_sock *u = unix_sk(s);\n\t\tunix_state_lock(s);\n\n\t\tseq_printf(seq, \"%pK: %08X %08X %08X %04X %02X %5lu\",\n\t\t\ts,\n\t\t\trefcount_read(&s->sk_refcnt),\n\t\t\t0,\n\t\t\ts->sk_state == TCP_LISTEN ? __SO_ACCEPTCON : 0,\n\t\t\ts->sk_type,\n\t\t\ts->sk_socket ?\n\t\t\t(s->sk_state == TCP_ESTABLISHED ? SS_CONNECTED : SS_UNCONNECTED) :\n\t\t\t(s->sk_state == TCP_ESTABLISHED ? SS_CONNECTING : SS_DISCONNECTING),\n\t\t\tsock_i_ino(s));\n\n\t\tif (u->addr) {\t\n\t\t\tint i, len;\n\t\t\tseq_putc(seq, ' ');\n\n\t\t\ti = 0;\n\t\t\tlen = u->addr->len -\n\t\t\t\toffsetof(struct sockaddr_un, sun_path);\n\t\t\tif (u->addr->name->sun_path[0]) {\n\t\t\t\tlen--;\n\t\t\t} else {\n\t\t\t\tseq_putc(seq, '@');\n\t\t\t\ti++;\n\t\t\t}\n\t\t\tfor ( ; i < len; i++)\n\t\t\t\tseq_putc(seq, u->addr->name->sun_path[i] ?:\n\t\t\t\t\t '@');\n\t\t}\n\t\tunix_state_unlock(s);\n\t\tseq_putc(seq, '\\n');\n\t}\n\n\treturn 0;\n}\n\nstatic const struct seq_operations unix_seq_ops = {\n\t.start  = unix_seq_start,\n\t.next   = unix_seq_next,\n\t.stop   = unix_seq_stop,\n\t.show   = unix_seq_show,\n};\n\n#if IS_BUILTIN(CONFIG_UNIX) && defined(CONFIG_BPF_SYSCALL)\nstruct bpf_unix_iter_state {\n\tstruct seq_net_private p;\n\tunsigned int cur_sk;\n\tunsigned int end_sk;\n\tunsigned int max_sk;\n\tstruct sock **batch;\n\tbool st_bucket_done;\n};\n\nstruct bpf_iter__unix {\n\t__bpf_md_ptr(struct bpf_iter_meta *, meta);\n\t__bpf_md_ptr(struct unix_sock *, unix_sk);\n\tuid_t uid __aligned(8);\n};\n\nstatic int unix_prog_seq_show(struct bpf_prog *prog, struct bpf_iter_meta *meta,\n\t\t\t      struct unix_sock *unix_sk, uid_t uid)\n{\n\tstruct bpf_iter__unix ctx;\n\n\tmeta->seq_num--;   \n\tctx.meta = meta;\n\tctx.unix_sk = unix_sk;\n\tctx.uid = uid;\n\treturn bpf_iter_run_prog(prog, &ctx);\n}\n\nstatic int bpf_iter_unix_hold_batch(struct seq_file *seq, struct sock *start_sk)\n\n{\n\tstruct bpf_unix_iter_state *iter = seq->private;\n\tunsigned int expected = 1;\n\tstruct sock *sk;\n\n\tsock_hold(start_sk);\n\titer->batch[iter->end_sk++] = start_sk;\n\n\tfor (sk = sk_next(start_sk); sk; sk = sk_next(sk)) {\n\t\tif (iter->end_sk < iter->max_sk) {\n\t\t\tsock_hold(sk);\n\t\t\titer->batch[iter->end_sk++] = sk;\n\t\t}\n\n\t\texpected++;\n\t}\n\n\tspin_unlock(&seq_file_net(seq)->unx.table.locks[start_sk->sk_hash]);\n\n\treturn expected;\n}\n\nstatic void bpf_iter_unix_put_batch(struct bpf_unix_iter_state *iter)\n{\n\twhile (iter->cur_sk < iter->end_sk)\n\t\tsock_put(iter->batch[iter->cur_sk++]);\n}\n\nstatic int bpf_iter_unix_realloc_batch(struct bpf_unix_iter_state *iter,\n\t\t\t\t       unsigned int new_batch_sz)\n{\n\tstruct sock **new_batch;\n\n\tnew_batch = kvmalloc(sizeof(*new_batch) * new_batch_sz,\n\t\t\t     GFP_USER | __GFP_NOWARN);\n\tif (!new_batch)\n\t\treturn -ENOMEM;\n\n\tbpf_iter_unix_put_batch(iter);\n\tkvfree(iter->batch);\n\titer->batch = new_batch;\n\titer->max_sk = new_batch_sz;\n\n\treturn 0;\n}\n\nstatic struct sock *bpf_iter_unix_batch(struct seq_file *seq,\n\t\t\t\t\tloff_t *pos)\n{\n\tstruct bpf_unix_iter_state *iter = seq->private;\n\tunsigned int expected;\n\tbool resized = false;\n\tstruct sock *sk;\n\n\tif (iter->st_bucket_done)\n\t\t*pos = set_bucket_offset(get_bucket(*pos) + 1, 1);\n\nagain:\n\t \n\titer->cur_sk = 0;\n\titer->end_sk = 0;\n\n\tsk = unix_get_first(seq, pos);\n\tif (!sk)\n\t\treturn NULL;  \n\n\texpected = bpf_iter_unix_hold_batch(seq, sk);\n\n\tif (iter->end_sk == expected) {\n\t\titer->st_bucket_done = true;\n\t\treturn sk;\n\t}\n\n\tif (!resized && !bpf_iter_unix_realloc_batch(iter, expected * 3 / 2)) {\n\t\tresized = true;\n\t\tgoto again;\n\t}\n\n\treturn sk;\n}\n\nstatic void *bpf_iter_unix_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tif (!*pos)\n\t\treturn SEQ_START_TOKEN;\n\n\t \n\treturn bpf_iter_unix_batch(seq, pos);\n}\n\nstatic void *bpf_iter_unix_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\tstruct bpf_unix_iter_state *iter = seq->private;\n\tstruct sock *sk;\n\n\t \n\tif (iter->cur_sk < iter->end_sk)\n\t\tsock_put(iter->batch[iter->cur_sk++]);\n\n\t++*pos;\n\n\tif (iter->cur_sk < iter->end_sk)\n\t\tsk = iter->batch[iter->cur_sk];\n\telse\n\t\tsk = bpf_iter_unix_batch(seq, pos);\n\n\treturn sk;\n}\n\nstatic int bpf_iter_unix_seq_show(struct seq_file *seq, void *v)\n{\n\tstruct bpf_iter_meta meta;\n\tstruct bpf_prog *prog;\n\tstruct sock *sk = v;\n\tuid_t uid;\n\tbool slow;\n\tint ret;\n\n\tif (v == SEQ_START_TOKEN)\n\t\treturn 0;\n\n\tslow = lock_sock_fast(sk);\n\n\tif (unlikely(sk_unhashed(sk))) {\n\t\tret = SEQ_SKIP;\n\t\tgoto unlock;\n\t}\n\n\tuid = from_kuid_munged(seq_user_ns(seq), sock_i_uid(sk));\n\tmeta.seq = seq;\n\tprog = bpf_iter_get_info(&meta, false);\n\tret = unix_prog_seq_show(prog, &meta, v, uid);\nunlock:\n\tunlock_sock_fast(sk, slow);\n\treturn ret;\n}\n\nstatic void bpf_iter_unix_seq_stop(struct seq_file *seq, void *v)\n{\n\tstruct bpf_unix_iter_state *iter = seq->private;\n\tstruct bpf_iter_meta meta;\n\tstruct bpf_prog *prog;\n\n\tif (!v) {\n\t\tmeta.seq = seq;\n\t\tprog = bpf_iter_get_info(&meta, true);\n\t\tif (prog)\n\t\t\t(void)unix_prog_seq_show(prog, &meta, v, 0);\n\t}\n\n\tif (iter->cur_sk < iter->end_sk)\n\t\tbpf_iter_unix_put_batch(iter);\n}\n\nstatic const struct seq_operations bpf_iter_unix_seq_ops = {\n\t.start\t= bpf_iter_unix_seq_start,\n\t.next\t= bpf_iter_unix_seq_next,\n\t.stop\t= bpf_iter_unix_seq_stop,\n\t.show\t= bpf_iter_unix_seq_show,\n};\n#endif\n#endif\n\nstatic const struct net_proto_family unix_family_ops = {\n\t.family = PF_UNIX,\n\t.create = unix_create,\n\t.owner\t= THIS_MODULE,\n};\n\n\nstatic int __net_init unix_net_init(struct net *net)\n{\n\tint i;\n\n\tnet->unx.sysctl_max_dgram_qlen = 10;\n\tif (unix_sysctl_register(net))\n\t\tgoto out;\n\n#ifdef CONFIG_PROC_FS\n\tif (!proc_create_net(\"unix\", 0, net->proc_net, &unix_seq_ops,\n\t\t\t     sizeof(struct seq_net_private)))\n\t\tgoto err_sysctl;\n#endif\n\n\tnet->unx.table.locks = kvmalloc_array(UNIX_HASH_SIZE,\n\t\t\t\t\t      sizeof(spinlock_t), GFP_KERNEL);\n\tif (!net->unx.table.locks)\n\t\tgoto err_proc;\n\n\tnet->unx.table.buckets = kvmalloc_array(UNIX_HASH_SIZE,\n\t\t\t\t\t\tsizeof(struct hlist_head),\n\t\t\t\t\t\tGFP_KERNEL);\n\tif (!net->unx.table.buckets)\n\t\tgoto free_locks;\n\n\tfor (i = 0; i < UNIX_HASH_SIZE; i++) {\n\t\tspin_lock_init(&net->unx.table.locks[i]);\n\t\tINIT_HLIST_HEAD(&net->unx.table.buckets[i]);\n\t}\n\n\treturn 0;\n\nfree_locks:\n\tkvfree(net->unx.table.locks);\nerr_proc:\n#ifdef CONFIG_PROC_FS\n\tremove_proc_entry(\"unix\", net->proc_net);\nerr_sysctl:\n#endif\n\tunix_sysctl_unregister(net);\nout:\n\treturn -ENOMEM;\n}\n\nstatic void __net_exit unix_net_exit(struct net *net)\n{\n\tkvfree(net->unx.table.buckets);\n\tkvfree(net->unx.table.locks);\n\tunix_sysctl_unregister(net);\n\tremove_proc_entry(\"unix\", net->proc_net);\n}\n\nstatic struct pernet_operations unix_net_ops = {\n\t.init = unix_net_init,\n\t.exit = unix_net_exit,\n};\n\n#if IS_BUILTIN(CONFIG_UNIX) && defined(CONFIG_BPF_SYSCALL) && defined(CONFIG_PROC_FS)\nDEFINE_BPF_ITER_FUNC(unix, struct bpf_iter_meta *meta,\n\t\t     struct unix_sock *unix_sk, uid_t uid)\n\n#define INIT_BATCH_SZ 16\n\nstatic int bpf_iter_init_unix(void *priv_data, struct bpf_iter_aux_info *aux)\n{\n\tstruct bpf_unix_iter_state *iter = priv_data;\n\tint err;\n\n\terr = bpf_iter_init_seq_net(priv_data, aux);\n\tif (err)\n\t\treturn err;\n\n\terr = bpf_iter_unix_realloc_batch(iter, INIT_BATCH_SZ);\n\tif (err) {\n\t\tbpf_iter_fini_seq_net(priv_data);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic void bpf_iter_fini_unix(void *priv_data)\n{\n\tstruct bpf_unix_iter_state *iter = priv_data;\n\n\tbpf_iter_fini_seq_net(priv_data);\n\tkvfree(iter->batch);\n}\n\nstatic const struct bpf_iter_seq_info unix_seq_info = {\n\t.seq_ops\t\t= &bpf_iter_unix_seq_ops,\n\t.init_seq_private\t= bpf_iter_init_unix,\n\t.fini_seq_private\t= bpf_iter_fini_unix,\n\t.seq_priv_size\t\t= sizeof(struct bpf_unix_iter_state),\n};\n\nstatic const struct bpf_func_proto *\nbpf_iter_unix_get_func_proto(enum bpf_func_id func_id,\n\t\t\t     const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_setsockopt:\n\t\treturn &bpf_sk_setsockopt_proto;\n\tcase BPF_FUNC_getsockopt:\n\t\treturn &bpf_sk_getsockopt_proto;\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nstatic struct bpf_iter_reg unix_reg_info = {\n\t.target\t\t\t= \"unix\",\n\t.ctx_arg_info_size\t= 1,\n\t.ctx_arg_info\t\t= {\n\t\t{ offsetof(struct bpf_iter__unix, unix_sk),\n\t\t  PTR_TO_BTF_ID_OR_NULL },\n\t},\n\t.get_func_proto         = bpf_iter_unix_get_func_proto,\n\t.seq_info\t\t= &unix_seq_info,\n};\n\nstatic void __init bpf_iter_register(void)\n{\n\tunix_reg_info.ctx_arg_info[0].btf_id = btf_sock_ids[BTF_SOCK_TYPE_UNIX];\n\tif (bpf_iter_reg_target(&unix_reg_info))\n\t\tpr_warn(\"Warning: could not register bpf iterator unix\\n\");\n}\n#endif\n\nstatic int __init af_unix_init(void)\n{\n\tint i, rc = -1;\n\n\tBUILD_BUG_ON(sizeof(struct unix_skb_parms) > sizeof_field(struct sk_buff, cb));\n\n\tfor (i = 0; i < UNIX_HASH_SIZE / 2; i++) {\n\t\tspin_lock_init(&bsd_socket_locks[i]);\n\t\tINIT_HLIST_HEAD(&bsd_socket_buckets[i]);\n\t}\n\n\trc = proto_register(&unix_dgram_proto, 1);\n\tif (rc != 0) {\n\t\tpr_crit(\"%s: Cannot create unix_sock SLAB cache!\\n\", __func__);\n\t\tgoto out;\n\t}\n\n\trc = proto_register(&unix_stream_proto, 1);\n\tif (rc != 0) {\n\t\tpr_crit(\"%s: Cannot create unix_sock SLAB cache!\\n\", __func__);\n\t\tproto_unregister(&unix_dgram_proto);\n\t\tgoto out;\n\t}\n\n\tsock_register(&unix_family_ops);\n\tregister_pernet_subsys(&unix_net_ops);\n\tunix_bpf_build_proto();\n\n#if IS_BUILTIN(CONFIG_UNIX) && defined(CONFIG_BPF_SYSCALL) && defined(CONFIG_PROC_FS)\n\tbpf_iter_register();\n#endif\n\nout:\n\treturn rc;\n}\n\nstatic void __exit af_unix_exit(void)\n{\n\tsock_unregister(PF_UNIX);\n\tproto_unregister(&unix_dgram_proto);\n\tproto_unregister(&unix_stream_proto);\n\tunregister_pernet_subsys(&unix_net_ops);\n}\n\n \nfs_initcall(af_unix_init);\nmodule_exit(af_unix_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_NETPROTO(PF_UNIX);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}