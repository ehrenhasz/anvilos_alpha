{
  "module_name": "caif_socket.c",
  "hash_id": "8da0701674983551fbaf097690dec3b495de72dcf001d181c807f309c4edbfd3",
  "original_prompt": "Ingested from linux-6.6.14/net/caif/caif_socket.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \":%s(): \" fmt, __func__\n\n#include <linux/filter.h>\n#include <linux/fs.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/sched/signal.h>\n#include <linux/spinlock.h>\n#include <linux/mutex.h>\n#include <linux/list.h>\n#include <linux/wait.h>\n#include <linux/poll.h>\n#include <linux/tcp.h>\n#include <linux/uaccess.h>\n#include <linux/debugfs.h>\n#include <linux/caif/caif_socket.h>\n#include <linux/pkt_sched.h>\n#include <net/sock.h>\n#include <net/tcp_states.h>\n#include <net/caif/caif_layer.h>\n#include <net/caif/caif_dev.h>\n#include <net/caif/cfpkt.h>\n\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_NETPROTO(AF_CAIF);\n\n \nenum caif_states {\n\tCAIF_CONNECTED\t\t= TCP_ESTABLISHED,\n\tCAIF_CONNECTING\t= TCP_SYN_SENT,\n\tCAIF_DISCONNECTED\t= TCP_CLOSE\n};\n\n#define TX_FLOW_ON_BIT\t1\n#define RX_FLOW_ON_BIT\t2\n\nstruct caifsock {\n\tstruct sock sk;  \n\tstruct cflayer layer;\n\tunsigned long flow_state;\n\tstruct caif_connect_request conn_req;\n\tstruct mutex readlock;\n\tstruct dentry *debugfs_socket_dir;\n\tint headroom, tailroom, maxframe;\n};\n\nstatic int rx_flow_is_on(struct caifsock *cf_sk)\n{\n\treturn test_bit(RX_FLOW_ON_BIT, &cf_sk->flow_state);\n}\n\nstatic int tx_flow_is_on(struct caifsock *cf_sk)\n{\n\treturn test_bit(TX_FLOW_ON_BIT, &cf_sk->flow_state);\n}\n\nstatic void set_rx_flow_off(struct caifsock *cf_sk)\n{\n\tclear_bit(RX_FLOW_ON_BIT, &cf_sk->flow_state);\n}\n\nstatic void set_rx_flow_on(struct caifsock *cf_sk)\n{\n\tset_bit(RX_FLOW_ON_BIT, &cf_sk->flow_state);\n}\n\nstatic void set_tx_flow_off(struct caifsock *cf_sk)\n{\n\tclear_bit(TX_FLOW_ON_BIT, &cf_sk->flow_state);\n}\n\nstatic void set_tx_flow_on(struct caifsock *cf_sk)\n{\n\tset_bit(TX_FLOW_ON_BIT, &cf_sk->flow_state);\n}\n\nstatic void caif_read_lock(struct sock *sk)\n{\n\tstruct caifsock *cf_sk;\n\tcf_sk = container_of(sk, struct caifsock, sk);\n\tmutex_lock(&cf_sk->readlock);\n}\n\nstatic void caif_read_unlock(struct sock *sk)\n{\n\tstruct caifsock *cf_sk;\n\tcf_sk = container_of(sk, struct caifsock, sk);\n\tmutex_unlock(&cf_sk->readlock);\n}\n\nstatic int sk_rcvbuf_lowwater(struct caifsock *cf_sk)\n{\n\t \n\treturn cf_sk->sk.sk_rcvbuf / 4;\n}\n\nstatic void caif_flow_ctrl(struct sock *sk, int mode)\n{\n\tstruct caifsock *cf_sk;\n\tcf_sk = container_of(sk, struct caifsock, sk);\n\tif (cf_sk->layer.dn && cf_sk->layer.dn->modemcmd)\n\t\tcf_sk->layer.dn->modemcmd(cf_sk->layer.dn, mode);\n}\n\n \nstatic void caif_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)\n{\n\tint err;\n\tunsigned long flags;\n\tstruct sk_buff_head *list = &sk->sk_receive_queue;\n\tstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\n\tbool queued = false;\n\n\tif (atomic_read(&sk->sk_rmem_alloc) + skb->truesize >=\n\t\t(unsigned int)sk->sk_rcvbuf && rx_flow_is_on(cf_sk)) {\n\t\tnet_dbg_ratelimited(\"sending flow OFF (queue len = %d %d)\\n\",\n\t\t\t\t    atomic_read(&cf_sk->sk.sk_rmem_alloc),\n\t\t\t\t    sk_rcvbuf_lowwater(cf_sk));\n\t\tset_rx_flow_off(cf_sk);\n\t\tcaif_flow_ctrl(sk, CAIF_MODEMCMD_FLOW_OFF_REQ);\n\t}\n\n\terr = sk_filter(sk, skb);\n\tif (err)\n\t\tgoto out;\n\n\tif (!sk_rmem_schedule(sk, skb, skb->truesize) && rx_flow_is_on(cf_sk)) {\n\t\tset_rx_flow_off(cf_sk);\n\t\tnet_dbg_ratelimited(\"sending flow OFF due to rmem_schedule\\n\");\n\t\tcaif_flow_ctrl(sk, CAIF_MODEMCMD_FLOW_OFF_REQ);\n\t}\n\tskb->dev = NULL;\n\tskb_set_owner_r(skb, sk);\n\tspin_lock_irqsave(&list->lock, flags);\n\tqueued = !sock_flag(sk, SOCK_DEAD);\n\tif (queued)\n\t\t__skb_queue_tail(list, skb);\n\tspin_unlock_irqrestore(&list->lock, flags);\nout:\n\tif (queued)\n\t\tsk->sk_data_ready(sk);\n\telse\n\t\tkfree_skb(skb);\n}\n\n \nstatic int caif_sktrecv_cb(struct cflayer *layr, struct cfpkt *pkt)\n{\n\tstruct caifsock *cf_sk;\n\tstruct sk_buff *skb;\n\n\tcf_sk = container_of(layr, struct caifsock, layer);\n\tskb = cfpkt_tonative(pkt);\n\n\tif (unlikely(cf_sk->sk.sk_state != CAIF_CONNECTED)) {\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\tcaif_queue_rcv_skb(&cf_sk->sk, skb);\n\treturn 0;\n}\n\nstatic void cfsk_hold(struct cflayer *layr)\n{\n\tstruct caifsock *cf_sk = container_of(layr, struct caifsock, layer);\n\tsock_hold(&cf_sk->sk);\n}\n\nstatic void cfsk_put(struct cflayer *layr)\n{\n\tstruct caifsock *cf_sk = container_of(layr, struct caifsock, layer);\n\tsock_put(&cf_sk->sk);\n}\n\n \nstatic void caif_ctrl_cb(struct cflayer *layr,\n\t\t\t enum caif_ctrlcmd flow,\n\t\t\t int phyid)\n{\n\tstruct caifsock *cf_sk = container_of(layr, struct caifsock, layer);\n\tswitch (flow) {\n\tcase CAIF_CTRLCMD_FLOW_ON_IND:\n\t\t \n\t\tset_tx_flow_on(cf_sk);\n\t\tcf_sk->sk.sk_state_change(&cf_sk->sk);\n\t\tbreak;\n\n\tcase CAIF_CTRLCMD_FLOW_OFF_IND:\n\t\t \n\t\tset_tx_flow_off(cf_sk);\n\t\tcf_sk->sk.sk_state_change(&cf_sk->sk);\n\t\tbreak;\n\n\tcase CAIF_CTRLCMD_INIT_RSP:\n\t\t \n\t\tcaif_client_register_refcnt(&cf_sk->layer,\n\t\t\t\t\t\tcfsk_hold, cfsk_put);\n\t\tcf_sk->sk.sk_state = CAIF_CONNECTED;\n\t\tset_tx_flow_on(cf_sk);\n\t\tcf_sk->sk.sk_shutdown = 0;\n\t\tcf_sk->sk.sk_state_change(&cf_sk->sk);\n\t\tbreak;\n\n\tcase CAIF_CTRLCMD_DEINIT_RSP:\n\t\t \n\t\tcf_sk->sk.sk_state = CAIF_DISCONNECTED;\n\t\tcf_sk->sk.sk_state_change(&cf_sk->sk);\n\t\tbreak;\n\n\tcase CAIF_CTRLCMD_INIT_FAIL_RSP:\n\t\t \n\t\tcf_sk->sk.sk_err = ECONNREFUSED;\n\t\tcf_sk->sk.sk_state = CAIF_DISCONNECTED;\n\t\tcf_sk->sk.sk_shutdown = SHUTDOWN_MASK;\n\t\t \n\t\tset_tx_flow_on(cf_sk);\n\t\tcf_sk->sk.sk_state_change(&cf_sk->sk);\n\t\tbreak;\n\n\tcase CAIF_CTRLCMD_REMOTE_SHUTDOWN_IND:\n\t\t \n\t\tcf_sk->sk.sk_shutdown = SHUTDOWN_MASK;\n\t\tcf_sk->sk.sk_err = ECONNRESET;\n\t\tset_rx_flow_on(cf_sk);\n\t\tsk_error_report(&cf_sk->sk);\n\t\tbreak;\n\n\tdefault:\n\t\tpr_debug(\"Unexpected flow command %d\\n\", flow);\n\t}\n}\n\nstatic void caif_check_flow_release(struct sock *sk)\n{\n\tstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\n\n\tif (rx_flow_is_on(cf_sk))\n\t\treturn;\n\n\tif (atomic_read(&sk->sk_rmem_alloc) <= sk_rcvbuf_lowwater(cf_sk)) {\n\t\t\tset_rx_flow_on(cf_sk);\n\t\t\tcaif_flow_ctrl(sk, CAIF_MODEMCMD_FLOW_ON_REQ);\n\t}\n}\n\n \nstatic int caif_seqpkt_recvmsg(struct socket *sock, struct msghdr *m,\n\t\t\t       size_t len, int flags)\n\n{\n\tstruct sock *sk = sock->sk;\n\tstruct sk_buff *skb;\n\tint ret;\n\tint copylen;\n\n\tret = -EOPNOTSUPP;\n\tif (flags & MSG_OOB)\n\t\tgoto read_error;\n\n\tskb = skb_recv_datagram(sk, flags, &ret);\n\tif (!skb)\n\t\tgoto read_error;\n\tcopylen = skb->len;\n\tif (len < copylen) {\n\t\tm->msg_flags |= MSG_TRUNC;\n\t\tcopylen = len;\n\t}\n\n\tret = skb_copy_datagram_msg(skb, 0, m, copylen);\n\tif (ret)\n\t\tgoto out_free;\n\n\tret = (flags & MSG_TRUNC) ? skb->len : copylen;\nout_free:\n\tskb_free_datagram(sk, skb);\n\tcaif_check_flow_release(sk);\n\treturn ret;\n\nread_error:\n\treturn ret;\n}\n\n\n \nstatic long caif_stream_data_wait(struct sock *sk, long timeo)\n{\n\tDEFINE_WAIT(wait);\n\tlock_sock(sk);\n\n\tfor (;;) {\n\t\tprepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);\n\n\t\tif (!skb_queue_empty(&sk->sk_receive_queue) ||\n\t\t\tsk->sk_err ||\n\t\t\tsk->sk_state != CAIF_CONNECTED ||\n\t\t\tsock_flag(sk, SOCK_DEAD) ||\n\t\t\t(sk->sk_shutdown & RCV_SHUTDOWN) ||\n\t\t\tsignal_pending(current) ||\n\t\t\t!timeo)\n\t\t\tbreak;\n\n\t\tsk_set_bit(SOCKWQ_ASYNC_WAITDATA, sk);\n\t\trelease_sock(sk);\n\t\ttimeo = schedule_timeout(timeo);\n\t\tlock_sock(sk);\n\n\t\tif (sock_flag(sk, SOCK_DEAD))\n\t\t\tbreak;\n\n\t\tsk_clear_bit(SOCKWQ_ASYNC_WAITDATA, sk);\n\t}\n\n\tfinish_wait(sk_sleep(sk), &wait);\n\trelease_sock(sk);\n\treturn timeo;\n}\n\n\n \nstatic int caif_stream_recvmsg(struct socket *sock, struct msghdr *msg,\n\t\t\t       size_t size, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tint copied = 0;\n\tint target;\n\tint err = 0;\n\tlong timeo;\n\n\terr = -EOPNOTSUPP;\n\tif (flags&MSG_OOB)\n\t\tgoto out;\n\n\t \n\terr = -EAGAIN;\n\tif (sk->sk_state == CAIF_CONNECTING)\n\t\tgoto out;\n\n\tcaif_read_lock(sk);\n\ttarget = sock_rcvlowat(sk, flags&MSG_WAITALL, size);\n\ttimeo = sock_rcvtimeo(sk, flags&MSG_DONTWAIT);\n\n\tdo {\n\t\tint chunk;\n\t\tstruct sk_buff *skb;\n\n\t\tlock_sock(sk);\n\t\tif (sock_flag(sk, SOCK_DEAD)) {\n\t\t\terr = -ECONNRESET;\n\t\t\tgoto unlock;\n\t\t}\n\t\tskb = skb_dequeue(&sk->sk_receive_queue);\n\t\tcaif_check_flow_release(sk);\n\n\t\tif (skb == NULL) {\n\t\t\tif (copied >= target)\n\t\t\t\tgoto unlock;\n\t\t\t \n\t\t\terr = sock_error(sk);\n\t\t\tif (err)\n\t\t\t\tgoto unlock;\n\t\t\terr = -ECONNRESET;\n\t\t\tif (sk->sk_shutdown & RCV_SHUTDOWN)\n\t\t\t\tgoto unlock;\n\n\t\t\terr = -EPIPE;\n\t\t\tif (sk->sk_state != CAIF_CONNECTED)\n\t\t\t\tgoto unlock;\n\t\t\tif (sock_flag(sk, SOCK_DEAD))\n\t\t\t\tgoto unlock;\n\n\t\t\trelease_sock(sk);\n\n\t\t\terr = -EAGAIN;\n\t\t\tif (!timeo)\n\t\t\t\tbreak;\n\n\t\t\tcaif_read_unlock(sk);\n\n\t\t\ttimeo = caif_stream_data_wait(sk, timeo);\n\n\t\t\tif (signal_pending(current)) {\n\t\t\t\terr = sock_intr_errno(timeo);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tcaif_read_lock(sk);\n\t\t\tcontinue;\nunlock:\n\t\t\trelease_sock(sk);\n\t\t\tbreak;\n\t\t}\n\t\trelease_sock(sk);\n\t\tchunk = min_t(unsigned int, skb->len, size);\n\t\tif (memcpy_to_msg(msg, skb->data, chunk)) {\n\t\t\tskb_queue_head(&sk->sk_receive_queue, skb);\n\t\t\tif (copied == 0)\n\t\t\t\tcopied = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tcopied += chunk;\n\t\tsize -= chunk;\n\n\t\t \n\t\tif (!(flags & MSG_PEEK)) {\n\t\t\tskb_pull(skb, chunk);\n\n\t\t\t \n\t\t\tif (skb->len) {\n\t\t\t\tskb_queue_head(&sk->sk_receive_queue, skb);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tkfree_skb(skb);\n\n\t\t} else {\n\t\t\t \n\t\t\t \n\t\t\tskb_queue_head(&sk->sk_receive_queue, skb);\n\t\t\tbreak;\n\t\t}\n\t} while (size);\n\tcaif_read_unlock(sk);\n\nout:\n\treturn copied ? : err;\n}\n\n \nstatic long caif_wait_for_flow_on(struct caifsock *cf_sk,\n\t\t\t\t  int wait_writeable, long timeo, int *err)\n{\n\tstruct sock *sk = &cf_sk->sk;\n\tDEFINE_WAIT(wait);\n\tfor (;;) {\n\t\t*err = 0;\n\t\tif (tx_flow_is_on(cf_sk) &&\n\t\t\t(!wait_writeable || sock_writeable(&cf_sk->sk)))\n\t\t\tbreak;\n\t\t*err = -ETIMEDOUT;\n\t\tif (!timeo)\n\t\t\tbreak;\n\t\t*err = -ERESTARTSYS;\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\t\tprepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);\n\t\t*err = -ECONNRESET;\n\t\tif (sk->sk_shutdown & SHUTDOWN_MASK)\n\t\t\tbreak;\n\t\t*err = -sk->sk_err;\n\t\tif (sk->sk_err)\n\t\t\tbreak;\n\t\t*err = -EPIPE;\n\t\tif (cf_sk->sk.sk_state != CAIF_CONNECTED)\n\t\t\tbreak;\n\t\ttimeo = schedule_timeout(timeo);\n\t}\n\tfinish_wait(sk_sleep(sk), &wait);\n\treturn timeo;\n}\n\n \nstatic int transmit_skb(struct sk_buff *skb, struct caifsock *cf_sk,\n\t\t\tint noblock, long timeo)\n{\n\tstruct cfpkt *pkt;\n\n\tpkt = cfpkt_fromnative(CAIF_DIR_OUT, skb);\n\tmemset(skb->cb, 0, sizeof(struct caif_payload_info));\n\tcfpkt_set_prio(pkt, cf_sk->sk.sk_priority);\n\n\tif (cf_sk->layer.dn == NULL) {\n\t\tkfree_skb(skb);\n\t\treturn -EINVAL;\n\t}\n\n\treturn cf_sk->layer.dn->transmit(cf_sk->layer.dn, pkt);\n}\n\n \nstatic int caif_seqpkt_sendmsg(struct socket *sock, struct msghdr *msg,\n\t\t\t       size_t len)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\n\tint buffer_size;\n\tint ret = 0;\n\tstruct sk_buff *skb = NULL;\n\tint noblock;\n\tlong timeo;\n\tcaif_assert(cf_sk);\n\tret = sock_error(sk);\n\tif (ret)\n\t\tgoto err;\n\n\tret = -EOPNOTSUPP;\n\tif (msg->msg_flags&MSG_OOB)\n\t\tgoto err;\n\n\tret = -EOPNOTSUPP;\n\tif (msg->msg_namelen)\n\t\tgoto err;\n\n\tnoblock = msg->msg_flags & MSG_DONTWAIT;\n\n\ttimeo = sock_sndtimeo(sk, noblock);\n\ttimeo = caif_wait_for_flow_on(container_of(sk, struct caifsock, sk),\n\t\t\t\t1, timeo, &ret);\n\n\tif (ret)\n\t\tgoto err;\n\tret = -EPIPE;\n\tif (cf_sk->sk.sk_state != CAIF_CONNECTED ||\n\t\tsock_flag(sk, SOCK_DEAD) ||\n\t\t(sk->sk_shutdown & RCV_SHUTDOWN))\n\t\tgoto err;\n\n\t \n\tret = -EMSGSIZE;\n\tif (len > cf_sk->maxframe && cf_sk->sk.sk_protocol != CAIFPROTO_RFM)\n\t\tgoto err;\n\n\tbuffer_size = len + cf_sk->headroom + cf_sk->tailroom;\n\n\tret = -ENOMEM;\n\tskb = sock_alloc_send_skb(sk, buffer_size, noblock, &ret);\n\n\tif (!skb || skb_tailroom(skb) < buffer_size)\n\t\tgoto err;\n\n\tskb_reserve(skb, cf_sk->headroom);\n\n\tret = memcpy_from_msg(skb_put(skb, len), msg, len);\n\n\tif (ret)\n\t\tgoto err;\n\tret = transmit_skb(skb, cf_sk, noblock, timeo);\n\tif (ret < 0)\n\t\t \n\t\treturn ret;\n\n\treturn len;\nerr:\n\tkfree_skb(skb);\n\treturn ret;\n}\n\n \nstatic int caif_stream_sendmsg(struct socket *sock, struct msghdr *msg,\n\t\t\t       size_t len)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\n\tint err, size;\n\tstruct sk_buff *skb;\n\tint sent = 0;\n\tlong timeo;\n\n\terr = -EOPNOTSUPP;\n\tif (unlikely(msg->msg_flags&MSG_OOB))\n\t\tgoto out_err;\n\n\tif (unlikely(msg->msg_namelen))\n\t\tgoto out_err;\n\n\ttimeo = sock_sndtimeo(sk, msg->msg_flags & MSG_DONTWAIT);\n\ttimeo = caif_wait_for_flow_on(cf_sk, 1, timeo, &err);\n\n\tif (unlikely(sk->sk_shutdown & SEND_SHUTDOWN))\n\t\tgoto pipe_err;\n\n\twhile (sent < len) {\n\n\t\tsize = len-sent;\n\n\t\tif (size > cf_sk->maxframe)\n\t\t\tsize = cf_sk->maxframe;\n\n\t\t \n\t\tif (size > ((sk->sk_sndbuf >> 1) - 64))\n\t\t\tsize = (sk->sk_sndbuf >> 1) - 64;\n\n\t\tif (size > SKB_MAX_ALLOC)\n\t\t\tsize = SKB_MAX_ALLOC;\n\n\t\tskb = sock_alloc_send_skb(sk,\n\t\t\t\t\tsize + cf_sk->headroom +\n\t\t\t\t\tcf_sk->tailroom,\n\t\t\t\t\tmsg->msg_flags&MSG_DONTWAIT,\n\t\t\t\t\t&err);\n\t\tif (skb == NULL)\n\t\t\tgoto out_err;\n\n\t\tskb_reserve(skb, cf_sk->headroom);\n\t\t \n\t\tsize = min_t(int, size, skb_tailroom(skb));\n\n\t\terr = memcpy_from_msg(skb_put(skb, size), msg, size);\n\t\tif (err) {\n\t\t\tkfree_skb(skb);\n\t\t\tgoto out_err;\n\t\t}\n\t\terr = transmit_skb(skb, cf_sk,\n\t\t\t\tmsg->msg_flags&MSG_DONTWAIT, timeo);\n\t\tif (err < 0)\n\t\t\t \n\t\t\tgoto pipe_err;\n\n\t\tsent += size;\n\t}\n\n\treturn sent;\n\npipe_err:\n\tif (sent == 0 && !(msg->msg_flags&MSG_NOSIGNAL))\n\t\tsend_sig(SIGPIPE, current, 0);\n\terr = -EPIPE;\nout_err:\n\treturn sent ? : err;\n}\n\nstatic int setsockopt(struct socket *sock, int lvl, int opt, sockptr_t ov,\n\t\tunsigned int ol)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\n\tint linksel;\n\n\tif (cf_sk->sk.sk_socket->state != SS_UNCONNECTED)\n\t\treturn -ENOPROTOOPT;\n\n\tswitch (opt) {\n\tcase CAIFSO_LINK_SELECT:\n\t\tif (ol < sizeof(int))\n\t\t\treturn -EINVAL;\n\t\tif (lvl != SOL_CAIF)\n\t\t\tgoto bad_sol;\n\t\tif (copy_from_sockptr(&linksel, ov, sizeof(int)))\n\t\t\treturn -EINVAL;\n\t\tlock_sock(&(cf_sk->sk));\n\t\tcf_sk->conn_req.link_selector = linksel;\n\t\trelease_sock(&cf_sk->sk);\n\t\treturn 0;\n\n\tcase CAIFSO_REQ_PARAM:\n\t\tif (lvl != SOL_CAIF)\n\t\t\tgoto bad_sol;\n\t\tif (cf_sk->sk.sk_protocol != CAIFPROTO_UTIL)\n\t\t\treturn -ENOPROTOOPT;\n\t\tlock_sock(&(cf_sk->sk));\n\t\tif (ol > sizeof(cf_sk->conn_req.param.data) ||\n\t\t    copy_from_sockptr(&cf_sk->conn_req.param.data, ov, ol)) {\n\t\t\trelease_sock(&cf_sk->sk);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tcf_sk->conn_req.param.size = ol;\n\t\trelease_sock(&cf_sk->sk);\n\t\treturn 0;\n\n\tdefault:\n\t\treturn -ENOPROTOOPT;\n\t}\n\n\treturn 0;\nbad_sol:\n\treturn -ENOPROTOOPT;\n\n}\n\n \nstatic int caif_connect(struct socket *sock, struct sockaddr *uaddr,\n\t\t\tint addr_len, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\n\tlong timeo;\n\tint err;\n\tint ifindex, headroom, tailroom;\n\tunsigned int mtu;\n\tstruct net_device *dev;\n\n\tlock_sock(sk);\n\n\terr = -EINVAL;\n\tif (addr_len < offsetofend(struct sockaddr, sa_family))\n\t\tgoto out;\n\n\terr = -EAFNOSUPPORT;\n\tif (uaddr->sa_family != AF_CAIF)\n\t\tgoto out;\n\n\tswitch (sock->state) {\n\tcase SS_UNCONNECTED:\n\t\t \n\t\tcaif_assert(sk->sk_state == CAIF_DISCONNECTED);\n\t\tbreak;\n\tcase SS_CONNECTING:\n\t\tswitch (sk->sk_state) {\n\t\tcase CAIF_CONNECTED:\n\t\t\tsock->state = SS_CONNECTED;\n\t\t\terr = -EISCONN;\n\t\t\tgoto out;\n\t\tcase CAIF_DISCONNECTED:\n\t\t\t \n\t\t\tbreak;\n\t\tcase CAIF_CONNECTING:\n\t\t\terr = -EALREADY;\n\t\t\tif (flags & O_NONBLOCK)\n\t\t\t\tgoto out;\n\t\t\tgoto wait_connect;\n\t\t}\n\t\tbreak;\n\tcase SS_CONNECTED:\n\t\tcaif_assert(sk->sk_state == CAIF_CONNECTED ||\n\t\t\t\tsk->sk_state == CAIF_DISCONNECTED);\n\t\tif (sk->sk_shutdown & SHUTDOWN_MASK) {\n\t\t\t \n\t\t\tcaif_disconnect_client(sock_net(sk), &cf_sk->layer);\n\t\t\tcaif_free_client(&cf_sk->layer);\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\terr = -EISCONN;\n\t\tgoto out;\n\tcase SS_DISCONNECTING:\n\tcase SS_FREE:\n\t\tcaif_assert(1);  \n\t\tbreak;\n\t}\n\tsk->sk_state = CAIF_DISCONNECTED;\n\tsock->state = SS_UNCONNECTED;\n\tsk_stream_kill_queues(&cf_sk->sk);\n\n\terr = -EINVAL;\n\tif (addr_len != sizeof(struct sockaddr_caif))\n\t\tgoto out;\n\n\tmemcpy(&cf_sk->conn_req.sockaddr, uaddr,\n\t\tsizeof(struct sockaddr_caif));\n\n\t \n\tsock->state = SS_CONNECTING;\n\tsk->sk_state = CAIF_CONNECTING;\n\n\t \n\t \n\tif (cf_sk->sk.sk_priority > CAIF_PRIO_MAX)\n\t\tcf_sk->conn_req.priority = CAIF_PRIO_MAX;\n\telse if (cf_sk->sk.sk_priority < CAIF_PRIO_MIN)\n\t\tcf_sk->conn_req.priority = CAIF_PRIO_MIN;\n\telse\n\t\tcf_sk->conn_req.priority = cf_sk->sk.sk_priority;\n\n\t \n\tcf_sk->conn_req.ifindex = cf_sk->sk.sk_bound_dev_if;\n\n\tcf_sk->layer.receive = caif_sktrecv_cb;\n\n\terr = caif_connect_client(sock_net(sk), &cf_sk->conn_req,\n\t\t\t\t&cf_sk->layer, &ifindex, &headroom, &tailroom);\n\n\tif (err < 0) {\n\t\tcf_sk->sk.sk_socket->state = SS_UNCONNECTED;\n\t\tcf_sk->sk.sk_state = CAIF_DISCONNECTED;\n\t\tgoto out;\n\t}\n\n\terr = -ENODEV;\n\trcu_read_lock();\n\tdev = dev_get_by_index_rcu(sock_net(sk), ifindex);\n\tif (!dev) {\n\t\trcu_read_unlock();\n\t\tgoto out;\n\t}\n\tcf_sk->headroom = LL_RESERVED_SPACE_EXTRA(dev, headroom);\n\tmtu = dev->mtu;\n\trcu_read_unlock();\n\n\tcf_sk->tailroom = tailroom;\n\tcf_sk->maxframe = mtu - (headroom + tailroom);\n\tif (cf_sk->maxframe < 1) {\n\t\tpr_warn(\"CAIF Interface MTU too small (%d)\\n\", dev->mtu);\n\t\terr = -ENODEV;\n\t\tgoto out;\n\t}\n\n\terr = -EINPROGRESS;\nwait_connect:\n\n\tif (sk->sk_state != CAIF_CONNECTED && (flags & O_NONBLOCK))\n\t\tgoto out;\n\n\ttimeo = sock_sndtimeo(sk, flags & O_NONBLOCK);\n\n\trelease_sock(sk);\n\terr = -ERESTARTSYS;\n\ttimeo = wait_event_interruptible_timeout(*sk_sleep(sk),\n\t\t\tsk->sk_state != CAIF_CONNECTING,\n\t\t\ttimeo);\n\tlock_sock(sk);\n\tif (timeo < 0)\n\t\tgoto out;  \n\n\terr = -ETIMEDOUT;\n\tif (timeo == 0 && sk->sk_state != CAIF_CONNECTED)\n\t\tgoto out;\n\tif (sk->sk_state != CAIF_CONNECTED) {\n\t\tsock->state = SS_UNCONNECTED;\n\t\terr = sock_error(sk);\n\t\tif (!err)\n\t\t\terr = -ECONNREFUSED;\n\t\tgoto out;\n\t}\n\tsock->state = SS_CONNECTED;\n\terr = 0;\nout:\n\trelease_sock(sk);\n\treturn err;\n}\n\n \nstatic int caif_release(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\n\n\tif (!sk)\n\t\treturn 0;\n\n\tset_tx_flow_off(cf_sk);\n\n\t \n\tspin_lock_bh(&sk->sk_receive_queue.lock);\n\tsock_set_flag(sk, SOCK_DEAD);\n\tspin_unlock_bh(&sk->sk_receive_queue.lock);\n\tsock->sk = NULL;\n\n\tWARN_ON(IS_ERR(cf_sk->debugfs_socket_dir));\n\tdebugfs_remove_recursive(cf_sk->debugfs_socket_dir);\n\n\tlock_sock(&(cf_sk->sk));\n\tsk->sk_state = CAIF_DISCONNECTED;\n\tsk->sk_shutdown = SHUTDOWN_MASK;\n\n\tcaif_disconnect_client(sock_net(sk), &cf_sk->layer);\n\tcf_sk->sk.sk_socket->state = SS_DISCONNECTING;\n\twake_up_interruptible_poll(sk_sleep(sk), EPOLLERR|EPOLLHUP);\n\n\tsock_orphan(sk);\n\tsk_stream_kill_queues(&cf_sk->sk);\n\trelease_sock(sk);\n\tsock_put(sk);\n\treturn 0;\n}\n\n \nstatic __poll_t caif_poll(struct file *file,\n\t\t\t      struct socket *sock, poll_table *wait)\n{\n\tstruct sock *sk = sock->sk;\n\t__poll_t mask;\n\tstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\n\n\tsock_poll_wait(file, sock, wait);\n\tmask = 0;\n\n\t \n\tif (sk->sk_err)\n\t\tmask |= EPOLLERR;\n\tif (sk->sk_shutdown == SHUTDOWN_MASK)\n\t\tmask |= EPOLLHUP;\n\tif (sk->sk_shutdown & RCV_SHUTDOWN)\n\t\tmask |= EPOLLRDHUP;\n\n\t \n\tif (!skb_queue_empty_lockless(&sk->sk_receive_queue) ||\n\t\t(sk->sk_shutdown & RCV_SHUTDOWN))\n\t\tmask |= EPOLLIN | EPOLLRDNORM;\n\n\t \n\tif (sock_writeable(sk) && tx_flow_is_on(cf_sk))\n\t\tmask |= EPOLLOUT | EPOLLWRNORM | EPOLLWRBAND;\n\n\treturn mask;\n}\n\nstatic const struct proto_ops caif_seqpacket_ops = {\n\t.family = PF_CAIF,\n\t.owner = THIS_MODULE,\n\t.release = caif_release,\n\t.bind = sock_no_bind,\n\t.connect = caif_connect,\n\t.socketpair = sock_no_socketpair,\n\t.accept = sock_no_accept,\n\t.getname = sock_no_getname,\n\t.poll = caif_poll,\n\t.ioctl = sock_no_ioctl,\n\t.listen = sock_no_listen,\n\t.shutdown = sock_no_shutdown,\n\t.setsockopt = setsockopt,\n\t.sendmsg = caif_seqpkt_sendmsg,\n\t.recvmsg = caif_seqpkt_recvmsg,\n\t.mmap = sock_no_mmap,\n};\n\nstatic const struct proto_ops caif_stream_ops = {\n\t.family = PF_CAIF,\n\t.owner = THIS_MODULE,\n\t.release = caif_release,\n\t.bind = sock_no_bind,\n\t.connect = caif_connect,\n\t.socketpair = sock_no_socketpair,\n\t.accept = sock_no_accept,\n\t.getname = sock_no_getname,\n\t.poll = caif_poll,\n\t.ioctl = sock_no_ioctl,\n\t.listen = sock_no_listen,\n\t.shutdown = sock_no_shutdown,\n\t.setsockopt = setsockopt,\n\t.sendmsg = caif_stream_sendmsg,\n\t.recvmsg = caif_stream_recvmsg,\n\t.mmap = sock_no_mmap,\n};\n\n \nstatic void caif_sock_destructor(struct sock *sk)\n{\n\tstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\n\tcaif_assert(!refcount_read(&sk->sk_wmem_alloc));\n\tcaif_assert(sk_unhashed(sk));\n\tcaif_assert(!sk->sk_socket);\n\tif (!sock_flag(sk, SOCK_DEAD)) {\n\t\tpr_debug(\"Attempt to release alive CAIF socket: %p\\n\", sk);\n\t\treturn;\n\t}\n\tsk_stream_kill_queues(&cf_sk->sk);\n\tWARN_ON_ONCE(sk->sk_forward_alloc);\n\tcaif_free_client(&cf_sk->layer);\n}\n\nstatic int caif_create(struct net *net, struct socket *sock, int protocol,\n\t\t       int kern)\n{\n\tstruct sock *sk = NULL;\n\tstruct caifsock *cf_sk = NULL;\n\tstatic struct proto prot = {.name = \"PF_CAIF\",\n\t\t.owner = THIS_MODULE,\n\t\t.obj_size = sizeof(struct caifsock),\n\t\t.useroffset = offsetof(struct caifsock, conn_req.param),\n\t\t.usersize = sizeof_field(struct caifsock, conn_req.param)\n\t};\n\n\tif (!capable(CAP_SYS_ADMIN) && !capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\t \n\tif (sock->type == SOCK_SEQPACKET)\n\t\tsock->ops = &caif_seqpacket_ops;\n\telse if (sock->type == SOCK_STREAM)\n\t\tsock->ops = &caif_stream_ops;\n\telse\n\t\treturn -ESOCKTNOSUPPORT;\n\n\tif (protocol < 0 || protocol >= CAIFPROTO_MAX)\n\t\treturn -EPROTONOSUPPORT;\n\t \n\tsk = sk_alloc(net, PF_CAIF, GFP_KERNEL, &prot, kern);\n\tif (!sk)\n\t\treturn -ENOMEM;\n\n\tcf_sk = container_of(sk, struct caifsock, sk);\n\n\t \n\tsk->sk_protocol = (unsigned char) protocol;\n\n\t \n\tswitch (protocol) {\n\tcase CAIFPROTO_AT:\n\t\tsk->sk_priority = TC_PRIO_CONTROL;\n\t\tbreak;\n\tcase CAIFPROTO_RFM:\n\t\tsk->sk_priority = TC_PRIO_INTERACTIVE_BULK;\n\t\tbreak;\n\tdefault:\n\t\tsk->sk_priority = TC_PRIO_BESTEFFORT;\n\t}\n\n\t \n\tlock_sock(&(cf_sk->sk));\n\n\t \n\tsock_init_data(sock, sk);\n\tsk->sk_destruct = caif_sock_destructor;\n\n\tmutex_init(&cf_sk->readlock);  \n\tcf_sk->layer.ctrlcmd = caif_ctrl_cb;\n\tcf_sk->sk.sk_socket->state = SS_UNCONNECTED;\n\tcf_sk->sk.sk_state = CAIF_DISCONNECTED;\n\n\tset_tx_flow_off(cf_sk);\n\tset_rx_flow_on(cf_sk);\n\n\t \n\tcf_sk->conn_req.link_selector = CAIF_LINK_LOW_LATENCY;\n\tcf_sk->conn_req.protocol = protocol;\n\trelease_sock(&cf_sk->sk);\n\treturn 0;\n}\n\n\nstatic const struct net_proto_family caif_family_ops = {\n\t.family = PF_CAIF,\n\t.create = caif_create,\n\t.owner = THIS_MODULE,\n};\n\nstatic int __init caif_sktinit_module(void)\n{\n\treturn sock_register(&caif_family_ops);\n}\n\nstatic void __exit caif_sktexit_module(void)\n{\n\tsock_unregister(PF_CAIF);\n}\nmodule_init(caif_sktinit_module);\nmodule_exit(caif_sktexit_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}