{
  "module_name": "virtio_transport.c",
  "hash_id": "e0a3ed75959a82299af4fcbcfa773106f585b75adc52d1fc73daeeac7e660682",
  "original_prompt": "Ingested from linux-6.6.14/net/vmw_vsock/virtio_transport.c",
  "human_readable_source": "\n \n#include <linux/spinlock.h>\n#include <linux/module.h>\n#include <linux/list.h>\n#include <linux/atomic.h>\n#include <linux/virtio.h>\n#include <linux/virtio_ids.h>\n#include <linux/virtio_config.h>\n#include <linux/virtio_vsock.h>\n#include <net/sock.h>\n#include <linux/mutex.h>\n#include <net/af_vsock.h>\n\nstatic struct workqueue_struct *virtio_vsock_workqueue;\nstatic struct virtio_vsock __rcu *the_virtio_vsock;\nstatic DEFINE_MUTEX(the_virtio_vsock_mutex);  \nstatic struct virtio_transport virtio_transport;  \n\nstruct virtio_vsock {\n\tstruct virtio_device *vdev;\n\tstruct virtqueue *vqs[VSOCK_VQ_MAX];\n\n\t \n\tstruct work_struct tx_work;\n\tstruct work_struct rx_work;\n\tstruct work_struct event_work;\n\n\t \n\tstruct mutex tx_lock;\n\tbool tx_run;\n\n\tstruct work_struct send_pkt_work;\n\tstruct sk_buff_head send_pkt_queue;\n\n\tatomic_t queued_replies;\n\n\t \n\tstruct mutex rx_lock;\n\tbool rx_run;\n\tint rx_buf_nr;\n\tint rx_buf_max_nr;\n\n\t \n\tstruct mutex event_lock;\n\tbool event_run;\n\tstruct virtio_vsock_event event_list[8];\n\n\tu32 guest_cid;\n\tbool seqpacket_allow;\n};\n\nstatic u32 virtio_transport_get_local_cid(void)\n{\n\tstruct virtio_vsock *vsock;\n\tu32 ret;\n\n\trcu_read_lock();\n\tvsock = rcu_dereference(the_virtio_vsock);\n\tif (!vsock) {\n\t\tret = VMADDR_CID_ANY;\n\t\tgoto out_rcu;\n\t}\n\n\tret = vsock->guest_cid;\nout_rcu:\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic void\nvirtio_transport_send_pkt_work(struct work_struct *work)\n{\n\tstruct virtio_vsock *vsock =\n\t\tcontainer_of(work, struct virtio_vsock, send_pkt_work);\n\tstruct virtqueue *vq;\n\tbool added = false;\n\tbool restart_rx = false;\n\n\tmutex_lock(&vsock->tx_lock);\n\n\tif (!vsock->tx_run)\n\t\tgoto out;\n\n\tvq = vsock->vqs[VSOCK_VQ_TX];\n\n\tfor (;;) {\n\t\tstruct scatterlist hdr, buf, *sgs[2];\n\t\tint ret, in_sg = 0, out_sg = 0;\n\t\tstruct sk_buff *skb;\n\t\tbool reply;\n\n\t\tskb = virtio_vsock_skb_dequeue(&vsock->send_pkt_queue);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tvirtio_transport_deliver_tap_pkt(skb);\n\t\treply = virtio_vsock_skb_reply(skb);\n\n\t\tsg_init_one(&hdr, virtio_vsock_hdr(skb), sizeof(*virtio_vsock_hdr(skb)));\n\t\tsgs[out_sg++] = &hdr;\n\t\tif (skb->len > 0) {\n\t\t\tsg_init_one(&buf, skb->data, skb->len);\n\t\t\tsgs[out_sg++] = &buf;\n\t\t}\n\n\t\tret = virtqueue_add_sgs(vq, sgs, out_sg, in_sg, skb, GFP_KERNEL);\n\t\t \n\t\tif (ret < 0) {\n\t\t\tvirtio_vsock_skb_queue_head(&vsock->send_pkt_queue, skb);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (reply) {\n\t\t\tstruct virtqueue *rx_vq = vsock->vqs[VSOCK_VQ_RX];\n\t\t\tint val;\n\n\t\t\tval = atomic_dec_return(&vsock->queued_replies);\n\n\t\t\t \n\t\t\tif (val + 1 == virtqueue_get_vring_size(rx_vq))\n\t\t\t\trestart_rx = true;\n\t\t}\n\n\t\tadded = true;\n\t}\n\n\tif (added)\n\t\tvirtqueue_kick(vq);\n\nout:\n\tmutex_unlock(&vsock->tx_lock);\n\n\tif (restart_rx)\n\t\tqueue_work(virtio_vsock_workqueue, &vsock->rx_work);\n}\n\nstatic int\nvirtio_transport_send_pkt(struct sk_buff *skb)\n{\n\tstruct virtio_vsock_hdr *hdr;\n\tstruct virtio_vsock *vsock;\n\tint len = skb->len;\n\n\thdr = virtio_vsock_hdr(skb);\n\n\trcu_read_lock();\n\tvsock = rcu_dereference(the_virtio_vsock);\n\tif (!vsock) {\n\t\tkfree_skb(skb);\n\t\tlen = -ENODEV;\n\t\tgoto out_rcu;\n\t}\n\n\tif (le64_to_cpu(hdr->dst_cid) == vsock->guest_cid) {\n\t\tkfree_skb(skb);\n\t\tlen = -ENODEV;\n\t\tgoto out_rcu;\n\t}\n\n\tif (virtio_vsock_skb_reply(skb))\n\t\tatomic_inc(&vsock->queued_replies);\n\n\tvirtio_vsock_skb_queue_tail(&vsock->send_pkt_queue, skb);\n\tqueue_work(virtio_vsock_workqueue, &vsock->send_pkt_work);\n\nout_rcu:\n\trcu_read_unlock();\n\treturn len;\n}\n\nstatic int\nvirtio_transport_cancel_pkt(struct vsock_sock *vsk)\n{\n\tstruct virtio_vsock *vsock;\n\tint cnt = 0, ret;\n\n\trcu_read_lock();\n\tvsock = rcu_dereference(the_virtio_vsock);\n\tif (!vsock) {\n\t\tret = -ENODEV;\n\t\tgoto out_rcu;\n\t}\n\n\tcnt = virtio_transport_purge_skbs(vsk, &vsock->send_pkt_queue);\n\n\tif (cnt) {\n\t\tstruct virtqueue *rx_vq = vsock->vqs[VSOCK_VQ_RX];\n\t\tint new_cnt;\n\n\t\tnew_cnt = atomic_sub_return(cnt, &vsock->queued_replies);\n\t\tif (new_cnt + cnt >= virtqueue_get_vring_size(rx_vq) &&\n\t\t    new_cnt < virtqueue_get_vring_size(rx_vq))\n\t\t\tqueue_work(virtio_vsock_workqueue, &vsock->rx_work);\n\t}\n\n\tret = 0;\n\nout_rcu:\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic void virtio_vsock_rx_fill(struct virtio_vsock *vsock)\n{\n\tint total_len = VIRTIO_VSOCK_DEFAULT_RX_BUF_SIZE + VIRTIO_VSOCK_SKB_HEADROOM;\n\tstruct scatterlist pkt, *p;\n\tstruct virtqueue *vq;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tvq = vsock->vqs[VSOCK_VQ_RX];\n\n\tdo {\n\t\tskb = virtio_vsock_alloc_skb(total_len, GFP_KERNEL);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tmemset(skb->head, 0, VIRTIO_VSOCK_SKB_HEADROOM);\n\t\tsg_init_one(&pkt, virtio_vsock_hdr(skb), total_len);\n\t\tp = &pkt;\n\t\tret = virtqueue_add_sgs(vq, &p, 0, 1, skb, GFP_KERNEL);\n\t\tif (ret < 0) {\n\t\t\tkfree_skb(skb);\n\t\t\tbreak;\n\t\t}\n\n\t\tvsock->rx_buf_nr++;\n\t} while (vq->num_free);\n\tif (vsock->rx_buf_nr > vsock->rx_buf_max_nr)\n\t\tvsock->rx_buf_max_nr = vsock->rx_buf_nr;\n\tvirtqueue_kick(vq);\n}\n\nstatic void virtio_transport_tx_work(struct work_struct *work)\n{\n\tstruct virtio_vsock *vsock =\n\t\tcontainer_of(work, struct virtio_vsock, tx_work);\n\tstruct virtqueue *vq;\n\tbool added = false;\n\n\tvq = vsock->vqs[VSOCK_VQ_TX];\n\tmutex_lock(&vsock->tx_lock);\n\n\tif (!vsock->tx_run)\n\t\tgoto out;\n\n\tdo {\n\t\tstruct sk_buff *skb;\n\t\tunsigned int len;\n\n\t\tvirtqueue_disable_cb(vq);\n\t\twhile ((skb = virtqueue_get_buf(vq, &len)) != NULL) {\n\t\t\tconsume_skb(skb);\n\t\t\tadded = true;\n\t\t}\n\t} while (!virtqueue_enable_cb(vq));\n\nout:\n\tmutex_unlock(&vsock->tx_lock);\n\n\tif (added)\n\t\tqueue_work(virtio_vsock_workqueue, &vsock->send_pkt_work);\n}\n\n \nstatic bool virtio_transport_more_replies(struct virtio_vsock *vsock)\n{\n\tstruct virtqueue *vq = vsock->vqs[VSOCK_VQ_RX];\n\tint val;\n\n\tsmp_rmb();  \n\tval = atomic_read(&vsock->queued_replies);\n\n\treturn val < virtqueue_get_vring_size(vq);\n}\n\n \nstatic int virtio_vsock_event_fill_one(struct virtio_vsock *vsock,\n\t\t\t\t       struct virtio_vsock_event *event)\n{\n\tstruct scatterlist sg;\n\tstruct virtqueue *vq;\n\n\tvq = vsock->vqs[VSOCK_VQ_EVENT];\n\n\tsg_init_one(&sg, event, sizeof(*event));\n\n\treturn virtqueue_add_inbuf(vq, &sg, 1, event, GFP_KERNEL);\n}\n\n \nstatic void virtio_vsock_event_fill(struct virtio_vsock *vsock)\n{\n\tsize_t i;\n\n\tfor (i = 0; i < ARRAY_SIZE(vsock->event_list); i++) {\n\t\tstruct virtio_vsock_event *event = &vsock->event_list[i];\n\n\t\tvirtio_vsock_event_fill_one(vsock, event);\n\t}\n\n\tvirtqueue_kick(vsock->vqs[VSOCK_VQ_EVENT]);\n}\n\nstatic void virtio_vsock_reset_sock(struct sock *sk)\n{\n\t \n\n\tsk->sk_state = TCP_CLOSE;\n\tsk->sk_err = ECONNRESET;\n\tsk_error_report(sk);\n}\n\nstatic void virtio_vsock_update_guest_cid(struct virtio_vsock *vsock)\n{\n\tstruct virtio_device *vdev = vsock->vdev;\n\t__le64 guest_cid;\n\n\tvdev->config->get(vdev, offsetof(struct virtio_vsock_config, guest_cid),\n\t\t\t  &guest_cid, sizeof(guest_cid));\n\tvsock->guest_cid = le64_to_cpu(guest_cid);\n}\n\n \nstatic void virtio_vsock_event_handle(struct virtio_vsock *vsock,\n\t\t\t\t      struct virtio_vsock_event *event)\n{\n\tswitch (le32_to_cpu(event->id)) {\n\tcase VIRTIO_VSOCK_EVENT_TRANSPORT_RESET:\n\t\tvirtio_vsock_update_guest_cid(vsock);\n\t\tvsock_for_each_connected_socket(&virtio_transport.transport,\n\t\t\t\t\t\tvirtio_vsock_reset_sock);\n\t\tbreak;\n\t}\n}\n\nstatic void virtio_transport_event_work(struct work_struct *work)\n{\n\tstruct virtio_vsock *vsock =\n\t\tcontainer_of(work, struct virtio_vsock, event_work);\n\tstruct virtqueue *vq;\n\n\tvq = vsock->vqs[VSOCK_VQ_EVENT];\n\n\tmutex_lock(&vsock->event_lock);\n\n\tif (!vsock->event_run)\n\t\tgoto out;\n\n\tdo {\n\t\tstruct virtio_vsock_event *event;\n\t\tunsigned int len;\n\n\t\tvirtqueue_disable_cb(vq);\n\t\twhile ((event = virtqueue_get_buf(vq, &len)) != NULL) {\n\t\t\tif (len == sizeof(*event))\n\t\t\t\tvirtio_vsock_event_handle(vsock, event);\n\n\t\t\tvirtio_vsock_event_fill_one(vsock, event);\n\t\t}\n\t} while (!virtqueue_enable_cb(vq));\n\n\tvirtqueue_kick(vsock->vqs[VSOCK_VQ_EVENT]);\nout:\n\tmutex_unlock(&vsock->event_lock);\n}\n\nstatic void virtio_vsock_event_done(struct virtqueue *vq)\n{\n\tstruct virtio_vsock *vsock = vq->vdev->priv;\n\n\tif (!vsock)\n\t\treturn;\n\tqueue_work(virtio_vsock_workqueue, &vsock->event_work);\n}\n\nstatic void virtio_vsock_tx_done(struct virtqueue *vq)\n{\n\tstruct virtio_vsock *vsock = vq->vdev->priv;\n\n\tif (!vsock)\n\t\treturn;\n\tqueue_work(virtio_vsock_workqueue, &vsock->tx_work);\n}\n\nstatic void virtio_vsock_rx_done(struct virtqueue *vq)\n{\n\tstruct virtio_vsock *vsock = vq->vdev->priv;\n\n\tif (!vsock)\n\t\treturn;\n\tqueue_work(virtio_vsock_workqueue, &vsock->rx_work);\n}\n\nstatic bool virtio_transport_seqpacket_allow(u32 remote_cid);\n\nstatic struct virtio_transport virtio_transport = {\n\t.transport = {\n\t\t.module                   = THIS_MODULE,\n\n\t\t.get_local_cid            = virtio_transport_get_local_cid,\n\n\t\t.init                     = virtio_transport_do_socket_init,\n\t\t.destruct                 = virtio_transport_destruct,\n\t\t.release                  = virtio_transport_release,\n\t\t.connect                  = virtio_transport_connect,\n\t\t.shutdown                 = virtio_transport_shutdown,\n\t\t.cancel_pkt               = virtio_transport_cancel_pkt,\n\n\t\t.dgram_bind               = virtio_transport_dgram_bind,\n\t\t.dgram_dequeue            = virtio_transport_dgram_dequeue,\n\t\t.dgram_enqueue            = virtio_transport_dgram_enqueue,\n\t\t.dgram_allow              = virtio_transport_dgram_allow,\n\n\t\t.stream_dequeue           = virtio_transport_stream_dequeue,\n\t\t.stream_enqueue           = virtio_transport_stream_enqueue,\n\t\t.stream_has_data          = virtio_transport_stream_has_data,\n\t\t.stream_has_space         = virtio_transport_stream_has_space,\n\t\t.stream_rcvhiwat          = virtio_transport_stream_rcvhiwat,\n\t\t.stream_is_active         = virtio_transport_stream_is_active,\n\t\t.stream_allow             = virtio_transport_stream_allow,\n\n\t\t.seqpacket_dequeue        = virtio_transport_seqpacket_dequeue,\n\t\t.seqpacket_enqueue        = virtio_transport_seqpacket_enqueue,\n\t\t.seqpacket_allow          = virtio_transport_seqpacket_allow,\n\t\t.seqpacket_has_data       = virtio_transport_seqpacket_has_data,\n\n\t\t.notify_poll_in           = virtio_transport_notify_poll_in,\n\t\t.notify_poll_out          = virtio_transport_notify_poll_out,\n\t\t.notify_recv_init         = virtio_transport_notify_recv_init,\n\t\t.notify_recv_pre_block    = virtio_transport_notify_recv_pre_block,\n\t\t.notify_recv_pre_dequeue  = virtio_transport_notify_recv_pre_dequeue,\n\t\t.notify_recv_post_dequeue = virtio_transport_notify_recv_post_dequeue,\n\t\t.notify_send_init         = virtio_transport_notify_send_init,\n\t\t.notify_send_pre_block    = virtio_transport_notify_send_pre_block,\n\t\t.notify_send_pre_enqueue  = virtio_transport_notify_send_pre_enqueue,\n\t\t.notify_send_post_enqueue = virtio_transport_notify_send_post_enqueue,\n\t\t.notify_buffer_size       = virtio_transport_notify_buffer_size,\n\t\t.notify_set_rcvlowat      = virtio_transport_notify_set_rcvlowat,\n\n\t\t.read_skb = virtio_transport_read_skb,\n\t},\n\n\t.send_pkt = virtio_transport_send_pkt,\n};\n\nstatic bool virtio_transport_seqpacket_allow(u32 remote_cid)\n{\n\tstruct virtio_vsock *vsock;\n\tbool seqpacket_allow;\n\n\tseqpacket_allow = false;\n\trcu_read_lock();\n\tvsock = rcu_dereference(the_virtio_vsock);\n\tif (vsock)\n\t\tseqpacket_allow = vsock->seqpacket_allow;\n\trcu_read_unlock();\n\n\treturn seqpacket_allow;\n}\n\nstatic void virtio_transport_rx_work(struct work_struct *work)\n{\n\tstruct virtio_vsock *vsock =\n\t\tcontainer_of(work, struct virtio_vsock, rx_work);\n\tstruct virtqueue *vq;\n\n\tvq = vsock->vqs[VSOCK_VQ_RX];\n\n\tmutex_lock(&vsock->rx_lock);\n\n\tif (!vsock->rx_run)\n\t\tgoto out;\n\n\tdo {\n\t\tvirtqueue_disable_cb(vq);\n\t\tfor (;;) {\n\t\t\tstruct sk_buff *skb;\n\t\t\tunsigned int len;\n\n\t\t\tif (!virtio_transport_more_replies(vsock)) {\n\t\t\t\t \n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tskb = virtqueue_get_buf(vq, &len);\n\t\t\tif (!skb)\n\t\t\t\tbreak;\n\n\t\t\tvsock->rx_buf_nr--;\n\n\t\t\t \n\t\t\tif (unlikely(len < sizeof(struct virtio_vsock_hdr) ||\n\t\t\t\t     len > virtio_vsock_skb_len(skb))) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tvirtio_vsock_skb_rx_put(skb);\n\t\t\tvirtio_transport_deliver_tap_pkt(skb);\n\t\t\tvirtio_transport_recv_pkt(&virtio_transport, skb);\n\t\t}\n\t} while (!virtqueue_enable_cb(vq));\n\nout:\n\tif (vsock->rx_buf_nr < vsock->rx_buf_max_nr / 2)\n\t\tvirtio_vsock_rx_fill(vsock);\n\tmutex_unlock(&vsock->rx_lock);\n}\n\nstatic int virtio_vsock_vqs_init(struct virtio_vsock *vsock)\n{\n\tstruct virtio_device *vdev = vsock->vdev;\n\tstatic const char * const names[] = {\n\t\t\"rx\",\n\t\t\"tx\",\n\t\t\"event\",\n\t};\n\tvq_callback_t *callbacks[] = {\n\t\tvirtio_vsock_rx_done,\n\t\tvirtio_vsock_tx_done,\n\t\tvirtio_vsock_event_done,\n\t};\n\tint ret;\n\n\tret = virtio_find_vqs(vdev, VSOCK_VQ_MAX, vsock->vqs, callbacks, names,\n\t\t\t      NULL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tvirtio_vsock_update_guest_cid(vsock);\n\n\tvirtio_device_ready(vdev);\n\n\treturn 0;\n}\n\nstatic void virtio_vsock_vqs_start(struct virtio_vsock *vsock)\n{\n\tmutex_lock(&vsock->tx_lock);\n\tvsock->tx_run = true;\n\tmutex_unlock(&vsock->tx_lock);\n\n\tmutex_lock(&vsock->rx_lock);\n\tvirtio_vsock_rx_fill(vsock);\n\tvsock->rx_run = true;\n\tmutex_unlock(&vsock->rx_lock);\n\n\tmutex_lock(&vsock->event_lock);\n\tvirtio_vsock_event_fill(vsock);\n\tvsock->event_run = true;\n\tmutex_unlock(&vsock->event_lock);\n\n\t \n\tqueue_work(virtio_vsock_workqueue, &vsock->send_pkt_work);\n}\n\nstatic void virtio_vsock_vqs_del(struct virtio_vsock *vsock)\n{\n\tstruct virtio_device *vdev = vsock->vdev;\n\tstruct sk_buff *skb;\n\n\t \n\tvsock_for_each_connected_socket(&virtio_transport.transport,\n\t\t\t\t\tvirtio_vsock_reset_sock);\n\n\t \n\tmutex_lock(&vsock->rx_lock);\n\tvsock->rx_run = false;\n\tmutex_unlock(&vsock->rx_lock);\n\n\tmutex_lock(&vsock->tx_lock);\n\tvsock->tx_run = false;\n\tmutex_unlock(&vsock->tx_lock);\n\n\tmutex_lock(&vsock->event_lock);\n\tvsock->event_run = false;\n\tmutex_unlock(&vsock->event_lock);\n\n\t \n\tvirtio_reset_device(vdev);\n\n\tmutex_lock(&vsock->rx_lock);\n\twhile ((skb = virtqueue_detach_unused_buf(vsock->vqs[VSOCK_VQ_RX])))\n\t\tkfree_skb(skb);\n\tmutex_unlock(&vsock->rx_lock);\n\n\tmutex_lock(&vsock->tx_lock);\n\twhile ((skb = virtqueue_detach_unused_buf(vsock->vqs[VSOCK_VQ_TX])))\n\t\tkfree_skb(skb);\n\tmutex_unlock(&vsock->tx_lock);\n\n\tvirtio_vsock_skb_queue_purge(&vsock->send_pkt_queue);\n\n\t \n\tvdev->config->del_vqs(vdev);\n}\n\nstatic int virtio_vsock_probe(struct virtio_device *vdev)\n{\n\tstruct virtio_vsock *vsock = NULL;\n\tint ret;\n\n\tret = mutex_lock_interruptible(&the_virtio_vsock_mutex);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (rcu_dereference_protected(the_virtio_vsock,\n\t\t\t\tlockdep_is_held(&the_virtio_vsock_mutex))) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tvsock = kzalloc(sizeof(*vsock), GFP_KERNEL);\n\tif (!vsock) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tvsock->vdev = vdev;\n\n\tvsock->rx_buf_nr = 0;\n\tvsock->rx_buf_max_nr = 0;\n\tatomic_set(&vsock->queued_replies, 0);\n\n\tmutex_init(&vsock->tx_lock);\n\tmutex_init(&vsock->rx_lock);\n\tmutex_init(&vsock->event_lock);\n\tskb_queue_head_init(&vsock->send_pkt_queue);\n\tINIT_WORK(&vsock->rx_work, virtio_transport_rx_work);\n\tINIT_WORK(&vsock->tx_work, virtio_transport_tx_work);\n\tINIT_WORK(&vsock->event_work, virtio_transport_event_work);\n\tINIT_WORK(&vsock->send_pkt_work, virtio_transport_send_pkt_work);\n\n\tif (virtio_has_feature(vdev, VIRTIO_VSOCK_F_SEQPACKET))\n\t\tvsock->seqpacket_allow = true;\n\n\tvdev->priv = vsock;\n\n\tret = virtio_vsock_vqs_init(vsock);\n\tif (ret < 0)\n\t\tgoto out;\n\n\trcu_assign_pointer(the_virtio_vsock, vsock);\n\tvirtio_vsock_vqs_start(vsock);\n\n\tmutex_unlock(&the_virtio_vsock_mutex);\n\n\treturn 0;\n\nout:\n\tkfree(vsock);\n\tmutex_unlock(&the_virtio_vsock_mutex);\n\treturn ret;\n}\n\nstatic void virtio_vsock_remove(struct virtio_device *vdev)\n{\n\tstruct virtio_vsock *vsock = vdev->priv;\n\n\tmutex_lock(&the_virtio_vsock_mutex);\n\n\tvdev->priv = NULL;\n\trcu_assign_pointer(the_virtio_vsock, NULL);\n\tsynchronize_rcu();\n\n\tvirtio_vsock_vqs_del(vsock);\n\n\t \n\tflush_work(&vsock->rx_work);\n\tflush_work(&vsock->tx_work);\n\tflush_work(&vsock->event_work);\n\tflush_work(&vsock->send_pkt_work);\n\n\tmutex_unlock(&the_virtio_vsock_mutex);\n\n\tkfree(vsock);\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int virtio_vsock_freeze(struct virtio_device *vdev)\n{\n\tstruct virtio_vsock *vsock = vdev->priv;\n\n\tmutex_lock(&the_virtio_vsock_mutex);\n\n\trcu_assign_pointer(the_virtio_vsock, NULL);\n\tsynchronize_rcu();\n\n\tvirtio_vsock_vqs_del(vsock);\n\n\tmutex_unlock(&the_virtio_vsock_mutex);\n\n\treturn 0;\n}\n\nstatic int virtio_vsock_restore(struct virtio_device *vdev)\n{\n\tstruct virtio_vsock *vsock = vdev->priv;\n\tint ret;\n\n\tmutex_lock(&the_virtio_vsock_mutex);\n\n\t \n\tif (rcu_dereference_protected(the_virtio_vsock,\n\t\t\t\tlockdep_is_held(&the_virtio_vsock_mutex))) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tret = virtio_vsock_vqs_init(vsock);\n\tif (ret < 0)\n\t\tgoto out;\n\n\trcu_assign_pointer(the_virtio_vsock, vsock);\n\tvirtio_vsock_vqs_start(vsock);\n\nout:\n\tmutex_unlock(&the_virtio_vsock_mutex);\n\treturn ret;\n}\n#endif  \n\nstatic struct virtio_device_id id_table[] = {\n\t{ VIRTIO_ID_VSOCK, VIRTIO_DEV_ANY_ID },\n\t{ 0 },\n};\n\nstatic unsigned int features[] = {\n\tVIRTIO_VSOCK_F_SEQPACKET\n};\n\nstatic struct virtio_driver virtio_vsock_driver = {\n\t.feature_table = features,\n\t.feature_table_size = ARRAY_SIZE(features),\n\t.driver.name = KBUILD_MODNAME,\n\t.driver.owner = THIS_MODULE,\n\t.id_table = id_table,\n\t.probe = virtio_vsock_probe,\n\t.remove = virtio_vsock_remove,\n#ifdef CONFIG_PM_SLEEP\n\t.freeze = virtio_vsock_freeze,\n\t.restore = virtio_vsock_restore,\n#endif\n};\n\nstatic int __init virtio_vsock_init(void)\n{\n\tint ret;\n\n\tvirtio_vsock_workqueue = alloc_workqueue(\"virtio_vsock\", 0, 0);\n\tif (!virtio_vsock_workqueue)\n\t\treturn -ENOMEM;\n\n\tret = vsock_core_register(&virtio_transport.transport,\n\t\t\t\t  VSOCK_TRANSPORT_F_G2H);\n\tif (ret)\n\t\tgoto out_wq;\n\n\tret = register_virtio_driver(&virtio_vsock_driver);\n\tif (ret)\n\t\tgoto out_vci;\n\n\treturn 0;\n\nout_vci:\n\tvsock_core_unregister(&virtio_transport.transport);\nout_wq:\n\tdestroy_workqueue(virtio_vsock_workqueue);\n\treturn ret;\n}\n\nstatic void __exit virtio_vsock_exit(void)\n{\n\tunregister_virtio_driver(&virtio_vsock_driver);\n\tvsock_core_unregister(&virtio_transport.transport);\n\tdestroy_workqueue(virtio_vsock_workqueue);\n}\n\nmodule_init(virtio_vsock_init);\nmodule_exit(virtio_vsock_exit);\nMODULE_LICENSE(\"GPL v2\");\nMODULE_AUTHOR(\"Asias He\");\nMODULE_DESCRIPTION(\"virtio transport for vsock\");\nMODULE_DEVICE_TABLE(virtio, id_table);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}