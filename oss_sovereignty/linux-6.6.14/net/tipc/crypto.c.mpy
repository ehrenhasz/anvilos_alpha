{
  "module_name": "crypto.c",
  "hash_id": "7e62bc5b73180ecd06fdafdc0bf6d942ad3f17c891ca68ef572cac4132fd9980",
  "original_prompt": "Ingested from linux-6.6.14/net/tipc/crypto.c",
  "human_readable_source": "\n \n\n#include <crypto/aead.h>\n#include <crypto/aes.h>\n#include <crypto/rng.h>\n#include \"crypto.h\"\n#include \"msg.h\"\n#include \"bcast.h\"\n\n#define TIPC_TX_GRACE_PERIOD\tmsecs_to_jiffies(5000)  \n#define TIPC_TX_LASTING_TIME\tmsecs_to_jiffies(10000)  \n#define TIPC_RX_ACTIVE_LIM\tmsecs_to_jiffies(3000)  \n#define TIPC_RX_PASSIVE_LIM\tmsecs_to_jiffies(15000)  \n\n#define TIPC_MAX_TFMS_DEF\t10\n#define TIPC_MAX_TFMS_LIM\t1000\n\n#define TIPC_REKEYING_INTV_DEF\t(60 * 24)  \n\n \nenum {\n\tKEY_MASTER = 0,\n\tKEY_MIN = KEY_MASTER,\n\tKEY_1 = 1,\n\tKEY_2,\n\tKEY_3,\n\tKEY_MAX = KEY_3,\n};\n\n \nenum {\n\tSTAT_OK,\n\tSTAT_NOK,\n\tSTAT_ASYNC,\n\tSTAT_ASYNC_OK,\n\tSTAT_ASYNC_NOK,\n\tSTAT_BADKEYS,  \n\tSTAT_BADMSGS = STAT_BADKEYS,  \n\tSTAT_NOKEYS,\n\tSTAT_SWITCHES,\n\n\tMAX_STATS,\n};\n\n \nstatic const char *hstats[MAX_STATS] = {\"ok\", \"nok\", \"async\", \"async_ok\",\n\t\t\t\t\t\"async_nok\", \"badmsgs\", \"nokeys\",\n\t\t\t\t\t\"switches\"};\n\n \nint sysctl_tipc_max_tfms __read_mostly = TIPC_MAX_TFMS_DEF;\n \nint sysctl_tipc_key_exchange_enabled __read_mostly = 1;\n\n \nstruct tipc_key {\n#define KEY_BITS (2)\n#define KEY_MASK ((1 << KEY_BITS) - 1)\n\tunion {\n\t\tstruct {\n#if defined(__LITTLE_ENDIAN_BITFIELD)\n\t\t\tu8 pending:2,\n\t\t\t   active:2,\n\t\t\t   passive:2,  \n\t\t\t   reserved:2;\n#elif defined(__BIG_ENDIAN_BITFIELD)\n\t\t\tu8 reserved:2,\n\t\t\t   passive:2,  \n\t\t\t   active:2,\n\t\t\t   pending:2;\n#else\n#error  \"Please fix <asm/byteorder.h>\"\n#endif\n\t\t} __packed;\n\t\tu8 keys;\n\t};\n};\n\n \nstruct tipc_tfm {\n\tstruct crypto_aead *tfm;\n\tstruct list_head list;\n};\n\n \nstruct tipc_aead {\n#define TIPC_AEAD_HINT_LEN (5)\n\tstruct tipc_tfm * __percpu *tfm_entry;\n\tstruct tipc_crypto *crypto;\n\tstruct tipc_aead *cloned;\n\tatomic_t users;\n\tu32 salt;\n\tu8 authsize;\n\tu8 mode;\n\tchar hint[2 * TIPC_AEAD_HINT_LEN + 1];\n\tstruct rcu_head rcu;\n\tstruct tipc_aead_key *key;\n\tu16 gen;\n\n\tatomic64_t seqno ____cacheline_aligned;\n\trefcount_t refcnt ____cacheline_aligned;\n\n} ____cacheline_aligned;\n\n \nstruct tipc_crypto_stats {\n\tunsigned int stat[MAX_STATS];\n};\n\n \nstruct tipc_crypto {\n\tstruct net *net;\n\tstruct tipc_node *node;\n\tstruct tipc_aead __rcu *aead[KEY_MAX + 1];\n\tatomic_t peer_rx_active;\n\tu16 key_gen;\n\tstruct tipc_key key;\n\tu8 skey_mode;\n\tstruct tipc_aead_key *skey;\n\tstruct workqueue_struct *wq;\n\tstruct delayed_work work;\n#define KEY_DISTR_SCHED\t\t1\n#define KEY_DISTR_COMPL\t\t2\n\tatomic_t key_distr;\n\tu32 rekeying_intv;\n\n\tstruct tipc_crypto_stats __percpu *stats;\n\tchar name[48];\n\n\tatomic64_t sndnxt ____cacheline_aligned;\n\tunsigned long timer1;\n\tunsigned long timer2;\n\tunion {\n\t\tstruct {\n\t\t\tu8 working:1;\n\t\t\tu8 key_master:1;\n\t\t\tu8 legacy_user:1;\n\t\t\tu8 nokey: 1;\n\t\t};\n\t\tu8 flags;\n\t};\n\tspinlock_t lock;  \n\n} ____cacheline_aligned;\n\n \nstruct tipc_crypto_tx_ctx {\n\tstruct tipc_aead *aead;\n\tstruct tipc_bearer *bearer;\n\tstruct tipc_media_addr dst;\n};\n\n \nstruct tipc_crypto_rx_ctx {\n\tstruct tipc_aead *aead;\n\tstruct tipc_bearer *bearer;\n};\n\nstatic struct tipc_aead *tipc_aead_get(struct tipc_aead __rcu *aead);\nstatic inline void tipc_aead_put(struct tipc_aead *aead);\nstatic void tipc_aead_free(struct rcu_head *rp);\nstatic int tipc_aead_users(struct tipc_aead __rcu *aead);\nstatic void tipc_aead_users_inc(struct tipc_aead __rcu *aead, int lim);\nstatic void tipc_aead_users_dec(struct tipc_aead __rcu *aead, int lim);\nstatic void tipc_aead_users_set(struct tipc_aead __rcu *aead, int val);\nstatic struct crypto_aead *tipc_aead_tfm_next(struct tipc_aead *aead);\nstatic int tipc_aead_init(struct tipc_aead **aead, struct tipc_aead_key *ukey,\n\t\t\t  u8 mode);\nstatic int tipc_aead_clone(struct tipc_aead **dst, struct tipc_aead *src);\nstatic void *tipc_aead_mem_alloc(struct crypto_aead *tfm,\n\t\t\t\t unsigned int crypto_ctx_size,\n\t\t\t\t u8 **iv, struct aead_request **req,\n\t\t\t\t struct scatterlist **sg, int nsg);\nstatic int tipc_aead_encrypt(struct tipc_aead *aead, struct sk_buff *skb,\n\t\t\t     struct tipc_bearer *b,\n\t\t\t     struct tipc_media_addr *dst,\n\t\t\t     struct tipc_node *__dnode);\nstatic void tipc_aead_encrypt_done(void *data, int err);\nstatic int tipc_aead_decrypt(struct net *net, struct tipc_aead *aead,\n\t\t\t     struct sk_buff *skb, struct tipc_bearer *b);\nstatic void tipc_aead_decrypt_done(void *data, int err);\nstatic inline int tipc_ehdr_size(struct tipc_ehdr *ehdr);\nstatic int tipc_ehdr_build(struct net *net, struct tipc_aead *aead,\n\t\t\t   u8 tx_key, struct sk_buff *skb,\n\t\t\t   struct tipc_crypto *__rx);\nstatic inline void tipc_crypto_key_set_state(struct tipc_crypto *c,\n\t\t\t\t\t     u8 new_passive,\n\t\t\t\t\t     u8 new_active,\n\t\t\t\t\t     u8 new_pending);\nstatic int tipc_crypto_key_attach(struct tipc_crypto *c,\n\t\t\t\t  struct tipc_aead *aead, u8 pos,\n\t\t\t\t  bool master_key);\nstatic bool tipc_crypto_key_try_align(struct tipc_crypto *rx, u8 new_pending);\nstatic struct tipc_aead *tipc_crypto_key_pick_tx(struct tipc_crypto *tx,\n\t\t\t\t\t\t struct tipc_crypto *rx,\n\t\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t\t u8 tx_key);\nstatic void tipc_crypto_key_synch(struct tipc_crypto *rx, struct sk_buff *skb);\nstatic int tipc_crypto_key_revoke(struct net *net, u8 tx_key);\nstatic inline void tipc_crypto_clone_msg(struct net *net, struct sk_buff *_skb,\n\t\t\t\t\t struct tipc_bearer *b,\n\t\t\t\t\t struct tipc_media_addr *dst,\n\t\t\t\t\t struct tipc_node *__dnode, u8 type);\nstatic void tipc_crypto_rcv_complete(struct net *net, struct tipc_aead *aead,\n\t\t\t\t     struct tipc_bearer *b,\n\t\t\t\t     struct sk_buff **skb, int err);\nstatic void tipc_crypto_do_cmd(struct net *net, int cmd);\nstatic char *tipc_crypto_key_dump(struct tipc_crypto *c, char *buf);\nstatic char *tipc_key_change_dump(struct tipc_key old, struct tipc_key new,\n\t\t\t\t  char *buf);\nstatic int tipc_crypto_key_xmit(struct net *net, struct tipc_aead_key *skey,\n\t\t\t\tu16 gen, u8 mode, u32 dnode);\nstatic bool tipc_crypto_key_rcv(struct tipc_crypto *rx, struct tipc_msg *hdr);\nstatic void tipc_crypto_work_tx(struct work_struct *work);\nstatic void tipc_crypto_work_rx(struct work_struct *work);\nstatic int tipc_aead_key_generate(struct tipc_aead_key *skey);\n\n#define is_tx(crypto) (!(crypto)->node)\n#define is_rx(crypto) (!is_tx(crypto))\n\n#define key_next(cur) ((cur) % KEY_MAX + 1)\n\n#define tipc_aead_rcu_ptr(rcu_ptr, lock)\t\t\t\t\\\n\trcu_dereference_protected((rcu_ptr), lockdep_is_held(lock))\n\n#define tipc_aead_rcu_replace(rcu_ptr, ptr, lock)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tstruct tipc_aead *__tmp = rcu_dereference_protected((rcu_ptr),\t\\\n\t\t\t\t\t\tlockdep_is_held(lock));\t\\\n\trcu_assign_pointer((rcu_ptr), (ptr));\t\t\t\t\\\n\ttipc_aead_put(__tmp);\t\t\t\t\t\t\\\n} while (0)\n\n#define tipc_crypto_key_detach(rcu_ptr, lock)\t\t\t\t\\\n\ttipc_aead_rcu_replace((rcu_ptr), NULL, lock)\n\n \nint tipc_aead_key_validate(struct tipc_aead_key *ukey, struct genl_info *info)\n{\n\tint keylen;\n\n\t \n\tif (unlikely(!crypto_has_alg(ukey->alg_name, 0, 0))) {\n\t\tGENL_SET_ERR_MSG(info, \"unable to load the algorithm (module existed?)\");\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tif (strcmp(ukey->alg_name, \"gcm(aes)\")) {\n\t\tGENL_SET_ERR_MSG(info, \"not supported yet the algorithm\");\n\t\treturn -ENOTSUPP;\n\t}\n\n\t \n\tkeylen = ukey->keylen - TIPC_AES_GCM_SALT_SIZE;\n\tif (unlikely(keylen != TIPC_AES_GCM_KEY_SIZE_128 &&\n\t\t     keylen != TIPC_AES_GCM_KEY_SIZE_192 &&\n\t\t     keylen != TIPC_AES_GCM_KEY_SIZE_256)) {\n\t\tGENL_SET_ERR_MSG(info, \"incorrect key length (20, 28 or 36 octets?)\");\n\t\treturn -EKEYREJECTED;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int tipc_aead_key_generate(struct tipc_aead_key *skey)\n{\n\tint rc = 0;\n\n\t \n\trc = crypto_get_default_rng();\n\tif (likely(!rc)) {\n\t\trc = crypto_rng_get_bytes(crypto_default_rng, skey->key,\n\t\t\t\t\t  skey->keylen);\n\t\tcrypto_put_default_rng();\n\t}\n\n\treturn rc;\n}\n\nstatic struct tipc_aead *tipc_aead_get(struct tipc_aead __rcu *aead)\n{\n\tstruct tipc_aead *tmp;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (unlikely(!tmp || !refcount_inc_not_zero(&tmp->refcnt)))\n\t\ttmp = NULL;\n\trcu_read_unlock();\n\n\treturn tmp;\n}\n\nstatic inline void tipc_aead_put(struct tipc_aead *aead)\n{\n\tif (aead && refcount_dec_and_test(&aead->refcnt))\n\t\tcall_rcu(&aead->rcu, tipc_aead_free);\n}\n\n \nstatic void tipc_aead_free(struct rcu_head *rp)\n{\n\tstruct tipc_aead *aead = container_of(rp, struct tipc_aead, rcu);\n\tstruct tipc_tfm *tfm_entry, *head, *tmp;\n\n\tif (aead->cloned) {\n\t\ttipc_aead_put(aead->cloned);\n\t} else {\n\t\thead = *get_cpu_ptr(aead->tfm_entry);\n\t\tput_cpu_ptr(aead->tfm_entry);\n\t\tlist_for_each_entry_safe(tfm_entry, tmp, &head->list, list) {\n\t\t\tcrypto_free_aead(tfm_entry->tfm);\n\t\t\tlist_del(&tfm_entry->list);\n\t\t\tkfree(tfm_entry);\n\t\t}\n\t\t \n\t\tcrypto_free_aead(head->tfm);\n\t\tlist_del(&head->list);\n\t\tkfree(head);\n\t}\n\tfree_percpu(aead->tfm_entry);\n\tkfree_sensitive(aead->key);\n\tkfree(aead);\n}\n\nstatic int tipc_aead_users(struct tipc_aead __rcu *aead)\n{\n\tstruct tipc_aead *tmp;\n\tint users = 0;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp)\n\t\tusers = atomic_read(&tmp->users);\n\trcu_read_unlock();\n\n\treturn users;\n}\n\nstatic void tipc_aead_users_inc(struct tipc_aead __rcu *aead, int lim)\n{\n\tstruct tipc_aead *tmp;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp)\n\t\tatomic_add_unless(&tmp->users, 1, lim);\n\trcu_read_unlock();\n}\n\nstatic void tipc_aead_users_dec(struct tipc_aead __rcu *aead, int lim)\n{\n\tstruct tipc_aead *tmp;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp)\n\t\tatomic_add_unless(&rcu_dereference(aead)->users, -1, lim);\n\trcu_read_unlock();\n}\n\nstatic void tipc_aead_users_set(struct tipc_aead __rcu *aead, int val)\n{\n\tstruct tipc_aead *tmp;\n\tint cur;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp) {\n\t\tdo {\n\t\t\tcur = atomic_read(&tmp->users);\n\t\t\tif (cur == val)\n\t\t\t\tbreak;\n\t\t} while (atomic_cmpxchg(&tmp->users, cur, val) != cur);\n\t}\n\trcu_read_unlock();\n}\n\n \nstatic struct crypto_aead *tipc_aead_tfm_next(struct tipc_aead *aead)\n{\n\tstruct tipc_tfm **tfm_entry;\n\tstruct crypto_aead *tfm;\n\n\ttfm_entry = get_cpu_ptr(aead->tfm_entry);\n\t*tfm_entry = list_next_entry(*tfm_entry, list);\n\ttfm = (*tfm_entry)->tfm;\n\tput_cpu_ptr(tfm_entry);\n\n\treturn tfm;\n}\n\n \nstatic int tipc_aead_init(struct tipc_aead **aead, struct tipc_aead_key *ukey,\n\t\t\t  u8 mode)\n{\n\tstruct tipc_tfm *tfm_entry, *head;\n\tstruct crypto_aead *tfm;\n\tstruct tipc_aead *tmp;\n\tint keylen, err, cpu;\n\tint tfm_cnt = 0;\n\n\tif (unlikely(*aead))\n\t\treturn -EEXIST;\n\n\t \n\ttmp = kzalloc(sizeof(*tmp), GFP_ATOMIC);\n\tif (unlikely(!tmp))\n\t\treturn -ENOMEM;\n\n\t \n\tkeylen = ukey->keylen - TIPC_AES_GCM_SALT_SIZE;\n\n\t \n\ttmp->tfm_entry = alloc_percpu(struct tipc_tfm *);\n\tif (!tmp->tfm_entry) {\n\t\tkfree_sensitive(tmp);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tdo {\n\t\ttfm = crypto_alloc_aead(ukey->alg_name, 0, 0);\n\t\tif (IS_ERR(tfm)) {\n\t\t\terr = PTR_ERR(tfm);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (unlikely(!tfm_cnt &&\n\t\t\t     crypto_aead_ivsize(tfm) != TIPC_AES_GCM_IV_SIZE)) {\n\t\t\tcrypto_free_aead(tfm);\n\t\t\terr = -ENOTSUPP;\n\t\t\tbreak;\n\t\t}\n\n\t\terr = crypto_aead_setauthsize(tfm, TIPC_AES_GCM_TAG_SIZE);\n\t\terr |= crypto_aead_setkey(tfm, ukey->key, keylen);\n\t\tif (unlikely(err)) {\n\t\t\tcrypto_free_aead(tfm);\n\t\t\tbreak;\n\t\t}\n\n\t\ttfm_entry = kmalloc(sizeof(*tfm_entry), GFP_KERNEL);\n\t\tif (unlikely(!tfm_entry)) {\n\t\t\tcrypto_free_aead(tfm);\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\tINIT_LIST_HEAD(&tfm_entry->list);\n\t\ttfm_entry->tfm = tfm;\n\n\t\t \n\t\tif (!tfm_cnt) {\n\t\t\thead = tfm_entry;\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\t*per_cpu_ptr(tmp->tfm_entry, cpu) = head;\n\t\t\t}\n\t\t} else {\n\t\t\tlist_add_tail(&tfm_entry->list, &head->list);\n\t\t}\n\n\t} while (++tfm_cnt < sysctl_tipc_max_tfms);\n\n\t \n\tif (!tfm_cnt) {\n\t\tfree_percpu(tmp->tfm_entry);\n\t\tkfree_sensitive(tmp);\n\t\treturn err;\n\t}\n\n\t \n\tbin2hex(tmp->hint, ukey->key + keylen - TIPC_AEAD_HINT_LEN,\n\t\tTIPC_AEAD_HINT_LEN);\n\n\t \n\ttmp->mode = mode;\n\ttmp->cloned = NULL;\n\ttmp->authsize = TIPC_AES_GCM_TAG_SIZE;\n\ttmp->key = kmemdup(ukey, tipc_aead_key_size(ukey), GFP_KERNEL);\n\tif (!tmp->key) {\n\t\ttipc_aead_free(&tmp->rcu);\n\t\treturn -ENOMEM;\n\t}\n\tmemcpy(&tmp->salt, ukey->key + keylen, TIPC_AES_GCM_SALT_SIZE);\n\tatomic_set(&tmp->users, 0);\n\tatomic64_set(&tmp->seqno, 0);\n\trefcount_set(&tmp->refcnt, 1);\n\n\t*aead = tmp;\n\treturn 0;\n}\n\n \nstatic int tipc_aead_clone(struct tipc_aead **dst, struct tipc_aead *src)\n{\n\tstruct tipc_aead *aead;\n\tint cpu;\n\n\tif (!src)\n\t\treturn -ENOKEY;\n\n\tif (src->mode != CLUSTER_KEY)\n\t\treturn -EINVAL;\n\n\tif (unlikely(*dst))\n\t\treturn -EEXIST;\n\n\taead = kzalloc(sizeof(*aead), GFP_ATOMIC);\n\tif (unlikely(!aead))\n\t\treturn -ENOMEM;\n\n\taead->tfm_entry = alloc_percpu_gfp(struct tipc_tfm *, GFP_ATOMIC);\n\tif (unlikely(!aead->tfm_entry)) {\n\t\tkfree_sensitive(aead);\n\t\treturn -ENOMEM;\n\t}\n\n\tfor_each_possible_cpu(cpu) {\n\t\t*per_cpu_ptr(aead->tfm_entry, cpu) =\n\t\t\t\t*per_cpu_ptr(src->tfm_entry, cpu);\n\t}\n\n\tmemcpy(aead->hint, src->hint, sizeof(src->hint));\n\taead->mode = src->mode;\n\taead->salt = src->salt;\n\taead->authsize = src->authsize;\n\tatomic_set(&aead->users, 0);\n\tatomic64_set(&aead->seqno, 0);\n\trefcount_set(&aead->refcnt, 1);\n\n\tWARN_ON(!refcount_inc_not_zero(&src->refcnt));\n\taead->cloned = src;\n\n\t*dst = aead;\n\treturn 0;\n}\n\n \nstatic void *tipc_aead_mem_alloc(struct crypto_aead *tfm,\n\t\t\t\t unsigned int crypto_ctx_size,\n\t\t\t\t u8 **iv, struct aead_request **req,\n\t\t\t\t struct scatterlist **sg, int nsg)\n{\n\tunsigned int iv_size, req_size;\n\tunsigned int len;\n\tu8 *mem;\n\n\tiv_size = crypto_aead_ivsize(tfm);\n\treq_size = sizeof(**req) + crypto_aead_reqsize(tfm);\n\n\tlen = crypto_ctx_size;\n\tlen += iv_size;\n\tlen += crypto_aead_alignmask(tfm) & ~(crypto_tfm_ctx_alignment() - 1);\n\tlen = ALIGN(len, crypto_tfm_ctx_alignment());\n\tlen += req_size;\n\tlen = ALIGN(len, __alignof__(struct scatterlist));\n\tlen += nsg * sizeof(**sg);\n\n\tmem = kmalloc(len, GFP_ATOMIC);\n\tif (!mem)\n\t\treturn NULL;\n\n\t*iv = (u8 *)PTR_ALIGN(mem + crypto_ctx_size,\n\t\t\t      crypto_aead_alignmask(tfm) + 1);\n\t*req = (struct aead_request *)PTR_ALIGN(*iv + iv_size,\n\t\t\t\t\t\tcrypto_tfm_ctx_alignment());\n\t*sg = (struct scatterlist *)PTR_ALIGN((u8 *)*req + req_size,\n\t\t\t\t\t      __alignof__(struct scatterlist));\n\n\treturn (void *)mem;\n}\n\n \nstatic int tipc_aead_encrypt(struct tipc_aead *aead, struct sk_buff *skb,\n\t\t\t     struct tipc_bearer *b,\n\t\t\t     struct tipc_media_addr *dst,\n\t\t\t     struct tipc_node *__dnode)\n{\n\tstruct crypto_aead *tfm = tipc_aead_tfm_next(aead);\n\tstruct tipc_crypto_tx_ctx *tx_ctx;\n\tstruct aead_request *req;\n\tstruct sk_buff *trailer;\n\tstruct scatterlist *sg;\n\tstruct tipc_ehdr *ehdr;\n\tint ehsz, len, tailen, nsg, rc;\n\tvoid *ctx;\n\tu32 salt;\n\tu8 *iv;\n\n\t \n\tlen = ALIGN(skb->len, 4);\n\ttailen = len - skb->len + aead->authsize;\n\n\t \n\tSKB_LINEAR_ASSERT(skb);\n\tif (tailen > skb_tailroom(skb)) {\n\t\tpr_debug(\"TX(): skb tailroom is not enough: %d, requires: %d\\n\",\n\t\t\t skb_tailroom(skb), tailen);\n\t}\n\n\tnsg = skb_cow_data(skb, tailen, &trailer);\n\tif (unlikely(nsg < 0)) {\n\t\tpr_err(\"TX: skb_cow_data() returned %d\\n\", nsg);\n\t\treturn nsg;\n\t}\n\n\tpskb_put(skb, trailer, tailen);\n\n\t \n\tctx = tipc_aead_mem_alloc(tfm, sizeof(*tx_ctx), &iv, &req, &sg, nsg);\n\tif (unlikely(!ctx))\n\t\treturn -ENOMEM;\n\tTIPC_SKB_CB(skb)->crypto_ctx = ctx;\n\n\t \n\tsg_init_table(sg, nsg);\n\trc = skb_to_sgvec(skb, sg, 0, skb->len);\n\tif (unlikely(rc < 0)) {\n\t\tpr_err(\"TX: skb_to_sgvec() returned %d, nsg %d!\\n\", rc, nsg);\n\t\tgoto exit;\n\t}\n\n\t \n\tehdr = (struct tipc_ehdr *)skb->data;\n\tsalt = aead->salt;\n\tif (aead->mode == CLUSTER_KEY)\n\t\tsalt ^= __be32_to_cpu(ehdr->addr);\n\telse if (__dnode)\n\t\tsalt ^= tipc_node_get_addr(__dnode);\n\tmemcpy(iv, &salt, 4);\n\tmemcpy(iv + 4, (u8 *)&ehdr->seqno, 8);\n\n\t \n\tehsz = tipc_ehdr_size(ehdr);\n\taead_request_set_tfm(req, tfm);\n\taead_request_set_ad(req, ehsz);\n\taead_request_set_crypt(req, sg, sg, len - ehsz, iv);\n\n\t \n\taead_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t  tipc_aead_encrypt_done, skb);\n\ttx_ctx = (struct tipc_crypto_tx_ctx *)ctx;\n\ttx_ctx->aead = aead;\n\ttx_ctx->bearer = b;\n\tmemcpy(&tx_ctx->dst, dst, sizeof(*dst));\n\n\t \n\tif (unlikely(!tipc_bearer_hold(b))) {\n\t\trc = -ENODEV;\n\t\tgoto exit;\n\t}\n\n\t \n\trc = crypto_aead_encrypt(req);\n\tif (rc == -EINPROGRESS || rc == -EBUSY)\n\t\treturn rc;\n\n\ttipc_bearer_put(b);\n\nexit:\n\tkfree(ctx);\n\tTIPC_SKB_CB(skb)->crypto_ctx = NULL;\n\treturn rc;\n}\n\nstatic void tipc_aead_encrypt_done(void *data, int err)\n{\n\tstruct sk_buff *skb = data;\n\tstruct tipc_crypto_tx_ctx *tx_ctx = TIPC_SKB_CB(skb)->crypto_ctx;\n\tstruct tipc_bearer *b = tx_ctx->bearer;\n\tstruct tipc_aead *aead = tx_ctx->aead;\n\tstruct tipc_crypto *tx = aead->crypto;\n\tstruct net *net = tx->net;\n\n\tswitch (err) {\n\tcase 0:\n\t\tthis_cpu_inc(tx->stats->stat[STAT_ASYNC_OK]);\n\t\trcu_read_lock();\n\t\tif (likely(test_bit(0, &b->up)))\n\t\t\tb->media->send_msg(net, skb, b, &tx_ctx->dst);\n\t\telse\n\t\t\tkfree_skb(skb);\n\t\trcu_read_unlock();\n\t\tbreak;\n\tcase -EINPROGRESS:\n\t\treturn;\n\tdefault:\n\t\tthis_cpu_inc(tx->stats->stat[STAT_ASYNC_NOK]);\n\t\tkfree_skb(skb);\n\t\tbreak;\n\t}\n\n\tkfree(tx_ctx);\n\ttipc_bearer_put(b);\n\ttipc_aead_put(aead);\n}\n\n \nstatic int tipc_aead_decrypt(struct net *net, struct tipc_aead *aead,\n\t\t\t     struct sk_buff *skb, struct tipc_bearer *b)\n{\n\tstruct tipc_crypto_rx_ctx *rx_ctx;\n\tstruct aead_request *req;\n\tstruct crypto_aead *tfm;\n\tstruct sk_buff *unused;\n\tstruct scatterlist *sg;\n\tstruct tipc_ehdr *ehdr;\n\tint ehsz, nsg, rc;\n\tvoid *ctx;\n\tu32 salt;\n\tu8 *iv;\n\n\tif (unlikely(!aead))\n\t\treturn -ENOKEY;\n\n\tnsg = skb_cow_data(skb, 0, &unused);\n\tif (unlikely(nsg < 0)) {\n\t\tpr_err(\"RX: skb_cow_data() returned %d\\n\", nsg);\n\t\treturn nsg;\n\t}\n\n\t \n\ttfm = tipc_aead_tfm_next(aead);\n\tctx = tipc_aead_mem_alloc(tfm, sizeof(*rx_ctx), &iv, &req, &sg, nsg);\n\tif (unlikely(!ctx))\n\t\treturn -ENOMEM;\n\tTIPC_SKB_CB(skb)->crypto_ctx = ctx;\n\n\t \n\tsg_init_table(sg, nsg);\n\trc = skb_to_sgvec(skb, sg, 0, skb->len);\n\tif (unlikely(rc < 0)) {\n\t\tpr_err(\"RX: skb_to_sgvec() returned %d, nsg %d\\n\", rc, nsg);\n\t\tgoto exit;\n\t}\n\n\t \n\tehdr = (struct tipc_ehdr *)skb->data;\n\tsalt = aead->salt;\n\tif (aead->mode == CLUSTER_KEY)\n\t\tsalt ^= __be32_to_cpu(ehdr->addr);\n\telse if (ehdr->destined)\n\t\tsalt ^= tipc_own_addr(net);\n\tmemcpy(iv, &salt, 4);\n\tmemcpy(iv + 4, (u8 *)&ehdr->seqno, 8);\n\n\t \n\tehsz = tipc_ehdr_size(ehdr);\n\taead_request_set_tfm(req, tfm);\n\taead_request_set_ad(req, ehsz);\n\taead_request_set_crypt(req, sg, sg, skb->len - ehsz, iv);\n\n\t \n\taead_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t  tipc_aead_decrypt_done, skb);\n\trx_ctx = (struct tipc_crypto_rx_ctx *)ctx;\n\trx_ctx->aead = aead;\n\trx_ctx->bearer = b;\n\n\t \n\tif (unlikely(!tipc_bearer_hold(b))) {\n\t\trc = -ENODEV;\n\t\tgoto exit;\n\t}\n\n\t \n\trc = crypto_aead_decrypt(req);\n\tif (rc == -EINPROGRESS || rc == -EBUSY)\n\t\treturn rc;\n\n\ttipc_bearer_put(b);\n\nexit:\n\tkfree(ctx);\n\tTIPC_SKB_CB(skb)->crypto_ctx = NULL;\n\treturn rc;\n}\n\nstatic void tipc_aead_decrypt_done(void *data, int err)\n{\n\tstruct sk_buff *skb = data;\n\tstruct tipc_crypto_rx_ctx *rx_ctx = TIPC_SKB_CB(skb)->crypto_ctx;\n\tstruct tipc_bearer *b = rx_ctx->bearer;\n\tstruct tipc_aead *aead = rx_ctx->aead;\n\tstruct tipc_crypto_stats __percpu *stats = aead->crypto->stats;\n\tstruct net *net = aead->crypto->net;\n\n\tswitch (err) {\n\tcase 0:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC_OK]);\n\t\tbreak;\n\tcase -EINPROGRESS:\n\t\treturn;\n\tdefault:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC_NOK]);\n\t\tbreak;\n\t}\n\n\tkfree(rx_ctx);\n\ttipc_crypto_rcv_complete(net, aead, b, &skb, err);\n\tif (likely(skb)) {\n\t\tif (likely(test_bit(0, &b->up)))\n\t\t\ttipc_rcv(net, skb, b);\n\t\telse\n\t\t\tkfree_skb(skb);\n\t}\n\n\ttipc_bearer_put(b);\n}\n\nstatic inline int tipc_ehdr_size(struct tipc_ehdr *ehdr)\n{\n\treturn (ehdr->user != LINK_CONFIG) ? EHDR_SIZE : EHDR_CFG_SIZE;\n}\n\n \nbool tipc_ehdr_validate(struct sk_buff *skb)\n{\n\tstruct tipc_ehdr *ehdr;\n\tint ehsz;\n\n\tif (unlikely(!pskb_may_pull(skb, EHDR_MIN_SIZE)))\n\t\treturn false;\n\n\tehdr = (struct tipc_ehdr *)skb->data;\n\tif (unlikely(ehdr->version != TIPC_EVERSION))\n\t\treturn false;\n\tehsz = tipc_ehdr_size(ehdr);\n\tif (unlikely(!pskb_may_pull(skb, ehsz)))\n\t\treturn false;\n\tif (unlikely(skb->len <= ehsz + TIPC_AES_GCM_TAG_SIZE))\n\t\treturn false;\n\n\treturn true;\n}\n\n \nstatic int tipc_ehdr_build(struct net *net, struct tipc_aead *aead,\n\t\t\t   u8 tx_key, struct sk_buff *skb,\n\t\t\t   struct tipc_crypto *__rx)\n{\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tstruct tipc_ehdr *ehdr;\n\tu32 user = msg_user(hdr);\n\tu64 seqno;\n\tint ehsz;\n\n\t \n\tehsz = (user != LINK_CONFIG) ? EHDR_SIZE : EHDR_CFG_SIZE;\n\tWARN_ON(skb_headroom(skb) < ehsz);\n\tehdr = (struct tipc_ehdr *)skb_push(skb, ehsz);\n\n\t \n\tif (!__rx || aead->mode == CLUSTER_KEY)\n\t\tseqno = atomic64_inc_return(&aead->seqno);\n\telse\n\t\tseqno = atomic64_inc_return(&__rx->sndnxt);\n\n\t \n\tif (unlikely(!seqno))\n\t\treturn tipc_crypto_key_revoke(net, tx_key);\n\n\t \n\tehdr->seqno = cpu_to_be64(seqno);\n\n\t \n\tehdr->version = TIPC_EVERSION;\n\tehdr->user = 0;\n\tehdr->keepalive = 0;\n\tehdr->tx_key = tx_key;\n\tehdr->destined = (__rx) ? 1 : 0;\n\tehdr->rx_key_active = (__rx) ? __rx->key.active : 0;\n\tehdr->rx_nokey = (__rx) ? __rx->nokey : 0;\n\tehdr->master_key = aead->crypto->key_master;\n\tehdr->reserved_1 = 0;\n\tehdr->reserved_2 = 0;\n\n\tswitch (user) {\n\tcase LINK_CONFIG:\n\t\tehdr->user = LINK_CONFIG;\n\t\tmemcpy(ehdr->id, tipc_own_id(net), NODE_ID_LEN);\n\t\tbreak;\n\tdefault:\n\t\tif (user == LINK_PROTOCOL && msg_type(hdr) == STATE_MSG) {\n\t\t\tehdr->user = LINK_PROTOCOL;\n\t\t\tehdr->keepalive = msg_is_keepalive(hdr);\n\t\t}\n\t\tehdr->addr = hdr->hdr[3];\n\t\tbreak;\n\t}\n\n\treturn ehsz;\n}\n\nstatic inline void tipc_crypto_key_set_state(struct tipc_crypto *c,\n\t\t\t\t\t     u8 new_passive,\n\t\t\t\t\t     u8 new_active,\n\t\t\t\t\t     u8 new_pending)\n{\n\tstruct tipc_key old = c->key;\n\tchar buf[32];\n\n\tc->key.keys = ((new_passive & KEY_MASK) << (KEY_BITS * 2)) |\n\t\t      ((new_active  & KEY_MASK) << (KEY_BITS)) |\n\t\t      ((new_pending & KEY_MASK));\n\n\tpr_debug(\"%s: key changing %s ::%pS\\n\", c->name,\n\t\t tipc_key_change_dump(old, c->key, buf),\n\t\t __builtin_return_address(0));\n}\n\n \nint tipc_crypto_key_init(struct tipc_crypto *c, struct tipc_aead_key *ukey,\n\t\t\t u8 mode, bool master_key)\n{\n\tstruct tipc_aead *aead = NULL;\n\tint rc = 0;\n\n\t \n\trc = tipc_aead_init(&aead, ukey, mode);\n\n\t \n\tif (likely(!rc)) {\n\t\trc = tipc_crypto_key_attach(c, aead, 0, master_key);\n\t\tif (rc < 0)\n\t\t\ttipc_aead_free(&aead->rcu);\n\t}\n\n\treturn rc;\n}\n\n \nstatic int tipc_crypto_key_attach(struct tipc_crypto *c,\n\t\t\t\t  struct tipc_aead *aead, u8 pos,\n\t\t\t\t  bool master_key)\n{\n\tstruct tipc_key key;\n\tint rc = -EBUSY;\n\tu8 new_key;\n\n\tspin_lock_bh(&c->lock);\n\tkey = c->key;\n\tif (master_key) {\n\t\tnew_key = KEY_MASTER;\n\t\tgoto attach;\n\t}\n\tif (key.active && key.passive)\n\t\tgoto exit;\n\tif (key.pending) {\n\t\tif (tipc_aead_users(c->aead[key.pending]) > 0)\n\t\t\tgoto exit;\n\t\t \n\t\t \n\t\tnew_key = key.pending;\n\t} else {\n\t\tif (pos) {\n\t\t\tif (key.active && pos != key_next(key.active)) {\n\t\t\t\tkey.passive = pos;\n\t\t\t\tnew_key = pos;\n\t\t\t\tgoto attach;\n\t\t\t} else if (!key.active && !key.passive) {\n\t\t\t\tkey.pending = pos;\n\t\t\t\tnew_key = pos;\n\t\t\t\tgoto attach;\n\t\t\t}\n\t\t}\n\t\tkey.pending = key_next(key.active ?: key.passive);\n\t\tnew_key = key.pending;\n\t}\n\nattach:\n\taead->crypto = c;\n\taead->gen = (is_tx(c)) ? ++c->key_gen : c->key_gen;\n\ttipc_aead_rcu_replace(c->aead[new_key], aead, &c->lock);\n\tif (likely(c->key.keys != key.keys))\n\t\ttipc_crypto_key_set_state(c, key.passive, key.active,\n\t\t\t\t\t  key.pending);\n\tc->working = 1;\n\tc->nokey = 0;\n\tc->key_master |= master_key;\n\trc = new_key;\n\nexit:\n\tspin_unlock_bh(&c->lock);\n\treturn rc;\n}\n\nvoid tipc_crypto_key_flush(struct tipc_crypto *c)\n{\n\tstruct tipc_crypto *tx, *rx;\n\tint k;\n\n\tspin_lock_bh(&c->lock);\n\tif (is_rx(c)) {\n\t\t \n\t\trx = c;\n\t\ttx = tipc_net(rx->net)->crypto_tx;\n\t\tif (cancel_delayed_work(&rx->work)) {\n\t\t\tkfree(rx->skey);\n\t\t\trx->skey = NULL;\n\t\t\tatomic_xchg(&rx->key_distr, 0);\n\t\t\ttipc_node_put(rx->node);\n\t\t}\n\t\t \n\t\tk = atomic_xchg(&rx->peer_rx_active, 0);\n\t\tif (k) {\n\t\t\ttipc_aead_users_dec(tx->aead[k], 0);\n\t\t\t \n\t\t\ttx->timer1 = jiffies;\n\t\t}\n\t}\n\n\tc->flags = 0;\n\ttipc_crypto_key_set_state(c, 0, 0, 0);\n\tfor (k = KEY_MIN; k <= KEY_MAX; k++)\n\t\ttipc_crypto_key_detach(c->aead[k], &c->lock);\n\tatomic64_set(&c->sndnxt, 0);\n\tspin_unlock_bh(&c->lock);\n}\n\n \nstatic bool tipc_crypto_key_try_align(struct tipc_crypto *rx, u8 new_pending)\n{\n\tstruct tipc_aead *tmp1, *tmp2 = NULL;\n\tstruct tipc_key key;\n\tbool aligned = false;\n\tu8 new_passive = 0;\n\tint x;\n\n\tspin_lock(&rx->lock);\n\tkey = rx->key;\n\tif (key.pending == new_pending) {\n\t\taligned = true;\n\t\tgoto exit;\n\t}\n\tif (key.active)\n\t\tgoto exit;\n\tif (!key.pending)\n\t\tgoto exit;\n\tif (tipc_aead_users(rx->aead[key.pending]) > 0)\n\t\tgoto exit;\n\n\t \n\ttmp1 = tipc_aead_rcu_ptr(rx->aead[key.pending], &rx->lock);\n\tif (!refcount_dec_if_one(&tmp1->refcnt))\n\t\tgoto exit;\n\trcu_assign_pointer(rx->aead[key.pending], NULL);\n\n\t \n\tif (key.passive) {\n\t\ttmp2 = rcu_replace_pointer(rx->aead[key.passive], tmp2, lockdep_is_held(&rx->lock));\n\t\tx = (key.passive - key.pending + new_pending) % KEY_MAX;\n\t\tnew_passive = (x <= 0) ? x + KEY_MAX : x;\n\t}\n\n\t \n\ttipc_crypto_key_set_state(rx, new_passive, 0, new_pending);\n\trcu_assign_pointer(rx->aead[new_pending], tmp1);\n\tif (new_passive)\n\t\trcu_assign_pointer(rx->aead[new_passive], tmp2);\n\trefcount_set(&tmp1->refcnt, 1);\n\taligned = true;\n\tpr_info_ratelimited(\"%s: key[%d] -> key[%d]\\n\", rx->name, key.pending,\n\t\t\t    new_pending);\n\nexit:\n\tspin_unlock(&rx->lock);\n\treturn aligned;\n}\n\n \nstatic struct tipc_aead *tipc_crypto_key_pick_tx(struct tipc_crypto *tx,\n\t\t\t\t\t\t struct tipc_crypto *rx,\n\t\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t\t u8 tx_key)\n{\n\tstruct tipc_skb_cb *skb_cb = TIPC_SKB_CB(skb);\n\tstruct tipc_aead *aead = NULL;\n\tstruct tipc_key key = tx->key;\n\tu8 k, i = 0;\n\n\t \n\tif (!skb_cb->tx_clone_deferred) {\n\t\tskb_cb->tx_clone_deferred = 1;\n\t\tmemset(&skb_cb->tx_clone_ctx, 0, sizeof(skb_cb->tx_clone_ctx));\n\t}\n\n\tskb_cb->tx_clone_ctx.rx = rx;\n\tif (++skb_cb->tx_clone_ctx.recurs > 2)\n\t\treturn NULL;\n\n\t \n\tspin_lock(&tx->lock);\n\tif (tx_key == KEY_MASTER) {\n\t\taead = tipc_aead_rcu_ptr(tx->aead[KEY_MASTER], &tx->lock);\n\t\tgoto done;\n\t}\n\tdo {\n\t\tk = (i == 0) ? key.pending :\n\t\t\t((i == 1) ? key.active : key.passive);\n\t\tif (!k)\n\t\t\tcontinue;\n\t\taead = tipc_aead_rcu_ptr(tx->aead[k], &tx->lock);\n\t\tif (!aead)\n\t\t\tcontinue;\n\t\tif (aead->mode != CLUSTER_KEY ||\n\t\t    aead == skb_cb->tx_clone_ctx.last) {\n\t\t\taead = NULL;\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tskb_cb->tx_clone_ctx.last = aead;\n\t\tWARN_ON(skb->next);\n\t\tskb->next = skb_clone(skb, GFP_ATOMIC);\n\t\tif (unlikely(!skb->next))\n\t\t\tpr_warn(\"Failed to clone skb for next round if any\\n\");\n\t\tbreak;\n\t} while (++i < 3);\n\ndone:\n\tif (likely(aead))\n\t\tWARN_ON(!refcount_inc_not_zero(&aead->refcnt));\n\tspin_unlock(&tx->lock);\n\n\treturn aead;\n}\n\n \nstatic void tipc_crypto_key_synch(struct tipc_crypto *rx, struct sk_buff *skb)\n{\n\tstruct tipc_ehdr *ehdr = (struct tipc_ehdr *)skb_network_header(skb);\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tu32 self = tipc_own_addr(rx->net);\n\tu8 cur, new;\n\tunsigned long delay;\n\n\t \n\trx->key_master = ehdr->master_key;\n\tif (!rx->key_master)\n\t\ttx->legacy_user = 1;\n\n\t \n\tif (!ehdr->destined || msg_short(hdr) || msg_destnode(hdr) != self)\n\t\treturn;\n\n\t \n\tif (ehdr->rx_nokey) {\n\t\t \n\t\ttx->timer2 = jiffies;\n\t\t \n\t\tif (tx->key.keys &&\n\t\t    !atomic_cmpxchg(&rx->key_distr, 0, KEY_DISTR_SCHED)) {\n\t\t\tget_random_bytes(&delay, 2);\n\t\t\tdelay %= 5;\n\t\t\tdelay = msecs_to_jiffies(500 * ++delay);\n\t\t\tif (queue_delayed_work(tx->wq, &rx->work, delay))\n\t\t\t\ttipc_node_get(rx->node);\n\t\t}\n\t} else {\n\t\t \n\t\tatomic_xchg(&rx->key_distr, 0);\n\t}\n\n\t \n\tcur = atomic_read(&rx->peer_rx_active);\n\tnew = ehdr->rx_key_active;\n\tif (tx->key.keys &&\n\t    cur != new &&\n\t    atomic_cmpxchg(&rx->peer_rx_active, cur, new) == cur) {\n\t\tif (new)\n\t\t\ttipc_aead_users_inc(tx->aead[new], INT_MAX);\n\t\tif (cur)\n\t\t\ttipc_aead_users_dec(tx->aead[cur], 0);\n\n\t\tatomic64_set(&rx->sndnxt, 0);\n\t\t \n\t\ttx->timer1 = jiffies;\n\n\t\tpr_debug(\"%s: key users changed %d-- %d++, peer %s\\n\",\n\t\t\t tx->name, cur, new, rx->name);\n\t}\n}\n\nstatic int tipc_crypto_key_revoke(struct net *net, u8 tx_key)\n{\n\tstruct tipc_crypto *tx = tipc_net(net)->crypto_tx;\n\tstruct tipc_key key;\n\n\tspin_lock_bh(&tx->lock);\n\tkey = tx->key;\n\tWARN_ON(!key.active || tx_key != key.active);\n\n\t \n\ttipc_crypto_key_set_state(tx, key.passive, 0, key.pending);\n\ttipc_crypto_key_detach(tx->aead[key.active], &tx->lock);\n\tspin_unlock_bh(&tx->lock);\n\n\tpr_warn(\"%s: key is revoked\\n\", tx->name);\n\treturn -EKEYREVOKED;\n}\n\nint tipc_crypto_start(struct tipc_crypto **crypto, struct net *net,\n\t\t      struct tipc_node *node)\n{\n\tstruct tipc_crypto *c;\n\n\tif (*crypto)\n\t\treturn -EEXIST;\n\n\t \n\tc = kzalloc(sizeof(*c), GFP_ATOMIC);\n\tif (!c)\n\t\treturn -ENOMEM;\n\n\t \n\tif (!node) {\n\t\tc->wq = alloc_ordered_workqueue(\"tipc_crypto\", 0);\n\t\tif (!c->wq) {\n\t\t\tkfree(c);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\t \n\tc->stats = alloc_percpu_gfp(struct tipc_crypto_stats, GFP_ATOMIC);\n\tif (!c->stats) {\n\t\tif (c->wq)\n\t\t\tdestroy_workqueue(c->wq);\n\t\tkfree_sensitive(c);\n\t\treturn -ENOMEM;\n\t}\n\n\tc->flags = 0;\n\tc->net = net;\n\tc->node = node;\n\tget_random_bytes(&c->key_gen, 2);\n\ttipc_crypto_key_set_state(c, 0, 0, 0);\n\tatomic_set(&c->key_distr, 0);\n\tatomic_set(&c->peer_rx_active, 0);\n\tatomic64_set(&c->sndnxt, 0);\n\tc->timer1 = jiffies;\n\tc->timer2 = jiffies;\n\tc->rekeying_intv = TIPC_REKEYING_INTV_DEF;\n\tspin_lock_init(&c->lock);\n\tscnprintf(c->name, 48, \"%s(%s)\", (is_rx(c)) ? \"RX\" : \"TX\",\n\t\t  (is_rx(c)) ? tipc_node_get_id_str(c->node) :\n\t\t\t       tipc_own_id_string(c->net));\n\n\tif (is_rx(c))\n\t\tINIT_DELAYED_WORK(&c->work, tipc_crypto_work_rx);\n\telse\n\t\tINIT_DELAYED_WORK(&c->work, tipc_crypto_work_tx);\n\n\t*crypto = c;\n\treturn 0;\n}\n\nvoid tipc_crypto_stop(struct tipc_crypto **crypto)\n{\n\tstruct tipc_crypto *c = *crypto;\n\tu8 k;\n\n\tif (!c)\n\t\treturn;\n\n\t \n\tif (is_tx(c)) {\n\t\tc->rekeying_intv = 0;\n\t\tcancel_delayed_work_sync(&c->work);\n\t\tdestroy_workqueue(c->wq);\n\t}\n\n\t \n\trcu_read_lock();\n\tfor (k = KEY_MIN; k <= KEY_MAX; k++)\n\t\ttipc_aead_put(rcu_dereference(c->aead[k]));\n\trcu_read_unlock();\n\tpr_debug(\"%s: has been stopped\\n\", c->name);\n\n\t \n\tfree_percpu(c->stats);\n\n\t*crypto = NULL;\n\tkfree_sensitive(c);\n}\n\nvoid tipc_crypto_timeout(struct tipc_crypto *rx)\n{\n\tstruct tipc_net *tn = tipc_net(rx->net);\n\tstruct tipc_crypto *tx = tn->crypto_tx;\n\tstruct tipc_key key;\n\tint cmd;\n\n\t \n\tspin_lock(&tx->lock);\n\tkey = tx->key;\n\tif (key.active && tipc_aead_users(tx->aead[key.active]) > 0)\n\t\tgoto s1;\n\tif (!key.pending || tipc_aead_users(tx->aead[key.pending]) <= 0)\n\t\tgoto s1;\n\tif (time_before(jiffies, tx->timer1 + TIPC_TX_LASTING_TIME))\n\t\tgoto s1;\n\n\ttipc_crypto_key_set_state(tx, key.passive, key.pending, 0);\n\tif (key.active)\n\t\ttipc_crypto_key_detach(tx->aead[key.active], &tx->lock);\n\tthis_cpu_inc(tx->stats->stat[STAT_SWITCHES]);\n\tpr_info(\"%s: key[%d] is activated\\n\", tx->name, key.pending);\n\ns1:\n\tspin_unlock(&tx->lock);\n\n\t \n\tspin_lock(&rx->lock);\n\tkey = rx->key;\n\tif (!key.pending || tipc_aead_users(rx->aead[key.pending]) <= 0)\n\t\tgoto s2;\n\n\tif (key.active)\n\t\tkey.passive = key.active;\n\tkey.active = key.pending;\n\trx->timer2 = jiffies;\n\ttipc_crypto_key_set_state(rx, key.passive, key.active, 0);\n\tthis_cpu_inc(rx->stats->stat[STAT_SWITCHES]);\n\tpr_info(\"%s: key[%d] is activated\\n\", rx->name, key.pending);\n\tgoto s5;\n\ns2:\n\t \n\tif (!key.pending || tipc_aead_users(rx->aead[key.pending]) > -10)\n\t\tgoto s3;\n\n\ttipc_crypto_key_set_state(rx, key.passive, key.active, 0);\n\ttipc_crypto_key_detach(rx->aead[key.pending], &rx->lock);\n\tpr_debug(\"%s: key[%d] is removed\\n\", rx->name, key.pending);\n\tgoto s5;\n\ns3:\n\t \n\tif (!key.active)\n\t\tgoto s4;\n\tif (time_before(jiffies, rx->timer1 + TIPC_RX_ACTIVE_LIM) &&\n\t    tipc_aead_users(rx->aead[key.active]) > 0)\n\t\tgoto s4;\n\n\tif (key.pending)\n\t\tkey.passive = key.active;\n\telse\n\t\tkey.pending = key.active;\n\trx->timer2 = jiffies;\n\ttipc_crypto_key_set_state(rx, key.passive, 0, key.pending);\n\ttipc_aead_users_set(rx->aead[key.pending], 0);\n\tpr_debug(\"%s: key[%d] is deactivated\\n\", rx->name, key.active);\n\tgoto s5;\n\ns4:\n\t \n\tif (!key.passive)\n\t\tgoto s5;\n\tif (time_before(jiffies, rx->timer2 + TIPC_RX_PASSIVE_LIM) &&\n\t    tipc_aead_users(rx->aead[key.passive]) > -10)\n\t\tgoto s5;\n\n\ttipc_crypto_key_set_state(rx, 0, key.active, key.pending);\n\ttipc_crypto_key_detach(rx->aead[key.passive], &rx->lock);\n\tpr_debug(\"%s: key[%d] is freed\\n\", rx->name, key.passive);\n\ns5:\n\tspin_unlock(&rx->lock);\n\n\t \n\tif (time_after(jiffies, tx->timer2 + TIPC_TX_GRACE_PERIOD))\n\t\ttx->legacy_user = 0;\n\n\t \n\tif (likely(sysctl_tipc_max_tfms <= TIPC_MAX_TFMS_LIM))\n\t\treturn;\n\n\tcmd = sysctl_tipc_max_tfms;\n\tsysctl_tipc_max_tfms = TIPC_MAX_TFMS_DEF;\n\ttipc_crypto_do_cmd(rx->net, cmd);\n}\n\nstatic inline void tipc_crypto_clone_msg(struct net *net, struct sk_buff *_skb,\n\t\t\t\t\t struct tipc_bearer *b,\n\t\t\t\t\t struct tipc_media_addr *dst,\n\t\t\t\t\t struct tipc_node *__dnode, u8 type)\n{\n\tstruct sk_buff *skb;\n\n\tskb = skb_clone(_skb, GFP_ATOMIC);\n\tif (skb) {\n\t\tTIPC_SKB_CB(skb)->xmit_type = type;\n\t\ttipc_crypto_xmit(net, &skb, b, dst, __dnode);\n\t\tif (skb)\n\t\t\tb->media->send_msg(net, skb, b, dst);\n\t}\n}\n\n \nint tipc_crypto_xmit(struct net *net, struct sk_buff **skb,\n\t\t     struct tipc_bearer *b, struct tipc_media_addr *dst,\n\t\t     struct tipc_node *__dnode)\n{\n\tstruct tipc_crypto *__rx = tipc_node_crypto_rx(__dnode);\n\tstruct tipc_crypto *tx = tipc_net(net)->crypto_tx;\n\tstruct tipc_crypto_stats __percpu *stats = tx->stats;\n\tstruct tipc_msg *hdr = buf_msg(*skb);\n\tstruct tipc_key key = tx->key;\n\tstruct tipc_aead *aead = NULL;\n\tu32 user = msg_user(hdr);\n\tu32 type = msg_type(hdr);\n\tint rc = -ENOKEY;\n\tu8 tx_key = 0;\n\n\t \n\tif (!tx->working)\n\t\treturn 0;\n\n\t \n\tif (unlikely(key.pending)) {\n\t\ttx_key = key.pending;\n\t\tif (!tx->key_master && !key.active)\n\t\t\tgoto encrypt;\n\t\tif (__rx && atomic_read(&__rx->peer_rx_active) == tx_key)\n\t\t\tgoto encrypt;\n\t\tif (TIPC_SKB_CB(*skb)->xmit_type == SKB_PROBING) {\n\t\t\tpr_debug(\"%s: probing for key[%d]\\n\", tx->name,\n\t\t\t\t key.pending);\n\t\t\tgoto encrypt;\n\t\t}\n\t\tif (user == LINK_CONFIG || user == LINK_PROTOCOL)\n\t\t\ttipc_crypto_clone_msg(net, *skb, b, dst, __dnode,\n\t\t\t\t\t      SKB_PROBING);\n\t}\n\n\t \n\tif (tx->key_master) {\n\t\ttx_key = KEY_MASTER;\n\t\tif (!key.active)\n\t\t\tgoto encrypt;\n\t\tif (TIPC_SKB_CB(*skb)->xmit_type == SKB_GRACING) {\n\t\t\tpr_debug(\"%s: gracing for msg (%d %d)\\n\", tx->name,\n\t\t\t\t user, type);\n\t\t\tgoto encrypt;\n\t\t}\n\t\tif (user == LINK_CONFIG ||\n\t\t    (user == LINK_PROTOCOL && type == RESET_MSG) ||\n\t\t    (user == MSG_CRYPTO && type == KEY_DISTR_MSG) ||\n\t\t    time_before(jiffies, tx->timer2 + TIPC_TX_GRACE_PERIOD)) {\n\t\t\tif (__rx && __rx->key_master &&\n\t\t\t    !atomic_read(&__rx->peer_rx_active))\n\t\t\t\tgoto encrypt;\n\t\t\tif (!__rx) {\n\t\t\t\tif (likely(!tx->legacy_user))\n\t\t\t\t\tgoto encrypt;\n\t\t\t\ttipc_crypto_clone_msg(net, *skb, b, dst,\n\t\t\t\t\t\t      __dnode, SKB_GRACING);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (likely(key.active)) {\n\t\ttx_key = key.active;\n\t\tgoto encrypt;\n\t}\n\n\tgoto exit;\n\nencrypt:\n\taead = tipc_aead_get(tx->aead[tx_key]);\n\tif (unlikely(!aead))\n\t\tgoto exit;\n\trc = tipc_ehdr_build(net, aead, tx_key, *skb, __rx);\n\tif (likely(rc > 0))\n\t\trc = tipc_aead_encrypt(aead, *skb, b, dst, __dnode);\n\nexit:\n\tswitch (rc) {\n\tcase 0:\n\t\tthis_cpu_inc(stats->stat[STAT_OK]);\n\t\tbreak;\n\tcase -EINPROGRESS:\n\tcase -EBUSY:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC]);\n\t\t*skb = NULL;\n\t\treturn rc;\n\tdefault:\n\t\tthis_cpu_inc(stats->stat[STAT_NOK]);\n\t\tif (rc == -ENOKEY)\n\t\t\tthis_cpu_inc(stats->stat[STAT_NOKEYS]);\n\t\telse if (rc == -EKEYREVOKED)\n\t\t\tthis_cpu_inc(stats->stat[STAT_BADKEYS]);\n\t\tkfree_skb(*skb);\n\t\t*skb = NULL;\n\t\tbreak;\n\t}\n\n\ttipc_aead_put(aead);\n\treturn rc;\n}\n\n \nint tipc_crypto_rcv(struct net *net, struct tipc_crypto *rx,\n\t\t    struct sk_buff **skb, struct tipc_bearer *b)\n{\n\tstruct tipc_crypto *tx = tipc_net(net)->crypto_tx;\n\tstruct tipc_crypto_stats __percpu *stats;\n\tstruct tipc_aead *aead = NULL;\n\tstruct tipc_key key;\n\tint rc = -ENOKEY;\n\tu8 tx_key, n;\n\n\ttx_key = ((struct tipc_ehdr *)(*skb)->data)->tx_key;\n\n\t \n\tif (unlikely(!rx || tx_key == KEY_MASTER))\n\t\tgoto pick_tx;\n\n\t \n\tkey = rx->key;\n\tif (tx_key == key.active || tx_key == key.pending ||\n\t    tx_key == key.passive)\n\t\tgoto decrypt;\n\n\t \n\tif (tipc_crypto_key_try_align(rx, tx_key))\n\t\tgoto decrypt;\n\npick_tx:\n\t \n\taead = tipc_crypto_key_pick_tx(tx, rx, *skb, tx_key);\n\tif (aead)\n\t\tgoto decrypt;\n\tgoto exit;\n\ndecrypt:\n\trcu_read_lock();\n\tif (!aead)\n\t\taead = tipc_aead_get(rx->aead[tx_key]);\n\trc = tipc_aead_decrypt(net, aead, *skb, b);\n\trcu_read_unlock();\n\nexit:\n\tstats = ((rx) ?: tx)->stats;\n\tswitch (rc) {\n\tcase 0:\n\t\tthis_cpu_inc(stats->stat[STAT_OK]);\n\t\tbreak;\n\tcase -EINPROGRESS:\n\tcase -EBUSY:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC]);\n\t\t*skb = NULL;\n\t\treturn rc;\n\tdefault:\n\t\tthis_cpu_inc(stats->stat[STAT_NOK]);\n\t\tif (rc == -ENOKEY) {\n\t\t\tkfree_skb(*skb);\n\t\t\t*skb = NULL;\n\t\t\tif (rx) {\n\t\t\t\t \n\t\t\t\tn = key_next(tx_key);\n\t\t\t\trx->nokey = !(rx->skey ||\n\t\t\t\t\t      rcu_access_pointer(rx->aead[n]));\n\t\t\t\tpr_debug_ratelimited(\"%s: nokey %d, key %d/%x\\n\",\n\t\t\t\t\t\t     rx->name, rx->nokey,\n\t\t\t\t\t\t     tx_key, rx->key.keys);\n\t\t\t\ttipc_node_put(rx->node);\n\t\t\t}\n\t\t\tthis_cpu_inc(stats->stat[STAT_NOKEYS]);\n\t\t\treturn rc;\n\t\t} else if (rc == -EBADMSG) {\n\t\t\tthis_cpu_inc(stats->stat[STAT_BADMSGS]);\n\t\t}\n\t\tbreak;\n\t}\n\n\ttipc_crypto_rcv_complete(net, aead, b, skb, rc);\n\treturn rc;\n}\n\nstatic void tipc_crypto_rcv_complete(struct net *net, struct tipc_aead *aead,\n\t\t\t\t     struct tipc_bearer *b,\n\t\t\t\t     struct sk_buff **skb, int err)\n{\n\tstruct tipc_skb_cb *skb_cb = TIPC_SKB_CB(*skb);\n\tstruct tipc_crypto *rx = aead->crypto;\n\tstruct tipc_aead *tmp = NULL;\n\tstruct tipc_ehdr *ehdr;\n\tstruct tipc_node *n;\n\n\t \n\tif (unlikely(is_tx(aead->crypto))) {\n\t\trx = skb_cb->tx_clone_ctx.rx;\n\t\tpr_debug(\"TX->RX(%s): err %d, aead %p, skb->next %p, flags %x\\n\",\n\t\t\t (rx) ? tipc_node_get_id_str(rx->node) : \"-\", err, aead,\n\t\t\t (*skb)->next, skb_cb->flags);\n\t\tpr_debug(\"skb_cb [recurs %d, last %p], tx->aead [%p %p %p]\\n\",\n\t\t\t skb_cb->tx_clone_ctx.recurs, skb_cb->tx_clone_ctx.last,\n\t\t\t aead->crypto->aead[1], aead->crypto->aead[2],\n\t\t\t aead->crypto->aead[3]);\n\t\tif (unlikely(err)) {\n\t\t\tif (err == -EBADMSG && (*skb)->next)\n\t\t\t\ttipc_rcv(net, (*skb)->next, b);\n\t\t\tgoto free_skb;\n\t\t}\n\n\t\tif (likely((*skb)->next)) {\n\t\t\tkfree_skb((*skb)->next);\n\t\t\t(*skb)->next = NULL;\n\t\t}\n\t\tehdr = (struct tipc_ehdr *)(*skb)->data;\n\t\tif (!rx) {\n\t\t\tWARN_ON(ehdr->user != LINK_CONFIG);\n\t\t\tn = tipc_node_create(net, 0, ehdr->id, 0xffffu, 0,\n\t\t\t\t\t     true);\n\t\t\trx = tipc_node_crypto_rx(n);\n\t\t\tif (unlikely(!rx))\n\t\t\t\tgoto free_skb;\n\t\t}\n\n\t\t \n\t\tif (ehdr->tx_key == KEY_MASTER)\n\t\t\tgoto rcv;\n\t\tif (tipc_aead_clone(&tmp, aead) < 0)\n\t\t\tgoto rcv;\n\t\tWARN_ON(!refcount_inc_not_zero(&tmp->refcnt));\n\t\tif (tipc_crypto_key_attach(rx, tmp, ehdr->tx_key, false) < 0) {\n\t\t\ttipc_aead_free(&tmp->rcu);\n\t\t\tgoto rcv;\n\t\t}\n\t\ttipc_aead_put(aead);\n\t\taead = tmp;\n\t}\n\n\tif (unlikely(err)) {\n\t\ttipc_aead_users_dec((struct tipc_aead __force __rcu *)aead, INT_MIN);\n\t\tgoto free_skb;\n\t}\n\n\t \n\ttipc_aead_users_set((struct tipc_aead __force __rcu *)aead, 1);\n\n\t \n\trx->timer1 = jiffies;\n\nrcv:\n\t \n\tehdr = (struct tipc_ehdr *)(*skb)->data;\n\n\t \n\tif (rx->key.passive && ehdr->tx_key == rx->key.passive)\n\t\trx->timer2 = jiffies;\n\n\tskb_reset_network_header(*skb);\n\tskb_pull(*skb, tipc_ehdr_size(ehdr));\n\tif (pskb_trim(*skb, (*skb)->len - aead->authsize))\n\t\tgoto free_skb;\n\n\t \n\tif (unlikely(!tipc_msg_validate(skb))) {\n\t\tpr_err_ratelimited(\"Packet dropped after decryption!\\n\");\n\t\tgoto free_skb;\n\t}\n\n\t \n\ttipc_crypto_key_synch(rx, *skb);\n\n\t \n\tskb_cb = TIPC_SKB_CB(*skb);\n\n\t \n\tskb_cb->decrypted = 1;\n\n\t \n\tif (likely(!skb_cb->tx_clone_deferred))\n\t\tgoto exit;\n\tskb_cb->tx_clone_deferred = 0;\n\tmemset(&skb_cb->tx_clone_ctx, 0, sizeof(skb_cb->tx_clone_ctx));\n\tgoto exit;\n\nfree_skb:\n\tkfree_skb(*skb);\n\t*skb = NULL;\n\nexit:\n\ttipc_aead_put(aead);\n\tif (rx)\n\t\ttipc_node_put(rx->node);\n}\n\nstatic void tipc_crypto_do_cmd(struct net *net, int cmd)\n{\n\tstruct tipc_net *tn = tipc_net(net);\n\tstruct tipc_crypto *tx = tn->crypto_tx, *rx;\n\tstruct list_head *p;\n\tunsigned int stat;\n\tint i, j, cpu;\n\tchar buf[200];\n\n\t \n\tswitch (cmd) {\n\tcase 0xfff1:\n\t\tgoto print_stats;\n\tdefault:\n\t\treturn;\n\t}\n\nprint_stats:\n\t \n\tpr_info(\"\\n=============== TIPC Crypto Statistics ===============\\n\\n\");\n\n\t \n\tpr_info(\"Key status:\\n\");\n\tpr_info(\"TX(%7.7s)\\n%s\", tipc_own_id_string(net),\n\t\ttipc_crypto_key_dump(tx, buf));\n\n\trcu_read_lock();\n\tfor (p = tn->node_list.next; p != &tn->node_list; p = p->next) {\n\t\trx = tipc_node_crypto_rx_by_list(p);\n\t\tpr_info(\"RX(%7.7s)\\n%s\", tipc_node_get_id_str(rx->node),\n\t\t\ttipc_crypto_key_dump(rx, buf));\n\t}\n\trcu_read_unlock();\n\n\t \n\tfor (i = 0, j = 0; i < MAX_STATS; i++)\n\t\tj += scnprintf(buf + j, 200 - j, \"|%11s \", hstats[i]);\n\tpr_info(\"Counter     %s\", buf);\n\n\tmemset(buf, '-', 115);\n\tbuf[115] = '\\0';\n\tpr_info(\"%s\\n\", buf);\n\n\tj = scnprintf(buf, 200, \"TX(%7.7s) \", tipc_own_id_string(net));\n\tfor_each_possible_cpu(cpu) {\n\t\tfor (i = 0; i < MAX_STATS; i++) {\n\t\t\tstat = per_cpu_ptr(tx->stats, cpu)->stat[i];\n\t\t\tj += scnprintf(buf + j, 200 - j, \"|%11d \", stat);\n\t\t}\n\t\tpr_info(\"%s\", buf);\n\t\tj = scnprintf(buf, 200, \"%12s\", \" \");\n\t}\n\n\trcu_read_lock();\n\tfor (p = tn->node_list.next; p != &tn->node_list; p = p->next) {\n\t\trx = tipc_node_crypto_rx_by_list(p);\n\t\tj = scnprintf(buf, 200, \"RX(%7.7s) \",\n\t\t\t      tipc_node_get_id_str(rx->node));\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tfor (i = 0; i < MAX_STATS; i++) {\n\t\t\t\tstat = per_cpu_ptr(rx->stats, cpu)->stat[i];\n\t\t\t\tj += scnprintf(buf + j, 200 - j, \"|%11d \",\n\t\t\t\t\t       stat);\n\t\t\t}\n\t\t\tpr_info(\"%s\", buf);\n\t\t\tj = scnprintf(buf, 200, \"%12s\", \" \");\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\tpr_info(\"\\n======================== Done ========================\\n\");\n}\n\nstatic char *tipc_crypto_key_dump(struct tipc_crypto *c, char *buf)\n{\n\tstruct tipc_key key = c->key;\n\tstruct tipc_aead *aead;\n\tint k, i = 0;\n\tchar *s;\n\n\tfor (k = KEY_MIN; k <= KEY_MAX; k++) {\n\t\tif (k == KEY_MASTER) {\n\t\t\tif (is_rx(c))\n\t\t\t\tcontinue;\n\t\t\tif (time_before(jiffies,\n\t\t\t\t\tc->timer2 + TIPC_TX_GRACE_PERIOD))\n\t\t\t\ts = \"ACT\";\n\t\t\telse\n\t\t\t\ts = \"PAS\";\n\t\t} else {\n\t\t\tif (k == key.passive)\n\t\t\t\ts = \"PAS\";\n\t\t\telse if (k == key.active)\n\t\t\t\ts = \"ACT\";\n\t\t\telse if (k == key.pending)\n\t\t\t\ts = \"PEN\";\n\t\t\telse\n\t\t\t\ts = \"-\";\n\t\t}\n\t\ti += scnprintf(buf + i, 200 - i, \"\\tKey%d: %s\", k, s);\n\n\t\trcu_read_lock();\n\t\taead = rcu_dereference(c->aead[k]);\n\t\tif (aead)\n\t\t\ti += scnprintf(buf + i, 200 - i,\n\t\t\t\t       \"{\\\"0x...%s\\\", \\\"%s\\\"}/%d:%d\",\n\t\t\t\t       aead->hint,\n\t\t\t\t       (aead->mode == CLUSTER_KEY) ? \"c\" : \"p\",\n\t\t\t\t       atomic_read(&aead->users),\n\t\t\t\t       refcount_read(&aead->refcnt));\n\t\trcu_read_unlock();\n\t\ti += scnprintf(buf + i, 200 - i, \"\\n\");\n\t}\n\n\tif (is_rx(c))\n\t\ti += scnprintf(buf + i, 200 - i, \"\\tPeer RX active: %d\\n\",\n\t\t\t       atomic_read(&c->peer_rx_active));\n\n\treturn buf;\n}\n\nstatic char *tipc_key_change_dump(struct tipc_key old, struct tipc_key new,\n\t\t\t\t  char *buf)\n{\n\tstruct tipc_key *key = &old;\n\tint k, i = 0;\n\tchar *s;\n\n\t \nagain:\n\ti += scnprintf(buf + i, 32 - i, \"[\");\n\tfor (k = KEY_1; k <= KEY_3; k++) {\n\t\tif (k == key->passive)\n\t\t\ts = \"pas\";\n\t\telse if (k == key->active)\n\t\t\ts = \"act\";\n\t\telse if (k == key->pending)\n\t\t\ts = \"pen\";\n\t\telse\n\t\t\ts = \"-\";\n\t\ti += scnprintf(buf + i, 32 - i,\n\t\t\t       (k != KEY_3) ? \"%s \" : \"%s\", s);\n\t}\n\tif (key != &new) {\n\t\ti += scnprintf(buf + i, 32 - i, \"] -> \");\n\t\tkey = &new;\n\t\tgoto again;\n\t}\n\ti += scnprintf(buf + i, 32 - i, \"]\");\n\treturn buf;\n}\n\n \nvoid tipc_crypto_msg_rcv(struct net *net, struct sk_buff *skb)\n{\n\tstruct tipc_crypto *rx;\n\tstruct tipc_msg *hdr;\n\n\tif (unlikely(skb_linearize(skb)))\n\t\tgoto exit;\n\n\thdr = buf_msg(skb);\n\trx = tipc_node_crypto_rx_by_addr(net, msg_prevnode(hdr));\n\tif (unlikely(!rx))\n\t\tgoto exit;\n\n\tswitch (msg_type(hdr)) {\n\tcase KEY_DISTR_MSG:\n\t\tif (tipc_crypto_key_rcv(rx, hdr))\n\t\t\tgoto exit;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\ttipc_node_put(rx->node);\n\nexit:\n\tkfree_skb(skb);\n}\n\n \nint tipc_crypto_key_distr(struct tipc_crypto *tx, u8 key,\n\t\t\t  struct tipc_node *dest)\n{\n\tstruct tipc_aead *aead;\n\tu32 dnode = tipc_node_get_addr(dest);\n\tint rc = -ENOKEY;\n\n\tif (!sysctl_tipc_key_exchange_enabled)\n\t\treturn 0;\n\n\tif (key) {\n\t\trcu_read_lock();\n\t\taead = tipc_aead_get(tx->aead[key]);\n\t\tif (likely(aead)) {\n\t\t\trc = tipc_crypto_key_xmit(tx->net, aead->key,\n\t\t\t\t\t\t  aead->gen, aead->mode,\n\t\t\t\t\t\t  dnode);\n\t\t\ttipc_aead_put(aead);\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\treturn rc;\n}\n\n \nstatic int tipc_crypto_key_xmit(struct net *net, struct tipc_aead_key *skey,\n\t\t\t\tu16 gen, u8 mode, u32 dnode)\n{\n\tstruct sk_buff_head pkts;\n\tstruct tipc_msg *hdr;\n\tstruct sk_buff *skb;\n\tu16 size, cong_link_cnt;\n\tu8 *data;\n\tint rc;\n\n\tsize = tipc_aead_key_size(skey);\n\tskb = tipc_buf_acquire(INT_H_SIZE + size, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\thdr = buf_msg(skb);\n\ttipc_msg_init(tipc_own_addr(net), hdr, MSG_CRYPTO, KEY_DISTR_MSG,\n\t\t      INT_H_SIZE, dnode);\n\tmsg_set_size(hdr, INT_H_SIZE + size);\n\tmsg_set_key_gen(hdr, gen);\n\tmsg_set_key_mode(hdr, mode);\n\n\tdata = msg_data(hdr);\n\t*((__be32 *)(data + TIPC_AEAD_ALG_NAME)) = htonl(skey->keylen);\n\tmemcpy(data, skey->alg_name, TIPC_AEAD_ALG_NAME);\n\tmemcpy(data + TIPC_AEAD_ALG_NAME + sizeof(__be32), skey->key,\n\t       skey->keylen);\n\n\t__skb_queue_head_init(&pkts);\n\t__skb_queue_tail(&pkts, skb);\n\tif (dnode)\n\t\trc = tipc_node_xmit(net, &pkts, dnode, 0);\n\telse\n\t\trc = tipc_bcast_xmit(net, &pkts, &cong_link_cnt);\n\n\treturn rc;\n}\n\n \nstatic bool tipc_crypto_key_rcv(struct tipc_crypto *rx, struct tipc_msg *hdr)\n{\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tstruct tipc_aead_key *skey = NULL;\n\tu16 key_gen = msg_key_gen(hdr);\n\tu32 size = msg_data_sz(hdr);\n\tu8 *data = msg_data(hdr);\n\tunsigned int keylen;\n\n\t \n\tif (unlikely(size < sizeof(struct tipc_aead_key) + TIPC_AEAD_KEYLEN_MIN)) {\n\t\tpr_debug(\"%s: message data size is too small\\n\", rx->name);\n\t\tgoto exit;\n\t}\n\n\tkeylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));\n\n\t \n\tif (unlikely(size != keylen + sizeof(struct tipc_aead_key) ||\n\t\t     keylen > TIPC_AEAD_KEY_SIZE_MAX)) {\n\t\tpr_debug(\"%s: invalid MSG_CRYPTO key size\\n\", rx->name);\n\t\tgoto exit;\n\t}\n\n\tspin_lock(&rx->lock);\n\tif (unlikely(rx->skey || (key_gen == rx->key_gen && rx->key.keys))) {\n\t\tpr_err(\"%s: key existed <%p>, gen %d vs %d\\n\", rx->name,\n\t\t       rx->skey, key_gen, rx->key_gen);\n\t\tgoto exit_unlock;\n\t}\n\n\t \n\tskey = kmalloc(size, GFP_ATOMIC);\n\tif (unlikely(!skey)) {\n\t\tpr_err(\"%s: unable to allocate memory for skey\\n\", rx->name);\n\t\tgoto exit_unlock;\n\t}\n\n\t \n\tskey->keylen = keylen;\n\tmemcpy(skey->alg_name, data, TIPC_AEAD_ALG_NAME);\n\tmemcpy(skey->key, data + TIPC_AEAD_ALG_NAME + sizeof(__be32),\n\t       skey->keylen);\n\n\trx->key_gen = key_gen;\n\trx->skey_mode = msg_key_mode(hdr);\n\trx->skey = skey;\n\trx->nokey = 0;\n\tmb();  \n\nexit_unlock:\n\tspin_unlock(&rx->lock);\n\nexit:\n\t \n\tif (likely(skey && queue_delayed_work(tx->wq, &rx->work, 0)))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic void tipc_crypto_work_rx(struct work_struct *work)\n{\n\tstruct delayed_work *dwork = to_delayed_work(work);\n\tstruct tipc_crypto *rx = container_of(dwork, struct tipc_crypto, work);\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tunsigned long delay = msecs_to_jiffies(5000);\n\tbool resched = false;\n\tu8 key;\n\tint rc;\n\n\t \n\tif (atomic_cmpxchg(&rx->key_distr,\n\t\t\t   KEY_DISTR_SCHED,\n\t\t\t   KEY_DISTR_COMPL) == KEY_DISTR_SCHED) {\n\t\t \n\t\tkey = tx->key.pending ?: tx->key.active;\n\t\trc = tipc_crypto_key_distr(tx, key, rx->node);\n\t\tif (unlikely(rc))\n\t\t\tpr_warn(\"%s: unable to distr key[%d] to %s, err %d\\n\",\n\t\t\t\ttx->name, key, tipc_node_get_id_str(rx->node),\n\t\t\t\trc);\n\n\t\t \n\t\tresched = true;\n\t} else {\n\t\tatomic_cmpxchg(&rx->key_distr, KEY_DISTR_COMPL, 0);\n\t}\n\n\t \n\tif (rx->skey) {\n\t\trc = tipc_crypto_key_init(rx, rx->skey, rx->skey_mode, false);\n\t\tif (unlikely(rc < 0))\n\t\t\tpr_warn(\"%s: unable to attach received skey, err %d\\n\",\n\t\t\t\trx->name, rc);\n\t\tswitch (rc) {\n\t\tcase -EBUSY:\n\t\tcase -ENOMEM:\n\t\t\t \n\t\t\tresched = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tsynchronize_rcu();\n\t\t\tkfree(rx->skey);\n\t\t\trx->skey = NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (resched && queue_delayed_work(tx->wq, &rx->work, delay))\n\t\treturn;\n\n\ttipc_node_put(rx->node);\n}\n\n \nvoid tipc_crypto_rekeying_sched(struct tipc_crypto *tx, bool changed,\n\t\t\t\tu32 new_intv)\n{\n\tunsigned long delay;\n\tbool now = false;\n\n\tif (changed) {\n\t\tif (new_intv == TIPC_REKEYING_NOW)\n\t\t\tnow = true;\n\t\telse\n\t\t\ttx->rekeying_intv = new_intv;\n\t\tcancel_delayed_work_sync(&tx->work);\n\t}\n\n\tif (tx->rekeying_intv || now) {\n\t\tdelay = (now) ? 0 : tx->rekeying_intv * 60 * 1000;\n\t\tqueue_delayed_work(tx->wq, &tx->work, msecs_to_jiffies(delay));\n\t}\n}\n\n \nstatic void tipc_crypto_work_tx(struct work_struct *work)\n{\n\tstruct delayed_work *dwork = to_delayed_work(work);\n\tstruct tipc_crypto *tx = container_of(dwork, struct tipc_crypto, work);\n\tstruct tipc_aead_key *skey = NULL;\n\tstruct tipc_key key = tx->key;\n\tstruct tipc_aead *aead;\n\tint rc = -ENOMEM;\n\n\tif (unlikely(key.pending))\n\t\tgoto resched;\n\n\t \n\trcu_read_lock();\n\taead = rcu_dereference(tx->aead[key.active ?: KEY_MASTER]);\n\tif (unlikely(!aead)) {\n\t\trcu_read_unlock();\n\t\t \n\t\treturn;\n\t}\n\n\t \n\tskey = kmemdup(aead->key, tipc_aead_key_size(aead->key), GFP_ATOMIC);\n\trcu_read_unlock();\n\n\t \n\tif (likely(skey)) {\n\t\trc = tipc_aead_key_generate(skey) ?:\n\t\t     tipc_crypto_key_init(tx, skey, PER_NODE_KEY, false);\n\t\tif (likely(rc > 0))\n\t\t\trc = tipc_crypto_key_distr(tx, rc, NULL);\n\t\tkfree_sensitive(skey);\n\t}\n\n\tif (unlikely(rc))\n\t\tpr_warn_ratelimited(\"%s: rekeying returns %d\\n\", tx->name, rc);\n\nresched:\n\t \n\ttipc_crypto_rekeying_sched(tx, false, 0);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}