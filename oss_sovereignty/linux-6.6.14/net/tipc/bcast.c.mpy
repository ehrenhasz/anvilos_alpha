{
  "module_name": "bcast.c",
  "hash_id": "91e79c7c8573ec6358897f6bf4ba046216428f2467078451b23546a5ff3292dd",
  "original_prompt": "Ingested from linux-6.6.14/net/tipc/bcast.c",
  "human_readable_source": " \n\n#include <linux/tipc_config.h>\n#include \"socket.h\"\n#include \"msg.h\"\n#include \"bcast.h\"\n#include \"link.h\"\n#include \"name_table.h\"\n\n#define BCLINK_WIN_DEFAULT  50\t \n#define BCLINK_WIN_MIN      32\t \n\nconst char tipc_bclink_name[] = \"broadcast-link\";\nunsigned long sysctl_tipc_bc_retruni __read_mostly;\n\n \nstruct tipc_bc_base {\n\tstruct tipc_link *link;\n\tstruct sk_buff_head inputq;\n\tint dests[MAX_BEARERS];\n\tint primary_bearer;\n\tbool bcast_support;\n\tbool force_bcast;\n\tbool rcast_support;\n\tbool force_rcast;\n\tint rc_ratio;\n\tint bc_threshold;\n};\n\nstatic struct tipc_bc_base *tipc_bc_base(struct net *net)\n{\n\treturn tipc_net(net)->bcbase;\n}\n\n \nint tipc_bcast_get_mtu(struct net *net)\n{\n\treturn tipc_link_mss(tipc_bc_sndlink(net));\n}\n\nvoid tipc_bcast_toggle_rcast(struct net *net, bool supp)\n{\n\ttipc_bc_base(net)->rcast_support = supp;\n}\n\nstatic void tipc_bcbase_calc_bc_threshold(struct net *net)\n{\n\tstruct tipc_bc_base *bb = tipc_bc_base(net);\n\tint cluster_size = tipc_link_bc_peers(tipc_bc_sndlink(net));\n\n\tbb->bc_threshold = 1 + (cluster_size * bb->rc_ratio / 100);\n}\n\n \nstatic void tipc_bcbase_select_primary(struct net *net)\n{\n\tstruct tipc_bc_base *bb = tipc_bc_base(net);\n\tint all_dests =  tipc_link_bc_peers(bb->link);\n\tint max_win = tipc_link_max_win(bb->link);\n\tint min_win = tipc_link_min_win(bb->link);\n\tint i, mtu, prim;\n\n\tbb->primary_bearer = INVALID_BEARER_ID;\n\tbb->bcast_support = true;\n\n\tif (!all_dests)\n\t\treturn;\n\n\tfor (i = 0; i < MAX_BEARERS; i++) {\n\t\tif (!bb->dests[i])\n\t\t\tcontinue;\n\n\t\tmtu = tipc_bearer_mtu(net, i);\n\t\tif (mtu < tipc_link_mtu(bb->link)) {\n\t\t\ttipc_link_set_mtu(bb->link, mtu);\n\t\t\ttipc_link_set_queue_limits(bb->link,\n\t\t\t\t\t\t   min_win,\n\t\t\t\t\t\t   max_win);\n\t\t}\n\t\tbb->bcast_support &= tipc_bearer_bcast_support(net, i);\n\t\tif (bb->dests[i] < all_dests)\n\t\t\tcontinue;\n\n\t\tbb->primary_bearer = i;\n\n\t\t \n\t\tif ((i ^ tipc_own_addr(net)) & 1)\n\t\t\tbreak;\n\t}\n\tprim = bb->primary_bearer;\n\tif (prim != INVALID_BEARER_ID)\n\t\tbb->bcast_support = tipc_bearer_bcast_support(net, prim);\n}\n\nvoid tipc_bcast_inc_bearer_dst_cnt(struct net *net, int bearer_id)\n{\n\tstruct tipc_bc_base *bb = tipc_bc_base(net);\n\n\ttipc_bcast_lock(net);\n\tbb->dests[bearer_id]++;\n\ttipc_bcbase_select_primary(net);\n\ttipc_bcast_unlock(net);\n}\n\nvoid tipc_bcast_dec_bearer_dst_cnt(struct net *net, int bearer_id)\n{\n\tstruct tipc_bc_base *bb = tipc_bc_base(net);\n\n\ttipc_bcast_lock(net);\n\tbb->dests[bearer_id]--;\n\ttipc_bcbase_select_primary(net);\n\ttipc_bcast_unlock(net);\n}\n\n \nstatic void tipc_bcbase_xmit(struct net *net, struct sk_buff_head *xmitq)\n{\n\tint bearer_id;\n\tstruct tipc_bc_base *bb = tipc_bc_base(net);\n\tstruct sk_buff *skb, *_skb;\n\tstruct sk_buff_head _xmitq;\n\n\tif (skb_queue_empty(xmitq))\n\t\treturn;\n\n\t \n\tbearer_id = bb->primary_bearer;\n\tif (bearer_id >= 0) {\n\t\ttipc_bearer_bc_xmit(net, bearer_id, xmitq);\n\t\treturn;\n\t}\n\n\t \n\t__skb_queue_head_init(&_xmitq);\n\tfor (bearer_id = 0; bearer_id < MAX_BEARERS; bearer_id++) {\n\t\tif (!bb->dests[bearer_id])\n\t\t\tcontinue;\n\n\t\tskb_queue_walk(xmitq, skb) {\n\t\t\t_skb = pskb_copy_for_clone(skb, GFP_ATOMIC);\n\t\t\tif (!_skb)\n\t\t\t\tbreak;\n\t\t\t__skb_queue_tail(&_xmitq, _skb);\n\t\t}\n\t\ttipc_bearer_bc_xmit(net, bearer_id, &_xmitq);\n\t}\n\t__skb_queue_purge(xmitq);\n\t__skb_queue_purge(&_xmitq);\n}\n\nstatic void tipc_bcast_select_xmit_method(struct net *net, int dests,\n\t\t\t\t\t  struct tipc_mc_method *method)\n{\n\tstruct tipc_bc_base *bb = tipc_bc_base(net);\n\tunsigned long exp = method->expires;\n\n\t \n\tif (!bb->bcast_support) {\n\t\tmethod->rcast = true;\n\t\treturn;\n\t}\n\t \n\tif (!bb->rcast_support) {\n\t\tmethod->rcast = false;\n\t\treturn;\n\t}\n\t \n\tmethod->expires = jiffies + TIPC_METHOD_EXPIRE;\n\tif (method->mandatory)\n\t\treturn;\n\n\tif (!(tipc_net(net)->capabilities & TIPC_MCAST_RBCTL) &&\n\t    time_before(jiffies, exp))\n\t\treturn;\n\n\t \n\tif (bb->force_bcast) {\n\t\tmethod->rcast = false;\n\t\treturn;\n\t}\n\t \n\tif (bb->force_rcast) {\n\t\tmethod->rcast = true;\n\t\treturn;\n\t}\n\t \n\t \n\tmethod->rcast = dests <= bb->bc_threshold;\n}\n\n \nint tipc_bcast_xmit(struct net *net, struct sk_buff_head *pkts,\n\t\t    u16 *cong_link_cnt)\n{\n\tstruct tipc_link *l = tipc_bc_sndlink(net);\n\tstruct sk_buff_head xmitq;\n\tint rc = 0;\n\n\t__skb_queue_head_init(&xmitq);\n\ttipc_bcast_lock(net);\n\tif (tipc_link_bc_peers(l))\n\t\trc = tipc_link_xmit(l, pkts, &xmitq);\n\ttipc_bcast_unlock(net);\n\ttipc_bcbase_xmit(net, &xmitq);\n\t__skb_queue_purge(pkts);\n\tif (rc == -ELINKCONG) {\n\t\t*cong_link_cnt = 1;\n\t\trc = 0;\n\t}\n\treturn rc;\n}\n\n \nstatic int tipc_rcast_xmit(struct net *net, struct sk_buff_head *pkts,\n\t\t\t   struct tipc_nlist *dests, u16 *cong_link_cnt)\n{\n\tstruct tipc_dest *dst, *tmp;\n\tstruct sk_buff_head _pkts;\n\tu32 dnode, selector;\n\n\tselector = msg_link_selector(buf_msg(skb_peek(pkts)));\n\t__skb_queue_head_init(&_pkts);\n\n\tlist_for_each_entry_safe(dst, tmp, &dests->list, list) {\n\t\tdnode = dst->node;\n\t\tif (!tipc_msg_pskb_copy(dnode, pkts, &_pkts))\n\t\t\treturn -ENOMEM;\n\n\t\t \n\t\tif (tipc_node_xmit(net, &_pkts, dnode, selector) == -ELINKCONG)\n\t\t\t(*cong_link_cnt)++;\n\t}\n\treturn 0;\n}\n\n \nstatic int tipc_mcast_send_sync(struct net *net, struct sk_buff *skb,\n\t\t\t\tstruct tipc_mc_method *method,\n\t\t\t\tstruct tipc_nlist *dests)\n{\n\tstruct tipc_msg *hdr, *_hdr;\n\tstruct sk_buff_head tmpq;\n\tstruct sk_buff *_skb;\n\tu16 cong_link_cnt;\n\tint rc = 0;\n\n\t \n\tif (!(tipc_net(net)->capabilities & TIPC_MCAST_RBCTL))\n\t\treturn 0;\n\n\thdr = buf_msg(skb);\n\tif (msg_user(hdr) == MSG_FRAGMENTER)\n\t\thdr = msg_inner_hdr(hdr);\n\tif (msg_type(hdr) != TIPC_MCAST_MSG)\n\t\treturn 0;\n\n\t \n\t_skb = tipc_buf_acquire(MCAST_H_SIZE, GFP_KERNEL);\n\tif (!_skb)\n\t\treturn -ENOMEM;\n\n\t \n\tmsg_set_syn(hdr, 1);\n\n\t \n\tskb_copy_to_linear_data(_skb, hdr, MCAST_H_SIZE);\n\tskb_orphan(_skb);\n\n\t \n\t_hdr = buf_msg(_skb);\n\tmsg_set_size(_hdr, MCAST_H_SIZE);\n\tmsg_set_is_rcast(_hdr, !msg_is_rcast(hdr));\n\tmsg_set_errcode(_hdr, TIPC_ERR_NO_PORT);\n\n\t__skb_queue_head_init(&tmpq);\n\t__skb_queue_tail(&tmpq, _skb);\n\tif (method->rcast)\n\t\trc = tipc_bcast_xmit(net, &tmpq, &cong_link_cnt);\n\telse\n\t\trc = tipc_rcast_xmit(net, &tmpq, dests, &cong_link_cnt);\n\n\t \n\t__skb_queue_purge(&tmpq);\n\n\treturn rc;\n}\n\n \nint tipc_mcast_xmit(struct net *net, struct sk_buff_head *pkts,\n\t\t    struct tipc_mc_method *method, struct tipc_nlist *dests,\n\t\t    u16 *cong_link_cnt)\n{\n\tstruct sk_buff_head inputq, localq;\n\tbool rcast = method->rcast;\n\tstruct tipc_msg *hdr;\n\tstruct sk_buff *skb;\n\tint rc = 0;\n\n\tskb_queue_head_init(&inputq);\n\t__skb_queue_head_init(&localq);\n\n\t \n\tif (dests->local && !tipc_msg_reassemble(pkts, &localq)) {\n\t\trc = -ENOMEM;\n\t\tgoto exit;\n\t}\n\t \n\tif (dests->remote) {\n\t\ttipc_bcast_select_xmit_method(net, dests->remote, method);\n\n\t\tskb = skb_peek(pkts);\n\t\thdr = buf_msg(skb);\n\t\tif (msg_user(hdr) == MSG_FRAGMENTER)\n\t\t\thdr = msg_inner_hdr(hdr);\n\t\tmsg_set_is_rcast(hdr, method->rcast);\n\n\t\t \n\t\tif (rcast != method->rcast) {\n\t\t\trc = tipc_mcast_send_sync(net, skb, method, dests);\n\t\t\tif (unlikely(rc)) {\n\t\t\t\tpr_err(\"Unable to send SYN: method %d, rc %d\\n\",\n\t\t\t\t       rcast, rc);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tif (method->rcast)\n\t\t\trc = tipc_rcast_xmit(net, pkts, dests, cong_link_cnt);\n\t\telse\n\t\t\trc = tipc_bcast_xmit(net, pkts, cong_link_cnt);\n\t}\n\n\tif (dests->local) {\n\t\ttipc_loopback_trace(net, &localq);\n\t\ttipc_sk_mcast_rcv(net, &localq, &inputq);\n\t}\nexit:\n\t \n\t__skb_queue_purge(pkts);\n\treturn rc;\n}\n\n \nint tipc_bcast_rcv(struct net *net, struct tipc_link *l, struct sk_buff *skb)\n{\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tstruct sk_buff_head *inputq = &tipc_bc_base(net)->inputq;\n\tstruct sk_buff_head xmitq;\n\tint rc;\n\n\t__skb_queue_head_init(&xmitq);\n\n\tif (msg_mc_netid(hdr) != tipc_netid(net) || !tipc_link_is_up(l)) {\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\n\ttipc_bcast_lock(net);\n\tif (msg_user(hdr) == BCAST_PROTOCOL)\n\t\trc = tipc_link_bc_nack_rcv(l, skb, &xmitq);\n\telse\n\t\trc = tipc_link_rcv(l, skb, NULL);\n\ttipc_bcast_unlock(net);\n\n\ttipc_bcbase_xmit(net, &xmitq);\n\n\t \n\tif (!skb_queue_empty(inputq))\n\t\ttipc_sk_rcv(net, inputq);\n\n\treturn rc;\n}\n\n \nvoid tipc_bcast_ack_rcv(struct net *net, struct tipc_link *l,\n\t\t\tstruct tipc_msg *hdr)\n{\n\tstruct sk_buff_head *inputq = &tipc_bc_base(net)->inputq;\n\tu16 acked = msg_bcast_ack(hdr);\n\tstruct sk_buff_head xmitq;\n\n\t \n\tif (msg_bc_ack_invalid(hdr))\n\t\treturn;\n\n\t__skb_queue_head_init(&xmitq);\n\n\ttipc_bcast_lock(net);\n\ttipc_link_bc_ack_rcv(l, acked, 0, NULL, &xmitq, NULL);\n\ttipc_bcast_unlock(net);\n\n\ttipc_bcbase_xmit(net, &xmitq);\n\n\t \n\tif (!skb_queue_empty(inputq))\n\t\ttipc_sk_rcv(net, inputq);\n}\n\n \nint tipc_bcast_sync_rcv(struct net *net, struct tipc_link *l,\n\t\t\tstruct tipc_msg *hdr,\n\t\t\tstruct sk_buff_head *retrq)\n{\n\tstruct sk_buff_head *inputq = &tipc_bc_base(net)->inputq;\n\tstruct tipc_gap_ack_blks *ga;\n\tstruct sk_buff_head xmitq;\n\tint rc = 0;\n\n\t__skb_queue_head_init(&xmitq);\n\n\ttipc_bcast_lock(net);\n\tif (msg_type(hdr) != STATE_MSG) {\n\t\ttipc_link_bc_init_rcv(l, hdr);\n\t} else if (!msg_bc_ack_invalid(hdr)) {\n\t\ttipc_get_gap_ack_blks(&ga, l, hdr, false);\n\t\tif (!sysctl_tipc_bc_retruni)\n\t\t\tretrq = &xmitq;\n\t\trc = tipc_link_bc_ack_rcv(l, msg_bcast_ack(hdr),\n\t\t\t\t\t  msg_bc_gap(hdr), ga, &xmitq,\n\t\t\t\t\t  retrq);\n\t\trc |= tipc_link_bc_sync_rcv(l, hdr, &xmitq);\n\t}\n\ttipc_bcast_unlock(net);\n\n\ttipc_bcbase_xmit(net, &xmitq);\n\n\t \n\tif (!skb_queue_empty(inputq))\n\t\ttipc_sk_rcv(net, inputq);\n\treturn rc;\n}\n\n \nvoid tipc_bcast_add_peer(struct net *net, struct tipc_link *uc_l,\n\t\t\t struct sk_buff_head *xmitq)\n{\n\tstruct tipc_link *snd_l = tipc_bc_sndlink(net);\n\n\ttipc_bcast_lock(net);\n\ttipc_link_add_bc_peer(snd_l, uc_l, xmitq);\n\ttipc_bcbase_select_primary(net);\n\ttipc_bcbase_calc_bc_threshold(net);\n\ttipc_bcast_unlock(net);\n}\n\n \nvoid tipc_bcast_remove_peer(struct net *net, struct tipc_link *rcv_l)\n{\n\tstruct tipc_link *snd_l = tipc_bc_sndlink(net);\n\tstruct sk_buff_head *inputq = &tipc_bc_base(net)->inputq;\n\tstruct sk_buff_head xmitq;\n\n\t__skb_queue_head_init(&xmitq);\n\n\ttipc_bcast_lock(net);\n\ttipc_link_remove_bc_peer(snd_l, rcv_l, &xmitq);\n\ttipc_bcbase_select_primary(net);\n\ttipc_bcbase_calc_bc_threshold(net);\n\ttipc_bcast_unlock(net);\n\n\ttipc_bcbase_xmit(net, &xmitq);\n\n\t \n\tif (!skb_queue_empty(inputq))\n\t\ttipc_sk_rcv(net, inputq);\n}\n\nint tipc_bclink_reset_stats(struct net *net, struct tipc_link *l)\n{\n\tif (!l)\n\t\treturn -ENOPROTOOPT;\n\n\ttipc_bcast_lock(net);\n\ttipc_link_reset_stats(l);\n\ttipc_bcast_unlock(net);\n\treturn 0;\n}\n\nstatic int tipc_bc_link_set_queue_limits(struct net *net, u32 max_win)\n{\n\tstruct tipc_link *l = tipc_bc_sndlink(net);\n\n\tif (!l)\n\t\treturn -ENOPROTOOPT;\n\tif (max_win < BCLINK_WIN_MIN)\n\t\tmax_win = BCLINK_WIN_MIN;\n\tif (max_win > TIPC_MAX_LINK_WIN)\n\t\treturn -EINVAL;\n\ttipc_bcast_lock(net);\n\ttipc_link_set_queue_limits(l, tipc_link_min_win(l), max_win);\n\ttipc_bcast_unlock(net);\n\treturn 0;\n}\n\nstatic int tipc_bc_link_set_broadcast_mode(struct net *net, u32 bc_mode)\n{\n\tstruct tipc_bc_base *bb = tipc_bc_base(net);\n\n\tswitch (bc_mode) {\n\tcase BCLINK_MODE_BCAST:\n\t\tif (!bb->bcast_support)\n\t\t\treturn -ENOPROTOOPT;\n\n\t\tbb->force_bcast = true;\n\t\tbb->force_rcast = false;\n\t\tbreak;\n\tcase BCLINK_MODE_RCAST:\n\t\tif (!bb->rcast_support)\n\t\t\treturn -ENOPROTOOPT;\n\n\t\tbb->force_bcast = false;\n\t\tbb->force_rcast = true;\n\t\tbreak;\n\tcase BCLINK_MODE_SEL:\n\t\tif (!bb->bcast_support || !bb->rcast_support)\n\t\t\treturn -ENOPROTOOPT;\n\n\t\tbb->force_bcast = false;\n\t\tbb->force_rcast = false;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int tipc_bc_link_set_broadcast_ratio(struct net *net, u32 bc_ratio)\n{\n\tstruct tipc_bc_base *bb = tipc_bc_base(net);\n\n\tif (!bb->bcast_support || !bb->rcast_support)\n\t\treturn -ENOPROTOOPT;\n\n\tif (bc_ratio > 100 || bc_ratio <= 0)\n\t\treturn -EINVAL;\n\n\tbb->rc_ratio = bc_ratio;\n\ttipc_bcast_lock(net);\n\ttipc_bcbase_calc_bc_threshold(net);\n\ttipc_bcast_unlock(net);\n\n\treturn 0;\n}\n\nint tipc_nl_bc_link_set(struct net *net, struct nlattr *attrs[])\n{\n\tint err;\n\tu32 win;\n\tu32 bc_mode;\n\tu32 bc_ratio;\n\tstruct nlattr *props[TIPC_NLA_PROP_MAX + 1];\n\n\tif (!attrs[TIPC_NLA_LINK_PROP])\n\t\treturn -EINVAL;\n\n\terr = tipc_nl_parse_link_prop(attrs[TIPC_NLA_LINK_PROP], props);\n\tif (err)\n\t\treturn err;\n\n\tif (!props[TIPC_NLA_PROP_WIN] &&\n\t    !props[TIPC_NLA_PROP_BROADCAST] &&\n\t    !props[TIPC_NLA_PROP_BROADCAST_RATIO]) {\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (props[TIPC_NLA_PROP_BROADCAST]) {\n\t\tbc_mode = nla_get_u32(props[TIPC_NLA_PROP_BROADCAST]);\n\t\terr = tipc_bc_link_set_broadcast_mode(net, bc_mode);\n\t}\n\n\tif (!err && props[TIPC_NLA_PROP_BROADCAST_RATIO]) {\n\t\tbc_ratio = nla_get_u32(props[TIPC_NLA_PROP_BROADCAST_RATIO]);\n\t\terr = tipc_bc_link_set_broadcast_ratio(net, bc_ratio);\n\t}\n\n\tif (!err && props[TIPC_NLA_PROP_WIN]) {\n\t\twin = nla_get_u32(props[TIPC_NLA_PROP_WIN]);\n\t\terr = tipc_bc_link_set_queue_limits(net, win);\n\t}\n\n\treturn err;\n}\n\nint tipc_bcast_init(struct net *net)\n{\n\tstruct tipc_net *tn = tipc_net(net);\n\tstruct tipc_bc_base *bb = NULL;\n\tstruct tipc_link *l = NULL;\n\n\tbb = kzalloc(sizeof(*bb), GFP_KERNEL);\n\tif (!bb)\n\t\tgoto enomem;\n\ttn->bcbase = bb;\n\tspin_lock_init(&tipc_net(net)->bclock);\n\n\tif (!tipc_link_bc_create(net, 0, 0, NULL,\n\t\t\t\t one_page_mtu,\n\t\t\t\t BCLINK_WIN_DEFAULT,\n\t\t\t\t BCLINK_WIN_DEFAULT,\n\t\t\t\t 0,\n\t\t\t\t &bb->inputq,\n\t\t\t\t NULL,\n\t\t\t\t NULL,\n\t\t\t\t &l))\n\t\tgoto enomem;\n\tbb->link = l;\n\ttn->bcl = l;\n\tbb->rc_ratio = 10;\n\tbb->rcast_support = true;\n\treturn 0;\nenomem:\n\tkfree(bb);\n\tkfree(l);\n\treturn -ENOMEM;\n}\n\nvoid tipc_bcast_stop(struct net *net)\n{\n\tstruct tipc_net *tn = net_generic(net, tipc_net_id);\n\n\tsynchronize_net();\n\tkfree(tn->bcbase);\n\tkfree(tn->bcl);\n}\n\nvoid tipc_nlist_init(struct tipc_nlist *nl, u32 self)\n{\n\tmemset(nl, 0, sizeof(*nl));\n\tINIT_LIST_HEAD(&nl->list);\n\tnl->self = self;\n}\n\nvoid tipc_nlist_add(struct tipc_nlist *nl, u32 node)\n{\n\tif (node == nl->self)\n\t\tnl->local = true;\n\telse if (tipc_dest_push(&nl->list, node, 0))\n\t\tnl->remote++;\n}\n\nvoid tipc_nlist_del(struct tipc_nlist *nl, u32 node)\n{\n\tif (node == nl->self)\n\t\tnl->local = false;\n\telse if (tipc_dest_del(&nl->list, node, 0))\n\t\tnl->remote--;\n}\n\nvoid tipc_nlist_purge(struct tipc_nlist *nl)\n{\n\ttipc_dest_list_purge(&nl->list);\n\tnl->remote = 0;\n\tnl->local = false;\n}\n\nu32 tipc_bcast_get_mode(struct net *net)\n{\n\tstruct tipc_bc_base *bb = tipc_bc_base(net);\n\n\tif (bb->force_bcast)\n\t\treturn BCLINK_MODE_BCAST;\n\n\tif (bb->force_rcast)\n\t\treturn BCLINK_MODE_RCAST;\n\n\tif (bb->bcast_support && bb->rcast_support)\n\t\treturn BCLINK_MODE_SEL;\n\n\treturn 0;\n}\n\nu32 tipc_bcast_get_broadcast_ratio(struct net *net)\n{\n\tstruct tipc_bc_base *bb = tipc_bc_base(net);\n\n\treturn bb->rc_ratio;\n}\n\nvoid tipc_mcast_filter_msg(struct net *net, struct sk_buff_head *defq,\n\t\t\t   struct sk_buff_head *inputq)\n{\n\tstruct sk_buff *skb, *_skb, *tmp;\n\tstruct tipc_msg *hdr, *_hdr;\n\tbool match = false;\n\tu32 node, port;\n\n\tskb = skb_peek(inputq);\n\tif (!skb)\n\t\treturn;\n\n\thdr = buf_msg(skb);\n\n\tif (likely(!msg_is_syn(hdr) && skb_queue_empty(defq)))\n\t\treturn;\n\n\tnode = msg_orignode(hdr);\n\tif (node == tipc_own_addr(net))\n\t\treturn;\n\n\tport = msg_origport(hdr);\n\n\t \n\tskb_queue_walk(defq, _skb) {\n\t\t_hdr = buf_msg(_skb);\n\t\tif (msg_orignode(_hdr) != node)\n\t\t\tcontinue;\n\t\tif (msg_origport(_hdr) != port)\n\t\t\tcontinue;\n\t\tmatch = true;\n\t\tbreak;\n\t}\n\n\tif (!match) {\n\t\tif (!msg_is_syn(hdr))\n\t\t\treturn;\n\t\t__skb_dequeue(inputq);\n\t\t__skb_queue_tail(defq, skb);\n\t\treturn;\n\t}\n\n\t \n\tif (!msg_is_syn(hdr)) {\n\t\tif (msg_is_rcast(hdr) != msg_is_rcast(_hdr))\n\t\t\treturn;\n\t\t__skb_dequeue(inputq);\n\t\t__skb_queue_tail(defq, skb);\n\t\treturn;\n\t}\n\n\t \n\tif (msg_is_rcast(hdr) == msg_is_rcast(_hdr)) {\n\t\t__skb_dequeue(inputq);\n\t\t__skb_queue_tail(defq, skb);\n\t\treturn;\n\t}\n\n\t \n\t__skb_unlink(_skb, defq);\n\tif (msg_data_sz(hdr)) {\n\t\tkfree_skb(_skb);\n\t} else {\n\t\t__skb_dequeue(inputq);\n\t\tkfree_skb(skb);\n\t\t__skb_queue_tail(inputq, _skb);\n\t}\n\n\t \n\tskb_queue_walk_safe(defq, _skb, tmp) {\n\t\t_hdr = buf_msg(_skb);\n\t\tif (msg_orignode(_hdr) != node)\n\t\t\tcontinue;\n\t\tif (msg_origport(_hdr) != port)\n\t\t\tcontinue;\n\t\tif (msg_is_syn(_hdr))\n\t\t\tbreak;\n\t\t__skb_unlink(_skb, defq);\n\t\t__skb_queue_tail(inputq, _skb);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}