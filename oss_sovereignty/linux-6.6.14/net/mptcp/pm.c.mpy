{
  "module_name": "pm.c",
  "hash_id": "186be5f0474f00381d0ef55507627cca1bfc8f18d4d7e4f3bfb03e487dc1f4eb",
  "original_prompt": "Ingested from linux-6.6.14/net/mptcp/pm.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) \"MPTCP: \" fmt\n\n#include <linux/kernel.h>\n#include <net/tcp.h>\n#include <net/mptcp.h>\n#include \"protocol.h\"\n\n#include \"mib.h\"\n\n \n\nint mptcp_pm_announce_addr(struct mptcp_sock *msk,\n\t\t\t   const struct mptcp_addr_info *addr,\n\t\t\t   bool echo)\n{\n\tu8 add_addr = READ_ONCE(msk->pm.addr_signal);\n\n\tpr_debug(\"msk=%p, local_id=%d, echo=%d\", msk, addr->id, echo);\n\n\tlockdep_assert_held(&msk->pm.lock);\n\n\tif (add_addr &\n\t    (echo ? BIT(MPTCP_ADD_ADDR_ECHO) : BIT(MPTCP_ADD_ADDR_SIGNAL))) {\n\t\tMPTCP_INC_STATS(sock_net((struct sock *)msk),\n\t\t\t\techo ? MPTCP_MIB_ECHOADDTXDROP : MPTCP_MIB_ADDADDRTXDROP);\n\t\treturn -EINVAL;\n\t}\n\n\tif (echo) {\n\t\tmsk->pm.remote = *addr;\n\t\tadd_addr |= BIT(MPTCP_ADD_ADDR_ECHO);\n\t} else {\n\t\tmsk->pm.local = *addr;\n\t\tadd_addr |= BIT(MPTCP_ADD_ADDR_SIGNAL);\n\t}\n\tWRITE_ONCE(msk->pm.addr_signal, add_addr);\n\treturn 0;\n}\n\nint mptcp_pm_remove_addr(struct mptcp_sock *msk, const struct mptcp_rm_list *rm_list)\n{\n\tu8 rm_addr = READ_ONCE(msk->pm.addr_signal);\n\n\tpr_debug(\"msk=%p, rm_list_nr=%d\", msk, rm_list->nr);\n\n\tif (rm_addr) {\n\t\tMPTCP_ADD_STATS(sock_net((struct sock *)msk),\n\t\t\t\tMPTCP_MIB_RMADDRTXDROP, rm_list->nr);\n\t\treturn -EINVAL;\n\t}\n\n\tmsk->pm.rm_list_tx = *rm_list;\n\trm_addr |= BIT(MPTCP_RM_ADDR_SIGNAL);\n\tWRITE_ONCE(msk->pm.addr_signal, rm_addr);\n\tmptcp_pm_nl_addr_send_ack(msk);\n\treturn 0;\n}\n\nint mptcp_pm_remove_subflow(struct mptcp_sock *msk, const struct mptcp_rm_list *rm_list)\n{\n\tpr_debug(\"msk=%p, rm_list_nr=%d\", msk, rm_list->nr);\n\n\tspin_lock_bh(&msk->pm.lock);\n\tmptcp_pm_nl_rm_subflow_received(msk, rm_list);\n\tspin_unlock_bh(&msk->pm.lock);\n\treturn 0;\n}\n\n \n\nvoid mptcp_pm_new_connection(struct mptcp_sock *msk, const struct sock *ssk, int server_side)\n{\n\tstruct mptcp_pm_data *pm = &msk->pm;\n\n\tpr_debug(\"msk=%p, token=%u side=%d\", msk, msk->token, server_side);\n\n\tWRITE_ONCE(pm->server_side, server_side);\n\tmptcp_event(MPTCP_EVENT_CREATED, msk, ssk, GFP_ATOMIC);\n}\n\nbool mptcp_pm_allow_new_subflow(struct mptcp_sock *msk)\n{\n\tstruct mptcp_pm_data *pm = &msk->pm;\n\tunsigned int subflows_max;\n\tint ret = 0;\n\n\tif (mptcp_pm_is_userspace(msk)) {\n\t\tif (mptcp_userspace_pm_active(msk)) {\n\t\t\tspin_lock_bh(&pm->lock);\n\t\t\tpm->subflows++;\n\t\t\tspin_unlock_bh(&pm->lock);\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\n\tsubflows_max = mptcp_pm_get_subflows_max(msk);\n\n\tpr_debug(\"msk=%p subflows=%d max=%d allow=%d\", msk, pm->subflows,\n\t\t subflows_max, READ_ONCE(pm->accept_subflow));\n\n\t \n\tif (!READ_ONCE(pm->accept_subflow))\n\t\treturn false;\n\n\tspin_lock_bh(&pm->lock);\n\tif (READ_ONCE(pm->accept_subflow)) {\n\t\tret = pm->subflows < subflows_max;\n\t\tif (ret && ++pm->subflows == subflows_max)\n\t\t\tWRITE_ONCE(pm->accept_subflow, false);\n\t}\n\tspin_unlock_bh(&pm->lock);\n\n\treturn ret;\n}\n\n \nstatic bool mptcp_pm_schedule_work(struct mptcp_sock *msk,\n\t\t\t\t   enum mptcp_pm_status new_status)\n{\n\tpr_debug(\"msk=%p status=%x new=%lx\", msk, msk->pm.status,\n\t\t BIT(new_status));\n\tif (msk->pm.status & BIT(new_status))\n\t\treturn false;\n\n\tmsk->pm.status |= BIT(new_status);\n\tmptcp_schedule_work((struct sock *)msk);\n\treturn true;\n}\n\nvoid mptcp_pm_fully_established(struct mptcp_sock *msk, const struct sock *ssk)\n{\n\tstruct mptcp_pm_data *pm = &msk->pm;\n\tbool announce = false;\n\n\tpr_debug(\"msk=%p\", msk);\n\n\tspin_lock_bh(&pm->lock);\n\n\t \n\tif (READ_ONCE(pm->work_pending) &&\n\t    !(msk->pm.status & BIT(MPTCP_PM_ALREADY_ESTABLISHED)))\n\t\tmptcp_pm_schedule_work(msk, MPTCP_PM_ESTABLISHED);\n\n\tif ((msk->pm.status & BIT(MPTCP_PM_ALREADY_ESTABLISHED)) == 0)\n\t\tannounce = true;\n\n\tmsk->pm.status |= BIT(MPTCP_PM_ALREADY_ESTABLISHED);\n\tspin_unlock_bh(&pm->lock);\n\n\tif (announce)\n\t\tmptcp_event(MPTCP_EVENT_ESTABLISHED, msk, ssk, GFP_ATOMIC);\n}\n\nvoid mptcp_pm_connection_closed(struct mptcp_sock *msk)\n{\n\tpr_debug(\"msk=%p\", msk);\n}\n\nvoid mptcp_pm_subflow_established(struct mptcp_sock *msk)\n{\n\tstruct mptcp_pm_data *pm = &msk->pm;\n\n\tpr_debug(\"msk=%p\", msk);\n\n\tif (!READ_ONCE(pm->work_pending))\n\t\treturn;\n\n\tspin_lock_bh(&pm->lock);\n\n\tif (READ_ONCE(pm->work_pending))\n\t\tmptcp_pm_schedule_work(msk, MPTCP_PM_SUBFLOW_ESTABLISHED);\n\n\tspin_unlock_bh(&pm->lock);\n}\n\nvoid mptcp_pm_subflow_check_next(struct mptcp_sock *msk, const struct sock *ssk,\n\t\t\t\t const struct mptcp_subflow_context *subflow)\n{\n\tstruct mptcp_pm_data *pm = &msk->pm;\n\tbool update_subflows;\n\n\tupdate_subflows = subflow->request_join || subflow->mp_join;\n\tif (mptcp_pm_is_userspace(msk)) {\n\t\tif (update_subflows) {\n\t\t\tspin_lock_bh(&pm->lock);\n\t\t\tpm->subflows--;\n\t\t\tspin_unlock_bh(&pm->lock);\n\t\t}\n\t\treturn;\n\t}\n\n\tif (!READ_ONCE(pm->work_pending) && !update_subflows)\n\t\treturn;\n\n\tspin_lock_bh(&pm->lock);\n\tif (update_subflows)\n\t\t__mptcp_pm_close_subflow(msk);\n\n\t \n\tif (mptcp_pm_nl_check_work_pending(msk))\n\t\tmptcp_pm_schedule_work(msk, MPTCP_PM_SUBFLOW_ESTABLISHED);\n\n\tspin_unlock_bh(&pm->lock);\n}\n\nvoid mptcp_pm_add_addr_received(const struct sock *ssk,\n\t\t\t\tconst struct mptcp_addr_info *addr)\n{\n\tstruct mptcp_subflow_context *subflow = mptcp_subflow_ctx(ssk);\n\tstruct mptcp_sock *msk = mptcp_sk(subflow->conn);\n\tstruct mptcp_pm_data *pm = &msk->pm;\n\n\tpr_debug(\"msk=%p remote_id=%d accept=%d\", msk, addr->id,\n\t\t READ_ONCE(pm->accept_addr));\n\n\tmptcp_event_addr_announced(ssk, addr);\n\n\tspin_lock_bh(&pm->lock);\n\n\tif (mptcp_pm_is_userspace(msk)) {\n\t\tif (mptcp_userspace_pm_active(msk)) {\n\t\t\tmptcp_pm_announce_addr(msk, addr, true);\n\t\t\tmptcp_pm_add_addr_send_ack(msk);\n\t\t} else {\n\t\t\t__MPTCP_INC_STATS(sock_net((struct sock *)msk), MPTCP_MIB_ADDADDRDROP);\n\t\t}\n\t} else if (!READ_ONCE(pm->accept_addr)) {\n\t\tmptcp_pm_announce_addr(msk, addr, true);\n\t\tmptcp_pm_add_addr_send_ack(msk);\n\t} else if (mptcp_pm_schedule_work(msk, MPTCP_PM_ADD_ADDR_RECEIVED)) {\n\t\tpm->remote = *addr;\n\t} else {\n\t\t__MPTCP_INC_STATS(sock_net((struct sock *)msk), MPTCP_MIB_ADDADDRDROP);\n\t}\n\n\tspin_unlock_bh(&pm->lock);\n}\n\nvoid mptcp_pm_add_addr_echoed(struct mptcp_sock *msk,\n\t\t\t      const struct mptcp_addr_info *addr)\n{\n\tstruct mptcp_pm_data *pm = &msk->pm;\n\n\tpr_debug(\"msk=%p\", msk);\n\n\tspin_lock_bh(&pm->lock);\n\n\tif (mptcp_lookup_anno_list_by_saddr(msk, addr) && READ_ONCE(pm->work_pending))\n\t\tmptcp_pm_schedule_work(msk, MPTCP_PM_SUBFLOW_ESTABLISHED);\n\n\tspin_unlock_bh(&pm->lock);\n}\n\nvoid mptcp_pm_add_addr_send_ack(struct mptcp_sock *msk)\n{\n\tif (!mptcp_pm_should_add_signal(msk))\n\t\treturn;\n\n\tmptcp_pm_schedule_work(msk, MPTCP_PM_ADD_ADDR_SEND_ACK);\n}\n\nvoid mptcp_pm_rm_addr_received(struct mptcp_sock *msk,\n\t\t\t       const struct mptcp_rm_list *rm_list)\n{\n\tstruct mptcp_pm_data *pm = &msk->pm;\n\tu8 i;\n\n\tpr_debug(\"msk=%p remote_ids_nr=%d\", msk, rm_list->nr);\n\n\tfor (i = 0; i < rm_list->nr; i++)\n\t\tmptcp_event_addr_removed(msk, rm_list->ids[i]);\n\n\tspin_lock_bh(&pm->lock);\n\tif (mptcp_pm_schedule_work(msk, MPTCP_PM_RM_ADDR_RECEIVED))\n\t\tpm->rm_list_rx = *rm_list;\n\telse\n\t\t__MPTCP_INC_STATS(sock_net((struct sock *)msk), MPTCP_MIB_RMADDRDROP);\n\tspin_unlock_bh(&pm->lock);\n}\n\nvoid mptcp_pm_mp_prio_received(struct sock *ssk, u8 bkup)\n{\n\tstruct mptcp_subflow_context *subflow = mptcp_subflow_ctx(ssk);\n\tstruct sock *sk = subflow->conn;\n\tstruct mptcp_sock *msk;\n\n\tpr_debug(\"subflow->backup=%d, bkup=%d\\n\", subflow->backup, bkup);\n\tmsk = mptcp_sk(sk);\n\tif (subflow->backup != bkup)\n\t\tsubflow->backup = bkup;\n\n\tmptcp_event(MPTCP_EVENT_SUB_PRIORITY, msk, ssk, GFP_ATOMIC);\n}\n\nvoid mptcp_pm_mp_fail_received(struct sock *sk, u64 fail_seq)\n{\n\tstruct mptcp_subflow_context *subflow = mptcp_subflow_ctx(sk);\n\tstruct mptcp_sock *msk = mptcp_sk(subflow->conn);\n\n\tpr_debug(\"fail_seq=%llu\", fail_seq);\n\n\tif (!READ_ONCE(msk->allow_infinite_fallback))\n\t\treturn;\n\n\tif (!subflow->fail_tout) {\n\t\tpr_debug(\"send MP_FAIL response and infinite map\");\n\n\t\tsubflow->send_mp_fail = 1;\n\t\tsubflow->send_infinite_map = 1;\n\t\ttcp_send_ack(sk);\n\t} else {\n\t\tpr_debug(\"MP_FAIL response received\");\n\t\tWRITE_ONCE(subflow->fail_tout, 0);\n\t}\n}\n\n \n\nbool mptcp_pm_add_addr_signal(struct mptcp_sock *msk, const struct sk_buff *skb,\n\t\t\t      unsigned int opt_size, unsigned int remaining,\n\t\t\t      struct mptcp_addr_info *addr, bool *echo,\n\t\t\t      bool *drop_other_suboptions)\n{\n\tint ret = false;\n\tu8 add_addr;\n\tu8 family;\n\tbool port;\n\n\tspin_lock_bh(&msk->pm.lock);\n\n\t \n\tif (!mptcp_pm_should_add_signal(msk))\n\t\tgoto out_unlock;\n\n\t \n\tif (skb && skb_is_tcp_pure_ack(skb)) {\n\t\tremaining += opt_size;\n\t\t*drop_other_suboptions = true;\n\t}\n\n\t*echo = mptcp_pm_should_add_signal_echo(msk);\n\tport = !!(*echo ? msk->pm.remote.port : msk->pm.local.port);\n\n\tfamily = *echo ? msk->pm.remote.family : msk->pm.local.family;\n\tif (remaining < mptcp_add_addr_len(family, *echo, port))\n\t\tgoto out_unlock;\n\n\tif (*echo) {\n\t\t*addr = msk->pm.remote;\n\t\tadd_addr = msk->pm.addr_signal & ~BIT(MPTCP_ADD_ADDR_ECHO);\n\t} else {\n\t\t*addr = msk->pm.local;\n\t\tadd_addr = msk->pm.addr_signal & ~BIT(MPTCP_ADD_ADDR_SIGNAL);\n\t}\n\tWRITE_ONCE(msk->pm.addr_signal, add_addr);\n\tret = true;\n\nout_unlock:\n\tspin_unlock_bh(&msk->pm.lock);\n\treturn ret;\n}\n\nbool mptcp_pm_rm_addr_signal(struct mptcp_sock *msk, unsigned int remaining,\n\t\t\t     struct mptcp_rm_list *rm_list)\n{\n\tint ret = false, len;\n\tu8 rm_addr;\n\n\tspin_lock_bh(&msk->pm.lock);\n\n\t \n\tif (!mptcp_pm_should_rm_signal(msk))\n\t\tgoto out_unlock;\n\n\trm_addr = msk->pm.addr_signal & ~BIT(MPTCP_RM_ADDR_SIGNAL);\n\tlen = mptcp_rm_addr_len(&msk->pm.rm_list_tx);\n\tif (len < 0) {\n\t\tWRITE_ONCE(msk->pm.addr_signal, rm_addr);\n\t\tgoto out_unlock;\n\t}\n\tif (remaining < len)\n\t\tgoto out_unlock;\n\n\t*rm_list = msk->pm.rm_list_tx;\n\tWRITE_ONCE(msk->pm.addr_signal, rm_addr);\n\tret = true;\n\nout_unlock:\n\tspin_unlock_bh(&msk->pm.lock);\n\treturn ret;\n}\n\nint mptcp_pm_get_local_id(struct mptcp_sock *msk, struct sock_common *skc)\n{\n\tstruct mptcp_addr_info skc_local;\n\tstruct mptcp_addr_info msk_local;\n\n\tif (WARN_ON_ONCE(!msk))\n\t\treturn -1;\n\n\t \n\tmptcp_local_address((struct sock_common *)msk, &msk_local);\n\tmptcp_local_address((struct sock_common *)skc, &skc_local);\n\tif (mptcp_addresses_equal(&msk_local, &skc_local, false))\n\t\treturn 0;\n\n\tif (mptcp_pm_is_userspace(msk))\n\t\treturn mptcp_userspace_pm_get_local_id(msk, &skc_local);\n\treturn mptcp_pm_nl_get_local_id(msk, &skc_local);\n}\n\nint mptcp_pm_get_flags_and_ifindex_by_id(struct mptcp_sock *msk, unsigned int id,\n\t\t\t\t\t u8 *flags, int *ifindex)\n{\n\t*flags = 0;\n\t*ifindex = 0;\n\n\tif (!id)\n\t\treturn 0;\n\n\tif (mptcp_pm_is_userspace(msk))\n\t\treturn mptcp_userspace_pm_get_flags_and_ifindex_by_id(msk, id, flags, ifindex);\n\treturn mptcp_pm_nl_get_flags_and_ifindex_by_id(msk, id, flags, ifindex);\n}\n\nint mptcp_pm_set_flags(struct net *net, struct nlattr *token,\n\t\t       struct mptcp_pm_addr_entry *loc,\n\t\t       struct mptcp_pm_addr_entry *rem, u8 bkup)\n{\n\tif (token)\n\t\treturn mptcp_userspace_pm_set_flags(net, token, loc, rem, bkup);\n\treturn mptcp_pm_nl_set_flags(net, loc, bkup);\n}\n\nvoid mptcp_pm_subflow_chk_stale(const struct mptcp_sock *msk, struct sock *ssk)\n{\n\tstruct mptcp_subflow_context *subflow = mptcp_subflow_ctx(ssk);\n\tu32 rcv_tstamp = READ_ONCE(tcp_sk(ssk)->rcv_tstamp);\n\n\t \n\tif (!subflow->stale_count) {\n\t\tsubflow->stale_rcv_tstamp = rcv_tstamp;\n\t\tsubflow->stale_count++;\n\t} else if (subflow->stale_rcv_tstamp == rcv_tstamp) {\n\t\tif (subflow->stale_count < U8_MAX)\n\t\t\tsubflow->stale_count++;\n\t\tmptcp_pm_nl_subflow_chk_stale(msk, ssk);\n\t} else {\n\t\tsubflow->stale_count = 0;\n\t\tmptcp_subflow_set_active(subflow);\n\t}\n}\n\n \nbool mptcp_pm_addr_families_match(const struct sock *sk,\n\t\t\t\t  const struct mptcp_addr_info *loc,\n\t\t\t\t  const struct mptcp_addr_info *rem)\n{\n\tbool mptcp_is_v4 = sk->sk_family == AF_INET;\n\n#if IS_ENABLED(CONFIG_MPTCP_IPV6)\n\tbool loc_is_v4 = loc->family == AF_INET || ipv6_addr_v4mapped(&loc->addr6);\n\tbool rem_is_v4 = rem->family == AF_INET || ipv6_addr_v4mapped(&rem->addr6);\n\n\tif (mptcp_is_v4)\n\t\treturn loc_is_v4 && rem_is_v4;\n\n\tif (ipv6_only_sock(sk))\n\t\treturn !loc_is_v4 && !rem_is_v4;\n\n\treturn loc_is_v4 == rem_is_v4;\n#else\n\treturn mptcp_is_v4 && loc->family == AF_INET && rem->family == AF_INET;\n#endif\n}\n\nvoid mptcp_pm_data_reset(struct mptcp_sock *msk)\n{\n\tu8 pm_type = mptcp_get_pm_type(sock_net((struct sock *)msk));\n\tstruct mptcp_pm_data *pm = &msk->pm;\n\n\tpm->add_addr_signaled = 0;\n\tpm->add_addr_accepted = 0;\n\tpm->local_addr_used = 0;\n\tpm->subflows = 0;\n\tpm->rm_list_tx.nr = 0;\n\tpm->rm_list_rx.nr = 0;\n\tWRITE_ONCE(pm->pm_type, pm_type);\n\n\tif (pm_type == MPTCP_PM_TYPE_KERNEL) {\n\t\tbool subflows_allowed = !!mptcp_pm_get_subflows_max(msk);\n\n\t\t \n\t\tWRITE_ONCE(pm->work_pending,\n\t\t\t   (!!mptcp_pm_get_local_addr_max(msk) &&\n\t\t\t    subflows_allowed) ||\n\t\t\t   !!mptcp_pm_get_add_addr_signal_max(msk));\n\t\tWRITE_ONCE(pm->accept_addr,\n\t\t\t   !!mptcp_pm_get_add_addr_accept_max(msk) &&\n\t\t\t   subflows_allowed);\n\t\tWRITE_ONCE(pm->accept_subflow, subflows_allowed);\n\t} else {\n\t\tWRITE_ONCE(pm->work_pending, 0);\n\t\tWRITE_ONCE(pm->accept_addr, 0);\n\t\tWRITE_ONCE(pm->accept_subflow, 0);\n\t}\n\n\tWRITE_ONCE(pm->addr_signal, 0);\n\tWRITE_ONCE(pm->remote_deny_join_id0, false);\n\tpm->status = 0;\n\tbitmap_fill(msk->pm.id_avail_bitmap, MPTCP_PM_MAX_ADDR_ID + 1);\n}\n\nvoid mptcp_pm_data_init(struct mptcp_sock *msk)\n{\n\tspin_lock_init(&msk->pm.lock);\n\tINIT_LIST_HEAD(&msk->pm.anno_list);\n\tINIT_LIST_HEAD(&msk->pm.userspace_pm_local_addr_list);\n\tmptcp_pm_data_reset(msk);\n}\n\nvoid __init mptcp_pm_init(void)\n{\n\tmptcp_pm_nl_init();\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}