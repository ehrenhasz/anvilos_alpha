{
  "module_name": "protocol.h",
  "hash_id": "0bf8c0753e4c62bd2345c2268f0bf130a42bbf1eee89ec217c5172b0aa5328bb",
  "original_prompt": "Ingested from linux-6.6.14/net/mptcp/protocol.h",
  "human_readable_source": " \n \n\n#ifndef __MPTCP_PROTOCOL_H\n#define __MPTCP_PROTOCOL_H\n\n#include <linux/random.h>\n#include <net/tcp.h>\n#include <net/inet_connection_sock.h>\n#include <uapi/linux/mptcp.h>\n#include <net/genetlink.h>\n\n#define MPTCP_SUPPORTED_VERSION\t1\n\n \n#define OPTION_MPTCP_MPC_SYN\tBIT(0)\n#define OPTION_MPTCP_MPC_SYNACK\tBIT(1)\n#define OPTION_MPTCP_MPC_ACK\tBIT(2)\n#define OPTION_MPTCP_MPJ_SYN\tBIT(3)\n#define OPTION_MPTCP_MPJ_SYNACK\tBIT(4)\n#define OPTION_MPTCP_MPJ_ACK\tBIT(5)\n#define OPTION_MPTCP_ADD_ADDR\tBIT(6)\n#define OPTION_MPTCP_RM_ADDR\tBIT(7)\n#define OPTION_MPTCP_FASTCLOSE\tBIT(8)\n#define OPTION_MPTCP_PRIO\tBIT(9)\n#define OPTION_MPTCP_RST\tBIT(10)\n#define OPTION_MPTCP_DSS\tBIT(11)\n#define OPTION_MPTCP_FAIL\tBIT(12)\n\n#define OPTION_MPTCP_CSUMREQD\tBIT(13)\n\n#define OPTIONS_MPTCP_MPC\t(OPTION_MPTCP_MPC_SYN | OPTION_MPTCP_MPC_SYNACK | \\\n\t\t\t\t OPTION_MPTCP_MPC_ACK)\n#define OPTIONS_MPTCP_MPJ\t(OPTION_MPTCP_MPJ_SYN | OPTION_MPTCP_MPJ_SYNACK | \\\n\t\t\t\t OPTION_MPTCP_MPJ_ACK)\n\n \n#define MPTCPOPT_MP_CAPABLE\t0\n#define MPTCPOPT_MP_JOIN\t1\n#define MPTCPOPT_DSS\t\t2\n#define MPTCPOPT_ADD_ADDR\t3\n#define MPTCPOPT_RM_ADDR\t4\n#define MPTCPOPT_MP_PRIO\t5\n#define MPTCPOPT_MP_FAIL\t6\n#define MPTCPOPT_MP_FASTCLOSE\t7\n#define MPTCPOPT_RST\t\t8\n\n \n#define TCPOLEN_MPTCP_MPC_SYN\t\t4\n#define TCPOLEN_MPTCP_MPC_SYNACK\t12\n#define TCPOLEN_MPTCP_MPC_ACK\t\t20\n#define TCPOLEN_MPTCP_MPC_ACK_DATA\t22\n#define TCPOLEN_MPTCP_MPJ_SYN\t\t12\n#define TCPOLEN_MPTCP_MPJ_SYNACK\t16\n#define TCPOLEN_MPTCP_MPJ_ACK\t\t24\n#define TCPOLEN_MPTCP_DSS_BASE\t\t4\n#define TCPOLEN_MPTCP_DSS_ACK32\t\t4\n#define TCPOLEN_MPTCP_DSS_ACK64\t\t8\n#define TCPOLEN_MPTCP_DSS_MAP32\t\t10\n#define TCPOLEN_MPTCP_DSS_MAP64\t\t14\n#define TCPOLEN_MPTCP_DSS_CHECKSUM\t2\n#define TCPOLEN_MPTCP_ADD_ADDR\t\t16\n#define TCPOLEN_MPTCP_ADD_ADDR_PORT\t18\n#define TCPOLEN_MPTCP_ADD_ADDR_BASE\t8\n#define TCPOLEN_MPTCP_ADD_ADDR_BASE_PORT\t10\n#define TCPOLEN_MPTCP_ADD_ADDR6\t\t28\n#define TCPOLEN_MPTCP_ADD_ADDR6_PORT\t30\n#define TCPOLEN_MPTCP_ADD_ADDR6_BASE\t20\n#define TCPOLEN_MPTCP_ADD_ADDR6_BASE_PORT\t22\n#define TCPOLEN_MPTCP_PORT_LEN\t\t2\n#define TCPOLEN_MPTCP_PORT_ALIGN\t2\n#define TCPOLEN_MPTCP_RM_ADDR_BASE\t3\n#define TCPOLEN_MPTCP_PRIO\t\t3\n#define TCPOLEN_MPTCP_PRIO_ALIGN\t4\n#define TCPOLEN_MPTCP_FASTCLOSE\t\t12\n#define TCPOLEN_MPTCP_RST\t\t4\n#define TCPOLEN_MPTCP_FAIL\t\t12\n\n#define TCPOLEN_MPTCP_MPC_ACK_DATA_CSUM\t(TCPOLEN_MPTCP_DSS_CHECKSUM + TCPOLEN_MPTCP_MPC_ACK_DATA)\n\n \n#define MPTCPOPT_BACKUP\t\tBIT(0)\n#define MPTCPOPT_THMAC_LEN\t8\n\n \n#define MPTCP_VERSION_MASK\t(0x0F)\n#define MPTCP_CAP_CHECKSUM_REQD\tBIT(7)\n#define MPTCP_CAP_EXTENSIBILITY\tBIT(6)\n#define MPTCP_CAP_DENY_JOIN_ID0\tBIT(5)\n#define MPTCP_CAP_HMAC_SHA256\tBIT(0)\n#define MPTCP_CAP_FLAG_MASK\t(0x1F)\n\n \n#define MPTCP_DSS_DATA_FIN\tBIT(4)\n#define MPTCP_DSS_DSN64\t\tBIT(3)\n#define MPTCP_DSS_HAS_MAP\tBIT(2)\n#define MPTCP_DSS_ACK64\t\tBIT(1)\n#define MPTCP_DSS_HAS_ACK\tBIT(0)\n#define MPTCP_DSS_FLAG_MASK\t(0x1F)\n\n \n#define MPTCP_ADDR_ECHO\t\tBIT(0)\n\n \n#define MPTCP_PRIO_BKUP\t\tBIT(0)\n\n \n#define MPTCP_RST_TRANSIENT\tBIT(0)\n\n \n#define MPTCP_NOSPACE\t\t1\n#define MPTCP_WORK_RTX\t\t2\n#define MPTCP_FALLBACK_DONE\t4\n#define MPTCP_WORK_CLOSE_SUBFLOW 5\n\n \n#define MPTCP_PUSH_PENDING\t1\n#define MPTCP_CLEAN_UNA\t\t2\n#define MPTCP_ERROR_REPORT\t3\n#define MPTCP_RETRANSMIT\t4\n#define MPTCP_FLUSH_JOIN_LIST\t5\n#define MPTCP_SYNC_STATE\t6\n#define MPTCP_SYNC_SNDBUF\t7\n\nstruct mptcp_skb_cb {\n\tu64 map_seq;\n\tu64 end_seq;\n\tu32 offset;\n\tu8  has_rxtstamp:1;\n};\n\n#define MPTCP_SKB_CB(__skb)\t((struct mptcp_skb_cb *)&((__skb)->cb[0]))\n\nstatic inline bool before64(__u64 seq1, __u64 seq2)\n{\n\treturn (__s64)(seq1 - seq2) < 0;\n}\n\n#define after64(seq2, seq1)\tbefore64(seq1, seq2)\n\nstruct mptcp_options_received {\n\tu64\tsndr_key;\n\tu64\trcvr_key;\n\tu64\tdata_ack;\n\tu64\tdata_seq;\n\tu32\tsubflow_seq;\n\tu16\tdata_len;\n\t__sum16\tcsum;\n\tu16\tsuboptions;\n\tu32\ttoken;\n\tu32\tnonce;\n\tu16\tuse_map:1,\n\t\tdsn64:1,\n\t\tdata_fin:1,\n\t\tuse_ack:1,\n\t\tack64:1,\n\t\tmpc_map:1,\n\t\treset_reason:4,\n\t\treset_transient:1,\n\t\techo:1,\n\t\tbackup:1,\n\t\tdeny_join_id0:1,\n\t\t__unused:2;\n\tu8\tjoin_id;\n\tu64\tthmac;\n\tu8\thmac[MPTCPOPT_HMAC_LEN];\n\tstruct mptcp_addr_info addr;\n\tstruct mptcp_rm_list rm_list;\n\tu64\tahmac;\n\tu64\tfail_seq;\n};\n\nstatic inline __be32 mptcp_option(u8 subopt, u8 len, u8 nib, u8 field)\n{\n\treturn htonl((TCPOPT_MPTCP << 24) | (len << 16) | (subopt << 12) |\n\t\t     ((nib & 0xF) << 8) | field);\n}\n\nenum mptcp_pm_status {\n\tMPTCP_PM_ADD_ADDR_RECEIVED,\n\tMPTCP_PM_ADD_ADDR_SEND_ACK,\n\tMPTCP_PM_RM_ADDR_RECEIVED,\n\tMPTCP_PM_ESTABLISHED,\n\tMPTCP_PM_SUBFLOW_ESTABLISHED,\n\tMPTCP_PM_ALREADY_ESTABLISHED,\t \n\tMPTCP_PM_MPC_ENDPOINT_ACCOUNTED  \n};\n\nenum mptcp_pm_type {\n\tMPTCP_PM_TYPE_KERNEL = 0,\n\tMPTCP_PM_TYPE_USERSPACE,\n\n\t__MPTCP_PM_TYPE_NR,\n\t__MPTCP_PM_TYPE_MAX = __MPTCP_PM_TYPE_NR - 1,\n};\n\n \n#define MPTCP_PM_WORK_MASK ((1 << MPTCP_PM_ALREADY_ESTABLISHED) - 1)\n\nenum mptcp_addr_signal_status {\n\tMPTCP_ADD_ADDR_SIGNAL,\n\tMPTCP_ADD_ADDR_ECHO,\n\tMPTCP_RM_ADDR_SIGNAL,\n};\n\n \n#define MPTCP_PM_MAX_ADDR_ID\t\tU8_MAX\n\nstruct mptcp_pm_data {\n\tstruct mptcp_addr_info local;\n\tstruct mptcp_addr_info remote;\n\tstruct list_head anno_list;\n\tstruct list_head userspace_pm_local_addr_list;\n\n\tspinlock_t\tlock;\t\t \n\n\tu8\t\taddr_signal;\n\tbool\t\tserver_side;\n\tbool\t\twork_pending;\n\tbool\t\taccept_addr;\n\tbool\t\taccept_subflow;\n\tbool\t\tremote_deny_join_id0;\n\tu8\t\tadd_addr_signaled;\n\tu8\t\tadd_addr_accepted;\n\tu8\t\tlocal_addr_used;\n\tu8\t\tpm_type;\n\tu8\t\tsubflows;\n\tu8\t\tstatus;\n\tDECLARE_BITMAP(id_avail_bitmap, MPTCP_PM_MAX_ADDR_ID + 1);\n\tstruct mptcp_rm_list rm_list_tx;\n\tstruct mptcp_rm_list rm_list_rx;\n};\n\nstruct mptcp_pm_addr_entry {\n\tstruct list_head\tlist;\n\tstruct mptcp_addr_info\taddr;\n\tu8\t\t\tflags;\n\tint\t\t\tifindex;\n\tstruct socket\t\t*lsk;\n};\n\nstruct mptcp_data_frag {\n\tstruct list_head list;\n\tu64 data_seq;\n\tu16 data_len;\n\tu16 offset;\n\tu16 overhead;\n\tu16 already_sent;\n\tstruct page *page;\n};\n\n \nstruct mptcp_sock {\n\t \n\tstruct inet_connection_sock sk;\n\tu64\t\tlocal_key;\n\tu64\t\tremote_key;\n\tu64\t\twrite_seq;\n\tu64\t\tbytes_sent;\n\tu64\t\tsnd_nxt;\n\tu64\t\tbytes_received;\n\tu64\t\tack_seq;\n\tatomic64_t\trcv_wnd_sent;\n\tu64\t\trcv_data_fin_seq;\n\tu64\t\tbytes_retrans;\n\tint\t\trmem_fwd_alloc;\n\tint\t\tsnd_burst;\n\tint\t\told_wspace;\n\tu64\t\trecovery_snd_nxt;\t \n\tu64\t\tbytes_acked;\n\tu64\t\tsnd_una;\n\tu64\t\twnd_end;\n\tunsigned long\ttimer_ival;\n\tu32\t\ttoken;\n\tint\t\trmem_released;\n\tunsigned long\tflags;\n\tunsigned long\tcb_flags;\n\tunsigned long\tpush_pending;\n\tbool\t\trecovery;\t\t \n\tbool\t\tcan_ack;\n\tbool\t\tfully_established;\n\tbool\t\trcv_data_fin;\n\tbool\t\tsnd_data_fin_enable;\n\tbool\t\trcv_fastclose;\n\tbool\t\tuse_64bit_ack;  \n\tbool\t\tcsum_enabled;\n\tbool\t\tallow_infinite_fallback;\n\tu8\t\tpending_state;  \n\tu8\t\tmpc_endpoint_id;\n\tu8\t\trecvmsg_inq:1,\n\t\t\tcork:1,\n\t\t\tnodelay:1,\n\t\t\tfastopening:1,\n\t\t\tin_accept_queue:1,\n\t\t\tfree_first:1;\n\tstruct work_struct work;\n\tstruct sk_buff  *ooo_last_skb;\n\tstruct rb_root  out_of_order_queue;\n\tstruct sk_buff_head receive_queue;\n\tstruct list_head conn_list;\n\tstruct list_head rtx_queue;\n\tstruct mptcp_data_frag *first_pending;\n\tstruct list_head join_list;\n\tstruct sock\t*first;  \n\tstruct mptcp_pm_data\tpm;\n\tstruct mptcp_sched_ops\t*sched;\n\tstruct {\n\t\tu32\tspace;\t \n\t\tu32\tcopied;  \n\t\tu64\ttime;\t \n\t\tu64\trtt_us;  \n\t} rcvq_space;\n\tu8\t\tscaling_ratio;\n\n\tu32\t\tsubflow_id;\n\tu32\t\tsetsockopt_seq;\n\tchar\t\tca_name[TCP_CA_NAME_MAX];\n};\n\n#define mptcp_data_lock(sk) spin_lock_bh(&(sk)->sk_lock.slock)\n#define mptcp_data_unlock(sk) spin_unlock_bh(&(sk)->sk_lock.slock)\n\n#define mptcp_for_each_subflow(__msk, __subflow)\t\t\t\\\n\tlist_for_each_entry(__subflow, &((__msk)->conn_list), node)\n#define mptcp_for_each_subflow_safe(__msk, __subflow, __tmp)\t\t\t\\\n\tlist_for_each_entry_safe(__subflow, __tmp, &((__msk)->conn_list), node)\n\nstatic inline void msk_owned_by_me(const struct mptcp_sock *msk)\n{\n\tsock_owned_by_me((const struct sock *)msk);\n}\n\n#define mptcp_sk(ptr) container_of_const(ptr, struct mptcp_sock, sk.icsk_inet.sk)\n\n \nstatic inline int __mptcp_rmem(const struct sock *sk)\n{\n\treturn atomic_read(&sk->sk_rmem_alloc) - READ_ONCE(mptcp_sk(sk)->rmem_released);\n}\n\nstatic inline int mptcp_win_from_space(const struct sock *sk, int space)\n{\n\treturn __tcp_win_from_space(mptcp_sk(sk)->scaling_ratio, space);\n}\n\nstatic inline int __mptcp_space(const struct sock *sk)\n{\n\treturn mptcp_win_from_space(sk, READ_ONCE(sk->sk_rcvbuf) - __mptcp_rmem(sk));\n}\n\nstatic inline struct mptcp_data_frag *mptcp_send_head(const struct sock *sk)\n{\n\tconst struct mptcp_sock *msk = mptcp_sk(sk);\n\n\treturn READ_ONCE(msk->first_pending);\n}\n\nstatic inline struct mptcp_data_frag *mptcp_send_next(struct sock *sk)\n{\n\tstruct mptcp_sock *msk = mptcp_sk(sk);\n\tstruct mptcp_data_frag *cur;\n\n\tcur = msk->first_pending;\n\treturn list_is_last(&cur->list, &msk->rtx_queue) ? NULL :\n\t\t\t\t\t\t     list_next_entry(cur, list);\n}\n\nstatic inline struct mptcp_data_frag *mptcp_pending_tail(const struct sock *sk)\n{\n\tconst struct mptcp_sock *msk = mptcp_sk(sk);\n\n\tif (!msk->first_pending)\n\t\treturn NULL;\n\n\tif (WARN_ON_ONCE(list_empty(&msk->rtx_queue)))\n\t\treturn NULL;\n\n\treturn list_last_entry(&msk->rtx_queue, struct mptcp_data_frag, list);\n}\n\nstatic inline struct mptcp_data_frag *mptcp_rtx_head(struct sock *sk)\n{\n\tstruct mptcp_sock *msk = mptcp_sk(sk);\n\n\tif (msk->snd_una == READ_ONCE(msk->snd_nxt))\n\t\treturn NULL;\n\n\treturn list_first_entry_or_null(&msk->rtx_queue, struct mptcp_data_frag, list);\n}\n\nstruct csum_pseudo_header {\n\t__be64 data_seq;\n\t__be32 subflow_seq;\n\t__be16 data_len;\n\t__sum16 csum;\n};\n\nstruct mptcp_subflow_request_sock {\n\tstruct\ttcp_request_sock sk;\n\tu16\tmp_capable : 1,\n\t\tmp_join : 1,\n\t\tbackup : 1,\n\t\tcsum_reqd : 1,\n\t\tallow_join_id0 : 1;\n\tu8\tlocal_id;\n\tu8\tremote_id;\n\tu64\tlocal_key;\n\tu64\tidsn;\n\tu32\ttoken;\n\tu32\tssn_offset;\n\tu64\tthmac;\n\tu32\tlocal_nonce;\n\tu32\tremote_nonce;\n\tstruct mptcp_sock\t*msk;\n\tstruct hlist_nulls_node token_node;\n};\n\nstatic inline struct mptcp_subflow_request_sock *\nmptcp_subflow_rsk(const struct request_sock *rsk)\n{\n\treturn (struct mptcp_subflow_request_sock *)rsk;\n}\n\nenum mptcp_data_avail {\n\tMPTCP_SUBFLOW_NODATA,\n\tMPTCP_SUBFLOW_DATA_AVAIL,\n};\n\nstruct mptcp_delegated_action {\n\tstruct napi_struct napi;\n\tstruct list_head head;\n};\n\nDECLARE_PER_CPU(struct mptcp_delegated_action, mptcp_delegated_actions);\n\n#define MPTCP_DELEGATE_SCHEDULED\t0\n#define MPTCP_DELEGATE_SEND\t\t1\n#define MPTCP_DELEGATE_ACK\t\t2\n#define MPTCP_DELEGATE_SNDBUF\t\t3\n\n#define MPTCP_DELEGATE_ACTIONS_MASK\t(~BIT(MPTCP_DELEGATE_SCHEDULED))\n \nstruct mptcp_subflow_context {\n\tstruct\tlist_head node; \n\n\tstruct_group(reset,\n\n\tunsigned long avg_pacing_rate;  \n\tu64\tlocal_key;\n\tu64\tremote_key;\n\tu64\tidsn;\n\tu64\tmap_seq;\n\tu32\tsnd_isn;\n\tu32\ttoken;\n\tu32\trel_write_seq;\n\tu32\tmap_subflow_seq;\n\tu32\tssn_offset;\n\tu32\tmap_data_len;\n\t__wsum\tmap_data_csum;\n\tu32\tmap_csum_len;\n\tu32\trequest_mptcp : 1,   \n\t\trequest_join : 1,    \n\t\trequest_bkup : 1,\n\t\tmp_capable : 1,\t     \n\t\tmp_join : 1,\t     \n\t\tfully_established : 1,\t     \n\t\tpm_notified : 1,     \n\t\tconn_finished : 1,\n\t\tmap_valid : 1,\n\t\tmap_csum_reqd : 1,\n\t\tmap_data_fin : 1,\n\t\tmpc_map : 1,\n\t\tbackup : 1,\n\t\tsend_mp_prio : 1,\n\t\tsend_mp_fail : 1,\n\t\tsend_fastclose : 1,\n\t\tsend_infinite_map : 1,\n\t\tremote_key_valid : 1,         \n\t\tdisposable : 1,\t     \n\t\tstale : 1,\t     \n\t\tlocal_id_valid : 1,  \n\t\tvalid_csum_seen : 1,         \n\t\tis_mptfo : 1,\t     \n\t\t__unused : 9;\n\tenum mptcp_data_avail data_avail;\n\tbool\tscheduled;\n\tu32\tremote_nonce;\n\tu64\tthmac;\n\tu32\tlocal_nonce;\n\tu32\tremote_token;\n\tunion {\n\t\tu8\thmac[MPTCPOPT_HMAC_LEN];  \n\t\tu64\tiasn;\t     \n\t};\n\tu8\tlocal_id;\n\tu8\tremote_id;\n\tu8\treset_seen:1;\n\tu8\treset_transient:1;\n\tu8\treset_reason:4;\n\tu8\tstale_count;\n\n\tu32\tsubflow_id;\n\n\tlong\tdelegated_status;\n\tunsigned long\tfail_tout;\n\n\t);\n\n\tstruct\tlist_head delegated_node;    \n\n\tu32\tsetsockopt_seq;\n\tu32\tstale_rcv_tstamp;\n\tint     cached_sndbuf;\t     \n\n\tstruct\tsock *tcp_sock;\t     \n\tstruct\tsock *conn;\t     \n\tconst\tstruct inet_connection_sock_af_ops *icsk_af_ops;\n\tvoid\t(*tcp_state_change)(struct sock *sk);\n\tvoid\t(*tcp_error_report)(struct sock *sk);\n\n\tstruct\trcu_head rcu;\n};\n\nstatic inline struct mptcp_subflow_context *\nmptcp_subflow_ctx(const struct sock *sk)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\n\t \n\treturn (__force struct mptcp_subflow_context *)icsk->icsk_ulp_data;\n}\n\nstatic inline struct sock *\nmptcp_subflow_tcp_sock(const struct mptcp_subflow_context *subflow)\n{\n\treturn subflow->tcp_sock;\n}\n\nstatic inline void\nmptcp_subflow_ctx_reset(struct mptcp_subflow_context *subflow)\n{\n\tmemset(&subflow->reset, 0, sizeof(subflow->reset));\n\tsubflow->request_mptcp = 1;\n}\n\nstatic inline u64\nmptcp_subflow_get_map_offset(const struct mptcp_subflow_context *subflow)\n{\n\treturn tcp_sk(mptcp_subflow_tcp_sock(subflow))->copied_seq -\n\t\t      subflow->ssn_offset -\n\t\t      subflow->map_subflow_seq;\n}\n\nstatic inline u64\nmptcp_subflow_get_mapped_dsn(const struct mptcp_subflow_context *subflow)\n{\n\treturn subflow->map_seq + mptcp_subflow_get_map_offset(subflow);\n}\n\nvoid mptcp_subflow_process_delegated(struct sock *ssk, long actions);\n\nstatic inline void mptcp_subflow_delegate(struct mptcp_subflow_context *subflow, int action)\n{\n\tlong old, set_bits = BIT(MPTCP_DELEGATE_SCHEDULED) | BIT(action);\n\tstruct mptcp_delegated_action *delegated;\n\tbool schedule;\n\n\t \n\tlockdep_assert_in_softirq();\n\n\t \n\told = set_mask_bits(&subflow->delegated_status, 0, set_bits);\n\tif (!(old & BIT(MPTCP_DELEGATE_SCHEDULED))) {\n\t\tif (WARN_ON_ONCE(!list_empty(&subflow->delegated_node)))\n\t\t\treturn;\n\n\t\tdelegated = this_cpu_ptr(&mptcp_delegated_actions);\n\t\tschedule = list_empty(&delegated->head);\n\t\tlist_add_tail(&subflow->delegated_node, &delegated->head);\n\t\tsock_hold(mptcp_subflow_tcp_sock(subflow));\n\t\tif (schedule)\n\t\t\tnapi_schedule(&delegated->napi);\n\t}\n}\n\nstatic inline struct mptcp_subflow_context *\nmptcp_subflow_delegated_next(struct mptcp_delegated_action *delegated)\n{\n\tstruct mptcp_subflow_context *ret;\n\n\tif (list_empty(&delegated->head))\n\t\treturn NULL;\n\n\tret = list_first_entry(&delegated->head, struct mptcp_subflow_context, delegated_node);\n\tlist_del_init(&ret->delegated_node);\n\treturn ret;\n}\n\nint mptcp_is_enabled(const struct net *net);\nunsigned int mptcp_get_add_addr_timeout(const struct net *net);\nint mptcp_is_checksum_enabled(const struct net *net);\nint mptcp_allow_join_id0(const struct net *net);\nunsigned int mptcp_stale_loss_cnt(const struct net *net);\nint mptcp_get_pm_type(const struct net *net);\nconst char *mptcp_get_scheduler(const struct net *net);\nvoid mptcp_subflow_fully_established(struct mptcp_subflow_context *subflow,\n\t\t\t\t     const struct mptcp_options_received *mp_opt);\nbool __mptcp_retransmit_pending_data(struct sock *sk);\nvoid mptcp_check_and_set_pending(struct sock *sk);\nvoid __mptcp_push_pending(struct sock *sk, unsigned int flags);\nbool mptcp_subflow_data_available(struct sock *sk);\nvoid __init mptcp_subflow_init(void);\nvoid mptcp_subflow_shutdown(struct sock *sk, struct sock *ssk, int how);\nvoid mptcp_close_ssk(struct sock *sk, struct sock *ssk,\n\t\t     struct mptcp_subflow_context *subflow);\nvoid __mptcp_subflow_send_ack(struct sock *ssk);\nvoid mptcp_subflow_reset(struct sock *ssk);\nvoid mptcp_subflow_queue_clean(struct sock *sk, struct sock *ssk);\nvoid mptcp_sock_graft(struct sock *sk, struct socket *parent);\nstruct sock *__mptcp_nmpc_sk(struct mptcp_sock *msk);\nbool __mptcp_close(struct sock *sk, long timeout);\nvoid mptcp_cancel_work(struct sock *sk);\nvoid __mptcp_unaccepted_force_close(struct sock *sk);\nvoid mptcp_set_owner_r(struct sk_buff *skb, struct sock *sk);\n\nbool mptcp_addresses_equal(const struct mptcp_addr_info *a,\n\t\t\t   const struct mptcp_addr_info *b, bool use_port);\nvoid mptcp_local_address(const struct sock_common *skc, struct mptcp_addr_info *addr);\n\n \nint __mptcp_subflow_connect(struct sock *sk, const struct mptcp_addr_info *loc,\n\t\t\t    const struct mptcp_addr_info *remote);\nint mptcp_subflow_create_socket(struct sock *sk, unsigned short family,\n\t\t\t\tstruct socket **new_sock);\nvoid mptcp_info2sockaddr(const struct mptcp_addr_info *info,\n\t\t\t struct sockaddr_storage *addr,\n\t\t\t unsigned short family);\nstruct mptcp_sched_ops *mptcp_sched_find(const char *name);\nint mptcp_register_scheduler(struct mptcp_sched_ops *sched);\nvoid mptcp_unregister_scheduler(struct mptcp_sched_ops *sched);\nvoid mptcp_sched_init(void);\nint mptcp_init_sched(struct mptcp_sock *msk,\n\t\t     struct mptcp_sched_ops *sched);\nvoid mptcp_release_sched(struct mptcp_sock *msk);\nvoid mptcp_subflow_set_scheduled(struct mptcp_subflow_context *subflow,\n\t\t\t\t bool scheduled);\nstruct sock *mptcp_subflow_get_send(struct mptcp_sock *msk);\nstruct sock *mptcp_subflow_get_retrans(struct mptcp_sock *msk);\nint mptcp_sched_get_send(struct mptcp_sock *msk);\nint mptcp_sched_get_retrans(struct mptcp_sock *msk);\n\nstatic inline bool __tcp_can_send(const struct sock *ssk)\n{\n\t \n\treturn ((1 << inet_sk_state_load(ssk)) & (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT));\n}\n\nstatic inline bool __mptcp_subflow_active(struct mptcp_subflow_context *subflow)\n{\n\t \n\tif (subflow->request_join && !subflow->fully_established)\n\t\treturn false;\n\n\treturn __tcp_can_send(mptcp_subflow_tcp_sock(subflow));\n}\n\nvoid mptcp_subflow_set_active(struct mptcp_subflow_context *subflow);\n\nbool mptcp_subflow_active(struct mptcp_subflow_context *subflow);\n\nvoid mptcp_subflow_drop_ctx(struct sock *ssk);\n\nstatic inline void mptcp_subflow_tcp_fallback(struct sock *sk,\n\t\t\t\t\t      struct mptcp_subflow_context *ctx)\n{\n\tsk->sk_data_ready = sock_def_readable;\n\tsk->sk_state_change = ctx->tcp_state_change;\n\tsk->sk_write_space = sk_stream_write_space;\n\tsk->sk_error_report = ctx->tcp_error_report;\n\n\tinet_csk(sk)->icsk_af_ops = ctx->icsk_af_ops;\n}\n\nvoid __init mptcp_proto_init(void);\n#if IS_ENABLED(CONFIG_MPTCP_IPV6)\nint __init mptcp_proto_v6_init(void);\n#endif\n\nstruct sock *mptcp_sk_clone_init(const struct sock *sk,\n\t\t\t\t const struct mptcp_options_received *mp_opt,\n\t\t\t\t struct sock *ssk,\n\t\t\t\t struct request_sock *req);\nvoid mptcp_get_options(const struct sk_buff *skb,\n\t\t       struct mptcp_options_received *mp_opt);\n\nvoid mptcp_finish_connect(struct sock *sk);\nvoid __mptcp_sync_state(struct sock *sk, int state);\nvoid mptcp_reset_tout_timer(struct mptcp_sock *msk, unsigned long fail_tout);\n\nstatic inline void mptcp_stop_tout_timer(struct sock *sk)\n{\n\tif (!inet_csk(sk)->icsk_mtup.probe_timestamp)\n\t\treturn;\n\n\tsk_stop_timer(sk, &sk->sk_timer);\n\tinet_csk(sk)->icsk_mtup.probe_timestamp = 0;\n}\n\nstatic inline void mptcp_set_close_tout(struct sock *sk, unsigned long tout)\n{\n\t \n\tinet_csk(sk)->icsk_mtup.probe_timestamp = tout ? : 1;\n}\n\nstatic inline void mptcp_start_tout_timer(struct sock *sk)\n{\n\tmptcp_set_close_tout(sk, tcp_jiffies32);\n\tmptcp_reset_tout_timer(mptcp_sk(sk), 0);\n}\n\nstatic inline bool mptcp_is_fully_established(struct sock *sk)\n{\n\treturn inet_sk_state_load(sk) == TCP_ESTABLISHED &&\n\t       READ_ONCE(mptcp_sk(sk)->fully_established);\n}\nvoid mptcp_rcv_space_init(struct mptcp_sock *msk, const struct sock *ssk);\nvoid mptcp_data_ready(struct sock *sk, struct sock *ssk);\nbool mptcp_finish_join(struct sock *sk);\nbool mptcp_schedule_work(struct sock *sk);\nint mptcp_setsockopt(struct sock *sk, int level, int optname,\n\t\t     sockptr_t optval, unsigned int optlen);\nint mptcp_getsockopt(struct sock *sk, int level, int optname,\n\t\t     char __user *optval, int __user *option);\n\nu64 __mptcp_expand_seq(u64 old_seq, u64 cur_seq);\nstatic inline u64 mptcp_expand_seq(u64 old_seq, u64 cur_seq, bool use_64bit)\n{\n\tif (use_64bit)\n\t\treturn cur_seq;\n\n\treturn __mptcp_expand_seq(old_seq, cur_seq);\n}\nvoid __mptcp_check_push(struct sock *sk, struct sock *ssk);\nvoid __mptcp_data_acked(struct sock *sk);\nvoid __mptcp_error_report(struct sock *sk);\nbool mptcp_update_rcv_data_fin(struct mptcp_sock *msk, u64 data_fin_seq, bool use_64bit);\nstatic inline bool mptcp_data_fin_enabled(const struct mptcp_sock *msk)\n{\n\treturn READ_ONCE(msk->snd_data_fin_enable) &&\n\t       READ_ONCE(msk->write_seq) == READ_ONCE(msk->snd_nxt);\n}\n\nstatic inline void __mptcp_sync_sndbuf(struct sock *sk)\n{\n\tstruct mptcp_subflow_context *subflow;\n\tint ssk_sndbuf, new_sndbuf;\n\n\tif (sk->sk_userlocks & SOCK_SNDBUF_LOCK)\n\t\treturn;\n\n\tnew_sndbuf = sock_net(sk)->ipv4.sysctl_tcp_wmem[0];\n\tmptcp_for_each_subflow(mptcp_sk(sk), subflow) {\n\t\tssk_sndbuf =  READ_ONCE(mptcp_subflow_tcp_sock(subflow)->sk_sndbuf);\n\n\t\tsubflow->cached_sndbuf = ssk_sndbuf;\n\t\tnew_sndbuf += ssk_sndbuf;\n\t}\n\n\t \n\tWRITE_ONCE(sk->sk_sndbuf, new_sndbuf);\n}\n\n \nstatic inline void __mptcp_propagate_sndbuf(struct sock *sk, struct sock *ssk)\n{\n\tstruct mptcp_subflow_context *subflow = mptcp_subflow_ctx(ssk);\n\n\tif (READ_ONCE(ssk->sk_sndbuf) != subflow->cached_sndbuf)\n\t\t__mptcp_sync_sndbuf(sk);\n}\n\n \nstatic inline void mptcp_propagate_sndbuf(struct sock *sk, struct sock *ssk)\n{\n\tstruct mptcp_subflow_context *subflow = mptcp_subflow_ctx(ssk);\n\n\tif (likely(READ_ONCE(ssk->sk_sndbuf) == subflow->cached_sndbuf))\n\t\treturn;\n\n\tlocal_bh_disable();\n\tmptcp_subflow_delegate(subflow, MPTCP_DELEGATE_SNDBUF);\n\tlocal_bh_enable();\n}\n\nstatic inline void mptcp_write_space(struct sock *sk)\n{\n\tif (sk_stream_is_writeable(sk)) {\n\t\t \n\t\tsmp_mb();\n\t\tif (test_and_clear_bit(MPTCP_NOSPACE, &mptcp_sk(sk)->flags))\n\t\t\tsk_stream_write_space(sk);\n\t}\n}\n\nvoid mptcp_destroy_common(struct mptcp_sock *msk, unsigned int flags);\n\n#define MPTCP_TOKEN_MAX_RETRIES\t4\n\nvoid __init mptcp_token_init(void);\nstatic inline void mptcp_token_init_request(struct request_sock *req)\n{\n\tmptcp_subflow_rsk(req)->token_node.pprev = NULL;\n}\n\nint mptcp_token_new_request(struct request_sock *req);\nvoid mptcp_token_destroy_request(struct request_sock *req);\nint mptcp_token_new_connect(struct sock *ssk);\nvoid mptcp_token_accept(struct mptcp_subflow_request_sock *r,\n\t\t\tstruct mptcp_sock *msk);\nbool mptcp_token_exists(u32 token);\nstruct mptcp_sock *mptcp_token_get_sock(struct net *net, u32 token);\nstruct mptcp_sock *mptcp_token_iter_next(const struct net *net, long *s_slot,\n\t\t\t\t\t long *s_num);\nvoid mptcp_token_destroy(struct mptcp_sock *msk);\n\nvoid mptcp_crypto_key_sha(u64 key, u32 *token, u64 *idsn);\n\nvoid mptcp_crypto_hmac_sha(u64 key1, u64 key2, u8 *msg, int len, void *hmac);\n__sum16 __mptcp_make_csum(u64 data_seq, u32 subflow_seq, u16 data_len, __wsum sum);\n\nvoid __init mptcp_pm_init(void);\nvoid mptcp_pm_data_init(struct mptcp_sock *msk);\nvoid mptcp_pm_data_reset(struct mptcp_sock *msk);\nint mptcp_pm_parse_addr(struct nlattr *attr, struct genl_info *info,\n\t\t\tstruct mptcp_addr_info *addr);\nint mptcp_pm_parse_entry(struct nlattr *attr, struct genl_info *info,\n\t\t\t bool require_family,\n\t\t\t struct mptcp_pm_addr_entry *entry);\nbool mptcp_pm_addr_families_match(const struct sock *sk,\n\t\t\t\t  const struct mptcp_addr_info *loc,\n\t\t\t\t  const struct mptcp_addr_info *rem);\nvoid mptcp_pm_subflow_chk_stale(const struct mptcp_sock *msk, struct sock *ssk);\nvoid mptcp_pm_nl_subflow_chk_stale(const struct mptcp_sock *msk, struct sock *ssk);\nvoid mptcp_pm_new_connection(struct mptcp_sock *msk, const struct sock *ssk, int server_side);\nvoid mptcp_pm_fully_established(struct mptcp_sock *msk, const struct sock *ssk);\nbool mptcp_pm_allow_new_subflow(struct mptcp_sock *msk);\nvoid mptcp_pm_connection_closed(struct mptcp_sock *msk);\nvoid mptcp_pm_subflow_established(struct mptcp_sock *msk);\nbool mptcp_pm_nl_check_work_pending(struct mptcp_sock *msk);\nvoid mptcp_pm_subflow_check_next(struct mptcp_sock *msk, const struct sock *ssk,\n\t\t\t\t const struct mptcp_subflow_context *subflow);\nvoid mptcp_pm_add_addr_received(const struct sock *ssk,\n\t\t\t\tconst struct mptcp_addr_info *addr);\nvoid mptcp_pm_add_addr_echoed(struct mptcp_sock *msk,\n\t\t\t      const struct mptcp_addr_info *addr);\nvoid mptcp_pm_add_addr_send_ack(struct mptcp_sock *msk);\nvoid mptcp_pm_nl_addr_send_ack(struct mptcp_sock *msk);\nvoid mptcp_pm_rm_addr_received(struct mptcp_sock *msk,\n\t\t\t       const struct mptcp_rm_list *rm_list);\nvoid mptcp_pm_mp_prio_received(struct sock *sk, u8 bkup);\nvoid mptcp_pm_mp_fail_received(struct sock *sk, u64 fail_seq);\nint mptcp_pm_nl_mp_prio_send_ack(struct mptcp_sock *msk,\n\t\t\t\t struct mptcp_addr_info *addr,\n\t\t\t\t struct mptcp_addr_info *rem,\n\t\t\t\t u8 bkup);\nbool mptcp_pm_alloc_anno_list(struct mptcp_sock *msk,\n\t\t\t      const struct mptcp_addr_info *addr);\nvoid mptcp_pm_free_anno_list(struct mptcp_sock *msk);\nbool mptcp_pm_sport_in_anno_list(struct mptcp_sock *msk, const struct sock *sk);\nstruct mptcp_pm_add_entry *\nmptcp_pm_del_add_timer(struct mptcp_sock *msk,\n\t\t       const struct mptcp_addr_info *addr, bool check_id);\nstruct mptcp_pm_add_entry *\nmptcp_lookup_anno_list_by_saddr(const struct mptcp_sock *msk,\n\t\t\t\tconst struct mptcp_addr_info *addr);\nint mptcp_pm_get_flags_and_ifindex_by_id(struct mptcp_sock *msk,\n\t\t\t\t\t unsigned int id,\n\t\t\t\t\t u8 *flags, int *ifindex);\nint mptcp_pm_nl_get_flags_and_ifindex_by_id(struct mptcp_sock *msk, unsigned int id,\n\t\t\t\t\t    u8 *flags, int *ifindex);\nint mptcp_userspace_pm_get_flags_and_ifindex_by_id(struct mptcp_sock *msk,\n\t\t\t\t\t\t   unsigned int id,\n\t\t\t\t\t\t   u8 *flags, int *ifindex);\nint mptcp_pm_set_flags(struct net *net, struct nlattr *token,\n\t\t       struct mptcp_pm_addr_entry *loc,\n\t\t       struct mptcp_pm_addr_entry *rem, u8 bkup);\nint mptcp_pm_nl_set_flags(struct net *net, struct mptcp_pm_addr_entry *addr, u8 bkup);\nint mptcp_userspace_pm_set_flags(struct net *net, struct nlattr *token,\n\t\t\t\t struct mptcp_pm_addr_entry *loc,\n\t\t\t\t struct mptcp_pm_addr_entry *rem, u8 bkup);\nint mptcp_pm_announce_addr(struct mptcp_sock *msk,\n\t\t\t   const struct mptcp_addr_info *addr,\n\t\t\t   bool echo);\nint mptcp_pm_remove_addr(struct mptcp_sock *msk, const struct mptcp_rm_list *rm_list);\nint mptcp_pm_remove_subflow(struct mptcp_sock *msk, const struct mptcp_rm_list *rm_list);\nvoid mptcp_pm_remove_addrs(struct mptcp_sock *msk, struct list_head *rm_list);\nvoid mptcp_pm_remove_addrs_and_subflows(struct mptcp_sock *msk,\n\t\t\t\t\tstruct list_head *rm_list);\n\nvoid mptcp_free_local_addr_list(struct mptcp_sock *msk);\nint mptcp_nl_cmd_announce(struct sk_buff *skb, struct genl_info *info);\nint mptcp_nl_cmd_remove(struct sk_buff *skb, struct genl_info *info);\nint mptcp_nl_cmd_sf_create(struct sk_buff *skb, struct genl_info *info);\nint mptcp_nl_cmd_sf_destroy(struct sk_buff *skb, struct genl_info *info);\n\nvoid mptcp_event(enum mptcp_event_type type, const struct mptcp_sock *msk,\n\t\t const struct sock *ssk, gfp_t gfp);\nvoid mptcp_event_addr_announced(const struct sock *ssk, const struct mptcp_addr_info *info);\nvoid mptcp_event_addr_removed(const struct mptcp_sock *msk, u8 id);\nvoid mptcp_event_pm_listener(const struct sock *ssk,\n\t\t\t     enum mptcp_event_type event);\nbool mptcp_userspace_pm_active(const struct mptcp_sock *msk);\n\nvoid mptcp_fastopen_gen_msk_ackseq(struct mptcp_sock *msk, struct mptcp_subflow_context *subflow,\n\t\t\t\t   const struct mptcp_options_received *mp_opt);\nvoid mptcp_fastopen_subflow_synack_set_params(struct mptcp_subflow_context *subflow,\n\t\t\t\t\t      struct request_sock *req);\n\nstatic inline bool mptcp_pm_should_add_signal(struct mptcp_sock *msk)\n{\n\treturn READ_ONCE(msk->pm.addr_signal) &\n\t\t(BIT(MPTCP_ADD_ADDR_SIGNAL) | BIT(MPTCP_ADD_ADDR_ECHO));\n}\n\nstatic inline bool mptcp_pm_should_add_signal_addr(struct mptcp_sock *msk)\n{\n\treturn READ_ONCE(msk->pm.addr_signal) & BIT(MPTCP_ADD_ADDR_SIGNAL);\n}\n\nstatic inline bool mptcp_pm_should_add_signal_echo(struct mptcp_sock *msk)\n{\n\treturn READ_ONCE(msk->pm.addr_signal) & BIT(MPTCP_ADD_ADDR_ECHO);\n}\n\nstatic inline bool mptcp_pm_should_rm_signal(struct mptcp_sock *msk)\n{\n\treturn READ_ONCE(msk->pm.addr_signal) & BIT(MPTCP_RM_ADDR_SIGNAL);\n}\n\nstatic inline bool mptcp_pm_is_userspace(const struct mptcp_sock *msk)\n{\n\treturn READ_ONCE(msk->pm.pm_type) == MPTCP_PM_TYPE_USERSPACE;\n}\n\nstatic inline bool mptcp_pm_is_kernel(const struct mptcp_sock *msk)\n{\n\treturn READ_ONCE(msk->pm.pm_type) == MPTCP_PM_TYPE_KERNEL;\n}\n\nstatic inline unsigned int mptcp_add_addr_len(int family, bool echo, bool port)\n{\n\tu8 len = TCPOLEN_MPTCP_ADD_ADDR_BASE;\n\n\tif (family == AF_INET6)\n\t\tlen = TCPOLEN_MPTCP_ADD_ADDR6_BASE;\n\tif (!echo)\n\t\tlen += MPTCPOPT_THMAC_LEN;\n\t \n\tif (port)\n\t\tlen += TCPOLEN_MPTCP_PORT_LEN + TCPOLEN_MPTCP_PORT_ALIGN;\n\n\treturn len;\n}\n\nstatic inline int mptcp_rm_addr_len(const struct mptcp_rm_list *rm_list)\n{\n\tif (rm_list->nr == 0 || rm_list->nr > MPTCP_RM_IDS_MAX)\n\t\treturn -EINVAL;\n\n\treturn TCPOLEN_MPTCP_RM_ADDR_BASE + roundup(rm_list->nr - 1, 4) + 1;\n}\n\nbool mptcp_pm_add_addr_signal(struct mptcp_sock *msk, const struct sk_buff *skb,\n\t\t\t      unsigned int opt_size, unsigned int remaining,\n\t\t\t      struct mptcp_addr_info *addr, bool *echo,\n\t\t\t      bool *drop_other_suboptions);\nbool mptcp_pm_rm_addr_signal(struct mptcp_sock *msk, unsigned int remaining,\n\t\t\t     struct mptcp_rm_list *rm_list);\nint mptcp_pm_get_local_id(struct mptcp_sock *msk, struct sock_common *skc);\nint mptcp_pm_nl_get_local_id(struct mptcp_sock *msk, struct mptcp_addr_info *skc);\nint mptcp_userspace_pm_get_local_id(struct mptcp_sock *msk, struct mptcp_addr_info *skc);\n\nvoid __init mptcp_pm_nl_init(void);\nvoid mptcp_pm_nl_work(struct mptcp_sock *msk);\nvoid mptcp_pm_nl_rm_subflow_received(struct mptcp_sock *msk,\n\t\t\t\t     const struct mptcp_rm_list *rm_list);\nunsigned int mptcp_pm_get_add_addr_signal_max(const struct mptcp_sock *msk);\nunsigned int mptcp_pm_get_add_addr_accept_max(const struct mptcp_sock *msk);\nunsigned int mptcp_pm_get_subflows_max(const struct mptcp_sock *msk);\nunsigned int mptcp_pm_get_local_addr_max(const struct mptcp_sock *msk);\n\n \nstatic inline void __mptcp_pm_close_subflow(struct mptcp_sock *msk)\n{\n\tif (--msk->pm.subflows < mptcp_pm_get_subflows_max(msk))\n\t\tWRITE_ONCE(msk->pm.accept_subflow, true);\n}\n\nstatic inline void mptcp_pm_close_subflow(struct mptcp_sock *msk)\n{\n\tspin_lock_bh(&msk->pm.lock);\n\t__mptcp_pm_close_subflow(msk);\n\tspin_unlock_bh(&msk->pm.lock);\n}\n\nvoid mptcp_sockopt_sync(struct mptcp_sock *msk, struct sock *ssk);\nvoid mptcp_sockopt_sync_locked(struct mptcp_sock *msk, struct sock *ssk);\n\nstatic inline struct mptcp_ext *mptcp_get_ext(const struct sk_buff *skb)\n{\n\treturn (struct mptcp_ext *)skb_ext_find(skb, SKB_EXT_MPTCP);\n}\n\nvoid mptcp_diag_subflow_init(struct tcp_ulp_ops *ops);\n\nstatic inline bool __mptcp_check_fallback(const struct mptcp_sock *msk)\n{\n\treturn test_bit(MPTCP_FALLBACK_DONE, &msk->flags);\n}\n\nstatic inline bool mptcp_check_fallback(const struct sock *sk)\n{\n\tstruct mptcp_subflow_context *subflow = mptcp_subflow_ctx(sk);\n\tstruct mptcp_sock *msk = mptcp_sk(subflow->conn);\n\n\treturn __mptcp_check_fallback(msk);\n}\n\nstatic inline void __mptcp_do_fallback(struct mptcp_sock *msk)\n{\n\tif (test_bit(MPTCP_FALLBACK_DONE, &msk->flags)) {\n\t\tpr_debug(\"TCP fallback already done (msk=%p)\", msk);\n\t\treturn;\n\t}\n\tset_bit(MPTCP_FALLBACK_DONE, &msk->flags);\n}\n\nstatic inline void mptcp_do_fallback(struct sock *ssk)\n{\n\tstruct mptcp_subflow_context *subflow = mptcp_subflow_ctx(ssk);\n\tstruct sock *sk = subflow->conn;\n\tstruct mptcp_sock *msk;\n\n\tmsk = mptcp_sk(sk);\n\t__mptcp_do_fallback(msk);\n\tif (READ_ONCE(msk->snd_data_fin_enable) && !(ssk->sk_shutdown & SEND_SHUTDOWN)) {\n\t\tgfp_t saved_allocation = ssk->sk_allocation;\n\n\t\t \n\t\tssk->sk_allocation = GFP_ATOMIC;\n\t\tssk->sk_shutdown |= SEND_SHUTDOWN;\n\t\ttcp_shutdown(ssk, SEND_SHUTDOWN);\n\t\tssk->sk_allocation = saved_allocation;\n\t}\n}\n\n#define pr_fallback(a) pr_debug(\"%s:fallback to TCP (msk=%p)\", __func__, a)\n\nstatic inline bool mptcp_check_infinite_map(struct sk_buff *skb)\n{\n\tstruct mptcp_ext *mpext;\n\n\tmpext = skb ? mptcp_get_ext(skb) : NULL;\n\tif (mpext && mpext->infinite_map)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic inline bool is_active_ssk(struct mptcp_subflow_context *subflow)\n{\n\treturn (subflow->request_mptcp || subflow->request_join);\n}\n\nstatic inline bool subflow_simultaneous_connect(struct sock *sk)\n{\n\tstruct mptcp_subflow_context *subflow = mptcp_subflow_ctx(sk);\n\n\treturn (1 << sk->sk_state) & (TCPF_ESTABLISHED | TCPF_FIN_WAIT1) &&\n\t       is_active_ssk(subflow) &&\n\t       !subflow->conn_finished;\n}\n\n#ifdef CONFIG_SYN_COOKIES\nvoid subflow_init_req_cookie_join_save(const struct mptcp_subflow_request_sock *subflow_req,\n\t\t\t\t       struct sk_buff *skb);\nbool mptcp_token_join_cookie_init_state(struct mptcp_subflow_request_sock *subflow_req,\n\t\t\t\t\tstruct sk_buff *skb);\nvoid __init mptcp_join_cookie_init(void);\n#else\nstatic inline void\nsubflow_init_req_cookie_join_save(const struct mptcp_subflow_request_sock *subflow_req,\n\t\t\t\t  struct sk_buff *skb) {}\nstatic inline bool\nmptcp_token_join_cookie_init_state(struct mptcp_subflow_request_sock *subflow_req,\n\t\t\t\t   struct sk_buff *skb)\n{\n\treturn false;\n}\n\nstatic inline void mptcp_join_cookie_init(void) {}\n#endif\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}