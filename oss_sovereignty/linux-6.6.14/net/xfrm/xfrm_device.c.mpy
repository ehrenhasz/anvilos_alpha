{
  "module_name": "xfrm_device.c",
  "hash_id": "26527650ce696f542916d238eefc332da3d6ab39b2cd7648204e1166587f122a",
  "original_prompt": "Ingested from linux-6.6.14/net/xfrm/xfrm_device.c",
  "human_readable_source": "\n \n\n#include <linux/errno.h>\n#include <linux/module.h>\n#include <linux/netdevice.h>\n#include <linux/skbuff.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <net/dst.h>\n#include <net/gso.h>\n#include <net/xfrm.h>\n#include <linux/notifier.h>\n\n#ifdef CONFIG_XFRM_OFFLOAD\nstatic void __xfrm_transport_prep(struct xfrm_state *x, struct sk_buff *skb,\n\t\t\t\t  unsigned int hsize)\n{\n\tstruct xfrm_offload *xo = xfrm_offload(skb);\n\n\tskb_reset_mac_len(skb);\n\tif (xo->flags & XFRM_GSO_SEGMENT)\n\t\tskb->transport_header -= x->props.header_len;\n\n\tpskb_pull(skb, skb_transport_offset(skb) + x->props.header_len);\n}\n\nstatic void __xfrm_mode_tunnel_prep(struct xfrm_state *x, struct sk_buff *skb,\n\t\t\t\t    unsigned int hsize)\n\n{\n\tstruct xfrm_offload *xo = xfrm_offload(skb);\n\n\tif (xo->flags & XFRM_GSO_SEGMENT)\n\t\tskb->transport_header = skb->network_header + hsize;\n\n\tskb_reset_mac_len(skb);\n\tpskb_pull(skb, skb->mac_len + x->props.header_len);\n}\n\nstatic void __xfrm_mode_beet_prep(struct xfrm_state *x, struct sk_buff *skb,\n\t\t\t\t  unsigned int hsize)\n{\n\tstruct xfrm_offload *xo = xfrm_offload(skb);\n\tint phlen = 0;\n\n\tif (xo->flags & XFRM_GSO_SEGMENT)\n\t\tskb->transport_header = skb->network_header + hsize;\n\n\tskb_reset_mac_len(skb);\n\tif (x->sel.family != AF_INET6) {\n\t\tphlen = IPV4_BEET_PHMAXLEN;\n\t\tif (x->outer_mode.family == AF_INET6)\n\t\t\tphlen += sizeof(struct ipv6hdr) - sizeof(struct iphdr);\n\t}\n\n\tpskb_pull(skb, skb->mac_len + hsize + (x->props.header_len - phlen));\n}\n\n \nstatic void xfrm_outer_mode_prep(struct xfrm_state *x, struct sk_buff *skb)\n{\n\tswitch (x->outer_mode.encap) {\n\tcase XFRM_MODE_TUNNEL:\n\t\tif (x->outer_mode.family == AF_INET)\n\t\t\treturn __xfrm_mode_tunnel_prep(x, skb,\n\t\t\t\t\t\t       sizeof(struct iphdr));\n\t\tif (x->outer_mode.family == AF_INET6)\n\t\t\treturn __xfrm_mode_tunnel_prep(x, skb,\n\t\t\t\t\t\t       sizeof(struct ipv6hdr));\n\t\tbreak;\n\tcase XFRM_MODE_TRANSPORT:\n\t\tif (x->outer_mode.family == AF_INET)\n\t\t\treturn __xfrm_transport_prep(x, skb,\n\t\t\t\t\t\t     sizeof(struct iphdr));\n\t\tif (x->outer_mode.family == AF_INET6)\n\t\t\treturn __xfrm_transport_prep(x, skb,\n\t\t\t\t\t\t     sizeof(struct ipv6hdr));\n\t\tbreak;\n\tcase XFRM_MODE_BEET:\n\t\tif (x->outer_mode.family == AF_INET)\n\t\t\treturn __xfrm_mode_beet_prep(x, skb,\n\t\t\t\t\t\t     sizeof(struct iphdr));\n\t\tif (x->outer_mode.family == AF_INET6)\n\t\t\treturn __xfrm_mode_beet_prep(x, skb,\n\t\t\t\t\t\t     sizeof(struct ipv6hdr));\n\t\tbreak;\n\tcase XFRM_MODE_ROUTEOPTIMIZATION:\n\tcase XFRM_MODE_IN_TRIGGER:\n\t\tbreak;\n\t}\n}\n\nstatic inline bool xmit_xfrm_check_overflow(struct sk_buff *skb)\n{\n\tstruct xfrm_offload *xo = xfrm_offload(skb);\n\t__u32 seq = xo->seq.low;\n\n\tseq += skb_shinfo(skb)->gso_segs;\n\tif (unlikely(seq < xo->seq.low))\n\t\treturn true;\n\n\treturn false;\n}\n\nstruct sk_buff *validate_xmit_xfrm(struct sk_buff *skb, netdev_features_t features, bool *again)\n{\n\tint err;\n\tunsigned long flags;\n\tstruct xfrm_state *x;\n\tstruct softnet_data *sd;\n\tstruct sk_buff *skb2, *nskb, *pskb = NULL;\n\tnetdev_features_t esp_features = features;\n\tstruct xfrm_offload *xo = xfrm_offload(skb);\n\tstruct net_device *dev = skb->dev;\n\tstruct sec_path *sp;\n\n\tif (!xo || (xo->flags & XFRM_XMIT))\n\t\treturn skb;\n\n\tif (!(features & NETIF_F_HW_ESP))\n\t\tesp_features = features & ~(NETIF_F_SG | NETIF_F_CSUM_MASK);\n\n\tsp = skb_sec_path(skb);\n\tx = sp->xvec[sp->len - 1];\n\tif (xo->flags & XFRM_GRO || x->xso.dir == XFRM_DEV_OFFLOAD_IN)\n\t\treturn skb;\n\n\t \n\tif (x->xso.type == XFRM_DEV_OFFLOAD_PACKET && x->xso.dev != dev) {\n\t\tkfree_skb(skb);\n\t\tdev_core_stats_tx_dropped_inc(dev);\n\t\treturn NULL;\n\t}\n\n\t \n\tif ((x->xso.dev != dev) && (x->xso.real_dev == dev))\n\t\treturn skb;\n\n\tlocal_irq_save(flags);\n\tsd = this_cpu_ptr(&softnet_data);\n\terr = !skb_queue_empty(&sd->xfrm_backlog);\n\tlocal_irq_restore(flags);\n\n\tif (err) {\n\t\t*again = true;\n\t\treturn skb;\n\t}\n\n\tif (skb_is_gso(skb) && (unlikely(x->xso.dev != dev) ||\n\t\t\t\tunlikely(xmit_xfrm_check_overflow(skb)))) {\n\t\tstruct sk_buff *segs;\n\n\t\t \n\t\tesp_features = esp_features & ~(NETIF_F_HW_ESP | NETIF_F_GSO_ESP);\n\n\t\tsegs = skb_gso_segment(skb, esp_features);\n\t\tif (IS_ERR(segs)) {\n\t\t\tkfree_skb(skb);\n\t\t\tdev_core_stats_tx_dropped_inc(dev);\n\t\t\treturn NULL;\n\t\t} else {\n\t\t\tconsume_skb(skb);\n\t\t\tskb = segs;\n\t\t}\n\t}\n\n\tif (!skb->next) {\n\t\tesp_features |= skb->dev->gso_partial_features;\n\t\txfrm_outer_mode_prep(x, skb);\n\n\t\txo->flags |= XFRM_DEV_RESUME;\n\n\t\terr = x->type_offload->xmit(x, skb, esp_features);\n\t\tif (err) {\n\t\t\tif (err == -EINPROGRESS)\n\t\t\t\treturn NULL;\n\n\t\t\tXFRM_INC_STATS(xs_net(x), LINUX_MIB_XFRMOUTSTATEPROTOERROR);\n\t\t\tkfree_skb(skb);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tskb_push(skb, skb->data - skb_mac_header(skb));\n\n\t\treturn skb;\n\t}\n\n\tskb_list_walk_safe(skb, skb2, nskb) {\n\t\tesp_features |= skb->dev->gso_partial_features;\n\t\tskb_mark_not_on_list(skb2);\n\n\t\txo = xfrm_offload(skb2);\n\t\txo->flags |= XFRM_DEV_RESUME;\n\n\t\txfrm_outer_mode_prep(x, skb2);\n\n\t\terr = x->type_offload->xmit(x, skb2, esp_features);\n\t\tif (!err) {\n\t\t\tskb2->next = nskb;\n\t\t} else if (err != -EINPROGRESS) {\n\t\t\tXFRM_INC_STATS(xs_net(x), LINUX_MIB_XFRMOUTSTATEPROTOERROR);\n\t\t\tskb2->next = nskb;\n\t\t\tkfree_skb_list(skb2);\n\t\t\treturn NULL;\n\t\t} else {\n\t\t\tif (skb == skb2)\n\t\t\t\tskb = nskb;\n\t\t\telse\n\t\t\t\tpskb->next = nskb;\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tskb_push(skb2, skb2->data - skb_mac_header(skb2));\n\t\tpskb = skb2;\n\t}\n\n\treturn skb;\n}\nEXPORT_SYMBOL_GPL(validate_xmit_xfrm);\n\nint xfrm_dev_state_add(struct net *net, struct xfrm_state *x,\n\t\t       struct xfrm_user_offload *xuo,\n\t\t       struct netlink_ext_ack *extack)\n{\n\tint err;\n\tstruct dst_entry *dst;\n\tstruct net_device *dev;\n\tstruct xfrm_dev_offload *xso = &x->xso;\n\txfrm_address_t *saddr;\n\txfrm_address_t *daddr;\n\tbool is_packet_offload;\n\n\tif (!x->type_offload) {\n\t\tNL_SET_ERR_MSG(extack, \"Type doesn't support offload\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (xuo->flags &\n\t    ~(XFRM_OFFLOAD_IPV6 | XFRM_OFFLOAD_INBOUND | XFRM_OFFLOAD_PACKET)) {\n\t\tNL_SET_ERR_MSG(extack, \"Unrecognized flags in offload request\");\n\t\treturn -EINVAL;\n\t}\n\n\tis_packet_offload = xuo->flags & XFRM_OFFLOAD_PACKET;\n\n\t \n\tif ((!is_packet_offload && x->encap) || x->tfcpad) {\n\t\tNL_SET_ERR_MSG(extack, \"Encapsulation and TFC padding can't be offloaded\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev = dev_get_by_index(net, xuo->ifindex);\n\tif (!dev) {\n\t\tif (!(xuo->flags & XFRM_OFFLOAD_INBOUND)) {\n\t\t\tsaddr = &x->props.saddr;\n\t\t\tdaddr = &x->id.daddr;\n\t\t} else {\n\t\t\tsaddr = &x->id.daddr;\n\t\t\tdaddr = &x->props.saddr;\n\t\t}\n\n\t\tdst = __xfrm_dst_lookup(net, 0, 0, saddr, daddr,\n\t\t\t\t\tx->props.family,\n\t\t\t\t\txfrm_smark_get(0, x));\n\t\tif (IS_ERR(dst))\n\t\t\treturn (is_packet_offload) ? -EINVAL : 0;\n\n\t\tdev = dst->dev;\n\n\t\tdev_hold(dev);\n\t\tdst_release(dst);\n\t}\n\n\tif (!dev->xfrmdev_ops || !dev->xfrmdev_ops->xdo_dev_state_add) {\n\t\txso->dev = NULL;\n\t\tdev_put(dev);\n\t\treturn (is_packet_offload) ? -EINVAL : 0;\n\t}\n\n\tif (!is_packet_offload && x->props.flags & XFRM_STATE_ESN &&\n\t    !dev->xfrmdev_ops->xdo_dev_state_advance_esn) {\n\t\tNL_SET_ERR_MSG(extack, \"Device doesn't support offload with ESN\");\n\t\txso->dev = NULL;\n\t\tdev_put(dev);\n\t\treturn -EINVAL;\n\t}\n\n\txso->dev = dev;\n\tnetdev_tracker_alloc(dev, &xso->dev_tracker, GFP_ATOMIC);\n\txso->real_dev = dev;\n\n\tif (xuo->flags & XFRM_OFFLOAD_INBOUND)\n\t\txso->dir = XFRM_DEV_OFFLOAD_IN;\n\telse\n\t\txso->dir = XFRM_DEV_OFFLOAD_OUT;\n\n\tif (is_packet_offload)\n\t\txso->type = XFRM_DEV_OFFLOAD_PACKET;\n\telse\n\t\txso->type = XFRM_DEV_OFFLOAD_CRYPTO;\n\n\terr = dev->xfrmdev_ops->xdo_dev_state_add(x, extack);\n\tif (err) {\n\t\txso->dev = NULL;\n\t\txso->dir = 0;\n\t\txso->real_dev = NULL;\n\t\tnetdev_put(dev, &xso->dev_tracker);\n\t\txso->type = XFRM_DEV_OFFLOAD_UNSPECIFIED;\n\n\t\t \n\t\tWARN_ON(err == -EOPNOTSUPP && is_packet_offload);\n\t\tif (err != -EOPNOTSUPP || is_packet_offload) {\n\t\t\tNL_SET_ERR_MSG_WEAK(extack, \"Device failed to offload this state\");\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xfrm_dev_state_add);\n\nint xfrm_dev_policy_add(struct net *net, struct xfrm_policy *xp,\n\t\t\tstruct xfrm_user_offload *xuo, u8 dir,\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct xfrm_dev_offload *xdo = &xp->xdo;\n\tstruct net_device *dev;\n\tint err;\n\n\tif (!xuo->flags || xuo->flags & ~XFRM_OFFLOAD_PACKET) {\n\t\t \n\t\tNL_SET_ERR_MSG(extack, \"Unrecognized flags in offload request\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev = dev_get_by_index(net, xuo->ifindex);\n\tif (!dev)\n\t\treturn -EINVAL;\n\n\tif (!dev->xfrmdev_ops || !dev->xfrmdev_ops->xdo_dev_policy_add) {\n\t\txdo->dev = NULL;\n\t\tdev_put(dev);\n\t\tNL_SET_ERR_MSG(extack, \"Policy offload is not supported\");\n\t\treturn -EINVAL;\n\t}\n\n\txdo->dev = dev;\n\tnetdev_tracker_alloc(dev, &xdo->dev_tracker, GFP_ATOMIC);\n\txdo->real_dev = dev;\n\txdo->type = XFRM_DEV_OFFLOAD_PACKET;\n\tswitch (dir) {\n\tcase XFRM_POLICY_IN:\n\t\txdo->dir = XFRM_DEV_OFFLOAD_IN;\n\t\tbreak;\n\tcase XFRM_POLICY_OUT:\n\t\txdo->dir = XFRM_DEV_OFFLOAD_OUT;\n\t\tbreak;\n\tcase XFRM_POLICY_FWD:\n\t\txdo->dir = XFRM_DEV_OFFLOAD_FWD;\n\t\tbreak;\n\tdefault:\n\t\txdo->dev = NULL;\n\t\tnetdev_put(dev, &xdo->dev_tracker);\n\t\tNL_SET_ERR_MSG(extack, \"Unrecognized offload direction\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = dev->xfrmdev_ops->xdo_dev_policy_add(xp, extack);\n\tif (err) {\n\t\txdo->dev = NULL;\n\t\txdo->real_dev = NULL;\n\t\txdo->type = XFRM_DEV_OFFLOAD_UNSPECIFIED;\n\t\txdo->dir = 0;\n\t\tnetdev_put(dev, &xdo->dev_tracker);\n\t\tNL_SET_ERR_MSG_WEAK(extack, \"Device failed to offload this policy\");\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xfrm_dev_policy_add);\n\nbool xfrm_dev_offload_ok(struct sk_buff *skb, struct xfrm_state *x)\n{\n\tint mtu;\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct xfrm_dst *xdst = (struct xfrm_dst *)dst;\n\tstruct net_device *dev = x->xso.dev;\n\n\tif (!x->type_offload || x->encap)\n\t\treturn false;\n\n\tif (x->xso.type == XFRM_DEV_OFFLOAD_PACKET ||\n\t    ((!dev || (dev == xfrm_dst_path(dst)->dev)) &&\n\t     !xdst->child->xfrm)) {\n\t\tmtu = xfrm_state_mtu(x, xdst->child_mtu_cached);\n\t\tif (skb->len <= mtu)\n\t\t\tgoto ok;\n\n\t\tif (skb_is_gso(skb) && skb_gso_validate_network_len(skb, mtu))\n\t\t\tgoto ok;\n\t}\n\n\treturn false;\n\nok:\n\tif (dev && dev->xfrmdev_ops && dev->xfrmdev_ops->xdo_dev_offload_ok)\n\t\treturn x->xso.dev->xfrmdev_ops->xdo_dev_offload_ok(skb, x);\n\n\treturn true;\n}\nEXPORT_SYMBOL_GPL(xfrm_dev_offload_ok);\n\nvoid xfrm_dev_resume(struct sk_buff *skb)\n{\n\tstruct net_device *dev = skb->dev;\n\tint ret = NETDEV_TX_BUSY;\n\tstruct netdev_queue *txq;\n\tstruct softnet_data *sd;\n\tunsigned long flags;\n\n\trcu_read_lock();\n\ttxq = netdev_core_pick_tx(dev, skb, NULL);\n\n\tHARD_TX_LOCK(dev, txq, smp_processor_id());\n\tif (!netif_xmit_frozen_or_stopped(txq))\n\t\tskb = dev_hard_start_xmit(skb, dev, txq, &ret);\n\tHARD_TX_UNLOCK(dev, txq);\n\n\tif (!dev_xmit_complete(ret)) {\n\t\tlocal_irq_save(flags);\n\t\tsd = this_cpu_ptr(&softnet_data);\n\t\tskb_queue_tail(&sd->xfrm_backlog, skb);\n\t\traise_softirq_irqoff(NET_TX_SOFTIRQ);\n\t\tlocal_irq_restore(flags);\n\t}\n\trcu_read_unlock();\n}\nEXPORT_SYMBOL_GPL(xfrm_dev_resume);\n\nvoid xfrm_dev_backlog(struct softnet_data *sd)\n{\n\tstruct sk_buff_head *xfrm_backlog = &sd->xfrm_backlog;\n\tstruct sk_buff_head list;\n\tstruct sk_buff *skb;\n\n\tif (skb_queue_empty(xfrm_backlog))\n\t\treturn;\n\n\t__skb_queue_head_init(&list);\n\n\tspin_lock(&xfrm_backlog->lock);\n\tskb_queue_splice_init(xfrm_backlog, &list);\n\tspin_unlock(&xfrm_backlog->lock);\n\n\twhile (!skb_queue_empty(&list)) {\n\t\tskb = __skb_dequeue(&list);\n\t\txfrm_dev_resume(skb);\n\t}\n\n}\n#endif\n\nstatic int xfrm_api_check(struct net_device *dev)\n{\n#ifdef CONFIG_XFRM_OFFLOAD\n\tif ((dev->features & NETIF_F_HW_ESP_TX_CSUM) &&\n\t    !(dev->features & NETIF_F_HW_ESP))\n\t\treturn NOTIFY_BAD;\n\n\tif ((dev->features & NETIF_F_HW_ESP) &&\n\t    (!(dev->xfrmdev_ops &&\n\t       dev->xfrmdev_ops->xdo_dev_state_add &&\n\t       dev->xfrmdev_ops->xdo_dev_state_delete)))\n\t\treturn NOTIFY_BAD;\n#else\n\tif (dev->features & (NETIF_F_HW_ESP | NETIF_F_HW_ESP_TX_CSUM))\n\t\treturn NOTIFY_BAD;\n#endif\n\n\treturn NOTIFY_DONE;\n}\n\nstatic int xfrm_dev_down(struct net_device *dev)\n{\n\tif (dev->features & NETIF_F_HW_ESP) {\n\t\txfrm_dev_state_flush(dev_net(dev), dev, true);\n\t\txfrm_dev_policy_flush(dev_net(dev), dev, true);\n\t}\n\n\treturn NOTIFY_DONE;\n}\n\nstatic int xfrm_dev_event(struct notifier_block *this, unsigned long event, void *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\n\tswitch (event) {\n\tcase NETDEV_REGISTER:\n\t\treturn xfrm_api_check(dev);\n\n\tcase NETDEV_FEAT_CHANGE:\n\t\treturn xfrm_api_check(dev);\n\n\tcase NETDEV_DOWN:\n\tcase NETDEV_UNREGISTER:\n\t\treturn xfrm_dev_down(dev);\n\t}\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block xfrm_dev_notifier = {\n\t.notifier_call\t= xfrm_dev_event,\n};\n\nvoid __init xfrm_dev_init(void)\n{\n\tregister_netdevice_notifier(&xfrm_dev_notifier);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}