{
  "module_name": "sch_tbf.c",
  "hash_id": "7044101e7b97b1477cd5f503a9171078c9cb360068b2cc8a4052a93c8cd4fb8f",
  "original_prompt": "Ingested from linux-6.6.14/net/sched/sch_tbf.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include <linux/errno.h>\n#include <linux/skbuff.h>\n#include <net/gso.h>\n#include <net/netlink.h>\n#include <net/sch_generic.h>\n#include <net/pkt_cls.h>\n#include <net/pkt_sched.h>\n\n\n \n\nstruct tbf_sched_data {\n \n\tu32\t\tlimit;\t\t \n\tu32\t\tmax_size;\n\ts64\t\tbuffer;\t\t \n\ts64\t\tmtu;\n\tstruct psched_ratecfg rate;\n\tstruct psched_ratecfg peak;\n\n \n\ts64\ttokens;\t\t\t \n\ts64\tptokens;\t\t \n\ts64\tt_c;\t\t\t \n\tstruct Qdisc\t*qdisc;\t\t \n\tstruct qdisc_watchdog watchdog;\t \n};\n\n\n \nstatic u64 psched_ns_t2l(const struct psched_ratecfg *r,\n\t\t\t u64 time_in_ns)\n{\n\t \n\tu64 len = time_in_ns * r->rate_bytes_ps;\n\n\tdo_div(len, NSEC_PER_SEC);\n\n\tif (unlikely(r->linklayer == TC_LINKLAYER_ATM)) {\n\t\tdo_div(len, 53);\n\t\tlen = len * 48;\n\t}\n\n\tif (len > r->overhead)\n\t\tlen -= r->overhead;\n\telse\n\t\tlen = 0;\n\n\treturn len;\n}\n\nstatic void tbf_offload_change(struct Qdisc *sch)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\tstruct net_device *dev = qdisc_dev(sch);\n\tstruct tc_tbf_qopt_offload qopt;\n\n\tif (!tc_can_offload(dev) || !dev->netdev_ops->ndo_setup_tc)\n\t\treturn;\n\n\tqopt.command = TC_TBF_REPLACE;\n\tqopt.handle = sch->handle;\n\tqopt.parent = sch->parent;\n\tqopt.replace_params.rate = q->rate;\n\tqopt.replace_params.max_size = q->max_size;\n\tqopt.replace_params.qstats = &sch->qstats;\n\n\tdev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_QDISC_TBF, &qopt);\n}\n\nstatic void tbf_offload_destroy(struct Qdisc *sch)\n{\n\tstruct net_device *dev = qdisc_dev(sch);\n\tstruct tc_tbf_qopt_offload qopt;\n\n\tif (!tc_can_offload(dev) || !dev->netdev_ops->ndo_setup_tc)\n\t\treturn;\n\n\tqopt.command = TC_TBF_DESTROY;\n\tqopt.handle = sch->handle;\n\tqopt.parent = sch->parent;\n\tdev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_QDISC_TBF, &qopt);\n}\n\nstatic int tbf_offload_dump(struct Qdisc *sch)\n{\n\tstruct tc_tbf_qopt_offload qopt;\n\n\tqopt.command = TC_TBF_STATS;\n\tqopt.handle = sch->handle;\n\tqopt.parent = sch->parent;\n\tqopt.stats.bstats = &sch->bstats;\n\tqopt.stats.qstats = &sch->qstats;\n\n\treturn qdisc_offload_dump_helper(sch, TC_SETUP_QDISC_TBF, &qopt);\n}\n\nstatic void tbf_offload_graft(struct Qdisc *sch, struct Qdisc *new,\n\t\t\t      struct Qdisc *old, struct netlink_ext_ack *extack)\n{\n\tstruct tc_tbf_qopt_offload graft_offload = {\n\t\t.handle\t\t= sch->handle,\n\t\t.parent\t\t= sch->parent,\n\t\t.child_handle\t= new->handle,\n\t\t.command\t= TC_TBF_GRAFT,\n\t};\n\n\tqdisc_offload_graft_helper(qdisc_dev(sch), sch, new, old,\n\t\t\t\t   TC_SETUP_QDISC_TBF, &graft_offload, extack);\n}\n\n \nstatic int tbf_segment(struct sk_buff *skb, struct Qdisc *sch,\n\t\t       struct sk_buff **to_free)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\tstruct sk_buff *segs, *nskb;\n\tnetdev_features_t features = netif_skb_features(skb);\n\tunsigned int len = 0, prev_len = qdisc_pkt_len(skb);\n\tint ret, nb;\n\n\tsegs = skb_gso_segment(skb, features & ~NETIF_F_GSO_MASK);\n\n\tif (IS_ERR_OR_NULL(segs))\n\t\treturn qdisc_drop(skb, sch, to_free);\n\n\tnb = 0;\n\tskb_list_walk_safe(segs, segs, nskb) {\n\t\tskb_mark_not_on_list(segs);\n\t\tqdisc_skb_cb(segs)->pkt_len = segs->len;\n\t\tlen += segs->len;\n\t\tret = qdisc_enqueue(segs, q->qdisc, to_free);\n\t\tif (ret != NET_XMIT_SUCCESS) {\n\t\t\tif (net_xmit_drop_count(ret))\n\t\t\t\tqdisc_qstats_drop(sch);\n\t\t} else {\n\t\t\tnb++;\n\t\t}\n\t}\n\tsch->q.qlen += nb;\n\tif (nb > 1)\n\t\tqdisc_tree_reduce_backlog(sch, 1 - nb, prev_len - len);\n\tconsume_skb(skb);\n\treturn nb > 0 ? NET_XMIT_SUCCESS : NET_XMIT_DROP;\n}\n\nstatic int tbf_enqueue(struct sk_buff *skb, struct Qdisc *sch,\n\t\t       struct sk_buff **to_free)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\tunsigned int len = qdisc_pkt_len(skb);\n\tint ret;\n\n\tif (qdisc_pkt_len(skb) > q->max_size) {\n\t\tif (skb_is_gso(skb) &&\n\t\t    skb_gso_validate_mac_len(skb, q->max_size))\n\t\t\treturn tbf_segment(skb, sch, to_free);\n\t\treturn qdisc_drop(skb, sch, to_free);\n\t}\n\tret = qdisc_enqueue(skb, q->qdisc, to_free);\n\tif (ret != NET_XMIT_SUCCESS) {\n\t\tif (net_xmit_drop_count(ret))\n\t\t\tqdisc_qstats_drop(sch);\n\t\treturn ret;\n\t}\n\n\tsch->qstats.backlog += len;\n\tsch->q.qlen++;\n\treturn NET_XMIT_SUCCESS;\n}\n\nstatic bool tbf_peak_present(const struct tbf_sched_data *q)\n{\n\treturn q->peak.rate_bytes_ps;\n}\n\nstatic struct sk_buff *tbf_dequeue(struct Qdisc *sch)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\tstruct sk_buff *skb;\n\n\tskb = q->qdisc->ops->peek(q->qdisc);\n\n\tif (skb) {\n\t\ts64 now;\n\t\ts64 toks;\n\t\ts64 ptoks = 0;\n\t\tunsigned int len = qdisc_pkt_len(skb);\n\n\t\tnow = ktime_get_ns();\n\t\ttoks = min_t(s64, now - q->t_c, q->buffer);\n\n\t\tif (tbf_peak_present(q)) {\n\t\t\tptoks = toks + q->ptokens;\n\t\t\tif (ptoks > q->mtu)\n\t\t\t\tptoks = q->mtu;\n\t\t\tptoks -= (s64) psched_l2t_ns(&q->peak, len);\n\t\t}\n\t\ttoks += q->tokens;\n\t\tif (toks > q->buffer)\n\t\t\ttoks = q->buffer;\n\t\ttoks -= (s64) psched_l2t_ns(&q->rate, len);\n\n\t\tif ((toks|ptoks) >= 0) {\n\t\t\tskb = qdisc_dequeue_peeked(q->qdisc);\n\t\t\tif (unlikely(!skb))\n\t\t\t\treturn NULL;\n\n\t\t\tq->t_c = now;\n\t\t\tq->tokens = toks;\n\t\t\tq->ptokens = ptoks;\n\t\t\tqdisc_qstats_backlog_dec(sch, skb);\n\t\t\tsch->q.qlen--;\n\t\t\tqdisc_bstats_update(sch, skb);\n\t\t\treturn skb;\n\t\t}\n\n\t\tqdisc_watchdog_schedule_ns(&q->watchdog,\n\t\t\t\t\t   now + max_t(long, -toks, -ptoks));\n\n\t\t \n\n\t\tqdisc_qstats_overlimit(sch);\n\t}\n\treturn NULL;\n}\n\nstatic void tbf_reset(struct Qdisc *sch)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\n\tqdisc_reset(q->qdisc);\n\tq->t_c = ktime_get_ns();\n\tq->tokens = q->buffer;\n\tq->ptokens = q->mtu;\n\tqdisc_watchdog_cancel(&q->watchdog);\n}\n\nstatic const struct nla_policy tbf_policy[TCA_TBF_MAX + 1] = {\n\t[TCA_TBF_PARMS]\t= { .len = sizeof(struct tc_tbf_qopt) },\n\t[TCA_TBF_RTAB]\t= { .type = NLA_BINARY, .len = TC_RTAB_SIZE },\n\t[TCA_TBF_PTAB]\t= { .type = NLA_BINARY, .len = TC_RTAB_SIZE },\n\t[TCA_TBF_RATE64]\t= { .type = NLA_U64 },\n\t[TCA_TBF_PRATE64]\t= { .type = NLA_U64 },\n\t[TCA_TBF_BURST] = { .type = NLA_U32 },\n\t[TCA_TBF_PBURST] = { .type = NLA_U32 },\n};\n\nstatic int tbf_change(struct Qdisc *sch, struct nlattr *opt,\n\t\t      struct netlink_ext_ack *extack)\n{\n\tint err;\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\tstruct nlattr *tb[TCA_TBF_MAX + 1];\n\tstruct tc_tbf_qopt *qopt;\n\tstruct Qdisc *child = NULL;\n\tstruct Qdisc *old = NULL;\n\tstruct psched_ratecfg rate;\n\tstruct psched_ratecfg peak;\n\tu64 max_size;\n\ts64 buffer, mtu;\n\tu64 rate64 = 0, prate64 = 0;\n\n\terr = nla_parse_nested_deprecated(tb, TCA_TBF_MAX, opt, tbf_policy,\n\t\t\t\t\t  NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = -EINVAL;\n\tif (tb[TCA_TBF_PARMS] == NULL)\n\t\tgoto done;\n\n\tqopt = nla_data(tb[TCA_TBF_PARMS]);\n\tif (qopt->rate.linklayer == TC_LINKLAYER_UNAWARE)\n\t\tqdisc_put_rtab(qdisc_get_rtab(&qopt->rate,\n\t\t\t\t\t      tb[TCA_TBF_RTAB],\n\t\t\t\t\t      NULL));\n\n\tif (qopt->peakrate.linklayer == TC_LINKLAYER_UNAWARE)\n\t\t\tqdisc_put_rtab(qdisc_get_rtab(&qopt->peakrate,\n\t\t\t\t\t\t      tb[TCA_TBF_PTAB],\n\t\t\t\t\t\t      NULL));\n\n\tbuffer = min_t(u64, PSCHED_TICKS2NS(qopt->buffer), ~0U);\n\tmtu = min_t(u64, PSCHED_TICKS2NS(qopt->mtu), ~0U);\n\n\tif (tb[TCA_TBF_RATE64])\n\t\trate64 = nla_get_u64(tb[TCA_TBF_RATE64]);\n\tpsched_ratecfg_precompute(&rate, &qopt->rate, rate64);\n\n\tif (tb[TCA_TBF_BURST]) {\n\t\tmax_size = nla_get_u32(tb[TCA_TBF_BURST]);\n\t\tbuffer = psched_l2t_ns(&rate, max_size);\n\t} else {\n\t\tmax_size = min_t(u64, psched_ns_t2l(&rate, buffer), ~0U);\n\t}\n\n\tif (qopt->peakrate.rate) {\n\t\tif (tb[TCA_TBF_PRATE64])\n\t\t\tprate64 = nla_get_u64(tb[TCA_TBF_PRATE64]);\n\t\tpsched_ratecfg_precompute(&peak, &qopt->peakrate, prate64);\n\t\tif (peak.rate_bytes_ps <= rate.rate_bytes_ps) {\n\t\t\tpr_warn_ratelimited(\"sch_tbf: peakrate %llu is lower than or equals to rate %llu !\\n\",\n\t\t\t\t\tpeak.rate_bytes_ps, rate.rate_bytes_ps);\n\t\t\terr = -EINVAL;\n\t\t\tgoto done;\n\t\t}\n\n\t\tif (tb[TCA_TBF_PBURST]) {\n\t\t\tu32 pburst = nla_get_u32(tb[TCA_TBF_PBURST]);\n\t\t\tmax_size = min_t(u32, max_size, pburst);\n\t\t\tmtu = psched_l2t_ns(&peak, pburst);\n\t\t} else {\n\t\t\tmax_size = min_t(u64, max_size, psched_ns_t2l(&peak, mtu));\n\t\t}\n\t} else {\n\t\tmemset(&peak, 0, sizeof(peak));\n\t}\n\n\tif (max_size < psched_mtu(qdisc_dev(sch)))\n\t\tpr_warn_ratelimited(\"sch_tbf: burst %llu is lower than device %s mtu (%u) !\\n\",\n\t\t\t\t    max_size, qdisc_dev(sch)->name,\n\t\t\t\t    psched_mtu(qdisc_dev(sch)));\n\n\tif (!max_size) {\n\t\terr = -EINVAL;\n\t\tgoto done;\n\t}\n\n\tif (q->qdisc != &noop_qdisc) {\n\t\terr = fifo_set_limit(q->qdisc, qopt->limit);\n\t\tif (err)\n\t\t\tgoto done;\n\t} else if (qopt->limit > 0) {\n\t\tchild = fifo_create_dflt(sch, &bfifo_qdisc_ops, qopt->limit,\n\t\t\t\t\t extack);\n\t\tif (IS_ERR(child)) {\n\t\t\terr = PTR_ERR(child);\n\t\t\tgoto done;\n\t\t}\n\n\t\t \n\t\tqdisc_hash_add(child, true);\n\t}\n\n\tsch_tree_lock(sch);\n\tif (child) {\n\t\tqdisc_tree_flush_backlog(q->qdisc);\n\t\told = q->qdisc;\n\t\tq->qdisc = child;\n\t}\n\tq->limit = qopt->limit;\n\tif (tb[TCA_TBF_PBURST])\n\t\tq->mtu = mtu;\n\telse\n\t\tq->mtu = PSCHED_TICKS2NS(qopt->mtu);\n\tq->max_size = max_size;\n\tif (tb[TCA_TBF_BURST])\n\t\tq->buffer = buffer;\n\telse\n\t\tq->buffer = PSCHED_TICKS2NS(qopt->buffer);\n\tq->tokens = q->buffer;\n\tq->ptokens = q->mtu;\n\n\tmemcpy(&q->rate, &rate, sizeof(struct psched_ratecfg));\n\tmemcpy(&q->peak, &peak, sizeof(struct psched_ratecfg));\n\n\tsch_tree_unlock(sch);\n\tqdisc_put(old);\n\terr = 0;\n\n\ttbf_offload_change(sch);\ndone:\n\treturn err;\n}\n\nstatic int tbf_init(struct Qdisc *sch, struct nlattr *opt,\n\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\n\tqdisc_watchdog_init(&q->watchdog, sch);\n\tq->qdisc = &noop_qdisc;\n\n\tif (!opt)\n\t\treturn -EINVAL;\n\n\tq->t_c = ktime_get_ns();\n\n\treturn tbf_change(sch, opt, extack);\n}\n\nstatic void tbf_destroy(struct Qdisc *sch)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\n\tqdisc_watchdog_cancel(&q->watchdog);\n\ttbf_offload_destroy(sch);\n\tqdisc_put(q->qdisc);\n}\n\nstatic int tbf_dump(struct Qdisc *sch, struct sk_buff *skb)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\tstruct nlattr *nest;\n\tstruct tc_tbf_qopt opt;\n\tint err;\n\n\terr = tbf_offload_dump(sch);\n\tif (err)\n\t\treturn err;\n\n\tnest = nla_nest_start_noflag(skb, TCA_OPTIONS);\n\tif (nest == NULL)\n\t\tgoto nla_put_failure;\n\n\topt.limit = q->limit;\n\tpsched_ratecfg_getrate(&opt.rate, &q->rate);\n\tif (tbf_peak_present(q))\n\t\tpsched_ratecfg_getrate(&opt.peakrate, &q->peak);\n\telse\n\t\tmemset(&opt.peakrate, 0, sizeof(opt.peakrate));\n\topt.mtu = PSCHED_NS2TICKS(q->mtu);\n\topt.buffer = PSCHED_NS2TICKS(q->buffer);\n\tif (nla_put(skb, TCA_TBF_PARMS, sizeof(opt), &opt))\n\t\tgoto nla_put_failure;\n\tif (q->rate.rate_bytes_ps >= (1ULL << 32) &&\n\t    nla_put_u64_64bit(skb, TCA_TBF_RATE64, q->rate.rate_bytes_ps,\n\t\t\t      TCA_TBF_PAD))\n\t\tgoto nla_put_failure;\n\tif (tbf_peak_present(q) &&\n\t    q->peak.rate_bytes_ps >= (1ULL << 32) &&\n\t    nla_put_u64_64bit(skb, TCA_TBF_PRATE64, q->peak.rate_bytes_ps,\n\t\t\t      TCA_TBF_PAD))\n\t\tgoto nla_put_failure;\n\n\treturn nla_nest_end(skb, nest);\n\nnla_put_failure:\n\tnla_nest_cancel(skb, nest);\n\treturn -1;\n}\n\nstatic int tbf_dump_class(struct Qdisc *sch, unsigned long cl,\n\t\t\t  struct sk_buff *skb, struct tcmsg *tcm)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\n\ttcm->tcm_handle |= TC_H_MIN(1);\n\ttcm->tcm_info = q->qdisc->handle;\n\n\treturn 0;\n}\n\nstatic int tbf_graft(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,\n\t\t     struct Qdisc **old, struct netlink_ext_ack *extack)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\n\tif (new == NULL)\n\t\tnew = &noop_qdisc;\n\n\t*old = qdisc_replace(sch, new, &q->qdisc);\n\n\ttbf_offload_graft(sch, new, *old, extack);\n\treturn 0;\n}\n\nstatic struct Qdisc *tbf_leaf(struct Qdisc *sch, unsigned long arg)\n{\n\tstruct tbf_sched_data *q = qdisc_priv(sch);\n\treturn q->qdisc;\n}\n\nstatic unsigned long tbf_find(struct Qdisc *sch, u32 classid)\n{\n\treturn 1;\n}\n\nstatic void tbf_walk(struct Qdisc *sch, struct qdisc_walker *walker)\n{\n\tif (!walker->stop) {\n\t\ttc_qdisc_stats_dump(sch, 1, walker);\n\t}\n}\n\nstatic const struct Qdisc_class_ops tbf_class_ops = {\n\t.graft\t\t=\ttbf_graft,\n\t.leaf\t\t=\ttbf_leaf,\n\t.find\t\t=\ttbf_find,\n\t.walk\t\t=\ttbf_walk,\n\t.dump\t\t=\ttbf_dump_class,\n};\n\nstatic struct Qdisc_ops tbf_qdisc_ops __read_mostly = {\n\t.next\t\t=\tNULL,\n\t.cl_ops\t\t=\t&tbf_class_ops,\n\t.id\t\t=\t\"tbf\",\n\t.priv_size\t=\tsizeof(struct tbf_sched_data),\n\t.enqueue\t=\ttbf_enqueue,\n\t.dequeue\t=\ttbf_dequeue,\n\t.peek\t\t=\tqdisc_peek_dequeued,\n\t.init\t\t=\ttbf_init,\n\t.reset\t\t=\ttbf_reset,\n\t.destroy\t=\ttbf_destroy,\n\t.change\t\t=\ttbf_change,\n\t.dump\t\t=\ttbf_dump,\n\t.owner\t\t=\tTHIS_MODULE,\n};\n\nstatic int __init tbf_module_init(void)\n{\n\treturn register_qdisc(&tbf_qdisc_ops);\n}\n\nstatic void __exit tbf_module_exit(void)\n{\n\tunregister_qdisc(&tbf_qdisc_ops);\n}\nmodule_init(tbf_module_init)\nmodule_exit(tbf_module_exit)\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}