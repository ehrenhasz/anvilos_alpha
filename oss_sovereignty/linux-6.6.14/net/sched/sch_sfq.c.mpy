{
  "module_name": "sch_sfq.c",
  "hash_id": "890f678aca4075dbaa762d1a52c9342a446b669e7c89276d5431e857367cc7ed",
  "original_prompt": "Ingested from linux-6.6.14/net/sched/sch_sfq.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/jiffies.h>\n#include <linux/string.h>\n#include <linux/in.h>\n#include <linux/errno.h>\n#include <linux/init.h>\n#include <linux/skbuff.h>\n#include <linux/siphash.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <net/netlink.h>\n#include <net/pkt_sched.h>\n#include <net/pkt_cls.h>\n#include <net/red.h>\n\n\n \n\n#define SFQ_MAX_DEPTH\t\t127  \n#define SFQ_DEFAULT_FLOWS\t128\n#define SFQ_MAX_FLOWS\t\t(0x10000 - SFQ_MAX_DEPTH - 1)  \n#define SFQ_EMPTY_SLOT\t\t0xffff\n#define SFQ_DEFAULT_HASH_DIVISOR 1024\n\n \n#define SFQ_ALLOT_SHIFT\t\t3\n#define SFQ_ALLOT_SIZE(X)\tDIV_ROUND_UP(X, 1 << SFQ_ALLOT_SHIFT)\n\n \ntypedef u16 sfq_index;\n\n \nstruct sfq_head {\n\tsfq_index\tnext;\n\tsfq_index\tprev;\n};\n\nstruct sfq_slot {\n\tstruct sk_buff\t*skblist_next;\n\tstruct sk_buff\t*skblist_prev;\n\tsfq_index\tqlen;  \n\tsfq_index\tnext;  \n\tstruct sfq_head dep;  \n\tunsigned short\thash;  \n\tshort\t\tallot;  \n\n\tunsigned int    backlog;\n\tstruct red_vars vars;\n};\n\nstruct sfq_sched_data {\n \n\tint\t\tlimit;\t\t \n\tunsigned int\tdivisor;\t \n\tu8\t\theaddrop;\n\tu8\t\tmaxdepth;\t \n\n\tsiphash_key_t \tperturbation;\n\tu8\t\tcur_depth;\t \n\tu8\t\tflags;\n\tunsigned short  scaled_quantum;  \n\tstruct tcf_proto __rcu *filter_list;\n\tstruct tcf_block *block;\n\tsfq_index\t*ht;\t\t \n\tstruct sfq_slot\t*slots;\t\t \n\n\tstruct red_parms *red_parms;\n\tstruct tc_sfqred_stats stats;\n\tstruct sfq_slot *tail;\t\t \n\n\tstruct sfq_head\tdep[SFQ_MAX_DEPTH + 1];\n\t\t\t\t\t \n\n\tunsigned int\tmaxflows;\t \n\tint\t\tperturb_period;\n\tunsigned int\tquantum;\t \n\tstruct timer_list perturb_timer;\n\tstruct Qdisc\t*sch;\n};\n\n \nstatic inline struct sfq_head *sfq_dep_head(struct sfq_sched_data *q, sfq_index val)\n{\n\tif (val < SFQ_MAX_FLOWS)\n\t\treturn &q->slots[val].dep;\n\treturn &q->dep[val - SFQ_MAX_FLOWS];\n}\n\nstatic unsigned int sfq_hash(const struct sfq_sched_data *q,\n\t\t\t     const struct sk_buff *skb)\n{\n\treturn skb_get_hash_perturb(skb, &q->perturbation) & (q->divisor - 1);\n}\n\nstatic unsigned int sfq_classify(struct sk_buff *skb, struct Qdisc *sch,\n\t\t\t\t int *qerr)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\tstruct tcf_result res;\n\tstruct tcf_proto *fl;\n\tint result;\n\n\tif (TC_H_MAJ(skb->priority) == sch->handle &&\n\t    TC_H_MIN(skb->priority) > 0 &&\n\t    TC_H_MIN(skb->priority) <= q->divisor)\n\t\treturn TC_H_MIN(skb->priority);\n\n\tfl = rcu_dereference_bh(q->filter_list);\n\tif (!fl)\n\t\treturn sfq_hash(q, skb) + 1;\n\n\t*qerr = NET_XMIT_SUCCESS | __NET_XMIT_BYPASS;\n\tresult = tcf_classify(skb, NULL, fl, &res, false);\n\tif (result >= 0) {\n#ifdef CONFIG_NET_CLS_ACT\n\t\tswitch (result) {\n\t\tcase TC_ACT_STOLEN:\n\t\tcase TC_ACT_QUEUED:\n\t\tcase TC_ACT_TRAP:\n\t\t\t*qerr = NET_XMIT_SUCCESS | __NET_XMIT_STOLEN;\n\t\t\tfallthrough;\n\t\tcase TC_ACT_SHOT:\n\t\t\treturn 0;\n\t\t}\n#endif\n\t\tif (TC_H_MIN(res.classid) <= q->divisor)\n\t\t\treturn TC_H_MIN(res.classid);\n\t}\n\treturn 0;\n}\n\n \nstatic inline void sfq_link(struct sfq_sched_data *q, sfq_index x)\n{\n\tsfq_index p, n;\n\tstruct sfq_slot *slot = &q->slots[x];\n\tint qlen = slot->qlen;\n\n\tp = qlen + SFQ_MAX_FLOWS;\n\tn = q->dep[qlen].next;\n\n\tslot->dep.next = n;\n\tslot->dep.prev = p;\n\n\tq->dep[qlen].next = x;\t\t \n\tsfq_dep_head(q, n)->prev = x;\n}\n\n#define sfq_unlink(q, x, n, p)\t\t\t\\\n\tdo {\t\t\t\t\t\\\n\t\tn = q->slots[x].dep.next;\t\\\n\t\tp = q->slots[x].dep.prev;\t\\\n\t\tsfq_dep_head(q, p)->next = n;\t\\\n\t\tsfq_dep_head(q, n)->prev = p;\t\\\n\t} while (0)\n\n\nstatic inline void sfq_dec(struct sfq_sched_data *q, sfq_index x)\n{\n\tsfq_index p, n;\n\tint d;\n\n\tsfq_unlink(q, x, n, p);\n\n\td = q->slots[x].qlen--;\n\tif (n == p && q->cur_depth == d)\n\t\tq->cur_depth--;\n\tsfq_link(q, x);\n}\n\nstatic inline void sfq_inc(struct sfq_sched_data *q, sfq_index x)\n{\n\tsfq_index p, n;\n\tint d;\n\n\tsfq_unlink(q, x, n, p);\n\n\td = ++q->slots[x].qlen;\n\tif (q->cur_depth < d)\n\t\tq->cur_depth = d;\n\tsfq_link(q, x);\n}\n\n \n\n \nstatic inline struct sk_buff *slot_dequeue_tail(struct sfq_slot *slot)\n{\n\tstruct sk_buff *skb = slot->skblist_prev;\n\n\tslot->skblist_prev = skb->prev;\n\tskb->prev->next = (struct sk_buff *)slot;\n\tskb->next = skb->prev = NULL;\n\treturn skb;\n}\n\n \nstatic inline struct sk_buff *slot_dequeue_head(struct sfq_slot *slot)\n{\n\tstruct sk_buff *skb = slot->skblist_next;\n\n\tslot->skblist_next = skb->next;\n\tskb->next->prev = (struct sk_buff *)slot;\n\tskb->next = skb->prev = NULL;\n\treturn skb;\n}\n\nstatic inline void slot_queue_init(struct sfq_slot *slot)\n{\n\tmemset(slot, 0, sizeof(*slot));\n\tslot->skblist_prev = slot->skblist_next = (struct sk_buff *)slot;\n}\n\n \nstatic inline void slot_queue_add(struct sfq_slot *slot, struct sk_buff *skb)\n{\n\tskb->prev = slot->skblist_prev;\n\tskb->next = (struct sk_buff *)slot;\n\tslot->skblist_prev->next = skb;\n\tslot->skblist_prev = skb;\n}\n\nstatic unsigned int sfq_drop(struct Qdisc *sch, struct sk_buff **to_free)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\tsfq_index x, d = q->cur_depth;\n\tstruct sk_buff *skb;\n\tunsigned int len;\n\tstruct sfq_slot *slot;\n\n\t \n\tif (d > 1) {\n\t\tx = q->dep[d].next;\n\t\tslot = &q->slots[x];\ndrop:\n\t\tskb = q->headdrop ? slot_dequeue_head(slot) : slot_dequeue_tail(slot);\n\t\tlen = qdisc_pkt_len(skb);\n\t\tslot->backlog -= len;\n\t\tsfq_dec(q, x);\n\t\tsch->q.qlen--;\n\t\tqdisc_qstats_backlog_dec(sch, skb);\n\t\tqdisc_drop(skb, sch, to_free);\n\t\treturn len;\n\t}\n\n\tif (d == 1) {\n\t\t \n\t\tx = q->tail->next;\n\t\tslot = &q->slots[x];\n\t\tq->tail->next = slot->next;\n\t\tq->ht[slot->hash] = SFQ_EMPTY_SLOT;\n\t\tgoto drop;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int sfq_prob_mark(const struct sfq_sched_data *q)\n{\n\treturn q->flags & TC_RED_ECN;\n}\n\n \nstatic int sfq_hard_mark(const struct sfq_sched_data *q)\n{\n\treturn (q->flags & (TC_RED_ECN | TC_RED_HARDDROP)) == TC_RED_ECN;\n}\n\nstatic int sfq_headdrop(const struct sfq_sched_data *q)\n{\n\treturn q->headdrop;\n}\n\nstatic int\nsfq_enqueue(struct sk_buff *skb, struct Qdisc *sch, struct sk_buff **to_free)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\tunsigned int hash, dropped;\n\tsfq_index x, qlen;\n\tstruct sfq_slot *slot;\n\tint ret;\n\tstruct sk_buff *head;\n\tint delta;\n\n\thash = sfq_classify(skb, sch, &ret);\n\tif (hash == 0) {\n\t\tif (ret & __NET_XMIT_BYPASS)\n\t\t\tqdisc_qstats_drop(sch);\n\t\t__qdisc_drop(skb, to_free);\n\t\treturn ret;\n\t}\n\thash--;\n\n\tx = q->ht[hash];\n\tslot = &q->slots[x];\n\tif (x == SFQ_EMPTY_SLOT) {\n\t\tx = q->dep[0].next;  \n\t\tif (x >= SFQ_MAX_FLOWS)\n\t\t\treturn qdisc_drop(skb, sch, to_free);\n\t\tq->ht[hash] = x;\n\t\tslot = &q->slots[x];\n\t\tslot->hash = hash;\n\t\tslot->backlog = 0;  \n\t\tred_set_vars(&slot->vars);\n\t\tgoto enqueue;\n\t}\n\tif (q->red_parms) {\n\t\tslot->vars.qavg = red_calc_qavg_no_idle_time(q->red_parms,\n\t\t\t\t\t\t\t&slot->vars,\n\t\t\t\t\t\t\tslot->backlog);\n\t\tswitch (red_action(q->red_parms,\n\t\t\t\t   &slot->vars,\n\t\t\t\t   slot->vars.qavg)) {\n\t\tcase RED_DONT_MARK:\n\t\t\tbreak;\n\n\t\tcase RED_PROB_MARK:\n\t\t\tqdisc_qstats_overlimit(sch);\n\t\t\tif (sfq_prob_mark(q)) {\n\t\t\t\t \n\t\t\t\tif (sfq_headdrop(q) &&\n\t\t\t\t    INET_ECN_set_ce(slot->skblist_next)) {\n\t\t\t\t\tq->stats.prob_mark_head++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (INET_ECN_set_ce(skb)) {\n\t\t\t\t\tq->stats.prob_mark++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tq->stats.prob_drop++;\n\t\t\tgoto congestion_drop;\n\n\t\tcase RED_HARD_MARK:\n\t\t\tqdisc_qstats_overlimit(sch);\n\t\t\tif (sfq_hard_mark(q)) {\n\t\t\t\t \n\t\t\t\tif (sfq_headdrop(q) &&\n\t\t\t\t    INET_ECN_set_ce(slot->skblist_next)) {\n\t\t\t\t\tq->stats.forced_mark_head++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (INET_ECN_set_ce(skb)) {\n\t\t\t\t\tq->stats.forced_mark++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tq->stats.forced_drop++;\n\t\t\tgoto congestion_drop;\n\t\t}\n\t}\n\n\tif (slot->qlen >= q->maxdepth) {\ncongestion_drop:\n\t\tif (!sfq_headdrop(q))\n\t\t\treturn qdisc_drop(skb, sch, to_free);\n\n\t\t \n\t\thead = slot_dequeue_head(slot);\n\t\tdelta = qdisc_pkt_len(head) - qdisc_pkt_len(skb);\n\t\tsch->qstats.backlog -= delta;\n\t\tslot->backlog -= delta;\n\t\tqdisc_drop(head, sch, to_free);\n\n\t\tslot_queue_add(slot, skb);\n\t\tqdisc_tree_reduce_backlog(sch, 0, delta);\n\t\treturn NET_XMIT_CN;\n\t}\n\nenqueue:\n\tqdisc_qstats_backlog_inc(sch, skb);\n\tslot->backlog += qdisc_pkt_len(skb);\n\tslot_queue_add(slot, skb);\n\tsfq_inc(q, x);\n\tif (slot->qlen == 1) {\t\t \n\t\tif (q->tail == NULL) {\t \n\t\t\tslot->next = x;\n\t\t} else {\n\t\t\tslot->next = q->tail->next;\n\t\t\tq->tail->next = x;\n\t\t}\n\t\t \n\t\tq->tail = slot;\n\t\t \n\t\tslot->allot = q->scaled_quantum;\n\t}\n\tif (++sch->q.qlen <= q->limit)\n\t\treturn NET_XMIT_SUCCESS;\n\n\tqlen = slot->qlen;\n\tdropped = sfq_drop(sch, to_free);\n\t \n\tif (qlen != slot->qlen) {\n\t\tqdisc_tree_reduce_backlog(sch, 0, dropped - qdisc_pkt_len(skb));\n\t\treturn NET_XMIT_CN;\n\t}\n\n\t \n\tqdisc_tree_reduce_backlog(sch, 1, dropped);\n\treturn NET_XMIT_SUCCESS;\n}\n\nstatic struct sk_buff *\nsfq_dequeue(struct Qdisc *sch)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\tstruct sk_buff *skb;\n\tsfq_index a, next_a;\n\tstruct sfq_slot *slot;\n\n\t \n\tif (q->tail == NULL)\n\t\treturn NULL;\n\nnext_slot:\n\ta = q->tail->next;\n\tslot = &q->slots[a];\n\tif (slot->allot <= 0) {\n\t\tq->tail = slot;\n\t\tslot->allot += q->scaled_quantum;\n\t\tgoto next_slot;\n\t}\n\tskb = slot_dequeue_head(slot);\n\tsfq_dec(q, a);\n\tqdisc_bstats_update(sch, skb);\n\tsch->q.qlen--;\n\tqdisc_qstats_backlog_dec(sch, skb);\n\tslot->backlog -= qdisc_pkt_len(skb);\n\t \n\tif (slot->qlen == 0) {\n\t\tq->ht[slot->hash] = SFQ_EMPTY_SLOT;\n\t\tnext_a = slot->next;\n\t\tif (a == next_a) {\n\t\t\tq->tail = NULL;  \n\t\t\treturn skb;\n\t\t}\n\t\tq->tail->next = next_a;\n\t} else {\n\t\tslot->allot -= SFQ_ALLOT_SIZE(qdisc_pkt_len(skb));\n\t}\n\treturn skb;\n}\n\nstatic void\nsfq_reset(struct Qdisc *sch)\n{\n\tstruct sk_buff *skb;\n\n\twhile ((skb = sfq_dequeue(sch)) != NULL)\n\t\trtnl_kfree_skbs(skb, skb);\n}\n\n \nstatic void sfq_rehash(struct Qdisc *sch)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\tstruct sk_buff *skb;\n\tint i;\n\tstruct sfq_slot *slot;\n\tstruct sk_buff_head list;\n\tint dropped = 0;\n\tunsigned int drop_len = 0;\n\n\t__skb_queue_head_init(&list);\n\n\tfor (i = 0; i < q->maxflows; i++) {\n\t\tslot = &q->slots[i];\n\t\tif (!slot->qlen)\n\t\t\tcontinue;\n\t\twhile (slot->qlen) {\n\t\t\tskb = slot_dequeue_head(slot);\n\t\t\tsfq_dec(q, i);\n\t\t\t__skb_queue_tail(&list, skb);\n\t\t}\n\t\tslot->backlog = 0;\n\t\tred_set_vars(&slot->vars);\n\t\tq->ht[slot->hash] = SFQ_EMPTY_SLOT;\n\t}\n\tq->tail = NULL;\n\n\twhile ((skb = __skb_dequeue(&list)) != NULL) {\n\t\tunsigned int hash = sfq_hash(q, skb);\n\t\tsfq_index x = q->ht[hash];\n\n\t\tslot = &q->slots[x];\n\t\tif (x == SFQ_EMPTY_SLOT) {\n\t\t\tx = q->dep[0].next;  \n\t\t\tif (x >= SFQ_MAX_FLOWS) {\ndrop:\n\t\t\t\tqdisc_qstats_backlog_dec(sch, skb);\n\t\t\t\tdrop_len += qdisc_pkt_len(skb);\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tdropped++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tq->ht[hash] = x;\n\t\t\tslot = &q->slots[x];\n\t\t\tslot->hash = hash;\n\t\t}\n\t\tif (slot->qlen >= q->maxdepth)\n\t\t\tgoto drop;\n\t\tslot_queue_add(slot, skb);\n\t\tif (q->red_parms)\n\t\t\tslot->vars.qavg = red_calc_qavg(q->red_parms,\n\t\t\t\t\t\t\t&slot->vars,\n\t\t\t\t\t\t\tslot->backlog);\n\t\tslot->backlog += qdisc_pkt_len(skb);\n\t\tsfq_inc(q, x);\n\t\tif (slot->qlen == 1) {\t\t \n\t\t\tif (q->tail == NULL) {\t \n\t\t\t\tslot->next = x;\n\t\t\t} else {\n\t\t\t\tslot->next = q->tail->next;\n\t\t\t\tq->tail->next = x;\n\t\t\t}\n\t\t\tq->tail = slot;\n\t\t\tslot->allot = q->scaled_quantum;\n\t\t}\n\t}\n\tsch->q.qlen -= dropped;\n\tqdisc_tree_reduce_backlog(sch, dropped, drop_len);\n}\n\nstatic void sfq_perturbation(struct timer_list *t)\n{\n\tstruct sfq_sched_data *q = from_timer(q, t, perturb_timer);\n\tstruct Qdisc *sch = q->sch;\n\tspinlock_t *root_lock;\n\tsiphash_key_t nkey;\n\n\tget_random_bytes(&nkey, sizeof(nkey));\n\trcu_read_lock();\n\troot_lock = qdisc_lock(qdisc_root_sleeping(sch));\n\tspin_lock(root_lock);\n\tq->perturbation = nkey;\n\tif (!q->filter_list && q->tail)\n\t\tsfq_rehash(sch);\n\tspin_unlock(root_lock);\n\n\tif (q->perturb_period)\n\t\tmod_timer(&q->perturb_timer, jiffies + q->perturb_period);\n\trcu_read_unlock();\n}\n\nstatic int sfq_change(struct Qdisc *sch, struct nlattr *opt)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\tstruct tc_sfq_qopt *ctl = nla_data(opt);\n\tstruct tc_sfq_qopt_v1 *ctl_v1 = NULL;\n\tunsigned int qlen, dropped = 0;\n\tstruct red_parms *p = NULL;\n\tstruct sk_buff *to_free = NULL;\n\tstruct sk_buff *tail = NULL;\n\n\tif (opt->nla_len < nla_attr_size(sizeof(*ctl)))\n\t\treturn -EINVAL;\n\tif (opt->nla_len >= nla_attr_size(sizeof(*ctl_v1)))\n\t\tctl_v1 = nla_data(opt);\n\tif (ctl->divisor &&\n\t    (!is_power_of_2(ctl->divisor) || ctl->divisor > 65536))\n\t\treturn -EINVAL;\n\n\t \n\tif (ctl->quantum) {\n\t\tunsigned int scaled = SFQ_ALLOT_SIZE(ctl->quantum);\n\n\t\tif (scaled <= 0 || scaled > SHRT_MAX)\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (ctl_v1 && !red_check_params(ctl_v1->qth_min, ctl_v1->qth_max,\n\t\t\t\t\tctl_v1->Wlog, ctl_v1->Scell_log, NULL))\n\t\treturn -EINVAL;\n\tif (ctl_v1 && ctl_v1->qth_min) {\n\t\tp = kmalloc(sizeof(*p), GFP_KERNEL);\n\t\tif (!p)\n\t\t\treturn -ENOMEM;\n\t}\n\tsch_tree_lock(sch);\n\tif (ctl->quantum) {\n\t\tq->quantum = ctl->quantum;\n\t\tq->scaled_quantum = SFQ_ALLOT_SIZE(q->quantum);\n\t}\n\tq->perturb_period = ctl->perturb_period * HZ;\n\tif (ctl->flows)\n\t\tq->maxflows = min_t(u32, ctl->flows, SFQ_MAX_FLOWS);\n\tif (ctl->divisor) {\n\t\tq->divisor = ctl->divisor;\n\t\tq->maxflows = min_t(u32, q->maxflows, q->divisor);\n\t}\n\tif (ctl_v1) {\n\t\tif (ctl_v1->depth)\n\t\t\tq->maxdepth = min_t(u32, ctl_v1->depth, SFQ_MAX_DEPTH);\n\t\tif (p) {\n\t\t\tswap(q->red_parms, p);\n\t\t\tred_set_parms(q->red_parms,\n\t\t\t\t      ctl_v1->qth_min, ctl_v1->qth_max,\n\t\t\t\t      ctl_v1->Wlog,\n\t\t\t\t      ctl_v1->Plog, ctl_v1->Scell_log,\n\t\t\t\t      NULL,\n\t\t\t\t      ctl_v1->max_P);\n\t\t}\n\t\tq->flags = ctl_v1->flags;\n\t\tq->headdrop = ctl_v1->headdrop;\n\t}\n\tif (ctl->limit) {\n\t\tq->limit = min_t(u32, ctl->limit, q->maxdepth * q->maxflows);\n\t\tq->maxflows = min_t(u32, q->maxflows, q->limit);\n\t}\n\n\tqlen = sch->q.qlen;\n\twhile (sch->q.qlen > q->limit) {\n\t\tdropped += sfq_drop(sch, &to_free);\n\t\tif (!tail)\n\t\t\ttail = to_free;\n\t}\n\n\trtnl_kfree_skbs(to_free, tail);\n\tqdisc_tree_reduce_backlog(sch, qlen - sch->q.qlen, dropped);\n\n\tdel_timer(&q->perturb_timer);\n\tif (q->perturb_period) {\n\t\tmod_timer(&q->perturb_timer, jiffies + q->perturb_period);\n\t\tget_random_bytes(&q->perturbation, sizeof(q->perturbation));\n\t}\n\tsch_tree_unlock(sch);\n\tkfree(p);\n\treturn 0;\n}\n\nstatic void *sfq_alloc(size_t sz)\n{\n\treturn  kvmalloc(sz, GFP_KERNEL);\n}\n\nstatic void sfq_free(void *addr)\n{\n\tkvfree(addr);\n}\n\nstatic void sfq_destroy(struct Qdisc *sch)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\n\ttcf_block_put(q->block);\n\tq->perturb_period = 0;\n\tdel_timer_sync(&q->perturb_timer);\n\tsfq_free(q->ht);\n\tsfq_free(q->slots);\n\tkfree(q->red_parms);\n}\n\nstatic int sfq_init(struct Qdisc *sch, struct nlattr *opt,\n\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\tint i;\n\tint err;\n\n\tq->sch = sch;\n\ttimer_setup(&q->perturb_timer, sfq_perturbation, TIMER_DEFERRABLE);\n\n\terr = tcf_block_get(&q->block, &q->filter_list, sch, extack);\n\tif (err)\n\t\treturn err;\n\n\tfor (i = 0; i < SFQ_MAX_DEPTH + 1; i++) {\n\t\tq->dep[i].next = i + SFQ_MAX_FLOWS;\n\t\tq->dep[i].prev = i + SFQ_MAX_FLOWS;\n\t}\n\n\tq->limit = SFQ_MAX_DEPTH;\n\tq->maxdepth = SFQ_MAX_DEPTH;\n\tq->cur_depth = 0;\n\tq->tail = NULL;\n\tq->divisor = SFQ_DEFAULT_HASH_DIVISOR;\n\tq->maxflows = SFQ_DEFAULT_FLOWS;\n\tq->quantum = psched_mtu(qdisc_dev(sch));\n\tq->scaled_quantum = SFQ_ALLOT_SIZE(q->quantum);\n\tq->perturb_period = 0;\n\tget_random_bytes(&q->perturbation, sizeof(q->perturbation));\n\n\tif (opt) {\n\t\tint err = sfq_change(sch, opt);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tq->ht = sfq_alloc(sizeof(q->ht[0]) * q->divisor);\n\tq->slots = sfq_alloc(sizeof(q->slots[0]) * q->maxflows);\n\tif (!q->ht || !q->slots) {\n\t\t \n\t\treturn -ENOMEM;\n\t}\n\n\tfor (i = 0; i < q->divisor; i++)\n\t\tq->ht[i] = SFQ_EMPTY_SLOT;\n\n\tfor (i = 0; i < q->maxflows; i++) {\n\t\tslot_queue_init(&q->slots[i]);\n\t\tsfq_link(q, i);\n\t}\n\tif (q->limit >= 1)\n\t\tsch->flags |= TCQ_F_CAN_BYPASS;\n\telse\n\t\tsch->flags &= ~TCQ_F_CAN_BYPASS;\n\treturn 0;\n}\n\nstatic int sfq_dump(struct Qdisc *sch, struct sk_buff *skb)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\tunsigned char *b = skb_tail_pointer(skb);\n\tstruct tc_sfq_qopt_v1 opt;\n\tstruct red_parms *p = q->red_parms;\n\n\tmemset(&opt, 0, sizeof(opt));\n\topt.v0.quantum\t= q->quantum;\n\topt.v0.perturb_period = q->perturb_period / HZ;\n\topt.v0.limit\t= q->limit;\n\topt.v0.divisor\t= q->divisor;\n\topt.v0.flows\t= q->maxflows;\n\topt.depth\t= q->maxdepth;\n\topt.headdrop\t= q->headdrop;\n\n\tif (p) {\n\t\topt.qth_min\t= p->qth_min >> p->Wlog;\n\t\topt.qth_max\t= p->qth_max >> p->Wlog;\n\t\topt.Wlog\t= p->Wlog;\n\t\topt.Plog\t= p->Plog;\n\t\topt.Scell_log\t= p->Scell_log;\n\t\topt.max_P\t= p->max_P;\n\t}\n\tmemcpy(&opt.stats, &q->stats, sizeof(opt.stats));\n\topt.flags\t= q->flags;\n\n\tif (nla_put(skb, TCA_OPTIONS, sizeof(opt), &opt))\n\t\tgoto nla_put_failure;\n\n\treturn skb->len;\n\nnla_put_failure:\n\tnlmsg_trim(skb, b);\n\treturn -1;\n}\n\nstatic struct Qdisc *sfq_leaf(struct Qdisc *sch, unsigned long arg)\n{\n\treturn NULL;\n}\n\nstatic unsigned long sfq_find(struct Qdisc *sch, u32 classid)\n{\n\treturn 0;\n}\n\nstatic unsigned long sfq_bind(struct Qdisc *sch, unsigned long parent,\n\t\t\t      u32 classid)\n{\n\treturn 0;\n}\n\nstatic void sfq_unbind(struct Qdisc *q, unsigned long cl)\n{\n}\n\nstatic struct tcf_block *sfq_tcf_block(struct Qdisc *sch, unsigned long cl,\n\t\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\n\tif (cl)\n\t\treturn NULL;\n\treturn q->block;\n}\n\nstatic int sfq_dump_class(struct Qdisc *sch, unsigned long cl,\n\t\t\t  struct sk_buff *skb, struct tcmsg *tcm)\n{\n\ttcm->tcm_handle |= TC_H_MIN(cl);\n\treturn 0;\n}\n\nstatic int sfq_dump_class_stats(struct Qdisc *sch, unsigned long cl,\n\t\t\t\tstruct gnet_dump *d)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\tsfq_index idx = q->ht[cl - 1];\n\tstruct gnet_stats_queue qs = { 0 };\n\tstruct tc_sfq_xstats xstats = { 0 };\n\n\tif (idx != SFQ_EMPTY_SLOT) {\n\t\tconst struct sfq_slot *slot = &q->slots[idx];\n\n\t\txstats.allot = slot->allot << SFQ_ALLOT_SHIFT;\n\t\tqs.qlen = slot->qlen;\n\t\tqs.backlog = slot->backlog;\n\t}\n\tif (gnet_stats_copy_queue(d, NULL, &qs, qs.qlen) < 0)\n\t\treturn -1;\n\treturn gnet_stats_copy_app(d, &xstats, sizeof(xstats));\n}\n\nstatic void sfq_walk(struct Qdisc *sch, struct qdisc_walker *arg)\n{\n\tstruct sfq_sched_data *q = qdisc_priv(sch);\n\tunsigned int i;\n\n\tif (arg->stop)\n\t\treturn;\n\n\tfor (i = 0; i < q->divisor; i++) {\n\t\tif (q->ht[i] == SFQ_EMPTY_SLOT) {\n\t\t\targ->count++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (!tc_qdisc_stats_dump(sch, i + 1, arg))\n\t\t\tbreak;\n\t}\n}\n\nstatic const struct Qdisc_class_ops sfq_class_ops = {\n\t.leaf\t\t=\tsfq_leaf,\n\t.find\t\t=\tsfq_find,\n\t.tcf_block\t=\tsfq_tcf_block,\n\t.bind_tcf\t=\tsfq_bind,\n\t.unbind_tcf\t=\tsfq_unbind,\n\t.dump\t\t=\tsfq_dump_class,\n\t.dump_stats\t=\tsfq_dump_class_stats,\n\t.walk\t\t=\tsfq_walk,\n};\n\nstatic struct Qdisc_ops sfq_qdisc_ops __read_mostly = {\n\t.cl_ops\t\t=\t&sfq_class_ops,\n\t.id\t\t=\t\"sfq\",\n\t.priv_size\t=\tsizeof(struct sfq_sched_data),\n\t.enqueue\t=\tsfq_enqueue,\n\t.dequeue\t=\tsfq_dequeue,\n\t.peek\t\t=\tqdisc_peek_dequeued,\n\t.init\t\t=\tsfq_init,\n\t.reset\t\t=\tsfq_reset,\n\t.destroy\t=\tsfq_destroy,\n\t.change\t\t=\tNULL,\n\t.dump\t\t=\tsfq_dump,\n\t.owner\t\t=\tTHIS_MODULE,\n};\n\nstatic int __init sfq_module_init(void)\n{\n\treturn register_qdisc(&sfq_qdisc_ops);\n}\nstatic void __exit sfq_module_exit(void)\n{\n\tunregister_qdisc(&sfq_qdisc_ops);\n}\nmodule_init(sfq_module_init)\nmodule_exit(sfq_module_exit)\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}