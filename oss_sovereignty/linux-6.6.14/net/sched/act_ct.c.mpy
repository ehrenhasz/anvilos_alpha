{
  "module_name": "act_ct.c",
  "hash_id": "bca7aba7507485c3cd638100818acbac09f707c13406f8193831eef2d12419dc",
  "original_prompt": "Ingested from linux-6.6.14/net/sched/act_ct.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/skbuff.h>\n#include <linux/rtnetlink.h>\n#include <linux/pkt_cls.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <linux/rhashtable.h>\n#include <net/netlink.h>\n#include <net/pkt_sched.h>\n#include <net/pkt_cls.h>\n#include <net/act_api.h>\n#include <net/ip.h>\n#include <net/ipv6_frag.h>\n#include <uapi/linux/tc_act/tc_ct.h>\n#include <net/tc_act/tc_ct.h>\n#include <net/tc_wrapper.h>\n\n#include <net/netfilter/nf_flow_table.h>\n#include <net/netfilter/nf_conntrack.h>\n#include <net/netfilter/nf_conntrack_core.h>\n#include <net/netfilter/nf_conntrack_zones.h>\n#include <net/netfilter/nf_conntrack_helper.h>\n#include <net/netfilter/nf_conntrack_acct.h>\n#include <net/netfilter/ipv6/nf_defrag_ipv6.h>\n#include <net/netfilter/nf_conntrack_act_ct.h>\n#include <net/netfilter/nf_conntrack_seqadj.h>\n#include <uapi/linux/netfilter/nf_nat.h>\n\nstatic struct workqueue_struct *act_ct_wq;\nstatic struct rhashtable zones_ht;\nstatic DEFINE_MUTEX(zones_mutex);\n\nstruct tcf_ct_flow_table {\n\tstruct rhash_head node;  \n\n\tstruct rcu_work rwork;\n\tstruct nf_flowtable nf_ft;\n\trefcount_t ref;\n\tu16 zone;\n\n\tbool dying;\n};\n\nstatic const struct rhashtable_params zones_params = {\n\t.head_offset = offsetof(struct tcf_ct_flow_table, node),\n\t.key_offset = offsetof(struct tcf_ct_flow_table, zone),\n\t.key_len = sizeof_field(struct tcf_ct_flow_table, zone),\n\t.automatic_shrinking = true,\n};\n\nstatic struct flow_action_entry *\ntcf_ct_flow_table_flow_action_get_next(struct flow_action *flow_action)\n{\n\tint i = flow_action->num_entries++;\n\n\treturn &flow_action->entries[i];\n}\n\nstatic void tcf_ct_add_mangle_action(struct flow_action *action,\n\t\t\t\t     enum flow_action_mangle_base htype,\n\t\t\t\t     u32 offset,\n\t\t\t\t     u32 mask,\n\t\t\t\t     u32 val)\n{\n\tstruct flow_action_entry *entry;\n\n\tentry = tcf_ct_flow_table_flow_action_get_next(action);\n\tentry->id = FLOW_ACTION_MANGLE;\n\tentry->mangle.htype = htype;\n\tentry->mangle.mask = ~mask;\n\tentry->mangle.offset = offset;\n\tentry->mangle.val = val;\n}\n\n \nstatic void\ntcf_ct_flow_table_add_action_nat_ipv4(const struct nf_conntrack_tuple *tuple,\n\t\t\t\t      struct nf_conntrack_tuple target,\n\t\t\t\t      struct flow_action *action)\n{\n\tif (memcmp(&target.src.u3, &tuple->src.u3, sizeof(target.src.u3)))\n\t\ttcf_ct_add_mangle_action(action, FLOW_ACT_MANGLE_HDR_TYPE_IP4,\n\t\t\t\t\t offsetof(struct iphdr, saddr),\n\t\t\t\t\t 0xFFFFFFFF,\n\t\t\t\t\t be32_to_cpu(target.src.u3.ip));\n\tif (memcmp(&target.dst.u3, &tuple->dst.u3, sizeof(target.dst.u3)))\n\t\ttcf_ct_add_mangle_action(action, FLOW_ACT_MANGLE_HDR_TYPE_IP4,\n\t\t\t\t\t offsetof(struct iphdr, daddr),\n\t\t\t\t\t 0xFFFFFFFF,\n\t\t\t\t\t be32_to_cpu(target.dst.u3.ip));\n}\n\nstatic void\ntcf_ct_add_ipv6_addr_mangle_action(struct flow_action *action,\n\t\t\t\t   union nf_inet_addr *addr,\n\t\t\t\t   u32 offset)\n{\n\tint i;\n\n\tfor (i = 0; i < sizeof(struct in6_addr) / sizeof(u32); i++)\n\t\ttcf_ct_add_mangle_action(action, FLOW_ACT_MANGLE_HDR_TYPE_IP6,\n\t\t\t\t\t i * sizeof(u32) + offset,\n\t\t\t\t\t 0xFFFFFFFF, be32_to_cpu(addr->ip6[i]));\n}\n\nstatic void\ntcf_ct_flow_table_add_action_nat_ipv6(const struct nf_conntrack_tuple *tuple,\n\t\t\t\t      struct nf_conntrack_tuple target,\n\t\t\t\t      struct flow_action *action)\n{\n\tif (memcmp(&target.src.u3, &tuple->src.u3, sizeof(target.src.u3)))\n\t\ttcf_ct_add_ipv6_addr_mangle_action(action, &target.src.u3,\n\t\t\t\t\t\t   offsetof(struct ipv6hdr,\n\t\t\t\t\t\t\t    saddr));\n\tif (memcmp(&target.dst.u3, &tuple->dst.u3, sizeof(target.dst.u3)))\n\t\ttcf_ct_add_ipv6_addr_mangle_action(action, &target.dst.u3,\n\t\t\t\t\t\t   offsetof(struct ipv6hdr,\n\t\t\t\t\t\t\t    daddr));\n}\n\nstatic void\ntcf_ct_flow_table_add_action_nat_tcp(const struct nf_conntrack_tuple *tuple,\n\t\t\t\t     struct nf_conntrack_tuple target,\n\t\t\t\t     struct flow_action *action)\n{\n\t__be16 target_src = target.src.u.tcp.port;\n\t__be16 target_dst = target.dst.u.tcp.port;\n\n\tif (target_src != tuple->src.u.tcp.port)\n\t\ttcf_ct_add_mangle_action(action, FLOW_ACT_MANGLE_HDR_TYPE_TCP,\n\t\t\t\t\t offsetof(struct tcphdr, source),\n\t\t\t\t\t 0xFFFF, be16_to_cpu(target_src));\n\tif (target_dst != tuple->dst.u.tcp.port)\n\t\ttcf_ct_add_mangle_action(action, FLOW_ACT_MANGLE_HDR_TYPE_TCP,\n\t\t\t\t\t offsetof(struct tcphdr, dest),\n\t\t\t\t\t 0xFFFF, be16_to_cpu(target_dst));\n}\n\nstatic void\ntcf_ct_flow_table_add_action_nat_udp(const struct nf_conntrack_tuple *tuple,\n\t\t\t\t     struct nf_conntrack_tuple target,\n\t\t\t\t     struct flow_action *action)\n{\n\t__be16 target_src = target.src.u.udp.port;\n\t__be16 target_dst = target.dst.u.udp.port;\n\n\tif (target_src != tuple->src.u.udp.port)\n\t\ttcf_ct_add_mangle_action(action, FLOW_ACT_MANGLE_HDR_TYPE_UDP,\n\t\t\t\t\t offsetof(struct udphdr, source),\n\t\t\t\t\t 0xFFFF, be16_to_cpu(target_src));\n\tif (target_dst != tuple->dst.u.udp.port)\n\t\ttcf_ct_add_mangle_action(action, FLOW_ACT_MANGLE_HDR_TYPE_UDP,\n\t\t\t\t\t offsetof(struct udphdr, dest),\n\t\t\t\t\t 0xFFFF, be16_to_cpu(target_dst));\n}\n\nstatic void tcf_ct_flow_table_add_action_meta(struct nf_conn *ct,\n\t\t\t\t\t      enum ip_conntrack_dir dir,\n\t\t\t\t\t      enum ip_conntrack_info ctinfo,\n\t\t\t\t\t      struct flow_action *action)\n{\n\tstruct nf_conn_labels *ct_labels;\n\tstruct flow_action_entry *entry;\n\tu32 *act_ct_labels;\n\n\tentry = tcf_ct_flow_table_flow_action_get_next(action);\n\tentry->id = FLOW_ACTION_CT_METADATA;\n#if IS_ENABLED(CONFIG_NF_CONNTRACK_MARK)\n\tentry->ct_metadata.mark = READ_ONCE(ct->mark);\n#endif\n\t \n\tentry->ct_metadata.cookie = (unsigned long)ct | ctinfo;\n\tentry->ct_metadata.orig_dir = dir == IP_CT_DIR_ORIGINAL;\n\n\tact_ct_labels = entry->ct_metadata.labels;\n\tct_labels = nf_ct_labels_find(ct);\n\tif (ct_labels)\n\t\tmemcpy(act_ct_labels, ct_labels->bits, NF_CT_LABELS_MAX_SIZE);\n\telse\n\t\tmemset(act_ct_labels, 0, NF_CT_LABELS_MAX_SIZE);\n}\n\nstatic int tcf_ct_flow_table_add_action_nat(struct net *net,\n\t\t\t\t\t    struct nf_conn *ct,\n\t\t\t\t\t    enum ip_conntrack_dir dir,\n\t\t\t\t\t    struct flow_action *action)\n{\n\tconst struct nf_conntrack_tuple *tuple = &ct->tuplehash[dir].tuple;\n\tstruct nf_conntrack_tuple target;\n\n\tif (!(ct->status & IPS_NAT_MASK))\n\t\treturn 0;\n\n\tnf_ct_invert_tuple(&target, &ct->tuplehash[!dir].tuple);\n\n\tswitch (tuple->src.l3num) {\n\tcase NFPROTO_IPV4:\n\t\ttcf_ct_flow_table_add_action_nat_ipv4(tuple, target,\n\t\t\t\t\t\t      action);\n\t\tbreak;\n\tcase NFPROTO_IPV6:\n\t\ttcf_ct_flow_table_add_action_nat_ipv6(tuple, target,\n\t\t\t\t\t\t      action);\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tswitch (nf_ct_protonum(ct)) {\n\tcase IPPROTO_TCP:\n\t\ttcf_ct_flow_table_add_action_nat_tcp(tuple, target, action);\n\t\tbreak;\n\tcase IPPROTO_UDP:\n\t\ttcf_ct_flow_table_add_action_nat_udp(tuple, target, action);\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int tcf_ct_flow_table_fill_actions(struct net *net,\n\t\t\t\t\t  struct flow_offload *flow,\n\t\t\t\t\t  enum flow_offload_tuple_dir tdir,\n\t\t\t\t\t  struct nf_flow_rule *flow_rule)\n{\n\tstruct flow_action *action = &flow_rule->rule->action;\n\tint num_entries = action->num_entries;\n\tstruct nf_conn *ct = flow->ct;\n\tenum ip_conntrack_info ctinfo;\n\tenum ip_conntrack_dir dir;\n\tint i, err;\n\n\tswitch (tdir) {\n\tcase FLOW_OFFLOAD_DIR_ORIGINAL:\n\t\tdir = IP_CT_DIR_ORIGINAL;\n\t\tctinfo = test_bit(IPS_SEEN_REPLY_BIT, &ct->status) ?\n\t\t\tIP_CT_ESTABLISHED : IP_CT_NEW;\n\t\tif (ctinfo == IP_CT_ESTABLISHED)\n\t\t\tset_bit(NF_FLOW_HW_ESTABLISHED, &flow->flags);\n\t\tbreak;\n\tcase FLOW_OFFLOAD_DIR_REPLY:\n\t\tdir = IP_CT_DIR_REPLY;\n\t\tctinfo = IP_CT_ESTABLISHED_REPLY;\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\terr = tcf_ct_flow_table_add_action_nat(net, ct, dir, action);\n\tif (err)\n\t\tgoto err_nat;\n\n\ttcf_ct_flow_table_add_action_meta(ct, dir, ctinfo, action);\n\treturn 0;\n\nerr_nat:\n\t \n\tfor (i = num_entries; i < action->num_entries; i++)\n\t\tmemset(&action->entries[i], 0, sizeof(action->entries[i]));\n\taction->num_entries = num_entries;\n\n\treturn err;\n}\n\nstatic bool tcf_ct_flow_is_outdated(const struct flow_offload *flow)\n{\n\treturn test_bit(IPS_SEEN_REPLY_BIT, &flow->ct->status) &&\n\t       test_bit(IPS_HW_OFFLOAD_BIT, &flow->ct->status) &&\n\t       !test_bit(NF_FLOW_HW_PENDING, &flow->flags) &&\n\t       !test_bit(NF_FLOW_HW_ESTABLISHED, &flow->flags);\n}\n\nstatic void tcf_ct_flow_table_get_ref(struct tcf_ct_flow_table *ct_ft);\n\nstatic void tcf_ct_nf_get(struct nf_flowtable *ft)\n{\n\tstruct tcf_ct_flow_table *ct_ft =\n\t\tcontainer_of(ft, struct tcf_ct_flow_table, nf_ft);\n\n\ttcf_ct_flow_table_get_ref(ct_ft);\n}\n\nstatic void tcf_ct_flow_table_put(struct tcf_ct_flow_table *ct_ft);\n\nstatic void tcf_ct_nf_put(struct nf_flowtable *ft)\n{\n\tstruct tcf_ct_flow_table *ct_ft =\n\t\tcontainer_of(ft, struct tcf_ct_flow_table, nf_ft);\n\n\ttcf_ct_flow_table_put(ct_ft);\n}\n\nstatic struct nf_flowtable_type flowtable_ct = {\n\t.gc\t\t= tcf_ct_flow_is_outdated,\n\t.action\t\t= tcf_ct_flow_table_fill_actions,\n\t.get\t\t= tcf_ct_nf_get,\n\t.put\t\t= tcf_ct_nf_put,\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic int tcf_ct_flow_table_get(struct net *net, struct tcf_ct_params *params)\n{\n\tstruct tcf_ct_flow_table *ct_ft;\n\tint err = -ENOMEM;\n\n\tmutex_lock(&zones_mutex);\n\tct_ft = rhashtable_lookup_fast(&zones_ht, &params->zone, zones_params);\n\tif (ct_ft && refcount_inc_not_zero(&ct_ft->ref))\n\t\tgoto out_unlock;\n\n\tct_ft = kzalloc(sizeof(*ct_ft), GFP_KERNEL);\n\tif (!ct_ft)\n\t\tgoto err_alloc;\n\trefcount_set(&ct_ft->ref, 1);\n\n\tct_ft->zone = params->zone;\n\terr = rhashtable_insert_fast(&zones_ht, &ct_ft->node, zones_params);\n\tif (err)\n\t\tgoto err_insert;\n\n\tct_ft->nf_ft.type = &flowtable_ct;\n\tct_ft->nf_ft.flags |= NF_FLOWTABLE_HW_OFFLOAD |\n\t\t\t      NF_FLOWTABLE_COUNTER;\n\terr = nf_flow_table_init(&ct_ft->nf_ft);\n\tif (err)\n\t\tgoto err_init;\n\twrite_pnet(&ct_ft->nf_ft.net, net);\n\n\t__module_get(THIS_MODULE);\nout_unlock:\n\tparams->ct_ft = ct_ft;\n\tparams->nf_ft = &ct_ft->nf_ft;\n\tmutex_unlock(&zones_mutex);\n\n\treturn 0;\n\nerr_init:\n\trhashtable_remove_fast(&zones_ht, &ct_ft->node, zones_params);\nerr_insert:\n\tkfree(ct_ft);\nerr_alloc:\n\tmutex_unlock(&zones_mutex);\n\treturn err;\n}\n\nstatic void tcf_ct_flow_table_get_ref(struct tcf_ct_flow_table *ct_ft)\n{\n\trefcount_inc(&ct_ft->ref);\n}\n\nstatic void tcf_ct_flow_table_cleanup_work(struct work_struct *work)\n{\n\tstruct tcf_ct_flow_table *ct_ft;\n\tstruct flow_block *block;\n\n\tct_ft = container_of(to_rcu_work(work), struct tcf_ct_flow_table,\n\t\t\t     rwork);\n\tnf_flow_table_free(&ct_ft->nf_ft);\n\n\tblock = &ct_ft->nf_ft.flow_block;\n\tdown_write(&ct_ft->nf_ft.flow_block_lock);\n\tWARN_ON(!list_empty(&block->cb_list));\n\tup_write(&ct_ft->nf_ft.flow_block_lock);\n\tkfree(ct_ft);\n\n\tmodule_put(THIS_MODULE);\n}\n\nstatic void tcf_ct_flow_table_put(struct tcf_ct_flow_table *ct_ft)\n{\n\tif (refcount_dec_and_test(&ct_ft->ref)) {\n\t\trhashtable_remove_fast(&zones_ht, &ct_ft->node, zones_params);\n\t\tINIT_RCU_WORK(&ct_ft->rwork, tcf_ct_flow_table_cleanup_work);\n\t\tqueue_rcu_work(act_ct_wq, &ct_ft->rwork);\n\t}\n}\n\nstatic void tcf_ct_flow_tc_ifidx(struct flow_offload *entry,\n\t\t\t\t struct nf_conn_act_ct_ext *act_ct_ext, u8 dir)\n{\n\tentry->tuplehash[dir].tuple.xmit_type = FLOW_OFFLOAD_XMIT_TC;\n\tentry->tuplehash[dir].tuple.tc.iifidx = act_ct_ext->ifindex[dir];\n}\n\nstatic void tcf_ct_flow_ct_ext_ifidx_update(struct flow_offload *entry)\n{\n\tstruct nf_conn_act_ct_ext *act_ct_ext;\n\n\tact_ct_ext = nf_conn_act_ct_ext_find(entry->ct);\n\tif (act_ct_ext) {\n\t\ttcf_ct_flow_tc_ifidx(entry, act_ct_ext, FLOW_OFFLOAD_DIR_ORIGINAL);\n\t\ttcf_ct_flow_tc_ifidx(entry, act_ct_ext, FLOW_OFFLOAD_DIR_REPLY);\n\t}\n}\n\nstatic void tcf_ct_flow_table_add(struct tcf_ct_flow_table *ct_ft,\n\t\t\t\t  struct nf_conn *ct,\n\t\t\t\t  bool tcp, bool bidirectional)\n{\n\tstruct nf_conn_act_ct_ext *act_ct_ext;\n\tstruct flow_offload *entry;\n\tint err;\n\n\tif (test_and_set_bit(IPS_OFFLOAD_BIT, &ct->status))\n\t\treturn;\n\n\tentry = flow_offload_alloc(ct);\n\tif (!entry) {\n\t\tWARN_ON_ONCE(1);\n\t\tgoto err_alloc;\n\t}\n\n\tif (tcp) {\n\t\tct->proto.tcp.seen[0].flags |= IP_CT_TCP_FLAG_BE_LIBERAL;\n\t\tct->proto.tcp.seen[1].flags |= IP_CT_TCP_FLAG_BE_LIBERAL;\n\t}\n\tif (bidirectional)\n\t\t__set_bit(NF_FLOW_HW_BIDIRECTIONAL, &entry->flags);\n\n\tact_ct_ext = nf_conn_act_ct_ext_find(ct);\n\tif (act_ct_ext) {\n\t\ttcf_ct_flow_tc_ifidx(entry, act_ct_ext, FLOW_OFFLOAD_DIR_ORIGINAL);\n\t\ttcf_ct_flow_tc_ifidx(entry, act_ct_ext, FLOW_OFFLOAD_DIR_REPLY);\n\t}\n\n\terr = flow_offload_add(&ct_ft->nf_ft, entry);\n\tif (err)\n\t\tgoto err_add;\n\n\treturn;\n\nerr_add:\n\tflow_offload_free(entry);\nerr_alloc:\n\tclear_bit(IPS_OFFLOAD_BIT, &ct->status);\n}\n\nstatic void tcf_ct_flow_table_process_conn(struct tcf_ct_flow_table *ct_ft,\n\t\t\t\t\t   struct nf_conn *ct,\n\t\t\t\t\t   enum ip_conntrack_info ctinfo)\n{\n\tbool tcp = false, bidirectional = true;\n\n\tswitch (nf_ct_protonum(ct)) {\n\tcase IPPROTO_TCP:\n\t\tif ((ctinfo != IP_CT_ESTABLISHED &&\n\t\t     ctinfo != IP_CT_ESTABLISHED_REPLY) ||\n\t\t    !test_bit(IPS_ASSURED_BIT, &ct->status) ||\n\t\t    ct->proto.tcp.state != TCP_CONNTRACK_ESTABLISHED)\n\t\t\treturn;\n\n\t\ttcp = true;\n\t\tbreak;\n\tcase IPPROTO_UDP:\n\t\tif (!nf_ct_is_confirmed(ct))\n\t\t\treturn;\n\t\tif (!test_bit(IPS_ASSURED_BIT, &ct->status))\n\t\t\tbidirectional = false;\n\t\tbreak;\n#ifdef CONFIG_NF_CT_PROTO_GRE\n\tcase IPPROTO_GRE: {\n\t\tstruct nf_conntrack_tuple *tuple;\n\n\t\tif ((ctinfo != IP_CT_ESTABLISHED &&\n\t\t     ctinfo != IP_CT_ESTABLISHED_REPLY) ||\n\t\t    !test_bit(IPS_ASSURED_BIT, &ct->status) ||\n\t\t    ct->status & IPS_NAT_MASK)\n\t\t\treturn;\n\n\t\ttuple = &ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple;\n\t\t \n\t\tif (tuple->src.u.gre.key || tuple->dst.u.gre.key)\n\t\t\treturn;\n\t\tbreak;\n\t}\n#endif\n\tdefault:\n\t\treturn;\n\t}\n\n\tif (nf_ct_ext_exist(ct, NF_CT_EXT_HELPER) ||\n\t    ct->status & IPS_SEQ_ADJUST)\n\t\treturn;\n\n\ttcf_ct_flow_table_add(ct_ft, ct, tcp, bidirectional);\n}\n\nstatic bool\ntcf_ct_flow_table_fill_tuple_ipv4(struct sk_buff *skb,\n\t\t\t\t  struct flow_offload_tuple *tuple,\n\t\t\t\t  struct tcphdr **tcph)\n{\n\tstruct flow_ports *ports;\n\tunsigned int thoff;\n\tstruct iphdr *iph;\n\tsize_t hdrsize;\n\tu8 ipproto;\n\n\tif (!pskb_network_may_pull(skb, sizeof(*iph)))\n\t\treturn false;\n\n\tiph = ip_hdr(skb);\n\tthoff = iph->ihl * 4;\n\n\tif (ip_is_fragment(iph) ||\n\t    unlikely(thoff != sizeof(struct iphdr)))\n\t\treturn false;\n\n\tipproto = iph->protocol;\n\tswitch (ipproto) {\n\tcase IPPROTO_TCP:\n\t\thdrsize = sizeof(struct tcphdr);\n\t\tbreak;\n\tcase IPPROTO_UDP:\n\t\thdrsize = sizeof(*ports);\n\t\tbreak;\n#ifdef CONFIG_NF_CT_PROTO_GRE\n\tcase IPPROTO_GRE:\n\t\thdrsize = sizeof(struct gre_base_hdr);\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn false;\n\t}\n\n\tif (iph->ttl <= 1)\n\t\treturn false;\n\n\tif (!pskb_network_may_pull(skb, thoff + hdrsize))\n\t\treturn false;\n\n\tswitch (ipproto) {\n\tcase IPPROTO_TCP:\n\t\t*tcph = (void *)(skb_network_header(skb) + thoff);\n\t\tfallthrough;\n\tcase IPPROTO_UDP:\n\t\tports = (struct flow_ports *)(skb_network_header(skb) + thoff);\n\t\ttuple->src_port = ports->source;\n\t\ttuple->dst_port = ports->dest;\n\t\tbreak;\n\tcase IPPROTO_GRE: {\n\t\tstruct gre_base_hdr *greh;\n\n\t\tgreh = (struct gre_base_hdr *)(skb_network_header(skb) + thoff);\n\t\tif ((greh->flags & GRE_VERSION) != GRE_VERSION_0)\n\t\t\treturn false;\n\t\tbreak;\n\t}\n\t}\n\n\tiph = ip_hdr(skb);\n\n\ttuple->src_v4.s_addr = iph->saddr;\n\ttuple->dst_v4.s_addr = iph->daddr;\n\ttuple->l3proto = AF_INET;\n\ttuple->l4proto = ipproto;\n\n\treturn true;\n}\n\nstatic bool\ntcf_ct_flow_table_fill_tuple_ipv6(struct sk_buff *skb,\n\t\t\t\t  struct flow_offload_tuple *tuple,\n\t\t\t\t  struct tcphdr **tcph)\n{\n\tstruct flow_ports *ports;\n\tstruct ipv6hdr *ip6h;\n\tunsigned int thoff;\n\tsize_t hdrsize;\n\tu8 nexthdr;\n\n\tif (!pskb_network_may_pull(skb, sizeof(*ip6h)))\n\t\treturn false;\n\n\tip6h = ipv6_hdr(skb);\n\tthoff = sizeof(*ip6h);\n\n\tnexthdr = ip6h->nexthdr;\n\tswitch (nexthdr) {\n\tcase IPPROTO_TCP:\n\t\thdrsize = sizeof(struct tcphdr);\n\t\tbreak;\n\tcase IPPROTO_UDP:\n\t\thdrsize = sizeof(*ports);\n\t\tbreak;\n#ifdef CONFIG_NF_CT_PROTO_GRE\n\tcase IPPROTO_GRE:\n\t\thdrsize = sizeof(struct gre_base_hdr);\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn false;\n\t}\n\n\tif (ip6h->hop_limit <= 1)\n\t\treturn false;\n\n\tif (!pskb_network_may_pull(skb, thoff + hdrsize))\n\t\treturn false;\n\n\tswitch (nexthdr) {\n\tcase IPPROTO_TCP:\n\t\t*tcph = (void *)(skb_network_header(skb) + thoff);\n\t\tfallthrough;\n\tcase IPPROTO_UDP:\n\t\tports = (struct flow_ports *)(skb_network_header(skb) + thoff);\n\t\ttuple->src_port = ports->source;\n\t\ttuple->dst_port = ports->dest;\n\t\tbreak;\n\tcase IPPROTO_GRE: {\n\t\tstruct gre_base_hdr *greh;\n\n\t\tgreh = (struct gre_base_hdr *)(skb_network_header(skb) + thoff);\n\t\tif ((greh->flags & GRE_VERSION) != GRE_VERSION_0)\n\t\t\treturn false;\n\t\tbreak;\n\t}\n\t}\n\n\tip6h = ipv6_hdr(skb);\n\n\ttuple->src_v6 = ip6h->saddr;\n\ttuple->dst_v6 = ip6h->daddr;\n\ttuple->l3proto = AF_INET6;\n\ttuple->l4proto = nexthdr;\n\n\treturn true;\n}\n\nstatic bool tcf_ct_flow_table_lookup(struct tcf_ct_params *p,\n\t\t\t\t     struct sk_buff *skb,\n\t\t\t\t     u8 family)\n{\n\tstruct nf_flowtable *nf_ft = &p->ct_ft->nf_ft;\n\tstruct flow_offload_tuple_rhash *tuplehash;\n\tstruct flow_offload_tuple tuple = {};\n\tenum ip_conntrack_info ctinfo;\n\tstruct tcphdr *tcph = NULL;\n\tbool force_refresh = false;\n\tstruct flow_offload *flow;\n\tstruct nf_conn *ct;\n\tu8 dir;\n\n\tswitch (family) {\n\tcase NFPROTO_IPV4:\n\t\tif (!tcf_ct_flow_table_fill_tuple_ipv4(skb, &tuple, &tcph))\n\t\t\treturn false;\n\t\tbreak;\n\tcase NFPROTO_IPV6:\n\t\tif (!tcf_ct_flow_table_fill_tuple_ipv6(skb, &tuple, &tcph))\n\t\t\treturn false;\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\n\ttuplehash = flow_offload_lookup(nf_ft, &tuple);\n\tif (!tuplehash)\n\t\treturn false;\n\n\tdir = tuplehash->tuple.dir;\n\tflow = container_of(tuplehash, struct flow_offload, tuplehash[dir]);\n\tct = flow->ct;\n\n\tif (dir == FLOW_OFFLOAD_DIR_REPLY &&\n\t    !test_bit(NF_FLOW_HW_BIDIRECTIONAL, &flow->flags)) {\n\t\t \n\t\tif (test_bit(IPS_ASSURED_BIT, &ct->status))\n\t\t\tset_bit(NF_FLOW_HW_BIDIRECTIONAL, &flow->flags);\n\t\telse if (test_bit(NF_FLOW_HW_ESTABLISHED, &flow->flags))\n\t\t\t \n\t\t\treturn false;\n\t\tforce_refresh = true;\n\t}\n\n\tif (tcph && (unlikely(tcph->fin || tcph->rst))) {\n\t\tflow_offload_teardown(flow);\n\t\treturn false;\n\t}\n\n\tif (dir == FLOW_OFFLOAD_DIR_ORIGINAL)\n\t\tctinfo = test_bit(IPS_SEEN_REPLY_BIT, &ct->status) ?\n\t\t\tIP_CT_ESTABLISHED : IP_CT_NEW;\n\telse\n\t\tctinfo = IP_CT_ESTABLISHED_REPLY;\n\n\tnf_conn_act_ct_ext_fill(skb, ct, ctinfo);\n\ttcf_ct_flow_ct_ext_ifidx_update(flow);\n\tflow_offload_refresh(nf_ft, flow, force_refresh);\n\tif (!test_bit(IPS_ASSURED_BIT, &ct->status)) {\n\t\t \n\t\treturn false;\n\t}\n\n\tnf_conntrack_get(&ct->ct_general);\n\tnf_ct_set(skb, ct, ctinfo);\n\tif (nf_ft->flags & NF_FLOWTABLE_COUNTER)\n\t\tnf_ct_acct_update(ct, dir, skb->len);\n\n\treturn true;\n}\n\nstatic int tcf_ct_flow_tables_init(void)\n{\n\treturn rhashtable_init(&zones_ht, &zones_params);\n}\n\nstatic void tcf_ct_flow_tables_uninit(void)\n{\n\trhashtable_destroy(&zones_ht);\n}\n\nstatic struct tc_action_ops act_ct_ops;\n\nstruct tc_ct_action_net {\n\tstruct tc_action_net tn;  \n\tbool labels;\n};\n\n \nstatic bool tcf_ct_skb_nfct_cached(struct net *net, struct sk_buff *skb,\n\t\t\t\t   struct tcf_ct_params *p)\n{\n\tenum ip_conntrack_info ctinfo;\n\tstruct nf_conn *ct;\n\n\tct = nf_ct_get(skb, &ctinfo);\n\tif (!ct)\n\t\treturn false;\n\tif (!net_eq(net, read_pnet(&ct->ct_net)))\n\t\tgoto drop_ct;\n\tif (nf_ct_zone(ct)->id != p->zone)\n\t\tgoto drop_ct;\n\tif (p->helper) {\n\t\tstruct nf_conn_help *help;\n\n\t\thelp = nf_ct_ext_find(ct, NF_CT_EXT_HELPER);\n\t\tif (help && rcu_access_pointer(help->helper) != p->helper)\n\t\t\tgoto drop_ct;\n\t}\n\n\t \n\tif ((p->ct_action & TCA_CT_ACT_FORCE) &&\n\t    CTINFO2DIR(ctinfo) != IP_CT_DIR_ORIGINAL) {\n\t\tif (nf_ct_is_confirmed(ct))\n\t\t\tnf_ct_kill(ct);\n\n\t\tgoto drop_ct;\n\t}\n\n\treturn true;\n\ndrop_ct:\n\tnf_ct_put(ct);\n\tnf_ct_set(skb, NULL, IP_CT_UNTRACKED);\n\n\treturn false;\n}\n\nstatic u8 tcf_ct_skb_nf_family(struct sk_buff *skb)\n{\n\tu8 family = NFPROTO_UNSPEC;\n\n\tswitch (skb_protocol(skb, true)) {\n\tcase htons(ETH_P_IP):\n\t\tfamily = NFPROTO_IPV4;\n\t\tbreak;\n\tcase htons(ETH_P_IPV6):\n\t\tfamily = NFPROTO_IPV6;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn family;\n}\n\nstatic int tcf_ct_ipv4_is_fragment(struct sk_buff *skb, bool *frag)\n{\n\tunsigned int len;\n\n\tlen =  skb_network_offset(skb) + sizeof(struct iphdr);\n\tif (unlikely(skb->len < len))\n\t\treturn -EINVAL;\n\tif (unlikely(!pskb_may_pull(skb, len)))\n\t\treturn -ENOMEM;\n\n\t*frag = ip_is_fragment(ip_hdr(skb));\n\treturn 0;\n}\n\nstatic int tcf_ct_ipv6_is_fragment(struct sk_buff *skb, bool *frag)\n{\n\tunsigned int flags = 0, len, payload_ofs = 0;\n\tunsigned short frag_off;\n\tint nexthdr;\n\n\tlen =  skb_network_offset(skb) + sizeof(struct ipv6hdr);\n\tif (unlikely(skb->len < len))\n\t\treturn -EINVAL;\n\tif (unlikely(!pskb_may_pull(skb, len)))\n\t\treturn -ENOMEM;\n\n\tnexthdr = ipv6_find_hdr(skb, &payload_ofs, -1, &frag_off, &flags);\n\tif (unlikely(nexthdr < 0))\n\t\treturn -EPROTO;\n\n\t*frag = flags & IP6_FH_F_FRAG;\n\treturn 0;\n}\n\nstatic int tcf_ct_handle_fragments(struct net *net, struct sk_buff *skb,\n\t\t\t\t   u8 family, u16 zone, bool *defrag)\n{\n\tenum ip_conntrack_info ctinfo;\n\tstruct nf_conn *ct;\n\tint err = 0;\n\tbool frag;\n\tu8 proto;\n\tu16 mru;\n\n\t \n\tct = nf_ct_get(skb, &ctinfo);\n\tif ((ct && !nf_ct_is_template(ct)) || ctinfo == IP_CT_UNTRACKED)\n\t\treturn 0;\n\n\tif (family == NFPROTO_IPV4)\n\t\terr = tcf_ct_ipv4_is_fragment(skb, &frag);\n\telse\n\t\terr = tcf_ct_ipv6_is_fragment(skb, &frag);\n\tif (err || !frag)\n\t\treturn err;\n\n\terr = nf_ct_handle_fragments(net, skb, zone, family, &proto, &mru);\n\tif (err)\n\t\treturn err;\n\n\t*defrag = true;\n\ttc_skb_cb(skb)->mru = mru;\n\n\treturn 0;\n}\n\nstatic void tcf_ct_params_free(struct tcf_ct_params *params)\n{\n\tif (params->helper) {\n#if IS_ENABLED(CONFIG_NF_NAT)\n\t\tif (params->ct_action & TCA_CT_ACT_NAT)\n\t\t\tnf_nat_helper_put(params->helper);\n#endif\n\t\tnf_conntrack_helper_put(params->helper);\n\t}\n\tif (params->ct_ft)\n\t\ttcf_ct_flow_table_put(params->ct_ft);\n\tif (params->tmpl)\n\t\tnf_ct_put(params->tmpl);\n\tkfree(params);\n}\n\nstatic void tcf_ct_params_free_rcu(struct rcu_head *head)\n{\n\tstruct tcf_ct_params *params;\n\n\tparams = container_of(head, struct tcf_ct_params, rcu);\n\ttcf_ct_params_free(params);\n}\n\nstatic void tcf_ct_act_set_mark(struct nf_conn *ct, u32 mark, u32 mask)\n{\n#if IS_ENABLED(CONFIG_NF_CONNTRACK_MARK)\n\tu32 new_mark;\n\n\tif (!mask)\n\t\treturn;\n\n\tnew_mark = mark | (READ_ONCE(ct->mark) & ~(mask));\n\tif (READ_ONCE(ct->mark) != new_mark) {\n\t\tWRITE_ONCE(ct->mark, new_mark);\n\t\tif (nf_ct_is_confirmed(ct))\n\t\t\tnf_conntrack_event_cache(IPCT_MARK, ct);\n\t}\n#endif\n}\n\nstatic void tcf_ct_act_set_labels(struct nf_conn *ct,\n\t\t\t\t  u32 *labels,\n\t\t\t\t  u32 *labels_m)\n{\n#if IS_ENABLED(CONFIG_NF_CONNTRACK_LABELS)\n\tsize_t labels_sz = sizeof_field(struct tcf_ct_params, labels);\n\n\tif (!memchr_inv(labels_m, 0, labels_sz))\n\t\treturn;\n\n\tnf_connlabels_replace(ct, labels, labels_m, 4);\n#endif\n}\n\nstatic int tcf_ct_act_nat(struct sk_buff *skb,\n\t\t\t  struct nf_conn *ct,\n\t\t\t  enum ip_conntrack_info ctinfo,\n\t\t\t  int ct_action,\n\t\t\t  struct nf_nat_range2 *range,\n\t\t\t  bool commit)\n{\n#if IS_ENABLED(CONFIG_NF_NAT)\n\tint err, action = 0;\n\n\tif (!(ct_action & TCA_CT_ACT_NAT))\n\t\treturn NF_ACCEPT;\n\tif (ct_action & TCA_CT_ACT_NAT_SRC)\n\t\taction |= BIT(NF_NAT_MANIP_SRC);\n\tif (ct_action & TCA_CT_ACT_NAT_DST)\n\t\taction |= BIT(NF_NAT_MANIP_DST);\n\n\terr = nf_ct_nat(skb, ct, ctinfo, &action, range, commit);\n\n\tif (action & BIT(NF_NAT_MANIP_SRC))\n\t\ttc_skb_cb(skb)->post_ct_snat = 1;\n\tif (action & BIT(NF_NAT_MANIP_DST))\n\t\ttc_skb_cb(skb)->post_ct_dnat = 1;\n\n\treturn err;\n#else\n\treturn NF_ACCEPT;\n#endif\n}\n\nTC_INDIRECT_SCOPE int tcf_ct_act(struct sk_buff *skb, const struct tc_action *a,\n\t\t\t\t struct tcf_result *res)\n{\n\tstruct net *net = dev_net(skb->dev);\n\tenum ip_conntrack_info ctinfo;\n\tstruct tcf_ct *c = to_ct(a);\n\tstruct nf_conn *tmpl = NULL;\n\tstruct nf_hook_state state;\n\tbool cached, commit, clear;\n\tint nh_ofs, err, retval;\n\tstruct tcf_ct_params *p;\n\tbool add_helper = false;\n\tbool skip_add = false;\n\tbool defrag = false;\n\tstruct nf_conn *ct;\n\tu8 family;\n\n\tp = rcu_dereference_bh(c->params);\n\n\tretval = READ_ONCE(c->tcf_action);\n\tcommit = p->ct_action & TCA_CT_ACT_COMMIT;\n\tclear = p->ct_action & TCA_CT_ACT_CLEAR;\n\ttmpl = p->tmpl;\n\n\ttcf_lastuse_update(&c->tcf_tm);\n\ttcf_action_update_bstats(&c->common, skb);\n\n\tif (clear) {\n\t\ttc_skb_cb(skb)->post_ct = false;\n\t\tct = nf_ct_get(skb, &ctinfo);\n\t\tif (ct) {\n\t\t\tnf_ct_put(ct);\n\t\t\tnf_ct_set(skb, NULL, IP_CT_UNTRACKED);\n\t\t}\n\n\t\tgoto out_clear;\n\t}\n\n\tfamily = tcf_ct_skb_nf_family(skb);\n\tif (family == NFPROTO_UNSPEC)\n\t\tgoto drop;\n\n\t \n\tnh_ofs = skb_network_offset(skb);\n\tskb_pull_rcsum(skb, nh_ofs);\n\terr = tcf_ct_handle_fragments(net, skb, family, p->zone, &defrag);\n\tif (err)\n\t\tgoto out_frag;\n\n\terr = nf_ct_skb_network_trim(skb, family);\n\tif (err)\n\t\tgoto drop;\n\n\t \n\tcached = tcf_ct_skb_nfct_cached(net, skb, p);\n\tif (!cached) {\n\t\tif (tcf_ct_flow_table_lookup(p, skb, family)) {\n\t\t\tskip_add = true;\n\t\t\tgoto do_nat;\n\t\t}\n\n\t\t \n\t\tif (tmpl) {\n\t\t\tnf_conntrack_put(skb_nfct(skb));\n\t\t\tnf_conntrack_get(&tmpl->ct_general);\n\t\t\tnf_ct_set(skb, tmpl, IP_CT_NEW);\n\t\t}\n\n\t\tstate.hook = NF_INET_PRE_ROUTING;\n\t\tstate.net = net;\n\t\tstate.pf = family;\n\t\terr = nf_conntrack_in(skb, &state);\n\t\tif (err != NF_ACCEPT)\n\t\t\tgoto out_push;\n\t}\n\ndo_nat:\n\tct = nf_ct_get(skb, &ctinfo);\n\tif (!ct)\n\t\tgoto out_push;\n\tnf_ct_deliver_cached_events(ct);\n\tnf_conn_act_ct_ext_fill(skb, ct, ctinfo);\n\n\terr = tcf_ct_act_nat(skb, ct, ctinfo, p->ct_action, &p->range, commit);\n\tif (err != NF_ACCEPT)\n\t\tgoto drop;\n\n\tif (!nf_ct_is_confirmed(ct) && commit && p->helper && !nfct_help(ct)) {\n\t\terr = __nf_ct_try_assign_helper(ct, p->tmpl, GFP_ATOMIC);\n\t\tif (err)\n\t\t\tgoto drop;\n\t\tadd_helper = true;\n\t\tif (p->ct_action & TCA_CT_ACT_NAT && !nfct_seqadj(ct)) {\n\t\t\tif (!nfct_seqadj_ext_add(ct))\n\t\t\t\tgoto drop;\n\t\t}\n\t}\n\n\tif (nf_ct_is_confirmed(ct) ? ((!cached && !skip_add) || add_helper) : commit) {\n\t\tif (nf_ct_helper(skb, ct, ctinfo, family) != NF_ACCEPT)\n\t\t\tgoto drop;\n\t}\n\n\tif (commit) {\n\t\ttcf_ct_act_set_mark(ct, p->mark, p->mark_mask);\n\t\ttcf_ct_act_set_labels(ct, p->labels, p->labels_mask);\n\n\t\tif (!nf_ct_is_confirmed(ct))\n\t\t\tnf_conn_act_ct_ext_add(skb, ct, ctinfo);\n\n\t\t \n\t\tif (nf_conntrack_confirm(skb) != NF_ACCEPT)\n\t\t\tgoto drop;\n\t}\n\n\tif (!skip_add)\n\t\ttcf_ct_flow_table_process_conn(p->ct_ft, ct, ctinfo);\n\nout_push:\n\tskb_push_rcsum(skb, nh_ofs);\n\n\ttc_skb_cb(skb)->post_ct = true;\n\ttc_skb_cb(skb)->zone = p->zone;\nout_clear:\n\tif (defrag)\n\t\tqdisc_skb_cb(skb)->pkt_len = skb->len;\n\treturn retval;\n\nout_frag:\n\tif (err != -EINPROGRESS)\n\t\ttcf_action_inc_drop_qstats(&c->common);\n\treturn TC_ACT_CONSUMED;\n\ndrop:\n\ttcf_action_inc_drop_qstats(&c->common);\n\treturn TC_ACT_SHOT;\n}\n\nstatic const struct nla_policy ct_policy[TCA_CT_MAX + 1] = {\n\t[TCA_CT_ACTION] = { .type = NLA_U16 },\n\t[TCA_CT_PARMS] = NLA_POLICY_EXACT_LEN(sizeof(struct tc_ct)),\n\t[TCA_CT_ZONE] = { .type = NLA_U16 },\n\t[TCA_CT_MARK] = { .type = NLA_U32 },\n\t[TCA_CT_MARK_MASK] = { .type = NLA_U32 },\n\t[TCA_CT_LABELS] = { .type = NLA_BINARY,\n\t\t\t    .len = 128 / BITS_PER_BYTE },\n\t[TCA_CT_LABELS_MASK] = { .type = NLA_BINARY,\n\t\t\t\t .len = 128 / BITS_PER_BYTE },\n\t[TCA_CT_NAT_IPV4_MIN] = { .type = NLA_U32 },\n\t[TCA_CT_NAT_IPV4_MAX] = { .type = NLA_U32 },\n\t[TCA_CT_NAT_IPV6_MIN] = NLA_POLICY_EXACT_LEN(sizeof(struct in6_addr)),\n\t[TCA_CT_NAT_IPV6_MAX] = NLA_POLICY_EXACT_LEN(sizeof(struct in6_addr)),\n\t[TCA_CT_NAT_PORT_MIN] = { .type = NLA_U16 },\n\t[TCA_CT_NAT_PORT_MAX] = { .type = NLA_U16 },\n\t[TCA_CT_HELPER_NAME] = { .type = NLA_STRING, .len = NF_CT_HELPER_NAME_LEN },\n\t[TCA_CT_HELPER_FAMILY] = { .type = NLA_U8 },\n\t[TCA_CT_HELPER_PROTO] = { .type = NLA_U8 },\n};\n\nstatic int tcf_ct_fill_params_nat(struct tcf_ct_params *p,\n\t\t\t\t  struct tc_ct *parm,\n\t\t\t\t  struct nlattr **tb,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct nf_nat_range2 *range;\n\n\tif (!(p->ct_action & TCA_CT_ACT_NAT))\n\t\treturn 0;\n\n\tif (!IS_ENABLED(CONFIG_NF_NAT)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Netfilter nat isn't enabled in kernel\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (!(p->ct_action & (TCA_CT_ACT_NAT_SRC | TCA_CT_ACT_NAT_DST)))\n\t\treturn 0;\n\n\tif ((p->ct_action & TCA_CT_ACT_NAT_SRC) &&\n\t    (p->ct_action & TCA_CT_ACT_NAT_DST)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"dnat and snat can't be enabled at the same time\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\trange = &p->range;\n\tif (tb[TCA_CT_NAT_IPV4_MIN]) {\n\t\tstruct nlattr *max_attr = tb[TCA_CT_NAT_IPV4_MAX];\n\n\t\tp->ipv4_range = true;\n\t\trange->flags |= NF_NAT_RANGE_MAP_IPS;\n\t\trange->min_addr.ip =\n\t\t\tnla_get_in_addr(tb[TCA_CT_NAT_IPV4_MIN]);\n\n\t\trange->max_addr.ip = max_attr ?\n\t\t\t\t     nla_get_in_addr(max_attr) :\n\t\t\t\t     range->min_addr.ip;\n\t} else if (tb[TCA_CT_NAT_IPV6_MIN]) {\n\t\tstruct nlattr *max_attr = tb[TCA_CT_NAT_IPV6_MAX];\n\n\t\tp->ipv4_range = false;\n\t\trange->flags |= NF_NAT_RANGE_MAP_IPS;\n\t\trange->min_addr.in6 =\n\t\t\tnla_get_in6_addr(tb[TCA_CT_NAT_IPV6_MIN]);\n\n\t\trange->max_addr.in6 = max_attr ?\n\t\t\t\t      nla_get_in6_addr(max_attr) :\n\t\t\t\t      range->min_addr.in6;\n\t}\n\n\tif (tb[TCA_CT_NAT_PORT_MIN]) {\n\t\trange->flags |= NF_NAT_RANGE_PROTO_SPECIFIED;\n\t\trange->min_proto.all = nla_get_be16(tb[TCA_CT_NAT_PORT_MIN]);\n\n\t\trange->max_proto.all = tb[TCA_CT_NAT_PORT_MAX] ?\n\t\t\t\t       nla_get_be16(tb[TCA_CT_NAT_PORT_MAX]) :\n\t\t\t\t       range->min_proto.all;\n\t}\n\n\treturn 0;\n}\n\nstatic void tcf_ct_set_key_val(struct nlattr **tb,\n\t\t\t       void *val, int val_type,\n\t\t\t       void *mask, int mask_type,\n\t\t\t       int len)\n{\n\tif (!tb[val_type])\n\t\treturn;\n\tnla_memcpy(val, tb[val_type], len);\n\n\tif (!mask)\n\t\treturn;\n\n\tif (mask_type == TCA_CT_UNSPEC || !tb[mask_type])\n\t\tmemset(mask, 0xff, len);\n\telse\n\t\tnla_memcpy(mask, tb[mask_type], len);\n}\n\nstatic int tcf_ct_fill_params(struct net *net,\n\t\t\t      struct tcf_ct_params *p,\n\t\t\t      struct tc_ct *parm,\n\t\t\t      struct nlattr **tb,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct tc_ct_action_net *tn = net_generic(net, act_ct_ops.net_id);\n\tstruct nf_conntrack_zone zone;\n\tint err, family, proto, len;\n\tstruct nf_conn *tmpl;\n\tchar *name;\n\n\tp->zone = NF_CT_DEFAULT_ZONE_ID;\n\n\ttcf_ct_set_key_val(tb,\n\t\t\t   &p->ct_action, TCA_CT_ACTION,\n\t\t\t   NULL, TCA_CT_UNSPEC,\n\t\t\t   sizeof(p->ct_action));\n\n\tif (p->ct_action & TCA_CT_ACT_CLEAR)\n\t\treturn 0;\n\n\terr = tcf_ct_fill_params_nat(p, parm, tb, extack);\n\tif (err)\n\t\treturn err;\n\n\tif (tb[TCA_CT_MARK]) {\n\t\tif (!IS_ENABLED(CONFIG_NF_CONNTRACK_MARK)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Conntrack mark isn't enabled.\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\ttcf_ct_set_key_val(tb,\n\t\t\t\t   &p->mark, TCA_CT_MARK,\n\t\t\t\t   &p->mark_mask, TCA_CT_MARK_MASK,\n\t\t\t\t   sizeof(p->mark));\n\t}\n\n\tif (tb[TCA_CT_LABELS]) {\n\t\tif (!IS_ENABLED(CONFIG_NF_CONNTRACK_LABELS)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Conntrack labels isn't enabled.\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tif (!tn->labels) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to set connlabel length\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\ttcf_ct_set_key_val(tb,\n\t\t\t\t   p->labels, TCA_CT_LABELS,\n\t\t\t\t   p->labels_mask, TCA_CT_LABELS_MASK,\n\t\t\t\t   sizeof(p->labels));\n\t}\n\n\tif (tb[TCA_CT_ZONE]) {\n\t\tif (!IS_ENABLED(CONFIG_NF_CONNTRACK_ZONES)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Conntrack zones isn't enabled.\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\ttcf_ct_set_key_val(tb,\n\t\t\t\t   &p->zone, TCA_CT_ZONE,\n\t\t\t\t   NULL, TCA_CT_UNSPEC,\n\t\t\t\t   sizeof(p->zone));\n\t}\n\n\tnf_ct_zone_init(&zone, p->zone, NF_CT_DEFAULT_ZONE_DIR, 0);\n\ttmpl = nf_ct_tmpl_alloc(net, &zone, GFP_KERNEL);\n\tif (!tmpl) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to allocate conntrack template\");\n\t\treturn -ENOMEM;\n\t}\n\tp->tmpl = tmpl;\n\tif (tb[TCA_CT_HELPER_NAME]) {\n\t\tname = nla_data(tb[TCA_CT_HELPER_NAME]);\n\t\tlen = nla_len(tb[TCA_CT_HELPER_NAME]);\n\t\tif (len > 16 || name[len - 1] != '\\0') {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to parse helper name.\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t\tfamily = tb[TCA_CT_HELPER_FAMILY] ? nla_get_u8(tb[TCA_CT_HELPER_FAMILY]) : AF_INET;\n\t\tproto = tb[TCA_CT_HELPER_PROTO] ? nla_get_u8(tb[TCA_CT_HELPER_PROTO]) : IPPROTO_TCP;\n\t\terr = nf_ct_add_helper(tmpl, name, family, proto,\n\t\t\t\t       p->ct_action & TCA_CT_ACT_NAT, &p->helper);\n\t\tif (err) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to add helper\");\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tif (p->ct_action & TCA_CT_ACT_COMMIT)\n\t\t__set_bit(IPS_CONFIRMED_BIT, &tmpl->status);\n\treturn 0;\nerr:\n\tnf_ct_put(p->tmpl);\n\tp->tmpl = NULL;\n\treturn err;\n}\n\nstatic int tcf_ct_init(struct net *net, struct nlattr *nla,\n\t\t       struct nlattr *est, struct tc_action **a,\n\t\t       struct tcf_proto *tp, u32 flags,\n\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct tc_action_net *tn = net_generic(net, act_ct_ops.net_id);\n\tbool bind = flags & TCA_ACT_FLAGS_BIND;\n\tstruct tcf_ct_params *params = NULL;\n\tstruct nlattr *tb[TCA_CT_MAX + 1];\n\tstruct tcf_chain *goto_ch = NULL;\n\tstruct tc_ct *parm;\n\tstruct tcf_ct *c;\n\tint err, res = 0;\n\tu32 index;\n\n\tif (!nla) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Ct requires attributes to be passed\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = nla_parse_nested(tb, TCA_CT_MAX, nla, ct_policy, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (!tb[TCA_CT_PARMS]) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Missing required ct parameters\");\n\t\treturn -EINVAL;\n\t}\n\tparm = nla_data(tb[TCA_CT_PARMS]);\n\tindex = parm->index;\n\terr = tcf_idr_check_alloc(tn, &index, a, bind);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (!err) {\n\t\terr = tcf_idr_create_from_flags(tn, index, est, a,\n\t\t\t\t\t\t&act_ct_ops, bind, flags);\n\t\tif (err) {\n\t\t\ttcf_idr_cleanup(tn, index);\n\t\t\treturn err;\n\t\t}\n\t\tres = ACT_P_CREATED;\n\t} else {\n\t\tif (bind)\n\t\t\treturn 0;\n\n\t\tif (!(flags & TCA_ACT_FLAGS_REPLACE)) {\n\t\t\ttcf_idr_release(*a, bind);\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\terr = tcf_action_check_ctrlact(parm->action, tp, &goto_ch, extack);\n\tif (err < 0)\n\t\tgoto cleanup;\n\n\tc = to_ct(*a);\n\n\tparams = kzalloc(sizeof(*params), GFP_KERNEL);\n\tif (unlikely(!params)) {\n\t\terr = -ENOMEM;\n\t\tgoto cleanup;\n\t}\n\n\terr = tcf_ct_fill_params(net, params, parm, tb, extack);\n\tif (err)\n\t\tgoto cleanup;\n\n\terr = tcf_ct_flow_table_get(net, params);\n\tif (err)\n\t\tgoto cleanup;\n\n\tspin_lock_bh(&c->tcf_lock);\n\tgoto_ch = tcf_action_set_ctrlact(*a, parm->action, goto_ch);\n\tparams = rcu_replace_pointer(c->params, params,\n\t\t\t\t     lockdep_is_held(&c->tcf_lock));\n\tspin_unlock_bh(&c->tcf_lock);\n\n\tif (goto_ch)\n\t\ttcf_chain_put_by_act(goto_ch);\n\tif (params)\n\t\tcall_rcu(&params->rcu, tcf_ct_params_free_rcu);\n\n\treturn res;\n\ncleanup:\n\tif (goto_ch)\n\t\ttcf_chain_put_by_act(goto_ch);\n\tif (params)\n\t\ttcf_ct_params_free(params);\n\ttcf_idr_release(*a, bind);\n\treturn err;\n}\n\nstatic void tcf_ct_cleanup(struct tc_action *a)\n{\n\tstruct tcf_ct_params *params;\n\tstruct tcf_ct *c = to_ct(a);\n\n\tparams = rcu_dereference_protected(c->params, 1);\n\tif (params)\n\t\tcall_rcu(&params->rcu, tcf_ct_params_free_rcu);\n}\n\nstatic int tcf_ct_dump_key_val(struct sk_buff *skb,\n\t\t\t       void *val, int val_type,\n\t\t\t       void *mask, int mask_type,\n\t\t\t       int len)\n{\n\tint err;\n\n\tif (mask && !memchr_inv(mask, 0, len))\n\t\treturn 0;\n\n\terr = nla_put(skb, val_type, len, val);\n\tif (err)\n\t\treturn err;\n\n\tif (mask_type != TCA_CT_UNSPEC) {\n\t\terr = nla_put(skb, mask_type, len, mask);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int tcf_ct_dump_nat(struct sk_buff *skb, struct tcf_ct_params *p)\n{\n\tstruct nf_nat_range2 *range = &p->range;\n\n\tif (!(p->ct_action & TCA_CT_ACT_NAT))\n\t\treturn 0;\n\n\tif (!(p->ct_action & (TCA_CT_ACT_NAT_SRC | TCA_CT_ACT_NAT_DST)))\n\t\treturn 0;\n\n\tif (range->flags & NF_NAT_RANGE_MAP_IPS) {\n\t\tif (p->ipv4_range) {\n\t\t\tif (nla_put_in_addr(skb, TCA_CT_NAT_IPV4_MIN,\n\t\t\t\t\t    range->min_addr.ip))\n\t\t\t\treturn -1;\n\t\t\tif (nla_put_in_addr(skb, TCA_CT_NAT_IPV4_MAX,\n\t\t\t\t\t    range->max_addr.ip))\n\t\t\t\treturn -1;\n\t\t} else {\n\t\t\tif (nla_put_in6_addr(skb, TCA_CT_NAT_IPV6_MIN,\n\t\t\t\t\t     &range->min_addr.in6))\n\t\t\t\treturn -1;\n\t\t\tif (nla_put_in6_addr(skb, TCA_CT_NAT_IPV6_MAX,\n\t\t\t\t\t     &range->max_addr.in6))\n\t\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (range->flags & NF_NAT_RANGE_PROTO_SPECIFIED) {\n\t\tif (nla_put_be16(skb, TCA_CT_NAT_PORT_MIN,\n\t\t\t\t range->min_proto.all))\n\t\t\treturn -1;\n\t\tif (nla_put_be16(skb, TCA_CT_NAT_PORT_MAX,\n\t\t\t\t range->max_proto.all))\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nstatic int tcf_ct_dump_helper(struct sk_buff *skb, struct nf_conntrack_helper *helper)\n{\n\tif (!helper)\n\t\treturn 0;\n\n\tif (nla_put_string(skb, TCA_CT_HELPER_NAME, helper->name) ||\n\t    nla_put_u8(skb, TCA_CT_HELPER_FAMILY, helper->tuple.src.l3num) ||\n\t    nla_put_u8(skb, TCA_CT_HELPER_PROTO, helper->tuple.dst.protonum))\n\t\treturn -1;\n\n\treturn 0;\n}\n\nstatic inline int tcf_ct_dump(struct sk_buff *skb, struct tc_action *a,\n\t\t\t      int bind, int ref)\n{\n\tunsigned char *b = skb_tail_pointer(skb);\n\tstruct tcf_ct *c = to_ct(a);\n\tstruct tcf_ct_params *p;\n\n\tstruct tc_ct opt = {\n\t\t.index   = c->tcf_index,\n\t\t.refcnt  = refcount_read(&c->tcf_refcnt) - ref,\n\t\t.bindcnt = atomic_read(&c->tcf_bindcnt) - bind,\n\t};\n\tstruct tcf_t t;\n\n\tspin_lock_bh(&c->tcf_lock);\n\tp = rcu_dereference_protected(c->params,\n\t\t\t\t      lockdep_is_held(&c->tcf_lock));\n\topt.action = c->tcf_action;\n\n\tif (tcf_ct_dump_key_val(skb,\n\t\t\t\t&p->ct_action, TCA_CT_ACTION,\n\t\t\t\tNULL, TCA_CT_UNSPEC,\n\t\t\t\tsizeof(p->ct_action)))\n\t\tgoto nla_put_failure;\n\n\tif (p->ct_action & TCA_CT_ACT_CLEAR)\n\t\tgoto skip_dump;\n\n\tif (IS_ENABLED(CONFIG_NF_CONNTRACK_MARK) &&\n\t    tcf_ct_dump_key_val(skb,\n\t\t\t\t&p->mark, TCA_CT_MARK,\n\t\t\t\t&p->mark_mask, TCA_CT_MARK_MASK,\n\t\t\t\tsizeof(p->mark)))\n\t\tgoto nla_put_failure;\n\n\tif (IS_ENABLED(CONFIG_NF_CONNTRACK_LABELS) &&\n\t    tcf_ct_dump_key_val(skb,\n\t\t\t\tp->labels, TCA_CT_LABELS,\n\t\t\t\tp->labels_mask, TCA_CT_LABELS_MASK,\n\t\t\t\tsizeof(p->labels)))\n\t\tgoto nla_put_failure;\n\n\tif (IS_ENABLED(CONFIG_NF_CONNTRACK_ZONES) &&\n\t    tcf_ct_dump_key_val(skb,\n\t\t\t\t&p->zone, TCA_CT_ZONE,\n\t\t\t\tNULL, TCA_CT_UNSPEC,\n\t\t\t\tsizeof(p->zone)))\n\t\tgoto nla_put_failure;\n\n\tif (tcf_ct_dump_nat(skb, p))\n\t\tgoto nla_put_failure;\n\n\tif (tcf_ct_dump_helper(skb, p->helper))\n\t\tgoto nla_put_failure;\n\nskip_dump:\n\tif (nla_put(skb, TCA_CT_PARMS, sizeof(opt), &opt))\n\t\tgoto nla_put_failure;\n\n\ttcf_tm_dump(&t, &c->tcf_tm);\n\tif (nla_put_64bit(skb, TCA_CT_TM, sizeof(t), &t, TCA_CT_PAD))\n\t\tgoto nla_put_failure;\n\tspin_unlock_bh(&c->tcf_lock);\n\n\treturn skb->len;\nnla_put_failure:\n\tspin_unlock_bh(&c->tcf_lock);\n\tnlmsg_trim(skb, b);\n\treturn -1;\n}\n\nstatic void tcf_stats_update(struct tc_action *a, u64 bytes, u64 packets,\n\t\t\t     u64 drops, u64 lastuse, bool hw)\n{\n\tstruct tcf_ct *c = to_ct(a);\n\n\ttcf_action_update_stats(a, bytes, packets, drops, hw);\n\tc->tcf_tm.lastuse = max_t(u64, c->tcf_tm.lastuse, lastuse);\n}\n\nstatic int tcf_ct_offload_act_setup(struct tc_action *act, void *entry_data,\n\t\t\t\t    u32 *index_inc, bool bind,\n\t\t\t\t    struct netlink_ext_ack *extack)\n{\n\tif (bind) {\n\t\tstruct flow_action_entry *entry = entry_data;\n\n\t\tif (tcf_ct_helper(act))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tentry->id = FLOW_ACTION_CT;\n\t\tentry->ct.action = tcf_ct_action(act);\n\t\tentry->ct.zone = tcf_ct_zone(act);\n\t\tentry->ct.flow_table = tcf_ct_ft(act);\n\t\t*index_inc = 1;\n\t} else {\n\t\tstruct flow_offload_action *fl_action = entry_data;\n\n\t\tfl_action->id = FLOW_ACTION_CT;\n\t}\n\n\treturn 0;\n}\n\nstatic struct tc_action_ops act_ct_ops = {\n\t.kind\t\t=\t\"ct\",\n\t.id\t\t=\tTCA_ID_CT,\n\t.owner\t\t=\tTHIS_MODULE,\n\t.act\t\t=\ttcf_ct_act,\n\t.dump\t\t=\ttcf_ct_dump,\n\t.init\t\t=\ttcf_ct_init,\n\t.cleanup\t=\ttcf_ct_cleanup,\n\t.stats_update\t=\ttcf_stats_update,\n\t.offload_act_setup =\ttcf_ct_offload_act_setup,\n\t.size\t\t=\tsizeof(struct tcf_ct),\n};\n\nstatic __net_init int ct_init_net(struct net *net)\n{\n\tunsigned int n_bits = sizeof_field(struct tcf_ct_params, labels) * 8;\n\tstruct tc_ct_action_net *tn = net_generic(net, act_ct_ops.net_id);\n\n\tif (nf_connlabels_get(net, n_bits - 1)) {\n\t\ttn->labels = false;\n\t\tpr_err(\"act_ct: Failed to set connlabels length\");\n\t} else {\n\t\ttn->labels = true;\n\t}\n\n\treturn tc_action_net_init(net, &tn->tn, &act_ct_ops);\n}\n\nstatic void __net_exit ct_exit_net(struct list_head *net_list)\n{\n\tstruct net *net;\n\n\trtnl_lock();\n\tlist_for_each_entry(net, net_list, exit_list) {\n\t\tstruct tc_ct_action_net *tn = net_generic(net, act_ct_ops.net_id);\n\n\t\tif (tn->labels)\n\t\t\tnf_connlabels_put(net);\n\t}\n\trtnl_unlock();\n\n\ttc_action_net_exit(net_list, act_ct_ops.net_id);\n}\n\nstatic struct pernet_operations ct_net_ops = {\n\t.init = ct_init_net,\n\t.exit_batch = ct_exit_net,\n\t.id   = &act_ct_ops.net_id,\n\t.size = sizeof(struct tc_ct_action_net),\n};\n\nstatic int __init ct_init_module(void)\n{\n\tint err;\n\n\tact_ct_wq = alloc_ordered_workqueue(\"act_ct_workqueue\", 0);\n\tif (!act_ct_wq)\n\t\treturn -ENOMEM;\n\n\terr = tcf_ct_flow_tables_init();\n\tif (err)\n\t\tgoto err_tbl_init;\n\n\terr = tcf_register_action(&act_ct_ops, &ct_net_ops);\n\tif (err)\n\t\tgoto err_register;\n\n\tstatic_branch_inc(&tcf_frag_xmit_count);\n\n\treturn 0;\n\nerr_register:\n\ttcf_ct_flow_tables_uninit();\nerr_tbl_init:\n\tdestroy_workqueue(act_ct_wq);\n\treturn err;\n}\n\nstatic void __exit ct_cleanup_module(void)\n{\n\tstatic_branch_dec(&tcf_frag_xmit_count);\n\ttcf_unregister_action(&act_ct_ops, &ct_net_ops);\n\ttcf_ct_flow_tables_uninit();\n\tdestroy_workqueue(act_ct_wq);\n}\n\nmodule_init(ct_init_module);\nmodule_exit(ct_cleanup_module);\nMODULE_AUTHOR(\"Paul Blakey <paulb@mellanox.com>\");\nMODULE_AUTHOR(\"Yossi Kuperman <yossiku@mellanox.com>\");\nMODULE_AUTHOR(\"Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>\");\nMODULE_DESCRIPTION(\"Connection tracking action\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}