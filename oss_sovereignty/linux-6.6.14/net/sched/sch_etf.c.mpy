{
  "module_name": "sch_etf.c",
  "hash_id": "72b98431b53c727bc8225886db0b5c725a93bc5cf24207b786d5df42e5313b66",
  "original_prompt": "Ingested from linux-6.6.14/net/sched/sch_etf.c",
  "human_readable_source": "\n\n \n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include <linux/errno.h>\n#include <linux/errqueue.h>\n#include <linux/rbtree.h>\n#include <linux/skbuff.h>\n#include <linux/posix-timers.h>\n#include <net/netlink.h>\n#include <net/sch_generic.h>\n#include <net/pkt_sched.h>\n#include <net/sock.h>\n\n#define DEADLINE_MODE_IS_ON(x) ((x)->flags & TC_ETF_DEADLINE_MODE_ON)\n#define OFFLOAD_IS_ON(x) ((x)->flags & TC_ETF_OFFLOAD_ON)\n#define SKIP_SOCK_CHECK_IS_SET(x) ((x)->flags & TC_ETF_SKIP_SOCK_CHECK)\n\nstruct etf_sched_data {\n\tbool offload;\n\tbool deadline_mode;\n\tbool skip_sock_check;\n\tint clockid;\n\tint queue;\n\ts32 delta;  \n\tktime_t last;  \n\tstruct rb_root_cached head;\n\tstruct qdisc_watchdog watchdog;\n\tktime_t (*get_time)(void);\n};\n\nstatic const struct nla_policy etf_policy[TCA_ETF_MAX + 1] = {\n\t[TCA_ETF_PARMS]\t= { .len = sizeof(struct tc_etf_qopt) },\n};\n\nstatic inline int validate_input_params(struct tc_etf_qopt *qopt,\n\t\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\t \n\tif (qopt->clockid < 0) {\n\t\tNL_SET_ERR_MSG(extack, \"Dynamic clockids are not supported\");\n\t\treturn -ENOTSUPP;\n\t}\n\n\tif (qopt->clockid != CLOCK_TAI) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid clockid. CLOCK_TAI must be used\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (qopt->delta < 0) {\n\t\tNL_SET_ERR_MSG(extack, \"Delta must be positive\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic bool is_packet_valid(struct Qdisc *sch, struct sk_buff *nskb)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\tktime_t txtime = nskb->tstamp;\n\tstruct sock *sk = nskb->sk;\n\tktime_t now;\n\n\tif (q->skip_sock_check)\n\t\tgoto skip;\n\n\tif (!sk || !sk_fullsock(sk))\n\t\treturn false;\n\n\tif (!sock_flag(sk, SOCK_TXTIME))\n\t\treturn false;\n\n\t \n\tif (sk->sk_clockid != q->clockid)\n\t\treturn false;\n\n\tif (sk->sk_txtime_deadline_mode != q->deadline_mode)\n\t\treturn false;\n\nskip:\n\tnow = q->get_time();\n\tif (ktime_before(txtime, now) || ktime_before(txtime, q->last))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic struct sk_buff *etf_peek_timesortedlist(struct Qdisc *sch)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\tstruct rb_node *p;\n\n\tp = rb_first_cached(&q->head);\n\tif (!p)\n\t\treturn NULL;\n\n\treturn rb_to_skb(p);\n}\n\nstatic void reset_watchdog(struct Qdisc *sch)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\tstruct sk_buff *skb = etf_peek_timesortedlist(sch);\n\tktime_t next;\n\n\tif (!skb) {\n\t\tqdisc_watchdog_cancel(&q->watchdog);\n\t\treturn;\n\t}\n\n\tnext = ktime_sub_ns(skb->tstamp, q->delta);\n\tqdisc_watchdog_schedule_ns(&q->watchdog, ktime_to_ns(next));\n}\n\nstatic void report_sock_error(struct sk_buff *skb, u32 err, u8 code)\n{\n\tstruct sock_exterr_skb *serr;\n\tstruct sk_buff *clone;\n\tktime_t txtime = skb->tstamp;\n\tstruct sock *sk = skb->sk;\n\n\tif (!sk || !sk_fullsock(sk) || !(sk->sk_txtime_report_errors))\n\t\treturn;\n\n\tclone = skb_clone(skb, GFP_ATOMIC);\n\tif (!clone)\n\t\treturn;\n\n\tserr = SKB_EXT_ERR(clone);\n\tserr->ee.ee_errno = err;\n\tserr->ee.ee_origin = SO_EE_ORIGIN_TXTIME;\n\tserr->ee.ee_type = 0;\n\tserr->ee.ee_code = code;\n\tserr->ee.ee_pad = 0;\n\tserr->ee.ee_data = (txtime >> 32);  \n\tserr->ee.ee_info = txtime;  \n\n\tif (sock_queue_err_skb(sk, clone))\n\t\tkfree_skb(clone);\n}\n\nstatic int etf_enqueue_timesortedlist(struct sk_buff *nskb, struct Qdisc *sch,\n\t\t\t\t      struct sk_buff **to_free)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\tstruct rb_node **p = &q->head.rb_root.rb_node, *parent = NULL;\n\tktime_t txtime = nskb->tstamp;\n\tbool leftmost = true;\n\n\tif (!is_packet_valid(sch, nskb)) {\n\t\treport_sock_error(nskb, EINVAL,\n\t\t\t\t  SO_EE_CODE_TXTIME_INVALID_PARAM);\n\t\treturn qdisc_drop(nskb, sch, to_free);\n\t}\n\n\twhile (*p) {\n\t\tstruct sk_buff *skb;\n\n\t\tparent = *p;\n\t\tskb = rb_to_skb(parent);\n\t\tif (ktime_compare(txtime, skb->tstamp) >= 0) {\n\t\t\tp = &parent->rb_right;\n\t\t\tleftmost = false;\n\t\t} else {\n\t\t\tp = &parent->rb_left;\n\t\t}\n\t}\n\trb_link_node(&nskb->rbnode, parent, p);\n\trb_insert_color_cached(&nskb->rbnode, &q->head, leftmost);\n\n\tqdisc_qstats_backlog_inc(sch, nskb);\n\tsch->q.qlen++;\n\n\t \n\treset_watchdog(sch);\n\n\treturn NET_XMIT_SUCCESS;\n}\n\nstatic void timesortedlist_drop(struct Qdisc *sch, struct sk_buff *skb,\n\t\t\t\tktime_t now)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\tstruct sk_buff *to_free = NULL;\n\tstruct sk_buff *tmp = NULL;\n\n\tskb_rbtree_walk_from_safe(skb, tmp) {\n\t\tif (ktime_after(skb->tstamp, now))\n\t\t\tbreak;\n\n\t\trb_erase_cached(&skb->rbnode, &q->head);\n\n\t\t \n\t\tskb->next = NULL;\n\t\tskb->prev = NULL;\n\t\tskb->dev = qdisc_dev(sch);\n\n\t\treport_sock_error(skb, ECANCELED, SO_EE_CODE_TXTIME_MISSED);\n\n\t\tqdisc_qstats_backlog_dec(sch, skb);\n\t\tqdisc_drop(skb, sch, &to_free);\n\t\tqdisc_qstats_overlimit(sch);\n\t\tsch->q.qlen--;\n\t}\n\n\tkfree_skb_list(to_free);\n}\n\nstatic void timesortedlist_remove(struct Qdisc *sch, struct sk_buff *skb)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\n\trb_erase_cached(&skb->rbnode, &q->head);\n\n\t \n\tskb->next = NULL;\n\tskb->prev = NULL;\n\tskb->dev = qdisc_dev(sch);\n\n\tqdisc_qstats_backlog_dec(sch, skb);\n\n\tqdisc_bstats_update(sch, skb);\n\n\tq->last = skb->tstamp;\n\n\tsch->q.qlen--;\n}\n\nstatic struct sk_buff *etf_dequeue_timesortedlist(struct Qdisc *sch)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\tstruct sk_buff *skb;\n\tktime_t now, next;\n\n\tskb = etf_peek_timesortedlist(sch);\n\tif (!skb)\n\t\treturn NULL;\n\n\tnow = q->get_time();\n\n\t \n\tif (ktime_before(skb->tstamp, now)) {\n\t\ttimesortedlist_drop(sch, skb, now);\n\t\tskb = NULL;\n\t\tgoto out;\n\t}\n\n\t \n\tif (q->deadline_mode) {\n\t\ttimesortedlist_remove(sch, skb);\n\t\tskb->tstamp = now;\n\t\tgoto out;\n\t}\n\n\tnext = ktime_sub_ns(skb->tstamp, q->delta);\n\n\t \n\tif (ktime_after(now, next))\n\t\ttimesortedlist_remove(sch, skb);\n\telse\n\t\tskb = NULL;\n\nout:\n\t \n\treset_watchdog(sch);\n\n\treturn skb;\n}\n\nstatic void etf_disable_offload(struct net_device *dev,\n\t\t\t\tstruct etf_sched_data *q)\n{\n\tstruct tc_etf_qopt_offload etf = { };\n\tconst struct net_device_ops *ops;\n\tint err;\n\n\tif (!q->offload)\n\t\treturn;\n\n\tops = dev->netdev_ops;\n\tif (!ops->ndo_setup_tc)\n\t\treturn;\n\n\tetf.queue = q->queue;\n\tetf.enable = 0;\n\n\terr = ops->ndo_setup_tc(dev, TC_SETUP_QDISC_ETF, &etf);\n\tif (err < 0)\n\t\tpr_warn(\"Couldn't disable ETF offload for queue %d\\n\",\n\t\t\tetf.queue);\n}\n\nstatic int etf_enable_offload(struct net_device *dev, struct etf_sched_data *q,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tconst struct net_device_ops *ops = dev->netdev_ops;\n\tstruct tc_etf_qopt_offload etf = { };\n\tint err;\n\n\tif (!ops->ndo_setup_tc) {\n\t\tNL_SET_ERR_MSG(extack, \"Specified device does not support ETF offload\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tetf.queue = q->queue;\n\tetf.enable = 1;\n\n\terr = ops->ndo_setup_tc(dev, TC_SETUP_QDISC_ETF, &etf);\n\tif (err < 0) {\n\t\tNL_SET_ERR_MSG(extack, \"Specified device failed to setup ETF hardware offload\");\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int etf_init(struct Qdisc *sch, struct nlattr *opt,\n\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\tstruct net_device *dev = qdisc_dev(sch);\n\tstruct nlattr *tb[TCA_ETF_MAX + 1];\n\tstruct tc_etf_qopt *qopt;\n\tint err;\n\n\tif (!opt) {\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"Missing ETF qdisc options which are mandatory\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = nla_parse_nested_deprecated(tb, TCA_ETF_MAX, opt, etf_policy,\n\t\t\t\t\t  extack);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (!tb[TCA_ETF_PARMS]) {\n\t\tNL_SET_ERR_MSG(extack, \"Missing mandatory ETF parameters\");\n\t\treturn -EINVAL;\n\t}\n\n\tqopt = nla_data(tb[TCA_ETF_PARMS]);\n\n\tpr_debug(\"delta %d clockid %d offload %s deadline %s\\n\",\n\t\t qopt->delta, qopt->clockid,\n\t\t OFFLOAD_IS_ON(qopt) ? \"on\" : \"off\",\n\t\t DEADLINE_MODE_IS_ON(qopt) ? \"on\" : \"off\");\n\n\terr = validate_input_params(qopt, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\tq->queue = sch->dev_queue - netdev_get_tx_queue(dev, 0);\n\n\tif (OFFLOAD_IS_ON(qopt)) {\n\t\terr = etf_enable_offload(dev, q, extack);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\t \n\tq->delta = qopt->delta;\n\tq->clockid = qopt->clockid;\n\tq->offload = OFFLOAD_IS_ON(qopt);\n\tq->deadline_mode = DEADLINE_MODE_IS_ON(qopt);\n\tq->skip_sock_check = SKIP_SOCK_CHECK_IS_SET(qopt);\n\n\tswitch (q->clockid) {\n\tcase CLOCK_REALTIME:\n\t\tq->get_time = ktime_get_real;\n\t\tbreak;\n\tcase CLOCK_MONOTONIC:\n\t\tq->get_time = ktime_get;\n\t\tbreak;\n\tcase CLOCK_BOOTTIME:\n\t\tq->get_time = ktime_get_boottime;\n\t\tbreak;\n\tcase CLOCK_TAI:\n\t\tq->get_time = ktime_get_clocktai;\n\t\tbreak;\n\tdefault:\n\t\tNL_SET_ERR_MSG(extack, \"Clockid is not supported\");\n\t\treturn -ENOTSUPP;\n\t}\n\n\tqdisc_watchdog_init_clockid(&q->watchdog, sch, q->clockid);\n\n\treturn 0;\n}\n\nstatic void timesortedlist_clear(struct Qdisc *sch)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\tstruct rb_node *p = rb_first_cached(&q->head);\n\n\twhile (p) {\n\t\tstruct sk_buff *skb = rb_to_skb(p);\n\n\t\tp = rb_next(p);\n\n\t\trb_erase_cached(&skb->rbnode, &q->head);\n\t\trtnl_kfree_skbs(skb, skb);\n\t\tsch->q.qlen--;\n\t}\n}\n\nstatic void etf_reset(struct Qdisc *sch)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\n\t \n\tif (q->watchdog.qdisc == sch)\n\t\tqdisc_watchdog_cancel(&q->watchdog);\n\n\t \n\ttimesortedlist_clear(sch);\n\t__qdisc_reset_queue(&sch->q);\n\n\tq->last = 0;\n}\n\nstatic void etf_destroy(struct Qdisc *sch)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\tstruct net_device *dev = qdisc_dev(sch);\n\n\t \n\tif (q->watchdog.qdisc == sch)\n\t\tqdisc_watchdog_cancel(&q->watchdog);\n\n\tetf_disable_offload(dev, q);\n}\n\nstatic int etf_dump(struct Qdisc *sch, struct sk_buff *skb)\n{\n\tstruct etf_sched_data *q = qdisc_priv(sch);\n\tstruct tc_etf_qopt opt = { };\n\tstruct nlattr *nest;\n\n\tnest = nla_nest_start_noflag(skb, TCA_OPTIONS);\n\tif (!nest)\n\t\tgoto nla_put_failure;\n\n\topt.delta = q->delta;\n\topt.clockid = q->clockid;\n\tif (q->offload)\n\t\topt.flags |= TC_ETF_OFFLOAD_ON;\n\n\tif (q->deadline_mode)\n\t\topt.flags |= TC_ETF_DEADLINE_MODE_ON;\n\n\tif (q->skip_sock_check)\n\t\topt.flags |= TC_ETF_SKIP_SOCK_CHECK;\n\n\tif (nla_put(skb, TCA_ETF_PARMS, sizeof(opt), &opt))\n\t\tgoto nla_put_failure;\n\n\treturn nla_nest_end(skb, nest);\n\nnla_put_failure:\n\tnla_nest_cancel(skb, nest);\n\treturn -1;\n}\n\nstatic struct Qdisc_ops etf_qdisc_ops __read_mostly = {\n\t.id\t\t=\t\"etf\",\n\t.priv_size\t=\tsizeof(struct etf_sched_data),\n\t.enqueue\t=\tetf_enqueue_timesortedlist,\n\t.dequeue\t=\tetf_dequeue_timesortedlist,\n\t.peek\t\t=\tetf_peek_timesortedlist,\n\t.init\t\t=\tetf_init,\n\t.reset\t\t=\tetf_reset,\n\t.destroy\t=\tetf_destroy,\n\t.dump\t\t=\tetf_dump,\n\t.owner\t\t=\tTHIS_MODULE,\n};\n\nstatic int __init etf_module_init(void)\n{\n\treturn register_qdisc(&etf_qdisc_ops);\n}\n\nstatic void __exit etf_module_exit(void)\n{\n\tunregister_qdisc(&etf_qdisc_ops);\n}\nmodule_init(etf_module_init)\nmodule_exit(etf_module_exit)\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}