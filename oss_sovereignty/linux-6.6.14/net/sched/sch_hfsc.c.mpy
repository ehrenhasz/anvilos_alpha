{
  "module_name": "sch_hfsc.c",
  "hash_id": "a5ec4c884e315f22264fbcb28596242bd13709e7e9439ed7af5ca4c4f0bd5ea4",
  "original_prompt": "Ingested from linux-6.6.14/net/sched/sch_hfsc.c",
  "human_readable_source": " \n \n \n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/compiler.h>\n#include <linux/spinlock.h>\n#include <linux/skbuff.h>\n#include <linux/string.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/rbtree.h>\n#include <linux/init.h>\n#include <linux/rtnetlink.h>\n#include <linux/pkt_sched.h>\n#include <net/netlink.h>\n#include <net/pkt_sched.h>\n#include <net/pkt_cls.h>\n#include <asm/div64.h>\n\n \n\nstruct internal_sc {\n\tu64\tsm1;\t \n\tu64\tism1;\t \n\tu64\tdx;\t \n\tu64\tdy;\t \n\tu64\tsm2;\t \n\tu64\tism2;\t \n};\n\n \nstruct runtime_sc {\n\tu64\tx;\t \n\tu64\ty;\t \n\tu64\tsm1;\t \n\tu64\tism1;\t \n\tu64\tdx;\t \n\tu64\tdy;\t \n\tu64\tsm2;\t \n\tu64\tism2;\t \n};\n\nenum hfsc_class_flags {\n\tHFSC_RSC = 0x1,\n\tHFSC_FSC = 0x2,\n\tHFSC_USC = 0x4\n};\n\nstruct hfsc_class {\n\tstruct Qdisc_class_common cl_common;\n\n\tstruct gnet_stats_basic_sync bstats;\n\tstruct gnet_stats_queue qstats;\n\tstruct net_rate_estimator __rcu *rate_est;\n\tstruct tcf_proto __rcu *filter_list;  \n\tstruct tcf_block *block;\n\tunsigned int\tlevel;\t\t \n\n\tstruct hfsc_sched *sched;\t \n\tstruct hfsc_class *cl_parent;\t \n\tstruct list_head siblings;\t \n\tstruct list_head children;\t \n\tstruct Qdisc\t*qdisc;\t\t \n\n\tstruct rb_node el_node;\t\t \n\tstruct rb_root vt_tree;\t\t \n\tstruct rb_node vt_node;\t\t \n\tstruct rb_root cf_tree;\t\t \n\tstruct rb_node cf_node;\t\t \n\n\tu64\tcl_total;\t\t \n\tu64\tcl_cumul;\t\t \n\n\tu64\tcl_d;\t\t\t \n\tu64\tcl_e;\t\t\t \n\tu64\tcl_vt;\t\t\t \n\tu64\tcl_f;\t\t\t \n\tu64\tcl_myf;\t\t\t \n\tu64\tcl_cfmin;\t\t \n\tu64\tcl_cvtmin;\t\t \n\tu64\tcl_vtadj;\t\t \n\tu64\tcl_cvtoff;\t\t \n\n\tstruct internal_sc cl_rsc;\t \n\tstruct internal_sc cl_fsc;\t \n\tstruct internal_sc cl_usc;\t \n\tstruct runtime_sc cl_deadline;\t \n\tstruct runtime_sc cl_eligible;\t \n\tstruct runtime_sc cl_virtual;\t \n\tstruct runtime_sc cl_ulimit;\t \n\n\tu8\t\tcl_flags;\t \n\tu32\t\tcl_vtperiod;\t \n\tu32\t\tcl_parentperiod; \n\tu32\t\tcl_nactive;\t \n};\n\nstruct hfsc_sched {\n\tu16\tdefcls;\t\t\t\t \n\tstruct hfsc_class root;\t\t\t \n\tstruct Qdisc_class_hash clhash;\t\t \n\tstruct rb_root eligible;\t\t \n\tstruct qdisc_watchdog watchdog;\t\t \n};\n\n#define\tHT_INFINITY\t0xffffffffffffffffULL\t \n\n\n \n\nstatic void\neltree_insert(struct hfsc_class *cl)\n{\n\tstruct rb_node **p = &cl->sched->eligible.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct hfsc_class *cl1;\n\n\twhile (*p != NULL) {\n\t\tparent = *p;\n\t\tcl1 = rb_entry(parent, struct hfsc_class, el_node);\n\t\tif (cl->cl_e >= cl1->cl_e)\n\t\t\tp = &parent->rb_right;\n\t\telse\n\t\t\tp = &parent->rb_left;\n\t}\n\trb_link_node(&cl->el_node, parent, p);\n\trb_insert_color(&cl->el_node, &cl->sched->eligible);\n}\n\nstatic inline void\neltree_remove(struct hfsc_class *cl)\n{\n\trb_erase(&cl->el_node, &cl->sched->eligible);\n}\n\nstatic inline void\neltree_update(struct hfsc_class *cl)\n{\n\teltree_remove(cl);\n\teltree_insert(cl);\n}\n\n \nstatic inline struct hfsc_class *\neltree_get_mindl(struct hfsc_sched *q, u64 cur_time)\n{\n\tstruct hfsc_class *p, *cl = NULL;\n\tstruct rb_node *n;\n\n\tfor (n = rb_first(&q->eligible); n != NULL; n = rb_next(n)) {\n\t\tp = rb_entry(n, struct hfsc_class, el_node);\n\t\tif (p->cl_e > cur_time)\n\t\t\tbreak;\n\t\tif (cl == NULL || p->cl_d < cl->cl_d)\n\t\t\tcl = p;\n\t}\n\treturn cl;\n}\n\n \nstatic inline struct hfsc_class *\neltree_get_minel(struct hfsc_sched *q)\n{\n\tstruct rb_node *n;\n\n\tn = rb_first(&q->eligible);\n\tif (n == NULL)\n\t\treturn NULL;\n\treturn rb_entry(n, struct hfsc_class, el_node);\n}\n\n \nstatic void\nvttree_insert(struct hfsc_class *cl)\n{\n\tstruct rb_node **p = &cl->cl_parent->vt_tree.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct hfsc_class *cl1;\n\n\twhile (*p != NULL) {\n\t\tparent = *p;\n\t\tcl1 = rb_entry(parent, struct hfsc_class, vt_node);\n\t\tif (cl->cl_vt >= cl1->cl_vt)\n\t\t\tp = &parent->rb_right;\n\t\telse\n\t\t\tp = &parent->rb_left;\n\t}\n\trb_link_node(&cl->vt_node, parent, p);\n\trb_insert_color(&cl->vt_node, &cl->cl_parent->vt_tree);\n}\n\nstatic inline void\nvttree_remove(struct hfsc_class *cl)\n{\n\trb_erase(&cl->vt_node, &cl->cl_parent->vt_tree);\n}\n\nstatic inline void\nvttree_update(struct hfsc_class *cl)\n{\n\tvttree_remove(cl);\n\tvttree_insert(cl);\n}\n\nstatic inline struct hfsc_class *\nvttree_firstfit(struct hfsc_class *cl, u64 cur_time)\n{\n\tstruct hfsc_class *p;\n\tstruct rb_node *n;\n\n\tfor (n = rb_first(&cl->vt_tree); n != NULL; n = rb_next(n)) {\n\t\tp = rb_entry(n, struct hfsc_class, vt_node);\n\t\tif (p->cl_f <= cur_time)\n\t\t\treturn p;\n\t}\n\treturn NULL;\n}\n\n \nstatic struct hfsc_class *\nvttree_get_minvt(struct hfsc_class *cl, u64 cur_time)\n{\n\t \n\tif (cl->cl_cfmin > cur_time)\n\t\treturn NULL;\n\n\twhile (cl->level > 0) {\n\t\tcl = vttree_firstfit(cl, cur_time);\n\t\tif (cl == NULL)\n\t\t\treturn NULL;\n\t\t \n\t\tif (cl->cl_parent->cl_cvtmin < cl->cl_vt)\n\t\t\tcl->cl_parent->cl_cvtmin = cl->cl_vt;\n\t}\n\treturn cl;\n}\n\nstatic void\ncftree_insert(struct hfsc_class *cl)\n{\n\tstruct rb_node **p = &cl->cl_parent->cf_tree.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct hfsc_class *cl1;\n\n\twhile (*p != NULL) {\n\t\tparent = *p;\n\t\tcl1 = rb_entry(parent, struct hfsc_class, cf_node);\n\t\tif (cl->cl_f >= cl1->cl_f)\n\t\t\tp = &parent->rb_right;\n\t\telse\n\t\t\tp = &parent->rb_left;\n\t}\n\trb_link_node(&cl->cf_node, parent, p);\n\trb_insert_color(&cl->cf_node, &cl->cl_parent->cf_tree);\n}\n\nstatic inline void\ncftree_remove(struct hfsc_class *cl)\n{\n\trb_erase(&cl->cf_node, &cl->cl_parent->cf_tree);\n}\n\nstatic inline void\ncftree_update(struct hfsc_class *cl)\n{\n\tcftree_remove(cl);\n\tcftree_insert(cl);\n}\n\n \n#define\tSM_SHIFT\t(30 - PSCHED_SHIFT)\n#define\tISM_SHIFT\t(8 + PSCHED_SHIFT)\n\n#define\tSM_MASK\t\t((1ULL << SM_SHIFT) - 1)\n#define\tISM_MASK\t((1ULL << ISM_SHIFT) - 1)\n\nstatic inline u64\nseg_x2y(u64 x, u64 sm)\n{\n\tu64 y;\n\n\t \n\ty = (x >> SM_SHIFT) * sm + (((x & SM_MASK) * sm) >> SM_SHIFT);\n\treturn y;\n}\n\nstatic inline u64\nseg_y2x(u64 y, u64 ism)\n{\n\tu64 x;\n\n\tif (y == 0)\n\t\tx = 0;\n\telse if (ism == HT_INFINITY)\n\t\tx = HT_INFINITY;\n\telse {\n\t\tx = (y >> ISM_SHIFT) * ism\n\t\t    + (((y & ISM_MASK) * ism) >> ISM_SHIFT);\n\t}\n\treturn x;\n}\n\n \nstatic u64\nm2sm(u32 m)\n{\n\tu64 sm;\n\n\tsm = ((u64)m << SM_SHIFT);\n\tsm += PSCHED_TICKS_PER_SEC - 1;\n\tdo_div(sm, PSCHED_TICKS_PER_SEC);\n\treturn sm;\n}\n\n \nstatic u64\nm2ism(u32 m)\n{\n\tu64 ism;\n\n\tif (m == 0)\n\t\tism = HT_INFINITY;\n\telse {\n\t\tism = ((u64)PSCHED_TICKS_PER_SEC << ISM_SHIFT);\n\t\tism += m - 1;\n\t\tdo_div(ism, m);\n\t}\n\treturn ism;\n}\n\n \nstatic u64\nd2dx(u32 d)\n{\n\tu64 dx;\n\n\tdx = ((u64)d * PSCHED_TICKS_PER_SEC);\n\tdx += USEC_PER_SEC - 1;\n\tdo_div(dx, USEC_PER_SEC);\n\treturn dx;\n}\n\n \nstatic u32\nsm2m(u64 sm)\n{\n\tu64 m;\n\n\tm = (sm * PSCHED_TICKS_PER_SEC) >> SM_SHIFT;\n\treturn (u32)m;\n}\n\n \nstatic u32\ndx2d(u64 dx)\n{\n\tu64 d;\n\n\td = dx * USEC_PER_SEC;\n\tdo_div(d, PSCHED_TICKS_PER_SEC);\n\treturn (u32)d;\n}\n\nstatic void\nsc2isc(struct tc_service_curve *sc, struct internal_sc *isc)\n{\n\tisc->sm1  = m2sm(sc->m1);\n\tisc->ism1 = m2ism(sc->m1);\n\tisc->dx   = d2dx(sc->d);\n\tisc->dy   = seg_x2y(isc->dx, isc->sm1);\n\tisc->sm2  = m2sm(sc->m2);\n\tisc->ism2 = m2ism(sc->m2);\n}\n\n \nstatic void\nrtsc_init(struct runtime_sc *rtsc, struct internal_sc *isc, u64 x, u64 y)\n{\n\trtsc->x\t   = x;\n\trtsc->y    = y;\n\trtsc->sm1  = isc->sm1;\n\trtsc->ism1 = isc->ism1;\n\trtsc->dx   = isc->dx;\n\trtsc->dy   = isc->dy;\n\trtsc->sm2  = isc->sm2;\n\trtsc->ism2 = isc->ism2;\n}\n\n \nstatic u64\nrtsc_y2x(struct runtime_sc *rtsc, u64 y)\n{\n\tu64 x;\n\n\tif (y < rtsc->y)\n\t\tx = rtsc->x;\n\telse if (y <= rtsc->y + rtsc->dy) {\n\t\t \n\t\tif (rtsc->dy == 0)\n\t\t\tx = rtsc->x + rtsc->dx;\n\t\telse\n\t\t\tx = rtsc->x + seg_y2x(y - rtsc->y, rtsc->ism1);\n\t} else {\n\t\t \n\t\tx = rtsc->x + rtsc->dx\n\t\t    + seg_y2x(y - rtsc->y - rtsc->dy, rtsc->ism2);\n\t}\n\treturn x;\n}\n\nstatic u64\nrtsc_x2y(struct runtime_sc *rtsc, u64 x)\n{\n\tu64 y;\n\n\tif (x <= rtsc->x)\n\t\ty = rtsc->y;\n\telse if (x <= rtsc->x + rtsc->dx)\n\t\t \n\t\ty = rtsc->y + seg_x2y(x - rtsc->x, rtsc->sm1);\n\telse\n\t\t \n\t\ty = rtsc->y + rtsc->dy\n\t\t    + seg_x2y(x - rtsc->x - rtsc->dx, rtsc->sm2);\n\treturn y;\n}\n\n \nstatic void\nrtsc_min(struct runtime_sc *rtsc, struct internal_sc *isc, u64 x, u64 y)\n{\n\tu64 y1, y2, dx, dy;\n\tu32 dsm;\n\n\tif (isc->sm1 <= isc->sm2) {\n\t\t \n\t\ty1 = rtsc_x2y(rtsc, x);\n\t\tif (y1 < y)\n\t\t\t \n\t\t\treturn;\n\t\trtsc->x = x;\n\t\trtsc->y = y;\n\t\treturn;\n\t}\n\n\t \n\ty1 = rtsc_x2y(rtsc, x);\n\tif (y1 <= y) {\n\t\t \n\t\treturn;\n\t}\n\n\ty2 = rtsc_x2y(rtsc, x + isc->dx);\n\tif (y2 >= y + isc->dy) {\n\t\t \n\t\trtsc->x = x;\n\t\trtsc->y = y;\n\t\trtsc->dx = isc->dx;\n\t\trtsc->dy = isc->dy;\n\t\treturn;\n\t}\n\n\t \n\tdx = (y1 - y) << SM_SHIFT;\n\tdsm = isc->sm1 - isc->sm2;\n\tdo_div(dx, dsm);\n\t \n\tif (rtsc->x + rtsc->dx > x)\n\t\tdx += rtsc->x + rtsc->dx - x;\n\tdy = seg_x2y(dx, isc->sm1);\n\n\trtsc->x = x;\n\trtsc->y = y;\n\trtsc->dx = dx;\n\trtsc->dy = dy;\n}\n\nstatic void\ninit_ed(struct hfsc_class *cl, unsigned int next_len)\n{\n\tu64 cur_time = psched_get_time();\n\n\t \n\trtsc_min(&cl->cl_deadline, &cl->cl_rsc, cur_time, cl->cl_cumul);\n\n\t \n\tcl->cl_eligible = cl->cl_deadline;\n\tif (cl->cl_rsc.sm1 <= cl->cl_rsc.sm2) {\n\t\tcl->cl_eligible.dx = 0;\n\t\tcl->cl_eligible.dy = 0;\n\t}\n\n\t \n\tcl->cl_e = rtsc_y2x(&cl->cl_eligible, cl->cl_cumul);\n\tcl->cl_d = rtsc_y2x(&cl->cl_deadline, cl->cl_cumul + next_len);\n\n\teltree_insert(cl);\n}\n\nstatic void\nupdate_ed(struct hfsc_class *cl, unsigned int next_len)\n{\n\tcl->cl_e = rtsc_y2x(&cl->cl_eligible, cl->cl_cumul);\n\tcl->cl_d = rtsc_y2x(&cl->cl_deadline, cl->cl_cumul + next_len);\n\n\teltree_update(cl);\n}\n\nstatic inline void\nupdate_d(struct hfsc_class *cl, unsigned int next_len)\n{\n\tcl->cl_d = rtsc_y2x(&cl->cl_deadline, cl->cl_cumul + next_len);\n}\n\nstatic inline void\nupdate_cfmin(struct hfsc_class *cl)\n{\n\tstruct rb_node *n = rb_first(&cl->cf_tree);\n\tstruct hfsc_class *p;\n\n\tif (n == NULL) {\n\t\tcl->cl_cfmin = 0;\n\t\treturn;\n\t}\n\tp = rb_entry(n, struct hfsc_class, cf_node);\n\tcl->cl_cfmin = p->cl_f;\n}\n\nstatic void\ninit_vf(struct hfsc_class *cl, unsigned int len)\n{\n\tstruct hfsc_class *max_cl;\n\tstruct rb_node *n;\n\tu64 vt, f, cur_time;\n\tint go_active;\n\n\tcur_time = 0;\n\tgo_active = 1;\n\tfor (; cl->cl_parent != NULL; cl = cl->cl_parent) {\n\t\tif (go_active && cl->cl_nactive++ == 0)\n\t\t\tgo_active = 1;\n\t\telse\n\t\t\tgo_active = 0;\n\n\t\tif (go_active) {\n\t\t\tn = rb_last(&cl->cl_parent->vt_tree);\n\t\t\tif (n != NULL) {\n\t\t\t\tmax_cl = rb_entry(n, struct hfsc_class, vt_node);\n\t\t\t\t \n\t\t\t\tvt = max_cl->cl_vt;\n\t\t\t\tif (cl->cl_parent->cl_cvtmin != 0)\n\t\t\t\t\tvt = (cl->cl_parent->cl_cvtmin + vt)/2;\n\n\t\t\t\tif (cl->cl_parent->cl_vtperiod !=\n\t\t\t\t    cl->cl_parentperiod || vt > cl->cl_vt)\n\t\t\t\t\tcl->cl_vt = vt;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tcl->cl_vt = cl->cl_parent->cl_cvtoff;\n\t\t\t\tcl->cl_parent->cl_cvtmin = 0;\n\t\t\t}\n\n\t\t\t \n\t\t\trtsc_min(&cl->cl_virtual, &cl->cl_fsc, cl->cl_vt, cl->cl_total);\n\t\t\tcl->cl_vtadj = 0;\n\n\t\t\tcl->cl_vtperiod++;   \n\t\t\tcl->cl_parentperiod = cl->cl_parent->cl_vtperiod;\n\t\t\tif (cl->cl_parent->cl_nactive == 0)\n\t\t\t\tcl->cl_parentperiod++;\n\t\t\tcl->cl_f = 0;\n\n\t\t\tvttree_insert(cl);\n\t\t\tcftree_insert(cl);\n\n\t\t\tif (cl->cl_flags & HFSC_USC) {\n\t\t\t\t \n\t\t\t\tif (cur_time == 0)\n\t\t\t\t\tcur_time = psched_get_time();\n\n\t\t\t\t \n\t\t\t\trtsc_min(&cl->cl_ulimit, &cl->cl_usc, cur_time,\n\t\t\t\t\t cl->cl_total);\n\t\t\t\t \n\t\t\t\tcl->cl_myf = rtsc_y2x(&cl->cl_ulimit,\n\t\t\t\t\t\t      cl->cl_total);\n\t\t\t}\n\t\t}\n\n\t\tf = max(cl->cl_myf, cl->cl_cfmin);\n\t\tif (f != cl->cl_f) {\n\t\t\tcl->cl_f = f;\n\t\t\tcftree_update(cl);\n\t\t}\n\t\tupdate_cfmin(cl->cl_parent);\n\t}\n}\n\nstatic void\nupdate_vf(struct hfsc_class *cl, unsigned int len, u64 cur_time)\n{\n\tu64 f;  \n\tint go_passive = 0;\n\n\tif (cl->qdisc->q.qlen == 0 && cl->cl_flags & HFSC_FSC)\n\t\tgo_passive = 1;\n\n\tfor (; cl->cl_parent != NULL; cl = cl->cl_parent) {\n\t\tcl->cl_total += len;\n\n\t\tif (!(cl->cl_flags & HFSC_FSC) || cl->cl_nactive == 0)\n\t\t\tcontinue;\n\n\t\tif (go_passive && --cl->cl_nactive == 0)\n\t\t\tgo_passive = 1;\n\t\telse\n\t\t\tgo_passive = 0;\n\n\t\t \n\t\tcl->cl_vt = rtsc_y2x(&cl->cl_virtual, cl->cl_total) + cl->cl_vtadj;\n\n\t\t \n\t\tif (cl->cl_vt < cl->cl_parent->cl_cvtmin) {\n\t\t\tcl->cl_vtadj += cl->cl_parent->cl_cvtmin - cl->cl_vt;\n\t\t\tcl->cl_vt = cl->cl_parent->cl_cvtmin;\n\t\t}\n\n\t\tif (go_passive) {\n\t\t\t \n\n\t\t\t \n\t\t\tif (cl->cl_vt > cl->cl_parent->cl_cvtoff)\n\t\t\t\tcl->cl_parent->cl_cvtoff = cl->cl_vt;\n\n\t\t\t \n\t\t\tvttree_remove(cl);\n\n\t\t\tcftree_remove(cl);\n\t\t\tupdate_cfmin(cl->cl_parent);\n\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tvttree_update(cl);\n\n\t\t \n\t\tif (cl->cl_flags & HFSC_USC) {\n\t\t\tcl->cl_myf = rtsc_y2x(&cl->cl_ulimit, cl->cl_total);\n#if 0\n\t\t\tcl->cl_myf = cl->cl_myfadj + rtsc_y2x(&cl->cl_ulimit,\n\t\t\t\t\t\t\t      cl->cl_total);\n\t\t\t \n\t\t\t \n\t\t\tmyf_bound = cur_time - PSCHED_JIFFIE2US(1);\n\t\t\tif (cl->cl_myf < myf_bound) {\n\t\t\t\tdelta = cur_time - cl->cl_myf;\n\t\t\t\tcl->cl_myfadj += delta;\n\t\t\t\tcl->cl_myf += delta;\n\t\t\t}\n#endif\n\t\t}\n\n\t\tf = max(cl->cl_myf, cl->cl_cfmin);\n\t\tif (f != cl->cl_f) {\n\t\t\tcl->cl_f = f;\n\t\t\tcftree_update(cl);\n\t\t\tupdate_cfmin(cl->cl_parent);\n\t\t}\n\t}\n}\n\nstatic unsigned int\nqdisc_peek_len(struct Qdisc *sch)\n{\n\tstruct sk_buff *skb;\n\tunsigned int len;\n\n\tskb = sch->ops->peek(sch);\n\tif (unlikely(skb == NULL)) {\n\t\tqdisc_warn_nonwc(\"qdisc_peek_len\", sch);\n\t\treturn 0;\n\t}\n\tlen = qdisc_pkt_len(skb);\n\n\treturn len;\n}\n\nstatic void\nhfsc_adjust_levels(struct hfsc_class *cl)\n{\n\tstruct hfsc_class *p;\n\tunsigned int level;\n\n\tdo {\n\t\tlevel = 0;\n\t\tlist_for_each_entry(p, &cl->children, siblings) {\n\t\t\tif (p->level >= level)\n\t\t\t\tlevel = p->level + 1;\n\t\t}\n\t\tcl->level = level;\n\t} while ((cl = cl->cl_parent) != NULL);\n}\n\nstatic inline struct hfsc_class *\nhfsc_find_class(u32 classid, struct Qdisc *sch)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct Qdisc_class_common *clc;\n\n\tclc = qdisc_class_find(&q->clhash, classid);\n\tif (clc == NULL)\n\t\treturn NULL;\n\treturn container_of(clc, struct hfsc_class, cl_common);\n}\n\nstatic void\nhfsc_change_rsc(struct hfsc_class *cl, struct tc_service_curve *rsc,\n\t\tu64 cur_time)\n{\n\tsc2isc(rsc, &cl->cl_rsc);\n\trtsc_init(&cl->cl_deadline, &cl->cl_rsc, cur_time, cl->cl_cumul);\n\tcl->cl_eligible = cl->cl_deadline;\n\tif (cl->cl_rsc.sm1 <= cl->cl_rsc.sm2) {\n\t\tcl->cl_eligible.dx = 0;\n\t\tcl->cl_eligible.dy = 0;\n\t}\n\tcl->cl_flags |= HFSC_RSC;\n}\n\nstatic void\nhfsc_change_fsc(struct hfsc_class *cl, struct tc_service_curve *fsc)\n{\n\tsc2isc(fsc, &cl->cl_fsc);\n\trtsc_init(&cl->cl_virtual, &cl->cl_fsc, cl->cl_vt, cl->cl_total);\n\tcl->cl_flags |= HFSC_FSC;\n}\n\nstatic void\nhfsc_change_usc(struct hfsc_class *cl, struct tc_service_curve *usc,\n\t\tu64 cur_time)\n{\n\tsc2isc(usc, &cl->cl_usc);\n\trtsc_init(&cl->cl_ulimit, &cl->cl_usc, cur_time, cl->cl_total);\n\tcl->cl_flags |= HFSC_USC;\n}\n\nstatic void\nhfsc_upgrade_rt(struct hfsc_class *cl)\n{\n\tcl->cl_fsc = cl->cl_rsc;\n\trtsc_init(&cl->cl_virtual, &cl->cl_fsc, cl->cl_vt, cl->cl_total);\n\tcl->cl_flags |= HFSC_FSC;\n}\n\nstatic const struct nla_policy hfsc_policy[TCA_HFSC_MAX + 1] = {\n\t[TCA_HFSC_RSC]\t= { .len = sizeof(struct tc_service_curve) },\n\t[TCA_HFSC_FSC]\t= { .len = sizeof(struct tc_service_curve) },\n\t[TCA_HFSC_USC]\t= { .len = sizeof(struct tc_service_curve) },\n};\n\nstatic int\nhfsc_change_class(struct Qdisc *sch, u32 classid, u32 parentid,\n\t\t  struct nlattr **tca, unsigned long *arg,\n\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct hfsc_class *cl = (struct hfsc_class *)*arg;\n\tstruct hfsc_class *parent = NULL;\n\tstruct nlattr *opt = tca[TCA_OPTIONS];\n\tstruct nlattr *tb[TCA_HFSC_MAX + 1];\n\tstruct tc_service_curve *rsc = NULL, *fsc = NULL, *usc = NULL;\n\tu64 cur_time;\n\tint err;\n\n\tif (opt == NULL)\n\t\treturn -EINVAL;\n\n\terr = nla_parse_nested_deprecated(tb, TCA_HFSC_MAX, opt, hfsc_policy,\n\t\t\t\t\t  NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[TCA_HFSC_RSC]) {\n\t\trsc = nla_data(tb[TCA_HFSC_RSC]);\n\t\tif (rsc->m1 == 0 && rsc->m2 == 0)\n\t\t\trsc = NULL;\n\t}\n\n\tif (tb[TCA_HFSC_FSC]) {\n\t\tfsc = nla_data(tb[TCA_HFSC_FSC]);\n\t\tif (fsc->m1 == 0 && fsc->m2 == 0)\n\t\t\tfsc = NULL;\n\t}\n\n\tif (tb[TCA_HFSC_USC]) {\n\t\tusc = nla_data(tb[TCA_HFSC_USC]);\n\t\tif (usc->m1 == 0 && usc->m2 == 0)\n\t\t\tusc = NULL;\n\t}\n\n\tif (cl != NULL) {\n\t\tint old_flags;\n\n\t\tif (parentid) {\n\t\t\tif (cl->cl_parent &&\n\t\t\t    cl->cl_parent->cl_common.classid != parentid)\n\t\t\t\treturn -EINVAL;\n\t\t\tif (cl->cl_parent == NULL && parentid != TC_H_ROOT)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\tcur_time = psched_get_time();\n\n\t\tif (tca[TCA_RATE]) {\n\t\t\terr = gen_replace_estimator(&cl->bstats, NULL,\n\t\t\t\t\t\t    &cl->rate_est,\n\t\t\t\t\t\t    NULL,\n\t\t\t\t\t\t    true,\n\t\t\t\t\t\t    tca[TCA_RATE]);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tsch_tree_lock(sch);\n\t\told_flags = cl->cl_flags;\n\n\t\tif (rsc != NULL)\n\t\t\thfsc_change_rsc(cl, rsc, cur_time);\n\t\tif (fsc != NULL)\n\t\t\thfsc_change_fsc(cl, fsc);\n\t\tif (usc != NULL)\n\t\t\thfsc_change_usc(cl, usc, cur_time);\n\n\t\tif (cl->qdisc->q.qlen != 0) {\n\t\t\tint len = qdisc_peek_len(cl->qdisc);\n\n\t\t\tif (cl->cl_flags & HFSC_RSC) {\n\t\t\t\tif (old_flags & HFSC_RSC)\n\t\t\t\t\tupdate_ed(cl, len);\n\t\t\t\telse\n\t\t\t\t\tinit_ed(cl, len);\n\t\t\t}\n\n\t\t\tif (cl->cl_flags & HFSC_FSC) {\n\t\t\t\tif (old_flags & HFSC_FSC)\n\t\t\t\t\tupdate_vf(cl, 0, cur_time);\n\t\t\t\telse\n\t\t\t\t\tinit_vf(cl, len);\n\t\t\t}\n\t\t}\n\t\tsch_tree_unlock(sch);\n\n\t\treturn 0;\n\t}\n\n\tif (parentid == TC_H_ROOT)\n\t\treturn -EEXIST;\n\n\tparent = &q->root;\n\tif (parentid) {\n\t\tparent = hfsc_find_class(parentid, sch);\n\t\tif (parent == NULL)\n\t\t\treturn -ENOENT;\n\t}\n\n\tif (classid == 0 || TC_H_MAJ(classid ^ sch->handle) != 0)\n\t\treturn -EINVAL;\n\tif (hfsc_find_class(classid, sch))\n\t\treturn -EEXIST;\n\n\tif (rsc == NULL && fsc == NULL)\n\t\treturn -EINVAL;\n\n\tcl = kzalloc(sizeof(struct hfsc_class), GFP_KERNEL);\n\tif (cl == NULL)\n\t\treturn -ENOBUFS;\n\n\terr = tcf_block_get(&cl->block, &cl->filter_list, sch, extack);\n\tif (err) {\n\t\tkfree(cl);\n\t\treturn err;\n\t}\n\n\tif (tca[TCA_RATE]) {\n\t\terr = gen_new_estimator(&cl->bstats, NULL, &cl->rate_est,\n\t\t\t\t\tNULL, true, tca[TCA_RATE]);\n\t\tif (err) {\n\t\t\ttcf_block_put(cl->block);\n\t\t\tkfree(cl);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (rsc != NULL)\n\t\thfsc_change_rsc(cl, rsc, 0);\n\tif (fsc != NULL)\n\t\thfsc_change_fsc(cl, fsc);\n\tif (usc != NULL)\n\t\thfsc_change_usc(cl, usc, 0);\n\n\tcl->cl_common.classid = classid;\n\tcl->sched     = q;\n\tcl->cl_parent = parent;\n\tcl->qdisc = qdisc_create_dflt(sch->dev_queue, &pfifo_qdisc_ops,\n\t\t\t\t      classid, NULL);\n\tif (cl->qdisc == NULL)\n\t\tcl->qdisc = &noop_qdisc;\n\telse\n\t\tqdisc_hash_add(cl->qdisc, true);\n\tINIT_LIST_HEAD(&cl->children);\n\tcl->vt_tree = RB_ROOT;\n\tcl->cf_tree = RB_ROOT;\n\n\tsch_tree_lock(sch);\n\t \n\tif (!(parent->cl_flags & HFSC_FSC) && parent != &q->root) {\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"Forced curve change on parent 'rt' to 'sc'\");\n\t\thfsc_upgrade_rt(parent);\n\t}\n\tqdisc_class_hash_insert(&q->clhash, &cl->cl_common);\n\tlist_add_tail(&cl->siblings, &parent->children);\n\tif (parent->level == 0)\n\t\tqdisc_purge_queue(parent->qdisc);\n\thfsc_adjust_levels(parent);\n\tsch_tree_unlock(sch);\n\n\tqdisc_class_hash_grow(sch, &q->clhash);\n\n\t*arg = (unsigned long)cl;\n\treturn 0;\n}\n\nstatic void\nhfsc_destroy_class(struct Qdisc *sch, struct hfsc_class *cl)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\n\ttcf_block_put(cl->block);\n\tqdisc_put(cl->qdisc);\n\tgen_kill_estimator(&cl->rate_est);\n\tif (cl != &q->root)\n\t\tkfree(cl);\n}\n\nstatic int\nhfsc_delete_class(struct Qdisc *sch, unsigned long arg,\n\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct hfsc_class *cl = (struct hfsc_class *)arg;\n\n\tif (cl->level > 0 || qdisc_class_in_use(&cl->cl_common) ||\n\t    cl == &q->root) {\n\t\tNL_SET_ERR_MSG(extack, \"HFSC class in use\");\n\t\treturn -EBUSY;\n\t}\n\n\tsch_tree_lock(sch);\n\n\tlist_del(&cl->siblings);\n\thfsc_adjust_levels(cl->cl_parent);\n\n\tqdisc_purge_queue(cl->qdisc);\n\tqdisc_class_hash_remove(&q->clhash, &cl->cl_common);\n\n\tsch_tree_unlock(sch);\n\n\thfsc_destroy_class(sch, cl);\n\treturn 0;\n}\n\nstatic struct hfsc_class *\nhfsc_classify(struct sk_buff *skb, struct Qdisc *sch, int *qerr)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct hfsc_class *head, *cl;\n\tstruct tcf_result res;\n\tstruct tcf_proto *tcf;\n\tint result;\n\n\tif (TC_H_MAJ(skb->priority ^ sch->handle) == 0 &&\n\t    (cl = hfsc_find_class(skb->priority, sch)) != NULL)\n\t\tif (cl->level == 0)\n\t\t\treturn cl;\n\n\t*qerr = NET_XMIT_SUCCESS | __NET_XMIT_BYPASS;\n\thead = &q->root;\n\ttcf = rcu_dereference_bh(q->root.filter_list);\n\twhile (tcf && (result = tcf_classify(skb, NULL, tcf, &res, false)) >= 0) {\n#ifdef CONFIG_NET_CLS_ACT\n\t\tswitch (result) {\n\t\tcase TC_ACT_QUEUED:\n\t\tcase TC_ACT_STOLEN:\n\t\tcase TC_ACT_TRAP:\n\t\t\t*qerr = NET_XMIT_SUCCESS | __NET_XMIT_STOLEN;\n\t\t\tfallthrough;\n\t\tcase TC_ACT_SHOT:\n\t\t\treturn NULL;\n\t\t}\n#endif\n\t\tcl = (struct hfsc_class *)res.class;\n\t\tif (!cl) {\n\t\t\tcl = hfsc_find_class(res.classid, sch);\n\t\t\tif (!cl)\n\t\t\t\tbreak;  \n\t\t\tif (cl->level >= head->level)\n\t\t\t\tbreak;  \n\t\t}\n\n\t\tif (cl->level == 0)\n\t\t\treturn cl;  \n\n\t\t \n\t\ttcf = rcu_dereference_bh(cl->filter_list);\n\t\thead = cl;\n\t}\n\n\t \n\tcl = hfsc_find_class(TC_H_MAKE(TC_H_MAJ(sch->handle), q->defcls), sch);\n\tif (cl == NULL || cl->level > 0)\n\t\treturn NULL;\n\n\treturn cl;\n}\n\nstatic int\nhfsc_graft_class(struct Qdisc *sch, unsigned long arg, struct Qdisc *new,\n\t\t struct Qdisc **old, struct netlink_ext_ack *extack)\n{\n\tstruct hfsc_class *cl = (struct hfsc_class *)arg;\n\n\tif (cl->level > 0)\n\t\treturn -EINVAL;\n\tif (new == NULL) {\n\t\tnew = qdisc_create_dflt(sch->dev_queue, &pfifo_qdisc_ops,\n\t\t\t\t\tcl->cl_common.classid, NULL);\n\t\tif (new == NULL)\n\t\t\tnew = &noop_qdisc;\n\t}\n\n\t*old = qdisc_replace(sch, new, &cl->qdisc);\n\treturn 0;\n}\n\nstatic struct Qdisc *\nhfsc_class_leaf(struct Qdisc *sch, unsigned long arg)\n{\n\tstruct hfsc_class *cl = (struct hfsc_class *)arg;\n\n\tif (cl->level == 0)\n\t\treturn cl->qdisc;\n\n\treturn NULL;\n}\n\nstatic void\nhfsc_qlen_notify(struct Qdisc *sch, unsigned long arg)\n{\n\tstruct hfsc_class *cl = (struct hfsc_class *)arg;\n\n\t \n\tupdate_vf(cl, 0, 0);\n\tif (cl->cl_flags & HFSC_RSC)\n\t\teltree_remove(cl);\n}\n\nstatic unsigned long\nhfsc_search_class(struct Qdisc *sch, u32 classid)\n{\n\treturn (unsigned long)hfsc_find_class(classid, sch);\n}\n\nstatic unsigned long\nhfsc_bind_tcf(struct Qdisc *sch, unsigned long parent, u32 classid)\n{\n\tstruct hfsc_class *p = (struct hfsc_class *)parent;\n\tstruct hfsc_class *cl = hfsc_find_class(classid, sch);\n\n\tif (cl != NULL) {\n\t\tif (p != NULL && p->level <= cl->level)\n\t\t\treturn 0;\n\t\tqdisc_class_get(&cl->cl_common);\n\t}\n\n\treturn (unsigned long)cl;\n}\n\nstatic void\nhfsc_unbind_tcf(struct Qdisc *sch, unsigned long arg)\n{\n\tstruct hfsc_class *cl = (struct hfsc_class *)arg;\n\n\tqdisc_class_put(&cl->cl_common);\n}\n\nstatic struct tcf_block *hfsc_tcf_block(struct Qdisc *sch, unsigned long arg,\n\t\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct hfsc_class *cl = (struct hfsc_class *)arg;\n\n\tif (cl == NULL)\n\t\tcl = &q->root;\n\n\treturn cl->block;\n}\n\nstatic int\nhfsc_dump_sc(struct sk_buff *skb, int attr, struct internal_sc *sc)\n{\n\tstruct tc_service_curve tsc;\n\n\ttsc.m1 = sm2m(sc->sm1);\n\ttsc.d  = dx2d(sc->dx);\n\ttsc.m2 = sm2m(sc->sm2);\n\tif (nla_put(skb, attr, sizeof(tsc), &tsc))\n\t\tgoto nla_put_failure;\n\n\treturn skb->len;\n\n nla_put_failure:\n\treturn -1;\n}\n\nstatic int\nhfsc_dump_curves(struct sk_buff *skb, struct hfsc_class *cl)\n{\n\tif ((cl->cl_flags & HFSC_RSC) &&\n\t    (hfsc_dump_sc(skb, TCA_HFSC_RSC, &cl->cl_rsc) < 0))\n\t\tgoto nla_put_failure;\n\n\tif ((cl->cl_flags & HFSC_FSC) &&\n\t    (hfsc_dump_sc(skb, TCA_HFSC_FSC, &cl->cl_fsc) < 0))\n\t\tgoto nla_put_failure;\n\n\tif ((cl->cl_flags & HFSC_USC) &&\n\t    (hfsc_dump_sc(skb, TCA_HFSC_USC, &cl->cl_usc) < 0))\n\t\tgoto nla_put_failure;\n\n\treturn skb->len;\n\n nla_put_failure:\n\treturn -1;\n}\n\nstatic int\nhfsc_dump_class(struct Qdisc *sch, unsigned long arg, struct sk_buff *skb,\n\t\tstruct tcmsg *tcm)\n{\n\tstruct hfsc_class *cl = (struct hfsc_class *)arg;\n\tstruct nlattr *nest;\n\n\ttcm->tcm_parent = cl->cl_parent ? cl->cl_parent->cl_common.classid :\n\t\t\t\t\t  TC_H_ROOT;\n\ttcm->tcm_handle = cl->cl_common.classid;\n\tif (cl->level == 0)\n\t\ttcm->tcm_info = cl->qdisc->handle;\n\n\tnest = nla_nest_start_noflag(skb, TCA_OPTIONS);\n\tif (nest == NULL)\n\t\tgoto nla_put_failure;\n\tif (hfsc_dump_curves(skb, cl) < 0)\n\t\tgoto nla_put_failure;\n\treturn nla_nest_end(skb, nest);\n\n nla_put_failure:\n\tnla_nest_cancel(skb, nest);\n\treturn -EMSGSIZE;\n}\n\nstatic int\nhfsc_dump_class_stats(struct Qdisc *sch, unsigned long arg,\n\tstruct gnet_dump *d)\n{\n\tstruct hfsc_class *cl = (struct hfsc_class *)arg;\n\tstruct tc_hfsc_stats xstats;\n\t__u32 qlen;\n\n\tqdisc_qstats_qlen_backlog(cl->qdisc, &qlen, &cl->qstats.backlog);\n\txstats.level   = cl->level;\n\txstats.period  = cl->cl_vtperiod;\n\txstats.work    = cl->cl_total;\n\txstats.rtwork  = cl->cl_cumul;\n\n\tif (gnet_stats_copy_basic(d, NULL, &cl->bstats, true) < 0 ||\n\t    gnet_stats_copy_rate_est(d, &cl->rate_est) < 0 ||\n\t    gnet_stats_copy_queue(d, NULL, &cl->qstats, qlen) < 0)\n\t\treturn -1;\n\n\treturn gnet_stats_copy_app(d, &xstats, sizeof(xstats));\n}\n\n\n\nstatic void\nhfsc_walk(struct Qdisc *sch, struct qdisc_walker *arg)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct hfsc_class *cl;\n\tunsigned int i;\n\n\tif (arg->stop)\n\t\treturn;\n\n\tfor (i = 0; i < q->clhash.hashsize; i++) {\n\t\thlist_for_each_entry(cl, &q->clhash.hash[i],\n\t\t\t\t     cl_common.hnode) {\n\t\t\tif (!tc_qdisc_stats_dump(sch, (unsigned long)cl, arg))\n\t\t\t\treturn;\n\t\t}\n\t}\n}\n\nstatic void\nhfsc_schedule_watchdog(struct Qdisc *sch)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct hfsc_class *cl;\n\tu64 next_time = 0;\n\n\tcl = eltree_get_minel(q);\n\tif (cl)\n\t\tnext_time = cl->cl_e;\n\tif (q->root.cl_cfmin != 0) {\n\t\tif (next_time == 0 || next_time > q->root.cl_cfmin)\n\t\t\tnext_time = q->root.cl_cfmin;\n\t}\n\tif (next_time)\n\t\tqdisc_watchdog_schedule(&q->watchdog, next_time);\n}\n\nstatic int\nhfsc_init_qdisc(struct Qdisc *sch, struct nlattr *opt,\n\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct tc_hfsc_qopt *qopt;\n\tint err;\n\n\tqdisc_watchdog_init(&q->watchdog, sch);\n\n\tif (!opt || nla_len(opt) < sizeof(*qopt))\n\t\treturn -EINVAL;\n\tqopt = nla_data(opt);\n\n\tq->defcls = qopt->defcls;\n\terr = qdisc_class_hash_init(&q->clhash);\n\tif (err < 0)\n\t\treturn err;\n\tq->eligible = RB_ROOT;\n\n\terr = tcf_block_get(&q->root.block, &q->root.filter_list, sch, extack);\n\tif (err)\n\t\treturn err;\n\n\tgnet_stats_basic_sync_init(&q->root.bstats);\n\tq->root.cl_common.classid = sch->handle;\n\tq->root.sched   = q;\n\tq->root.qdisc = qdisc_create_dflt(sch->dev_queue, &pfifo_qdisc_ops,\n\t\t\t\t\t  sch->handle, NULL);\n\tif (q->root.qdisc == NULL)\n\t\tq->root.qdisc = &noop_qdisc;\n\telse\n\t\tqdisc_hash_add(q->root.qdisc, true);\n\tINIT_LIST_HEAD(&q->root.children);\n\tq->root.vt_tree = RB_ROOT;\n\tq->root.cf_tree = RB_ROOT;\n\n\tqdisc_class_hash_insert(&q->clhash, &q->root.cl_common);\n\tqdisc_class_hash_grow(sch, &q->clhash);\n\n\treturn 0;\n}\n\nstatic int\nhfsc_change_qdisc(struct Qdisc *sch, struct nlattr *opt,\n\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct tc_hfsc_qopt *qopt;\n\n\tif (nla_len(opt) < sizeof(*qopt))\n\t\treturn -EINVAL;\n\tqopt = nla_data(opt);\n\n\tsch_tree_lock(sch);\n\tq->defcls = qopt->defcls;\n\tsch_tree_unlock(sch);\n\n\treturn 0;\n}\n\nstatic void\nhfsc_reset_class(struct hfsc_class *cl)\n{\n\tcl->cl_total        = 0;\n\tcl->cl_cumul        = 0;\n\tcl->cl_d            = 0;\n\tcl->cl_e            = 0;\n\tcl->cl_vt           = 0;\n\tcl->cl_vtadj        = 0;\n\tcl->cl_cvtmin       = 0;\n\tcl->cl_cvtoff       = 0;\n\tcl->cl_vtperiod     = 0;\n\tcl->cl_parentperiod = 0;\n\tcl->cl_f            = 0;\n\tcl->cl_myf          = 0;\n\tcl->cl_cfmin        = 0;\n\tcl->cl_nactive      = 0;\n\n\tcl->vt_tree = RB_ROOT;\n\tcl->cf_tree = RB_ROOT;\n\tqdisc_reset(cl->qdisc);\n\n\tif (cl->cl_flags & HFSC_RSC)\n\t\trtsc_init(&cl->cl_deadline, &cl->cl_rsc, 0, 0);\n\tif (cl->cl_flags & HFSC_FSC)\n\t\trtsc_init(&cl->cl_virtual, &cl->cl_fsc, 0, 0);\n\tif (cl->cl_flags & HFSC_USC)\n\t\trtsc_init(&cl->cl_ulimit, &cl->cl_usc, 0, 0);\n}\n\nstatic void\nhfsc_reset_qdisc(struct Qdisc *sch)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct hfsc_class *cl;\n\tunsigned int i;\n\n\tfor (i = 0; i < q->clhash.hashsize; i++) {\n\t\thlist_for_each_entry(cl, &q->clhash.hash[i], cl_common.hnode)\n\t\t\thfsc_reset_class(cl);\n\t}\n\tq->eligible = RB_ROOT;\n\tqdisc_watchdog_cancel(&q->watchdog);\n}\n\nstatic void\nhfsc_destroy_qdisc(struct Qdisc *sch)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct hlist_node *next;\n\tstruct hfsc_class *cl;\n\tunsigned int i;\n\n\tfor (i = 0; i < q->clhash.hashsize; i++) {\n\t\thlist_for_each_entry(cl, &q->clhash.hash[i], cl_common.hnode) {\n\t\t\ttcf_block_put(cl->block);\n\t\t\tcl->block = NULL;\n\t\t}\n\t}\n\tfor (i = 0; i < q->clhash.hashsize; i++) {\n\t\thlist_for_each_entry_safe(cl, next, &q->clhash.hash[i],\n\t\t\t\t\t  cl_common.hnode)\n\t\t\thfsc_destroy_class(sch, cl);\n\t}\n\tqdisc_class_hash_destroy(&q->clhash);\n\tqdisc_watchdog_cancel(&q->watchdog);\n}\n\nstatic int\nhfsc_dump_qdisc(struct Qdisc *sch, struct sk_buff *skb)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tunsigned char *b = skb_tail_pointer(skb);\n\tstruct tc_hfsc_qopt qopt;\n\n\tqopt.defcls = q->defcls;\n\tif (nla_put(skb, TCA_OPTIONS, sizeof(qopt), &qopt))\n\t\tgoto nla_put_failure;\n\treturn skb->len;\n\n nla_put_failure:\n\tnlmsg_trim(skb, b);\n\treturn -1;\n}\n\nstatic int\nhfsc_enqueue(struct sk_buff *skb, struct Qdisc *sch, struct sk_buff **to_free)\n{\n\tunsigned int len = qdisc_pkt_len(skb);\n\tstruct hfsc_class *cl;\n\tint err;\n\tbool first;\n\n\tcl = hfsc_classify(skb, sch, &err);\n\tif (cl == NULL) {\n\t\tif (err & __NET_XMIT_BYPASS)\n\t\t\tqdisc_qstats_drop(sch);\n\t\t__qdisc_drop(skb, to_free);\n\t\treturn err;\n\t}\n\n\tfirst = !cl->qdisc->q.qlen;\n\terr = qdisc_enqueue(skb, cl->qdisc, to_free);\n\tif (unlikely(err != NET_XMIT_SUCCESS)) {\n\t\tif (net_xmit_drop_count(err)) {\n\t\t\tcl->qstats.drops++;\n\t\t\tqdisc_qstats_drop(sch);\n\t\t}\n\t\treturn err;\n\t}\n\n\tif (first) {\n\t\tif (cl->cl_flags & HFSC_RSC)\n\t\t\tinit_ed(cl, len);\n\t\tif (cl->cl_flags & HFSC_FSC)\n\t\t\tinit_vf(cl, len);\n\t\t \n\t\tif (cl->cl_flags & HFSC_RSC)\n\t\t\tcl->qdisc->ops->peek(cl->qdisc);\n\n\t}\n\n\tsch->qstats.backlog += len;\n\tsch->q.qlen++;\n\n\treturn NET_XMIT_SUCCESS;\n}\n\nstatic struct sk_buff *\nhfsc_dequeue(struct Qdisc *sch)\n{\n\tstruct hfsc_sched *q = qdisc_priv(sch);\n\tstruct hfsc_class *cl;\n\tstruct sk_buff *skb;\n\tu64 cur_time;\n\tunsigned int next_len;\n\tint realtime = 0;\n\n\tif (sch->q.qlen == 0)\n\t\treturn NULL;\n\n\tcur_time = psched_get_time();\n\n\t \n\tcl = eltree_get_mindl(q, cur_time);\n\tif (cl) {\n\t\trealtime = 1;\n\t} else {\n\t\t \n\t\tcl = vttree_get_minvt(&q->root, cur_time);\n\t\tif (cl == NULL) {\n\t\t\tqdisc_qstats_overlimit(sch);\n\t\t\thfsc_schedule_watchdog(sch);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tskb = qdisc_dequeue_peeked(cl->qdisc);\n\tif (skb == NULL) {\n\t\tqdisc_warn_nonwc(\"HFSC\", cl->qdisc);\n\t\treturn NULL;\n\t}\n\n\tbstats_update(&cl->bstats, skb);\n\tupdate_vf(cl, qdisc_pkt_len(skb), cur_time);\n\tif (realtime)\n\t\tcl->cl_cumul += qdisc_pkt_len(skb);\n\n\tif (cl->cl_flags & HFSC_RSC) {\n\t\tif (cl->qdisc->q.qlen != 0) {\n\t\t\t \n\t\t\tnext_len = qdisc_peek_len(cl->qdisc);\n\t\t\tif (realtime)\n\t\t\t\tupdate_ed(cl, next_len);\n\t\t\telse\n\t\t\t\tupdate_d(cl, next_len);\n\t\t} else {\n\t\t\t \n\t\t\teltree_remove(cl);\n\t\t}\n\t}\n\n\tqdisc_bstats_update(sch, skb);\n\tqdisc_qstats_backlog_dec(sch, skb);\n\tsch->q.qlen--;\n\n\treturn skb;\n}\n\nstatic const struct Qdisc_class_ops hfsc_class_ops = {\n\t.change\t\t= hfsc_change_class,\n\t.delete\t\t= hfsc_delete_class,\n\t.graft\t\t= hfsc_graft_class,\n\t.leaf\t\t= hfsc_class_leaf,\n\t.qlen_notify\t= hfsc_qlen_notify,\n\t.find\t\t= hfsc_search_class,\n\t.bind_tcf\t= hfsc_bind_tcf,\n\t.unbind_tcf\t= hfsc_unbind_tcf,\n\t.tcf_block\t= hfsc_tcf_block,\n\t.dump\t\t= hfsc_dump_class,\n\t.dump_stats\t= hfsc_dump_class_stats,\n\t.walk\t\t= hfsc_walk\n};\n\nstatic struct Qdisc_ops hfsc_qdisc_ops __read_mostly = {\n\t.id\t\t= \"hfsc\",\n\t.init\t\t= hfsc_init_qdisc,\n\t.change\t\t= hfsc_change_qdisc,\n\t.reset\t\t= hfsc_reset_qdisc,\n\t.destroy\t= hfsc_destroy_qdisc,\n\t.dump\t\t= hfsc_dump_qdisc,\n\t.enqueue\t= hfsc_enqueue,\n\t.dequeue\t= hfsc_dequeue,\n\t.peek\t\t= qdisc_peek_dequeued,\n\t.cl_ops\t\t= &hfsc_class_ops,\n\t.priv_size\t= sizeof(struct hfsc_sched),\n\t.owner\t\t= THIS_MODULE\n};\n\nstatic int __init\nhfsc_init(void)\n{\n\treturn register_qdisc(&hfsc_qdisc_ops);\n}\n\nstatic void __exit\nhfsc_cleanup(void)\n{\n\tunregister_qdisc(&hfsc_qdisc_ops);\n}\n\nMODULE_LICENSE(\"GPL\");\nmodule_init(hfsc_init);\nmodule_exit(hfsc_cleanup);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}