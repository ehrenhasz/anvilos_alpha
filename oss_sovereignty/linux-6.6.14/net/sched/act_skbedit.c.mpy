{
  "module_name": "act_skbedit.c",
  "hash_id": "57347e2e02cfffed265c4160c3def39c121090d5296f19aac07223cdb30269f8",
  "original_prompt": "Ingested from linux-6.6.14/net/sched/act_skbedit.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/skbuff.h>\n#include <linux/rtnetlink.h>\n#include <net/netlink.h>\n#include <net/pkt_sched.h>\n#include <net/ip.h>\n#include <net/ipv6.h>\n#include <net/dsfield.h>\n#include <net/pkt_cls.h>\n#include <net/tc_wrapper.h>\n\n#include <linux/tc_act/tc_skbedit.h>\n#include <net/tc_act/tc_skbedit.h>\n\nstatic struct tc_action_ops act_skbedit_ops;\n\nstatic u16 tcf_skbedit_hash(struct tcf_skbedit_params *params,\n\t\t\t    struct sk_buff *skb)\n{\n\tu16 queue_mapping = params->queue_mapping;\n\n\tif (params->flags & SKBEDIT_F_TXQ_SKBHASH) {\n\t\tu32 hash = skb_get_hash(skb);\n\n\t\tqueue_mapping += hash % params->mapping_mod;\n\t}\n\n\treturn netdev_cap_txqueue(skb->dev, queue_mapping);\n}\n\nTC_INDIRECT_SCOPE int tcf_skbedit_act(struct sk_buff *skb,\n\t\t\t\t      const struct tc_action *a,\n\t\t\t\t      struct tcf_result *res)\n{\n\tstruct tcf_skbedit *d = to_skbedit(a);\n\tstruct tcf_skbedit_params *params;\n\tint action;\n\n\ttcf_lastuse_update(&d->tcf_tm);\n\tbstats_update(this_cpu_ptr(d->common.cpu_bstats), skb);\n\n\tparams = rcu_dereference_bh(d->params);\n\taction = READ_ONCE(d->tcf_action);\n\n\tif (params->flags & SKBEDIT_F_PRIORITY)\n\t\tskb->priority = params->priority;\n\tif (params->flags & SKBEDIT_F_INHERITDSFIELD) {\n\t\tint wlen = skb_network_offset(skb);\n\n\t\tswitch (skb_protocol(skb, true)) {\n\t\tcase htons(ETH_P_IP):\n\t\t\twlen += sizeof(struct iphdr);\n\t\t\tif (!pskb_may_pull(skb, wlen))\n\t\t\t\tgoto err;\n\t\t\tskb->priority = ipv4_get_dsfield(ip_hdr(skb)) >> 2;\n\t\t\tbreak;\n\n\t\tcase htons(ETH_P_IPV6):\n\t\t\twlen += sizeof(struct ipv6hdr);\n\t\t\tif (!pskb_may_pull(skb, wlen))\n\t\t\t\tgoto err;\n\t\t\tskb->priority = ipv6_get_dsfield(ipv6_hdr(skb)) >> 2;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (params->flags & SKBEDIT_F_QUEUE_MAPPING &&\n\t    skb->dev->real_num_tx_queues > params->queue_mapping) {\n#ifdef CONFIG_NET_EGRESS\n\t\tnetdev_xmit_skip_txqueue(true);\n#endif\n\t\tskb_set_queue_mapping(skb, tcf_skbedit_hash(params, skb));\n\t}\n\tif (params->flags & SKBEDIT_F_MARK) {\n\t\tskb->mark &= ~params->mask;\n\t\tskb->mark |= params->mark & params->mask;\n\t}\n\tif (params->flags & SKBEDIT_F_PTYPE)\n\t\tskb->pkt_type = params->ptype;\n\treturn action;\n\nerr:\n\tqstats_drop_inc(this_cpu_ptr(d->common.cpu_qstats));\n\treturn TC_ACT_SHOT;\n}\n\nstatic void tcf_skbedit_stats_update(struct tc_action *a, u64 bytes,\n\t\t\t\t     u64 packets, u64 drops,\n\t\t\t\t     u64 lastuse, bool hw)\n{\n\tstruct tcf_skbedit *d = to_skbedit(a);\n\tstruct tcf_t *tm = &d->tcf_tm;\n\n\ttcf_action_update_stats(a, bytes, packets, drops, hw);\n\ttm->lastuse = max_t(u64, tm->lastuse, lastuse);\n}\n\nstatic const struct nla_policy skbedit_policy[TCA_SKBEDIT_MAX + 1] = {\n\t[TCA_SKBEDIT_PARMS]\t\t= { .len = sizeof(struct tc_skbedit) },\n\t[TCA_SKBEDIT_PRIORITY]\t\t= { .len = sizeof(u32) },\n\t[TCA_SKBEDIT_QUEUE_MAPPING]\t= { .len = sizeof(u16) },\n\t[TCA_SKBEDIT_MARK]\t\t= { .len = sizeof(u32) },\n\t[TCA_SKBEDIT_PTYPE]\t\t= { .len = sizeof(u16) },\n\t[TCA_SKBEDIT_MASK]\t\t= { .len = sizeof(u32) },\n\t[TCA_SKBEDIT_FLAGS]\t\t= { .len = sizeof(u64) },\n\t[TCA_SKBEDIT_QUEUE_MAPPING_MAX]\t= { .len = sizeof(u16) },\n};\n\nstatic int tcf_skbedit_init(struct net *net, struct nlattr *nla,\n\t\t\t    struct nlattr *est, struct tc_action **a,\n\t\t\t    struct tcf_proto *tp, u32 act_flags,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct tc_action_net *tn = net_generic(net, act_skbedit_ops.net_id);\n\tbool bind = act_flags & TCA_ACT_FLAGS_BIND;\n\tstruct tcf_skbedit_params *params_new;\n\tstruct nlattr *tb[TCA_SKBEDIT_MAX + 1];\n\tstruct tcf_chain *goto_ch = NULL;\n\tstruct tc_skbedit *parm;\n\tstruct tcf_skbedit *d;\n\tu32 flags = 0, *priority = NULL, *mark = NULL, *mask = NULL;\n\tu16 *queue_mapping = NULL, *ptype = NULL;\n\tu16 mapping_mod = 1;\n\tbool exists = false;\n\tint ret = 0, err;\n\tu32 index;\n\n\tif (nla == NULL)\n\t\treturn -EINVAL;\n\n\terr = nla_parse_nested_deprecated(tb, TCA_SKBEDIT_MAX, nla,\n\t\t\t\t\t  skbedit_policy, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[TCA_SKBEDIT_PARMS] == NULL)\n\t\treturn -EINVAL;\n\n\tif (tb[TCA_SKBEDIT_PRIORITY] != NULL) {\n\t\tflags |= SKBEDIT_F_PRIORITY;\n\t\tpriority = nla_data(tb[TCA_SKBEDIT_PRIORITY]);\n\t}\n\n\tif (tb[TCA_SKBEDIT_QUEUE_MAPPING] != NULL) {\n\t\tif (is_tcf_skbedit_ingress(act_flags) &&\n\t\t    !(act_flags & TCA_ACT_FLAGS_SKIP_SW)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"\\\"queue_mapping\\\" option on receive side is hardware only, use skip_sw\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tflags |= SKBEDIT_F_QUEUE_MAPPING;\n\t\tqueue_mapping = nla_data(tb[TCA_SKBEDIT_QUEUE_MAPPING]);\n\t}\n\n\tif (tb[TCA_SKBEDIT_PTYPE] != NULL) {\n\t\tptype = nla_data(tb[TCA_SKBEDIT_PTYPE]);\n\t\tif (!skb_pkt_type_ok(*ptype))\n\t\t\treturn -EINVAL;\n\t\tflags |= SKBEDIT_F_PTYPE;\n\t}\n\n\tif (tb[TCA_SKBEDIT_MARK] != NULL) {\n\t\tflags |= SKBEDIT_F_MARK;\n\t\tmark = nla_data(tb[TCA_SKBEDIT_MARK]);\n\t}\n\n\tif (tb[TCA_SKBEDIT_MASK] != NULL) {\n\t\tflags |= SKBEDIT_F_MASK;\n\t\tmask = nla_data(tb[TCA_SKBEDIT_MASK]);\n\t}\n\n\tif (tb[TCA_SKBEDIT_FLAGS] != NULL) {\n\t\tu64 *pure_flags = nla_data(tb[TCA_SKBEDIT_FLAGS]);\n\n\t\tif (*pure_flags & SKBEDIT_F_TXQ_SKBHASH) {\n\t\t\tu16 *queue_mapping_max;\n\n\t\t\tif (!tb[TCA_SKBEDIT_QUEUE_MAPPING] ||\n\t\t\t    !tb[TCA_SKBEDIT_QUEUE_MAPPING_MAX]) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Missing required range of queue_mapping.\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tqueue_mapping_max =\n\t\t\t\tnla_data(tb[TCA_SKBEDIT_QUEUE_MAPPING_MAX]);\n\t\t\tif (*queue_mapping_max < *queue_mapping) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"The range of queue_mapping is invalid, max < min.\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tmapping_mod = *queue_mapping_max - *queue_mapping + 1;\n\t\t\tflags |= SKBEDIT_F_TXQ_SKBHASH;\n\t\t}\n\t\tif (*pure_flags & SKBEDIT_F_INHERITDSFIELD)\n\t\t\tflags |= SKBEDIT_F_INHERITDSFIELD;\n\t}\n\n\tparm = nla_data(tb[TCA_SKBEDIT_PARMS]);\n\tindex = parm->index;\n\terr = tcf_idr_check_alloc(tn, &index, a, bind);\n\tif (err < 0)\n\t\treturn err;\n\texists = err;\n\tif (exists && bind)\n\t\treturn 0;\n\n\tif (!flags) {\n\t\tif (exists)\n\t\t\ttcf_idr_release(*a, bind);\n\t\telse\n\t\t\ttcf_idr_cleanup(tn, index);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!exists) {\n\t\tret = tcf_idr_create(tn, index, est, a,\n\t\t\t\t     &act_skbedit_ops, bind, true, act_flags);\n\t\tif (ret) {\n\t\t\ttcf_idr_cleanup(tn, index);\n\t\t\treturn ret;\n\t\t}\n\n\t\td = to_skbedit(*a);\n\t\tret = ACT_P_CREATED;\n\t} else {\n\t\td = to_skbedit(*a);\n\t\tif (!(act_flags & TCA_ACT_FLAGS_REPLACE)) {\n\t\t\ttcf_idr_release(*a, bind);\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\terr = tcf_action_check_ctrlact(parm->action, tp, &goto_ch, extack);\n\tif (err < 0)\n\t\tgoto release_idr;\n\n\tparams_new = kzalloc(sizeof(*params_new), GFP_KERNEL);\n\tif (unlikely(!params_new)) {\n\t\terr = -ENOMEM;\n\t\tgoto put_chain;\n\t}\n\n\tparams_new->flags = flags;\n\tif (flags & SKBEDIT_F_PRIORITY)\n\t\tparams_new->priority = *priority;\n\tif (flags & SKBEDIT_F_QUEUE_MAPPING) {\n\t\tparams_new->queue_mapping = *queue_mapping;\n\t\tparams_new->mapping_mod = mapping_mod;\n\t}\n\tif (flags & SKBEDIT_F_MARK)\n\t\tparams_new->mark = *mark;\n\tif (flags & SKBEDIT_F_PTYPE)\n\t\tparams_new->ptype = *ptype;\n\t \n\tparams_new->mask = 0xffffffff;\n\tif (flags & SKBEDIT_F_MASK)\n\t\tparams_new->mask = *mask;\n\n\tspin_lock_bh(&d->tcf_lock);\n\tgoto_ch = tcf_action_set_ctrlact(*a, parm->action, goto_ch);\n\tparams_new = rcu_replace_pointer(d->params, params_new,\n\t\t\t\t\t lockdep_is_held(&d->tcf_lock));\n\tspin_unlock_bh(&d->tcf_lock);\n\tif (params_new)\n\t\tkfree_rcu(params_new, rcu);\n\tif (goto_ch)\n\t\ttcf_chain_put_by_act(goto_ch);\n\n\treturn ret;\nput_chain:\n\tif (goto_ch)\n\t\ttcf_chain_put_by_act(goto_ch);\nrelease_idr:\n\ttcf_idr_release(*a, bind);\n\treturn err;\n}\n\nstatic int tcf_skbedit_dump(struct sk_buff *skb, struct tc_action *a,\n\t\t\t    int bind, int ref)\n{\n\tunsigned char *b = skb_tail_pointer(skb);\n\tstruct tcf_skbedit *d = to_skbedit(a);\n\tstruct tcf_skbedit_params *params;\n\tstruct tc_skbedit opt = {\n\t\t.index   = d->tcf_index,\n\t\t.refcnt  = refcount_read(&d->tcf_refcnt) - ref,\n\t\t.bindcnt = atomic_read(&d->tcf_bindcnt) - bind,\n\t};\n\tu64 pure_flags = 0;\n\tstruct tcf_t t;\n\n\tspin_lock_bh(&d->tcf_lock);\n\tparams = rcu_dereference_protected(d->params,\n\t\t\t\t\t   lockdep_is_held(&d->tcf_lock));\n\topt.action = d->tcf_action;\n\n\tif (nla_put(skb, TCA_SKBEDIT_PARMS, sizeof(opt), &opt))\n\t\tgoto nla_put_failure;\n\tif ((params->flags & SKBEDIT_F_PRIORITY) &&\n\t    nla_put_u32(skb, TCA_SKBEDIT_PRIORITY, params->priority))\n\t\tgoto nla_put_failure;\n\tif ((params->flags & SKBEDIT_F_QUEUE_MAPPING) &&\n\t    nla_put_u16(skb, TCA_SKBEDIT_QUEUE_MAPPING, params->queue_mapping))\n\t\tgoto nla_put_failure;\n\tif ((params->flags & SKBEDIT_F_MARK) &&\n\t    nla_put_u32(skb, TCA_SKBEDIT_MARK, params->mark))\n\t\tgoto nla_put_failure;\n\tif ((params->flags & SKBEDIT_F_PTYPE) &&\n\t    nla_put_u16(skb, TCA_SKBEDIT_PTYPE, params->ptype))\n\t\tgoto nla_put_failure;\n\tif ((params->flags & SKBEDIT_F_MASK) &&\n\t    nla_put_u32(skb, TCA_SKBEDIT_MASK, params->mask))\n\t\tgoto nla_put_failure;\n\tif (params->flags & SKBEDIT_F_INHERITDSFIELD)\n\t\tpure_flags |= SKBEDIT_F_INHERITDSFIELD;\n\tif (params->flags & SKBEDIT_F_TXQ_SKBHASH) {\n\t\tif (nla_put_u16(skb, TCA_SKBEDIT_QUEUE_MAPPING_MAX,\n\t\t\t\tparams->queue_mapping + params->mapping_mod - 1))\n\t\t\tgoto nla_put_failure;\n\n\t\tpure_flags |= SKBEDIT_F_TXQ_SKBHASH;\n\t}\n\tif (pure_flags != 0 &&\n\t    nla_put(skb, TCA_SKBEDIT_FLAGS, sizeof(pure_flags), &pure_flags))\n\t\tgoto nla_put_failure;\n\n\ttcf_tm_dump(&t, &d->tcf_tm);\n\tif (nla_put_64bit(skb, TCA_SKBEDIT_TM, sizeof(t), &t, TCA_SKBEDIT_PAD))\n\t\tgoto nla_put_failure;\n\tspin_unlock_bh(&d->tcf_lock);\n\n\treturn skb->len;\n\nnla_put_failure:\n\tspin_unlock_bh(&d->tcf_lock);\n\tnlmsg_trim(skb, b);\n\treturn -1;\n}\n\nstatic void tcf_skbedit_cleanup(struct tc_action *a)\n{\n\tstruct tcf_skbedit *d = to_skbedit(a);\n\tstruct tcf_skbedit_params *params;\n\n\tparams = rcu_dereference_protected(d->params, 1);\n\tif (params)\n\t\tkfree_rcu(params, rcu);\n}\n\nstatic size_t tcf_skbedit_get_fill_size(const struct tc_action *act)\n{\n\treturn nla_total_size(sizeof(struct tc_skbedit))\n\t\t+ nla_total_size(sizeof(u32))  \n\t\t+ nla_total_size(sizeof(u16))  \n\t\t+ nla_total_size(sizeof(u16))  \n\t\t+ nla_total_size(sizeof(u32))  \n\t\t+ nla_total_size(sizeof(u16))  \n\t\t+ nla_total_size(sizeof(u32))  \n\t\t+ nla_total_size_64bit(sizeof(u64));  \n}\n\nstatic int tcf_skbedit_offload_act_setup(struct tc_action *act, void *entry_data,\n\t\t\t\t\t u32 *index_inc, bool bind,\n\t\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tif (bind) {\n\t\tstruct flow_action_entry *entry = entry_data;\n\n\t\tif (is_tcf_skbedit_mark(act)) {\n\t\t\tentry->id = FLOW_ACTION_MARK;\n\t\t\tentry->mark = tcf_skbedit_mark(act);\n\t\t} else if (is_tcf_skbedit_ptype(act)) {\n\t\t\tentry->id = FLOW_ACTION_PTYPE;\n\t\t\tentry->ptype = tcf_skbedit_ptype(act);\n\t\t} else if (is_tcf_skbedit_priority(act)) {\n\t\t\tentry->id = FLOW_ACTION_PRIORITY;\n\t\t\tentry->priority = tcf_skbedit_priority(act);\n\t\t} else if (is_tcf_skbedit_tx_queue_mapping(act)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Offload not supported when \\\"queue_mapping\\\" option is used on transmit side\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t} else if (is_tcf_skbedit_rx_queue_mapping(act)) {\n\t\t\tentry->id = FLOW_ACTION_RX_QUEUE_MAPPING;\n\t\t\tentry->rx_queue = tcf_skbedit_rx_queue_mapping(act);\n\t\t} else if (is_tcf_skbedit_inheritdsfield(act)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Offload not supported when \\\"inheritdsfield\\\" option is used\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t} else {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported skbedit option offload\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\t*index_inc = 1;\n\t} else {\n\t\tstruct flow_offload_action *fl_action = entry_data;\n\n\t\tif (is_tcf_skbedit_mark(act))\n\t\t\tfl_action->id = FLOW_ACTION_MARK;\n\t\telse if (is_tcf_skbedit_ptype(act))\n\t\t\tfl_action->id = FLOW_ACTION_PTYPE;\n\t\telse if (is_tcf_skbedit_priority(act))\n\t\t\tfl_action->id = FLOW_ACTION_PRIORITY;\n\t\telse if (is_tcf_skbedit_rx_queue_mapping(act))\n\t\t\tfl_action->id = FLOW_ACTION_RX_QUEUE_MAPPING;\n\t\telse\n\t\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic struct tc_action_ops act_skbedit_ops = {\n\t.kind\t\t=\t\"skbedit\",\n\t.id\t\t=\tTCA_ID_SKBEDIT,\n\t.owner\t\t=\tTHIS_MODULE,\n\t.act\t\t=\ttcf_skbedit_act,\n\t.stats_update\t=\ttcf_skbedit_stats_update,\n\t.dump\t\t=\ttcf_skbedit_dump,\n\t.init\t\t=\ttcf_skbedit_init,\n\t.cleanup\t=\ttcf_skbedit_cleanup,\n\t.get_fill_size\t=\ttcf_skbedit_get_fill_size,\n\t.offload_act_setup =\ttcf_skbedit_offload_act_setup,\n\t.size\t\t=\tsizeof(struct tcf_skbedit),\n};\n\nstatic __net_init int skbedit_init_net(struct net *net)\n{\n\tstruct tc_action_net *tn = net_generic(net, act_skbedit_ops.net_id);\n\n\treturn tc_action_net_init(net, tn, &act_skbedit_ops);\n}\n\nstatic void __net_exit skbedit_exit_net(struct list_head *net_list)\n{\n\ttc_action_net_exit(net_list, act_skbedit_ops.net_id);\n}\n\nstatic struct pernet_operations skbedit_net_ops = {\n\t.init = skbedit_init_net,\n\t.exit_batch = skbedit_exit_net,\n\t.id   = &act_skbedit_ops.net_id,\n\t.size = sizeof(struct tc_action_net),\n};\n\nMODULE_AUTHOR(\"Alexander Duyck, <alexander.h.duyck@intel.com>\");\nMODULE_DESCRIPTION(\"SKB Editing\");\nMODULE_LICENSE(\"GPL\");\n\nstatic int __init skbedit_init_module(void)\n{\n\treturn tcf_register_action(&act_skbedit_ops, &skbedit_net_ops);\n}\n\nstatic void __exit skbedit_cleanup_module(void)\n{\n\ttcf_unregister_action(&act_skbedit_ops, &skbedit_net_ops);\n}\n\nmodule_init(skbedit_init_module);\nmodule_exit(skbedit_cleanup_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}