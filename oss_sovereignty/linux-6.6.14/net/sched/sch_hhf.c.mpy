{
  "module_name": "sch_hhf.c",
  "hash_id": "8f084b3cf0f1992902f8b5e6bcbca0c65a5f9672f28b4e0f250dd952e81b404a",
  "original_prompt": "Ingested from linux-6.6.14/net/sched/sch_hhf.c",
  "human_readable_source": "\n \n\n#include <linux/jiffies.h>\n#include <linux/module.h>\n#include <linux/skbuff.h>\n#include <linux/vmalloc.h>\n#include <linux/siphash.h>\n#include <net/pkt_sched.h>\n#include <net/sock.h>\n\n \n\n \n#define HH_FLOWS_CNT\t 1024   \n#define HHF_ARRAYS_CNT\t 4      \n#define HHF_ARRAYS_LEN\t 1024   \n#define HHF_BIT_MASK_LEN 10     \n#define HHF_BIT_MASK\t 0x3FF  \n\n#define WDRR_BUCKET_CNT  2      \nenum wdrr_bucket_idx {\n\tWDRR_BUCKET_FOR_HH\t= 0,  \n\tWDRR_BUCKET_FOR_NON_HH\t= 1   \n};\n\n#define hhf_time_before(a, b)\t\\\n\t(typecheck(u32, a) && typecheck(u32, b) && ((s32)((a) - (b)) < 0))\n\n \nstruct hh_flow_state {\n\tu32\t\t hash_id;\t \n\tu32\t\t hit_timestamp;\t \n\tstruct list_head flowchain;\t \n};\n\n \nstruct wdrr_bucket {\n\tstruct sk_buff\t  *head;\n\tstruct sk_buff\t  *tail;\n\tstruct list_head  bucketchain;\n\tint\t\t  deficit;\n};\n\nstruct hhf_sched_data {\n\tstruct wdrr_bucket buckets[WDRR_BUCKET_CNT];\n\tsiphash_key_t\t   perturbation;    \n\tu32\t\t   quantum;         \n\tu32\t\t   drop_overlimit;  \n\tstruct list_head   *hh_flows;        \n\tu32\t\t   hh_flows_limit;             \n\tu32\t\t   hh_flows_overlimit;  \n\tu32\t\t   hh_flows_total_cnt;           \n\tu32\t\t   hh_flows_current_cnt;         \n\tu32\t\t   *hhf_arrays[HHF_ARRAYS_CNT];  \n\tu32\t\t   hhf_arrays_reset_timestamp;   \n\tunsigned long\t   *hhf_valid_bits[HHF_ARRAYS_CNT];  \n\t \n\tstruct list_head   new_buckets;  \n\tstruct list_head   old_buckets;  \n\n\t \n\tu32\t\t   hhf_reset_timeout;  \n\tu32\t\t   hhf_admit_bytes;    \n\tu32\t\t   hhf_evict_timeout;  \n\tu32\t\t   hhf_non_hh_weight;  \n};\n\nstatic u32 hhf_time_stamp(void)\n{\n\treturn jiffies;\n}\n\n \nstatic struct hh_flow_state *seek_list(const u32 hash,\n\t\t\t\t       struct list_head *head,\n\t\t\t\t       struct hhf_sched_data *q)\n{\n\tstruct hh_flow_state *flow, *next;\n\tu32 now = hhf_time_stamp();\n\n\tif (list_empty(head))\n\t\treturn NULL;\n\n\tlist_for_each_entry_safe(flow, next, head, flowchain) {\n\t\tu32 prev = flow->hit_timestamp + q->hhf_evict_timeout;\n\n\t\tif (hhf_time_before(prev, now)) {\n\t\t\t \n\t\t\tif (list_is_last(&flow->flowchain, head))\n\t\t\t\treturn NULL;\n\t\t\tlist_del(&flow->flowchain);\n\t\t\tkfree(flow);\n\t\t\tq->hh_flows_current_cnt--;\n\t\t} else if (flow->hash_id == hash) {\n\t\t\treturn flow;\n\t\t}\n\t}\n\treturn NULL;\n}\n\n \nstatic struct hh_flow_state *alloc_new_hh(struct list_head *head,\n\t\t\t\t\t  struct hhf_sched_data *q)\n{\n\tstruct hh_flow_state *flow;\n\tu32 now = hhf_time_stamp();\n\n\tif (!list_empty(head)) {\n\t\t \n\t\tlist_for_each_entry(flow, head, flowchain) {\n\t\t\tu32 prev = flow->hit_timestamp + q->hhf_evict_timeout;\n\n\t\t\tif (hhf_time_before(prev, now))\n\t\t\t\treturn flow;\n\t\t}\n\t}\n\n\tif (q->hh_flows_current_cnt >= q->hh_flows_limit) {\n\t\tq->hh_flows_overlimit++;\n\t\treturn NULL;\n\t}\n\t \n\tflow = kzalloc(sizeof(struct hh_flow_state), GFP_ATOMIC);\n\tif (!flow)\n\t\treturn NULL;\n\n\tq->hh_flows_current_cnt++;\n\tINIT_LIST_HEAD(&flow->flowchain);\n\tlist_add_tail(&flow->flowchain, head);\n\n\treturn flow;\n}\n\n \nstatic enum wdrr_bucket_idx hhf_classify(struct sk_buff *skb, struct Qdisc *sch)\n{\n\tstruct hhf_sched_data *q = qdisc_priv(sch);\n\tu32 tmp_hash, hash;\n\tu32 xorsum, filter_pos[HHF_ARRAYS_CNT], flow_pos;\n\tstruct hh_flow_state *flow;\n\tu32 pkt_len, min_hhf_val;\n\tint i;\n\tu32 prev;\n\tu32 now = hhf_time_stamp();\n\n\t \n\tprev = q->hhf_arrays_reset_timestamp + q->hhf_reset_timeout;\n\tif (hhf_time_before(prev, now)) {\n\t\tfor (i = 0; i < HHF_ARRAYS_CNT; i++)\n\t\t\tbitmap_zero(q->hhf_valid_bits[i], HHF_ARRAYS_LEN);\n\t\tq->hhf_arrays_reset_timestamp = now;\n\t}\n\n\t \n\thash = skb_get_hash_perturb(skb, &q->perturbation);\n\n\t \n\tflow_pos = hash & HHF_BIT_MASK;\n\tflow = seek_list(hash, &q->hh_flows[flow_pos], q);\n\tif (flow) {  \n\t\tflow->hit_timestamp = now;\n\t\treturn WDRR_BUCKET_FOR_HH;\n\t}\n\n\t \n\ttmp_hash = hash;\n\txorsum = 0;\n\tfor (i = 0; i < HHF_ARRAYS_CNT - 1; i++) {\n\t\t \n\t\tfilter_pos[i] = tmp_hash & HHF_BIT_MASK;\n\t\txorsum ^= filter_pos[i];\n\t\ttmp_hash >>= HHF_BIT_MASK_LEN;\n\t}\n\t \n\tfilter_pos[HHF_ARRAYS_CNT - 1] = xorsum ^ tmp_hash;\n\n\tpkt_len = qdisc_pkt_len(skb);\n\tmin_hhf_val = ~0U;\n\tfor (i = 0; i < HHF_ARRAYS_CNT; i++) {\n\t\tu32 val;\n\n\t\tif (!test_bit(filter_pos[i], q->hhf_valid_bits[i])) {\n\t\t\tq->hhf_arrays[i][filter_pos[i]] = 0;\n\t\t\t__set_bit(filter_pos[i], q->hhf_valid_bits[i]);\n\t\t}\n\n\t\tval = q->hhf_arrays[i][filter_pos[i]] + pkt_len;\n\t\tif (min_hhf_val > val)\n\t\t\tmin_hhf_val = val;\n\t}\n\n\t \n\tif (min_hhf_val > q->hhf_admit_bytes) {\n\t\t \n\t\tflow = alloc_new_hh(&q->hh_flows[flow_pos], q);\n\t\tif (!flow)  \n\t\t\treturn WDRR_BUCKET_FOR_NON_HH;\n\t\tflow->hash_id = hash;\n\t\tflow->hit_timestamp = now;\n\t\tq->hh_flows_total_cnt++;\n\n\t\t \n\t\treturn WDRR_BUCKET_FOR_HH;\n\t}\n\n\t \n\tfor (i = 0; i < HHF_ARRAYS_CNT; i++) {\n\t\tif (q->hhf_arrays[i][filter_pos[i]] < min_hhf_val)\n\t\t\tq->hhf_arrays[i][filter_pos[i]] = min_hhf_val;\n\t}\n\treturn WDRR_BUCKET_FOR_NON_HH;\n}\n\n \nstatic struct sk_buff *dequeue_head(struct wdrr_bucket *bucket)\n{\n\tstruct sk_buff *skb = bucket->head;\n\n\tbucket->head = skb->next;\n\tskb_mark_not_on_list(skb);\n\treturn skb;\n}\n\n \nstatic void bucket_add(struct wdrr_bucket *bucket, struct sk_buff *skb)\n{\n\tif (bucket->head == NULL)\n\t\tbucket->head = skb;\n\telse\n\t\tbucket->tail->next = skb;\n\tbucket->tail = skb;\n\tskb->next = NULL;\n}\n\nstatic unsigned int hhf_drop(struct Qdisc *sch, struct sk_buff **to_free)\n{\n\tstruct hhf_sched_data *q = qdisc_priv(sch);\n\tstruct wdrr_bucket *bucket;\n\n\t \n\tbucket = &q->buckets[WDRR_BUCKET_FOR_HH];\n\tif (!bucket->head)\n\t\tbucket = &q->buckets[WDRR_BUCKET_FOR_NON_HH];\n\n\tif (bucket->head) {\n\t\tstruct sk_buff *skb = dequeue_head(bucket);\n\n\t\tsch->q.qlen--;\n\t\tqdisc_qstats_backlog_dec(sch, skb);\n\t\tqdisc_drop(skb, sch, to_free);\n\t}\n\n\t \n\treturn bucket - q->buckets;\n}\n\nstatic int hhf_enqueue(struct sk_buff *skb, struct Qdisc *sch,\n\t\t       struct sk_buff **to_free)\n{\n\tstruct hhf_sched_data *q = qdisc_priv(sch);\n\tenum wdrr_bucket_idx idx;\n\tstruct wdrr_bucket *bucket;\n\tunsigned int prev_backlog;\n\n\tidx = hhf_classify(skb, sch);\n\n\tbucket = &q->buckets[idx];\n\tbucket_add(bucket, skb);\n\tqdisc_qstats_backlog_inc(sch, skb);\n\n\tif (list_empty(&bucket->bucketchain)) {\n\t\tunsigned int weight;\n\n\t\t \n\t\tif (idx == WDRR_BUCKET_FOR_HH) {\n\t\t\t \n\t\t\tweight = 1;\n\t\t\tlist_add_tail(&bucket->bucketchain, &q->old_buckets);\n\t\t} else {\n\t\t\tweight = q->hhf_non_hh_weight;\n\t\t\tlist_add_tail(&bucket->bucketchain, &q->new_buckets);\n\t\t}\n\t\tbucket->deficit = weight * q->quantum;\n\t}\n\tif (++sch->q.qlen <= sch->limit)\n\t\treturn NET_XMIT_SUCCESS;\n\n\tprev_backlog = sch->qstats.backlog;\n\tq->drop_overlimit++;\n\t \n\tif (hhf_drop(sch, to_free) == idx)\n\t\treturn NET_XMIT_CN;\n\n\t \n\tqdisc_tree_reduce_backlog(sch, 1, prev_backlog - sch->qstats.backlog);\n\treturn NET_XMIT_SUCCESS;\n}\n\nstatic struct sk_buff *hhf_dequeue(struct Qdisc *sch)\n{\n\tstruct hhf_sched_data *q = qdisc_priv(sch);\n\tstruct sk_buff *skb = NULL;\n\tstruct wdrr_bucket *bucket;\n\tstruct list_head *head;\n\nbegin:\n\thead = &q->new_buckets;\n\tif (list_empty(head)) {\n\t\thead = &q->old_buckets;\n\t\tif (list_empty(head))\n\t\t\treturn NULL;\n\t}\n\tbucket = list_first_entry(head, struct wdrr_bucket, bucketchain);\n\n\tif (bucket->deficit <= 0) {\n\t\tint weight = (bucket - q->buckets == WDRR_BUCKET_FOR_HH) ?\n\t\t\t      1 : q->hhf_non_hh_weight;\n\n\t\tbucket->deficit += weight * q->quantum;\n\t\tlist_move_tail(&bucket->bucketchain, &q->old_buckets);\n\t\tgoto begin;\n\t}\n\n\tif (bucket->head) {\n\t\tskb = dequeue_head(bucket);\n\t\tsch->q.qlen--;\n\t\tqdisc_qstats_backlog_dec(sch, skb);\n\t}\n\n\tif (!skb) {\n\t\t \n\t\tif ((head == &q->new_buckets) && !list_empty(&q->old_buckets))\n\t\t\tlist_move_tail(&bucket->bucketchain, &q->old_buckets);\n\t\telse\n\t\t\tlist_del_init(&bucket->bucketchain);\n\t\tgoto begin;\n\t}\n\tqdisc_bstats_update(sch, skb);\n\tbucket->deficit -= qdisc_pkt_len(skb);\n\n\treturn skb;\n}\n\nstatic void hhf_reset(struct Qdisc *sch)\n{\n\tstruct sk_buff *skb;\n\n\twhile ((skb = hhf_dequeue(sch)) != NULL)\n\t\trtnl_kfree_skbs(skb, skb);\n}\n\nstatic void hhf_destroy(struct Qdisc *sch)\n{\n\tint i;\n\tstruct hhf_sched_data *q = qdisc_priv(sch);\n\n\tfor (i = 0; i < HHF_ARRAYS_CNT; i++) {\n\t\tkvfree(q->hhf_arrays[i]);\n\t\tkvfree(q->hhf_valid_bits[i]);\n\t}\n\n\tif (!q->hh_flows)\n\t\treturn;\n\n\tfor (i = 0; i < HH_FLOWS_CNT; i++) {\n\t\tstruct hh_flow_state *flow, *next;\n\t\tstruct list_head *head = &q->hh_flows[i];\n\n\t\tif (list_empty(head))\n\t\t\tcontinue;\n\t\tlist_for_each_entry_safe(flow, next, head, flowchain) {\n\t\t\tlist_del(&flow->flowchain);\n\t\t\tkfree(flow);\n\t\t}\n\t}\n\tkvfree(q->hh_flows);\n}\n\nstatic const struct nla_policy hhf_policy[TCA_HHF_MAX + 1] = {\n\t[TCA_HHF_BACKLOG_LIMIT]\t = { .type = NLA_U32 },\n\t[TCA_HHF_QUANTUM]\t = { .type = NLA_U32 },\n\t[TCA_HHF_HH_FLOWS_LIMIT] = { .type = NLA_U32 },\n\t[TCA_HHF_RESET_TIMEOUT]\t = { .type = NLA_U32 },\n\t[TCA_HHF_ADMIT_BYTES]\t = { .type = NLA_U32 },\n\t[TCA_HHF_EVICT_TIMEOUT]\t = { .type = NLA_U32 },\n\t[TCA_HHF_NON_HH_WEIGHT]\t = { .type = NLA_U32 },\n};\n\nstatic int hhf_change(struct Qdisc *sch, struct nlattr *opt,\n\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct hhf_sched_data *q = qdisc_priv(sch);\n\tstruct nlattr *tb[TCA_HHF_MAX + 1];\n\tunsigned int qlen, prev_backlog;\n\tint err;\n\tu64 non_hh_quantum;\n\tu32 new_quantum = q->quantum;\n\tu32 new_hhf_non_hh_weight = q->hhf_non_hh_weight;\n\n\terr = nla_parse_nested_deprecated(tb, TCA_HHF_MAX, opt, hhf_policy,\n\t\t\t\t\t  NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[TCA_HHF_QUANTUM])\n\t\tnew_quantum = nla_get_u32(tb[TCA_HHF_QUANTUM]);\n\n\tif (tb[TCA_HHF_NON_HH_WEIGHT])\n\t\tnew_hhf_non_hh_weight = nla_get_u32(tb[TCA_HHF_NON_HH_WEIGHT]);\n\n\tnon_hh_quantum = (u64)new_quantum * new_hhf_non_hh_weight;\n\tif (non_hh_quantum == 0 || non_hh_quantum > INT_MAX)\n\t\treturn -EINVAL;\n\n\tsch_tree_lock(sch);\n\n\tif (tb[TCA_HHF_BACKLOG_LIMIT])\n\t\tsch->limit = nla_get_u32(tb[TCA_HHF_BACKLOG_LIMIT]);\n\n\tq->quantum = new_quantum;\n\tq->hhf_non_hh_weight = new_hhf_non_hh_weight;\n\n\tif (tb[TCA_HHF_HH_FLOWS_LIMIT])\n\t\tq->hh_flows_limit = nla_get_u32(tb[TCA_HHF_HH_FLOWS_LIMIT]);\n\n\tif (tb[TCA_HHF_RESET_TIMEOUT]) {\n\t\tu32 us = nla_get_u32(tb[TCA_HHF_RESET_TIMEOUT]);\n\n\t\tq->hhf_reset_timeout = usecs_to_jiffies(us);\n\t}\n\n\tif (tb[TCA_HHF_ADMIT_BYTES])\n\t\tq->hhf_admit_bytes = nla_get_u32(tb[TCA_HHF_ADMIT_BYTES]);\n\n\tif (tb[TCA_HHF_EVICT_TIMEOUT]) {\n\t\tu32 us = nla_get_u32(tb[TCA_HHF_EVICT_TIMEOUT]);\n\n\t\tq->hhf_evict_timeout = usecs_to_jiffies(us);\n\t}\n\n\tqlen = sch->q.qlen;\n\tprev_backlog = sch->qstats.backlog;\n\twhile (sch->q.qlen > sch->limit) {\n\t\tstruct sk_buff *skb = hhf_dequeue(sch);\n\n\t\trtnl_kfree_skbs(skb, skb);\n\t}\n\tqdisc_tree_reduce_backlog(sch, qlen - sch->q.qlen,\n\t\t\t\t  prev_backlog - sch->qstats.backlog);\n\n\tsch_tree_unlock(sch);\n\treturn 0;\n}\n\nstatic int hhf_init(struct Qdisc *sch, struct nlattr *opt,\n\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct hhf_sched_data *q = qdisc_priv(sch);\n\tint i;\n\n\tsch->limit = 1000;\n\tq->quantum = psched_mtu(qdisc_dev(sch));\n\tget_random_bytes(&q->perturbation, sizeof(q->perturbation));\n\tINIT_LIST_HEAD(&q->new_buckets);\n\tINIT_LIST_HEAD(&q->old_buckets);\n\n\t \n\tq->hhf_reset_timeout = HZ / 25;  \n\tq->hhf_admit_bytes = 131072;     \n\tq->hhf_evict_timeout = HZ;       \n\tq->hhf_non_hh_weight = 2;\n\n\tif (opt) {\n\t\tint err = hhf_change(sch, opt, extack);\n\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (!q->hh_flows) {\n\t\t \n\t\tq->hh_flows = kvcalloc(HH_FLOWS_CNT, sizeof(struct list_head),\n\t\t\t\t       GFP_KERNEL);\n\t\tif (!q->hh_flows)\n\t\t\treturn -ENOMEM;\n\t\tfor (i = 0; i < HH_FLOWS_CNT; i++)\n\t\t\tINIT_LIST_HEAD(&q->hh_flows[i]);\n\n\t\t \n\t\tq->hh_flows_limit = 2 * HH_FLOWS_CNT;\n\t\tq->hh_flows_overlimit = 0;\n\t\tq->hh_flows_total_cnt = 0;\n\t\tq->hh_flows_current_cnt = 0;\n\n\t\t \n\t\tfor (i = 0; i < HHF_ARRAYS_CNT; i++) {\n\t\t\tq->hhf_arrays[i] = kvcalloc(HHF_ARRAYS_LEN,\n\t\t\t\t\t\t    sizeof(u32),\n\t\t\t\t\t\t    GFP_KERNEL);\n\t\t\tif (!q->hhf_arrays[i]) {\n\t\t\t\t \n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t}\n\t\tq->hhf_arrays_reset_timestamp = hhf_time_stamp();\n\n\t\t \n\t\tfor (i = 0; i < HHF_ARRAYS_CNT; i++) {\n\t\t\tq->hhf_valid_bits[i] = kvzalloc(HHF_ARRAYS_LEN /\n\t\t\t\t\t\t\t  BITS_PER_BYTE, GFP_KERNEL);\n\t\t\tif (!q->hhf_valid_bits[i]) {\n\t\t\t\t \n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tfor (i = 0; i < WDRR_BUCKET_CNT; i++) {\n\t\t\tstruct wdrr_bucket *bucket = q->buckets + i;\n\n\t\t\tINIT_LIST_HEAD(&bucket->bucketchain);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int hhf_dump(struct Qdisc *sch, struct sk_buff *skb)\n{\n\tstruct hhf_sched_data *q = qdisc_priv(sch);\n\tstruct nlattr *opts;\n\n\topts = nla_nest_start_noflag(skb, TCA_OPTIONS);\n\tif (opts == NULL)\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u32(skb, TCA_HHF_BACKLOG_LIMIT, sch->limit) ||\n\t    nla_put_u32(skb, TCA_HHF_QUANTUM, q->quantum) ||\n\t    nla_put_u32(skb, TCA_HHF_HH_FLOWS_LIMIT, q->hh_flows_limit) ||\n\t    nla_put_u32(skb, TCA_HHF_RESET_TIMEOUT,\n\t\t\tjiffies_to_usecs(q->hhf_reset_timeout)) ||\n\t    nla_put_u32(skb, TCA_HHF_ADMIT_BYTES, q->hhf_admit_bytes) ||\n\t    nla_put_u32(skb, TCA_HHF_EVICT_TIMEOUT,\n\t\t\tjiffies_to_usecs(q->hhf_evict_timeout)) ||\n\t    nla_put_u32(skb, TCA_HHF_NON_HH_WEIGHT, q->hhf_non_hh_weight))\n\t\tgoto nla_put_failure;\n\n\treturn nla_nest_end(skb, opts);\n\nnla_put_failure:\n\treturn -1;\n}\n\nstatic int hhf_dump_stats(struct Qdisc *sch, struct gnet_dump *d)\n{\n\tstruct hhf_sched_data *q = qdisc_priv(sch);\n\tstruct tc_hhf_xstats st = {\n\t\t.drop_overlimit = q->drop_overlimit,\n\t\t.hh_overlimit\t= q->hh_flows_overlimit,\n\t\t.hh_tot_count\t= q->hh_flows_total_cnt,\n\t\t.hh_cur_count\t= q->hh_flows_current_cnt,\n\t};\n\n\treturn gnet_stats_copy_app(d, &st, sizeof(st));\n}\n\nstatic struct Qdisc_ops hhf_qdisc_ops __read_mostly = {\n\t.id\t\t=\t\"hhf\",\n\t.priv_size\t=\tsizeof(struct hhf_sched_data),\n\n\t.enqueue\t=\thhf_enqueue,\n\t.dequeue\t=\thhf_dequeue,\n\t.peek\t\t=\tqdisc_peek_dequeued,\n\t.init\t\t=\thhf_init,\n\t.reset\t\t=\thhf_reset,\n\t.destroy\t=\thhf_destroy,\n\t.change\t\t=\thhf_change,\n\t.dump\t\t=\thhf_dump,\n\t.dump_stats\t=\thhf_dump_stats,\n\t.owner\t\t=\tTHIS_MODULE,\n};\n\nstatic int __init hhf_module_init(void)\n{\n\treturn register_qdisc(&hhf_qdisc_ops);\n}\n\nstatic void __exit hhf_module_exit(void)\n{\n\tunregister_qdisc(&hhf_qdisc_ops);\n}\n\nmodule_init(hhf_module_init)\nmodule_exit(hhf_module_exit)\nMODULE_AUTHOR(\"Terry Lam\");\nMODULE_AUTHOR(\"Nandita Dukkipati\");\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Heavy-Hitter Filter (HHF)\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}