{
  "module_name": "sch_choke.c",
  "hash_id": "fedc1abcfbe146dd29c249880133bf74c2425ba29efb2a619aab0c515fa8ecf3",
  "original_prompt": "Ingested from linux-6.6.14/net/sched/sch_choke.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/skbuff.h>\n#include <linux/vmalloc.h>\n#include <net/pkt_sched.h>\n#include <net/pkt_cls.h>\n#include <net/inet_ecn.h>\n#include <net/red.h>\n#include <net/flow_dissector.h>\n\n \n\n \n#define CHOKE_MAX_QUEUE\t(128*1024 - 1)\n\nstruct choke_sched_data {\n \n\tu32\t\t limit;\n\tunsigned char\t flags;\n\n\tstruct red_parms parms;\n\n \n\tstruct red_vars  vars;\n\tstruct {\n\t\tu32\tprob_drop;\t \n\t\tu32\tprob_mark;\t \n\t\tu32\tforced_drop;\t \n\t\tu32\tforced_mark;\t \n\t\tu32\tpdrop;           \n\t\tu32\tmatched;\t \n\t} stats;\n\n\tunsigned int\t head;\n\tunsigned int\t tail;\n\n\tunsigned int\t tab_mask;  \n\n\tstruct sk_buff **tab;\n};\n\n \nstatic unsigned int choke_len(const struct choke_sched_data *q)\n{\n\treturn (q->tail - q->head) & q->tab_mask;\n}\n\n \nstatic int use_ecn(const struct choke_sched_data *q)\n{\n\treturn q->flags & TC_RED_ECN;\n}\n\n \nstatic int use_harddrop(const struct choke_sched_data *q)\n{\n\treturn q->flags & TC_RED_HARDDROP;\n}\n\n \nstatic void choke_zap_head_holes(struct choke_sched_data *q)\n{\n\tdo {\n\t\tq->head = (q->head + 1) & q->tab_mask;\n\t\tif (q->head == q->tail)\n\t\t\tbreak;\n\t} while (q->tab[q->head] == NULL);\n}\n\n \nstatic void choke_zap_tail_holes(struct choke_sched_data *q)\n{\n\tdo {\n\t\tq->tail = (q->tail - 1) & q->tab_mask;\n\t\tif (q->head == q->tail)\n\t\t\tbreak;\n\t} while (q->tab[q->tail] == NULL);\n}\n\n \nstatic void choke_drop_by_idx(struct Qdisc *sch, unsigned int idx,\n\t\t\t      struct sk_buff **to_free)\n{\n\tstruct choke_sched_data *q = qdisc_priv(sch);\n\tstruct sk_buff *skb = q->tab[idx];\n\n\tq->tab[idx] = NULL;\n\n\tif (idx == q->head)\n\t\tchoke_zap_head_holes(q);\n\tif (idx == q->tail)\n\t\tchoke_zap_tail_holes(q);\n\n\tqdisc_qstats_backlog_dec(sch, skb);\n\tqdisc_tree_reduce_backlog(sch, 1, qdisc_pkt_len(skb));\n\tqdisc_drop(skb, sch, to_free);\n\t--sch->q.qlen;\n}\n\nstruct choke_skb_cb {\n\tu8\t\t\tkeys_valid;\n\tstruct\t\t\tflow_keys_digest keys;\n};\n\nstatic inline struct choke_skb_cb *choke_skb_cb(const struct sk_buff *skb)\n{\n\tqdisc_cb_private_validate(skb, sizeof(struct choke_skb_cb));\n\treturn (struct choke_skb_cb *)qdisc_skb_cb(skb)->data;\n}\n\n \nstatic bool choke_match_flow(struct sk_buff *skb1,\n\t\t\t     struct sk_buff *skb2)\n{\n\tstruct flow_keys temp;\n\n\tif (skb1->protocol != skb2->protocol)\n\t\treturn false;\n\n\tif (!choke_skb_cb(skb1)->keys_valid) {\n\t\tchoke_skb_cb(skb1)->keys_valid = 1;\n\t\tskb_flow_dissect_flow_keys(skb1, &temp, 0);\n\t\tmake_flow_keys_digest(&choke_skb_cb(skb1)->keys, &temp);\n\t}\n\n\tif (!choke_skb_cb(skb2)->keys_valid) {\n\t\tchoke_skb_cb(skb2)->keys_valid = 1;\n\t\tskb_flow_dissect_flow_keys(skb2, &temp, 0);\n\t\tmake_flow_keys_digest(&choke_skb_cb(skb2)->keys, &temp);\n\t}\n\n\treturn !memcmp(&choke_skb_cb(skb1)->keys,\n\t\t       &choke_skb_cb(skb2)->keys,\n\t\t       sizeof(choke_skb_cb(skb1)->keys));\n}\n\n \nstatic struct sk_buff *choke_peek_random(const struct choke_sched_data *q,\n\t\t\t\t\t unsigned int *pidx)\n{\n\tstruct sk_buff *skb;\n\tint retrys = 3;\n\n\tdo {\n\t\t*pidx = (q->head + get_random_u32_below(choke_len(q))) & q->tab_mask;\n\t\tskb = q->tab[*pidx];\n\t\tif (skb)\n\t\t\treturn skb;\n\t} while (--retrys > 0);\n\n\treturn q->tab[*pidx = q->head];\n}\n\n \nstatic bool choke_match_random(const struct choke_sched_data *q,\n\t\t\t       struct sk_buff *nskb,\n\t\t\t       unsigned int *pidx)\n{\n\tstruct sk_buff *oskb;\n\n\tif (q->head == q->tail)\n\t\treturn false;\n\n\toskb = choke_peek_random(q, pidx);\n\treturn choke_match_flow(oskb, nskb);\n}\n\nstatic int choke_enqueue(struct sk_buff *skb, struct Qdisc *sch,\n\t\t\t struct sk_buff **to_free)\n{\n\tstruct choke_sched_data *q = qdisc_priv(sch);\n\tconst struct red_parms *p = &q->parms;\n\n\tchoke_skb_cb(skb)->keys_valid = 0;\n\t \n\tq->vars.qavg = red_calc_qavg(p, &q->vars, sch->q.qlen);\n\tif (red_is_idling(&q->vars))\n\t\tred_end_of_idle_period(&q->vars);\n\n\t \n\tif (q->vars.qavg <= p->qth_min)\n\t\tq->vars.qcount = -1;\n\telse {\n\t\tunsigned int idx;\n\n\t\t \n\t\tif (choke_match_random(q, skb, &idx)) {\n\t\t\tq->stats.matched++;\n\t\t\tchoke_drop_by_idx(sch, idx, to_free);\n\t\t\tgoto congestion_drop;\n\t\t}\n\n\t\t \n\t\tif (q->vars.qavg > p->qth_max) {\n\t\t\tq->vars.qcount = -1;\n\n\t\t\tqdisc_qstats_overlimit(sch);\n\t\t\tif (use_harddrop(q) || !use_ecn(q) ||\n\t\t\t    !INET_ECN_set_ce(skb)) {\n\t\t\t\tq->stats.forced_drop++;\n\t\t\t\tgoto congestion_drop;\n\t\t\t}\n\n\t\t\tq->stats.forced_mark++;\n\t\t} else if (++q->vars.qcount) {\n\t\t\tif (red_mark_probability(p, &q->vars, q->vars.qavg)) {\n\t\t\t\tq->vars.qcount = 0;\n\t\t\t\tq->vars.qR = red_random(p);\n\n\t\t\t\tqdisc_qstats_overlimit(sch);\n\t\t\t\tif (!use_ecn(q) || !INET_ECN_set_ce(skb)) {\n\t\t\t\t\tq->stats.prob_drop++;\n\t\t\t\t\tgoto congestion_drop;\n\t\t\t\t}\n\n\t\t\t\tq->stats.prob_mark++;\n\t\t\t}\n\t\t} else\n\t\t\tq->vars.qR = red_random(p);\n\t}\n\n\t \n\tif (sch->q.qlen < q->limit) {\n\t\tq->tab[q->tail] = skb;\n\t\tq->tail = (q->tail + 1) & q->tab_mask;\n\t\t++sch->q.qlen;\n\t\tqdisc_qstats_backlog_inc(sch, skb);\n\t\treturn NET_XMIT_SUCCESS;\n\t}\n\n\tq->stats.pdrop++;\n\treturn qdisc_drop(skb, sch, to_free);\n\ncongestion_drop:\n\tqdisc_drop(skb, sch, to_free);\n\treturn NET_XMIT_CN;\n}\n\nstatic struct sk_buff *choke_dequeue(struct Qdisc *sch)\n{\n\tstruct choke_sched_data *q = qdisc_priv(sch);\n\tstruct sk_buff *skb;\n\n\tif (q->head == q->tail) {\n\t\tif (!red_is_idling(&q->vars))\n\t\t\tred_start_of_idle_period(&q->vars);\n\t\treturn NULL;\n\t}\n\n\tskb = q->tab[q->head];\n\tq->tab[q->head] = NULL;\n\tchoke_zap_head_holes(q);\n\t--sch->q.qlen;\n\tqdisc_qstats_backlog_dec(sch, skb);\n\tqdisc_bstats_update(sch, skb);\n\n\treturn skb;\n}\n\nstatic void choke_reset(struct Qdisc *sch)\n{\n\tstruct choke_sched_data *q = qdisc_priv(sch);\n\n\twhile (q->head != q->tail) {\n\t\tstruct sk_buff *skb = q->tab[q->head];\n\n\t\tq->head = (q->head + 1) & q->tab_mask;\n\t\tif (!skb)\n\t\t\tcontinue;\n\t\trtnl_qdisc_drop(skb, sch);\n\t}\n\n\tif (q->tab)\n\t\tmemset(q->tab, 0, (q->tab_mask + 1) * sizeof(struct sk_buff *));\n\tq->head = q->tail = 0;\n\tred_restart(&q->vars);\n}\n\nstatic const struct nla_policy choke_policy[TCA_CHOKE_MAX + 1] = {\n\t[TCA_CHOKE_PARMS]\t= { .len = sizeof(struct tc_red_qopt) },\n\t[TCA_CHOKE_STAB]\t= { .len = RED_STAB_SIZE },\n\t[TCA_CHOKE_MAX_P]\t= { .type = NLA_U32 },\n};\n\n\nstatic void choke_free(void *addr)\n{\n\tkvfree(addr);\n}\n\nstatic int choke_change(struct Qdisc *sch, struct nlattr *opt,\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct choke_sched_data *q = qdisc_priv(sch);\n\tstruct nlattr *tb[TCA_CHOKE_MAX + 1];\n\tconst struct tc_red_qopt *ctl;\n\tint err;\n\tstruct sk_buff **old = NULL;\n\tunsigned int mask;\n\tu32 max_P;\n\tu8 *stab;\n\n\tif (opt == NULL)\n\t\treturn -EINVAL;\n\n\terr = nla_parse_nested_deprecated(tb, TCA_CHOKE_MAX, opt,\n\t\t\t\t\t  choke_policy, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[TCA_CHOKE_PARMS] == NULL ||\n\t    tb[TCA_CHOKE_STAB] == NULL)\n\t\treturn -EINVAL;\n\n\tmax_P = tb[TCA_CHOKE_MAX_P] ? nla_get_u32(tb[TCA_CHOKE_MAX_P]) : 0;\n\n\tctl = nla_data(tb[TCA_CHOKE_PARMS]);\n\tstab = nla_data(tb[TCA_CHOKE_STAB]);\n\tif (!red_check_params(ctl->qth_min, ctl->qth_max, ctl->Wlog, ctl->Scell_log, stab))\n\t\treturn -EINVAL;\n\n\tif (ctl->limit > CHOKE_MAX_QUEUE)\n\t\treturn -EINVAL;\n\n\tmask = roundup_pow_of_two(ctl->limit + 1) - 1;\n\tif (mask != q->tab_mask) {\n\t\tstruct sk_buff **ntab;\n\n\t\tntab = kvcalloc(mask + 1, sizeof(struct sk_buff *), GFP_KERNEL);\n\t\tif (!ntab)\n\t\t\treturn -ENOMEM;\n\n\t\tsch_tree_lock(sch);\n\t\told = q->tab;\n\t\tif (old) {\n\t\t\tunsigned int oqlen = sch->q.qlen, tail = 0;\n\t\t\tunsigned dropped = 0;\n\n\t\t\twhile (q->head != q->tail) {\n\t\t\t\tstruct sk_buff *skb = q->tab[q->head];\n\n\t\t\t\tq->head = (q->head + 1) & q->tab_mask;\n\t\t\t\tif (!skb)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (tail < mask) {\n\t\t\t\t\tntab[tail++] = skb;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tdropped += qdisc_pkt_len(skb);\n\t\t\t\tqdisc_qstats_backlog_dec(sch, skb);\n\t\t\t\t--sch->q.qlen;\n\t\t\t\trtnl_qdisc_drop(skb, sch);\n\t\t\t}\n\t\t\tqdisc_tree_reduce_backlog(sch, oqlen - sch->q.qlen, dropped);\n\t\t\tq->head = 0;\n\t\t\tq->tail = tail;\n\t\t}\n\n\t\tq->tab_mask = mask;\n\t\tq->tab = ntab;\n\t} else\n\t\tsch_tree_lock(sch);\n\n\tq->flags = ctl->flags;\n\tq->limit = ctl->limit;\n\n\tred_set_parms(&q->parms, ctl->qth_min, ctl->qth_max, ctl->Wlog,\n\t\t      ctl->Plog, ctl->Scell_log,\n\t\t      stab,\n\t\t      max_P);\n\tred_set_vars(&q->vars);\n\n\tif (q->head == q->tail)\n\t\tred_end_of_idle_period(&q->vars);\n\n\tsch_tree_unlock(sch);\n\tchoke_free(old);\n\treturn 0;\n}\n\nstatic int choke_init(struct Qdisc *sch, struct nlattr *opt,\n\t\t      struct netlink_ext_ack *extack)\n{\n\treturn choke_change(sch, opt, extack);\n}\n\nstatic int choke_dump(struct Qdisc *sch, struct sk_buff *skb)\n{\n\tstruct choke_sched_data *q = qdisc_priv(sch);\n\tstruct nlattr *opts = NULL;\n\tstruct tc_red_qopt opt = {\n\t\t.limit\t\t= q->limit,\n\t\t.flags\t\t= q->flags,\n\t\t.qth_min\t= q->parms.qth_min >> q->parms.Wlog,\n\t\t.qth_max\t= q->parms.qth_max >> q->parms.Wlog,\n\t\t.Wlog\t\t= q->parms.Wlog,\n\t\t.Plog\t\t= q->parms.Plog,\n\t\t.Scell_log\t= q->parms.Scell_log,\n\t};\n\n\topts = nla_nest_start_noflag(skb, TCA_OPTIONS);\n\tif (opts == NULL)\n\t\tgoto nla_put_failure;\n\n\tif (nla_put(skb, TCA_CHOKE_PARMS, sizeof(opt), &opt) ||\n\t    nla_put_u32(skb, TCA_CHOKE_MAX_P, q->parms.max_P))\n\t\tgoto nla_put_failure;\n\treturn nla_nest_end(skb, opts);\n\nnla_put_failure:\n\tnla_nest_cancel(skb, opts);\n\treturn -EMSGSIZE;\n}\n\nstatic int choke_dump_stats(struct Qdisc *sch, struct gnet_dump *d)\n{\n\tstruct choke_sched_data *q = qdisc_priv(sch);\n\tstruct tc_choke_xstats st = {\n\t\t.early\t= q->stats.prob_drop + q->stats.forced_drop,\n\t\t.marked\t= q->stats.prob_mark + q->stats.forced_mark,\n\t\t.pdrop\t= q->stats.pdrop,\n\t\t.matched = q->stats.matched,\n\t};\n\n\treturn gnet_stats_copy_app(d, &st, sizeof(st));\n}\n\nstatic void choke_destroy(struct Qdisc *sch)\n{\n\tstruct choke_sched_data *q = qdisc_priv(sch);\n\n\tchoke_free(q->tab);\n}\n\nstatic struct sk_buff *choke_peek_head(struct Qdisc *sch)\n{\n\tstruct choke_sched_data *q = qdisc_priv(sch);\n\n\treturn (q->head != q->tail) ? q->tab[q->head] : NULL;\n}\n\nstatic struct Qdisc_ops choke_qdisc_ops __read_mostly = {\n\t.id\t\t=\t\"choke\",\n\t.priv_size\t=\tsizeof(struct choke_sched_data),\n\n\t.enqueue\t=\tchoke_enqueue,\n\t.dequeue\t=\tchoke_dequeue,\n\t.peek\t\t=\tchoke_peek_head,\n\t.init\t\t=\tchoke_init,\n\t.destroy\t=\tchoke_destroy,\n\t.reset\t\t=\tchoke_reset,\n\t.change\t\t=\tchoke_change,\n\t.dump\t\t=\tchoke_dump,\n\t.dump_stats\t=\tchoke_dump_stats,\n\t.owner\t\t=\tTHIS_MODULE,\n};\n\nstatic int __init choke_module_init(void)\n{\n\treturn register_qdisc(&choke_qdisc_ops);\n}\n\nstatic void __exit choke_module_exit(void)\n{\n\tunregister_qdisc(&choke_qdisc_ops);\n}\n\nmodule_init(choke_module_init)\nmodule_exit(choke_module_exit)\n\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}