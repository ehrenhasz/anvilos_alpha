{
  "module_name": "gen_stats.c",
  "hash_id": "4100c1e529ce0da0205ff9e93ff4a2c0081f0a4f4761f452715d661d4f97896d",
  "original_prompt": "Ingested from linux-6.6.14/net/core/gen_stats.c",
  "human_readable_source": "\n \n\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/socket.h>\n#include <linux/rtnetlink.h>\n#include <linux/gen_stats.h>\n#include <net/netlink.h>\n#include <net/gen_stats.h>\n#include <net/sch_generic.h>\n\nstatic inline int\ngnet_stats_copy(struct gnet_dump *d, int type, void *buf, int size, int padattr)\n{\n\tif (nla_put_64bit(d->skb, type, size, buf, padattr))\n\t\tgoto nla_put_failure;\n\treturn 0;\n\nnla_put_failure:\n\tif (d->lock)\n\t\tspin_unlock_bh(d->lock);\n\tkfree(d->xstats);\n\td->xstats = NULL;\n\td->xstats_len = 0;\n\treturn -1;\n}\n\n \nint\ngnet_stats_start_copy_compat(struct sk_buff *skb, int type, int tc_stats_type,\n\t\t\t     int xstats_type, spinlock_t *lock,\n\t\t\t     struct gnet_dump *d, int padattr)\n\t__acquires(lock)\n{\n\tmemset(d, 0, sizeof(*d));\n\n\tif (type)\n\t\td->tail = (struct nlattr *)skb_tail_pointer(skb);\n\td->skb = skb;\n\td->compat_tc_stats = tc_stats_type;\n\td->compat_xstats = xstats_type;\n\td->padattr = padattr;\n\tif (lock) {\n\t\td->lock = lock;\n\t\tspin_lock_bh(lock);\n\t}\n\tif (d->tail) {\n\t\tint ret = gnet_stats_copy(d, type, NULL, 0, padattr);\n\n\t\t \n\t\tif (ret == 0 && d->tail->nla_type == padattr)\n\t\t\td->tail = (struct nlattr *)((char *)d->tail +\n\t\t\t\t\t\t    NLA_ALIGN(d->tail->nla_len));\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL(gnet_stats_start_copy_compat);\n\n \nint\ngnet_stats_start_copy(struct sk_buff *skb, int type, spinlock_t *lock,\n\t\t      struct gnet_dump *d, int padattr)\n{\n\treturn gnet_stats_start_copy_compat(skb, type, 0, 0, lock, d, padattr);\n}\nEXPORT_SYMBOL(gnet_stats_start_copy);\n\n \nvoid gnet_stats_basic_sync_init(struct gnet_stats_basic_sync *b)\n{\n\tu64_stats_set(&b->bytes, 0);\n\tu64_stats_set(&b->packets, 0);\n\tu64_stats_init(&b->syncp);\n}\nEXPORT_SYMBOL(gnet_stats_basic_sync_init);\n\nstatic void gnet_stats_add_basic_cpu(struct gnet_stats_basic_sync *bstats,\n\t\t\t\t     struct gnet_stats_basic_sync __percpu *cpu)\n{\n\tu64 t_bytes = 0, t_packets = 0;\n\tint i;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct gnet_stats_basic_sync *bcpu = per_cpu_ptr(cpu, i);\n\t\tunsigned int start;\n\t\tu64 bytes, packets;\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&bcpu->syncp);\n\t\t\tbytes = u64_stats_read(&bcpu->bytes);\n\t\t\tpackets = u64_stats_read(&bcpu->packets);\n\t\t} while (u64_stats_fetch_retry(&bcpu->syncp, start));\n\n\t\tt_bytes += bytes;\n\t\tt_packets += packets;\n\t}\n\t_bstats_update(bstats, t_bytes, t_packets);\n}\n\nvoid gnet_stats_add_basic(struct gnet_stats_basic_sync *bstats,\n\t\t\t  struct gnet_stats_basic_sync __percpu *cpu,\n\t\t\t  struct gnet_stats_basic_sync *b, bool running)\n{\n\tunsigned int start;\n\tu64 bytes = 0;\n\tu64 packets = 0;\n\n\tWARN_ON_ONCE((cpu || running) && in_hardirq());\n\n\tif (cpu) {\n\t\tgnet_stats_add_basic_cpu(bstats, cpu);\n\t\treturn;\n\t}\n\tdo {\n\t\tif (running)\n\t\t\tstart = u64_stats_fetch_begin(&b->syncp);\n\t\tbytes = u64_stats_read(&b->bytes);\n\t\tpackets = u64_stats_read(&b->packets);\n\t} while (running && u64_stats_fetch_retry(&b->syncp, start));\n\n\t_bstats_update(bstats, bytes, packets);\n}\nEXPORT_SYMBOL(gnet_stats_add_basic);\n\nstatic void gnet_stats_read_basic(u64 *ret_bytes, u64 *ret_packets,\n\t\t\t\t  struct gnet_stats_basic_sync __percpu *cpu,\n\t\t\t\t  struct gnet_stats_basic_sync *b, bool running)\n{\n\tunsigned int start;\n\n\tif (cpu) {\n\t\tu64 t_bytes = 0, t_packets = 0;\n\t\tint i;\n\n\t\tfor_each_possible_cpu(i) {\n\t\t\tstruct gnet_stats_basic_sync *bcpu = per_cpu_ptr(cpu, i);\n\t\t\tunsigned int start;\n\t\t\tu64 bytes, packets;\n\n\t\t\tdo {\n\t\t\t\tstart = u64_stats_fetch_begin(&bcpu->syncp);\n\t\t\t\tbytes = u64_stats_read(&bcpu->bytes);\n\t\t\t\tpackets = u64_stats_read(&bcpu->packets);\n\t\t\t} while (u64_stats_fetch_retry(&bcpu->syncp, start));\n\n\t\t\tt_bytes += bytes;\n\t\t\tt_packets += packets;\n\t\t}\n\t\t*ret_bytes = t_bytes;\n\t\t*ret_packets = t_packets;\n\t\treturn;\n\t}\n\tdo {\n\t\tif (running)\n\t\t\tstart = u64_stats_fetch_begin(&b->syncp);\n\t\t*ret_bytes = u64_stats_read(&b->bytes);\n\t\t*ret_packets = u64_stats_read(&b->packets);\n\t} while (running && u64_stats_fetch_retry(&b->syncp, start));\n}\n\nstatic int\n___gnet_stats_copy_basic(struct gnet_dump *d,\n\t\t\t struct gnet_stats_basic_sync __percpu *cpu,\n\t\t\t struct gnet_stats_basic_sync *b,\n\t\t\t int type, bool running)\n{\n\tu64 bstats_bytes, bstats_packets;\n\n\tgnet_stats_read_basic(&bstats_bytes, &bstats_packets, cpu, b, running);\n\n\tif (d->compat_tc_stats && type == TCA_STATS_BASIC) {\n\t\td->tc_stats.bytes = bstats_bytes;\n\t\td->tc_stats.packets = bstats_packets;\n\t}\n\n\tif (d->tail) {\n\t\tstruct gnet_stats_basic sb;\n\t\tint res;\n\n\t\tmemset(&sb, 0, sizeof(sb));\n\t\tsb.bytes = bstats_bytes;\n\t\tsb.packets = bstats_packets;\n\t\tres = gnet_stats_copy(d, type, &sb, sizeof(sb), TCA_STATS_PAD);\n\t\tif (res < 0 || sb.packets == bstats_packets)\n\t\t\treturn res;\n\t\t \n\t\treturn gnet_stats_copy(d, TCA_STATS_PKT64, &bstats_packets,\n\t\t\t\t       sizeof(bstats_packets), TCA_STATS_PAD);\n\t}\n\treturn 0;\n}\n\n \nint\ngnet_stats_copy_basic(struct gnet_dump *d,\n\t\t      struct gnet_stats_basic_sync __percpu *cpu,\n\t\t      struct gnet_stats_basic_sync *b,\n\t\t      bool running)\n{\n\treturn ___gnet_stats_copy_basic(d, cpu, b, TCA_STATS_BASIC, running);\n}\nEXPORT_SYMBOL(gnet_stats_copy_basic);\n\n \nint\ngnet_stats_copy_basic_hw(struct gnet_dump *d,\n\t\t\t struct gnet_stats_basic_sync __percpu *cpu,\n\t\t\t struct gnet_stats_basic_sync *b,\n\t\t\t bool running)\n{\n\treturn ___gnet_stats_copy_basic(d, cpu, b, TCA_STATS_BASIC_HW, running);\n}\nEXPORT_SYMBOL(gnet_stats_copy_basic_hw);\n\n \nint\ngnet_stats_copy_rate_est(struct gnet_dump *d,\n\t\t\t struct net_rate_estimator __rcu **rate_est)\n{\n\tstruct gnet_stats_rate_est64 sample;\n\tstruct gnet_stats_rate_est est;\n\tint res;\n\n\tif (!gen_estimator_read(rate_est, &sample))\n\t\treturn 0;\n\test.bps = min_t(u64, UINT_MAX, sample.bps);\n\t \n\test.pps = sample.pps;\n\n\tif (d->compat_tc_stats) {\n\t\td->tc_stats.bps = est.bps;\n\t\td->tc_stats.pps = est.pps;\n\t}\n\n\tif (d->tail) {\n\t\tres = gnet_stats_copy(d, TCA_STATS_RATE_EST, &est, sizeof(est),\n\t\t\t\t      TCA_STATS_PAD);\n\t\tif (res < 0 || est.bps == sample.bps)\n\t\t\treturn res;\n\t\t \n\t\treturn gnet_stats_copy(d, TCA_STATS_RATE_EST64, &sample,\n\t\t\t\t       sizeof(sample), TCA_STATS_PAD);\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL(gnet_stats_copy_rate_est);\n\nstatic void gnet_stats_add_queue_cpu(struct gnet_stats_queue *qstats,\n\t\t\t\t     const struct gnet_stats_queue __percpu *q)\n{\n\tint i;\n\n\tfor_each_possible_cpu(i) {\n\t\tconst struct gnet_stats_queue *qcpu = per_cpu_ptr(q, i);\n\n\t\tqstats->qlen += qcpu->qlen;\n\t\tqstats->backlog += qcpu->backlog;\n\t\tqstats->drops += qcpu->drops;\n\t\tqstats->requeues += qcpu->requeues;\n\t\tqstats->overlimits += qcpu->overlimits;\n\t}\n}\n\nvoid gnet_stats_add_queue(struct gnet_stats_queue *qstats,\n\t\t\t  const struct gnet_stats_queue __percpu *cpu,\n\t\t\t  const struct gnet_stats_queue *q)\n{\n\tif (cpu) {\n\t\tgnet_stats_add_queue_cpu(qstats, cpu);\n\t} else {\n\t\tqstats->qlen += q->qlen;\n\t\tqstats->backlog += q->backlog;\n\t\tqstats->drops += q->drops;\n\t\tqstats->requeues += q->requeues;\n\t\tqstats->overlimits += q->overlimits;\n\t}\n}\nEXPORT_SYMBOL(gnet_stats_add_queue);\n\n \nint\ngnet_stats_copy_queue(struct gnet_dump *d,\n\t\t      struct gnet_stats_queue __percpu *cpu_q,\n\t\t      struct gnet_stats_queue *q, __u32 qlen)\n{\n\tstruct gnet_stats_queue qstats = {0};\n\n\tgnet_stats_add_queue(&qstats, cpu_q, q);\n\tqstats.qlen = qlen;\n\n\tif (d->compat_tc_stats) {\n\t\td->tc_stats.drops = qstats.drops;\n\t\td->tc_stats.qlen = qstats.qlen;\n\t\td->tc_stats.backlog = qstats.backlog;\n\t\td->tc_stats.overlimits = qstats.overlimits;\n\t}\n\n\tif (d->tail)\n\t\treturn gnet_stats_copy(d, TCA_STATS_QUEUE,\n\t\t\t\t       &qstats, sizeof(qstats),\n\t\t\t\t       TCA_STATS_PAD);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(gnet_stats_copy_queue);\n\n \nint\ngnet_stats_copy_app(struct gnet_dump *d, void *st, int len)\n{\n\tif (d->compat_xstats) {\n\t\td->xstats = kmemdup(st, len, GFP_ATOMIC);\n\t\tif (!d->xstats)\n\t\t\tgoto err_out;\n\t\td->xstats_len = len;\n\t}\n\n\tif (d->tail)\n\t\treturn gnet_stats_copy(d, TCA_STATS_APP, st, len,\n\t\t\t\t       TCA_STATS_PAD);\n\n\treturn 0;\n\nerr_out:\n\tif (d->lock)\n\t\tspin_unlock_bh(d->lock);\n\td->xstats_len = 0;\n\treturn -1;\n}\nEXPORT_SYMBOL(gnet_stats_copy_app);\n\n \nint\ngnet_stats_finish_copy(struct gnet_dump *d)\n{\n\tif (d->tail)\n\t\td->tail->nla_len = skb_tail_pointer(d->skb) - (u8 *)d->tail;\n\n\tif (d->compat_tc_stats)\n\t\tif (gnet_stats_copy(d, d->compat_tc_stats, &d->tc_stats,\n\t\t\t\t    sizeof(d->tc_stats), d->padattr) < 0)\n\t\t\treturn -1;\n\n\tif (d->compat_xstats && d->xstats) {\n\t\tif (gnet_stats_copy(d, d->compat_xstats, d->xstats,\n\t\t\t\t    d->xstats_len, d->padattr) < 0)\n\t\t\treturn -1;\n\t}\n\n\tif (d->lock)\n\t\tspin_unlock_bh(d->lock);\n\tkfree(d->xstats);\n\td->xstats = NULL;\n\td->xstats_len = 0;\n\treturn 0;\n}\nEXPORT_SYMBOL(gnet_stats_finish_copy);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}