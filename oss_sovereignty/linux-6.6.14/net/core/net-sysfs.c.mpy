{
  "module_name": "net-sysfs.c",
  "hash_id": "9696ffbbbb1c8ce95c48ca70ba1650d0a4487e500f94067ea0e67d62b78c8f0c",
  "original_prompt": "Ingested from linux-6.6.14/net/core/net-sysfs.c",
  "human_readable_source": "\n \n\n#include <linux/capability.h>\n#include <linux/kernel.h>\n#include <linux/netdevice.h>\n#include <linux/if_arp.h>\n#include <linux/slab.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/isolation.h>\n#include <linux/nsproxy.h>\n#include <net/sock.h>\n#include <net/net_namespace.h>\n#include <linux/rtnetlink.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/jiffies.h>\n#include <linux/pm_runtime.h>\n#include <linux/of.h>\n#include <linux/of_net.h>\n#include <linux/cpu.h>\n#include <net/netdev_rx_queue.h>\n\n#include \"dev.h\"\n#include \"net-sysfs.h\"\n\n#ifdef CONFIG_SYSFS\nstatic const char fmt_hex[] = \"%#x\\n\";\nstatic const char fmt_dec[] = \"%d\\n\";\nstatic const char fmt_ulong[] = \"%lu\\n\";\nstatic const char fmt_u64[] = \"%llu\\n\";\n\n \nstatic inline int dev_isalive(const struct net_device *dev)\n{\n\treturn dev->reg_state <= NETREG_REGISTERED;\n}\n\n \nstatic ssize_t netdev_show(const struct device *dev,\n\t\t\t   struct device_attribute *attr, char *buf,\n\t\t\t   ssize_t (*format)(const struct net_device *, char *))\n{\n\tstruct net_device *ndev = to_net_dev(dev);\n\tssize_t ret = -EINVAL;\n\n\tread_lock(&dev_base_lock);\n\tif (dev_isalive(ndev))\n\t\tret = (*format)(ndev, buf);\n\tread_unlock(&dev_base_lock);\n\n\treturn ret;\n}\n\n \n#define NETDEVICE_SHOW(field, format_string)\t\t\t\t\\\nstatic ssize_t format_##field(const struct net_device *dev, char *buf)\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\treturn sysfs_emit(buf, format_string, dev->field);\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\nstatic ssize_t field##_show(struct device *dev,\t\t\t\t\\\n\t\t\t    struct device_attribute *attr, char *buf)\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\treturn netdev_show(dev, attr, buf, format_##field);\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\n\n#define NETDEVICE_SHOW_RO(field, format_string)\t\t\t\t\\\nNETDEVICE_SHOW(field, format_string);\t\t\t\t\t\\\nstatic DEVICE_ATTR_RO(field)\n\n#define NETDEVICE_SHOW_RW(field, format_string)\t\t\t\t\\\nNETDEVICE_SHOW(field, format_string);\t\t\t\t\t\\\nstatic DEVICE_ATTR_RW(field)\n\n \nstatic ssize_t netdev_store(struct device *dev, struct device_attribute *attr,\n\t\t\t    const char *buf, size_t len,\n\t\t\t    int (*set)(struct net_device *, unsigned long))\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\tstruct net *net = dev_net(netdev);\n\tunsigned long new;\n\tint ret;\n\n\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tret = kstrtoul(buf, 0, &new);\n\tif (ret)\n\t\tgoto err;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tif (dev_isalive(netdev)) {\n\t\tret = (*set)(netdev, new);\n\t\tif (ret == 0)\n\t\t\tret = len;\n\t}\n\trtnl_unlock();\n err:\n\treturn ret;\n}\n\nNETDEVICE_SHOW_RO(dev_id, fmt_hex);\nNETDEVICE_SHOW_RO(dev_port, fmt_dec);\nNETDEVICE_SHOW_RO(addr_assign_type, fmt_dec);\nNETDEVICE_SHOW_RO(addr_len, fmt_dec);\nNETDEVICE_SHOW_RO(ifindex, fmt_dec);\nNETDEVICE_SHOW_RO(type, fmt_dec);\nNETDEVICE_SHOW_RO(link_mode, fmt_dec);\n\nstatic ssize_t iflink_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct net_device *ndev = to_net_dev(dev);\n\n\treturn sysfs_emit(buf, fmt_dec, dev_get_iflink(ndev));\n}\nstatic DEVICE_ATTR_RO(iflink);\n\nstatic ssize_t format_name_assign_type(const struct net_device *dev, char *buf)\n{\n\treturn sysfs_emit(buf, fmt_dec, dev->name_assign_type);\n}\n\nstatic ssize_t name_assign_type_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     char *buf)\n{\n\tstruct net_device *ndev = to_net_dev(dev);\n\tssize_t ret = -EINVAL;\n\n\tif (ndev->name_assign_type != NET_NAME_UNKNOWN)\n\t\tret = netdev_show(dev, attr, buf, format_name_assign_type);\n\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(name_assign_type);\n\n \nstatic ssize_t address_show(struct device *dev, struct device_attribute *attr,\n\t\t\t    char *buf)\n{\n\tstruct net_device *ndev = to_net_dev(dev);\n\tssize_t ret = -EINVAL;\n\n\tread_lock(&dev_base_lock);\n\tif (dev_isalive(ndev))\n\t\tret = sysfs_format_mac(buf, ndev->dev_addr, ndev->addr_len);\n\tread_unlock(&dev_base_lock);\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(address);\n\nstatic ssize_t broadcast_show(struct device *dev,\n\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tstruct net_device *ndev = to_net_dev(dev);\n\n\tif (dev_isalive(ndev))\n\t\treturn sysfs_format_mac(buf, ndev->broadcast, ndev->addr_len);\n\treturn -EINVAL;\n}\nstatic DEVICE_ATTR_RO(broadcast);\n\nstatic int change_carrier(struct net_device *dev, unsigned long new_carrier)\n{\n\tif (!netif_running(dev))\n\t\treturn -EINVAL;\n\treturn dev_change_carrier(dev, (bool)new_carrier);\n}\n\nstatic ssize_t carrier_store(struct device *dev, struct device_attribute *attr,\n\t\t\t     const char *buf, size_t len)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\n\t \n\tif (!netdev->netdev_ops->ndo_change_carrier)\n\t\treturn -EOPNOTSUPP;\n\n\treturn netdev_store(dev, attr, buf, len, change_carrier);\n}\n\nstatic ssize_t carrier_show(struct device *dev,\n\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\n\tif (netif_running(netdev))\n\t\treturn sysfs_emit(buf, fmt_dec, !!netif_carrier_ok(netdev));\n\n\treturn -EINVAL;\n}\nstatic DEVICE_ATTR_RW(carrier);\n\nstatic ssize_t speed_show(struct device *dev,\n\t\t\t  struct device_attribute *attr, char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\tint ret = -EINVAL;\n\n\t \n\tif (!netdev->ethtool_ops->get_link_ksettings)\n\t\treturn ret;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tif (netif_running(netdev) && netif_device_present(netdev)) {\n\t\tstruct ethtool_link_ksettings cmd;\n\n\t\tif (!__ethtool_get_link_ksettings(netdev, &cmd))\n\t\t\tret = sysfs_emit(buf, fmt_dec, cmd.base.speed);\n\t}\n\trtnl_unlock();\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(speed);\n\nstatic ssize_t duplex_show(struct device *dev,\n\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\tint ret = -EINVAL;\n\n\t \n\tif (!netdev->ethtool_ops->get_link_ksettings)\n\t\treturn ret;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tif (netif_running(netdev)) {\n\t\tstruct ethtool_link_ksettings cmd;\n\n\t\tif (!__ethtool_get_link_ksettings(netdev, &cmd)) {\n\t\t\tconst char *duplex;\n\n\t\t\tswitch (cmd.base.duplex) {\n\t\t\tcase DUPLEX_HALF:\n\t\t\t\tduplex = \"half\";\n\t\t\t\tbreak;\n\t\t\tcase DUPLEX_FULL:\n\t\t\t\tduplex = \"full\";\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tduplex = \"unknown\";\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tret = sysfs_emit(buf, \"%s\\n\", duplex);\n\t\t}\n\t}\n\trtnl_unlock();\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(duplex);\n\nstatic ssize_t testing_show(struct device *dev,\n\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\n\tif (netif_running(netdev))\n\t\treturn sysfs_emit(buf, fmt_dec, !!netif_testing(netdev));\n\n\treturn -EINVAL;\n}\nstatic DEVICE_ATTR_RO(testing);\n\nstatic ssize_t dormant_show(struct device *dev,\n\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\n\tif (netif_running(netdev))\n\t\treturn sysfs_emit(buf, fmt_dec, !!netif_dormant(netdev));\n\n\treturn -EINVAL;\n}\nstatic DEVICE_ATTR_RO(dormant);\n\nstatic const char *const operstates[] = {\n\t\"unknown\",\n\t\"notpresent\",  \n\t\"down\",\n\t\"lowerlayerdown\",\n\t\"testing\",\n\t\"dormant\",\n\t\"up\"\n};\n\nstatic ssize_t operstate_show(struct device *dev,\n\t\t\t      struct device_attribute *attr, char *buf)\n{\n\tconst struct net_device *netdev = to_net_dev(dev);\n\tunsigned char operstate;\n\n\tread_lock(&dev_base_lock);\n\toperstate = netdev->operstate;\n\tif (!netif_running(netdev))\n\t\toperstate = IF_OPER_DOWN;\n\tread_unlock(&dev_base_lock);\n\n\tif (operstate >= ARRAY_SIZE(operstates))\n\t\treturn -EINVAL;  \n\n\treturn sysfs_emit(buf, \"%s\\n\", operstates[operstate]);\n}\nstatic DEVICE_ATTR_RO(operstate);\n\nstatic ssize_t carrier_changes_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\n\treturn sysfs_emit(buf, fmt_dec,\n\t\t\t  atomic_read(&netdev->carrier_up_count) +\n\t\t\t  atomic_read(&netdev->carrier_down_count));\n}\nstatic DEVICE_ATTR_RO(carrier_changes);\n\nstatic ssize_t carrier_up_count_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\n\treturn sysfs_emit(buf, fmt_dec, atomic_read(&netdev->carrier_up_count));\n}\nstatic DEVICE_ATTR_RO(carrier_up_count);\n\nstatic ssize_t carrier_down_count_show(struct device *dev,\n\t\t\t\t       struct device_attribute *attr,\n\t\t\t\t       char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\n\treturn sysfs_emit(buf, fmt_dec, atomic_read(&netdev->carrier_down_count));\n}\nstatic DEVICE_ATTR_RO(carrier_down_count);\n\n \n\nstatic int change_mtu(struct net_device *dev, unsigned long new_mtu)\n{\n\treturn dev_set_mtu(dev, (int)new_mtu);\n}\n\nstatic ssize_t mtu_store(struct device *dev, struct device_attribute *attr,\n\t\t\t const char *buf, size_t len)\n{\n\treturn netdev_store(dev, attr, buf, len, change_mtu);\n}\nNETDEVICE_SHOW_RW(mtu, fmt_dec);\n\nstatic int change_flags(struct net_device *dev, unsigned long new_flags)\n{\n\treturn dev_change_flags(dev, (unsigned int)new_flags, NULL);\n}\n\nstatic ssize_t flags_store(struct device *dev, struct device_attribute *attr,\n\t\t\t   const char *buf, size_t len)\n{\n\treturn netdev_store(dev, attr, buf, len, change_flags);\n}\nNETDEVICE_SHOW_RW(flags, fmt_hex);\n\nstatic ssize_t tx_queue_len_store(struct device *dev,\n\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t  const char *buf, size_t len)\n{\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\treturn netdev_store(dev, attr, buf, len, dev_change_tx_queue_len);\n}\nNETDEVICE_SHOW_RW(tx_queue_len, fmt_dec);\n\nstatic int change_gro_flush_timeout(struct net_device *dev, unsigned long val)\n{\n\tWRITE_ONCE(dev->gro_flush_timeout, val);\n\treturn 0;\n}\n\nstatic ssize_t gro_flush_timeout_store(struct device *dev,\n\t\t\t\t       struct device_attribute *attr,\n\t\t\t\t       const char *buf, size_t len)\n{\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\treturn netdev_store(dev, attr, buf, len, change_gro_flush_timeout);\n}\nNETDEVICE_SHOW_RW(gro_flush_timeout, fmt_ulong);\n\nstatic int change_napi_defer_hard_irqs(struct net_device *dev, unsigned long val)\n{\n\tWRITE_ONCE(dev->napi_defer_hard_irqs, val);\n\treturn 0;\n}\n\nstatic ssize_t napi_defer_hard_irqs_store(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  const char *buf, size_t len)\n{\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\treturn netdev_store(dev, attr, buf, len, change_napi_defer_hard_irqs);\n}\nNETDEVICE_SHOW_RW(napi_defer_hard_irqs, fmt_dec);\n\nstatic ssize_t ifalias_store(struct device *dev, struct device_attribute *attr,\n\t\t\t     const char *buf, size_t len)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\tstruct net *net = dev_net(netdev);\n\tsize_t count = len;\n\tssize_t ret = 0;\n\n\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\t \n\tif (len >  0 && buf[len - 1] == '\\n')\n\t\t--count;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tif (dev_isalive(netdev)) {\n\t\tret = dev_set_alias(netdev, buf, count);\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\t\tret = len;\n\t\tnetdev_state_change(netdev);\n\t}\nerr:\n\trtnl_unlock();\n\n\treturn ret;\n}\n\nstatic ssize_t ifalias_show(struct device *dev,\n\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tconst struct net_device *netdev = to_net_dev(dev);\n\tchar tmp[IFALIASZ];\n\tssize_t ret = 0;\n\n\tret = dev_get_alias(netdev, tmp, sizeof(tmp));\n\tif (ret > 0)\n\t\tret = sysfs_emit(buf, \"%s\\n\", tmp);\n\treturn ret;\n}\nstatic DEVICE_ATTR_RW(ifalias);\n\nstatic int change_group(struct net_device *dev, unsigned long new_group)\n{\n\tdev_set_group(dev, (int)new_group);\n\treturn 0;\n}\n\nstatic ssize_t group_store(struct device *dev, struct device_attribute *attr,\n\t\t\t   const char *buf, size_t len)\n{\n\treturn netdev_store(dev, attr, buf, len, change_group);\n}\nNETDEVICE_SHOW(group, fmt_dec);\nstatic DEVICE_ATTR(netdev_group, 0644, group_show, group_store);\n\nstatic int change_proto_down(struct net_device *dev, unsigned long proto_down)\n{\n\treturn dev_change_proto_down(dev, (bool)proto_down);\n}\n\nstatic ssize_t proto_down_store(struct device *dev,\n\t\t\t\tstruct device_attribute *attr,\n\t\t\t\tconst char *buf, size_t len)\n{\n\treturn netdev_store(dev, attr, buf, len, change_proto_down);\n}\nNETDEVICE_SHOW_RW(proto_down, fmt_dec);\n\nstatic ssize_t phys_port_id_show(struct device *dev,\n\t\t\t\t struct device_attribute *attr, char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\tssize_t ret = -EINVAL;\n\n\t \n\tif (!netdev->netdev_ops->ndo_get_phys_port_id)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tif (dev_isalive(netdev)) {\n\t\tstruct netdev_phys_item_id ppid;\n\n\t\tret = dev_get_phys_port_id(netdev, &ppid);\n\t\tif (!ret)\n\t\t\tret = sysfs_emit(buf, \"%*phN\\n\", ppid.id_len, ppid.id);\n\t}\n\trtnl_unlock();\n\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(phys_port_id);\n\nstatic ssize_t phys_port_name_show(struct device *dev,\n\t\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\tssize_t ret = -EINVAL;\n\n\t \n\tif (!netdev->netdev_ops->ndo_get_phys_port_name &&\n\t    !netdev->devlink_port)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tif (dev_isalive(netdev)) {\n\t\tchar name[IFNAMSIZ];\n\n\t\tret = dev_get_phys_port_name(netdev, name, sizeof(name));\n\t\tif (!ret)\n\t\t\tret = sysfs_emit(buf, \"%s\\n\", name);\n\t}\n\trtnl_unlock();\n\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(phys_port_name);\n\nstatic ssize_t phys_switch_id_show(struct device *dev,\n\t\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\tssize_t ret = -EINVAL;\n\n\t \n\tif (!netdev->netdev_ops->ndo_get_port_parent_id &&\n\t    !netdev->devlink_port)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tif (dev_isalive(netdev)) {\n\t\tstruct netdev_phys_item_id ppid = { };\n\n\t\tret = dev_get_port_parent_id(netdev, &ppid, false);\n\t\tif (!ret)\n\t\t\tret = sysfs_emit(buf, \"%*phN\\n\", ppid.id_len, ppid.id);\n\t}\n\trtnl_unlock();\n\n\treturn ret;\n}\nstatic DEVICE_ATTR_RO(phys_switch_id);\n\nstatic ssize_t threaded_show(struct device *dev,\n\t\t\t     struct device_attribute *attr, char *buf)\n{\n\tstruct net_device *netdev = to_net_dev(dev);\n\tssize_t ret = -EINVAL;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tif (dev_isalive(netdev))\n\t\tret = sysfs_emit(buf, fmt_dec, netdev->threaded);\n\n\trtnl_unlock();\n\treturn ret;\n}\n\nstatic int modify_napi_threaded(struct net_device *dev, unsigned long val)\n{\n\tint ret;\n\n\tif (list_empty(&dev->napi_list))\n\t\treturn -EOPNOTSUPP;\n\n\tif (val != 0 && val != 1)\n\t\treturn -EOPNOTSUPP;\n\n\tret = dev_set_threaded(dev, val);\n\n\treturn ret;\n}\n\nstatic ssize_t threaded_store(struct device *dev,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      const char *buf, size_t len)\n{\n\treturn netdev_store(dev, attr, buf, len, modify_napi_threaded);\n}\nstatic DEVICE_ATTR_RW(threaded);\n\nstatic struct attribute *net_class_attrs[] __ro_after_init = {\n\t&dev_attr_netdev_group.attr,\n\t&dev_attr_type.attr,\n\t&dev_attr_dev_id.attr,\n\t&dev_attr_dev_port.attr,\n\t&dev_attr_iflink.attr,\n\t&dev_attr_ifindex.attr,\n\t&dev_attr_name_assign_type.attr,\n\t&dev_attr_addr_assign_type.attr,\n\t&dev_attr_addr_len.attr,\n\t&dev_attr_link_mode.attr,\n\t&dev_attr_address.attr,\n\t&dev_attr_broadcast.attr,\n\t&dev_attr_speed.attr,\n\t&dev_attr_duplex.attr,\n\t&dev_attr_dormant.attr,\n\t&dev_attr_testing.attr,\n\t&dev_attr_operstate.attr,\n\t&dev_attr_carrier_changes.attr,\n\t&dev_attr_ifalias.attr,\n\t&dev_attr_carrier.attr,\n\t&dev_attr_mtu.attr,\n\t&dev_attr_flags.attr,\n\t&dev_attr_tx_queue_len.attr,\n\t&dev_attr_gro_flush_timeout.attr,\n\t&dev_attr_napi_defer_hard_irqs.attr,\n\t&dev_attr_phys_port_id.attr,\n\t&dev_attr_phys_port_name.attr,\n\t&dev_attr_phys_switch_id.attr,\n\t&dev_attr_proto_down.attr,\n\t&dev_attr_carrier_up_count.attr,\n\t&dev_attr_carrier_down_count.attr,\n\t&dev_attr_threaded.attr,\n\tNULL,\n};\nATTRIBUTE_GROUPS(net_class);\n\n \nstatic ssize_t netstat_show(const struct device *d,\n\t\t\t    struct device_attribute *attr, char *buf,\n\t\t\t    unsigned long offset)\n{\n\tstruct net_device *dev = to_net_dev(d);\n\tssize_t ret = -EINVAL;\n\n\tWARN_ON(offset > sizeof(struct rtnl_link_stats64) ||\n\t\toffset % sizeof(u64) != 0);\n\n\tread_lock(&dev_base_lock);\n\tif (dev_isalive(dev)) {\n\t\tstruct rtnl_link_stats64 temp;\n\t\tconst struct rtnl_link_stats64 *stats = dev_get_stats(dev, &temp);\n\n\t\tret = sysfs_emit(buf, fmt_u64, *(u64 *)(((u8 *)stats) + offset));\n\t}\n\tread_unlock(&dev_base_lock);\n\treturn ret;\n}\n\n \n#define NETSTAT_ENTRY(name)\t\t\t\t\t\t\\\nstatic ssize_t name##_show(struct device *d,\t\t\t\t\\\n\t\t\t   struct device_attribute *attr, char *buf)\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\treturn netstat_show(d, attr, buf,\t\t\t\t\\\n\t\t\t    offsetof(struct rtnl_link_stats64, name));\t\\\n}\t\t\t\t\t\t\t\t\t\\\nstatic DEVICE_ATTR_RO(name)\n\nNETSTAT_ENTRY(rx_packets);\nNETSTAT_ENTRY(tx_packets);\nNETSTAT_ENTRY(rx_bytes);\nNETSTAT_ENTRY(tx_bytes);\nNETSTAT_ENTRY(rx_errors);\nNETSTAT_ENTRY(tx_errors);\nNETSTAT_ENTRY(rx_dropped);\nNETSTAT_ENTRY(tx_dropped);\nNETSTAT_ENTRY(multicast);\nNETSTAT_ENTRY(collisions);\nNETSTAT_ENTRY(rx_length_errors);\nNETSTAT_ENTRY(rx_over_errors);\nNETSTAT_ENTRY(rx_crc_errors);\nNETSTAT_ENTRY(rx_frame_errors);\nNETSTAT_ENTRY(rx_fifo_errors);\nNETSTAT_ENTRY(rx_missed_errors);\nNETSTAT_ENTRY(tx_aborted_errors);\nNETSTAT_ENTRY(tx_carrier_errors);\nNETSTAT_ENTRY(tx_fifo_errors);\nNETSTAT_ENTRY(tx_heartbeat_errors);\nNETSTAT_ENTRY(tx_window_errors);\nNETSTAT_ENTRY(rx_compressed);\nNETSTAT_ENTRY(tx_compressed);\nNETSTAT_ENTRY(rx_nohandler);\n\nstatic struct attribute *netstat_attrs[] __ro_after_init = {\n\t&dev_attr_rx_packets.attr,\n\t&dev_attr_tx_packets.attr,\n\t&dev_attr_rx_bytes.attr,\n\t&dev_attr_tx_bytes.attr,\n\t&dev_attr_rx_errors.attr,\n\t&dev_attr_tx_errors.attr,\n\t&dev_attr_rx_dropped.attr,\n\t&dev_attr_tx_dropped.attr,\n\t&dev_attr_multicast.attr,\n\t&dev_attr_collisions.attr,\n\t&dev_attr_rx_length_errors.attr,\n\t&dev_attr_rx_over_errors.attr,\n\t&dev_attr_rx_crc_errors.attr,\n\t&dev_attr_rx_frame_errors.attr,\n\t&dev_attr_rx_fifo_errors.attr,\n\t&dev_attr_rx_missed_errors.attr,\n\t&dev_attr_tx_aborted_errors.attr,\n\t&dev_attr_tx_carrier_errors.attr,\n\t&dev_attr_tx_fifo_errors.attr,\n\t&dev_attr_tx_heartbeat_errors.attr,\n\t&dev_attr_tx_window_errors.attr,\n\t&dev_attr_rx_compressed.attr,\n\t&dev_attr_tx_compressed.attr,\n\t&dev_attr_rx_nohandler.attr,\n\tNULL\n};\n\nstatic const struct attribute_group netstat_group = {\n\t.name  = \"statistics\",\n\t.attrs  = netstat_attrs,\n};\n\nstatic struct attribute *wireless_attrs[] = {\n\tNULL\n};\n\nstatic const struct attribute_group wireless_group = {\n\t.name = \"wireless\",\n\t.attrs = wireless_attrs,\n};\n\nstatic bool wireless_group_needed(struct net_device *ndev)\n{\n#if IS_ENABLED(CONFIG_CFG80211)\n\tif (ndev->ieee80211_ptr)\n\t\treturn true;\n#endif\n#if IS_ENABLED(CONFIG_WIRELESS_EXT)\n\tif (ndev->wireless_handlers)\n\t\treturn true;\n#endif\n\treturn false;\n}\n\n#else  \n#define net_class_groups\tNULL\n#endif  \n\n#ifdef CONFIG_SYSFS\n#define to_rx_queue_attr(_attr) \\\n\tcontainer_of(_attr, struct rx_queue_attribute, attr)\n\n#define to_rx_queue(obj) container_of(obj, struct netdev_rx_queue, kobj)\n\nstatic ssize_t rx_queue_attr_show(struct kobject *kobj, struct attribute *attr,\n\t\t\t\t  char *buf)\n{\n\tconst struct rx_queue_attribute *attribute = to_rx_queue_attr(attr);\n\tstruct netdev_rx_queue *queue = to_rx_queue(kobj);\n\n\tif (!attribute->show)\n\t\treturn -EIO;\n\n\treturn attribute->show(queue, buf);\n}\n\nstatic ssize_t rx_queue_attr_store(struct kobject *kobj, struct attribute *attr,\n\t\t\t\t   const char *buf, size_t count)\n{\n\tconst struct rx_queue_attribute *attribute = to_rx_queue_attr(attr);\n\tstruct netdev_rx_queue *queue = to_rx_queue(kobj);\n\n\tif (!attribute->store)\n\t\treturn -EIO;\n\n\treturn attribute->store(queue, buf, count);\n}\n\nstatic const struct sysfs_ops rx_queue_sysfs_ops = {\n\t.show = rx_queue_attr_show,\n\t.store = rx_queue_attr_store,\n};\n\n#ifdef CONFIG_RPS\nstatic ssize_t show_rps_map(struct netdev_rx_queue *queue, char *buf)\n{\n\tstruct rps_map *map;\n\tcpumask_var_t mask;\n\tint i, len;\n\n\tif (!zalloc_cpumask_var(&mask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\trcu_read_lock();\n\tmap = rcu_dereference(queue->rps_map);\n\tif (map)\n\t\tfor (i = 0; i < map->len; i++)\n\t\t\tcpumask_set_cpu(map->cpus[i], mask);\n\n\tlen = sysfs_emit(buf, \"%*pb\\n\", cpumask_pr_args(mask));\n\trcu_read_unlock();\n\tfree_cpumask_var(mask);\n\n\treturn len < PAGE_SIZE ? len : -EINVAL;\n}\n\nstatic int netdev_rx_queue_set_rps_mask(struct netdev_rx_queue *queue,\n\t\t\t\t\tcpumask_var_t mask)\n{\n\tstatic DEFINE_MUTEX(rps_map_mutex);\n\tstruct rps_map *old_map, *map;\n\tint cpu, i;\n\n\tmap = kzalloc(max_t(unsigned int,\n\t\t\t    RPS_MAP_SIZE(cpumask_weight(mask)), L1_CACHE_BYTES),\n\t\t      GFP_KERNEL);\n\tif (!map)\n\t\treturn -ENOMEM;\n\n\ti = 0;\n\tfor_each_cpu_and(cpu, mask, cpu_online_mask)\n\t\tmap->cpus[i++] = cpu;\n\n\tif (i) {\n\t\tmap->len = i;\n\t} else {\n\t\tkfree(map);\n\t\tmap = NULL;\n\t}\n\n\tmutex_lock(&rps_map_mutex);\n\told_map = rcu_dereference_protected(queue->rps_map,\n\t\t\t\t\t    mutex_is_locked(&rps_map_mutex));\n\trcu_assign_pointer(queue->rps_map, map);\n\n\tif (map)\n\t\tstatic_branch_inc(&rps_needed);\n\tif (old_map)\n\t\tstatic_branch_dec(&rps_needed);\n\n\tmutex_unlock(&rps_map_mutex);\n\n\tif (old_map)\n\t\tkfree_rcu(old_map, rcu);\n\treturn 0;\n}\n\nint rps_cpumask_housekeeping(struct cpumask *mask)\n{\n\tif (!cpumask_empty(mask)) {\n\t\tcpumask_and(mask, mask, housekeeping_cpumask(HK_TYPE_DOMAIN));\n\t\tcpumask_and(mask, mask, housekeeping_cpumask(HK_TYPE_WQ));\n\t\tif (cpumask_empty(mask))\n\t\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic ssize_t store_rps_map(struct netdev_rx_queue *queue,\n\t\t\t     const char *buf, size_t len)\n{\n\tcpumask_var_t mask;\n\tint err;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!alloc_cpumask_var(&mask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\terr = bitmap_parse(buf, len, cpumask_bits(mask), nr_cpumask_bits);\n\tif (err)\n\t\tgoto out;\n\n\terr = rps_cpumask_housekeeping(mask);\n\tif (err)\n\t\tgoto out;\n\n\terr = netdev_rx_queue_set_rps_mask(queue, mask);\n\nout:\n\tfree_cpumask_var(mask);\n\treturn err ? : len;\n}\n\nstatic ssize_t show_rps_dev_flow_table_cnt(struct netdev_rx_queue *queue,\n\t\t\t\t\t   char *buf)\n{\n\tstruct rps_dev_flow_table *flow_table;\n\tunsigned long val = 0;\n\n\trcu_read_lock();\n\tflow_table = rcu_dereference(queue->rps_flow_table);\n\tif (flow_table)\n\t\tval = (unsigned long)flow_table->mask + 1;\n\trcu_read_unlock();\n\n\treturn sysfs_emit(buf, \"%lu\\n\", val);\n}\n\nstatic void rps_dev_flow_table_release(struct rcu_head *rcu)\n{\n\tstruct rps_dev_flow_table *table = container_of(rcu,\n\t    struct rps_dev_flow_table, rcu);\n\tvfree(table);\n}\n\nstatic ssize_t store_rps_dev_flow_table_cnt(struct netdev_rx_queue *queue,\n\t\t\t\t\t    const char *buf, size_t len)\n{\n\tunsigned long mask, count;\n\tstruct rps_dev_flow_table *table, *old_table;\n\tstatic DEFINE_SPINLOCK(rps_dev_flow_lock);\n\tint rc;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\trc = kstrtoul(buf, 0, &count);\n\tif (rc < 0)\n\t\treturn rc;\n\n\tif (count) {\n\t\tmask = count - 1;\n\t\t \n\t\twhile ((mask | (mask >> 1)) != mask)\n\t\t\tmask |= (mask >> 1);\n\t\t \n#if BITS_PER_LONG > 32\n\t\tif (mask > (unsigned long)(u32)mask)\n\t\t\treturn -EINVAL;\n#else\n\t\tif (mask > (ULONG_MAX - RPS_DEV_FLOW_TABLE_SIZE(1))\n\t\t\t\t/ sizeof(struct rps_dev_flow)) {\n\t\t\t \n\t\t\treturn -EINVAL;\n\t\t}\n#endif\n\t\ttable = vmalloc(RPS_DEV_FLOW_TABLE_SIZE(mask + 1));\n\t\tif (!table)\n\t\t\treturn -ENOMEM;\n\n\t\ttable->mask = mask;\n\t\tfor (count = 0; count <= mask; count++)\n\t\t\ttable->flows[count].cpu = RPS_NO_CPU;\n\t} else {\n\t\ttable = NULL;\n\t}\n\n\tspin_lock(&rps_dev_flow_lock);\n\told_table = rcu_dereference_protected(queue->rps_flow_table,\n\t\t\t\t\t      lockdep_is_held(&rps_dev_flow_lock));\n\trcu_assign_pointer(queue->rps_flow_table, table);\n\tspin_unlock(&rps_dev_flow_lock);\n\n\tif (old_table)\n\t\tcall_rcu(&old_table->rcu, rps_dev_flow_table_release);\n\n\treturn len;\n}\n\nstatic struct rx_queue_attribute rps_cpus_attribute __ro_after_init\n\t= __ATTR(rps_cpus, 0644, show_rps_map, store_rps_map);\n\nstatic struct rx_queue_attribute rps_dev_flow_table_cnt_attribute __ro_after_init\n\t= __ATTR(rps_flow_cnt, 0644,\n\t\t show_rps_dev_flow_table_cnt, store_rps_dev_flow_table_cnt);\n#endif  \n\nstatic struct attribute *rx_queue_default_attrs[] __ro_after_init = {\n#ifdef CONFIG_RPS\n\t&rps_cpus_attribute.attr,\n\t&rps_dev_flow_table_cnt_attribute.attr,\n#endif\n\tNULL\n};\nATTRIBUTE_GROUPS(rx_queue_default);\n\nstatic void rx_queue_release(struct kobject *kobj)\n{\n\tstruct netdev_rx_queue *queue = to_rx_queue(kobj);\n#ifdef CONFIG_RPS\n\tstruct rps_map *map;\n\tstruct rps_dev_flow_table *flow_table;\n\n\tmap = rcu_dereference_protected(queue->rps_map, 1);\n\tif (map) {\n\t\tRCU_INIT_POINTER(queue->rps_map, NULL);\n\t\tkfree_rcu(map, rcu);\n\t}\n\n\tflow_table = rcu_dereference_protected(queue->rps_flow_table, 1);\n\tif (flow_table) {\n\t\tRCU_INIT_POINTER(queue->rps_flow_table, NULL);\n\t\tcall_rcu(&flow_table->rcu, rps_dev_flow_table_release);\n\t}\n#endif\n\n\tmemset(kobj, 0, sizeof(*kobj));\n\tnetdev_put(queue->dev, &queue->dev_tracker);\n}\n\nstatic const void *rx_queue_namespace(const struct kobject *kobj)\n{\n\tstruct netdev_rx_queue *queue = to_rx_queue(kobj);\n\tstruct device *dev = &queue->dev->dev;\n\tconst void *ns = NULL;\n\n\tif (dev->class && dev->class->ns_type)\n\t\tns = dev->class->namespace(dev);\n\n\treturn ns;\n}\n\nstatic void rx_queue_get_ownership(const struct kobject *kobj,\n\t\t\t\t   kuid_t *uid, kgid_t *gid)\n{\n\tconst struct net *net = rx_queue_namespace(kobj);\n\n\tnet_ns_get_ownership(net, uid, gid);\n}\n\nstatic const struct kobj_type rx_queue_ktype = {\n\t.sysfs_ops = &rx_queue_sysfs_ops,\n\t.release = rx_queue_release,\n\t.default_groups = rx_queue_default_groups,\n\t.namespace = rx_queue_namespace,\n\t.get_ownership = rx_queue_get_ownership,\n};\n\nstatic int rx_queue_default_mask(struct net_device *dev,\n\t\t\t\t struct netdev_rx_queue *queue)\n{\n#if IS_ENABLED(CONFIG_RPS) && IS_ENABLED(CONFIG_SYSCTL)\n\tstruct cpumask *rps_default_mask = READ_ONCE(dev_net(dev)->core.rps_default_mask);\n\n\tif (rps_default_mask && !cpumask_empty(rps_default_mask))\n\t\treturn netdev_rx_queue_set_rps_mask(queue, rps_default_mask);\n#endif\n\treturn 0;\n}\n\nstatic int rx_queue_add_kobject(struct net_device *dev, int index)\n{\n\tstruct netdev_rx_queue *queue = dev->_rx + index;\n\tstruct kobject *kobj = &queue->kobj;\n\tint error = 0;\n\n\t \n\tnetdev_hold(queue->dev, &queue->dev_tracker, GFP_KERNEL);\n\n\tkobj->kset = dev->queues_kset;\n\terror = kobject_init_and_add(kobj, &rx_queue_ktype, NULL,\n\t\t\t\t     \"rx-%u\", index);\n\tif (error)\n\t\tgoto err;\n\n\tif (dev->sysfs_rx_queue_group) {\n\t\terror = sysfs_create_group(kobj, dev->sysfs_rx_queue_group);\n\t\tif (error)\n\t\t\tgoto err;\n\t}\n\n\terror = rx_queue_default_mask(dev, queue);\n\tif (error)\n\t\tgoto err;\n\n\tkobject_uevent(kobj, KOBJ_ADD);\n\n\treturn error;\n\nerr:\n\tkobject_put(kobj);\n\treturn error;\n}\n\nstatic int rx_queue_change_owner(struct net_device *dev, int index, kuid_t kuid,\n\t\t\t\t kgid_t kgid)\n{\n\tstruct netdev_rx_queue *queue = dev->_rx + index;\n\tstruct kobject *kobj = &queue->kobj;\n\tint error;\n\n\terror = sysfs_change_owner(kobj, kuid, kgid);\n\tif (error)\n\t\treturn error;\n\n\tif (dev->sysfs_rx_queue_group)\n\t\terror = sysfs_group_change_owner(\n\t\t\tkobj, dev->sysfs_rx_queue_group, kuid, kgid);\n\n\treturn error;\n}\n#endif  \n\nint\nnet_rx_queue_update_kobjects(struct net_device *dev, int old_num, int new_num)\n{\n#ifdef CONFIG_SYSFS\n\tint i;\n\tint error = 0;\n\n#ifndef CONFIG_RPS\n\tif (!dev->sysfs_rx_queue_group)\n\t\treturn 0;\n#endif\n\tfor (i = old_num; i < new_num; i++) {\n\t\terror = rx_queue_add_kobject(dev, i);\n\t\tif (error) {\n\t\t\tnew_num = old_num;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (--i >= new_num) {\n\t\tstruct kobject *kobj = &dev->_rx[i].kobj;\n\n\t\tif (!refcount_read(&dev_net(dev)->ns.count))\n\t\t\tkobj->uevent_suppress = 1;\n\t\tif (dev->sysfs_rx_queue_group)\n\t\t\tsysfs_remove_group(kobj, dev->sysfs_rx_queue_group);\n\t\tkobject_put(kobj);\n\t}\n\n\treturn error;\n#else\n\treturn 0;\n#endif\n}\n\nstatic int net_rx_queue_change_owner(struct net_device *dev, int num,\n\t\t\t\t     kuid_t kuid, kgid_t kgid)\n{\n#ifdef CONFIG_SYSFS\n\tint error = 0;\n\tint i;\n\n#ifndef CONFIG_RPS\n\tif (!dev->sysfs_rx_queue_group)\n\t\treturn 0;\n#endif\n\tfor (i = 0; i < num; i++) {\n\t\terror = rx_queue_change_owner(dev, i, kuid, kgid);\n\t\tif (error)\n\t\t\tbreak;\n\t}\n\n\treturn error;\n#else\n\treturn 0;\n#endif\n}\n\n#ifdef CONFIG_SYSFS\n \nstruct netdev_queue_attribute {\n\tstruct attribute attr;\n\tssize_t (*show)(struct netdev_queue *queue, char *buf);\n\tssize_t (*store)(struct netdev_queue *queue,\n\t\t\t const char *buf, size_t len);\n};\n#define to_netdev_queue_attr(_attr) \\\n\tcontainer_of(_attr, struct netdev_queue_attribute, attr)\n\n#define to_netdev_queue(obj) container_of(obj, struct netdev_queue, kobj)\n\nstatic ssize_t netdev_queue_attr_show(struct kobject *kobj,\n\t\t\t\t      struct attribute *attr, char *buf)\n{\n\tconst struct netdev_queue_attribute *attribute\n\t\t= to_netdev_queue_attr(attr);\n\tstruct netdev_queue *queue = to_netdev_queue(kobj);\n\n\tif (!attribute->show)\n\t\treturn -EIO;\n\n\treturn attribute->show(queue, buf);\n}\n\nstatic ssize_t netdev_queue_attr_store(struct kobject *kobj,\n\t\t\t\t       struct attribute *attr,\n\t\t\t\t       const char *buf, size_t count)\n{\n\tconst struct netdev_queue_attribute *attribute\n\t\t= to_netdev_queue_attr(attr);\n\tstruct netdev_queue *queue = to_netdev_queue(kobj);\n\n\tif (!attribute->store)\n\t\treturn -EIO;\n\n\treturn attribute->store(queue, buf, count);\n}\n\nstatic const struct sysfs_ops netdev_queue_sysfs_ops = {\n\t.show = netdev_queue_attr_show,\n\t.store = netdev_queue_attr_store,\n};\n\nstatic ssize_t tx_timeout_show(struct netdev_queue *queue, char *buf)\n{\n\tunsigned long trans_timeout = atomic_long_read(&queue->trans_timeout);\n\n\treturn sysfs_emit(buf, fmt_ulong, trans_timeout);\n}\n\nstatic unsigned int get_netdev_queue_index(struct netdev_queue *queue)\n{\n\tstruct net_device *dev = queue->dev;\n\tunsigned int i;\n\n\ti = queue - dev->_tx;\n\tBUG_ON(i >= dev->num_tx_queues);\n\n\treturn i;\n}\n\nstatic ssize_t traffic_class_show(struct netdev_queue *queue,\n\t\t\t\t  char *buf)\n{\n\tstruct net_device *dev = queue->dev;\n\tint num_tc, tc;\n\tint index;\n\n\tif (!netif_is_multiqueue(dev))\n\t\treturn -ENOENT;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\tindex = get_netdev_queue_index(queue);\n\n\t \n\tdev = netdev_get_tx_queue(dev, index)->sb_dev ? : dev;\n\n\tnum_tc = dev->num_tc;\n\ttc = netdev_txq_to_tc(dev, index);\n\n\trtnl_unlock();\n\n\tif (tc < 0)\n\t\treturn -EINVAL;\n\n\t \n\treturn num_tc < 0 ? sysfs_emit(buf, \"%d%d\\n\", tc, num_tc) :\n\t\t\t    sysfs_emit(buf, \"%d\\n\", tc);\n}\n\n#ifdef CONFIG_XPS\nstatic ssize_t tx_maxrate_show(struct netdev_queue *queue,\n\t\t\t       char *buf)\n{\n\treturn sysfs_emit(buf, \"%lu\\n\", queue->tx_maxrate);\n}\n\nstatic ssize_t tx_maxrate_store(struct netdev_queue *queue,\n\t\t\t\tconst char *buf, size_t len)\n{\n\tstruct net_device *dev = queue->dev;\n\tint err, index = get_netdev_queue_index(queue);\n\tu32 rate = 0;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\t \n\tif (!dev->netdev_ops->ndo_set_tx_maxrate)\n\t\treturn -EOPNOTSUPP;\n\n\terr = kstrtou32(buf, 10, &rate);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\terr = -EOPNOTSUPP;\n\tif (dev->netdev_ops->ndo_set_tx_maxrate)\n\t\terr = dev->netdev_ops->ndo_set_tx_maxrate(dev, index, rate);\n\n\trtnl_unlock();\n\tif (!err) {\n\t\tqueue->tx_maxrate = rate;\n\t\treturn len;\n\t}\n\treturn err;\n}\n\nstatic struct netdev_queue_attribute queue_tx_maxrate __ro_after_init\n\t= __ATTR_RW(tx_maxrate);\n#endif\n\nstatic struct netdev_queue_attribute queue_trans_timeout __ro_after_init\n\t= __ATTR_RO(tx_timeout);\n\nstatic struct netdev_queue_attribute queue_traffic_class __ro_after_init\n\t= __ATTR_RO(traffic_class);\n\n#ifdef CONFIG_BQL\n \nstatic ssize_t bql_show(char *buf, unsigned int value)\n{\n\treturn sysfs_emit(buf, \"%u\\n\", value);\n}\n\nstatic ssize_t bql_set(const char *buf, const size_t count,\n\t\t       unsigned int *pvalue)\n{\n\tunsigned int value;\n\tint err;\n\n\tif (!strcmp(buf, \"max\") || !strcmp(buf, \"max\\n\")) {\n\t\tvalue = DQL_MAX_LIMIT;\n\t} else {\n\t\terr = kstrtouint(buf, 10, &value);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tif (value > DQL_MAX_LIMIT)\n\t\t\treturn -EINVAL;\n\t}\n\n\t*pvalue = value;\n\n\treturn count;\n}\n\nstatic ssize_t bql_show_hold_time(struct netdev_queue *queue,\n\t\t\t\t  char *buf)\n{\n\tstruct dql *dql = &queue->dql;\n\n\treturn sysfs_emit(buf, \"%u\\n\", jiffies_to_msecs(dql->slack_hold_time));\n}\n\nstatic ssize_t bql_set_hold_time(struct netdev_queue *queue,\n\t\t\t\t const char *buf, size_t len)\n{\n\tstruct dql *dql = &queue->dql;\n\tunsigned int value;\n\tint err;\n\n\terr = kstrtouint(buf, 10, &value);\n\tif (err < 0)\n\t\treturn err;\n\n\tdql->slack_hold_time = msecs_to_jiffies(value);\n\n\treturn len;\n}\n\nstatic struct netdev_queue_attribute bql_hold_time_attribute __ro_after_init\n\t= __ATTR(hold_time, 0644,\n\t\t bql_show_hold_time, bql_set_hold_time);\n\nstatic ssize_t bql_show_inflight(struct netdev_queue *queue,\n\t\t\t\t char *buf)\n{\n\tstruct dql *dql = &queue->dql;\n\n\treturn sysfs_emit(buf, \"%u\\n\", dql->num_queued - dql->num_completed);\n}\n\nstatic struct netdev_queue_attribute bql_inflight_attribute __ro_after_init =\n\t__ATTR(inflight, 0444, bql_show_inflight, NULL);\n\n#define BQL_ATTR(NAME, FIELD)\t\t\t\t\t\t\\\nstatic ssize_t bql_show_ ## NAME(struct netdev_queue *queue,\t\t\\\n\t\t\t\t char *buf)\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\treturn bql_show(buf, queue->dql.FIELD);\t\t\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\nstatic ssize_t bql_set_ ## NAME(struct netdev_queue *queue,\t\t\\\n\t\t\t\tconst char *buf, size_t len)\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\treturn bql_set(buf, len, &queue->dql.FIELD);\t\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\nstatic struct netdev_queue_attribute bql_ ## NAME ## _attribute __ro_after_init \\\n\t= __ATTR(NAME, 0644,\t\t\t\t\\\n\t\t bql_show_ ## NAME, bql_set_ ## NAME)\n\nBQL_ATTR(limit, limit);\nBQL_ATTR(limit_max, max_limit);\nBQL_ATTR(limit_min, min_limit);\n\nstatic struct attribute *dql_attrs[] __ro_after_init = {\n\t&bql_limit_attribute.attr,\n\t&bql_limit_max_attribute.attr,\n\t&bql_limit_min_attribute.attr,\n\t&bql_hold_time_attribute.attr,\n\t&bql_inflight_attribute.attr,\n\tNULL\n};\n\nstatic const struct attribute_group dql_group = {\n\t.name  = \"byte_queue_limits\",\n\t.attrs  = dql_attrs,\n};\n#endif  \n\n#ifdef CONFIG_XPS\nstatic ssize_t xps_queue_show(struct net_device *dev, unsigned int index,\n\t\t\t      int tc, char *buf, enum xps_map_type type)\n{\n\tstruct xps_dev_maps *dev_maps;\n\tunsigned long *mask;\n\tunsigned int nr_ids;\n\tint j, len;\n\n\trcu_read_lock();\n\tdev_maps = rcu_dereference(dev->xps_maps[type]);\n\n\t \n\tnr_ids = dev_maps ? dev_maps->nr_ids :\n\t\t (type == XPS_CPUS ? nr_cpu_ids : dev->num_rx_queues);\n\n\tmask = bitmap_zalloc(nr_ids, GFP_NOWAIT);\n\tif (!mask) {\n\t\trcu_read_unlock();\n\t\treturn -ENOMEM;\n\t}\n\n\tif (!dev_maps || tc >= dev_maps->num_tc)\n\t\tgoto out_no_maps;\n\n\tfor (j = 0; j < nr_ids; j++) {\n\t\tint i, tci = j * dev_maps->num_tc + tc;\n\t\tstruct xps_map *map;\n\n\t\tmap = rcu_dereference(dev_maps->attr_map[tci]);\n\t\tif (!map)\n\t\t\tcontinue;\n\n\t\tfor (i = map->len; i--;) {\n\t\t\tif (map->queues[i] == index) {\n\t\t\t\t__set_bit(j, mask);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\nout_no_maps:\n\trcu_read_unlock();\n\n\tlen = bitmap_print_to_pagebuf(false, buf, mask, nr_ids);\n\tbitmap_free(mask);\n\n\treturn len < PAGE_SIZE ? len : -EINVAL;\n}\n\nstatic ssize_t xps_cpus_show(struct netdev_queue *queue, char *buf)\n{\n\tstruct net_device *dev = queue->dev;\n\tunsigned int index;\n\tint len, tc;\n\n\tif (!netif_is_multiqueue(dev))\n\t\treturn -ENOENT;\n\n\tindex = get_netdev_queue_index(queue);\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\t \n\tdev = netdev_get_tx_queue(dev, index)->sb_dev ? : dev;\n\n\ttc = netdev_txq_to_tc(dev, index);\n\tif (tc < 0) {\n\t\trtnl_unlock();\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tget_device(&dev->dev);\n\trtnl_unlock();\n\n\tlen = xps_queue_show(dev, index, tc, buf, XPS_CPUS);\n\n\tput_device(&dev->dev);\n\treturn len;\n}\n\nstatic ssize_t xps_cpus_store(struct netdev_queue *queue,\n\t\t\t      const char *buf, size_t len)\n{\n\tstruct net_device *dev = queue->dev;\n\tunsigned int index;\n\tcpumask_var_t mask;\n\tint err;\n\n\tif (!netif_is_multiqueue(dev))\n\t\treturn -ENOENT;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!alloc_cpumask_var(&mask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\tindex = get_netdev_queue_index(queue);\n\n\terr = bitmap_parse(buf, len, cpumask_bits(mask), nr_cpumask_bits);\n\tif (err) {\n\t\tfree_cpumask_var(mask);\n\t\treturn err;\n\t}\n\n\tif (!rtnl_trylock()) {\n\t\tfree_cpumask_var(mask);\n\t\treturn restart_syscall();\n\t}\n\n\terr = netif_set_xps_queue(dev, mask, index);\n\trtnl_unlock();\n\n\tfree_cpumask_var(mask);\n\n\treturn err ? : len;\n}\n\nstatic struct netdev_queue_attribute xps_cpus_attribute __ro_after_init\n\t= __ATTR_RW(xps_cpus);\n\nstatic ssize_t xps_rxqs_show(struct netdev_queue *queue, char *buf)\n{\n\tstruct net_device *dev = queue->dev;\n\tunsigned int index;\n\tint tc;\n\n\tindex = get_netdev_queue_index(queue);\n\n\tif (!rtnl_trylock())\n\t\treturn restart_syscall();\n\n\ttc = netdev_txq_to_tc(dev, index);\n\trtnl_unlock();\n\tif (tc < 0)\n\t\treturn -EINVAL;\n\n\treturn xps_queue_show(dev, index, tc, buf, XPS_RXQS);\n}\n\nstatic ssize_t xps_rxqs_store(struct netdev_queue *queue, const char *buf,\n\t\t\t      size_t len)\n{\n\tstruct net_device *dev = queue->dev;\n\tstruct net *net = dev_net(dev);\n\tunsigned long *mask;\n\tunsigned int index;\n\tint err;\n\n\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tmask = bitmap_zalloc(dev->num_rx_queues, GFP_KERNEL);\n\tif (!mask)\n\t\treturn -ENOMEM;\n\n\tindex = get_netdev_queue_index(queue);\n\n\terr = bitmap_parse(buf, len, mask, dev->num_rx_queues);\n\tif (err) {\n\t\tbitmap_free(mask);\n\t\treturn err;\n\t}\n\n\tif (!rtnl_trylock()) {\n\t\tbitmap_free(mask);\n\t\treturn restart_syscall();\n\t}\n\n\tcpus_read_lock();\n\terr = __netif_set_xps_queue(dev, mask, index, XPS_RXQS);\n\tcpus_read_unlock();\n\n\trtnl_unlock();\n\n\tbitmap_free(mask);\n\treturn err ? : len;\n}\n\nstatic struct netdev_queue_attribute xps_rxqs_attribute __ro_after_init\n\t= __ATTR_RW(xps_rxqs);\n#endif  \n\nstatic struct attribute *netdev_queue_default_attrs[] __ro_after_init = {\n\t&queue_trans_timeout.attr,\n\t&queue_traffic_class.attr,\n#ifdef CONFIG_XPS\n\t&xps_cpus_attribute.attr,\n\t&xps_rxqs_attribute.attr,\n\t&queue_tx_maxrate.attr,\n#endif\n\tNULL\n};\nATTRIBUTE_GROUPS(netdev_queue_default);\n\nstatic void netdev_queue_release(struct kobject *kobj)\n{\n\tstruct netdev_queue *queue = to_netdev_queue(kobj);\n\n\tmemset(kobj, 0, sizeof(*kobj));\n\tnetdev_put(queue->dev, &queue->dev_tracker);\n}\n\nstatic const void *netdev_queue_namespace(const struct kobject *kobj)\n{\n\tstruct netdev_queue *queue = to_netdev_queue(kobj);\n\tstruct device *dev = &queue->dev->dev;\n\tconst void *ns = NULL;\n\n\tif (dev->class && dev->class->ns_type)\n\t\tns = dev->class->namespace(dev);\n\n\treturn ns;\n}\n\nstatic void netdev_queue_get_ownership(const struct kobject *kobj,\n\t\t\t\t       kuid_t *uid, kgid_t *gid)\n{\n\tconst struct net *net = netdev_queue_namespace(kobj);\n\n\tnet_ns_get_ownership(net, uid, gid);\n}\n\nstatic const struct kobj_type netdev_queue_ktype = {\n\t.sysfs_ops = &netdev_queue_sysfs_ops,\n\t.release = netdev_queue_release,\n\t.default_groups = netdev_queue_default_groups,\n\t.namespace = netdev_queue_namespace,\n\t.get_ownership = netdev_queue_get_ownership,\n};\n\nstatic int netdev_queue_add_kobject(struct net_device *dev, int index)\n{\n\tstruct netdev_queue *queue = dev->_tx + index;\n\tstruct kobject *kobj = &queue->kobj;\n\tint error = 0;\n\n\t \n\tnetdev_hold(queue->dev, &queue->dev_tracker, GFP_KERNEL);\n\n\tkobj->kset = dev->queues_kset;\n\terror = kobject_init_and_add(kobj, &netdev_queue_ktype, NULL,\n\t\t\t\t     \"tx-%u\", index);\n\tif (error)\n\t\tgoto err;\n\n#ifdef CONFIG_BQL\n\terror = sysfs_create_group(kobj, &dql_group);\n\tif (error)\n\t\tgoto err;\n#endif\n\n\tkobject_uevent(kobj, KOBJ_ADD);\n\treturn 0;\n\nerr:\n\tkobject_put(kobj);\n\treturn error;\n}\n\nstatic int tx_queue_change_owner(struct net_device *ndev, int index,\n\t\t\t\t kuid_t kuid, kgid_t kgid)\n{\n\tstruct netdev_queue *queue = ndev->_tx + index;\n\tstruct kobject *kobj = &queue->kobj;\n\tint error;\n\n\terror = sysfs_change_owner(kobj, kuid, kgid);\n\tif (error)\n\t\treturn error;\n\n#ifdef CONFIG_BQL\n\terror = sysfs_group_change_owner(kobj, &dql_group, kuid, kgid);\n#endif\n\treturn error;\n}\n#endif  \n\nint\nnetdev_queue_update_kobjects(struct net_device *dev, int old_num, int new_num)\n{\n#ifdef CONFIG_SYSFS\n\tint i;\n\tint error = 0;\n\n\t \n\tWARN(dev->reg_state == NETREG_UNREGISTERING && new_num > old_num,\n\t     \"New queues can't be registered after device unregistration.\");\n\n\tfor (i = old_num; i < new_num; i++) {\n\t\terror = netdev_queue_add_kobject(dev, i);\n\t\tif (error) {\n\t\t\tnew_num = old_num;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (--i >= new_num) {\n\t\tstruct netdev_queue *queue = dev->_tx + i;\n\n\t\tif (!refcount_read(&dev_net(dev)->ns.count))\n\t\t\tqueue->kobj.uevent_suppress = 1;\n#ifdef CONFIG_BQL\n\t\tsysfs_remove_group(&queue->kobj, &dql_group);\n#endif\n\t\tkobject_put(&queue->kobj);\n\t}\n\n\treturn error;\n#else\n\treturn 0;\n#endif  \n}\n\nstatic int net_tx_queue_change_owner(struct net_device *dev, int num,\n\t\t\t\t     kuid_t kuid, kgid_t kgid)\n{\n#ifdef CONFIG_SYSFS\n\tint error = 0;\n\tint i;\n\n\tfor (i = 0; i < num; i++) {\n\t\terror = tx_queue_change_owner(dev, i, kuid, kgid);\n\t\tif (error)\n\t\t\tbreak;\n\t}\n\n\treturn error;\n#else\n\treturn 0;\n#endif  \n}\n\nstatic int register_queue_kobjects(struct net_device *dev)\n{\n\tint error = 0, txq = 0, rxq = 0, real_rx = 0, real_tx = 0;\n\n#ifdef CONFIG_SYSFS\n\tdev->queues_kset = kset_create_and_add(\"queues\",\n\t\t\t\t\t       NULL, &dev->dev.kobj);\n\tif (!dev->queues_kset)\n\t\treturn -ENOMEM;\n\treal_rx = dev->real_num_rx_queues;\n#endif\n\treal_tx = dev->real_num_tx_queues;\n\n\terror = net_rx_queue_update_kobjects(dev, 0, real_rx);\n\tif (error)\n\t\tgoto error;\n\trxq = real_rx;\n\n\terror = netdev_queue_update_kobjects(dev, 0, real_tx);\n\tif (error)\n\t\tgoto error;\n\ttxq = real_tx;\n\n\treturn 0;\n\nerror:\n\tnetdev_queue_update_kobjects(dev, txq, 0);\n\tnet_rx_queue_update_kobjects(dev, rxq, 0);\n#ifdef CONFIG_SYSFS\n\tkset_unregister(dev->queues_kset);\n#endif\n\treturn error;\n}\n\nstatic int queue_change_owner(struct net_device *ndev, kuid_t kuid, kgid_t kgid)\n{\n\tint error = 0, real_rx = 0, real_tx = 0;\n\n#ifdef CONFIG_SYSFS\n\tif (ndev->queues_kset) {\n\t\terror = sysfs_change_owner(&ndev->queues_kset->kobj, kuid, kgid);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\treal_rx = ndev->real_num_rx_queues;\n#endif\n\treal_tx = ndev->real_num_tx_queues;\n\n\terror = net_rx_queue_change_owner(ndev, real_rx, kuid, kgid);\n\tif (error)\n\t\treturn error;\n\n\terror = net_tx_queue_change_owner(ndev, real_tx, kuid, kgid);\n\tif (error)\n\t\treturn error;\n\n\treturn 0;\n}\n\nstatic void remove_queue_kobjects(struct net_device *dev)\n{\n\tint real_rx = 0, real_tx = 0;\n\n#ifdef CONFIG_SYSFS\n\treal_rx = dev->real_num_rx_queues;\n#endif\n\treal_tx = dev->real_num_tx_queues;\n\n\tnet_rx_queue_update_kobjects(dev, real_rx, 0);\n\tnetdev_queue_update_kobjects(dev, real_tx, 0);\n\n\tdev->real_num_rx_queues = 0;\n\tdev->real_num_tx_queues = 0;\n#ifdef CONFIG_SYSFS\n\tkset_unregister(dev->queues_kset);\n#endif\n}\n\nstatic bool net_current_may_mount(void)\n{\n\tstruct net *net = current->nsproxy->net_ns;\n\n\treturn ns_capable(net->user_ns, CAP_SYS_ADMIN);\n}\n\nstatic void *net_grab_current_ns(void)\n{\n\tstruct net *ns = current->nsproxy->net_ns;\n#ifdef CONFIG_NET_NS\n\tif (ns)\n\t\trefcount_inc(&ns->passive);\n#endif\n\treturn ns;\n}\n\nstatic const void *net_initial_ns(void)\n{\n\treturn &init_net;\n}\n\nstatic const void *net_netlink_ns(struct sock *sk)\n{\n\treturn sock_net(sk);\n}\n\nconst struct kobj_ns_type_operations net_ns_type_operations = {\n\t.type = KOBJ_NS_TYPE_NET,\n\t.current_may_mount = net_current_may_mount,\n\t.grab_current_ns = net_grab_current_ns,\n\t.netlink_ns = net_netlink_ns,\n\t.initial_ns = net_initial_ns,\n\t.drop_ns = net_drop_ns,\n};\nEXPORT_SYMBOL_GPL(net_ns_type_operations);\n\nstatic int netdev_uevent(const struct device *d, struct kobj_uevent_env *env)\n{\n\tconst struct net_device *dev = to_net_dev(d);\n\tint retval;\n\n\t \n\tretval = add_uevent_var(env, \"INTERFACE=%s\", dev->name);\n\tif (retval)\n\t\tgoto exit;\n\n\t \n\tretval = add_uevent_var(env, \"IFINDEX=%d\", dev->ifindex);\n\nexit:\n\treturn retval;\n}\n\n \nstatic void netdev_release(struct device *d)\n{\n\tstruct net_device *dev = to_net_dev(d);\n\n\tBUG_ON(dev->reg_state != NETREG_RELEASED);\n\n\t \n\tkfree(rcu_access_pointer(dev->ifalias));\n\tnetdev_freemem(dev);\n}\n\nstatic const void *net_namespace(const struct device *d)\n{\n\tconst struct net_device *dev = to_net_dev(d);\n\n\treturn dev_net(dev);\n}\n\nstatic void net_get_ownership(const struct device *d, kuid_t *uid, kgid_t *gid)\n{\n\tconst struct net_device *dev = to_net_dev(d);\n\tconst struct net *net = dev_net(dev);\n\n\tnet_ns_get_ownership(net, uid, gid);\n}\n\nstatic struct class net_class __ro_after_init = {\n\t.name = \"net\",\n\t.dev_release = netdev_release,\n\t.dev_groups = net_class_groups,\n\t.dev_uevent = netdev_uevent,\n\t.ns_type = &net_ns_type_operations,\n\t.namespace = net_namespace,\n\t.get_ownership = net_get_ownership,\n};\n\n#ifdef CONFIG_OF\nstatic int of_dev_node_match(struct device *dev, const void *data)\n{\n\tfor (; dev; dev = dev->parent) {\n\t\tif (dev->of_node == data)\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n \nstruct net_device *of_find_net_device_by_node(struct device_node *np)\n{\n\tstruct device *dev;\n\n\tdev = class_find_device(&net_class, NULL, np, of_dev_node_match);\n\tif (!dev)\n\t\treturn NULL;\n\n\treturn to_net_dev(dev);\n}\nEXPORT_SYMBOL(of_find_net_device_by_node);\n#endif\n\n \nvoid netdev_unregister_kobject(struct net_device *ndev)\n{\n\tstruct device *dev = &ndev->dev;\n\n\tif (!refcount_read(&dev_net(ndev)->ns.count))\n\t\tdev_set_uevent_suppress(dev, 1);\n\n\tkobject_get(&dev->kobj);\n\n\tremove_queue_kobjects(ndev);\n\n\tpm_runtime_set_memalloc_noio(dev, false);\n\n\tdevice_del(dev);\n}\n\n \nint netdev_register_kobject(struct net_device *ndev)\n{\n\tstruct device *dev = &ndev->dev;\n\tconst struct attribute_group **groups = ndev->sysfs_groups;\n\tint error = 0;\n\n\tdevice_initialize(dev);\n\tdev->class = &net_class;\n\tdev->platform_data = ndev;\n\tdev->groups = groups;\n\n\tdev_set_name(dev, \"%s\", ndev->name);\n\n#ifdef CONFIG_SYSFS\n\t \n\tif (*groups)\n\t\tgroups++;\n\n\t*groups++ = &netstat_group;\n\n\tif (wireless_group_needed(ndev))\n\t\t*groups++ = &wireless_group;\n#endif  \n\n\terror = device_add(dev);\n\tif (error)\n\t\treturn error;\n\n\terror = register_queue_kobjects(ndev);\n\tif (error) {\n\t\tdevice_del(dev);\n\t\treturn error;\n\t}\n\n\tpm_runtime_set_memalloc_noio(dev, true);\n\n\treturn error;\n}\n\n \nint netdev_change_owner(struct net_device *ndev, const struct net *net_old,\n\t\t\tconst struct net *net_new)\n{\n\tkuid_t old_uid = GLOBAL_ROOT_UID, new_uid = GLOBAL_ROOT_UID;\n\tkgid_t old_gid = GLOBAL_ROOT_GID, new_gid = GLOBAL_ROOT_GID;\n\tstruct device *dev = &ndev->dev;\n\tint error;\n\n\tnet_ns_get_ownership(net_old, &old_uid, &old_gid);\n\tnet_ns_get_ownership(net_new, &new_uid, &new_gid);\n\n\t \n\tif (uid_eq(old_uid, new_uid) && gid_eq(old_gid, new_gid))\n\t\treturn 0;\n\n\terror = device_change_owner(dev, new_uid, new_gid);\n\tif (error)\n\t\treturn error;\n\n\terror = queue_change_owner(ndev, new_uid, new_gid);\n\tif (error)\n\t\treturn error;\n\n\treturn 0;\n}\n\nint netdev_class_create_file_ns(const struct class_attribute *class_attr,\n\t\t\t\tconst void *ns)\n{\n\treturn class_create_file_ns(&net_class, class_attr, ns);\n}\nEXPORT_SYMBOL(netdev_class_create_file_ns);\n\nvoid netdev_class_remove_file_ns(const struct class_attribute *class_attr,\n\t\t\t\t const void *ns)\n{\n\tclass_remove_file_ns(&net_class, class_attr, ns);\n}\nEXPORT_SYMBOL(netdev_class_remove_file_ns);\n\nint __init netdev_kobject_init(void)\n{\n\tkobj_ns_type_register(&net_ns_type_operations);\n\treturn class_register(&net_class);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}