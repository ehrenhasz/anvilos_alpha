{
  "module_name": "gro.c",
  "hash_id": "a2e3b1e382692c9c47ebd4e1dfbd6b2dd4be37f76ebfad56a993f2750008b497",
  "original_prompt": "Ingested from linux-6.6.14/net/core/gro.c",
  "human_readable_source": "\n#include <net/gro.h>\n#include <net/dst_metadata.h>\n#include <net/busy_poll.h>\n#include <trace/events/net.h>\n\n#define MAX_GRO_SKBS 8\n\n \n#define GRO_MAX_HEAD (MAX_HEADER + 128)\n\nstatic DEFINE_SPINLOCK(offload_lock);\nstruct list_head offload_base __read_mostly = LIST_HEAD_INIT(offload_base);\n \nint gro_normal_batch __read_mostly = 8;\n\n \nvoid dev_add_offload(struct packet_offload *po)\n{\n\tstruct packet_offload *elem;\n\n\tspin_lock(&offload_lock);\n\tlist_for_each_entry(elem, &offload_base, list) {\n\t\tif (po->priority < elem->priority)\n\t\t\tbreak;\n\t}\n\tlist_add_rcu(&po->list, elem->list.prev);\n\tspin_unlock(&offload_lock);\n}\nEXPORT_SYMBOL(dev_add_offload);\n\n \nstatic void __dev_remove_offload(struct packet_offload *po)\n{\n\tstruct list_head *head = &offload_base;\n\tstruct packet_offload *po1;\n\n\tspin_lock(&offload_lock);\n\n\tlist_for_each_entry(po1, head, list) {\n\t\tif (po == po1) {\n\t\t\tlist_del_rcu(&po->list);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tpr_warn(\"dev_remove_offload: %p not found\\n\", po);\nout:\n\tspin_unlock(&offload_lock);\n}\n\n \nvoid dev_remove_offload(struct packet_offload *po)\n{\n\t__dev_remove_offload(po);\n\n\tsynchronize_net();\n}\nEXPORT_SYMBOL(dev_remove_offload);\n\n\nint skb_gro_receive(struct sk_buff *p, struct sk_buff *skb)\n{\n\tstruct skb_shared_info *pinfo, *skbinfo = skb_shinfo(skb);\n\tunsigned int offset = skb_gro_offset(skb);\n\tunsigned int headlen = skb_headlen(skb);\n\tunsigned int len = skb_gro_len(skb);\n\tunsigned int delta_truesize;\n\tunsigned int gro_max_size;\n\tunsigned int new_truesize;\n\tstruct sk_buff *lp;\n\tint segs;\n\n\t \n\tif (p->pp_recycle != skb->pp_recycle)\n\t\treturn -ETOOMANYREFS;\n\n\t \n\tgro_max_size = p->protocol == htons(ETH_P_IPV6) ?\n\t\t\tREAD_ONCE(p->dev->gro_max_size) :\n\t\t\tREAD_ONCE(p->dev->gro_ipv4_max_size);\n\n\tif (unlikely(p->len + len >= gro_max_size || NAPI_GRO_CB(skb)->flush))\n\t\treturn -E2BIG;\n\n\tif (unlikely(p->len + len >= GRO_LEGACY_MAX_SIZE)) {\n\t\tif (NAPI_GRO_CB(skb)->proto != IPPROTO_TCP ||\n\t\t    (p->protocol == htons(ETH_P_IPV6) &&\n\t\t     skb_headroom(p) < sizeof(struct hop_jumbo_hdr)) ||\n\t\t    p->encapsulation)\n\t\t\treturn -E2BIG;\n\t}\n\n\tsegs = NAPI_GRO_CB(skb)->count;\n\tlp = NAPI_GRO_CB(p)->last;\n\tpinfo = skb_shinfo(lp);\n\n\tif (headlen <= offset) {\n\t\tskb_frag_t *frag;\n\t\tskb_frag_t *frag2;\n\t\tint i = skbinfo->nr_frags;\n\t\tint nr_frags = pinfo->nr_frags + i;\n\n\t\tif (nr_frags > MAX_SKB_FRAGS)\n\t\t\tgoto merge;\n\n\t\toffset -= headlen;\n\t\tpinfo->nr_frags = nr_frags;\n\t\tskbinfo->nr_frags = 0;\n\n\t\tfrag = pinfo->frags + nr_frags;\n\t\tfrag2 = skbinfo->frags + i;\n\t\tdo {\n\t\t\t*--frag = *--frag2;\n\t\t} while (--i);\n\n\t\tskb_frag_off_add(frag, offset);\n\t\tskb_frag_size_sub(frag, offset);\n\n\t\t \n\t\tnew_truesize = SKB_TRUESIZE(skb_end_offset(skb));\n\t\tdelta_truesize = skb->truesize - new_truesize;\n\n\t\tskb->truesize = new_truesize;\n\t\tskb->len -= skb->data_len;\n\t\tskb->data_len = 0;\n\n\t\tNAPI_GRO_CB(skb)->free = NAPI_GRO_FREE;\n\t\tgoto done;\n\t} else if (skb->head_frag) {\n\t\tint nr_frags = pinfo->nr_frags;\n\t\tskb_frag_t *frag = pinfo->frags + nr_frags;\n\t\tstruct page *page = virt_to_head_page(skb->head);\n\t\tunsigned int first_size = headlen - offset;\n\t\tunsigned int first_offset;\n\n\t\tif (nr_frags + 1 + skbinfo->nr_frags > MAX_SKB_FRAGS)\n\t\t\tgoto merge;\n\n\t\tfirst_offset = skb->data -\n\t\t\t       (unsigned char *)page_address(page) +\n\t\t\t       offset;\n\n\t\tpinfo->nr_frags = nr_frags + 1 + skbinfo->nr_frags;\n\n\t\tskb_frag_fill_page_desc(frag, page, first_offset, first_size);\n\n\t\tmemcpy(frag + 1, skbinfo->frags, sizeof(*frag) * skbinfo->nr_frags);\n\t\t \n\n\t\tnew_truesize = SKB_DATA_ALIGN(sizeof(struct sk_buff));\n\t\tdelta_truesize = skb->truesize - new_truesize;\n\t\tskb->truesize = new_truesize;\n\t\tNAPI_GRO_CB(skb)->free = NAPI_GRO_FREE_STOLEN_HEAD;\n\t\tgoto done;\n\t}\n\nmerge:\n\t \n\tskb->destructor = NULL;\n\tdelta_truesize = skb->truesize;\n\tif (offset > headlen) {\n\t\tunsigned int eat = offset - headlen;\n\n\t\tskb_frag_off_add(&skbinfo->frags[0], eat);\n\t\tskb_frag_size_sub(&skbinfo->frags[0], eat);\n\t\tskb->data_len -= eat;\n\t\tskb->len -= eat;\n\t\toffset = headlen;\n\t}\n\n\t__skb_pull(skb, offset);\n\n\tif (NAPI_GRO_CB(p)->last == p)\n\t\tskb_shinfo(p)->frag_list = skb;\n\telse\n\t\tNAPI_GRO_CB(p)->last->next = skb;\n\tNAPI_GRO_CB(p)->last = skb;\n\t__skb_header_release(skb);\n\tlp = p;\n\ndone:\n\tNAPI_GRO_CB(p)->count += segs;\n\tp->data_len += len;\n\tp->truesize += delta_truesize;\n\tp->len += len;\n\tif (lp != p) {\n\t\tlp->data_len += len;\n\t\tlp->truesize += delta_truesize;\n\t\tlp->len += len;\n\t}\n\tNAPI_GRO_CB(skb)->same_flow = 1;\n\treturn 0;\n}\n\n\nstatic void napi_gro_complete(struct napi_struct *napi, struct sk_buff *skb)\n{\n\tstruct packet_offload *ptype;\n\t__be16 type = skb->protocol;\n\tstruct list_head *head = &offload_base;\n\tint err = -ENOENT;\n\n\tBUILD_BUG_ON(sizeof(struct napi_gro_cb) > sizeof(skb->cb));\n\n\tif (NAPI_GRO_CB(skb)->count == 1) {\n\t\tskb_shinfo(skb)->gso_size = 0;\n\t\tgoto out;\n\t}\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(ptype, head, list) {\n\t\tif (ptype->type != type || !ptype->callbacks.gro_complete)\n\t\t\tcontinue;\n\n\t\terr = INDIRECT_CALL_INET(ptype->callbacks.gro_complete,\n\t\t\t\t\t ipv6_gro_complete, inet_gro_complete,\n\t\t\t\t\t skb, 0);\n\t\tbreak;\n\t}\n\trcu_read_unlock();\n\n\tif (err) {\n\t\tWARN_ON(&ptype->list == head);\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\nout:\n\tgro_normal_one(napi, skb, NAPI_GRO_CB(skb)->count);\n}\n\nstatic void __napi_gro_flush_chain(struct napi_struct *napi, u32 index,\n\t\t\t\t   bool flush_old)\n{\n\tstruct list_head *head = &napi->gro_hash[index].list;\n\tstruct sk_buff *skb, *p;\n\n\tlist_for_each_entry_safe_reverse(skb, p, head, list) {\n\t\tif (flush_old && NAPI_GRO_CB(skb)->age == jiffies)\n\t\t\treturn;\n\t\tskb_list_del_init(skb);\n\t\tnapi_gro_complete(napi, skb);\n\t\tnapi->gro_hash[index].count--;\n\t}\n\n\tif (!napi->gro_hash[index].count)\n\t\t__clear_bit(index, &napi->gro_bitmask);\n}\n\n \nvoid napi_gro_flush(struct napi_struct *napi, bool flush_old)\n{\n\tunsigned long bitmask = napi->gro_bitmask;\n\tunsigned int i, base = ~0U;\n\n\twhile ((i = ffs(bitmask)) != 0) {\n\t\tbitmask >>= i;\n\t\tbase += i;\n\t\t__napi_gro_flush_chain(napi, base, flush_old);\n\t}\n}\nEXPORT_SYMBOL(napi_gro_flush);\n\nstatic unsigned long gro_list_prepare_tc_ext(const struct sk_buff *skb,\n\t\t\t\t\t     const struct sk_buff *p,\n\t\t\t\t\t     unsigned long diffs)\n{\n#if IS_ENABLED(CONFIG_NET_TC_SKB_EXT)\n\tstruct tc_skb_ext *skb_ext;\n\tstruct tc_skb_ext *p_ext;\n\n\tskb_ext = skb_ext_find(skb, TC_SKB_EXT);\n\tp_ext = skb_ext_find(p, TC_SKB_EXT);\n\n\tdiffs |= (!!p_ext) ^ (!!skb_ext);\n\tif (!diffs && unlikely(skb_ext))\n\t\tdiffs |= p_ext->chain ^ skb_ext->chain;\n#endif\n\treturn diffs;\n}\n\nstatic void gro_list_prepare(const struct list_head *head,\n\t\t\t     const struct sk_buff *skb)\n{\n\tunsigned int maclen = skb->dev->hard_header_len;\n\tu32 hash = skb_get_hash_raw(skb);\n\tstruct sk_buff *p;\n\n\tlist_for_each_entry(p, head, list) {\n\t\tunsigned long diffs;\n\n\t\tNAPI_GRO_CB(p)->flush = 0;\n\n\t\tif (hash != skb_get_hash_raw(p)) {\n\t\t\tNAPI_GRO_CB(p)->same_flow = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tdiffs = (unsigned long)p->dev ^ (unsigned long)skb->dev;\n\t\tdiffs |= p->vlan_all ^ skb->vlan_all;\n\t\tdiffs |= skb_metadata_differs(p, skb);\n\t\tif (maclen == ETH_HLEN)\n\t\t\tdiffs |= compare_ether_header(skb_mac_header(p),\n\t\t\t\t\t\t      skb_mac_header(skb));\n\t\telse if (!diffs)\n\t\t\tdiffs = memcmp(skb_mac_header(p),\n\t\t\t\t       skb_mac_header(skb),\n\t\t\t\t       maclen);\n\n\t\t \n\t\tif (!diffs && unlikely(skb->slow_gro | p->slow_gro)) {\n\t\t\tdiffs |= p->sk != skb->sk;\n\t\t\tdiffs |= skb_metadata_dst_cmp(p, skb);\n\t\t\tdiffs |= skb_get_nfct(p) ^ skb_get_nfct(skb);\n\n\t\t\tdiffs |= gro_list_prepare_tc_ext(skb, p, diffs);\n\t\t}\n\n\t\tNAPI_GRO_CB(p)->same_flow = !diffs;\n\t}\n}\n\nstatic inline void skb_gro_reset_offset(struct sk_buff *skb, u32 nhoff)\n{\n\tconst struct skb_shared_info *pinfo = skb_shinfo(skb);\n\tconst skb_frag_t *frag0 = &pinfo->frags[0];\n\n\tNAPI_GRO_CB(skb)->data_offset = 0;\n\tNAPI_GRO_CB(skb)->frag0 = NULL;\n\tNAPI_GRO_CB(skb)->frag0_len = 0;\n\n\tif (!skb_headlen(skb) && pinfo->nr_frags &&\n\t    !PageHighMem(skb_frag_page(frag0)) &&\n\t    (!NET_IP_ALIGN || !((skb_frag_off(frag0) + nhoff) & 3))) {\n\t\tNAPI_GRO_CB(skb)->frag0 = skb_frag_address(frag0);\n\t\tNAPI_GRO_CB(skb)->frag0_len = min_t(unsigned int,\n\t\t\t\t\t\t    skb_frag_size(frag0),\n\t\t\t\t\t\t    skb->end - skb->tail);\n\t}\n}\n\nstatic void gro_pull_from_frag0(struct sk_buff *skb, int grow)\n{\n\tstruct skb_shared_info *pinfo = skb_shinfo(skb);\n\n\tBUG_ON(skb->end - skb->tail < grow);\n\n\tmemcpy(skb_tail_pointer(skb), NAPI_GRO_CB(skb)->frag0, grow);\n\n\tskb->data_len -= grow;\n\tskb->tail += grow;\n\n\tskb_frag_off_add(&pinfo->frags[0], grow);\n\tskb_frag_size_sub(&pinfo->frags[0], grow);\n\n\tif (unlikely(!skb_frag_size(&pinfo->frags[0]))) {\n\t\tskb_frag_unref(skb, 0);\n\t\tmemmove(pinfo->frags, pinfo->frags + 1,\n\t\t\t--pinfo->nr_frags * sizeof(pinfo->frags[0]));\n\t}\n}\n\nstatic void gro_try_pull_from_frag0(struct sk_buff *skb)\n{\n\tint grow = skb_gro_offset(skb) - skb_headlen(skb);\n\n\tif (grow > 0)\n\t\tgro_pull_from_frag0(skb, grow);\n}\n\nstatic void gro_flush_oldest(struct napi_struct *napi, struct list_head *head)\n{\n\tstruct sk_buff *oldest;\n\n\toldest = list_last_entry(head, struct sk_buff, list);\n\n\t \n\tif (WARN_ON_ONCE(!oldest))\n\t\treturn;\n\n\t \n\tskb_list_del_init(oldest);\n\tnapi_gro_complete(napi, oldest);\n}\n\nstatic enum gro_result dev_gro_receive(struct napi_struct *napi, struct sk_buff *skb)\n{\n\tu32 bucket = skb_get_hash_raw(skb) & (GRO_HASH_BUCKETS - 1);\n\tstruct gro_list *gro_list = &napi->gro_hash[bucket];\n\tstruct list_head *head = &offload_base;\n\tstruct packet_offload *ptype;\n\t__be16 type = skb->protocol;\n\tstruct sk_buff *pp = NULL;\n\tenum gro_result ret;\n\tint same_flow;\n\n\tif (netif_elide_gro(skb->dev))\n\t\tgoto normal;\n\n\tgro_list_prepare(&gro_list->list, skb);\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(ptype, head, list) {\n\t\tif (ptype->type == type && ptype->callbacks.gro_receive)\n\t\t\tgoto found_ptype;\n\t}\n\trcu_read_unlock();\n\tgoto normal;\n\nfound_ptype:\n\tskb_set_network_header(skb, skb_gro_offset(skb));\n\tskb_reset_mac_len(skb);\n\tBUILD_BUG_ON(sizeof_field(struct napi_gro_cb, zeroed) != sizeof(u32));\n\tBUILD_BUG_ON(!IS_ALIGNED(offsetof(struct napi_gro_cb, zeroed),\n\t\t\t\t\tsizeof(u32)));  \n\t*(u32 *)&NAPI_GRO_CB(skb)->zeroed = 0;\n\tNAPI_GRO_CB(skb)->flush = skb_has_frag_list(skb);\n\tNAPI_GRO_CB(skb)->is_atomic = 1;\n\tNAPI_GRO_CB(skb)->count = 1;\n\tif (unlikely(skb_is_gso(skb))) {\n\t\tNAPI_GRO_CB(skb)->count = skb_shinfo(skb)->gso_segs;\n\t\t \n\t\tif (!skb_is_gso_tcp(skb) ||\n\t\t    (skb_shinfo(skb)->gso_type & SKB_GSO_DODGY))\n\t\t\tNAPI_GRO_CB(skb)->flush = 1;\n\t}\n\n\t \n\tswitch (skb->ip_summed) {\n\tcase CHECKSUM_COMPLETE:\n\t\tNAPI_GRO_CB(skb)->csum = skb->csum;\n\t\tNAPI_GRO_CB(skb)->csum_valid = 1;\n\t\tbreak;\n\tcase CHECKSUM_UNNECESSARY:\n\t\tNAPI_GRO_CB(skb)->csum_cnt = skb->csum_level + 1;\n\t\tbreak;\n\t}\n\n\tpp = INDIRECT_CALL_INET(ptype->callbacks.gro_receive,\n\t\t\t\tipv6_gro_receive, inet_gro_receive,\n\t\t\t\t&gro_list->list, skb);\n\n\trcu_read_unlock();\n\n\tif (PTR_ERR(pp) == -EINPROGRESS) {\n\t\tret = GRO_CONSUMED;\n\t\tgoto ok;\n\t}\n\n\tsame_flow = NAPI_GRO_CB(skb)->same_flow;\n\tret = NAPI_GRO_CB(skb)->free ? GRO_MERGED_FREE : GRO_MERGED;\n\n\tif (pp) {\n\t\tskb_list_del_init(pp);\n\t\tnapi_gro_complete(napi, pp);\n\t\tgro_list->count--;\n\t}\n\n\tif (same_flow)\n\t\tgoto ok;\n\n\tif (NAPI_GRO_CB(skb)->flush)\n\t\tgoto normal;\n\n\tif (unlikely(gro_list->count >= MAX_GRO_SKBS))\n\t\tgro_flush_oldest(napi, &gro_list->list);\n\telse\n\t\tgro_list->count++;\n\n\t \n\tgro_try_pull_from_frag0(skb);\n\tNAPI_GRO_CB(skb)->age = jiffies;\n\tNAPI_GRO_CB(skb)->last = skb;\n\tif (!skb_is_gso(skb))\n\t\tskb_shinfo(skb)->gso_size = skb_gro_len(skb);\n\tlist_add(&skb->list, &gro_list->list);\n\tret = GRO_HELD;\nok:\n\tif (gro_list->count) {\n\t\tif (!test_bit(bucket, &napi->gro_bitmask))\n\t\t\t__set_bit(bucket, &napi->gro_bitmask);\n\t} else if (test_bit(bucket, &napi->gro_bitmask)) {\n\t\t__clear_bit(bucket, &napi->gro_bitmask);\n\t}\n\n\treturn ret;\n\nnormal:\n\tret = GRO_NORMAL;\n\tgro_try_pull_from_frag0(skb);\n\tgoto ok;\n}\n\nstruct packet_offload *gro_find_receive_by_type(__be16 type)\n{\n\tstruct list_head *offload_head = &offload_base;\n\tstruct packet_offload *ptype;\n\n\tlist_for_each_entry_rcu(ptype, offload_head, list) {\n\t\tif (ptype->type != type || !ptype->callbacks.gro_receive)\n\t\t\tcontinue;\n\t\treturn ptype;\n\t}\n\treturn NULL;\n}\nEXPORT_SYMBOL(gro_find_receive_by_type);\n\nstruct packet_offload *gro_find_complete_by_type(__be16 type)\n{\n\tstruct list_head *offload_head = &offload_base;\n\tstruct packet_offload *ptype;\n\n\tlist_for_each_entry_rcu(ptype, offload_head, list) {\n\t\tif (ptype->type != type || !ptype->callbacks.gro_complete)\n\t\t\tcontinue;\n\t\treturn ptype;\n\t}\n\treturn NULL;\n}\nEXPORT_SYMBOL(gro_find_complete_by_type);\n\nstatic gro_result_t napi_skb_finish(struct napi_struct *napi,\n\t\t\t\t    struct sk_buff *skb,\n\t\t\t\t    gro_result_t ret)\n{\n\tswitch (ret) {\n\tcase GRO_NORMAL:\n\t\tgro_normal_one(napi, skb, 1);\n\t\tbreak;\n\n\tcase GRO_MERGED_FREE:\n\t\tif (NAPI_GRO_CB(skb)->free == NAPI_GRO_FREE_STOLEN_HEAD)\n\t\t\tnapi_skb_free_stolen_head(skb);\n\t\telse if (skb->fclone != SKB_FCLONE_UNAVAILABLE)\n\t\t\t__kfree_skb(skb);\n\t\telse\n\t\t\t__napi_kfree_skb(skb, SKB_CONSUMED);\n\t\tbreak;\n\n\tcase GRO_HELD:\n\tcase GRO_MERGED:\n\tcase GRO_CONSUMED:\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\ngro_result_t napi_gro_receive(struct napi_struct *napi, struct sk_buff *skb)\n{\n\tgro_result_t ret;\n\n\tskb_mark_napi_id(skb, napi);\n\ttrace_napi_gro_receive_entry(skb);\n\n\tskb_gro_reset_offset(skb, 0);\n\n\tret = napi_skb_finish(napi, skb, dev_gro_receive(napi, skb));\n\ttrace_napi_gro_receive_exit(ret);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(napi_gro_receive);\n\nstatic void napi_reuse_skb(struct napi_struct *napi, struct sk_buff *skb)\n{\n\tif (unlikely(skb->pfmemalloc)) {\n\t\tconsume_skb(skb);\n\t\treturn;\n\t}\n\t__skb_pull(skb, skb_headlen(skb));\n\t \n\tskb_reserve(skb, NET_SKB_PAD + NET_IP_ALIGN - skb_headroom(skb));\n\t__vlan_hwaccel_clear_tag(skb);\n\tskb->dev = napi->dev;\n\tskb->skb_iif = 0;\n\n\t \n\tskb->pkt_type = PACKET_HOST;\n\n\tskb->encapsulation = 0;\n\tskb_shinfo(skb)->gso_type = 0;\n\tskb_shinfo(skb)->gso_size = 0;\n\tif (unlikely(skb->slow_gro)) {\n\t\tskb_orphan(skb);\n\t\tskb_ext_reset(skb);\n\t\tnf_reset_ct(skb);\n\t\tskb->slow_gro = 0;\n\t}\n\n\tnapi->skb = skb;\n}\n\nstruct sk_buff *napi_get_frags(struct napi_struct *napi)\n{\n\tstruct sk_buff *skb = napi->skb;\n\n\tif (!skb) {\n\t\tskb = napi_alloc_skb(napi, GRO_MAX_HEAD);\n\t\tif (skb) {\n\t\t\tnapi->skb = skb;\n\t\t\tskb_mark_napi_id(skb, napi);\n\t\t}\n\t}\n\treturn skb;\n}\nEXPORT_SYMBOL(napi_get_frags);\n\nstatic gro_result_t napi_frags_finish(struct napi_struct *napi,\n\t\t\t\t      struct sk_buff *skb,\n\t\t\t\t      gro_result_t ret)\n{\n\tswitch (ret) {\n\tcase GRO_NORMAL:\n\tcase GRO_HELD:\n\t\t__skb_push(skb, ETH_HLEN);\n\t\tskb->protocol = eth_type_trans(skb, skb->dev);\n\t\tif (ret == GRO_NORMAL)\n\t\t\tgro_normal_one(napi, skb, 1);\n\t\tbreak;\n\n\tcase GRO_MERGED_FREE:\n\t\tif (NAPI_GRO_CB(skb)->free == NAPI_GRO_FREE_STOLEN_HEAD)\n\t\t\tnapi_skb_free_stolen_head(skb);\n\t\telse\n\t\t\tnapi_reuse_skb(napi, skb);\n\t\tbreak;\n\n\tcase GRO_MERGED:\n\tcase GRO_CONSUMED:\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\n \nstatic struct sk_buff *napi_frags_skb(struct napi_struct *napi)\n{\n\tstruct sk_buff *skb = napi->skb;\n\tconst struct ethhdr *eth;\n\tunsigned int hlen = sizeof(*eth);\n\n\tnapi->skb = NULL;\n\n\tskb_reset_mac_header(skb);\n\tskb_gro_reset_offset(skb, hlen);\n\n\tif (unlikely(skb_gro_header_hard(skb, hlen))) {\n\t\teth = skb_gro_header_slow(skb, hlen, 0);\n\t\tif (unlikely(!eth)) {\n\t\t\tnet_warn_ratelimited(\"%s: dropping impossible skb from %s\\n\",\n\t\t\t\t\t     __func__, napi->dev->name);\n\t\t\tnapi_reuse_skb(napi, skb);\n\t\t\treturn NULL;\n\t\t}\n\t} else {\n\t\teth = (const struct ethhdr *)skb->data;\n\t\tgro_pull_from_frag0(skb, hlen);\n\t\tNAPI_GRO_CB(skb)->frag0 += hlen;\n\t\tNAPI_GRO_CB(skb)->frag0_len -= hlen;\n\t}\n\t__skb_pull(skb, hlen);\n\n\t \n\tskb->protocol = eth->h_proto;\n\n\treturn skb;\n}\n\ngro_result_t napi_gro_frags(struct napi_struct *napi)\n{\n\tgro_result_t ret;\n\tstruct sk_buff *skb = napi_frags_skb(napi);\n\n\ttrace_napi_gro_frags_entry(skb);\n\n\tret = napi_frags_finish(napi, skb, dev_gro_receive(napi, skb));\n\ttrace_napi_gro_frags_exit(ret);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(napi_gro_frags);\n\n \n__sum16 __skb_gro_checksum_complete(struct sk_buff *skb)\n{\n\t__wsum wsum;\n\t__sum16 sum;\n\n\twsum = skb_checksum(skb, skb_gro_offset(skb), skb_gro_len(skb), 0);\n\n\t \n\tsum = csum_fold(csum_add(NAPI_GRO_CB(skb)->csum, wsum));\n\t \n\tif (likely(!sum)) {\n\t\tif (unlikely(skb->ip_summed == CHECKSUM_COMPLETE) &&\n\t\t    !skb->csum_complete_sw)\n\t\t\tnetdev_rx_csum_fault(skb->dev, skb);\n\t}\n\n\tNAPI_GRO_CB(skb)->csum = wsum;\n\tNAPI_GRO_CB(skb)->csum_valid = 1;\n\n\treturn sum;\n}\nEXPORT_SYMBOL(__skb_gro_checksum_complete);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}