{
  "module_name": "lwt_bpf.c",
  "hash_id": "0be464ab545a1970100cf61bd24d0b73964713c8cb63b9f7f797ff1bd4da99b0",
  "original_prompt": "Ingested from linux-6.6.14/net/core/lwt_bpf.c",
  "human_readable_source": "\n \n\n#include <linux/filter.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/skbuff.h>\n#include <linux/types.h>\n#include <linux/bpf.h>\n#include <net/lwtunnel.h>\n#include <net/gre.h>\n#include <net/ip6_route.h>\n#include <net/ipv6_stubs.h>\n\nstruct bpf_lwt_prog {\n\tstruct bpf_prog *prog;\n\tchar *name;\n};\n\nstruct bpf_lwt {\n\tstruct bpf_lwt_prog in;\n\tstruct bpf_lwt_prog out;\n\tstruct bpf_lwt_prog xmit;\n\tint family;\n};\n\n#define MAX_PROG_NAME 256\n\nstatic inline struct bpf_lwt *bpf_lwt_lwtunnel(struct lwtunnel_state *lwt)\n{\n\treturn (struct bpf_lwt *)lwt->data;\n}\n\n#define NO_REDIRECT false\n#define CAN_REDIRECT true\n\nstatic int run_lwt_bpf(struct sk_buff *skb, struct bpf_lwt_prog *lwt,\n\t\t       struct dst_entry *dst, bool can_redirect)\n{\n\tint ret;\n\n\t \n\tmigrate_disable();\n\tlocal_bh_disable();\n\tbpf_compute_data_pointers(skb);\n\tret = bpf_prog_run_save_cb(lwt->prog, skb);\n\n\tswitch (ret) {\n\tcase BPF_OK:\n\tcase BPF_LWT_REROUTE:\n\t\tbreak;\n\n\tcase BPF_REDIRECT:\n\t\tif (unlikely(!can_redirect)) {\n\t\t\tpr_warn_once(\"Illegal redirect return code in prog %s\\n\",\n\t\t\t\t     lwt->name ? : \"<unknown>\");\n\t\t\tret = BPF_OK;\n\t\t} else {\n\t\t\tskb_reset_mac_header(skb);\n\t\t\tskb_do_redirect(skb);\n\t\t\tret = BPF_REDIRECT;\n\t\t}\n\t\tbreak;\n\n\tcase BPF_DROP:\n\t\tkfree_skb(skb);\n\t\tret = -EPERM;\n\t\tbreak;\n\n\tdefault:\n\t\tpr_warn_once(\"bpf-lwt: Illegal return value %u, expect packet loss\\n\", ret);\n\t\tkfree_skb(skb);\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\n\tlocal_bh_enable();\n\tmigrate_enable();\n\n\treturn ret;\n}\n\nstatic int bpf_lwt_input_reroute(struct sk_buff *skb)\n{\n\tint err = -EINVAL;\n\n\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\tstruct net_device *dev = skb_dst(skb)->dev;\n\t\tstruct iphdr *iph = ip_hdr(skb);\n\n\t\tdev_hold(dev);\n\t\tskb_dst_drop(skb);\n\t\terr = ip_route_input_noref(skb, iph->daddr, iph->saddr,\n\t\t\t\t\t   iph->tos, dev);\n\t\tdev_put(dev);\n\t} else if (skb->protocol == htons(ETH_P_IPV6)) {\n\t\tskb_dst_drop(skb);\n\t\terr = ipv6_stub->ipv6_route_input(skb);\n\t} else {\n\t\terr = -EAFNOSUPPORT;\n\t}\n\n\tif (err)\n\t\tgoto err;\n\treturn dst_input(skb);\n\nerr:\n\tkfree_skb(skb);\n\treturn err;\n}\n\nstatic int bpf_input(struct sk_buff *skb)\n{\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct bpf_lwt *bpf;\n\tint ret;\n\n\tbpf = bpf_lwt_lwtunnel(dst->lwtstate);\n\tif (bpf->in.prog) {\n\t\tret = run_lwt_bpf(skb, &bpf->in, dst, NO_REDIRECT);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tif (ret == BPF_LWT_REROUTE)\n\t\t\treturn bpf_lwt_input_reroute(skb);\n\t}\n\n\tif (unlikely(!dst->lwtstate->orig_input)) {\n\t\tkfree_skb(skb);\n\t\treturn -EINVAL;\n\t}\n\n\treturn dst->lwtstate->orig_input(skb);\n}\n\nstatic int bpf_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct bpf_lwt *bpf;\n\tint ret;\n\n\tbpf = bpf_lwt_lwtunnel(dst->lwtstate);\n\tif (bpf->out.prog) {\n\t\tret = run_lwt_bpf(skb, &bpf->out, dst, NO_REDIRECT);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tif (unlikely(!dst->lwtstate->orig_output)) {\n\t\tpr_warn_once(\"orig_output not set on dst for prog %s\\n\",\n\t\t\t     bpf->out.name);\n\t\tkfree_skb(skb);\n\t\treturn -EINVAL;\n\t}\n\n\treturn dst->lwtstate->orig_output(net, sk, skb);\n}\n\nstatic int xmit_check_hhlen(struct sk_buff *skb, int hh_len)\n{\n\tif (skb_headroom(skb) < hh_len) {\n\t\tint nhead = HH_DATA_ALIGN(hh_len - skb_headroom(skb));\n\n\t\tif (pskb_expand_head(skb, nhead, 0, GFP_ATOMIC))\n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic int bpf_lwt_xmit_reroute(struct sk_buff *skb)\n{\n\tstruct net_device *l3mdev = l3mdev_master_dev_rcu(skb_dst(skb)->dev);\n\tint oif = l3mdev ? l3mdev->ifindex : 0;\n\tstruct dst_entry *dst = NULL;\n\tint err = -EAFNOSUPPORT;\n\tstruct sock *sk;\n\tstruct net *net;\n\tbool ipv4;\n\n\tif (skb->protocol == htons(ETH_P_IP))\n\t\tipv4 = true;\n\telse if (skb->protocol == htons(ETH_P_IPV6))\n\t\tipv4 = false;\n\telse\n\t\tgoto err;\n\n\tsk = sk_to_full_sk(skb->sk);\n\tif (sk) {\n\t\tif (sk->sk_bound_dev_if)\n\t\t\toif = sk->sk_bound_dev_if;\n\t\tnet = sock_net(sk);\n\t} else {\n\t\tnet = dev_net(skb_dst(skb)->dev);\n\t}\n\n\tif (ipv4) {\n\t\tstruct iphdr *iph = ip_hdr(skb);\n\t\tstruct flowi4 fl4 = {};\n\t\tstruct rtable *rt;\n\n\t\tfl4.flowi4_oif = oif;\n\t\tfl4.flowi4_mark = skb->mark;\n\t\tfl4.flowi4_uid = sock_net_uid(net, sk);\n\t\tfl4.flowi4_tos = RT_TOS(iph->tos);\n\t\tfl4.flowi4_flags = FLOWI_FLAG_ANYSRC;\n\t\tfl4.flowi4_proto = iph->protocol;\n\t\tfl4.daddr = iph->daddr;\n\t\tfl4.saddr = iph->saddr;\n\n\t\trt = ip_route_output_key(net, &fl4);\n\t\tif (IS_ERR(rt)) {\n\t\t\terr = PTR_ERR(rt);\n\t\t\tgoto err;\n\t\t}\n\t\tdst = &rt->dst;\n\t} else {\n\t\tstruct ipv6hdr *iph6 = ipv6_hdr(skb);\n\t\tstruct flowi6 fl6 = {};\n\n\t\tfl6.flowi6_oif = oif;\n\t\tfl6.flowi6_mark = skb->mark;\n\t\tfl6.flowi6_uid = sock_net_uid(net, sk);\n\t\tfl6.flowlabel = ip6_flowinfo(iph6);\n\t\tfl6.flowi6_proto = iph6->nexthdr;\n\t\tfl6.daddr = iph6->daddr;\n\t\tfl6.saddr = iph6->saddr;\n\n\t\tdst = ipv6_stub->ipv6_dst_lookup_flow(net, skb->sk, &fl6, NULL);\n\t\tif (IS_ERR(dst)) {\n\t\t\terr = PTR_ERR(dst);\n\t\t\tgoto err;\n\t\t}\n\t}\n\tif (unlikely(dst->error)) {\n\t\terr = dst->error;\n\t\tdst_release(dst);\n\t\tgoto err;\n\t}\n\n\t \n\terr = skb_cow_head(skb, LL_RESERVED_SPACE(dst->dev));\n\tif (unlikely(err))\n\t\tgoto err;\n\n\tskb_dst_drop(skb);\n\tskb_dst_set(skb, dst);\n\n\terr = dst_output(dev_net(skb_dst(skb)->dev), skb->sk, skb);\n\tif (unlikely(err))\n\t\treturn net_xmit_errno(err);\n\n\t \n\treturn LWTUNNEL_XMIT_DONE;\n\nerr:\n\tkfree_skb(skb);\n\treturn err;\n}\n\nstatic int bpf_xmit(struct sk_buff *skb)\n{\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct bpf_lwt *bpf;\n\n\tbpf = bpf_lwt_lwtunnel(dst->lwtstate);\n\tif (bpf->xmit.prog) {\n\t\tint hh_len = dst->dev->hard_header_len;\n\t\t__be16 proto = skb->protocol;\n\t\tint ret;\n\n\t\tret = run_lwt_bpf(skb, &bpf->xmit, dst, CAN_REDIRECT);\n\t\tswitch (ret) {\n\t\tcase BPF_OK:\n\t\t\t \n\t\t\tif (skb->protocol != proto) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\t \n\t\t\tret = xmit_check_hhlen(skb, hh_len);\n\t\t\tif (unlikely(ret))\n\t\t\t\treturn ret;\n\n\t\t\treturn LWTUNNEL_XMIT_CONTINUE;\n\t\tcase BPF_REDIRECT:\n\t\t\treturn LWTUNNEL_XMIT_DONE;\n\t\tcase BPF_LWT_REROUTE:\n\t\t\treturn bpf_lwt_xmit_reroute(skb);\n\t\tdefault:\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn LWTUNNEL_XMIT_CONTINUE;\n}\n\nstatic void bpf_lwt_prog_destroy(struct bpf_lwt_prog *prog)\n{\n\tif (prog->prog)\n\t\tbpf_prog_put(prog->prog);\n\n\tkfree(prog->name);\n}\n\nstatic void bpf_destroy_state(struct lwtunnel_state *lwt)\n{\n\tstruct bpf_lwt *bpf = bpf_lwt_lwtunnel(lwt);\n\n\tbpf_lwt_prog_destroy(&bpf->in);\n\tbpf_lwt_prog_destroy(&bpf->out);\n\tbpf_lwt_prog_destroy(&bpf->xmit);\n}\n\nstatic const struct nla_policy bpf_prog_policy[LWT_BPF_PROG_MAX + 1] = {\n\t[LWT_BPF_PROG_FD]   = { .type = NLA_U32, },\n\t[LWT_BPF_PROG_NAME] = { .type = NLA_NUL_STRING,\n\t\t\t\t.len = MAX_PROG_NAME },\n};\n\nstatic int bpf_parse_prog(struct nlattr *attr, struct bpf_lwt_prog *prog,\n\t\t\t  enum bpf_prog_type type)\n{\n\tstruct nlattr *tb[LWT_BPF_PROG_MAX + 1];\n\tstruct bpf_prog *p;\n\tint ret;\n\tu32 fd;\n\n\tret = nla_parse_nested_deprecated(tb, LWT_BPF_PROG_MAX, attr,\n\t\t\t\t\t  bpf_prog_policy, NULL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (!tb[LWT_BPF_PROG_FD] || !tb[LWT_BPF_PROG_NAME])\n\t\treturn -EINVAL;\n\n\tprog->name = nla_memdup(tb[LWT_BPF_PROG_NAME], GFP_ATOMIC);\n\tif (!prog->name)\n\t\treturn -ENOMEM;\n\n\tfd = nla_get_u32(tb[LWT_BPF_PROG_FD]);\n\tp = bpf_prog_get_type(fd, type);\n\tif (IS_ERR(p))\n\t\treturn PTR_ERR(p);\n\n\tprog->prog = p;\n\n\treturn 0;\n}\n\nstatic const struct nla_policy bpf_nl_policy[LWT_BPF_MAX + 1] = {\n\t[LWT_BPF_IN]\t\t= { .type = NLA_NESTED, },\n\t[LWT_BPF_OUT]\t\t= { .type = NLA_NESTED, },\n\t[LWT_BPF_XMIT]\t\t= { .type = NLA_NESTED, },\n\t[LWT_BPF_XMIT_HEADROOM]\t= { .type = NLA_U32 },\n};\n\nstatic int bpf_build_state(struct net *net, struct nlattr *nla,\n\t\t\t   unsigned int family, const void *cfg,\n\t\t\t   struct lwtunnel_state **ts,\n\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct nlattr *tb[LWT_BPF_MAX + 1];\n\tstruct lwtunnel_state *newts;\n\tstruct bpf_lwt *bpf;\n\tint ret;\n\n\tif (family != AF_INET && family != AF_INET6)\n\t\treturn -EAFNOSUPPORT;\n\n\tret = nla_parse_nested_deprecated(tb, LWT_BPF_MAX, nla, bpf_nl_policy,\n\t\t\t\t\t  extack);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (!tb[LWT_BPF_IN] && !tb[LWT_BPF_OUT] && !tb[LWT_BPF_XMIT])\n\t\treturn -EINVAL;\n\n\tnewts = lwtunnel_state_alloc(sizeof(*bpf));\n\tif (!newts)\n\t\treturn -ENOMEM;\n\n\tnewts->type = LWTUNNEL_ENCAP_BPF;\n\tbpf = bpf_lwt_lwtunnel(newts);\n\n\tif (tb[LWT_BPF_IN]) {\n\t\tnewts->flags |= LWTUNNEL_STATE_INPUT_REDIRECT;\n\t\tret = bpf_parse_prog(tb[LWT_BPF_IN], &bpf->in,\n\t\t\t\t     BPF_PROG_TYPE_LWT_IN);\n\t\tif (ret  < 0)\n\t\t\tgoto errout;\n\t}\n\n\tif (tb[LWT_BPF_OUT]) {\n\t\tnewts->flags |= LWTUNNEL_STATE_OUTPUT_REDIRECT;\n\t\tret = bpf_parse_prog(tb[LWT_BPF_OUT], &bpf->out,\n\t\t\t\t     BPF_PROG_TYPE_LWT_OUT);\n\t\tif (ret < 0)\n\t\t\tgoto errout;\n\t}\n\n\tif (tb[LWT_BPF_XMIT]) {\n\t\tnewts->flags |= LWTUNNEL_STATE_XMIT_REDIRECT;\n\t\tret = bpf_parse_prog(tb[LWT_BPF_XMIT], &bpf->xmit,\n\t\t\t\t     BPF_PROG_TYPE_LWT_XMIT);\n\t\tif (ret < 0)\n\t\t\tgoto errout;\n\t}\n\n\tif (tb[LWT_BPF_XMIT_HEADROOM]) {\n\t\tu32 headroom = nla_get_u32(tb[LWT_BPF_XMIT_HEADROOM]);\n\n\t\tif (headroom > LWT_BPF_MAX_HEADROOM) {\n\t\t\tret = -ERANGE;\n\t\t\tgoto errout;\n\t\t}\n\n\t\tnewts->headroom = headroom;\n\t}\n\n\tbpf->family = family;\n\t*ts = newts;\n\n\treturn 0;\n\nerrout:\n\tbpf_destroy_state(newts);\n\tkfree(newts);\n\treturn ret;\n}\n\nstatic int bpf_fill_lwt_prog(struct sk_buff *skb, int attr,\n\t\t\t     struct bpf_lwt_prog *prog)\n{\n\tstruct nlattr *nest;\n\n\tif (!prog->prog)\n\t\treturn 0;\n\n\tnest = nla_nest_start_noflag(skb, attr);\n\tif (!nest)\n\t\treturn -EMSGSIZE;\n\n\tif (prog->name &&\n\t    nla_put_string(skb, LWT_BPF_PROG_NAME, prog->name))\n\t\treturn -EMSGSIZE;\n\n\treturn nla_nest_end(skb, nest);\n}\n\nstatic int bpf_fill_encap_info(struct sk_buff *skb, struct lwtunnel_state *lwt)\n{\n\tstruct bpf_lwt *bpf = bpf_lwt_lwtunnel(lwt);\n\n\tif (bpf_fill_lwt_prog(skb, LWT_BPF_IN, &bpf->in) < 0 ||\n\t    bpf_fill_lwt_prog(skb, LWT_BPF_OUT, &bpf->out) < 0 ||\n\t    bpf_fill_lwt_prog(skb, LWT_BPF_XMIT, &bpf->xmit) < 0)\n\t\treturn -EMSGSIZE;\n\n\treturn 0;\n}\n\nstatic int bpf_encap_nlsize(struct lwtunnel_state *lwtstate)\n{\n\tint nest_len = nla_total_size(sizeof(struct nlattr)) +\n\t\t       nla_total_size(MAX_PROG_NAME) +  \n\t\t       0;\n\n\treturn nest_len +  \n\t       nest_len +  \n\t       nest_len +  \n\t       0;\n}\n\nstatic int bpf_lwt_prog_cmp(struct bpf_lwt_prog *a, struct bpf_lwt_prog *b)\n{\n\t \n\tif (!a->name && !b->name)\n\t\treturn 0;\n\n\tif (!a->name || !b->name)\n\t\treturn 1;\n\n\treturn strcmp(a->name, b->name);\n}\n\nstatic int bpf_encap_cmp(struct lwtunnel_state *a, struct lwtunnel_state *b)\n{\n\tstruct bpf_lwt *a_bpf = bpf_lwt_lwtunnel(a);\n\tstruct bpf_lwt *b_bpf = bpf_lwt_lwtunnel(b);\n\n\treturn bpf_lwt_prog_cmp(&a_bpf->in, &b_bpf->in) ||\n\t       bpf_lwt_prog_cmp(&a_bpf->out, &b_bpf->out) ||\n\t       bpf_lwt_prog_cmp(&a_bpf->xmit, &b_bpf->xmit);\n}\n\nstatic const struct lwtunnel_encap_ops bpf_encap_ops = {\n\t.build_state\t= bpf_build_state,\n\t.destroy_state\t= bpf_destroy_state,\n\t.input\t\t= bpf_input,\n\t.output\t\t= bpf_output,\n\t.xmit\t\t= bpf_xmit,\n\t.fill_encap\t= bpf_fill_encap_info,\n\t.get_encap_size = bpf_encap_nlsize,\n\t.cmp_encap\t= bpf_encap_cmp,\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic int handle_gso_type(struct sk_buff *skb, unsigned int gso_type,\n\t\t\t   int encap_len)\n{\n\tstruct skb_shared_info *shinfo = skb_shinfo(skb);\n\n\tgso_type |= SKB_GSO_DODGY;\n\tshinfo->gso_type |= gso_type;\n\tskb_decrease_gso_size(shinfo, encap_len);\n\tshinfo->gso_segs = 0;\n\treturn 0;\n}\n\nstatic int handle_gso_encap(struct sk_buff *skb, bool ipv4, int encap_len)\n{\n\tint next_hdr_offset;\n\tvoid *next_hdr;\n\t__u8 protocol;\n\n\t \n\tif (!(skb_shinfo(skb)->gso_type & (SKB_GSO_TCPV4 | SKB_GSO_TCPV6)))\n\t\treturn -ENOTSUPP;\n\n\tif (ipv4) {\n\t\tprotocol = ip_hdr(skb)->protocol;\n\t\tnext_hdr_offset = sizeof(struct iphdr);\n\t\tnext_hdr = skb_network_header(skb) + next_hdr_offset;\n\t} else {\n\t\tprotocol = ipv6_hdr(skb)->nexthdr;\n\t\tnext_hdr_offset = sizeof(struct ipv6hdr);\n\t\tnext_hdr = skb_network_header(skb) + next_hdr_offset;\n\t}\n\n\tswitch (protocol) {\n\tcase IPPROTO_GRE:\n\t\tnext_hdr_offset += sizeof(struct gre_base_hdr);\n\t\tif (next_hdr_offset > encap_len)\n\t\t\treturn -EINVAL;\n\n\t\tif (((struct gre_base_hdr *)next_hdr)->flags & GRE_CSUM)\n\t\t\treturn handle_gso_type(skb, SKB_GSO_GRE_CSUM,\n\t\t\t\t\t       encap_len);\n\t\treturn handle_gso_type(skb, SKB_GSO_GRE, encap_len);\n\n\tcase IPPROTO_UDP:\n\t\tnext_hdr_offset += sizeof(struct udphdr);\n\t\tif (next_hdr_offset > encap_len)\n\t\t\treturn -EINVAL;\n\n\t\tif (((struct udphdr *)next_hdr)->check)\n\t\t\treturn handle_gso_type(skb, SKB_GSO_UDP_TUNNEL_CSUM,\n\t\t\t\t\t       encap_len);\n\t\treturn handle_gso_type(skb, SKB_GSO_UDP_TUNNEL, encap_len);\n\n\tcase IPPROTO_IP:\n\tcase IPPROTO_IPV6:\n\t\tif (ipv4)\n\t\t\treturn handle_gso_type(skb, SKB_GSO_IPXIP4, encap_len);\n\t\telse\n\t\t\treturn handle_gso_type(skb, SKB_GSO_IPXIP6, encap_len);\n\n\tdefault:\n\t\treturn -EPROTONOSUPPORT;\n\t}\n}\n\nint bpf_lwt_push_ip_encap(struct sk_buff *skb, void *hdr, u32 len, bool ingress)\n{\n\tstruct iphdr *iph;\n\tbool ipv4;\n\tint err;\n\n\tif (unlikely(len < sizeof(struct iphdr) || len > LWT_BPF_MAX_HEADROOM))\n\t\treturn -EINVAL;\n\n\t \n\tiph = (struct iphdr *)hdr;\n\tif (iph->version == 4) {\n\t\tipv4 = true;\n\t\tif (unlikely(len < iph->ihl * 4))\n\t\t\treturn -EINVAL;\n\t} else if (iph->version == 6) {\n\t\tipv4 = false;\n\t\tif (unlikely(len < sizeof(struct ipv6hdr)))\n\t\t\treturn -EINVAL;\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\tif (ingress)\n\t\terr = skb_cow_head(skb, len + skb->mac_len);\n\telse\n\t\terr = skb_cow_head(skb,\n\t\t\t\t   len + LL_RESERVED_SPACE(skb_dst(skb)->dev));\n\tif (unlikely(err))\n\t\treturn err;\n\n\t \n\tskb_reset_inner_headers(skb);\n\tskb_reset_inner_mac_header(skb);   \n\tskb_set_inner_protocol(skb, skb->protocol);\n\tskb->encapsulation = 1;\n\tskb_push(skb, len);\n\tif (ingress)\n\t\tskb_postpush_rcsum(skb, iph, len);\n\tskb_reset_network_header(skb);\n\tmemcpy(skb_network_header(skb), hdr, len);\n\tbpf_compute_data_pointers(skb);\n\tskb_clear_hash(skb);\n\n\tif (ipv4) {\n\t\tskb->protocol = htons(ETH_P_IP);\n\t\tiph = ip_hdr(skb);\n\n\t\tif (!iph->check)\n\t\t\tiph->check = ip_fast_csum((unsigned char *)iph,\n\t\t\t\t\t\t  iph->ihl);\n\t} else {\n\t\tskb->protocol = htons(ETH_P_IPV6);\n\t}\n\n\tif (skb_is_gso(skb))\n\t\treturn handle_gso_encap(skb, ipv4, len);\n\n\treturn 0;\n}\n\nstatic int __init bpf_lwt_init(void)\n{\n\treturn lwtunnel_encap_add_ops(&bpf_encap_ops, LWTUNNEL_ENCAP_BPF);\n}\n\nsubsys_initcall(bpf_lwt_init)\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}