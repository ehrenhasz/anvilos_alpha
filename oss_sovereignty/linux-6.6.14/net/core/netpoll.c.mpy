{
  "module_name": "netpoll.c",
  "hash_id": "62d39fa4c90c96a50bee979e3903c4234bb51bc51d34bbc98df83efba5ea3737",
  "original_prompt": "Ingested from linux-6.6.14/net/core/netpoll.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/moduleparam.h>\n#include <linux/kernel.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/string.h>\n#include <linux/if_arp.h>\n#include <linux/inetdevice.h>\n#include <linux/inet.h>\n#include <linux/interrupt.h>\n#include <linux/netpoll.h>\n#include <linux/sched.h>\n#include <linux/delay.h>\n#include <linux/rcupdate.h>\n#include <linux/workqueue.h>\n#include <linux/slab.h>\n#include <linux/export.h>\n#include <linux/if_vlan.h>\n#include <net/tcp.h>\n#include <net/udp.h>\n#include <net/addrconf.h>\n#include <net/ndisc.h>\n#include <net/ip6_checksum.h>\n#include <asm/unaligned.h>\n#include <trace/events/napi.h>\n#include <linux/kconfig.h>\n\n \n\n#define MAX_UDP_CHUNK 1460\n#define MAX_SKBS 32\n\nstatic struct sk_buff_head skb_pool;\n\nDEFINE_STATIC_SRCU(netpoll_srcu);\n\n#define USEC_PER_POLL\t50\n\n#define MAX_SKB_SIZE\t\t\t\t\t\t\t\\\n\t(sizeof(struct ethhdr) +\t\t\t\t\t\\\n\t sizeof(struct iphdr) +\t\t\t\t\t\t\\\n\t sizeof(struct udphdr) +\t\t\t\t\t\\\n\t MAX_UDP_CHUNK)\n\nstatic void zap_completion_queue(void);\n\nstatic unsigned int carrier_timeout = 4;\nmodule_param(carrier_timeout, uint, 0644);\n\n#define np_info(np, fmt, ...)\t\t\t\t\\\n\tpr_info(\"%s: \" fmt, np->name, ##__VA_ARGS__)\n#define np_err(np, fmt, ...)\t\t\t\t\\\n\tpr_err(\"%s: \" fmt, np->name, ##__VA_ARGS__)\n#define np_notice(np, fmt, ...)\t\t\t\t\\\n\tpr_notice(\"%s: \" fmt, np->name, ##__VA_ARGS__)\n\nstatic netdev_tx_t netpoll_start_xmit(struct sk_buff *skb,\n\t\t\t\t      struct net_device *dev,\n\t\t\t\t      struct netdev_queue *txq)\n{\n\tnetdev_tx_t status = NETDEV_TX_OK;\n\tnetdev_features_t features;\n\n\tfeatures = netif_skb_features(skb);\n\n\tif (skb_vlan_tag_present(skb) &&\n\t    !vlan_hw_offload_capable(features, skb->vlan_proto)) {\n\t\tskb = __vlan_hwaccel_push_inside(skb);\n\t\tif (unlikely(!skb)) {\n\t\t\t \n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tstatus = netdev_start_xmit(skb, dev, txq, false);\n\nout:\n\treturn status;\n}\n\nstatic void queue_process(struct work_struct *work)\n{\n\tstruct netpoll_info *npinfo =\n\t\tcontainer_of(work, struct netpoll_info, tx_work.work);\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\n\twhile ((skb = skb_dequeue(&npinfo->txq))) {\n\t\tstruct net_device *dev = skb->dev;\n\t\tstruct netdev_queue *txq;\n\t\tunsigned int q_index;\n\n\t\tif (!netif_device_present(dev) || !netif_running(dev)) {\n\t\t\tkfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tlocal_irq_save(flags);\n\t\t \n\t\tq_index = skb_get_queue_mapping(skb);\n\t\tif (unlikely(q_index >= dev->real_num_tx_queues)) {\n\t\t\tq_index = q_index % dev->real_num_tx_queues;\n\t\t\tskb_set_queue_mapping(skb, q_index);\n\t\t}\n\t\ttxq = netdev_get_tx_queue(dev, q_index);\n\t\tHARD_TX_LOCK(dev, txq, smp_processor_id());\n\t\tif (netif_xmit_frozen_or_stopped(txq) ||\n\t\t    !dev_xmit_complete(netpoll_start_xmit(skb, dev, txq))) {\n\t\t\tskb_queue_head(&npinfo->txq, skb);\n\t\t\tHARD_TX_UNLOCK(dev, txq);\n\t\t\tlocal_irq_restore(flags);\n\n\t\t\tschedule_delayed_work(&npinfo->tx_work, HZ/10);\n\t\t\treturn;\n\t\t}\n\t\tHARD_TX_UNLOCK(dev, txq);\n\t\tlocal_irq_restore(flags);\n\t}\n}\n\nstatic int netif_local_xmit_active(struct net_device *dev)\n{\n\tint i;\n\n\tfor (i = 0; i < dev->num_tx_queues; i++) {\n\t\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, i);\n\n\t\tif (READ_ONCE(txq->xmit_lock_owner) == smp_processor_id())\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic void poll_one_napi(struct napi_struct *napi)\n{\n\tint work;\n\n\t \n\tif (test_and_set_bit(NAPI_STATE_NPSVC, &napi->state))\n\t\treturn;\n\n\t \n\twork = napi->poll(napi, 0);\n\tWARN_ONCE(work, \"%pS exceeded budget in poll\\n\", napi->poll);\n\ttrace_napi_poll(napi, work, 0);\n\n\tclear_bit(NAPI_STATE_NPSVC, &napi->state);\n}\n\nstatic void poll_napi(struct net_device *dev)\n{\n\tstruct napi_struct *napi;\n\tint cpu = smp_processor_id();\n\n\tlist_for_each_entry_rcu(napi, &dev->napi_list, dev_list) {\n\t\tif (cmpxchg(&napi->poll_owner, -1, cpu) == -1) {\n\t\t\tpoll_one_napi(napi);\n\t\t\tsmp_store_release(&napi->poll_owner, -1);\n\t\t}\n\t}\n}\n\nvoid netpoll_poll_dev(struct net_device *dev)\n{\n\tstruct netpoll_info *ni = rcu_dereference_bh(dev->npinfo);\n\tconst struct net_device_ops *ops;\n\n\t \n\tif (!ni || down_trylock(&ni->dev_lock))\n\t\treturn;\n\n\t \n\tif (!netif_running(dev) || netif_local_xmit_active(dev)) {\n\t\tup(&ni->dev_lock);\n\t\treturn;\n\t}\n\n\tops = dev->netdev_ops;\n\tif (ops->ndo_poll_controller)\n\t\tops->ndo_poll_controller(dev);\n\n\tpoll_napi(dev);\n\n\tup(&ni->dev_lock);\n\n\tzap_completion_queue();\n}\nEXPORT_SYMBOL(netpoll_poll_dev);\n\nvoid netpoll_poll_disable(struct net_device *dev)\n{\n\tstruct netpoll_info *ni;\n\tint idx;\n\tmight_sleep();\n\tidx = srcu_read_lock(&netpoll_srcu);\n\tni = srcu_dereference(dev->npinfo, &netpoll_srcu);\n\tif (ni)\n\t\tdown(&ni->dev_lock);\n\tsrcu_read_unlock(&netpoll_srcu, idx);\n}\nEXPORT_SYMBOL(netpoll_poll_disable);\n\nvoid netpoll_poll_enable(struct net_device *dev)\n{\n\tstruct netpoll_info *ni;\n\trcu_read_lock();\n\tni = rcu_dereference(dev->npinfo);\n\tif (ni)\n\t\tup(&ni->dev_lock);\n\trcu_read_unlock();\n}\nEXPORT_SYMBOL(netpoll_poll_enable);\n\nstatic void refill_skbs(void)\n{\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&skb_pool.lock, flags);\n\twhile (skb_pool.qlen < MAX_SKBS) {\n\t\tskb = alloc_skb(MAX_SKB_SIZE, GFP_ATOMIC);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\t__skb_queue_tail(&skb_pool, skb);\n\t}\n\tspin_unlock_irqrestore(&skb_pool.lock, flags);\n}\n\nstatic void zap_completion_queue(void)\n{\n\tunsigned long flags;\n\tstruct softnet_data *sd = &get_cpu_var(softnet_data);\n\n\tif (sd->completion_queue) {\n\t\tstruct sk_buff *clist;\n\n\t\tlocal_irq_save(flags);\n\t\tclist = sd->completion_queue;\n\t\tsd->completion_queue = NULL;\n\t\tlocal_irq_restore(flags);\n\n\t\twhile (clist != NULL) {\n\t\t\tstruct sk_buff *skb = clist;\n\t\t\tclist = clist->next;\n\t\t\tif (!skb_irq_freeable(skb)) {\n\t\t\t\trefcount_set(&skb->users, 1);\n\t\t\t\tdev_kfree_skb_any(skb);  \n\t\t\t} else {\n\t\t\t\t__kfree_skb(skb);\n\t\t\t}\n\t\t}\n\t}\n\n\tput_cpu_var(softnet_data);\n}\n\nstatic struct sk_buff *find_skb(struct netpoll *np, int len, int reserve)\n{\n\tint count = 0;\n\tstruct sk_buff *skb;\n\n\tzap_completion_queue();\n\trefill_skbs();\nrepeat:\n\n\tskb = alloc_skb(len, GFP_ATOMIC);\n\tif (!skb)\n\t\tskb = skb_dequeue(&skb_pool);\n\n\tif (!skb) {\n\t\tif (++count < 10) {\n\t\t\tnetpoll_poll_dev(np->dev);\n\t\t\tgoto repeat;\n\t\t}\n\t\treturn NULL;\n\t}\n\n\trefcount_set(&skb->users, 1);\n\tskb_reserve(skb, reserve);\n\treturn skb;\n}\n\nstatic int netpoll_owner_active(struct net_device *dev)\n{\n\tstruct napi_struct *napi;\n\n\tlist_for_each_entry_rcu(napi, &dev->napi_list, dev_list) {\n\t\tif (napi->poll_owner == smp_processor_id())\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nstatic netdev_tx_t __netpoll_send_skb(struct netpoll *np, struct sk_buff *skb)\n{\n\tnetdev_tx_t status = NETDEV_TX_BUSY;\n\tstruct net_device *dev;\n\tunsigned long tries;\n\t \n\tstruct netpoll_info *npinfo;\n\n\tlockdep_assert_irqs_disabled();\n\n\tdev = np->dev;\n\tnpinfo = rcu_dereference_bh(dev->npinfo);\n\n\tif (!npinfo || !netif_running(dev) || !netif_device_present(dev)) {\n\t\tdev_kfree_skb_irq(skb);\n\t\treturn NET_XMIT_DROP;\n\t}\n\n\t \n\tif (skb_queue_len(&npinfo->txq) == 0 && !netpoll_owner_active(dev)) {\n\t\tstruct netdev_queue *txq;\n\n\t\ttxq = netdev_core_pick_tx(dev, skb, NULL);\n\n\t\t \n\t\tfor (tries = jiffies_to_usecs(1)/USEC_PER_POLL;\n\t\t     tries > 0; --tries) {\n\t\t\tif (HARD_TX_TRYLOCK(dev, txq)) {\n\t\t\t\tif (!netif_xmit_stopped(txq))\n\t\t\t\t\tstatus = netpoll_start_xmit(skb, dev, txq);\n\n\t\t\t\tHARD_TX_UNLOCK(dev, txq);\n\n\t\t\t\tif (dev_xmit_complete(status))\n\t\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t\t \n\t\t\tnetpoll_poll_dev(np->dev);\n\n\t\t\tudelay(USEC_PER_POLL);\n\t\t}\n\n\t\tWARN_ONCE(!irqs_disabled(),\n\t\t\t\"netpoll_send_skb_on_dev(): %s enabled interrupts in poll (%pS)\\n\",\n\t\t\tdev->name, dev->netdev_ops->ndo_start_xmit);\n\n\t}\n\n\tif (!dev_xmit_complete(status)) {\n\t\tskb_queue_tail(&npinfo->txq, skb);\n\t\tschedule_delayed_work(&npinfo->tx_work,0);\n\t}\n\treturn NETDEV_TX_OK;\n}\n\nnetdev_tx_t netpoll_send_skb(struct netpoll *np, struct sk_buff *skb)\n{\n\tunsigned long flags;\n\tnetdev_tx_t ret;\n\n\tif (unlikely(!np)) {\n\t\tdev_kfree_skb_irq(skb);\n\t\tret = NET_XMIT_DROP;\n\t} else {\n\t\tlocal_irq_save(flags);\n\t\tret = __netpoll_send_skb(np, skb);\n\t\tlocal_irq_restore(flags);\n\t}\n\treturn ret;\n}\nEXPORT_SYMBOL(netpoll_send_skb);\n\nvoid netpoll_send_udp(struct netpoll *np, const char *msg, int len)\n{\n\tint total_len, ip_len, udp_len;\n\tstruct sk_buff *skb;\n\tstruct udphdr *udph;\n\tstruct iphdr *iph;\n\tstruct ethhdr *eth;\n\tstatic atomic_t ip_ident;\n\tstruct ipv6hdr *ip6h;\n\n\tif (!IS_ENABLED(CONFIG_PREEMPT_RT))\n\t\tWARN_ON_ONCE(!irqs_disabled());\n\n\tudp_len = len + sizeof(*udph);\n\tif (np->ipv6)\n\t\tip_len = udp_len + sizeof(*ip6h);\n\telse\n\t\tip_len = udp_len + sizeof(*iph);\n\n\ttotal_len = ip_len + LL_RESERVED_SPACE(np->dev);\n\n\tskb = find_skb(np, total_len + np->dev->needed_tailroom,\n\t\t       total_len - len);\n\tif (!skb)\n\t\treturn;\n\n\tskb_copy_to_linear_data(skb, msg, len);\n\tskb_put(skb, len);\n\n\tskb_push(skb, sizeof(*udph));\n\tskb_reset_transport_header(skb);\n\tudph = udp_hdr(skb);\n\tudph->source = htons(np->local_port);\n\tudph->dest = htons(np->remote_port);\n\tudph->len = htons(udp_len);\n\n\tif (np->ipv6) {\n\t\tudph->check = 0;\n\t\tudph->check = csum_ipv6_magic(&np->local_ip.in6,\n\t\t\t\t\t      &np->remote_ip.in6,\n\t\t\t\t\t      udp_len, IPPROTO_UDP,\n\t\t\t\t\t      csum_partial(udph, udp_len, 0));\n\t\tif (udph->check == 0)\n\t\t\tudph->check = CSUM_MANGLED_0;\n\n\t\tskb_push(skb, sizeof(*ip6h));\n\t\tskb_reset_network_header(skb);\n\t\tip6h = ipv6_hdr(skb);\n\n\t\t \n\t\t*(unsigned char *)ip6h = 0x60;\n\t\tip6h->flow_lbl[0] = 0;\n\t\tip6h->flow_lbl[1] = 0;\n\t\tip6h->flow_lbl[2] = 0;\n\n\t\tip6h->payload_len = htons(sizeof(struct udphdr) + len);\n\t\tip6h->nexthdr = IPPROTO_UDP;\n\t\tip6h->hop_limit = 32;\n\t\tip6h->saddr = np->local_ip.in6;\n\t\tip6h->daddr = np->remote_ip.in6;\n\n\t\teth = skb_push(skb, ETH_HLEN);\n\t\tskb_reset_mac_header(skb);\n\t\tskb->protocol = eth->h_proto = htons(ETH_P_IPV6);\n\t} else {\n\t\tudph->check = 0;\n\t\tudph->check = csum_tcpudp_magic(np->local_ip.ip,\n\t\t\t\t\t\tnp->remote_ip.ip,\n\t\t\t\t\t\tudp_len, IPPROTO_UDP,\n\t\t\t\t\t\tcsum_partial(udph, udp_len, 0));\n\t\tif (udph->check == 0)\n\t\t\tudph->check = CSUM_MANGLED_0;\n\n\t\tskb_push(skb, sizeof(*iph));\n\t\tskb_reset_network_header(skb);\n\t\tiph = ip_hdr(skb);\n\n\t\t \n\t\t*(unsigned char *)iph = 0x45;\n\t\tiph->tos      = 0;\n\t\tput_unaligned(htons(ip_len), &(iph->tot_len));\n\t\tiph->id       = htons(atomic_inc_return(&ip_ident));\n\t\tiph->frag_off = 0;\n\t\tiph->ttl      = 64;\n\t\tiph->protocol = IPPROTO_UDP;\n\t\tiph->check    = 0;\n\t\tput_unaligned(np->local_ip.ip, &(iph->saddr));\n\t\tput_unaligned(np->remote_ip.ip, &(iph->daddr));\n\t\tiph->check    = ip_fast_csum((unsigned char *)iph, iph->ihl);\n\n\t\teth = skb_push(skb, ETH_HLEN);\n\t\tskb_reset_mac_header(skb);\n\t\tskb->protocol = eth->h_proto = htons(ETH_P_IP);\n\t}\n\n\tether_addr_copy(eth->h_source, np->dev->dev_addr);\n\tether_addr_copy(eth->h_dest, np->remote_mac);\n\n\tskb->dev = np->dev;\n\n\tnetpoll_send_skb(np, skb);\n}\nEXPORT_SYMBOL(netpoll_send_udp);\n\nvoid netpoll_print_options(struct netpoll *np)\n{\n\tnp_info(np, \"local port %d\\n\", np->local_port);\n\tif (np->ipv6)\n\t\tnp_info(np, \"local IPv6 address %pI6c\\n\", &np->local_ip.in6);\n\telse\n\t\tnp_info(np, \"local IPv4 address %pI4\\n\", &np->local_ip.ip);\n\tnp_info(np, \"interface '%s'\\n\", np->dev_name);\n\tnp_info(np, \"remote port %d\\n\", np->remote_port);\n\tif (np->ipv6)\n\t\tnp_info(np, \"remote IPv6 address %pI6c\\n\", &np->remote_ip.in6);\n\telse\n\t\tnp_info(np, \"remote IPv4 address %pI4\\n\", &np->remote_ip.ip);\n\tnp_info(np, \"remote ethernet address %pM\\n\", np->remote_mac);\n}\nEXPORT_SYMBOL(netpoll_print_options);\n\nstatic int netpoll_parse_ip_addr(const char *str, union inet_addr *addr)\n{\n\tconst char *end;\n\n\tif (!strchr(str, ':') &&\n\t    in4_pton(str, -1, (void *)addr, -1, &end) > 0) {\n\t\tif (!*end)\n\t\t\treturn 0;\n\t}\n\tif (in6_pton(str, -1, addr->in6.s6_addr, -1, &end) > 0) {\n#if IS_ENABLED(CONFIG_IPV6)\n\t\tif (!*end)\n\t\t\treturn 1;\n#else\n\t\treturn -1;\n#endif\n\t}\n\treturn -1;\n}\n\nint netpoll_parse_options(struct netpoll *np, char *opt)\n{\n\tchar *cur=opt, *delim;\n\tint ipv6;\n\tbool ipversion_set = false;\n\n\tif (*cur != '@') {\n\t\tif ((delim = strchr(cur, '@')) == NULL)\n\t\t\tgoto parse_failed;\n\t\t*delim = 0;\n\t\tif (kstrtou16(cur, 10, &np->local_port))\n\t\t\tgoto parse_failed;\n\t\tcur = delim;\n\t}\n\tcur++;\n\n\tif (*cur != '/') {\n\t\tipversion_set = true;\n\t\tif ((delim = strchr(cur, '/')) == NULL)\n\t\t\tgoto parse_failed;\n\t\t*delim = 0;\n\t\tipv6 = netpoll_parse_ip_addr(cur, &np->local_ip);\n\t\tif (ipv6 < 0)\n\t\t\tgoto parse_failed;\n\t\telse\n\t\t\tnp->ipv6 = (bool)ipv6;\n\t\tcur = delim;\n\t}\n\tcur++;\n\n\tif (*cur != ',') {\n\t\t \n\t\tif ((delim = strchr(cur, ',')) == NULL)\n\t\t\tgoto parse_failed;\n\t\t*delim = 0;\n\t\tstrscpy(np->dev_name, cur, sizeof(np->dev_name));\n\t\tcur = delim;\n\t}\n\tcur++;\n\n\tif (*cur != '@') {\n\t\t \n\t\tif ((delim = strchr(cur, '@')) == NULL)\n\t\t\tgoto parse_failed;\n\t\t*delim = 0;\n\t\tif (*cur == ' ' || *cur == '\\t')\n\t\t\tnp_info(np, \"warning: whitespace is not allowed\\n\");\n\t\tif (kstrtou16(cur, 10, &np->remote_port))\n\t\t\tgoto parse_failed;\n\t\tcur = delim;\n\t}\n\tcur++;\n\n\t \n\tif ((delim = strchr(cur, '/')) == NULL)\n\t\tgoto parse_failed;\n\t*delim = 0;\n\tipv6 = netpoll_parse_ip_addr(cur, &np->remote_ip);\n\tif (ipv6 < 0)\n\t\tgoto parse_failed;\n\telse if (ipversion_set && np->ipv6 != (bool)ipv6)\n\t\tgoto parse_failed;\n\telse\n\t\tnp->ipv6 = (bool)ipv6;\n\tcur = delim + 1;\n\n\tif (*cur != 0) {\n\t\t \n\t\tif (!mac_pton(cur, np->remote_mac))\n\t\t\tgoto parse_failed;\n\t}\n\n\tnetpoll_print_options(np);\n\n\treturn 0;\n\n parse_failed:\n\tnp_info(np, \"couldn't parse config at '%s'!\\n\", cur);\n\treturn -1;\n}\nEXPORT_SYMBOL(netpoll_parse_options);\n\nint __netpoll_setup(struct netpoll *np, struct net_device *ndev)\n{\n\tstruct netpoll_info *npinfo;\n\tconst struct net_device_ops *ops;\n\tint err;\n\n\tnp->dev = ndev;\n\tstrscpy(np->dev_name, ndev->name, IFNAMSIZ);\n\n\tif (ndev->priv_flags & IFF_DISABLE_NETPOLL) {\n\t\tnp_err(np, \"%s doesn't support polling, aborting\\n\",\n\t\t       np->dev_name);\n\t\terr = -ENOTSUPP;\n\t\tgoto out;\n\t}\n\n\tif (!ndev->npinfo) {\n\t\tnpinfo = kmalloc(sizeof(*npinfo), GFP_KERNEL);\n\t\tif (!npinfo) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\tsema_init(&npinfo->dev_lock, 1);\n\t\tskb_queue_head_init(&npinfo->txq);\n\t\tINIT_DELAYED_WORK(&npinfo->tx_work, queue_process);\n\n\t\trefcount_set(&npinfo->refcnt, 1);\n\n\t\tops = np->dev->netdev_ops;\n\t\tif (ops->ndo_netpoll_setup) {\n\t\t\terr = ops->ndo_netpoll_setup(ndev, npinfo);\n\t\t\tif (err)\n\t\t\t\tgoto free_npinfo;\n\t\t}\n\t} else {\n\t\tnpinfo = rtnl_dereference(ndev->npinfo);\n\t\trefcount_inc(&npinfo->refcnt);\n\t}\n\n\tnpinfo->netpoll = np;\n\n\t \n\trcu_assign_pointer(ndev->npinfo, npinfo);\n\n\treturn 0;\n\nfree_npinfo:\n\tkfree(npinfo);\nout:\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(__netpoll_setup);\n\nint netpoll_setup(struct netpoll *np)\n{\n\tstruct net_device *ndev = NULL;\n\tstruct in_device *in_dev;\n\tint err;\n\n\trtnl_lock();\n\tif (np->dev_name[0]) {\n\t\tstruct net *net = current->nsproxy->net_ns;\n\t\tndev = __dev_get_by_name(net, np->dev_name);\n\t}\n\tif (!ndev) {\n\t\tnp_err(np, \"%s doesn't exist, aborting\\n\", np->dev_name);\n\t\terr = -ENODEV;\n\t\tgoto unlock;\n\t}\n\tnetdev_hold(ndev, &np->dev_tracker, GFP_KERNEL);\n\n\tif (netdev_master_upper_dev_get(ndev)) {\n\t\tnp_err(np, \"%s is a slave device, aborting\\n\", np->dev_name);\n\t\terr = -EBUSY;\n\t\tgoto put;\n\t}\n\n\tif (!netif_running(ndev)) {\n\t\tunsigned long atmost;\n\n\t\tnp_info(np, \"device %s not up yet, forcing it\\n\", np->dev_name);\n\n\t\terr = dev_open(ndev, NULL);\n\n\t\tif (err) {\n\t\t\tnp_err(np, \"failed to open %s\\n\", ndev->name);\n\t\t\tgoto put;\n\t\t}\n\n\t\trtnl_unlock();\n\t\tatmost = jiffies + carrier_timeout * HZ;\n\t\twhile (!netif_carrier_ok(ndev)) {\n\t\t\tif (time_after(jiffies, atmost)) {\n\t\t\t\tnp_notice(np, \"timeout waiting for carrier\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tmsleep(1);\n\t\t}\n\n\t\trtnl_lock();\n\t}\n\n\tif (!np->local_ip.ip) {\n\t\tif (!np->ipv6) {\n\t\t\tconst struct in_ifaddr *ifa;\n\n\t\t\tin_dev = __in_dev_get_rtnl(ndev);\n\t\t\tif (!in_dev)\n\t\t\t\tgoto put_noaddr;\n\n\t\t\tifa = rtnl_dereference(in_dev->ifa_list);\n\t\t\tif (!ifa) {\nput_noaddr:\n\t\t\t\tnp_err(np, \"no IP address for %s, aborting\\n\",\n\t\t\t\t       np->dev_name);\n\t\t\t\terr = -EDESTADDRREQ;\n\t\t\t\tgoto put;\n\t\t\t}\n\n\t\t\tnp->local_ip.ip = ifa->ifa_local;\n\t\t\tnp_info(np, \"local IP %pI4\\n\", &np->local_ip.ip);\n\t\t} else {\n#if IS_ENABLED(CONFIG_IPV6)\n\t\t\tstruct inet6_dev *idev;\n\n\t\t\terr = -EDESTADDRREQ;\n\t\t\tidev = __in6_dev_get(ndev);\n\t\t\tif (idev) {\n\t\t\t\tstruct inet6_ifaddr *ifp;\n\n\t\t\t\tread_lock_bh(&idev->lock);\n\t\t\t\tlist_for_each_entry(ifp, &idev->addr_list, if_list) {\n\t\t\t\t\tif (!!(ipv6_addr_type(&ifp->addr) & IPV6_ADDR_LINKLOCAL) !=\n\t\t\t\t\t    !!(ipv6_addr_type(&np->remote_ip.in6) & IPV6_ADDR_LINKLOCAL))\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tnp->local_ip.in6 = ifp->addr;\n\t\t\t\t\terr = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tread_unlock_bh(&idev->lock);\n\t\t\t}\n\t\t\tif (err) {\n\t\t\t\tnp_err(np, \"no IPv6 address for %s, aborting\\n\",\n\t\t\t\t       np->dev_name);\n\t\t\t\tgoto put;\n\t\t\t} else\n\t\t\t\tnp_info(np, \"local IPv6 %pI6c\\n\", &np->local_ip.in6);\n#else\n\t\t\tnp_err(np, \"IPv6 is not supported %s, aborting\\n\",\n\t\t\t       np->dev_name);\n\t\t\terr = -EINVAL;\n\t\t\tgoto put;\n#endif\n\t\t}\n\t}\n\n\t \n\trefill_skbs();\n\n\terr = __netpoll_setup(np, ndev);\n\tif (err)\n\t\tgoto put;\n\trtnl_unlock();\n\treturn 0;\n\nput:\n\tnetdev_put(ndev, &np->dev_tracker);\nunlock:\n\trtnl_unlock();\n\treturn err;\n}\nEXPORT_SYMBOL(netpoll_setup);\n\nstatic int __init netpoll_init(void)\n{\n\tskb_queue_head_init(&skb_pool);\n\treturn 0;\n}\ncore_initcall(netpoll_init);\n\nstatic void rcu_cleanup_netpoll_info(struct rcu_head *rcu_head)\n{\n\tstruct netpoll_info *npinfo =\n\t\t\tcontainer_of(rcu_head, struct netpoll_info, rcu);\n\n\tskb_queue_purge(&npinfo->txq);\n\n\t \n\tcancel_delayed_work(&npinfo->tx_work);\n\n\t \n\t__skb_queue_purge(&npinfo->txq);\n\t \n\tcancel_delayed_work(&npinfo->tx_work);\n\tkfree(npinfo);\n}\n\nvoid __netpoll_cleanup(struct netpoll *np)\n{\n\tstruct netpoll_info *npinfo;\n\n\tnpinfo = rtnl_dereference(np->dev->npinfo);\n\tif (!npinfo)\n\t\treturn;\n\n\tsynchronize_srcu(&netpoll_srcu);\n\n\tif (refcount_dec_and_test(&npinfo->refcnt)) {\n\t\tconst struct net_device_ops *ops;\n\n\t\tops = np->dev->netdev_ops;\n\t\tif (ops->ndo_netpoll_cleanup)\n\t\t\tops->ndo_netpoll_cleanup(np->dev);\n\n\t\tRCU_INIT_POINTER(np->dev->npinfo, NULL);\n\t\tcall_rcu(&npinfo->rcu, rcu_cleanup_netpoll_info);\n\t} else\n\t\tRCU_INIT_POINTER(np->dev->npinfo, NULL);\n}\nEXPORT_SYMBOL_GPL(__netpoll_cleanup);\n\nvoid __netpoll_free(struct netpoll *np)\n{\n\tASSERT_RTNL();\n\n\t \n\tsynchronize_rcu();\n\t__netpoll_cleanup(np);\n\tkfree(np);\n}\nEXPORT_SYMBOL_GPL(__netpoll_free);\n\nvoid netpoll_cleanup(struct netpoll *np)\n{\n\trtnl_lock();\n\tif (!np->dev)\n\t\tgoto out;\n\t__netpoll_cleanup(np);\n\tnetdev_put(np->dev, &np->dev_tracker);\n\tnp->dev = NULL;\nout:\n\trtnl_unlock();\n}\nEXPORT_SYMBOL(netpoll_cleanup);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}