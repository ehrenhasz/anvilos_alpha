{
  "module_name": "drop_monitor.c",
  "hash_id": "d0ea55cfa8c47a3fc39630e8bd8dd85f0619cf1caec30e67ff291a846af1b8ad",
  "original_prompt": "Ingested from linux-6.6.14/net/core/drop_monitor.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/string.h>\n#include <linux/if_arp.h>\n#include <linux/inetdevice.h>\n#include <linux/inet.h>\n#include <linux/interrupt.h>\n#include <linux/netpoll.h>\n#include <linux/sched.h>\n#include <linux/delay.h>\n#include <linux/types.h>\n#include <linux/workqueue.h>\n#include <linux/netlink.h>\n#include <linux/net_dropmon.h>\n#include <linux/bitfield.h>\n#include <linux/percpu.h>\n#include <linux/timer.h>\n#include <linux/bitops.h>\n#include <linux/slab.h>\n#include <linux/module.h>\n#include <net/genetlink.h>\n#include <net/netevent.h>\n#include <net/flow_offload.h>\n#include <net/dropreason.h>\n#include <net/devlink.h>\n\n#include <trace/events/skb.h>\n#include <trace/events/napi.h>\n#include <trace/events/devlink.h>\n\n#include <asm/unaligned.h>\n\n#define TRACE_ON 1\n#define TRACE_OFF 0\n\n \nstatic int trace_state = TRACE_OFF;\nstatic bool monitor_hw;\n\n \nstatic DEFINE_MUTEX(net_dm_mutex);\n\nstruct net_dm_stats {\n\tu64_stats_t dropped;\n\tstruct u64_stats_sync syncp;\n};\n\n#define NET_DM_MAX_HW_TRAP_NAME_LEN 40\n\nstruct net_dm_hw_entry {\n\tchar trap_name[NET_DM_MAX_HW_TRAP_NAME_LEN];\n\tu32 count;\n};\n\nstruct net_dm_hw_entries {\n\tu32 num_entries;\n\tstruct net_dm_hw_entry entries[];\n};\n\nstruct per_cpu_dm_data {\n\tspinlock_t\t\tlock;\t \n\tunion {\n\t\tstruct sk_buff\t\t\t*skb;\n\t\tstruct net_dm_hw_entries\t*hw_entries;\n\t};\n\tstruct sk_buff_head\tdrop_queue;\n\tstruct work_struct\tdm_alert_work;\n\tstruct timer_list\tsend_timer;\n\tstruct net_dm_stats\tstats;\n};\n\nstruct dm_hw_stat_delta {\n\tunsigned long last_rx;\n\tunsigned long last_drop_val;\n\tstruct rcu_head rcu;\n};\n\nstatic struct genl_family net_drop_monitor_family;\n\nstatic DEFINE_PER_CPU(struct per_cpu_dm_data, dm_cpu_data);\nstatic DEFINE_PER_CPU(struct per_cpu_dm_data, dm_hw_cpu_data);\n\nstatic int dm_hit_limit = 64;\nstatic int dm_delay = 1;\nstatic unsigned long dm_hw_check_delta = 2*HZ;\n\nstatic enum net_dm_alert_mode net_dm_alert_mode = NET_DM_ALERT_MODE_SUMMARY;\nstatic u32 net_dm_trunc_len;\nstatic u32 net_dm_queue_len = 1000;\n\nstruct net_dm_alert_ops {\n\tvoid (*kfree_skb_probe)(void *ignore, struct sk_buff *skb,\n\t\t\t\tvoid *location,\n\t\t\t\tenum skb_drop_reason reason);\n\tvoid (*napi_poll_probe)(void *ignore, struct napi_struct *napi,\n\t\t\t\tint work, int budget);\n\tvoid (*work_item_func)(struct work_struct *work);\n\tvoid (*hw_work_item_func)(struct work_struct *work);\n\tvoid (*hw_trap_probe)(void *ignore, const struct devlink *devlink,\n\t\t\t      struct sk_buff *skb,\n\t\t\t      const struct devlink_trap_metadata *metadata);\n};\n\nstruct net_dm_skb_cb {\n\tunion {\n\t\tstruct devlink_trap_metadata *hw_metadata;\n\t\tvoid *pc;\n\t};\n\tenum skb_drop_reason reason;\n};\n\n#define NET_DM_SKB_CB(__skb) ((struct net_dm_skb_cb *)&((__skb)->cb[0]))\n\nstatic struct sk_buff *reset_per_cpu_data(struct per_cpu_dm_data *data)\n{\n\tsize_t al;\n\tstruct net_dm_alert_msg *msg;\n\tstruct nlattr *nla;\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\tvoid *msg_header;\n\n\tal = sizeof(struct net_dm_alert_msg);\n\tal += dm_hit_limit * sizeof(struct net_dm_drop_point);\n\tal += sizeof(struct nlattr);\n\n\tskb = genlmsg_new(al, GFP_KERNEL);\n\n\tif (!skb)\n\t\tgoto err;\n\n\tmsg_header = genlmsg_put(skb, 0, 0, &net_drop_monitor_family,\n\t\t\t\t 0, NET_DM_CMD_ALERT);\n\tif (!msg_header) {\n\t\tnlmsg_free(skb);\n\t\tskb = NULL;\n\t\tgoto err;\n\t}\n\tnla = nla_reserve(skb, NLA_UNSPEC,\n\t\t\t  sizeof(struct net_dm_alert_msg));\n\tif (!nla) {\n\t\tnlmsg_free(skb);\n\t\tskb = NULL;\n\t\tgoto err;\n\t}\n\tmsg = nla_data(nla);\n\tmemset(msg, 0, al);\n\tgoto out;\n\nerr:\n\tmod_timer(&data->send_timer, jiffies + HZ / 10);\nout:\n\tspin_lock_irqsave(&data->lock, flags);\n\tswap(data->skb, skb);\n\tspin_unlock_irqrestore(&data->lock, flags);\n\n\tif (skb) {\n\t\tstruct nlmsghdr *nlh = (struct nlmsghdr *)skb->data;\n\t\tstruct genlmsghdr *gnlh = (struct genlmsghdr *)nlmsg_data(nlh);\n\n\t\tgenlmsg_end(skb, genlmsg_data(gnlh));\n\t}\n\n\treturn skb;\n}\n\nstatic const struct genl_multicast_group dropmon_mcgrps[] = {\n\t{ .name = \"events\", .cap_sys_admin = 1 },\n};\n\nstatic void send_dm_alert(struct work_struct *work)\n{\n\tstruct sk_buff *skb;\n\tstruct per_cpu_dm_data *data;\n\n\tdata = container_of(work, struct per_cpu_dm_data, dm_alert_work);\n\n\tskb = reset_per_cpu_data(data);\n\n\tif (skb)\n\t\tgenlmsg_multicast(&net_drop_monitor_family, skb, 0,\n\t\t\t\t  0, GFP_KERNEL);\n}\n\n \nstatic void sched_send_work(struct timer_list *t)\n{\n\tstruct per_cpu_dm_data *data = from_timer(data, t, send_timer);\n\n\tschedule_work(&data->dm_alert_work);\n}\n\nstatic void trace_drop_common(struct sk_buff *skb, void *location)\n{\n\tstruct net_dm_alert_msg *msg;\n\tstruct net_dm_drop_point *point;\n\tstruct nlmsghdr *nlh;\n\tstruct nlattr *nla;\n\tint i;\n\tstruct sk_buff *dskb;\n\tstruct per_cpu_dm_data *data;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tdata = this_cpu_ptr(&dm_cpu_data);\n\tspin_lock(&data->lock);\n\tdskb = data->skb;\n\n\tif (!dskb)\n\t\tgoto out;\n\n\tnlh = (struct nlmsghdr *)dskb->data;\n\tnla = genlmsg_data(nlmsg_data(nlh));\n\tmsg = nla_data(nla);\n\tpoint = msg->points;\n\tfor (i = 0; i < msg->entries; i++) {\n\t\tif (!memcmp(&location, &point->pc, sizeof(void *))) {\n\t\t\tpoint->count++;\n\t\t\tgoto out;\n\t\t}\n\t\tpoint++;\n\t}\n\tif (msg->entries == dm_hit_limit)\n\t\tgoto out;\n\t \n\t__nla_reserve_nohdr(dskb, sizeof(struct net_dm_drop_point));\n\tnla->nla_len += NLA_ALIGN(sizeof(struct net_dm_drop_point));\n\tmemcpy(point->pc, &location, sizeof(void *));\n\tpoint->count = 1;\n\tmsg->entries++;\n\n\tif (!timer_pending(&data->send_timer)) {\n\t\tdata->send_timer.expires = jiffies + dm_delay * HZ;\n\t\tadd_timer(&data->send_timer);\n\t}\n\nout:\n\tspin_unlock_irqrestore(&data->lock, flags);\n}\n\nstatic void trace_kfree_skb_hit(void *ignore, struct sk_buff *skb,\n\t\t\t\tvoid *location,\n\t\t\t\tenum skb_drop_reason reason)\n{\n\ttrace_drop_common(skb, location);\n}\n\nstatic void trace_napi_poll_hit(void *ignore, struct napi_struct *napi,\n\t\t\t\tint work, int budget)\n{\n\tstruct net_device *dev = napi->dev;\n\tstruct dm_hw_stat_delta *stat;\n\t \n\tif (!dev)\n\t\treturn;\n\n\trcu_read_lock();\n\tstat = rcu_dereference(dev->dm_private);\n\tif (stat) {\n\t\t \n\t\tif (time_after(jiffies, stat->last_rx + dm_hw_check_delta) &&\n\t\t    (dev->stats.rx_dropped != stat->last_drop_val)) {\n\t\t\ttrace_drop_common(NULL, NULL);\n\t\t\tstat->last_drop_val = dev->stats.rx_dropped;\n\t\t\tstat->last_rx = jiffies;\n\t\t}\n\t}\n\trcu_read_unlock();\n}\n\nstatic struct net_dm_hw_entries *\nnet_dm_hw_reset_per_cpu_data(struct per_cpu_dm_data *hw_data)\n{\n\tstruct net_dm_hw_entries *hw_entries;\n\tunsigned long flags;\n\n\thw_entries = kzalloc(struct_size(hw_entries, entries, dm_hit_limit),\n\t\t\t     GFP_KERNEL);\n\tif (!hw_entries) {\n\t\t \n\t\tmod_timer(&hw_data->send_timer, jiffies + HZ / 10);\n\t}\n\n\tspin_lock_irqsave(&hw_data->lock, flags);\n\tswap(hw_data->hw_entries, hw_entries);\n\tspin_unlock_irqrestore(&hw_data->lock, flags);\n\n\treturn hw_entries;\n}\n\nstatic int net_dm_hw_entry_put(struct sk_buff *msg,\n\t\t\t       const struct net_dm_hw_entry *hw_entry)\n{\n\tstruct nlattr *attr;\n\n\tattr = nla_nest_start(msg, NET_DM_ATTR_HW_ENTRY);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tif (nla_put_string(msg, NET_DM_ATTR_HW_TRAP_NAME, hw_entry->trap_name))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u32(msg, NET_DM_ATTR_HW_TRAP_COUNT, hw_entry->count))\n\t\tgoto nla_put_failure;\n\n\tnla_nest_end(msg, attr);\n\n\treturn 0;\n\nnla_put_failure:\n\tnla_nest_cancel(msg, attr);\n\treturn -EMSGSIZE;\n}\n\nstatic int net_dm_hw_entries_put(struct sk_buff *msg,\n\t\t\t\t const struct net_dm_hw_entries *hw_entries)\n{\n\tstruct nlattr *attr;\n\tint i;\n\n\tattr = nla_nest_start(msg, NET_DM_ATTR_HW_ENTRIES);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tfor (i = 0; i < hw_entries->num_entries; i++) {\n\t\tint rc;\n\n\t\trc = net_dm_hw_entry_put(msg, &hw_entries->entries[i]);\n\t\tif (rc)\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tnla_nest_end(msg, attr);\n\n\treturn 0;\n\nnla_put_failure:\n\tnla_nest_cancel(msg, attr);\n\treturn -EMSGSIZE;\n}\n\nstatic int\nnet_dm_hw_summary_report_fill(struct sk_buff *msg,\n\t\t\t      const struct net_dm_hw_entries *hw_entries)\n{\n\tstruct net_dm_alert_msg anc_hdr = { 0 };\n\tvoid *hdr;\n\tint rc;\n\n\thdr = genlmsg_put(msg, 0, 0, &net_drop_monitor_family, 0,\n\t\t\t  NET_DM_CMD_ALERT);\n\tif (!hdr)\n\t\treturn -EMSGSIZE;\n\n\t \n\tif (nla_put(msg, NLA_UNSPEC, sizeof(anc_hdr), &anc_hdr))\n\t\tgoto nla_put_failure;\n\n\trc = net_dm_hw_entries_put(msg, hw_entries);\n\tif (rc)\n\t\tgoto nla_put_failure;\n\n\tgenlmsg_end(msg, hdr);\n\n\treturn 0;\n\nnla_put_failure:\n\tgenlmsg_cancel(msg, hdr);\n\treturn -EMSGSIZE;\n}\n\nstatic void net_dm_hw_summary_work(struct work_struct *work)\n{\n\tstruct net_dm_hw_entries *hw_entries;\n\tstruct per_cpu_dm_data *hw_data;\n\tstruct sk_buff *msg;\n\tint rc;\n\n\thw_data = container_of(work, struct per_cpu_dm_data, dm_alert_work);\n\n\thw_entries = net_dm_hw_reset_per_cpu_data(hw_data);\n\tif (!hw_entries)\n\t\treturn;\n\n\tmsg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\n\tif (!msg)\n\t\tgoto out;\n\n\trc = net_dm_hw_summary_report_fill(msg, hw_entries);\n\tif (rc) {\n\t\tnlmsg_free(msg);\n\t\tgoto out;\n\t}\n\n\tgenlmsg_multicast(&net_drop_monitor_family, msg, 0, 0, GFP_KERNEL);\n\nout:\n\tkfree(hw_entries);\n}\n\nstatic void\nnet_dm_hw_trap_summary_probe(void *ignore, const struct devlink *devlink,\n\t\t\t     struct sk_buff *skb,\n\t\t\t     const struct devlink_trap_metadata *metadata)\n{\n\tstruct net_dm_hw_entries *hw_entries;\n\tstruct net_dm_hw_entry *hw_entry;\n\tstruct per_cpu_dm_data *hw_data;\n\tunsigned long flags;\n\tint i;\n\n\tif (metadata->trap_type == DEVLINK_TRAP_TYPE_CONTROL)\n\t\treturn;\n\n\thw_data = this_cpu_ptr(&dm_hw_cpu_data);\n\tspin_lock_irqsave(&hw_data->lock, flags);\n\thw_entries = hw_data->hw_entries;\n\n\tif (!hw_entries)\n\t\tgoto out;\n\n\tfor (i = 0; i < hw_entries->num_entries; i++) {\n\t\thw_entry = &hw_entries->entries[i];\n\t\tif (!strncmp(hw_entry->trap_name, metadata->trap_name,\n\t\t\t     NET_DM_MAX_HW_TRAP_NAME_LEN - 1)) {\n\t\t\thw_entry->count++;\n\t\t\tgoto out;\n\t\t}\n\t}\n\tif (WARN_ON_ONCE(hw_entries->num_entries == dm_hit_limit))\n\t\tgoto out;\n\n\thw_entry = &hw_entries->entries[hw_entries->num_entries];\n\tstrscpy(hw_entry->trap_name, metadata->trap_name,\n\t\tNET_DM_MAX_HW_TRAP_NAME_LEN - 1);\n\thw_entry->count = 1;\n\thw_entries->num_entries++;\n\n\tif (!timer_pending(&hw_data->send_timer)) {\n\t\thw_data->send_timer.expires = jiffies + dm_delay * HZ;\n\t\tadd_timer(&hw_data->send_timer);\n\t}\n\nout:\n\tspin_unlock_irqrestore(&hw_data->lock, flags);\n}\n\nstatic const struct net_dm_alert_ops net_dm_alert_summary_ops = {\n\t.kfree_skb_probe\t= trace_kfree_skb_hit,\n\t.napi_poll_probe\t= trace_napi_poll_hit,\n\t.work_item_func\t\t= send_dm_alert,\n\t.hw_work_item_func\t= net_dm_hw_summary_work,\n\t.hw_trap_probe\t\t= net_dm_hw_trap_summary_probe,\n};\n\nstatic void net_dm_packet_trace_kfree_skb_hit(void *ignore,\n\t\t\t\t\t      struct sk_buff *skb,\n\t\t\t\t\t      void *location,\n\t\t\t\t\t      enum skb_drop_reason reason)\n{\n\tktime_t tstamp = ktime_get_real();\n\tstruct per_cpu_dm_data *data;\n\tstruct net_dm_skb_cb *cb;\n\tstruct sk_buff *nskb;\n\tunsigned long flags;\n\n\tif (!skb_mac_header_was_set(skb))\n\t\treturn;\n\n\tnskb = skb_clone(skb, GFP_ATOMIC);\n\tif (!nskb)\n\t\treturn;\n\n\tcb = NET_DM_SKB_CB(nskb);\n\tcb->reason = reason;\n\tcb->pc = location;\n\t \n\tnskb->tstamp = tstamp;\n\n\tdata = this_cpu_ptr(&dm_cpu_data);\n\n\tspin_lock_irqsave(&data->drop_queue.lock, flags);\n\tif (skb_queue_len(&data->drop_queue) < net_dm_queue_len)\n\t\t__skb_queue_tail(&data->drop_queue, nskb);\n\telse\n\t\tgoto unlock_free;\n\tspin_unlock_irqrestore(&data->drop_queue.lock, flags);\n\n\tschedule_work(&data->dm_alert_work);\n\n\treturn;\n\nunlock_free:\n\tspin_unlock_irqrestore(&data->drop_queue.lock, flags);\n\tu64_stats_update_begin(&data->stats.syncp);\n\tu64_stats_inc(&data->stats.dropped);\n\tu64_stats_update_end(&data->stats.syncp);\n\tconsume_skb(nskb);\n}\n\nstatic void net_dm_packet_trace_napi_poll_hit(void *ignore,\n\t\t\t\t\t      struct napi_struct *napi,\n\t\t\t\t\t      int work, int budget)\n{\n}\n\nstatic size_t net_dm_in_port_size(void)\n{\n\t        \n\treturn nla_total_size(0) +\n\t        \n\t       nla_total_size(sizeof(u32)) +\n\t        \n\t       nla_total_size(IFNAMSIZ + 1);\n}\n\n#define NET_DM_MAX_SYMBOL_LEN 40\n#define NET_DM_MAX_REASON_LEN 50\n\nstatic size_t net_dm_packet_report_size(size_t payload_len)\n{\n\tsize_t size;\n\n\tsize = nlmsg_msg_size(GENL_HDRLEN + net_drop_monitor_family.hdrsize);\n\n\treturn NLMSG_ALIGN(size) +\n\t        \n\t       nla_total_size(sizeof(u16)) +\n\t        \n\t       nla_total_size(sizeof(u64)) +\n\t        \n\t       nla_total_size(NET_DM_MAX_SYMBOL_LEN + 1) +\n\t        \n\t       net_dm_in_port_size() +\n\t        \n\t       nla_total_size(sizeof(u64)) +\n\t        \n\t       nla_total_size(sizeof(u32)) +\n\t        \n\t       nla_total_size(sizeof(u16)) +\n\t        \n\t       nla_total_size(NET_DM_MAX_REASON_LEN + 1) +\n\t        \n\t       nla_total_size(payload_len);\n}\n\nstatic int net_dm_packet_report_in_port_put(struct sk_buff *msg, int ifindex,\n\t\t\t\t\t    const char *name)\n{\n\tstruct nlattr *attr;\n\n\tattr = nla_nest_start(msg, NET_DM_ATTR_IN_PORT);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tif (ifindex &&\n\t    nla_put_u32(msg, NET_DM_ATTR_PORT_NETDEV_IFINDEX, ifindex))\n\t\tgoto nla_put_failure;\n\n\tif (name && nla_put_string(msg, NET_DM_ATTR_PORT_NETDEV_NAME, name))\n\t\tgoto nla_put_failure;\n\n\tnla_nest_end(msg, attr);\n\n\treturn 0;\n\nnla_put_failure:\n\tnla_nest_cancel(msg, attr);\n\treturn -EMSGSIZE;\n}\n\nstatic int net_dm_packet_report_fill(struct sk_buff *msg, struct sk_buff *skb,\n\t\t\t\t     size_t payload_len)\n{\n\tstruct net_dm_skb_cb *cb = NET_DM_SKB_CB(skb);\n\tconst struct drop_reason_list *list = NULL;\n\tunsigned int subsys, subsys_reason;\n\tchar buf[NET_DM_MAX_SYMBOL_LEN];\n\tstruct nlattr *attr;\n\tvoid *hdr;\n\tint rc;\n\n\thdr = genlmsg_put(msg, 0, 0, &net_drop_monitor_family, 0,\n\t\t\t  NET_DM_CMD_PACKET_ALERT);\n\tif (!hdr)\n\t\treturn -EMSGSIZE;\n\n\tif (nla_put_u16(msg, NET_DM_ATTR_ORIGIN, NET_DM_ORIGIN_SW))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u64_64bit(msg, NET_DM_ATTR_PC, (u64)(uintptr_t)cb->pc,\n\t\t\t      NET_DM_ATTR_PAD))\n\t\tgoto nla_put_failure;\n\n\trcu_read_lock();\n\tsubsys = u32_get_bits(cb->reason, SKB_DROP_REASON_SUBSYS_MASK);\n\tif (subsys < SKB_DROP_REASON_SUBSYS_NUM)\n\t\tlist = rcu_dereference(drop_reasons_by_subsys[subsys]);\n\tsubsys_reason = cb->reason & ~SKB_DROP_REASON_SUBSYS_MASK;\n\tif (!list ||\n\t    subsys_reason >= list->n_reasons ||\n\t    !list->reasons[subsys_reason] ||\n\t    strlen(list->reasons[subsys_reason]) > NET_DM_MAX_REASON_LEN) {\n\t\tlist = rcu_dereference(drop_reasons_by_subsys[SKB_DROP_REASON_SUBSYS_CORE]);\n\t\tsubsys_reason = SKB_DROP_REASON_NOT_SPECIFIED;\n\t}\n\tif (nla_put_string(msg, NET_DM_ATTR_REASON,\n\t\t\t   list->reasons[subsys_reason])) {\n\t\trcu_read_unlock();\n\t\tgoto nla_put_failure;\n\t}\n\trcu_read_unlock();\n\n\tsnprintf(buf, sizeof(buf), \"%pS\", cb->pc);\n\tif (nla_put_string(msg, NET_DM_ATTR_SYMBOL, buf))\n\t\tgoto nla_put_failure;\n\n\trc = net_dm_packet_report_in_port_put(msg, skb->skb_iif, NULL);\n\tif (rc)\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u64_64bit(msg, NET_DM_ATTR_TIMESTAMP,\n\t\t\t      ktime_to_ns(skb->tstamp), NET_DM_ATTR_PAD))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u32(msg, NET_DM_ATTR_ORIG_LEN, skb->len))\n\t\tgoto nla_put_failure;\n\n\tif (!payload_len)\n\t\tgoto out;\n\n\tif (nla_put_u16(msg, NET_DM_ATTR_PROTO, be16_to_cpu(skb->protocol)))\n\t\tgoto nla_put_failure;\n\n\tattr = skb_put(msg, nla_total_size(payload_len));\n\tattr->nla_type = NET_DM_ATTR_PAYLOAD;\n\tattr->nla_len = nla_attr_size(payload_len);\n\tif (skb_copy_bits(skb, 0, nla_data(attr), payload_len))\n\t\tgoto nla_put_failure;\n\nout:\n\tgenlmsg_end(msg, hdr);\n\n\treturn 0;\n\nnla_put_failure:\n\tgenlmsg_cancel(msg, hdr);\n\treturn -EMSGSIZE;\n}\n\n#define NET_DM_MAX_PACKET_SIZE (0xffff - NLA_HDRLEN - NLA_ALIGNTO)\n\nstatic void net_dm_packet_report(struct sk_buff *skb)\n{\n\tstruct sk_buff *msg;\n\tsize_t payload_len;\n\tint rc;\n\n\t \n\tif (skb->data > skb_mac_header(skb))\n\t\tskb_push(skb, skb->data - skb_mac_header(skb));\n\telse\n\t\tskb_pull(skb, skb_mac_header(skb) - skb->data);\n\n\t \n\tpayload_len = min_t(size_t, skb->len, NET_DM_MAX_PACKET_SIZE);\n\tif (net_dm_trunc_len)\n\t\tpayload_len = min_t(size_t, net_dm_trunc_len, payload_len);\n\n\tmsg = nlmsg_new(net_dm_packet_report_size(payload_len), GFP_KERNEL);\n\tif (!msg)\n\t\tgoto out;\n\n\trc = net_dm_packet_report_fill(msg, skb, payload_len);\n\tif (rc) {\n\t\tnlmsg_free(msg);\n\t\tgoto out;\n\t}\n\n\tgenlmsg_multicast(&net_drop_monitor_family, msg, 0, 0, GFP_KERNEL);\n\nout:\n\tconsume_skb(skb);\n}\n\nstatic void net_dm_packet_work(struct work_struct *work)\n{\n\tstruct per_cpu_dm_data *data;\n\tstruct sk_buff_head list;\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\n\tdata = container_of(work, struct per_cpu_dm_data, dm_alert_work);\n\n\t__skb_queue_head_init(&list);\n\n\tspin_lock_irqsave(&data->drop_queue.lock, flags);\n\tskb_queue_splice_tail_init(&data->drop_queue, &list);\n\tspin_unlock_irqrestore(&data->drop_queue.lock, flags);\n\n\twhile ((skb = __skb_dequeue(&list)))\n\t\tnet_dm_packet_report(skb);\n}\n\nstatic size_t\nnet_dm_flow_action_cookie_size(const struct devlink_trap_metadata *hw_metadata)\n{\n\treturn hw_metadata->fa_cookie ?\n\t       nla_total_size(hw_metadata->fa_cookie->cookie_len) : 0;\n}\n\nstatic size_t\nnet_dm_hw_packet_report_size(size_t payload_len,\n\t\t\t     const struct devlink_trap_metadata *hw_metadata)\n{\n\tsize_t size;\n\n\tsize = nlmsg_msg_size(GENL_HDRLEN + net_drop_monitor_family.hdrsize);\n\n\treturn NLMSG_ALIGN(size) +\n\t        \n\t       nla_total_size(sizeof(u16)) +\n\t        \n\t       nla_total_size(strlen(hw_metadata->trap_group_name) + 1) +\n\t        \n\t       nla_total_size(strlen(hw_metadata->trap_name) + 1) +\n\t        \n\t       net_dm_in_port_size() +\n\t        \n\t       net_dm_flow_action_cookie_size(hw_metadata) +\n\t        \n\t       nla_total_size(sizeof(u64)) +\n\t        \n\t       nla_total_size(sizeof(u32)) +\n\t        \n\t       nla_total_size(sizeof(u16)) +\n\t        \n\t       nla_total_size(payload_len);\n}\n\nstatic int net_dm_hw_packet_report_fill(struct sk_buff *msg,\n\t\t\t\t\tstruct sk_buff *skb, size_t payload_len)\n{\n\tstruct devlink_trap_metadata *hw_metadata;\n\tstruct nlattr *attr;\n\tvoid *hdr;\n\n\thw_metadata = NET_DM_SKB_CB(skb)->hw_metadata;\n\n\thdr = genlmsg_put(msg, 0, 0, &net_drop_monitor_family, 0,\n\t\t\t  NET_DM_CMD_PACKET_ALERT);\n\tif (!hdr)\n\t\treturn -EMSGSIZE;\n\n\tif (nla_put_u16(msg, NET_DM_ATTR_ORIGIN, NET_DM_ORIGIN_HW))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_string(msg, NET_DM_ATTR_HW_TRAP_GROUP_NAME,\n\t\t\t   hw_metadata->trap_group_name))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_string(msg, NET_DM_ATTR_HW_TRAP_NAME,\n\t\t\t   hw_metadata->trap_name))\n\t\tgoto nla_put_failure;\n\n\tif (hw_metadata->input_dev) {\n\t\tstruct net_device *dev = hw_metadata->input_dev;\n\t\tint rc;\n\n\t\trc = net_dm_packet_report_in_port_put(msg, dev->ifindex,\n\t\t\t\t\t\t      dev->name);\n\t\tif (rc)\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (hw_metadata->fa_cookie &&\n\t    nla_put(msg, NET_DM_ATTR_FLOW_ACTION_COOKIE,\n\t\t    hw_metadata->fa_cookie->cookie_len,\n\t\t    hw_metadata->fa_cookie->cookie))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u64_64bit(msg, NET_DM_ATTR_TIMESTAMP,\n\t\t\t      ktime_to_ns(skb->tstamp), NET_DM_ATTR_PAD))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u32(msg, NET_DM_ATTR_ORIG_LEN, skb->len))\n\t\tgoto nla_put_failure;\n\n\tif (!payload_len)\n\t\tgoto out;\n\n\tif (nla_put_u16(msg, NET_DM_ATTR_PROTO, be16_to_cpu(skb->protocol)))\n\t\tgoto nla_put_failure;\n\n\tattr = skb_put(msg, nla_total_size(payload_len));\n\tattr->nla_type = NET_DM_ATTR_PAYLOAD;\n\tattr->nla_len = nla_attr_size(payload_len);\n\tif (skb_copy_bits(skb, 0, nla_data(attr), payload_len))\n\t\tgoto nla_put_failure;\n\nout:\n\tgenlmsg_end(msg, hdr);\n\n\treturn 0;\n\nnla_put_failure:\n\tgenlmsg_cancel(msg, hdr);\n\treturn -EMSGSIZE;\n}\n\nstatic struct devlink_trap_metadata *\nnet_dm_hw_metadata_copy(const struct devlink_trap_metadata *metadata)\n{\n\tconst struct flow_action_cookie *fa_cookie;\n\tstruct devlink_trap_metadata *hw_metadata;\n\tconst char *trap_group_name;\n\tconst char *trap_name;\n\n\thw_metadata = kzalloc(sizeof(*hw_metadata), GFP_ATOMIC);\n\tif (!hw_metadata)\n\t\treturn NULL;\n\n\ttrap_group_name = kstrdup(metadata->trap_group_name, GFP_ATOMIC);\n\tif (!trap_group_name)\n\t\tgoto free_hw_metadata;\n\thw_metadata->trap_group_name = trap_group_name;\n\n\ttrap_name = kstrdup(metadata->trap_name, GFP_ATOMIC);\n\tif (!trap_name)\n\t\tgoto free_trap_group;\n\thw_metadata->trap_name = trap_name;\n\n\tif (metadata->fa_cookie) {\n\t\tsize_t cookie_size = sizeof(*fa_cookie) +\n\t\t\t\t     metadata->fa_cookie->cookie_len;\n\n\t\tfa_cookie = kmemdup(metadata->fa_cookie, cookie_size,\n\t\t\t\t    GFP_ATOMIC);\n\t\tif (!fa_cookie)\n\t\t\tgoto free_trap_name;\n\t\thw_metadata->fa_cookie = fa_cookie;\n\t}\n\n\thw_metadata->input_dev = metadata->input_dev;\n\tnetdev_hold(hw_metadata->input_dev, &hw_metadata->dev_tracker,\n\t\t    GFP_ATOMIC);\n\n\treturn hw_metadata;\n\nfree_trap_name:\n\tkfree(trap_name);\nfree_trap_group:\n\tkfree(trap_group_name);\nfree_hw_metadata:\n\tkfree(hw_metadata);\n\treturn NULL;\n}\n\nstatic void\nnet_dm_hw_metadata_free(struct devlink_trap_metadata *hw_metadata)\n{\n\tnetdev_put(hw_metadata->input_dev, &hw_metadata->dev_tracker);\n\tkfree(hw_metadata->fa_cookie);\n\tkfree(hw_metadata->trap_name);\n\tkfree(hw_metadata->trap_group_name);\n\tkfree(hw_metadata);\n}\n\nstatic void net_dm_hw_packet_report(struct sk_buff *skb)\n{\n\tstruct devlink_trap_metadata *hw_metadata;\n\tstruct sk_buff *msg;\n\tsize_t payload_len;\n\tint rc;\n\n\tif (skb->data > skb_mac_header(skb))\n\t\tskb_push(skb, skb->data - skb_mac_header(skb));\n\telse\n\t\tskb_pull(skb, skb_mac_header(skb) - skb->data);\n\n\tpayload_len = min_t(size_t, skb->len, NET_DM_MAX_PACKET_SIZE);\n\tif (net_dm_trunc_len)\n\t\tpayload_len = min_t(size_t, net_dm_trunc_len, payload_len);\n\n\thw_metadata = NET_DM_SKB_CB(skb)->hw_metadata;\n\tmsg = nlmsg_new(net_dm_hw_packet_report_size(payload_len, hw_metadata),\n\t\t\tGFP_KERNEL);\n\tif (!msg)\n\t\tgoto out;\n\n\trc = net_dm_hw_packet_report_fill(msg, skb, payload_len);\n\tif (rc) {\n\t\tnlmsg_free(msg);\n\t\tgoto out;\n\t}\n\n\tgenlmsg_multicast(&net_drop_monitor_family, msg, 0, 0, GFP_KERNEL);\n\nout:\n\tnet_dm_hw_metadata_free(NET_DM_SKB_CB(skb)->hw_metadata);\n\tconsume_skb(skb);\n}\n\nstatic void net_dm_hw_packet_work(struct work_struct *work)\n{\n\tstruct per_cpu_dm_data *hw_data;\n\tstruct sk_buff_head list;\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\n\thw_data = container_of(work, struct per_cpu_dm_data, dm_alert_work);\n\n\t__skb_queue_head_init(&list);\n\n\tspin_lock_irqsave(&hw_data->drop_queue.lock, flags);\n\tskb_queue_splice_tail_init(&hw_data->drop_queue, &list);\n\tspin_unlock_irqrestore(&hw_data->drop_queue.lock, flags);\n\n\twhile ((skb = __skb_dequeue(&list)))\n\t\tnet_dm_hw_packet_report(skb);\n}\n\nstatic void\nnet_dm_hw_trap_packet_probe(void *ignore, const struct devlink *devlink,\n\t\t\t    struct sk_buff *skb,\n\t\t\t    const struct devlink_trap_metadata *metadata)\n{\n\tstruct devlink_trap_metadata *n_hw_metadata;\n\tktime_t tstamp = ktime_get_real();\n\tstruct per_cpu_dm_data *hw_data;\n\tstruct sk_buff *nskb;\n\tunsigned long flags;\n\n\tif (metadata->trap_type == DEVLINK_TRAP_TYPE_CONTROL)\n\t\treturn;\n\n\tif (!skb_mac_header_was_set(skb))\n\t\treturn;\n\n\tnskb = skb_clone(skb, GFP_ATOMIC);\n\tif (!nskb)\n\t\treturn;\n\n\tn_hw_metadata = net_dm_hw_metadata_copy(metadata);\n\tif (!n_hw_metadata)\n\t\tgoto free;\n\n\tNET_DM_SKB_CB(nskb)->hw_metadata = n_hw_metadata;\n\tnskb->tstamp = tstamp;\n\n\thw_data = this_cpu_ptr(&dm_hw_cpu_data);\n\n\tspin_lock_irqsave(&hw_data->drop_queue.lock, flags);\n\tif (skb_queue_len(&hw_data->drop_queue) < net_dm_queue_len)\n\t\t__skb_queue_tail(&hw_data->drop_queue, nskb);\n\telse\n\t\tgoto unlock_free;\n\tspin_unlock_irqrestore(&hw_data->drop_queue.lock, flags);\n\n\tschedule_work(&hw_data->dm_alert_work);\n\n\treturn;\n\nunlock_free:\n\tspin_unlock_irqrestore(&hw_data->drop_queue.lock, flags);\n\tu64_stats_update_begin(&hw_data->stats.syncp);\n\tu64_stats_inc(&hw_data->stats.dropped);\n\tu64_stats_update_end(&hw_data->stats.syncp);\n\tnet_dm_hw_metadata_free(n_hw_metadata);\nfree:\n\tconsume_skb(nskb);\n}\n\nstatic const struct net_dm_alert_ops net_dm_alert_packet_ops = {\n\t.kfree_skb_probe\t= net_dm_packet_trace_kfree_skb_hit,\n\t.napi_poll_probe\t= net_dm_packet_trace_napi_poll_hit,\n\t.work_item_func\t\t= net_dm_packet_work,\n\t.hw_work_item_func\t= net_dm_hw_packet_work,\n\t.hw_trap_probe\t\t= net_dm_hw_trap_packet_probe,\n};\n\nstatic const struct net_dm_alert_ops *net_dm_alert_ops_arr[] = {\n\t[NET_DM_ALERT_MODE_SUMMARY]\t= &net_dm_alert_summary_ops,\n\t[NET_DM_ALERT_MODE_PACKET]\t= &net_dm_alert_packet_ops,\n};\n\n#if IS_ENABLED(CONFIG_NET_DEVLINK)\nstatic int net_dm_hw_probe_register(const struct net_dm_alert_ops *ops)\n{\n\treturn register_trace_devlink_trap_report(ops->hw_trap_probe, NULL);\n}\n\nstatic void net_dm_hw_probe_unregister(const struct net_dm_alert_ops *ops)\n{\n\tunregister_trace_devlink_trap_report(ops->hw_trap_probe, NULL);\n\ttracepoint_synchronize_unregister();\n}\n#else\nstatic int net_dm_hw_probe_register(const struct net_dm_alert_ops *ops)\n{\n\treturn -EOPNOTSUPP;\n}\n\nstatic void net_dm_hw_probe_unregister(const struct net_dm_alert_ops *ops)\n{\n}\n#endif\n\nstatic int net_dm_hw_monitor_start(struct netlink_ext_ack *extack)\n{\n\tconst struct net_dm_alert_ops *ops;\n\tint cpu, rc;\n\n\tif (monitor_hw) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Hardware monitoring already enabled\");\n\t\treturn -EAGAIN;\n\t}\n\n\tops = net_dm_alert_ops_arr[net_dm_alert_mode];\n\n\tif (!try_module_get(THIS_MODULE)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to take reference on module\");\n\t\treturn -ENODEV;\n\t}\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct per_cpu_dm_data *hw_data = &per_cpu(dm_hw_cpu_data, cpu);\n\t\tstruct net_dm_hw_entries *hw_entries;\n\n\t\tINIT_WORK(&hw_data->dm_alert_work, ops->hw_work_item_func);\n\t\ttimer_setup(&hw_data->send_timer, sched_send_work, 0);\n\t\thw_entries = net_dm_hw_reset_per_cpu_data(hw_data);\n\t\tkfree(hw_entries);\n\t}\n\n\trc = net_dm_hw_probe_register(ops);\n\tif (rc) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to connect probe to devlink_trap_probe() tracepoint\");\n\t\tgoto err_module_put;\n\t}\n\n\tmonitor_hw = true;\n\n\treturn 0;\n\nerr_module_put:\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct per_cpu_dm_data *hw_data = &per_cpu(dm_hw_cpu_data, cpu);\n\t\tstruct sk_buff *skb;\n\n\t\tdel_timer_sync(&hw_data->send_timer);\n\t\tcancel_work_sync(&hw_data->dm_alert_work);\n\t\twhile ((skb = __skb_dequeue(&hw_data->drop_queue))) {\n\t\t\tstruct devlink_trap_metadata *hw_metadata;\n\n\t\t\thw_metadata = NET_DM_SKB_CB(skb)->hw_metadata;\n\t\t\tnet_dm_hw_metadata_free(hw_metadata);\n\t\t\tconsume_skb(skb);\n\t\t}\n\t}\n\tmodule_put(THIS_MODULE);\n\treturn rc;\n}\n\nstatic void net_dm_hw_monitor_stop(struct netlink_ext_ack *extack)\n{\n\tconst struct net_dm_alert_ops *ops;\n\tint cpu;\n\n\tif (!monitor_hw) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Hardware monitoring already disabled\");\n\t\treturn;\n\t}\n\n\tops = net_dm_alert_ops_arr[net_dm_alert_mode];\n\n\tmonitor_hw = false;\n\n\tnet_dm_hw_probe_unregister(ops);\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct per_cpu_dm_data *hw_data = &per_cpu(dm_hw_cpu_data, cpu);\n\t\tstruct sk_buff *skb;\n\n\t\tdel_timer_sync(&hw_data->send_timer);\n\t\tcancel_work_sync(&hw_data->dm_alert_work);\n\t\twhile ((skb = __skb_dequeue(&hw_data->drop_queue))) {\n\t\t\tstruct devlink_trap_metadata *hw_metadata;\n\n\t\t\thw_metadata = NET_DM_SKB_CB(skb)->hw_metadata;\n\t\t\tnet_dm_hw_metadata_free(hw_metadata);\n\t\t\tconsume_skb(skb);\n\t\t}\n\t}\n\n\tmodule_put(THIS_MODULE);\n}\n\nstatic int net_dm_trace_on_set(struct netlink_ext_ack *extack)\n{\n\tconst struct net_dm_alert_ops *ops;\n\tint cpu, rc;\n\n\tops = net_dm_alert_ops_arr[net_dm_alert_mode];\n\n\tif (!try_module_get(THIS_MODULE)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to take reference on module\");\n\t\treturn -ENODEV;\n\t}\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct per_cpu_dm_data *data = &per_cpu(dm_cpu_data, cpu);\n\t\tstruct sk_buff *skb;\n\n\t\tINIT_WORK(&data->dm_alert_work, ops->work_item_func);\n\t\ttimer_setup(&data->send_timer, sched_send_work, 0);\n\t\t \n\t\tskb = reset_per_cpu_data(data);\n\t\tconsume_skb(skb);\n\t}\n\n\trc = register_trace_kfree_skb(ops->kfree_skb_probe, NULL);\n\tif (rc) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to connect probe to kfree_skb() tracepoint\");\n\t\tgoto err_module_put;\n\t}\n\n\trc = register_trace_napi_poll(ops->napi_poll_probe, NULL);\n\tif (rc) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to connect probe to napi_poll() tracepoint\");\n\t\tgoto err_unregister_trace;\n\t}\n\n\treturn 0;\n\nerr_unregister_trace:\n\tunregister_trace_kfree_skb(ops->kfree_skb_probe, NULL);\nerr_module_put:\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct per_cpu_dm_data *data = &per_cpu(dm_cpu_data, cpu);\n\t\tstruct sk_buff *skb;\n\n\t\tdel_timer_sync(&data->send_timer);\n\t\tcancel_work_sync(&data->dm_alert_work);\n\t\twhile ((skb = __skb_dequeue(&data->drop_queue)))\n\t\t\tconsume_skb(skb);\n\t}\n\tmodule_put(THIS_MODULE);\n\treturn rc;\n}\n\nstatic void net_dm_trace_off_set(void)\n{\n\tconst struct net_dm_alert_ops *ops;\n\tint cpu;\n\n\tops = net_dm_alert_ops_arr[net_dm_alert_mode];\n\n\tunregister_trace_napi_poll(ops->napi_poll_probe, NULL);\n\tunregister_trace_kfree_skb(ops->kfree_skb_probe, NULL);\n\n\ttracepoint_synchronize_unregister();\n\n\t \n\tfor_each_possible_cpu(cpu) {\n\t\tstruct per_cpu_dm_data *data = &per_cpu(dm_cpu_data, cpu);\n\t\tstruct sk_buff *skb;\n\n\t\tdel_timer_sync(&data->send_timer);\n\t\tcancel_work_sync(&data->dm_alert_work);\n\t\twhile ((skb = __skb_dequeue(&data->drop_queue)))\n\t\t\tconsume_skb(skb);\n\t}\n\n\tmodule_put(THIS_MODULE);\n}\n\nstatic int set_all_monitor_traces(int state, struct netlink_ext_ack *extack)\n{\n\tint rc = 0;\n\n\tif (state == trace_state) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Trace state already set to requested state\");\n\t\treturn -EAGAIN;\n\t}\n\n\tswitch (state) {\n\tcase TRACE_ON:\n\t\trc = net_dm_trace_on_set(extack);\n\t\tbreak;\n\tcase TRACE_OFF:\n\t\tnet_dm_trace_off_set();\n\t\tbreak;\n\tdefault:\n\t\trc = 1;\n\t\tbreak;\n\t}\n\n\tif (!rc)\n\t\ttrace_state = state;\n\telse\n\t\trc = -EINPROGRESS;\n\n\treturn rc;\n}\n\nstatic bool net_dm_is_monitoring(void)\n{\n\treturn trace_state == TRACE_ON || monitor_hw;\n}\n\nstatic int net_dm_alert_mode_get_from_info(struct genl_info *info,\n\t\t\t\t\t   enum net_dm_alert_mode *p_alert_mode)\n{\n\tu8 val;\n\n\tval = nla_get_u8(info->attrs[NET_DM_ATTR_ALERT_MODE]);\n\n\tswitch (val) {\n\tcase NET_DM_ALERT_MODE_SUMMARY:\n\tcase NET_DM_ALERT_MODE_PACKET:\n\t\t*p_alert_mode = val;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int net_dm_alert_mode_set(struct genl_info *info)\n{\n\tstruct netlink_ext_ack *extack = info->extack;\n\tenum net_dm_alert_mode alert_mode;\n\tint rc;\n\n\tif (!info->attrs[NET_DM_ATTR_ALERT_MODE])\n\t\treturn 0;\n\n\trc = net_dm_alert_mode_get_from_info(info, &alert_mode);\n\tif (rc) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Invalid alert mode\");\n\t\treturn -EINVAL;\n\t}\n\n\tnet_dm_alert_mode = alert_mode;\n\n\treturn 0;\n}\n\nstatic void net_dm_trunc_len_set(struct genl_info *info)\n{\n\tif (!info->attrs[NET_DM_ATTR_TRUNC_LEN])\n\t\treturn;\n\n\tnet_dm_trunc_len = nla_get_u32(info->attrs[NET_DM_ATTR_TRUNC_LEN]);\n}\n\nstatic void net_dm_queue_len_set(struct genl_info *info)\n{\n\tif (!info->attrs[NET_DM_ATTR_QUEUE_LEN])\n\t\treturn;\n\n\tnet_dm_queue_len = nla_get_u32(info->attrs[NET_DM_ATTR_QUEUE_LEN]);\n}\n\nstatic int net_dm_cmd_config(struct sk_buff *skb,\n\t\t\tstruct genl_info *info)\n{\n\tstruct netlink_ext_ack *extack = info->extack;\n\tint rc;\n\n\tif (net_dm_is_monitoring()) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot configure drop monitor during monitoring\");\n\t\treturn -EBUSY;\n\t}\n\n\trc = net_dm_alert_mode_set(info);\n\tif (rc)\n\t\treturn rc;\n\n\tnet_dm_trunc_len_set(info);\n\n\tnet_dm_queue_len_set(info);\n\n\treturn 0;\n}\n\nstatic int net_dm_monitor_start(bool set_sw, bool set_hw,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tbool sw_set = false;\n\tint rc;\n\n\tif (set_sw) {\n\t\trc = set_all_monitor_traces(TRACE_ON, extack);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tsw_set = true;\n\t}\n\n\tif (set_hw) {\n\t\trc = net_dm_hw_monitor_start(extack);\n\t\tif (rc)\n\t\t\tgoto err_monitor_hw;\n\t}\n\n\treturn 0;\n\nerr_monitor_hw:\n\tif (sw_set)\n\t\tset_all_monitor_traces(TRACE_OFF, extack);\n\treturn rc;\n}\n\nstatic void net_dm_monitor_stop(bool set_sw, bool set_hw,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tif (set_hw)\n\t\tnet_dm_hw_monitor_stop(extack);\n\tif (set_sw)\n\t\tset_all_monitor_traces(TRACE_OFF, extack);\n}\n\nstatic int net_dm_cmd_trace(struct sk_buff *skb,\n\t\t\tstruct genl_info *info)\n{\n\tbool set_sw = !!info->attrs[NET_DM_ATTR_SW_DROPS];\n\tbool set_hw = !!info->attrs[NET_DM_ATTR_HW_DROPS];\n\tstruct netlink_ext_ack *extack = info->extack;\n\n\t \n\tif (!set_sw && !set_hw)\n\t\tset_sw = true;\n\n\tswitch (info->genlhdr->cmd) {\n\tcase NET_DM_CMD_START:\n\t\treturn net_dm_monitor_start(set_sw, set_hw, extack);\n\tcase NET_DM_CMD_STOP:\n\t\tnet_dm_monitor_stop(set_sw, set_hw, extack);\n\t\treturn 0;\n\t}\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic int net_dm_config_fill(struct sk_buff *msg, struct genl_info *info)\n{\n\tvoid *hdr;\n\n\thdr = genlmsg_put(msg, info->snd_portid, info->snd_seq,\n\t\t\t  &net_drop_monitor_family, 0, NET_DM_CMD_CONFIG_NEW);\n\tif (!hdr)\n\t\treturn -EMSGSIZE;\n\n\tif (nla_put_u8(msg, NET_DM_ATTR_ALERT_MODE, net_dm_alert_mode))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u32(msg, NET_DM_ATTR_TRUNC_LEN, net_dm_trunc_len))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u32(msg, NET_DM_ATTR_QUEUE_LEN, net_dm_queue_len))\n\t\tgoto nla_put_failure;\n\n\tgenlmsg_end(msg, hdr);\n\n\treturn 0;\n\nnla_put_failure:\n\tgenlmsg_cancel(msg, hdr);\n\treturn -EMSGSIZE;\n}\n\nstatic int net_dm_cmd_config_get(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct sk_buff *msg;\n\tint rc;\n\n\tmsg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\n\tif (!msg)\n\t\treturn -ENOMEM;\n\n\trc = net_dm_config_fill(msg, info);\n\tif (rc)\n\t\tgoto free_msg;\n\n\treturn genlmsg_reply(msg, info);\n\nfree_msg:\n\tnlmsg_free(msg);\n\treturn rc;\n}\n\nstatic void net_dm_stats_read(struct net_dm_stats *stats)\n{\n\tint cpu;\n\n\tmemset(stats, 0, sizeof(*stats));\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct per_cpu_dm_data *data = &per_cpu(dm_cpu_data, cpu);\n\t\tstruct net_dm_stats *cpu_stats = &data->stats;\n\t\tunsigned int start;\n\t\tu64 dropped;\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&cpu_stats->syncp);\n\t\t\tdropped = u64_stats_read(&cpu_stats->dropped);\n\t\t} while (u64_stats_fetch_retry(&cpu_stats->syncp, start));\n\n\t\tu64_stats_add(&stats->dropped, dropped);\n\t}\n}\n\nstatic int net_dm_stats_put(struct sk_buff *msg)\n{\n\tstruct net_dm_stats stats;\n\tstruct nlattr *attr;\n\n\tnet_dm_stats_read(&stats);\n\n\tattr = nla_nest_start(msg, NET_DM_ATTR_STATS);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tif (nla_put_u64_64bit(msg, NET_DM_ATTR_STATS_DROPPED,\n\t\t\t      u64_stats_read(&stats.dropped), NET_DM_ATTR_PAD))\n\t\tgoto nla_put_failure;\n\n\tnla_nest_end(msg, attr);\n\n\treturn 0;\n\nnla_put_failure:\n\tnla_nest_cancel(msg, attr);\n\treturn -EMSGSIZE;\n}\n\nstatic void net_dm_hw_stats_read(struct net_dm_stats *stats)\n{\n\tint cpu;\n\n\tmemset(stats, 0, sizeof(*stats));\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct per_cpu_dm_data *hw_data = &per_cpu(dm_hw_cpu_data, cpu);\n\t\tstruct net_dm_stats *cpu_stats = &hw_data->stats;\n\t\tunsigned int start;\n\t\tu64 dropped;\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&cpu_stats->syncp);\n\t\t\tdropped = u64_stats_read(&cpu_stats->dropped);\n\t\t} while (u64_stats_fetch_retry(&cpu_stats->syncp, start));\n\n\t\tu64_stats_add(&stats->dropped, dropped);\n\t}\n}\n\nstatic int net_dm_hw_stats_put(struct sk_buff *msg)\n{\n\tstruct net_dm_stats stats;\n\tstruct nlattr *attr;\n\n\tnet_dm_hw_stats_read(&stats);\n\n\tattr = nla_nest_start(msg, NET_DM_ATTR_HW_STATS);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tif (nla_put_u64_64bit(msg, NET_DM_ATTR_STATS_DROPPED,\n\t\t\t      u64_stats_read(&stats.dropped), NET_DM_ATTR_PAD))\n\t\tgoto nla_put_failure;\n\n\tnla_nest_end(msg, attr);\n\n\treturn 0;\n\nnla_put_failure:\n\tnla_nest_cancel(msg, attr);\n\treturn -EMSGSIZE;\n}\n\nstatic int net_dm_stats_fill(struct sk_buff *msg, struct genl_info *info)\n{\n\tvoid *hdr;\n\tint rc;\n\n\thdr = genlmsg_put(msg, info->snd_portid, info->snd_seq,\n\t\t\t  &net_drop_monitor_family, 0, NET_DM_CMD_STATS_NEW);\n\tif (!hdr)\n\t\treturn -EMSGSIZE;\n\n\trc = net_dm_stats_put(msg);\n\tif (rc)\n\t\tgoto nla_put_failure;\n\n\trc = net_dm_hw_stats_put(msg);\n\tif (rc)\n\t\tgoto nla_put_failure;\n\n\tgenlmsg_end(msg, hdr);\n\n\treturn 0;\n\nnla_put_failure:\n\tgenlmsg_cancel(msg, hdr);\n\treturn -EMSGSIZE;\n}\n\nstatic int net_dm_cmd_stats_get(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct sk_buff *msg;\n\tint rc;\n\n\tmsg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\n\tif (!msg)\n\t\treturn -ENOMEM;\n\n\trc = net_dm_stats_fill(msg, info);\n\tif (rc)\n\t\tgoto free_msg;\n\n\treturn genlmsg_reply(msg, info);\n\nfree_msg:\n\tnlmsg_free(msg);\n\treturn rc;\n}\n\nstatic int dropmon_net_event(struct notifier_block *ev_block,\n\t\t\t     unsigned long event, void *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\tstruct dm_hw_stat_delta *stat;\n\n\tswitch (event) {\n\tcase NETDEV_REGISTER:\n\t\tif (WARN_ON_ONCE(rtnl_dereference(dev->dm_private)))\n\t\t\tbreak;\n\t\tstat = kzalloc(sizeof(*stat), GFP_KERNEL);\n\t\tif (!stat)\n\t\t\tbreak;\n\n\t\tstat->last_rx = jiffies;\n\t\trcu_assign_pointer(dev->dm_private, stat);\n\n\t\tbreak;\n\tcase NETDEV_UNREGISTER:\n\t\tstat = rtnl_dereference(dev->dm_private);\n\t\tif (stat) {\n\t\t\trcu_assign_pointer(dev->dm_private, NULL);\n\t\t\tkfree_rcu(stat, rcu);\n\t\t}\n\t\tbreak;\n\t}\n\treturn NOTIFY_DONE;\n}\n\nstatic const struct nla_policy net_dm_nl_policy[NET_DM_ATTR_MAX + 1] = {\n\t[NET_DM_ATTR_UNSPEC] = { .strict_start_type = NET_DM_ATTR_UNSPEC + 1 },\n\t[NET_DM_ATTR_ALERT_MODE] = { .type = NLA_U8 },\n\t[NET_DM_ATTR_TRUNC_LEN] = { .type = NLA_U32 },\n\t[NET_DM_ATTR_QUEUE_LEN] = { .type = NLA_U32 },\n\t[NET_DM_ATTR_SW_DROPS]\t= {. type = NLA_FLAG },\n\t[NET_DM_ATTR_HW_DROPS]\t= {. type = NLA_FLAG },\n};\n\nstatic const struct genl_small_ops dropmon_ops[] = {\n\t{\n\t\t.cmd = NET_DM_CMD_CONFIG,\n\t\t.validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t\t.doit = net_dm_cmd_config,\n\t\t.flags = GENL_ADMIN_PERM,\n\t},\n\t{\n\t\t.cmd = NET_DM_CMD_START,\n\t\t.validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t\t.doit = net_dm_cmd_trace,\n\t\t.flags = GENL_ADMIN_PERM,\n\t},\n\t{\n\t\t.cmd = NET_DM_CMD_STOP,\n\t\t.validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t\t.doit = net_dm_cmd_trace,\n\t\t.flags = GENL_ADMIN_PERM,\n\t},\n\t{\n\t\t.cmd = NET_DM_CMD_CONFIG_GET,\n\t\t.doit = net_dm_cmd_config_get,\n\t},\n\t{\n\t\t.cmd = NET_DM_CMD_STATS_GET,\n\t\t.doit = net_dm_cmd_stats_get,\n\t},\n};\n\nstatic int net_dm_nl_pre_doit(const struct genl_split_ops *ops,\n\t\t\t      struct sk_buff *skb, struct genl_info *info)\n{\n\tmutex_lock(&net_dm_mutex);\n\n\treturn 0;\n}\n\nstatic void net_dm_nl_post_doit(const struct genl_split_ops *ops,\n\t\t\t\tstruct sk_buff *skb, struct genl_info *info)\n{\n\tmutex_unlock(&net_dm_mutex);\n}\n\nstatic struct genl_family net_drop_monitor_family __ro_after_init = {\n\t.hdrsize        = 0,\n\t.name           = \"NET_DM\",\n\t.version        = 2,\n\t.maxattr\t= NET_DM_ATTR_MAX,\n\t.policy\t\t= net_dm_nl_policy,\n\t.pre_doit\t= net_dm_nl_pre_doit,\n\t.post_doit\t= net_dm_nl_post_doit,\n\t.module\t\t= THIS_MODULE,\n\t.small_ops\t= dropmon_ops,\n\t.n_small_ops\t= ARRAY_SIZE(dropmon_ops),\n\t.resv_start_op\t= NET_DM_CMD_STATS_GET + 1,\n\t.mcgrps\t\t= dropmon_mcgrps,\n\t.n_mcgrps\t= ARRAY_SIZE(dropmon_mcgrps),\n};\n\nstatic struct notifier_block dropmon_net_notifier = {\n\t.notifier_call = dropmon_net_event\n};\n\nstatic void __net_dm_cpu_data_init(struct per_cpu_dm_data *data)\n{\n\tspin_lock_init(&data->lock);\n\tskb_queue_head_init(&data->drop_queue);\n\tu64_stats_init(&data->stats.syncp);\n}\n\nstatic void __net_dm_cpu_data_fini(struct per_cpu_dm_data *data)\n{\n\tWARN_ON(!skb_queue_empty(&data->drop_queue));\n}\n\nstatic void net_dm_cpu_data_init(int cpu)\n{\n\tstruct per_cpu_dm_data *data;\n\n\tdata = &per_cpu(dm_cpu_data, cpu);\n\t__net_dm_cpu_data_init(data);\n}\n\nstatic void net_dm_cpu_data_fini(int cpu)\n{\n\tstruct per_cpu_dm_data *data;\n\n\tdata = &per_cpu(dm_cpu_data, cpu);\n\t \n\tconsume_skb(data->skb);\n\t__net_dm_cpu_data_fini(data);\n}\n\nstatic void net_dm_hw_cpu_data_init(int cpu)\n{\n\tstruct per_cpu_dm_data *hw_data;\n\n\thw_data = &per_cpu(dm_hw_cpu_data, cpu);\n\t__net_dm_cpu_data_init(hw_data);\n}\n\nstatic void net_dm_hw_cpu_data_fini(int cpu)\n{\n\tstruct per_cpu_dm_data *hw_data;\n\n\thw_data = &per_cpu(dm_hw_cpu_data, cpu);\n\tkfree(hw_data->hw_entries);\n\t__net_dm_cpu_data_fini(hw_data);\n}\n\nstatic int __init init_net_drop_monitor(void)\n{\n\tint cpu, rc;\n\n\tpr_info(\"Initializing network drop monitor service\\n\");\n\n\tif (sizeof(void *) > 8) {\n\t\tpr_err(\"Unable to store program counters on this arch, Drop monitor failed\\n\");\n\t\treturn -ENOSPC;\n\t}\n\n\trc = genl_register_family(&net_drop_monitor_family);\n\tif (rc) {\n\t\tpr_err(\"Could not create drop monitor netlink family\\n\");\n\t\treturn rc;\n\t}\n\tWARN_ON(net_drop_monitor_family.mcgrp_offset != NET_DM_GRP_ALERT);\n\n\trc = register_netdevice_notifier(&dropmon_net_notifier);\n\tif (rc < 0) {\n\t\tpr_crit(\"Failed to register netdevice notifier\\n\");\n\t\tgoto out_unreg;\n\t}\n\n\trc = 0;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tnet_dm_cpu_data_init(cpu);\n\t\tnet_dm_hw_cpu_data_init(cpu);\n\t}\n\n\tgoto out;\n\nout_unreg:\n\tgenl_unregister_family(&net_drop_monitor_family);\nout:\n\treturn rc;\n}\n\nstatic void exit_net_drop_monitor(void)\n{\n\tint cpu;\n\n\tBUG_ON(unregister_netdevice_notifier(&dropmon_net_notifier));\n\n\t \n\n\tfor_each_possible_cpu(cpu) {\n\t\tnet_dm_hw_cpu_data_fini(cpu);\n\t\tnet_dm_cpu_data_fini(cpu);\n\t}\n\n\tBUG_ON(genl_unregister_family(&net_drop_monitor_family));\n}\n\nmodule_init(init_net_drop_monitor);\nmodule_exit(exit_net_drop_monitor);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_AUTHOR(\"Neil Horman <nhorman@tuxdriver.com>\");\nMODULE_ALIAS_GENL_FAMILY(\"NET_DM\");\nMODULE_DESCRIPTION(\"Monitoring code for network dropped packet alerts\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}