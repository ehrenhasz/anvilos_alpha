{
  "module_name": "osdmap.c",
  "hash_id": "70845be95556cd9c9ba5e2625e66cdf41cbe81ee9fcc3dbc551f374a97a3b56a",
  "original_prompt": "Ingested from linux-6.6.14/net/ceph/osdmap.c",
  "human_readable_source": "\n\n#include <linux/ceph/ceph_debug.h>\n\n#include <linux/module.h>\n#include <linux/slab.h>\n\n#include <linux/ceph/libceph.h>\n#include <linux/ceph/osdmap.h>\n#include <linux/ceph/decode.h>\n#include <linux/crush/hash.h>\n#include <linux/crush/mapper.h>\n\nstatic __printf(2, 3)\nvoid osdmap_info(const struct ceph_osdmap *map, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\n\tprintk(KERN_INFO \"%s (%pU e%u): %pV\", KBUILD_MODNAME, &map->fsid,\n\t       map->epoch, &vaf);\n\n\tva_end(args);\n}\n\nchar *ceph_osdmap_state_str(char *str, int len, u32 state)\n{\n\tif (!len)\n\t\treturn str;\n\n\tif ((state & CEPH_OSD_EXISTS) && (state & CEPH_OSD_UP))\n\t\tsnprintf(str, len, \"exists, up\");\n\telse if (state & CEPH_OSD_EXISTS)\n\t\tsnprintf(str, len, \"exists\");\n\telse if (state & CEPH_OSD_UP)\n\t\tsnprintf(str, len, \"up\");\n\telse\n\t\tsnprintf(str, len, \"doesn't exist\");\n\n\treturn str;\n}\n\n \n\nstatic int calc_bits_of(unsigned int t)\n{\n\tint b = 0;\n\twhile (t) {\n\t\tt = t >> 1;\n\t\tb++;\n\t}\n\treturn b;\n}\n\n \nstatic void calc_pg_masks(struct ceph_pg_pool_info *pi)\n{\n\tpi->pg_num_mask = (1 << calc_bits_of(pi->pg_num-1)) - 1;\n\tpi->pgp_num_mask = (1 << calc_bits_of(pi->pgp_num-1)) - 1;\n}\n\n \nstatic int crush_decode_uniform_bucket(void **p, void *end,\n\t\t\t\t       struct crush_bucket_uniform *b)\n{\n\tdout(\"crush_decode_uniform_bucket %p to %p\\n\", *p, end);\n\tceph_decode_need(p, end, (1+b->h.size) * sizeof(u32), bad);\n\tb->item_weight = ceph_decode_32(p);\n\treturn 0;\nbad:\n\treturn -EINVAL;\n}\n\nstatic int crush_decode_list_bucket(void **p, void *end,\n\t\t\t\t    struct crush_bucket_list *b)\n{\n\tint j;\n\tdout(\"crush_decode_list_bucket %p to %p\\n\", *p, end);\n\tb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\n\tif (b->item_weights == NULL)\n\t\treturn -ENOMEM;\n\tb->sum_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\n\tif (b->sum_weights == NULL)\n\t\treturn -ENOMEM;\n\tceph_decode_need(p, end, 2 * b->h.size * sizeof(u32), bad);\n\tfor (j = 0; j < b->h.size; j++) {\n\t\tb->item_weights[j] = ceph_decode_32(p);\n\t\tb->sum_weights[j] = ceph_decode_32(p);\n\t}\n\treturn 0;\nbad:\n\treturn -EINVAL;\n}\n\nstatic int crush_decode_tree_bucket(void **p, void *end,\n\t\t\t\t    struct crush_bucket_tree *b)\n{\n\tint j;\n\tdout(\"crush_decode_tree_bucket %p to %p\\n\", *p, end);\n\tceph_decode_8_safe(p, end, b->num_nodes, bad);\n\tb->node_weights = kcalloc(b->num_nodes, sizeof(u32), GFP_NOFS);\n\tif (b->node_weights == NULL)\n\t\treturn -ENOMEM;\n\tceph_decode_need(p, end, b->num_nodes * sizeof(u32), bad);\n\tfor (j = 0; j < b->num_nodes; j++)\n\t\tb->node_weights[j] = ceph_decode_32(p);\n\treturn 0;\nbad:\n\treturn -EINVAL;\n}\n\nstatic int crush_decode_straw_bucket(void **p, void *end,\n\t\t\t\t     struct crush_bucket_straw *b)\n{\n\tint j;\n\tdout(\"crush_decode_straw_bucket %p to %p\\n\", *p, end);\n\tb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\n\tif (b->item_weights == NULL)\n\t\treturn -ENOMEM;\n\tb->straws = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\n\tif (b->straws == NULL)\n\t\treturn -ENOMEM;\n\tceph_decode_need(p, end, 2 * b->h.size * sizeof(u32), bad);\n\tfor (j = 0; j < b->h.size; j++) {\n\t\tb->item_weights[j] = ceph_decode_32(p);\n\t\tb->straws[j] = ceph_decode_32(p);\n\t}\n\treturn 0;\nbad:\n\treturn -EINVAL;\n}\n\nstatic int crush_decode_straw2_bucket(void **p, void *end,\n\t\t\t\t      struct crush_bucket_straw2 *b)\n{\n\tint j;\n\tdout(\"crush_decode_straw2_bucket %p to %p\\n\", *p, end);\n\tb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\n\tif (b->item_weights == NULL)\n\t\treturn -ENOMEM;\n\tceph_decode_need(p, end, b->h.size * sizeof(u32), bad);\n\tfor (j = 0; j < b->h.size; j++)\n\t\tb->item_weights[j] = ceph_decode_32(p);\n\treturn 0;\nbad:\n\treturn -EINVAL;\n}\n\nstruct crush_name_node {\n\tstruct rb_node cn_node;\n\tint cn_id;\n\tchar cn_name[];\n};\n\nstatic struct crush_name_node *alloc_crush_name(size_t name_len)\n{\n\tstruct crush_name_node *cn;\n\n\tcn = kmalloc(sizeof(*cn) + name_len + 1, GFP_NOIO);\n\tif (!cn)\n\t\treturn NULL;\n\n\tRB_CLEAR_NODE(&cn->cn_node);\n\treturn cn;\n}\n\nstatic void free_crush_name(struct crush_name_node *cn)\n{\n\tWARN_ON(!RB_EMPTY_NODE(&cn->cn_node));\n\n\tkfree(cn);\n}\n\nDEFINE_RB_FUNCS(crush_name, struct crush_name_node, cn_id, cn_node)\n\nstatic int decode_crush_names(void **p, void *end, struct rb_root *root)\n{\n\tu32 n;\n\n\tceph_decode_32_safe(p, end, n, e_inval);\n\twhile (n--) {\n\t\tstruct crush_name_node *cn;\n\t\tint id;\n\t\tu32 name_len;\n\n\t\tceph_decode_32_safe(p, end, id, e_inval);\n\t\tceph_decode_32_safe(p, end, name_len, e_inval);\n\t\tceph_decode_need(p, end, name_len, e_inval);\n\n\t\tcn = alloc_crush_name(name_len);\n\t\tif (!cn)\n\t\t\treturn -ENOMEM;\n\n\t\tcn->cn_id = id;\n\t\tmemcpy(cn->cn_name, *p, name_len);\n\t\tcn->cn_name[name_len] = '\\0';\n\t\t*p += name_len;\n\n\t\tif (!__insert_crush_name(root, cn)) {\n\t\t\tfree_crush_name(cn);\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\treturn 0;\n\ne_inval:\n\treturn -EINVAL;\n}\n\nvoid clear_crush_names(struct rb_root *root)\n{\n\twhile (!RB_EMPTY_ROOT(root)) {\n\t\tstruct crush_name_node *cn =\n\t\t    rb_entry(rb_first(root), struct crush_name_node, cn_node);\n\n\t\terase_crush_name(root, cn);\n\t\tfree_crush_name(cn);\n\t}\n}\n\nstatic struct crush_choose_arg_map *alloc_choose_arg_map(void)\n{\n\tstruct crush_choose_arg_map *arg_map;\n\n\targ_map = kzalloc(sizeof(*arg_map), GFP_NOIO);\n\tif (!arg_map)\n\t\treturn NULL;\n\n\tRB_CLEAR_NODE(&arg_map->node);\n\treturn arg_map;\n}\n\nstatic void free_choose_arg_map(struct crush_choose_arg_map *arg_map)\n{\n\tif (arg_map) {\n\t\tint i, j;\n\n\t\tWARN_ON(!RB_EMPTY_NODE(&arg_map->node));\n\n\t\tfor (i = 0; i < arg_map->size; i++) {\n\t\t\tstruct crush_choose_arg *arg = &arg_map->args[i];\n\n\t\t\tfor (j = 0; j < arg->weight_set_size; j++)\n\t\t\t\tkfree(arg->weight_set[j].weights);\n\t\t\tkfree(arg->weight_set);\n\t\t\tkfree(arg->ids);\n\t\t}\n\t\tkfree(arg_map->args);\n\t\tkfree(arg_map);\n\t}\n}\n\nDEFINE_RB_FUNCS(choose_arg_map, struct crush_choose_arg_map, choose_args_index,\n\t\tnode);\n\nvoid clear_choose_args(struct crush_map *c)\n{\n\twhile (!RB_EMPTY_ROOT(&c->choose_args)) {\n\t\tstruct crush_choose_arg_map *arg_map =\n\t\t    rb_entry(rb_first(&c->choose_args),\n\t\t\t     struct crush_choose_arg_map, node);\n\n\t\terase_choose_arg_map(&c->choose_args, arg_map);\n\t\tfree_choose_arg_map(arg_map);\n\t}\n}\n\nstatic u32 *decode_array_32_alloc(void **p, void *end, u32 *plen)\n{\n\tu32 *a = NULL;\n\tu32 len;\n\tint ret;\n\n\tceph_decode_32_safe(p, end, len, e_inval);\n\tif (len) {\n\t\tu32 i;\n\n\t\ta = kmalloc_array(len, sizeof(u32), GFP_NOIO);\n\t\tif (!a) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tceph_decode_need(p, end, len * sizeof(u32), e_inval);\n\t\tfor (i = 0; i < len; i++)\n\t\t\ta[i] = ceph_decode_32(p);\n\t}\n\n\t*plen = len;\n\treturn a;\n\ne_inval:\n\tret = -EINVAL;\nfail:\n\tkfree(a);\n\treturn ERR_PTR(ret);\n}\n\n \nstatic int decode_choose_arg(void **p, void *end, struct crush_choose_arg *arg)\n{\n\tint ret;\n\n\tceph_decode_32_safe(p, end, arg->weight_set_size, e_inval);\n\tif (arg->weight_set_size) {\n\t\tu32 i;\n\n\t\targ->weight_set = kmalloc_array(arg->weight_set_size,\n\t\t\t\t\t\tsizeof(*arg->weight_set),\n\t\t\t\t\t\tGFP_NOIO);\n\t\tif (!arg->weight_set)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < arg->weight_set_size; i++) {\n\t\t\tstruct crush_weight_set *w = &arg->weight_set[i];\n\n\t\t\tw->weights = decode_array_32_alloc(p, end, &w->size);\n\t\t\tif (IS_ERR(w->weights)) {\n\t\t\t\tret = PTR_ERR(w->weights);\n\t\t\t\tw->weights = NULL;\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\targ->ids = decode_array_32_alloc(p, end, &arg->ids_size);\n\tif (IS_ERR(arg->ids)) {\n\t\tret = PTR_ERR(arg->ids);\n\t\targ->ids = NULL;\n\t\treturn ret;\n\t}\n\n\treturn 0;\n\ne_inval:\n\treturn -EINVAL;\n}\n\nstatic int decode_choose_args(void **p, void *end, struct crush_map *c)\n{\n\tstruct crush_choose_arg_map *arg_map = NULL;\n\tu32 num_choose_arg_maps, num_buckets;\n\tint ret;\n\n\tceph_decode_32_safe(p, end, num_choose_arg_maps, e_inval);\n\twhile (num_choose_arg_maps--) {\n\t\targ_map = alloc_choose_arg_map();\n\t\tif (!arg_map) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tceph_decode_64_safe(p, end, arg_map->choose_args_index,\n\t\t\t\t    e_inval);\n\t\targ_map->size = c->max_buckets;\n\t\targ_map->args = kcalloc(arg_map->size, sizeof(*arg_map->args),\n\t\t\t\t\tGFP_NOIO);\n\t\tif (!arg_map->args) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tceph_decode_32_safe(p, end, num_buckets, e_inval);\n\t\twhile (num_buckets--) {\n\t\t\tstruct crush_choose_arg *arg;\n\t\t\tu32 bucket_index;\n\n\t\t\tceph_decode_32_safe(p, end, bucket_index, e_inval);\n\t\t\tif (bucket_index >= arg_map->size)\n\t\t\t\tgoto e_inval;\n\n\t\t\targ = &arg_map->args[bucket_index];\n\t\t\tret = decode_choose_arg(p, end, arg);\n\t\t\tif (ret)\n\t\t\t\tgoto fail;\n\n\t\t\tif (arg->ids_size &&\n\t\t\t    arg->ids_size != c->buckets[bucket_index]->size)\n\t\t\t\tgoto e_inval;\n\t\t}\n\n\t\tinsert_choose_arg_map(&c->choose_args, arg_map);\n\t}\n\n\treturn 0;\n\ne_inval:\n\tret = -EINVAL;\nfail:\n\tfree_choose_arg_map(arg_map);\n\treturn ret;\n}\n\nstatic void crush_finalize(struct crush_map *c)\n{\n\t__s32 b;\n\n\t \n\tc->working_size = sizeof(struct crush_work) +\n\t    c->max_buckets * sizeof(struct crush_work_bucket *);\n\n\tfor (b = 0; b < c->max_buckets; b++) {\n\t\tif (!c->buckets[b])\n\t\t\tcontinue;\n\n\t\tswitch (c->buckets[b]->alg) {\n\t\tdefault:\n\t\t\t \n\t\t\tc->working_size += sizeof(struct crush_work_bucket);\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tc->working_size += c->buckets[b]->size * sizeof(__u32);\n\t}\n}\n\nstatic struct crush_map *crush_decode(void *pbyval, void *end)\n{\n\tstruct crush_map *c;\n\tint err;\n\tint i, j;\n\tvoid **p = &pbyval;\n\tvoid *start = pbyval;\n\tu32 magic;\n\n\tdout(\"crush_decode %p to %p len %d\\n\", *p, end, (int)(end - *p));\n\n\tc = kzalloc(sizeof(*c), GFP_NOFS);\n\tif (c == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tc->type_names = RB_ROOT;\n\tc->names = RB_ROOT;\n\tc->choose_args = RB_ROOT;\n\n         \n        c->choose_local_tries = 2;\n        c->choose_local_fallback_tries = 5;\n        c->choose_total_tries = 19;\n\tc->chooseleaf_descend_once = 0;\n\n\tceph_decode_need(p, end, 4*sizeof(u32), bad);\n\tmagic = ceph_decode_32(p);\n\tif (magic != CRUSH_MAGIC) {\n\t\tpr_err(\"crush_decode magic %x != current %x\\n\",\n\t\t       (unsigned int)magic, (unsigned int)CRUSH_MAGIC);\n\t\tgoto bad;\n\t}\n\tc->max_buckets = ceph_decode_32(p);\n\tc->max_rules = ceph_decode_32(p);\n\tc->max_devices = ceph_decode_32(p);\n\n\tc->buckets = kcalloc(c->max_buckets, sizeof(*c->buckets), GFP_NOFS);\n\tif (c->buckets == NULL)\n\t\tgoto badmem;\n\tc->rules = kcalloc(c->max_rules, sizeof(*c->rules), GFP_NOFS);\n\tif (c->rules == NULL)\n\t\tgoto badmem;\n\n\t \n\tfor (i = 0; i < c->max_buckets; i++) {\n\t\tint size = 0;\n\t\tu32 alg;\n\t\tstruct crush_bucket *b;\n\n\t\tceph_decode_32_safe(p, end, alg, bad);\n\t\tif (alg == 0) {\n\t\t\tc->buckets[i] = NULL;\n\t\t\tcontinue;\n\t\t}\n\t\tdout(\"crush_decode bucket %d off %x %p to %p\\n\",\n\t\t     i, (int)(*p-start), *p, end);\n\n\t\tswitch (alg) {\n\t\tcase CRUSH_BUCKET_UNIFORM:\n\t\t\tsize = sizeof(struct crush_bucket_uniform);\n\t\t\tbreak;\n\t\tcase CRUSH_BUCKET_LIST:\n\t\t\tsize = sizeof(struct crush_bucket_list);\n\t\t\tbreak;\n\t\tcase CRUSH_BUCKET_TREE:\n\t\t\tsize = sizeof(struct crush_bucket_tree);\n\t\t\tbreak;\n\t\tcase CRUSH_BUCKET_STRAW:\n\t\t\tsize = sizeof(struct crush_bucket_straw);\n\t\t\tbreak;\n\t\tcase CRUSH_BUCKET_STRAW2:\n\t\t\tsize = sizeof(struct crush_bucket_straw2);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto bad;\n\t\t}\n\t\tBUG_ON(size == 0);\n\t\tb = c->buckets[i] = kzalloc(size, GFP_NOFS);\n\t\tif (b == NULL)\n\t\t\tgoto badmem;\n\n\t\tceph_decode_need(p, end, 4*sizeof(u32), bad);\n\t\tb->id = ceph_decode_32(p);\n\t\tb->type = ceph_decode_16(p);\n\t\tb->alg = ceph_decode_8(p);\n\t\tb->hash = ceph_decode_8(p);\n\t\tb->weight = ceph_decode_32(p);\n\t\tb->size = ceph_decode_32(p);\n\n\t\tdout(\"crush_decode bucket size %d off %x %p to %p\\n\",\n\t\t     b->size, (int)(*p-start), *p, end);\n\n\t\tb->items = kcalloc(b->size, sizeof(__s32), GFP_NOFS);\n\t\tif (b->items == NULL)\n\t\t\tgoto badmem;\n\n\t\tceph_decode_need(p, end, b->size*sizeof(u32), bad);\n\t\tfor (j = 0; j < b->size; j++)\n\t\t\tb->items[j] = ceph_decode_32(p);\n\n\t\tswitch (b->alg) {\n\t\tcase CRUSH_BUCKET_UNIFORM:\n\t\t\terr = crush_decode_uniform_bucket(p, end,\n\t\t\t\t  (struct crush_bucket_uniform *)b);\n\t\t\tif (err < 0)\n\t\t\t\tgoto fail;\n\t\t\tbreak;\n\t\tcase CRUSH_BUCKET_LIST:\n\t\t\terr = crush_decode_list_bucket(p, end,\n\t\t\t       (struct crush_bucket_list *)b);\n\t\t\tif (err < 0)\n\t\t\t\tgoto fail;\n\t\t\tbreak;\n\t\tcase CRUSH_BUCKET_TREE:\n\t\t\terr = crush_decode_tree_bucket(p, end,\n\t\t\t\t(struct crush_bucket_tree *)b);\n\t\t\tif (err < 0)\n\t\t\t\tgoto fail;\n\t\t\tbreak;\n\t\tcase CRUSH_BUCKET_STRAW:\n\t\t\terr = crush_decode_straw_bucket(p, end,\n\t\t\t\t(struct crush_bucket_straw *)b);\n\t\t\tif (err < 0)\n\t\t\t\tgoto fail;\n\t\t\tbreak;\n\t\tcase CRUSH_BUCKET_STRAW2:\n\t\t\terr = crush_decode_straw2_bucket(p, end,\n\t\t\t\t(struct crush_bucket_straw2 *)b);\n\t\t\tif (err < 0)\n\t\t\t\tgoto fail;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tdout(\"rule vec is %p\\n\", c->rules);\n\tfor (i = 0; i < c->max_rules; i++) {\n\t\tu32 yes;\n\t\tstruct crush_rule *r;\n\n\t\tceph_decode_32_safe(p, end, yes, bad);\n\t\tif (!yes) {\n\t\t\tdout(\"crush_decode NO rule %d off %x %p to %p\\n\",\n\t\t\t     i, (int)(*p-start), *p, end);\n\t\t\tc->rules[i] = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tdout(\"crush_decode rule %d off %x %p to %p\\n\",\n\t\t     i, (int)(*p-start), *p, end);\n\n\t\t \n\t\tceph_decode_32_safe(p, end, yes, bad);\n#if BITS_PER_LONG == 32\n\t\tif (yes > (ULONG_MAX - sizeof(*r))\n\t\t\t  / sizeof(struct crush_rule_step))\n\t\t\tgoto bad;\n#endif\n\t\tr = kmalloc(struct_size(r, steps, yes), GFP_NOFS);\n\t\tif (r == NULL)\n\t\t\tgoto badmem;\n\t\tdout(\" rule %d is at %p\\n\", i, r);\n\t\tc->rules[i] = r;\n\t\tr->len = yes;\n\t\tceph_decode_copy_safe(p, end, &r->mask, 4, bad);  \n\t\tceph_decode_need(p, end, r->len*3*sizeof(u32), bad);\n\t\tfor (j = 0; j < r->len; j++) {\n\t\t\tr->steps[j].op = ceph_decode_32(p);\n\t\t\tr->steps[j].arg1 = ceph_decode_32(p);\n\t\t\tr->steps[j].arg2 = ceph_decode_32(p);\n\t\t}\n\t}\n\n\terr = decode_crush_names(p, end, &c->type_names);\n\tif (err)\n\t\tgoto fail;\n\n\terr = decode_crush_names(p, end, &c->names);\n\tif (err)\n\t\tgoto fail;\n\n\tceph_decode_skip_map(p, end, 32, string, bad);  \n\n         \n        ceph_decode_need(p, end, 3*sizeof(u32), done);\n        c->choose_local_tries = ceph_decode_32(p);\n        c->choose_local_fallback_tries =  ceph_decode_32(p);\n        c->choose_total_tries = ceph_decode_32(p);\n        dout(\"crush decode tunable choose_local_tries = %d\\n\",\n             c->choose_local_tries);\n        dout(\"crush decode tunable choose_local_fallback_tries = %d\\n\",\n             c->choose_local_fallback_tries);\n        dout(\"crush decode tunable choose_total_tries = %d\\n\",\n             c->choose_total_tries);\n\n\tceph_decode_need(p, end, sizeof(u32), done);\n\tc->chooseleaf_descend_once = ceph_decode_32(p);\n\tdout(\"crush decode tunable chooseleaf_descend_once = %d\\n\",\n\t     c->chooseleaf_descend_once);\n\n\tceph_decode_need(p, end, sizeof(u8), done);\n\tc->chooseleaf_vary_r = ceph_decode_8(p);\n\tdout(\"crush decode tunable chooseleaf_vary_r = %d\\n\",\n\t     c->chooseleaf_vary_r);\n\n\t \n\tceph_decode_need(p, end, sizeof(u8) + sizeof(u32), done);\n\t*p += sizeof(u8) + sizeof(u32);\n\n\tceph_decode_need(p, end, sizeof(u8), done);\n\tc->chooseleaf_stable = ceph_decode_8(p);\n\tdout(\"crush decode tunable chooseleaf_stable = %d\\n\",\n\t     c->chooseleaf_stable);\n\n\tif (*p != end) {\n\t\t \n\t\tceph_decode_skip_map(p, end, 32, 32, bad);\n\t\t \n\t\tceph_decode_skip_map(p, end, 32, string, bad);\n\t\t \n\t\tceph_decode_skip_map_of_map(p, end, 32, 32, 32, bad);\n\t}\n\n\tif (*p != end) {\n\t\terr = decode_choose_args(p, end, c);\n\t\tif (err)\n\t\t\tgoto fail;\n\t}\n\ndone:\n\tcrush_finalize(c);\n\tdout(\"crush_decode success\\n\");\n\treturn c;\n\nbadmem:\n\terr = -ENOMEM;\nfail:\n\tdout(\"crush_decode fail %d\\n\", err);\n\tcrush_destroy(c);\n\treturn ERR_PTR(err);\n\nbad:\n\terr = -EINVAL;\n\tgoto fail;\n}\n\nint ceph_pg_compare(const struct ceph_pg *lhs, const struct ceph_pg *rhs)\n{\n\tif (lhs->pool < rhs->pool)\n\t\treturn -1;\n\tif (lhs->pool > rhs->pool)\n\t\treturn 1;\n\tif (lhs->seed < rhs->seed)\n\t\treturn -1;\n\tif (lhs->seed > rhs->seed)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nint ceph_spg_compare(const struct ceph_spg *lhs, const struct ceph_spg *rhs)\n{\n\tint ret;\n\n\tret = ceph_pg_compare(&lhs->pgid, &rhs->pgid);\n\tif (ret)\n\t\treturn ret;\n\n\tif (lhs->shard < rhs->shard)\n\t\treturn -1;\n\tif (lhs->shard > rhs->shard)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic struct ceph_pg_mapping *alloc_pg_mapping(size_t payload_len)\n{\n\tstruct ceph_pg_mapping *pg;\n\n\tpg = kmalloc(sizeof(*pg) + payload_len, GFP_NOIO);\n\tif (!pg)\n\t\treturn NULL;\n\n\tRB_CLEAR_NODE(&pg->node);\n\treturn pg;\n}\n\nstatic void free_pg_mapping(struct ceph_pg_mapping *pg)\n{\n\tWARN_ON(!RB_EMPTY_NODE(&pg->node));\n\n\tkfree(pg);\n}\n\n \nDEFINE_RB_FUNCS2(pg_mapping, struct ceph_pg_mapping, pgid, ceph_pg_compare,\n\t\t RB_BYPTR, const struct ceph_pg *, node)\n\n \nDEFINE_RB_FUNCS(pg_pool, struct ceph_pg_pool_info, id, node)\n\nstruct ceph_pg_pool_info *ceph_pg_pool_by_id(struct ceph_osdmap *map, u64 id)\n{\n\treturn lookup_pg_pool(&map->pg_pools, id);\n}\n\nconst char *ceph_pg_pool_name_by_id(struct ceph_osdmap *map, u64 id)\n{\n\tstruct ceph_pg_pool_info *pi;\n\n\tif (id == CEPH_NOPOOL)\n\t\treturn NULL;\n\n\tif (WARN_ON_ONCE(id > (u64) INT_MAX))\n\t\treturn NULL;\n\n\tpi = lookup_pg_pool(&map->pg_pools, id);\n\treturn pi ? pi->name : NULL;\n}\nEXPORT_SYMBOL(ceph_pg_pool_name_by_id);\n\nint ceph_pg_poolid_by_name(struct ceph_osdmap *map, const char *name)\n{\n\tstruct rb_node *rbp;\n\n\tfor (rbp = rb_first(&map->pg_pools); rbp; rbp = rb_next(rbp)) {\n\t\tstruct ceph_pg_pool_info *pi =\n\t\t\trb_entry(rbp, struct ceph_pg_pool_info, node);\n\t\tif (pi->name && strcmp(pi->name, name) == 0)\n\t\t\treturn pi->id;\n\t}\n\treturn -ENOENT;\n}\nEXPORT_SYMBOL(ceph_pg_poolid_by_name);\n\nu64 ceph_pg_pool_flags(struct ceph_osdmap *map, u64 id)\n{\n\tstruct ceph_pg_pool_info *pi;\n\n\tpi = lookup_pg_pool(&map->pg_pools, id);\n\treturn pi ? pi->flags : 0;\n}\nEXPORT_SYMBOL(ceph_pg_pool_flags);\n\nstatic void __remove_pg_pool(struct rb_root *root, struct ceph_pg_pool_info *pi)\n{\n\terase_pg_pool(root, pi);\n\tkfree(pi->name);\n\tkfree(pi);\n}\n\nstatic int decode_pool(void **p, void *end, struct ceph_pg_pool_info *pi)\n{\n\tu8 ev, cv;\n\tunsigned len, num;\n\tvoid *pool_end;\n\n\tceph_decode_need(p, end, 2 + 4, bad);\n\tev = ceph_decode_8(p);   \n\tcv = ceph_decode_8(p);  \n\tif (ev < 5) {\n\t\tpr_warn(\"got v %d < 5 cv %d of ceph_pg_pool\\n\", ev, cv);\n\t\treturn -EINVAL;\n\t}\n\tif (cv > 9) {\n\t\tpr_warn(\"got v %d cv %d > 9 of ceph_pg_pool\\n\", ev, cv);\n\t\treturn -EINVAL;\n\t}\n\tlen = ceph_decode_32(p);\n\tceph_decode_need(p, end, len, bad);\n\tpool_end = *p + len;\n\n\tpi->type = ceph_decode_8(p);\n\tpi->size = ceph_decode_8(p);\n\tpi->crush_ruleset = ceph_decode_8(p);\n\tpi->object_hash = ceph_decode_8(p);\n\n\tpi->pg_num = ceph_decode_32(p);\n\tpi->pgp_num = ceph_decode_32(p);\n\n\t*p += 4 + 4;   \n\t*p += 4;       \n\t*p += 8 + 4;   \n\n\t \n\tnum = ceph_decode_32(p);\n\twhile (num--) {\n\t\t*p += 8;   \n\t\t*p += 1 + 1;  \n\t\tlen = ceph_decode_32(p);\n\t\t*p += len;\n\t}\n\n\t \n\tnum = ceph_decode_32(p);\n\t*p += num * (8 + 8);\n\n\t*p += 8;   \n\tpi->flags = ceph_decode_64(p);\n\t*p += 4;   \n\n\tif (ev >= 7)\n\t\tpi->min_size = ceph_decode_8(p);\n\telse\n\t\tpi->min_size = pi->size - pi->size / 2;\n\n\tif (ev >= 8)\n\t\t*p += 8 + 8;   \n\n\tif (ev >= 9) {\n\t\t \n\t\tnum = ceph_decode_32(p);\n\t\t*p += num * 8;\n\n\t\t*p += 8;   \n\t\t*p += 1;   \n\n\t\tpi->read_tier = ceph_decode_64(p);\n\t\tpi->write_tier = ceph_decode_64(p);\n\t} else {\n\t\tpi->read_tier = -1;\n\t\tpi->write_tier = -1;\n\t}\n\n\tif (ev >= 10) {\n\t\t \n\t\tnum = ceph_decode_32(p);\n\t\twhile (num--) {\n\t\t\tlen = ceph_decode_32(p);\n\t\t\t*p += len;  \n\t\t\tlen = ceph_decode_32(p);\n\t\t\t*p += len;  \n\t\t}\n\t}\n\n\tif (ev >= 11) {\n\t\t \n\t\t*p += 1 + 1;  \n\t\tlen = ceph_decode_32(p);\n\t\t*p += len;\n\n\t\t*p += 4;  \n\t\t*p += 4;  \n\t}\n\n\tif (ev >= 12)\n\t\t*p += 4;  \n\n\tif (ev >= 13) {\n\t\t*p += 8;  \n\t\t*p += 8;  \n\t\t*p += 4;  \n\t\t*p += 4;  \n\t\t*p += 4;  \n\t\t*p += 4;  \n\t}\n\n\tif (ev >=  14) {\n\t\t \n\t\tlen = ceph_decode_32(p);\n\t\t*p += len;\n\t}\n\n\t \n\tif (ev >= 15)\n\t\tpi->last_force_request_resend = ceph_decode_32(p);\n\telse\n\t\tpi->last_force_request_resend = 0;\n\n\tif (ev >= 16)\n\t\t*p += 4;  \n\n\tif (ev >= 17)\n\t\t*p += 8;  \n\n\tif (ev >= 19)\n\t\t*p += 4;  \n\n\tif (ev >= 20)\n\t\t*p += 4;  \n\n\tif (ev >= 21)\n\t\t*p += 1;  \n\n\tif (ev >= 22)\n\t\t*p += 1;  \n\n\tif (ev >= 23) {\n\t\t*p += 4;  \n\t\t*p += 4;  \n\t}\n\n\tif (ev >= 24) {\n\t\t \n\t\t*p += 1 + 1;  \n\t\tlen = ceph_decode_32(p);\n\t\t*p += len;\n\t}\n\n\tif (ev >= 25)\n\t\tpi->last_force_request_resend = ceph_decode_32(p);\n\n\t \n\n\t*p = pool_end;\n\tcalc_pg_masks(pi);\n\treturn 0;\n\nbad:\n\treturn -EINVAL;\n}\n\nstatic int decode_pool_names(void **p, void *end, struct ceph_osdmap *map)\n{\n\tstruct ceph_pg_pool_info *pi;\n\tu32 num, len;\n\tu64 pool;\n\n\tceph_decode_32_safe(p, end, num, bad);\n\tdout(\" %d pool names\\n\", num);\n\twhile (num--) {\n\t\tceph_decode_64_safe(p, end, pool, bad);\n\t\tceph_decode_32_safe(p, end, len, bad);\n\t\tdout(\"  pool %llu len %d\\n\", pool, len);\n\t\tceph_decode_need(p, end, len, bad);\n\t\tpi = lookup_pg_pool(&map->pg_pools, pool);\n\t\tif (pi) {\n\t\t\tchar *name = kstrndup(*p, len, GFP_NOFS);\n\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\t\t\tkfree(pi->name);\n\t\t\tpi->name = name;\n\t\t\tdout(\"  name is %s\\n\", pi->name);\n\t\t}\n\t\t*p += len;\n\t}\n\treturn 0;\n\nbad:\n\treturn -EINVAL;\n}\n\n \nstatic struct crush_work *alloc_workspace(const struct crush_map *c)\n{\n\tstruct crush_work *work;\n\tsize_t work_size;\n\n\tWARN_ON(!c->working_size);\n\twork_size = crush_work_size(c, CEPH_PG_MAX_SIZE);\n\tdout(\"%s work_size %zu bytes\\n\", __func__, work_size);\n\n\twork = kvmalloc(work_size, GFP_NOIO);\n\tif (!work)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&work->item);\n\tcrush_init_workspace(c, work);\n\treturn work;\n}\n\nstatic void free_workspace(struct crush_work *work)\n{\n\tWARN_ON(!list_empty(&work->item));\n\tkvfree(work);\n}\n\nstatic void init_workspace_manager(struct workspace_manager *wsm)\n{\n\tINIT_LIST_HEAD(&wsm->idle_ws);\n\tspin_lock_init(&wsm->ws_lock);\n\tatomic_set(&wsm->total_ws, 0);\n\twsm->free_ws = 0;\n\tinit_waitqueue_head(&wsm->ws_wait);\n}\n\nstatic void add_initial_workspace(struct workspace_manager *wsm,\n\t\t\t\t  struct crush_work *work)\n{\n\tWARN_ON(!list_empty(&wsm->idle_ws));\n\n\tlist_add(&work->item, &wsm->idle_ws);\n\tatomic_set(&wsm->total_ws, 1);\n\twsm->free_ws = 1;\n}\n\nstatic void cleanup_workspace_manager(struct workspace_manager *wsm)\n{\n\tstruct crush_work *work;\n\n\twhile (!list_empty(&wsm->idle_ws)) {\n\t\twork = list_first_entry(&wsm->idle_ws, struct crush_work,\n\t\t\t\t\titem);\n\t\tlist_del_init(&work->item);\n\t\tfree_workspace(work);\n\t}\n\tatomic_set(&wsm->total_ws, 0);\n\twsm->free_ws = 0;\n}\n\n \nstatic struct crush_work *get_workspace(struct workspace_manager *wsm,\n\t\t\t\t\tconst struct crush_map *c)\n{\n\tstruct crush_work *work;\n\tint cpus = num_online_cpus();\n\nagain:\n\tspin_lock(&wsm->ws_lock);\n\tif (!list_empty(&wsm->idle_ws)) {\n\t\twork = list_first_entry(&wsm->idle_ws, struct crush_work,\n\t\t\t\t\titem);\n\t\tlist_del_init(&work->item);\n\t\twsm->free_ws--;\n\t\tspin_unlock(&wsm->ws_lock);\n\t\treturn work;\n\n\t}\n\tif (atomic_read(&wsm->total_ws) > cpus) {\n\t\tDEFINE_WAIT(wait);\n\n\t\tspin_unlock(&wsm->ws_lock);\n\t\tprepare_to_wait(&wsm->ws_wait, &wait, TASK_UNINTERRUPTIBLE);\n\t\tif (atomic_read(&wsm->total_ws) > cpus && !wsm->free_ws)\n\t\t\tschedule();\n\t\tfinish_wait(&wsm->ws_wait, &wait);\n\t\tgoto again;\n\t}\n\tatomic_inc(&wsm->total_ws);\n\tspin_unlock(&wsm->ws_lock);\n\n\twork = alloc_workspace(c);\n\tif (!work) {\n\t\tatomic_dec(&wsm->total_ws);\n\t\twake_up(&wsm->ws_wait);\n\n\t\t \n\t\tWARN_ON(atomic_read(&wsm->total_ws) < 1);\n\t\tgoto again;\n\t}\n\treturn work;\n}\n\n \nstatic void put_workspace(struct workspace_manager *wsm,\n\t\t\t  struct crush_work *work)\n{\n\tspin_lock(&wsm->ws_lock);\n\tif (wsm->free_ws <= num_online_cpus()) {\n\t\tlist_add(&work->item, &wsm->idle_ws);\n\t\twsm->free_ws++;\n\t\tspin_unlock(&wsm->ws_lock);\n\t\tgoto wake;\n\t}\n\tspin_unlock(&wsm->ws_lock);\n\n\tfree_workspace(work);\n\tatomic_dec(&wsm->total_ws);\nwake:\n\tif (wq_has_sleeper(&wsm->ws_wait))\n\t\twake_up(&wsm->ws_wait);\n}\n\n \nstruct ceph_osdmap *ceph_osdmap_alloc(void)\n{\n\tstruct ceph_osdmap *map;\n\n\tmap = kzalloc(sizeof(*map), GFP_NOIO);\n\tif (!map)\n\t\treturn NULL;\n\n\tmap->pg_pools = RB_ROOT;\n\tmap->pool_max = -1;\n\tmap->pg_temp = RB_ROOT;\n\tmap->primary_temp = RB_ROOT;\n\tmap->pg_upmap = RB_ROOT;\n\tmap->pg_upmap_items = RB_ROOT;\n\n\tinit_workspace_manager(&map->crush_wsm);\n\n\treturn map;\n}\n\nvoid ceph_osdmap_destroy(struct ceph_osdmap *map)\n{\n\tdout(\"osdmap_destroy %p\\n\", map);\n\n\tif (map->crush)\n\t\tcrush_destroy(map->crush);\n\tcleanup_workspace_manager(&map->crush_wsm);\n\n\twhile (!RB_EMPTY_ROOT(&map->pg_temp)) {\n\t\tstruct ceph_pg_mapping *pg =\n\t\t\trb_entry(rb_first(&map->pg_temp),\n\t\t\t\t struct ceph_pg_mapping, node);\n\t\terase_pg_mapping(&map->pg_temp, pg);\n\t\tfree_pg_mapping(pg);\n\t}\n\twhile (!RB_EMPTY_ROOT(&map->primary_temp)) {\n\t\tstruct ceph_pg_mapping *pg =\n\t\t\trb_entry(rb_first(&map->primary_temp),\n\t\t\t\t struct ceph_pg_mapping, node);\n\t\terase_pg_mapping(&map->primary_temp, pg);\n\t\tfree_pg_mapping(pg);\n\t}\n\twhile (!RB_EMPTY_ROOT(&map->pg_upmap)) {\n\t\tstruct ceph_pg_mapping *pg =\n\t\t\trb_entry(rb_first(&map->pg_upmap),\n\t\t\t\t struct ceph_pg_mapping, node);\n\t\trb_erase(&pg->node, &map->pg_upmap);\n\t\tkfree(pg);\n\t}\n\twhile (!RB_EMPTY_ROOT(&map->pg_upmap_items)) {\n\t\tstruct ceph_pg_mapping *pg =\n\t\t\trb_entry(rb_first(&map->pg_upmap_items),\n\t\t\t\t struct ceph_pg_mapping, node);\n\t\trb_erase(&pg->node, &map->pg_upmap_items);\n\t\tkfree(pg);\n\t}\n\twhile (!RB_EMPTY_ROOT(&map->pg_pools)) {\n\t\tstruct ceph_pg_pool_info *pi =\n\t\t\trb_entry(rb_first(&map->pg_pools),\n\t\t\t\t struct ceph_pg_pool_info, node);\n\t\t__remove_pg_pool(&map->pg_pools, pi);\n\t}\n\tkvfree(map->osd_state);\n\tkvfree(map->osd_weight);\n\tkvfree(map->osd_addr);\n\tkvfree(map->osd_primary_affinity);\n\tkfree(map);\n}\n\n \nstatic int osdmap_set_max_osd(struct ceph_osdmap *map, u32 max)\n{\n\tu32 *state;\n\tu32 *weight;\n\tstruct ceph_entity_addr *addr;\n\tu32 to_copy;\n\tint i;\n\n\tdout(\"%s old %u new %u\\n\", __func__, map->max_osd, max);\n\tif (max == map->max_osd)\n\t\treturn 0;\n\n\tstate = kvmalloc(array_size(max, sizeof(*state)), GFP_NOFS);\n\tweight = kvmalloc(array_size(max, sizeof(*weight)), GFP_NOFS);\n\taddr = kvmalloc(array_size(max, sizeof(*addr)), GFP_NOFS);\n\tif (!state || !weight || !addr) {\n\t\tkvfree(state);\n\t\tkvfree(weight);\n\t\tkvfree(addr);\n\t\treturn -ENOMEM;\n\t}\n\n\tto_copy = min(map->max_osd, max);\n\tif (map->osd_state) {\n\t\tmemcpy(state, map->osd_state, to_copy * sizeof(*state));\n\t\tmemcpy(weight, map->osd_weight, to_copy * sizeof(*weight));\n\t\tmemcpy(addr, map->osd_addr, to_copy * sizeof(*addr));\n\t\tkvfree(map->osd_state);\n\t\tkvfree(map->osd_weight);\n\t\tkvfree(map->osd_addr);\n\t}\n\n\tmap->osd_state = state;\n\tmap->osd_weight = weight;\n\tmap->osd_addr = addr;\n\tfor (i = map->max_osd; i < max; i++) {\n\t\tmap->osd_state[i] = 0;\n\t\tmap->osd_weight[i] = CEPH_OSD_OUT;\n\t\tmemset(map->osd_addr + i, 0, sizeof(*map->osd_addr));\n\t}\n\n\tif (map->osd_primary_affinity) {\n\t\tu32 *affinity;\n\n\t\taffinity = kvmalloc(array_size(max, sizeof(*affinity)),\n\t\t\t\t\t GFP_NOFS);\n\t\tif (!affinity)\n\t\t\treturn -ENOMEM;\n\n\t\tmemcpy(affinity, map->osd_primary_affinity,\n\t\t       to_copy * sizeof(*affinity));\n\t\tkvfree(map->osd_primary_affinity);\n\n\t\tmap->osd_primary_affinity = affinity;\n\t\tfor (i = map->max_osd; i < max; i++)\n\t\t\tmap->osd_primary_affinity[i] =\n\t\t\t    CEPH_OSD_DEFAULT_PRIMARY_AFFINITY;\n\t}\n\n\tmap->max_osd = max;\n\n\treturn 0;\n}\n\nstatic int osdmap_set_crush(struct ceph_osdmap *map, struct crush_map *crush)\n{\n\tstruct crush_work *work;\n\n\tif (IS_ERR(crush))\n\t\treturn PTR_ERR(crush);\n\n\twork = alloc_workspace(crush);\n\tif (!work) {\n\t\tcrush_destroy(crush);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (map->crush)\n\t\tcrush_destroy(map->crush);\n\tcleanup_workspace_manager(&map->crush_wsm);\n\tmap->crush = crush;\n\tadd_initial_workspace(&map->crush_wsm, work);\n\treturn 0;\n}\n\n#define OSDMAP_WRAPPER_COMPAT_VER\t7\n#define OSDMAP_CLIENT_DATA_COMPAT_VER\t1\n\n \nstatic int get_osdmap_client_data_v(void **p, void *end,\n\t\t\t\t    const char *prefix, u8 *v)\n{\n\tu8 struct_v;\n\n\tceph_decode_8_safe(p, end, struct_v, e_inval);\n\tif (struct_v >= 7) {\n\t\tu8 struct_compat;\n\n\t\tceph_decode_8_safe(p, end, struct_compat, e_inval);\n\t\tif (struct_compat > OSDMAP_WRAPPER_COMPAT_VER) {\n\t\t\tpr_warn(\"got v %d cv %d > %d of %s ceph_osdmap\\n\",\n\t\t\t\tstruct_v, struct_compat,\n\t\t\t\tOSDMAP_WRAPPER_COMPAT_VER, prefix);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t*p += 4;  \n\n\t\tceph_decode_8_safe(p, end, struct_v, e_inval);\n\t\tceph_decode_8_safe(p, end, struct_compat, e_inval);\n\t\tif (struct_compat > OSDMAP_CLIENT_DATA_COMPAT_VER) {\n\t\t\tpr_warn(\"got v %d cv %d > %d of %s ceph_osdmap client data\\n\",\n\t\t\t\tstruct_v, struct_compat,\n\t\t\t\tOSDMAP_CLIENT_DATA_COMPAT_VER, prefix);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t*p += 4;  \n\t} else {\n\t\tu16 version;\n\n\t\t*p -= 1;\n\t\tceph_decode_16_safe(p, end, version, e_inval);\n\t\tif (version < 6) {\n\t\t\tpr_warn(\"got v %d < 6 of %s ceph_osdmap\\n\",\n\t\t\t\tversion, prefix);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tstruct_v = 0;\n\t}\n\n\t*v = struct_v;\n\treturn 0;\n\ne_inval:\n\treturn -EINVAL;\n}\n\nstatic int __decode_pools(void **p, void *end, struct ceph_osdmap *map,\n\t\t\t  bool incremental)\n{\n\tu32 n;\n\n\tceph_decode_32_safe(p, end, n, e_inval);\n\twhile (n--) {\n\t\tstruct ceph_pg_pool_info *pi;\n\t\tu64 pool;\n\t\tint ret;\n\n\t\tceph_decode_64_safe(p, end, pool, e_inval);\n\n\t\tpi = lookup_pg_pool(&map->pg_pools, pool);\n\t\tif (!incremental || !pi) {\n\t\t\tpi = kzalloc(sizeof(*pi), GFP_NOFS);\n\t\t\tif (!pi)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tRB_CLEAR_NODE(&pi->node);\n\t\t\tpi->id = pool;\n\n\t\t\tif (!__insert_pg_pool(&map->pg_pools, pi)) {\n\t\t\t\tkfree(pi);\n\t\t\t\treturn -EEXIST;\n\t\t\t}\n\t\t}\n\n\t\tret = decode_pool(p, end, pi);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n\ne_inval:\n\treturn -EINVAL;\n}\n\nstatic int decode_pools(void **p, void *end, struct ceph_osdmap *map)\n{\n\treturn __decode_pools(p, end, map, false);\n}\n\nstatic int decode_new_pools(void **p, void *end, struct ceph_osdmap *map)\n{\n\treturn __decode_pools(p, end, map, true);\n}\n\ntypedef struct ceph_pg_mapping *(*decode_mapping_fn_t)(void **, void *, bool);\n\nstatic int decode_pg_mapping(void **p, void *end, struct rb_root *mapping_root,\n\t\t\t     decode_mapping_fn_t fn, bool incremental)\n{\n\tu32 n;\n\n\tWARN_ON(!incremental && !fn);\n\n\tceph_decode_32_safe(p, end, n, e_inval);\n\twhile (n--) {\n\t\tstruct ceph_pg_mapping *pg;\n\t\tstruct ceph_pg pgid;\n\t\tint ret;\n\n\t\tret = ceph_decode_pgid(p, end, &pgid);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tpg = lookup_pg_mapping(mapping_root, &pgid);\n\t\tif (pg) {\n\t\t\tWARN_ON(!incremental);\n\t\t\terase_pg_mapping(mapping_root, pg);\n\t\t\tfree_pg_mapping(pg);\n\t\t}\n\n\t\tif (fn) {\n\t\t\tpg = fn(p, end, incremental);\n\t\t\tif (IS_ERR(pg))\n\t\t\t\treturn PTR_ERR(pg);\n\n\t\t\tif (pg) {\n\t\t\t\tpg->pgid = pgid;  \n\t\t\t\tinsert_pg_mapping(mapping_root, pg);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n\ne_inval:\n\treturn -EINVAL;\n}\n\nstatic struct ceph_pg_mapping *__decode_pg_temp(void **p, void *end,\n\t\t\t\t\t\tbool incremental)\n{\n\tstruct ceph_pg_mapping *pg;\n\tu32 len, i;\n\n\tceph_decode_32_safe(p, end, len, e_inval);\n\tif (len == 0 && incremental)\n\t\treturn NULL;\t \n\tif (len > (SIZE_MAX - sizeof(*pg)) / sizeof(u32))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tceph_decode_need(p, end, len * sizeof(u32), e_inval);\n\tpg = alloc_pg_mapping(len * sizeof(u32));\n\tif (!pg)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tpg->pg_temp.len = len;\n\tfor (i = 0; i < len; i++)\n\t\tpg->pg_temp.osds[i] = ceph_decode_32(p);\n\n\treturn pg;\n\ne_inval:\n\treturn ERR_PTR(-EINVAL);\n}\n\nstatic int decode_pg_temp(void **p, void *end, struct ceph_osdmap *map)\n{\n\treturn decode_pg_mapping(p, end, &map->pg_temp, __decode_pg_temp,\n\t\t\t\t false);\n}\n\nstatic int decode_new_pg_temp(void **p, void *end, struct ceph_osdmap *map)\n{\n\treturn decode_pg_mapping(p, end, &map->pg_temp, __decode_pg_temp,\n\t\t\t\t true);\n}\n\nstatic struct ceph_pg_mapping *__decode_primary_temp(void **p, void *end,\n\t\t\t\t\t\t     bool incremental)\n{\n\tstruct ceph_pg_mapping *pg;\n\tu32 osd;\n\n\tceph_decode_32_safe(p, end, osd, e_inval);\n\tif (osd == (u32)-1 && incremental)\n\t\treturn NULL;\t \n\n\tpg = alloc_pg_mapping(0);\n\tif (!pg)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tpg->primary_temp.osd = osd;\n\treturn pg;\n\ne_inval:\n\treturn ERR_PTR(-EINVAL);\n}\n\nstatic int decode_primary_temp(void **p, void *end, struct ceph_osdmap *map)\n{\n\treturn decode_pg_mapping(p, end, &map->primary_temp,\n\t\t\t\t __decode_primary_temp, false);\n}\n\nstatic int decode_new_primary_temp(void **p, void *end,\n\t\t\t\t   struct ceph_osdmap *map)\n{\n\treturn decode_pg_mapping(p, end, &map->primary_temp,\n\t\t\t\t __decode_primary_temp, true);\n}\n\nu32 ceph_get_primary_affinity(struct ceph_osdmap *map, int osd)\n{\n\tBUG_ON(osd >= map->max_osd);\n\n\tif (!map->osd_primary_affinity)\n\t\treturn CEPH_OSD_DEFAULT_PRIMARY_AFFINITY;\n\n\treturn map->osd_primary_affinity[osd];\n}\n\nstatic int set_primary_affinity(struct ceph_osdmap *map, int osd, u32 aff)\n{\n\tBUG_ON(osd >= map->max_osd);\n\n\tif (!map->osd_primary_affinity) {\n\t\tint i;\n\n\t\tmap->osd_primary_affinity = kvmalloc(\n\t\t    array_size(map->max_osd, sizeof(*map->osd_primary_affinity)),\n\t\t    GFP_NOFS);\n\t\tif (!map->osd_primary_affinity)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < map->max_osd; i++)\n\t\t\tmap->osd_primary_affinity[i] =\n\t\t\t    CEPH_OSD_DEFAULT_PRIMARY_AFFINITY;\n\t}\n\n\tmap->osd_primary_affinity[osd] = aff;\n\n\treturn 0;\n}\n\nstatic int decode_primary_affinity(void **p, void *end,\n\t\t\t\t   struct ceph_osdmap *map)\n{\n\tu32 len, i;\n\n\tceph_decode_32_safe(p, end, len, e_inval);\n\tif (len == 0) {\n\t\tkvfree(map->osd_primary_affinity);\n\t\tmap->osd_primary_affinity = NULL;\n\t\treturn 0;\n\t}\n\tif (len != map->max_osd)\n\t\tgoto e_inval;\n\n\tceph_decode_need(p, end, map->max_osd*sizeof(u32), e_inval);\n\n\tfor (i = 0; i < map->max_osd; i++) {\n\t\tint ret;\n\n\t\tret = set_primary_affinity(map, i, ceph_decode_32(p));\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n\ne_inval:\n\treturn -EINVAL;\n}\n\nstatic int decode_new_primary_affinity(void **p, void *end,\n\t\t\t\t       struct ceph_osdmap *map)\n{\n\tu32 n;\n\n\tceph_decode_32_safe(p, end, n, e_inval);\n\twhile (n--) {\n\t\tu32 osd, aff;\n\t\tint ret;\n\n\t\tceph_decode_32_safe(p, end, osd, e_inval);\n\t\tceph_decode_32_safe(p, end, aff, e_inval);\n\n\t\tret = set_primary_affinity(map, osd, aff);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tosdmap_info(map, \"osd%d primary-affinity 0x%x\\n\", osd, aff);\n\t}\n\n\treturn 0;\n\ne_inval:\n\treturn -EINVAL;\n}\n\nstatic struct ceph_pg_mapping *__decode_pg_upmap(void **p, void *end,\n\t\t\t\t\t\t bool __unused)\n{\n\treturn __decode_pg_temp(p, end, false);\n}\n\nstatic int decode_pg_upmap(void **p, void *end, struct ceph_osdmap *map)\n{\n\treturn decode_pg_mapping(p, end, &map->pg_upmap, __decode_pg_upmap,\n\t\t\t\t false);\n}\n\nstatic int decode_new_pg_upmap(void **p, void *end, struct ceph_osdmap *map)\n{\n\treturn decode_pg_mapping(p, end, &map->pg_upmap, __decode_pg_upmap,\n\t\t\t\t true);\n}\n\nstatic int decode_old_pg_upmap(void **p, void *end, struct ceph_osdmap *map)\n{\n\treturn decode_pg_mapping(p, end, &map->pg_upmap, NULL, true);\n}\n\nstatic struct ceph_pg_mapping *__decode_pg_upmap_items(void **p, void *end,\n\t\t\t\t\t\t       bool __unused)\n{\n\tstruct ceph_pg_mapping *pg;\n\tu32 len, i;\n\n\tceph_decode_32_safe(p, end, len, e_inval);\n\tif (len > (SIZE_MAX - sizeof(*pg)) / (2 * sizeof(u32)))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tceph_decode_need(p, end, 2 * len * sizeof(u32), e_inval);\n\tpg = alloc_pg_mapping(2 * len * sizeof(u32));\n\tif (!pg)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tpg->pg_upmap_items.len = len;\n\tfor (i = 0; i < len; i++) {\n\t\tpg->pg_upmap_items.from_to[i][0] = ceph_decode_32(p);\n\t\tpg->pg_upmap_items.from_to[i][1] = ceph_decode_32(p);\n\t}\n\n\treturn pg;\n\ne_inval:\n\treturn ERR_PTR(-EINVAL);\n}\n\nstatic int decode_pg_upmap_items(void **p, void *end, struct ceph_osdmap *map)\n{\n\treturn decode_pg_mapping(p, end, &map->pg_upmap_items,\n\t\t\t\t __decode_pg_upmap_items, false);\n}\n\nstatic int decode_new_pg_upmap_items(void **p, void *end,\n\t\t\t\t     struct ceph_osdmap *map)\n{\n\treturn decode_pg_mapping(p, end, &map->pg_upmap_items,\n\t\t\t\t __decode_pg_upmap_items, true);\n}\n\nstatic int decode_old_pg_upmap_items(void **p, void *end,\n\t\t\t\t     struct ceph_osdmap *map)\n{\n\treturn decode_pg_mapping(p, end, &map->pg_upmap_items, NULL, true);\n}\n\n \nstatic int osdmap_decode(void **p, void *end, bool msgr2,\n\t\t\t struct ceph_osdmap *map)\n{\n\tu8 struct_v;\n\tu32 epoch = 0;\n\tvoid *start = *p;\n\tu32 max;\n\tu32 len, i;\n\tint err;\n\n\tdout(\"%s %p to %p len %d\\n\", __func__, *p, end, (int)(end - *p));\n\n\terr = get_osdmap_client_data_v(p, end, \"full\", &struct_v);\n\tif (err)\n\t\tgoto bad;\n\n\t \n\tceph_decode_need(p, end, sizeof(map->fsid) + sizeof(u32) +\n\t\t\t sizeof(map->created) + sizeof(map->modified), e_inval);\n\tceph_decode_copy(p, &map->fsid, sizeof(map->fsid));\n\tepoch = map->epoch = ceph_decode_32(p);\n\tceph_decode_copy(p, &map->created, sizeof(map->created));\n\tceph_decode_copy(p, &map->modified, sizeof(map->modified));\n\n\t \n\terr = decode_pools(p, end, map);\n\tif (err)\n\t\tgoto bad;\n\n\t \n\terr = decode_pool_names(p, end, map);\n\tif (err)\n\t\tgoto bad;\n\n\tceph_decode_32_safe(p, end, map->pool_max, e_inval);\n\n\tceph_decode_32_safe(p, end, map->flags, e_inval);\n\n\t \n\tceph_decode_32_safe(p, end, max, e_inval);\n\n\t \n\terr = osdmap_set_max_osd(map, max);\n\tif (err)\n\t\tgoto bad;\n\n\t \n\tceph_decode_need(p, end, 3*sizeof(u32) +\n\t\t\t map->max_osd*(struct_v >= 5 ? sizeof(u32) :\n\t\t\t\t\t\t       sizeof(u8)) +\n\t\t\t\t       sizeof(*map->osd_weight), e_inval);\n\tif (ceph_decode_32(p) != map->max_osd)\n\t\tgoto e_inval;\n\n\tif (struct_v >= 5) {\n\t\tfor (i = 0; i < map->max_osd; i++)\n\t\t\tmap->osd_state[i] = ceph_decode_32(p);\n\t} else {\n\t\tfor (i = 0; i < map->max_osd; i++)\n\t\t\tmap->osd_state[i] = ceph_decode_8(p);\n\t}\n\n\tif (ceph_decode_32(p) != map->max_osd)\n\t\tgoto e_inval;\n\n\tfor (i = 0; i < map->max_osd; i++)\n\t\tmap->osd_weight[i] = ceph_decode_32(p);\n\n\tif (ceph_decode_32(p) != map->max_osd)\n\t\tgoto e_inval;\n\n\tfor (i = 0; i < map->max_osd; i++) {\n\t\tstruct ceph_entity_addr *addr = &map->osd_addr[i];\n\n\t\tif (struct_v >= 8)\n\t\t\terr = ceph_decode_entity_addrvec(p, end, msgr2, addr);\n\t\telse\n\t\t\terr = ceph_decode_entity_addr(p, end, addr);\n\t\tif (err)\n\t\t\tgoto bad;\n\n\t\tdout(\"%s osd%d addr %s\\n\", __func__, i, ceph_pr_addr(addr));\n\t}\n\n\t \n\terr = decode_pg_temp(p, end, map);\n\tif (err)\n\t\tgoto bad;\n\n\t \n\tif (struct_v >= 1) {\n\t\terr = decode_primary_temp(p, end, map);\n\t\tif (err)\n\t\t\tgoto bad;\n\t}\n\n\t \n\tif (struct_v >= 2) {\n\t\terr = decode_primary_affinity(p, end, map);\n\t\tif (err)\n\t\t\tgoto bad;\n\t} else {\n\t\tWARN_ON(map->osd_primary_affinity);\n\t}\n\n\t \n\tceph_decode_32_safe(p, end, len, e_inval);\n\terr = osdmap_set_crush(map, crush_decode(*p, min(*p + len, end)));\n\tif (err)\n\t\tgoto bad;\n\n\t*p += len;\n\tif (struct_v >= 3) {\n\t\t \n\t\tceph_decode_skip_map_of_map(p, end, string, string, string,\n\t\t\t\t\t    e_inval);\n\t}\n\n\tif (struct_v >= 4) {\n\t\terr = decode_pg_upmap(p, end, map);\n\t\tif (err)\n\t\t\tgoto bad;\n\n\t\terr = decode_pg_upmap_items(p, end, map);\n\t\tif (err)\n\t\t\tgoto bad;\n\t} else {\n\t\tWARN_ON(!RB_EMPTY_ROOT(&map->pg_upmap));\n\t\tWARN_ON(!RB_EMPTY_ROOT(&map->pg_upmap_items));\n\t}\n\n\t \n\t*p = end;\n\n\tdout(\"full osdmap epoch %d max_osd %d\\n\", map->epoch, map->max_osd);\n\treturn 0;\n\ne_inval:\n\terr = -EINVAL;\nbad:\n\tpr_err(\"corrupt full osdmap (%d) epoch %d off %d (%p of %p-%p)\\n\",\n\t       err, epoch, (int)(*p - start), *p, start, end);\n\tprint_hex_dump(KERN_DEBUG, \"osdmap: \",\n\t\t       DUMP_PREFIX_OFFSET, 16, 1,\n\t\t       start, end - start, true);\n\treturn err;\n}\n\n \nstruct ceph_osdmap *ceph_osdmap_decode(void **p, void *end, bool msgr2)\n{\n\tstruct ceph_osdmap *map;\n\tint ret;\n\n\tmap = ceph_osdmap_alloc();\n\tif (!map)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = osdmap_decode(p, end, msgr2, map);\n\tif (ret) {\n\t\tceph_osdmap_destroy(map);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\treturn map;\n}\n\n \nstatic int decode_new_up_state_weight(void **p, void *end, u8 struct_v,\n\t\t\t\t      bool msgr2, struct ceph_osdmap *map)\n{\n\tvoid *new_up_client;\n\tvoid *new_state;\n\tvoid *new_weight_end;\n\tu32 len;\n\tint ret;\n\tint i;\n\n\tnew_up_client = *p;\n\tceph_decode_32_safe(p, end, len, e_inval);\n\tfor (i = 0; i < len; ++i) {\n\t\tstruct ceph_entity_addr addr;\n\n\t\tceph_decode_skip_32(p, end, e_inval);\n\t\tif (struct_v >= 7)\n\t\t\tret = ceph_decode_entity_addrvec(p, end, msgr2, &addr);\n\t\telse\n\t\t\tret = ceph_decode_entity_addr(p, end, &addr);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tnew_state = *p;\n\tceph_decode_32_safe(p, end, len, e_inval);\n\tlen *= sizeof(u32) + (struct_v >= 5 ? sizeof(u32) : sizeof(u8));\n\tceph_decode_need(p, end, len, e_inval);\n\t*p += len;\n\n\t \n\tceph_decode_32_safe(p, end, len, e_inval);\n\twhile (len--) {\n\t\ts32 osd;\n\t\tu32 w;\n\n\t\tceph_decode_need(p, end, 2*sizeof(u32), e_inval);\n\t\tosd = ceph_decode_32(p);\n\t\tw = ceph_decode_32(p);\n\t\tBUG_ON(osd >= map->max_osd);\n\t\tosdmap_info(map, \"osd%d weight 0x%x %s\\n\", osd, w,\n\t\t\t    w == CEPH_OSD_IN ? \"(in)\" :\n\t\t\t    (w == CEPH_OSD_OUT ? \"(out)\" : \"\"));\n\t\tmap->osd_weight[osd] = w;\n\n\t\t \n\t\tif (w) {\n\t\t\tmap->osd_state[osd] |= CEPH_OSD_EXISTS;\n\t\t\tmap->osd_state[osd] &= ~(CEPH_OSD_AUTOOUT |\n\t\t\t\t\t\t CEPH_OSD_NEW);\n\t\t}\n\t}\n\tnew_weight_end = *p;\n\n\t \n\t*p = new_state;\n\tlen = ceph_decode_32(p);\n\twhile (len--) {\n\t\ts32 osd;\n\t\tu32 xorstate;\n\n\t\tosd = ceph_decode_32(p);\n\t\tif (struct_v >= 5)\n\t\t\txorstate = ceph_decode_32(p);\n\t\telse\n\t\t\txorstate = ceph_decode_8(p);\n\t\tif (xorstate == 0)\n\t\t\txorstate = CEPH_OSD_UP;\n\t\tBUG_ON(osd >= map->max_osd);\n\t\tif ((map->osd_state[osd] & CEPH_OSD_UP) &&\n\t\t    (xorstate & CEPH_OSD_UP))\n\t\t\tosdmap_info(map, \"osd%d down\\n\", osd);\n\t\tif ((map->osd_state[osd] & CEPH_OSD_EXISTS) &&\n\t\t    (xorstate & CEPH_OSD_EXISTS)) {\n\t\t\tosdmap_info(map, \"osd%d does not exist\\n\", osd);\n\t\t\tret = set_primary_affinity(map, osd,\n\t\t\t\t\t\t   CEPH_OSD_DEFAULT_PRIMARY_AFFINITY);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tmemset(map->osd_addr + osd, 0, sizeof(*map->osd_addr));\n\t\t\tmap->osd_state[osd] = 0;\n\t\t} else {\n\t\t\tmap->osd_state[osd] ^= xorstate;\n\t\t}\n\t}\n\n\t \n\t*p = new_up_client;\n\tlen = ceph_decode_32(p);\n\twhile (len--) {\n\t\ts32 osd;\n\t\tstruct ceph_entity_addr addr;\n\n\t\tosd = ceph_decode_32(p);\n\t\tBUG_ON(osd >= map->max_osd);\n\t\tif (struct_v >= 7)\n\t\t\tret = ceph_decode_entity_addrvec(p, end, msgr2, &addr);\n\t\telse\n\t\t\tret = ceph_decode_entity_addr(p, end, &addr);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tdout(\"%s osd%d addr %s\\n\", __func__, osd, ceph_pr_addr(&addr));\n\n\t\tosdmap_info(map, \"osd%d up\\n\", osd);\n\t\tmap->osd_state[osd] |= CEPH_OSD_EXISTS | CEPH_OSD_UP;\n\t\tmap->osd_addr[osd] = addr;\n\t}\n\n\t*p = new_weight_end;\n\treturn 0;\n\ne_inval:\n\treturn -EINVAL;\n}\n\n \nstruct ceph_osdmap *osdmap_apply_incremental(void **p, void *end, bool msgr2,\n\t\t\t\t\t     struct ceph_osdmap *map)\n{\n\tstruct ceph_fsid fsid;\n\tu32 epoch = 0;\n\tstruct ceph_timespec modified;\n\ts32 len;\n\tu64 pool;\n\t__s64 new_pool_max;\n\t__s32 new_flags, max;\n\tvoid *start = *p;\n\tint err;\n\tu8 struct_v;\n\n\tdout(\"%s %p to %p len %d\\n\", __func__, *p, end, (int)(end - *p));\n\n\terr = get_osdmap_client_data_v(p, end, \"inc\", &struct_v);\n\tif (err)\n\t\tgoto bad;\n\n\t \n\tceph_decode_need(p, end, sizeof(fsid) + sizeof(u32) + sizeof(modified) +\n\t\t\t sizeof(u64) + sizeof(u32), e_inval);\n\tceph_decode_copy(p, &fsid, sizeof(fsid));\n\tepoch = ceph_decode_32(p);\n\tBUG_ON(epoch != map->epoch+1);\n\tceph_decode_copy(p, &modified, sizeof(modified));\n\tnew_pool_max = ceph_decode_64(p);\n\tnew_flags = ceph_decode_32(p);\n\n\t \n\tceph_decode_32_safe(p, end, len, e_inval);\n\tif (len > 0) {\n\t\tdout(\"apply_incremental full map len %d, %p to %p\\n\",\n\t\t     len, *p, end);\n\t\treturn ceph_osdmap_decode(p, min(*p+len, end), msgr2);\n\t}\n\n\t \n\tceph_decode_32_safe(p, end, len, e_inval);\n\tif (len > 0) {\n\t\terr = osdmap_set_crush(map,\n\t\t\t\t       crush_decode(*p, min(*p + len, end)));\n\t\tif (err)\n\t\t\tgoto bad;\n\t\t*p += len;\n\t}\n\n\t \n\tif (new_flags >= 0)\n\t\tmap->flags = new_flags;\n\tif (new_pool_max >= 0)\n\t\tmap->pool_max = new_pool_max;\n\n\t \n\tceph_decode_32_safe(p, end, max, e_inval);\n\tif (max >= 0) {\n\t\terr = osdmap_set_max_osd(map, max);\n\t\tif (err)\n\t\t\tgoto bad;\n\t}\n\n\tmap->epoch++;\n\tmap->modified = modified;\n\n\t \n\terr = decode_new_pools(p, end, map);\n\tif (err)\n\t\tgoto bad;\n\n\t \n\terr = decode_pool_names(p, end, map);\n\tif (err)\n\t\tgoto bad;\n\n\t \n\tceph_decode_32_safe(p, end, len, e_inval);\n\twhile (len--) {\n\t\tstruct ceph_pg_pool_info *pi;\n\n\t\tceph_decode_64_safe(p, end, pool, e_inval);\n\t\tpi = lookup_pg_pool(&map->pg_pools, pool);\n\t\tif (pi)\n\t\t\t__remove_pg_pool(&map->pg_pools, pi);\n\t}\n\n\t \n\terr = decode_new_up_state_weight(p, end, struct_v, msgr2, map);\n\tif (err)\n\t\tgoto bad;\n\n\t \n\terr = decode_new_pg_temp(p, end, map);\n\tif (err)\n\t\tgoto bad;\n\n\t \n\tif (struct_v >= 1) {\n\t\terr = decode_new_primary_temp(p, end, map);\n\t\tif (err)\n\t\t\tgoto bad;\n\t}\n\n\t \n\tif (struct_v >= 2) {\n\t\terr = decode_new_primary_affinity(p, end, map);\n\t\tif (err)\n\t\t\tgoto bad;\n\t}\n\n\tif (struct_v >= 3) {\n\t\t \n\t\tceph_decode_skip_map_of_map(p, end, string, string, string,\n\t\t\t\t\t    e_inval);\n\t\t \n\t\tceph_decode_skip_set(p, end, string, e_inval);\n\t}\n\n\tif (struct_v >= 4) {\n\t\terr = decode_new_pg_upmap(p, end, map);\n\t\tif (err)\n\t\t\tgoto bad;\n\n\t\terr = decode_old_pg_upmap(p, end, map);\n\t\tif (err)\n\t\t\tgoto bad;\n\n\t\terr = decode_new_pg_upmap_items(p, end, map);\n\t\tif (err)\n\t\t\tgoto bad;\n\n\t\terr = decode_old_pg_upmap_items(p, end, map);\n\t\tif (err)\n\t\t\tgoto bad;\n\t}\n\n\t \n\t*p = end;\n\n\tdout(\"inc osdmap epoch %d max_osd %d\\n\", map->epoch, map->max_osd);\n\treturn map;\n\ne_inval:\n\terr = -EINVAL;\nbad:\n\tpr_err(\"corrupt inc osdmap (%d) epoch %d off %d (%p of %p-%p)\\n\",\n\t       err, epoch, (int)(*p - start), *p, start, end);\n\tprint_hex_dump(KERN_DEBUG, \"osdmap: \",\n\t\t       DUMP_PREFIX_OFFSET, 16, 1,\n\t\t       start, end - start, true);\n\treturn ERR_PTR(err);\n}\n\nvoid ceph_oloc_copy(struct ceph_object_locator *dest,\n\t\t    const struct ceph_object_locator *src)\n{\n\tceph_oloc_destroy(dest);\n\n\tdest->pool = src->pool;\n\tif (src->pool_ns)\n\t\tdest->pool_ns = ceph_get_string(src->pool_ns);\n\telse\n\t\tdest->pool_ns = NULL;\n}\nEXPORT_SYMBOL(ceph_oloc_copy);\n\nvoid ceph_oloc_destroy(struct ceph_object_locator *oloc)\n{\n\tceph_put_string(oloc->pool_ns);\n}\nEXPORT_SYMBOL(ceph_oloc_destroy);\n\nvoid ceph_oid_copy(struct ceph_object_id *dest,\n\t\t   const struct ceph_object_id *src)\n{\n\tceph_oid_destroy(dest);\n\n\tif (src->name != src->inline_name) {\n\t\t \n\t\tdest->name = kmalloc(src->name_len + 1,\n\t\t\t\t     GFP_NOIO | __GFP_NOFAIL);\n\t} else {\n\t\tdest->name = dest->inline_name;\n\t}\n\tmemcpy(dest->name, src->name, src->name_len + 1);\n\tdest->name_len = src->name_len;\n}\nEXPORT_SYMBOL(ceph_oid_copy);\n\nstatic __printf(2, 0)\nint oid_printf_vargs(struct ceph_object_id *oid, const char *fmt, va_list ap)\n{\n\tint len;\n\n\tWARN_ON(!ceph_oid_empty(oid));\n\n\tlen = vsnprintf(oid->inline_name, sizeof(oid->inline_name), fmt, ap);\n\tif (len >= sizeof(oid->inline_name))\n\t\treturn len;\n\n\toid->name_len = len;\n\treturn 0;\n}\n\n \nvoid ceph_oid_printf(struct ceph_object_id *oid, const char *fmt, ...)\n{\n\tva_list ap;\n\n\tva_start(ap, fmt);\n\tBUG_ON(oid_printf_vargs(oid, fmt, ap));\n\tva_end(ap);\n}\nEXPORT_SYMBOL(ceph_oid_printf);\n\nstatic __printf(3, 0)\nint oid_aprintf_vargs(struct ceph_object_id *oid, gfp_t gfp,\n\t\t      const char *fmt, va_list ap)\n{\n\tva_list aq;\n\tint len;\n\n\tva_copy(aq, ap);\n\tlen = oid_printf_vargs(oid, fmt, aq);\n\tva_end(aq);\n\n\tif (len) {\n\t\tchar *external_name;\n\n\t\texternal_name = kmalloc(len + 1, gfp);\n\t\tif (!external_name)\n\t\t\treturn -ENOMEM;\n\n\t\toid->name = external_name;\n\t\tWARN_ON(vsnprintf(oid->name, len + 1, fmt, ap) != len);\n\t\toid->name_len = len;\n\t}\n\n\treturn 0;\n}\n\n \nint ceph_oid_aprintf(struct ceph_object_id *oid, gfp_t gfp,\n\t\t     const char *fmt, ...)\n{\n\tva_list ap;\n\tint ret;\n\n\tva_start(ap, fmt);\n\tret = oid_aprintf_vargs(oid, gfp, fmt, ap);\n\tva_end(ap);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(ceph_oid_aprintf);\n\nvoid ceph_oid_destroy(struct ceph_object_id *oid)\n{\n\tif (oid->name != oid->inline_name)\n\t\tkfree(oid->name);\n}\nEXPORT_SYMBOL(ceph_oid_destroy);\n\n \nstatic bool __osds_equal(const struct ceph_osds *lhs,\n\t\t\t const struct ceph_osds *rhs)\n{\n\tif (lhs->size == rhs->size &&\n\t    !memcmp(lhs->osds, rhs->osds, rhs->size * sizeof(rhs->osds[0])))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic bool osds_equal(const struct ceph_osds *lhs,\n\t\t       const struct ceph_osds *rhs)\n{\n\tif (__osds_equal(lhs, rhs) &&\n\t    lhs->primary == rhs->primary)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic bool osds_valid(const struct ceph_osds *set)\n{\n\t \n\tif (set->size > 0 && set->primary >= 0)\n\t\treturn true;\n\n\t \n\tif (!set->size && set->primary == -1)\n\t\treturn true;\n\n\t \n\tif (set->size > 0 && set->primary == -1) {\n\t\tint i;\n\n\t\tfor (i = 0; i < set->size; i++) {\n\t\t\tif (set->osds[i] != CRUSH_ITEM_NONE)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (i == set->size)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nvoid ceph_osds_copy(struct ceph_osds *dest, const struct ceph_osds *src)\n{\n\tmemcpy(dest->osds, src->osds, src->size * sizeof(src->osds[0]));\n\tdest->size = src->size;\n\tdest->primary = src->primary;\n}\n\nbool ceph_pg_is_split(const struct ceph_pg *pgid, u32 old_pg_num,\n\t\t      u32 new_pg_num)\n{\n\tint old_bits = calc_bits_of(old_pg_num);\n\tint old_mask = (1 << old_bits) - 1;\n\tint n;\n\n\tWARN_ON(pgid->seed >= old_pg_num);\n\tif (new_pg_num <= old_pg_num)\n\t\treturn false;\n\n\tfor (n = 1; ; n++) {\n\t\tint next_bit = n << (old_bits - 1);\n\t\tu32 s = next_bit | pgid->seed;\n\n\t\tif (s < old_pg_num || s == pgid->seed)\n\t\t\tcontinue;\n\t\tif (s >= new_pg_num)\n\t\t\tbreak;\n\n\t\ts = ceph_stable_mod(s, old_pg_num, old_mask);\n\t\tif (s == pgid->seed)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nbool ceph_is_new_interval(const struct ceph_osds *old_acting,\n\t\t\t  const struct ceph_osds *new_acting,\n\t\t\t  const struct ceph_osds *old_up,\n\t\t\t  const struct ceph_osds *new_up,\n\t\t\t  int old_size,\n\t\t\t  int new_size,\n\t\t\t  int old_min_size,\n\t\t\t  int new_min_size,\n\t\t\t  u32 old_pg_num,\n\t\t\t  u32 new_pg_num,\n\t\t\t  bool old_sort_bitwise,\n\t\t\t  bool new_sort_bitwise,\n\t\t\t  bool old_recovery_deletes,\n\t\t\t  bool new_recovery_deletes,\n\t\t\t  const struct ceph_pg *pgid)\n{\n\treturn !osds_equal(old_acting, new_acting) ||\n\t       !osds_equal(old_up, new_up) ||\n\t       old_size != new_size ||\n\t       old_min_size != new_min_size ||\n\t       ceph_pg_is_split(pgid, old_pg_num, new_pg_num) ||\n\t       old_sort_bitwise != new_sort_bitwise ||\n\t       old_recovery_deletes != new_recovery_deletes;\n}\n\nstatic int calc_pg_rank(int osd, const struct ceph_osds *acting)\n{\n\tint i;\n\n\tfor (i = 0; i < acting->size; i++) {\n\t\tif (acting->osds[i] == osd)\n\t\t\treturn i;\n\t}\n\n\treturn -1;\n}\n\nstatic bool primary_changed(const struct ceph_osds *old_acting,\n\t\t\t    const struct ceph_osds *new_acting)\n{\n\tif (!old_acting->size && !new_acting->size)\n\t\treturn false;  \n\n\tif (!old_acting->size ^ !new_acting->size)\n\t\treturn true;  \n\n\tif (old_acting->primary != new_acting->primary)\n\t\treturn true;  \n\n\tif (calc_pg_rank(old_acting->primary, old_acting) !=\n\t    calc_pg_rank(new_acting->primary, new_acting))\n\t\treturn true;\n\n\treturn false;  \n}\n\nbool ceph_osds_changed(const struct ceph_osds *old_acting,\n\t\t       const struct ceph_osds *new_acting,\n\t\t       bool any_change)\n{\n\tif (primary_changed(old_acting, new_acting))\n\t\treturn true;\n\n\tif (any_change && !__osds_equal(old_acting, new_acting))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nvoid __ceph_object_locator_to_pg(struct ceph_pg_pool_info *pi,\n\t\t\t\t const struct ceph_object_id *oid,\n\t\t\t\t const struct ceph_object_locator *oloc,\n\t\t\t\t struct ceph_pg *raw_pgid)\n{\n\tWARN_ON(pi->id != oloc->pool);\n\n\tif (!oloc->pool_ns) {\n\t\traw_pgid->pool = oloc->pool;\n\t\traw_pgid->seed = ceph_str_hash(pi->object_hash, oid->name,\n\t\t\t\t\t     oid->name_len);\n\t\tdout(\"%s %s -> raw_pgid %llu.%x\\n\", __func__, oid->name,\n\t\t     raw_pgid->pool, raw_pgid->seed);\n\t} else {\n\t\tchar stack_buf[256];\n\t\tchar *buf = stack_buf;\n\t\tint nsl = oloc->pool_ns->len;\n\t\tsize_t total = nsl + 1 + oid->name_len;\n\n\t\tif (total > sizeof(stack_buf))\n\t\t\tbuf = kmalloc(total, GFP_NOIO | __GFP_NOFAIL);\n\t\tmemcpy(buf, oloc->pool_ns->str, nsl);\n\t\tbuf[nsl] = '\\037';\n\t\tmemcpy(buf + nsl + 1, oid->name, oid->name_len);\n\t\traw_pgid->pool = oloc->pool;\n\t\traw_pgid->seed = ceph_str_hash(pi->object_hash, buf, total);\n\t\tif (buf != stack_buf)\n\t\t\tkfree(buf);\n\t\tdout(\"%s %s ns %.*s -> raw_pgid %llu.%x\\n\", __func__,\n\t\t     oid->name, nsl, oloc->pool_ns->str,\n\t\t     raw_pgid->pool, raw_pgid->seed);\n\t}\n}\n\nint ceph_object_locator_to_pg(struct ceph_osdmap *osdmap,\n\t\t\t      const struct ceph_object_id *oid,\n\t\t\t      const struct ceph_object_locator *oloc,\n\t\t\t      struct ceph_pg *raw_pgid)\n{\n\tstruct ceph_pg_pool_info *pi;\n\n\tpi = ceph_pg_pool_by_id(osdmap, oloc->pool);\n\tif (!pi)\n\t\treturn -ENOENT;\n\n\t__ceph_object_locator_to_pg(pi, oid, oloc, raw_pgid);\n\treturn 0;\n}\nEXPORT_SYMBOL(ceph_object_locator_to_pg);\n\n \nstatic void raw_pg_to_pg(struct ceph_pg_pool_info *pi,\n\t\t\t const struct ceph_pg *raw_pgid,\n\t\t\t struct ceph_pg *pgid)\n{\n\tpgid->pool = raw_pgid->pool;\n\tpgid->seed = ceph_stable_mod(raw_pgid->seed, pi->pg_num,\n\t\t\t\t     pi->pg_num_mask);\n}\n\n \nstatic u32 raw_pg_to_pps(struct ceph_pg_pool_info *pi,\n\t\t\t const struct ceph_pg *raw_pgid)\n{\n\tif (pi->flags & CEPH_POOL_FLAG_HASHPSPOOL) {\n\t\t \n\t\treturn crush_hash32_2(CRUSH_HASH_RJENKINS1,\n\t\t\t\t      ceph_stable_mod(raw_pgid->seed,\n\t\t\t\t\t\t      pi->pgp_num,\n\t\t\t\t\t\t      pi->pgp_num_mask),\n\t\t\t\t      raw_pgid->pool);\n\t} else {\n\t\t \n\t\treturn ceph_stable_mod(raw_pgid->seed, pi->pgp_num,\n\t\t\t\t       pi->pgp_num_mask) +\n\t\t       (unsigned)raw_pgid->pool;\n\t}\n}\n\n \n#define CEPH_DEFAULT_CHOOSE_ARGS\t-1\n\nstatic int do_crush(struct ceph_osdmap *map, int ruleno, int x,\n\t\t    int *result, int result_max,\n\t\t    const __u32 *weight, int weight_max,\n\t\t    s64 choose_args_index)\n{\n\tstruct crush_choose_arg_map *arg_map;\n\tstruct crush_work *work;\n\tint r;\n\n\tBUG_ON(result_max > CEPH_PG_MAX_SIZE);\n\n\targ_map = lookup_choose_arg_map(&map->crush->choose_args,\n\t\t\t\t\tchoose_args_index);\n\tif (!arg_map)\n\t\targ_map = lookup_choose_arg_map(&map->crush->choose_args,\n\t\t\t\t\t\tCEPH_DEFAULT_CHOOSE_ARGS);\n\n\twork = get_workspace(&map->crush_wsm, map->crush);\n\tr = crush_do_rule(map->crush, ruleno, x, result, result_max,\n\t\t\t  weight, weight_max, work,\n\t\t\t  arg_map ? arg_map->args : NULL);\n\tput_workspace(&map->crush_wsm, work);\n\treturn r;\n}\n\nstatic void remove_nonexistent_osds(struct ceph_osdmap *osdmap,\n\t\t\t\t    struct ceph_pg_pool_info *pi,\n\t\t\t\t    struct ceph_osds *set)\n{\n\tint i;\n\n\tif (ceph_can_shift_osds(pi)) {\n\t\tint removed = 0;\n\n\t\t \n\t\tfor (i = 0; i < set->size; i++) {\n\t\t\tif (!ceph_osd_exists(osdmap, set->osds[i])) {\n\t\t\t\tremoved++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (removed)\n\t\t\t\tset->osds[i - removed] = set->osds[i];\n\t\t}\n\t\tset->size -= removed;\n\t} else {\n\t\t \n\t\tfor (i = 0; i < set->size; i++) {\n\t\t\tif (!ceph_osd_exists(osdmap, set->osds[i]))\n\t\t\t\tset->osds[i] = CRUSH_ITEM_NONE;\n\t\t}\n\t}\n}\n\n \nstatic void pg_to_raw_osds(struct ceph_osdmap *osdmap,\n\t\t\t   struct ceph_pg_pool_info *pi,\n\t\t\t   const struct ceph_pg *raw_pgid,\n\t\t\t   struct ceph_osds *raw,\n\t\t\t   u32 *ppps)\n{\n\tu32 pps = raw_pg_to_pps(pi, raw_pgid);\n\tint ruleno;\n\tint len;\n\n\tceph_osds_init(raw);\n\tif (ppps)\n\t\t*ppps = pps;\n\n\truleno = crush_find_rule(osdmap->crush, pi->crush_ruleset, pi->type,\n\t\t\t\t pi->size);\n\tif (ruleno < 0) {\n\t\tpr_err(\"no crush rule: pool %lld ruleset %d type %d size %d\\n\",\n\t\t       pi->id, pi->crush_ruleset, pi->type, pi->size);\n\t\treturn;\n\t}\n\n\tif (pi->size > ARRAY_SIZE(raw->osds)) {\n\t\tpr_err_ratelimited(\"pool %lld ruleset %d type %d too wide: size %d > %zu\\n\",\n\t\t       pi->id, pi->crush_ruleset, pi->type, pi->size,\n\t\t       ARRAY_SIZE(raw->osds));\n\t\treturn;\n\t}\n\n\tlen = do_crush(osdmap, ruleno, pps, raw->osds, pi->size,\n\t\t       osdmap->osd_weight, osdmap->max_osd, pi->id);\n\tif (len < 0) {\n\t\tpr_err(\"error %d from crush rule %d: pool %lld ruleset %d type %d size %d\\n\",\n\t\t       len, ruleno, pi->id, pi->crush_ruleset, pi->type,\n\t\t       pi->size);\n\t\treturn;\n\t}\n\n\traw->size = len;\n\tremove_nonexistent_osds(osdmap, pi, raw);\n}\n\n \nstatic void apply_upmap(struct ceph_osdmap *osdmap,\n\t\t\tconst struct ceph_pg *pgid,\n\t\t\tstruct ceph_osds *raw)\n{\n\tstruct ceph_pg_mapping *pg;\n\tint i, j;\n\n\tpg = lookup_pg_mapping(&osdmap->pg_upmap, pgid);\n\tif (pg) {\n\t\t \n\t\tfor (i = 0; i < pg->pg_upmap.len; i++) {\n\t\t\tint osd = pg->pg_upmap.osds[i];\n\n\t\t\tif (osd != CRUSH_ITEM_NONE &&\n\t\t\t    osd < osdmap->max_osd &&\n\t\t\t    osdmap->osd_weight[osd] == 0) {\n\t\t\t\t \n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tfor (i = 0; i < pg->pg_upmap.len; i++)\n\t\t\traw->osds[i] = pg->pg_upmap.osds[i];\n\t\traw->size = pg->pg_upmap.len;\n\t\t \n\t}\n\n\tpg = lookup_pg_mapping(&osdmap->pg_upmap_items, pgid);\n\tif (pg) {\n\t\t \n\t\tfor (i = 0; i < pg->pg_upmap_items.len; i++) {\n\t\t\tint from = pg->pg_upmap_items.from_to[i][0];\n\t\t\tint to = pg->pg_upmap_items.from_to[i][1];\n\t\t\tint pos = -1;\n\t\t\tbool exists = false;\n\n\t\t\t \n\t\t\tfor (j = 0; j < raw->size; j++) {\n\t\t\t\tint osd = raw->osds[j];\n\n\t\t\t\tif (osd == to) {\n\t\t\t\t\texists = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t \n\t\t\t\tif (osd == from && pos < 0 &&\n\t\t\t\t    !(to != CRUSH_ITEM_NONE &&\n\t\t\t\t      to < osdmap->max_osd &&\n\t\t\t\t      osdmap->osd_weight[to] == 0)) {\n\t\t\t\t\tpos = j;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!exists && pos >= 0)\n\t\t\t\traw->osds[pos] = to;\n\t\t}\n\t}\n}\n\n \nstatic void raw_to_up_osds(struct ceph_osdmap *osdmap,\n\t\t\t   struct ceph_pg_pool_info *pi,\n\t\t\t   struct ceph_osds *set)\n{\n\tint i;\n\n\t \n\tBUG_ON(set->primary != -1);\n\n\tif (ceph_can_shift_osds(pi)) {\n\t\tint removed = 0;\n\n\t\t \n\t\tfor (i = 0; i < set->size; i++) {\n\t\t\tif (ceph_osd_is_down(osdmap, set->osds[i])) {\n\t\t\t\tremoved++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (removed)\n\t\t\t\tset->osds[i - removed] = set->osds[i];\n\t\t}\n\t\tset->size -= removed;\n\t\tif (set->size > 0)\n\t\t\tset->primary = set->osds[0];\n\t} else {\n\t\t \n\t\tfor (i = set->size - 1; i >= 0; i--) {\n\t\t\tif (ceph_osd_is_down(osdmap, set->osds[i]))\n\t\t\t\tset->osds[i] = CRUSH_ITEM_NONE;\n\t\t\telse\n\t\t\t\tset->primary = set->osds[i];\n\t\t}\n\t}\n}\n\nstatic void apply_primary_affinity(struct ceph_osdmap *osdmap,\n\t\t\t\t   struct ceph_pg_pool_info *pi,\n\t\t\t\t   u32 pps,\n\t\t\t\t   struct ceph_osds *up)\n{\n\tint i;\n\tint pos = -1;\n\n\t \n\tif (!osdmap->osd_primary_affinity)\n\t\treturn;\n\n\tfor (i = 0; i < up->size; i++) {\n\t\tint osd = up->osds[i];\n\n\t\tif (osd != CRUSH_ITEM_NONE &&\n\t\t    osdmap->osd_primary_affinity[osd] !=\n\t\t\t\t\tCEPH_OSD_DEFAULT_PRIMARY_AFFINITY) {\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (i == up->size)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < up->size; i++) {\n\t\tint osd = up->osds[i];\n\t\tu32 aff;\n\n\t\tif (osd == CRUSH_ITEM_NONE)\n\t\t\tcontinue;\n\n\t\taff = osdmap->osd_primary_affinity[osd];\n\t\tif (aff < CEPH_OSD_MAX_PRIMARY_AFFINITY &&\n\t\t    (crush_hash32_2(CRUSH_HASH_RJENKINS1,\n\t\t\t\t    pps, osd) >> 16) >= aff) {\n\t\t\t \n\t\t\tif (pos < 0)\n\t\t\t\tpos = i;\n\t\t} else {\n\t\t\tpos = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (pos < 0)\n\t\treturn;\n\n\tup->primary = up->osds[pos];\n\n\tif (ceph_can_shift_osds(pi) && pos > 0) {\n\t\t \n\t\tfor (i = pos; i > 0; i--)\n\t\t\tup->osds[i] = up->osds[i - 1];\n\t\tup->osds[0] = up->primary;\n\t}\n}\n\n \nstatic void get_temp_osds(struct ceph_osdmap *osdmap,\n\t\t\t  struct ceph_pg_pool_info *pi,\n\t\t\t  const struct ceph_pg *pgid,\n\t\t\t  struct ceph_osds *temp)\n{\n\tstruct ceph_pg_mapping *pg;\n\tint i;\n\n\tceph_osds_init(temp);\n\n\t \n\tpg = lookup_pg_mapping(&osdmap->pg_temp, pgid);\n\tif (pg) {\n\t\tfor (i = 0; i < pg->pg_temp.len; i++) {\n\t\t\tif (ceph_osd_is_down(osdmap, pg->pg_temp.osds[i])) {\n\t\t\t\tif (ceph_can_shift_osds(pi))\n\t\t\t\t\tcontinue;\n\n\t\t\t\ttemp->osds[temp->size++] = CRUSH_ITEM_NONE;\n\t\t\t} else {\n\t\t\t\ttemp->osds[temp->size++] = pg->pg_temp.osds[i];\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tfor (i = 0; i < temp->size; i++) {\n\t\t\tif (temp->osds[i] != CRUSH_ITEM_NONE) {\n\t\t\t\ttemp->primary = temp->osds[i];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tpg = lookup_pg_mapping(&osdmap->primary_temp, pgid);\n\tif (pg)\n\t\ttemp->primary = pg->primary_temp.osd;\n}\n\n \nvoid ceph_pg_to_up_acting_osds(struct ceph_osdmap *osdmap,\n\t\t\t       struct ceph_pg_pool_info *pi,\n\t\t\t       const struct ceph_pg *raw_pgid,\n\t\t\t       struct ceph_osds *up,\n\t\t\t       struct ceph_osds *acting)\n{\n\tstruct ceph_pg pgid;\n\tu32 pps;\n\n\tWARN_ON(pi->id != raw_pgid->pool);\n\traw_pg_to_pg(pi, raw_pgid, &pgid);\n\n\tpg_to_raw_osds(osdmap, pi, raw_pgid, up, &pps);\n\tapply_upmap(osdmap, &pgid, up);\n\traw_to_up_osds(osdmap, pi, up);\n\tapply_primary_affinity(osdmap, pi, pps, up);\n\tget_temp_osds(osdmap, pi, &pgid, acting);\n\tif (!acting->size) {\n\t\tmemcpy(acting->osds, up->osds, up->size * sizeof(up->osds[0]));\n\t\tacting->size = up->size;\n\t\tif (acting->primary == -1)\n\t\t\tacting->primary = up->primary;\n\t}\n\tWARN_ON(!osds_valid(up) || !osds_valid(acting));\n}\n\nbool ceph_pg_to_primary_shard(struct ceph_osdmap *osdmap,\n\t\t\t      struct ceph_pg_pool_info *pi,\n\t\t\t      const struct ceph_pg *raw_pgid,\n\t\t\t      struct ceph_spg *spgid)\n{\n\tstruct ceph_pg pgid;\n\tstruct ceph_osds up, acting;\n\tint i;\n\n\tWARN_ON(pi->id != raw_pgid->pool);\n\traw_pg_to_pg(pi, raw_pgid, &pgid);\n\n\tif (ceph_can_shift_osds(pi)) {\n\t\tspgid->pgid = pgid;  \n\t\tspgid->shard = CEPH_SPG_NOSHARD;\n\t\treturn true;\n\t}\n\n\tceph_pg_to_up_acting_osds(osdmap, pi, &pgid, &up, &acting);\n\tfor (i = 0; i < acting.size; i++) {\n\t\tif (acting.osds[i] == acting.primary) {\n\t\t\tspgid->pgid = pgid;  \n\t\t\tspgid->shard = i;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n\n \nint ceph_pg_to_acting_primary(struct ceph_osdmap *osdmap,\n\t\t\t      const struct ceph_pg *raw_pgid)\n{\n\tstruct ceph_pg_pool_info *pi;\n\tstruct ceph_osds up, acting;\n\n\tpi = ceph_pg_pool_by_id(osdmap, raw_pgid->pool);\n\tif (!pi)\n\t\treturn -1;\n\n\tceph_pg_to_up_acting_osds(osdmap, pi, raw_pgid, &up, &acting);\n\treturn acting.primary;\n}\nEXPORT_SYMBOL(ceph_pg_to_acting_primary);\n\nstatic struct crush_loc_node *alloc_crush_loc(size_t type_name_len,\n\t\t\t\t\t      size_t name_len)\n{\n\tstruct crush_loc_node *loc;\n\n\tloc = kmalloc(sizeof(*loc) + type_name_len + name_len + 2, GFP_NOIO);\n\tif (!loc)\n\t\treturn NULL;\n\n\tRB_CLEAR_NODE(&loc->cl_node);\n\treturn loc;\n}\n\nstatic void free_crush_loc(struct crush_loc_node *loc)\n{\n\tWARN_ON(!RB_EMPTY_NODE(&loc->cl_node));\n\n\tkfree(loc);\n}\n\nstatic int crush_loc_compare(const struct crush_loc *loc1,\n\t\t\t     const struct crush_loc *loc2)\n{\n\treturn strcmp(loc1->cl_type_name, loc2->cl_type_name) ?:\n\t       strcmp(loc1->cl_name, loc2->cl_name);\n}\n\nDEFINE_RB_FUNCS2(crush_loc, struct crush_loc_node, cl_loc, crush_loc_compare,\n\t\t RB_BYPTR, const struct crush_loc *, cl_node)\n\n \nint ceph_parse_crush_location(char *crush_location, struct rb_root *locs)\n{\n\tstruct crush_loc_node *loc;\n\tconst char *type_name, *name, *colon;\n\tsize_t type_name_len, name_len;\n\n\tdout(\"%s '%s'\\n\", __func__, crush_location);\n\twhile ((type_name = strsep(&crush_location, \"|\"))) {\n\t\tcolon = strchr(type_name, ':');\n\t\tif (!colon)\n\t\t\treturn -EINVAL;\n\n\t\ttype_name_len = colon - type_name;\n\t\tif (type_name_len == 0)\n\t\t\treturn -EINVAL;\n\n\t\tname = colon + 1;\n\t\tname_len = strlen(name);\n\t\tif (name_len == 0)\n\t\t\treturn -EINVAL;\n\n\t\tloc = alloc_crush_loc(type_name_len, name_len);\n\t\tif (!loc)\n\t\t\treturn -ENOMEM;\n\n\t\tloc->cl_loc.cl_type_name = loc->cl_data;\n\t\tmemcpy(loc->cl_loc.cl_type_name, type_name, type_name_len);\n\t\tloc->cl_loc.cl_type_name[type_name_len] = '\\0';\n\n\t\tloc->cl_loc.cl_name = loc->cl_data + type_name_len + 1;\n\t\tmemcpy(loc->cl_loc.cl_name, name, name_len);\n\t\tloc->cl_loc.cl_name[name_len] = '\\0';\n\n\t\tif (!__insert_crush_loc(locs, loc)) {\n\t\t\tfree_crush_loc(loc);\n\t\t\treturn -EEXIST;\n\t\t}\n\n\t\tdout(\"%s type_name '%s' name '%s'\\n\", __func__,\n\t\t     loc->cl_loc.cl_type_name, loc->cl_loc.cl_name);\n\t}\n\n\treturn 0;\n}\n\nint ceph_compare_crush_locs(struct rb_root *locs1, struct rb_root *locs2)\n{\n\tstruct rb_node *n1 = rb_first(locs1);\n\tstruct rb_node *n2 = rb_first(locs2);\n\tint ret;\n\n\tfor ( ; n1 && n2; n1 = rb_next(n1), n2 = rb_next(n2)) {\n\t\tstruct crush_loc_node *loc1 =\n\t\t    rb_entry(n1, struct crush_loc_node, cl_node);\n\t\tstruct crush_loc_node *loc2 =\n\t\t    rb_entry(n2, struct crush_loc_node, cl_node);\n\n\t\tret = crush_loc_compare(&loc1->cl_loc, &loc2->cl_loc);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (!n1 && n2)\n\t\treturn -1;\n\tif (n1 && !n2)\n\t\treturn 1;\n\treturn 0;\n}\n\nvoid ceph_clear_crush_locs(struct rb_root *locs)\n{\n\twhile (!RB_EMPTY_ROOT(locs)) {\n\t\tstruct crush_loc_node *loc =\n\t\t    rb_entry(rb_first(locs), struct crush_loc_node, cl_node);\n\n\t\terase_crush_loc(locs, loc);\n\t\tfree_crush_loc(loc);\n\t}\n}\n\n \nstatic bool is_valid_crush_name(const char *name)\n{\n\tdo {\n\t\tif (!('a' <= *name && *name <= 'z') &&\n\t\t    !('A' <= *name && *name <= 'Z') &&\n\t\t    !('0' <= *name && *name <= '9') &&\n\t\t    *name != '-' && *name != '_' && *name != '.')\n\t\t\treturn false;\n\t} while (*++name != '\\0');\n\n\treturn true;\n}\n\n \nstatic int get_immediate_parent(struct crush_map *c, int id,\n\t\t\t\tu16 *parent_type_id,\n\t\t\t\tstruct crush_loc *parent_loc)\n{\n\tstruct crush_bucket *b;\n\tstruct crush_name_node *type_cn, *cn;\n\tint i, j;\n\n\tfor (i = 0; i < c->max_buckets; i++) {\n\t\tb = c->buckets[i];\n\t\tif (!b)\n\t\t\tcontinue;\n\n\t\t \n\t\tcn = lookup_crush_name(&c->names, b->id);\n\t\tif (!cn || !is_valid_crush_name(cn->cn_name))\n\t\t\tcontinue;\n\n\t\tfor (j = 0; j < b->size; j++) {\n\t\t\tif (b->items[j] != id)\n\t\t\t\tcontinue;\n\n\t\t\t*parent_type_id = b->type;\n\t\t\ttype_cn = lookup_crush_name(&c->type_names, b->type);\n\t\t\tparent_loc->cl_type_name = type_cn->cn_name;\n\t\t\tparent_loc->cl_name = cn->cn_name;\n\t\t\treturn b->id;\n\t\t}\n\t}\n\n\treturn 0;   \n}\n\n \nint ceph_get_crush_locality(struct ceph_osdmap *osdmap, int id,\n\t\t\t    struct rb_root *locs)\n{\n\tstruct crush_loc loc;\n\tu16 type_id;\n\n\t \n\tfor (;;) {\n\t\tid = get_immediate_parent(osdmap->crush, id, &type_id, &loc);\n\t\tif (id >= 0)\n\t\t\treturn -1;   \n\n\t\tif (lookup_crush_loc(locs, &loc))\n\t\t\treturn type_id;\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}