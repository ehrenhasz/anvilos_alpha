{
  "module_name": "ip_output.c",
  "hash_id": "0d501906687672a0f3824e38b63ce95f27dc1f60c802c8deaf47429706cfdff0",
  "original_prompt": "Ingested from linux-6.6.14/net/ipv4/ip_output.c",
  "human_readable_source": "\n \n\n#include <linux/uaccess.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/errno.h>\n#include <linux/highmem.h>\n#include <linux/slab.h>\n\n#include <linux/socket.h>\n#include <linux/sockios.h>\n#include <linux/in.h>\n#include <linux/inet.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/proc_fs.h>\n#include <linux/stat.h>\n#include <linux/init.h>\n\n#include <net/snmp.h>\n#include <net/ip.h>\n#include <net/protocol.h>\n#include <net/route.h>\n#include <net/xfrm.h>\n#include <linux/skbuff.h>\n#include <net/sock.h>\n#include <net/arp.h>\n#include <net/icmp.h>\n#include <net/checksum.h>\n#include <net/gso.h>\n#include <net/inetpeer.h>\n#include <net/inet_ecn.h>\n#include <net/lwtunnel.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/igmp.h>\n#include <linux/netfilter_ipv4.h>\n#include <linux/netfilter_bridge.h>\n#include <linux/netlink.h>\n#include <linux/tcp.h>\n\nstatic int\nip_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,\n\t    unsigned int mtu,\n\t    int (*output)(struct net *, struct sock *, struct sk_buff *));\n\n \nvoid ip_send_check(struct iphdr *iph)\n{\n\tiph->check = 0;\n\tiph->check = ip_fast_csum((unsigned char *)iph, iph->ihl);\n}\nEXPORT_SYMBOL(ip_send_check);\n\nint __ip_local_out(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tstruct iphdr *iph = ip_hdr(skb);\n\n\tiph_set_totlen(iph, skb->len);\n\tip_send_check(iph);\n\n\t \n\tskb = l3mdev_ip_out(sk, skb);\n\tif (unlikely(!skb))\n\t\treturn 0;\n\n\tskb->protocol = htons(ETH_P_IP);\n\n\treturn nf_hook(NFPROTO_IPV4, NF_INET_LOCAL_OUT,\n\t\t       net, sk, skb, NULL, skb_dst(skb)->dev,\n\t\t       dst_output);\n}\n\nint ip_local_out(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tint err;\n\n\terr = __ip_local_out(net, sk, skb);\n\tif (likely(err == 1))\n\t\terr = dst_output(net, sk, skb);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(ip_local_out);\n\nstatic inline int ip_select_ttl(const struct inet_sock *inet,\n\t\t\t\tconst struct dst_entry *dst)\n{\n\tint ttl = READ_ONCE(inet->uc_ttl);\n\n\tif (ttl < 0)\n\t\tttl = ip4_dst_hoplimit(dst);\n\treturn ttl;\n}\n\n \nint ip_build_and_send_pkt(struct sk_buff *skb, const struct sock *sk,\n\t\t\t  __be32 saddr, __be32 daddr, struct ip_options_rcu *opt,\n\t\t\t  u8 tos)\n{\n\tconst struct inet_sock *inet = inet_sk(sk);\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct net *net = sock_net(sk);\n\tstruct iphdr *iph;\n\n\t \n\tskb_push(skb, sizeof(struct iphdr) + (opt ? opt->opt.optlen : 0));\n\tskb_reset_network_header(skb);\n\tiph = ip_hdr(skb);\n\tiph->version  = 4;\n\tiph->ihl      = 5;\n\tiph->tos      = tos;\n\tiph->ttl      = ip_select_ttl(inet, &rt->dst);\n\tiph->daddr    = (opt && opt->opt.srr ? opt->opt.faddr : daddr);\n\tiph->saddr    = saddr;\n\tiph->protocol = sk->sk_protocol;\n\t \n\tif (skb->len <= IPV4_MIN_MTU || ip_dont_fragment(sk, &rt->dst)) {\n\t\tiph->frag_off = htons(IP_DF);\n\t\tiph->id = 0;\n\t} else {\n\t\tiph->frag_off = 0;\n\t\t \n\t\tif (sk->sk_protocol == IPPROTO_TCP)\n\t\t\tiph->id = (__force __be16)get_random_u16();\n\t\telse\n\t\t\t__ip_select_ident(net, iph, 1);\n\t}\n\n\tif (opt && opt->opt.optlen) {\n\t\tiph->ihl += opt->opt.optlen>>2;\n\t\tip_options_build(skb, &opt->opt, daddr, rt);\n\t}\n\n\tskb->priority = READ_ONCE(sk->sk_priority);\n\tif (!skb->mark)\n\t\tskb->mark = READ_ONCE(sk->sk_mark);\n\n\t \n\treturn ip_local_out(net, skb->sk, skb);\n}\nEXPORT_SYMBOL_GPL(ip_build_and_send_pkt);\n\nstatic int ip_finish_output2(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct rtable *rt = (struct rtable *)dst;\n\tstruct net_device *dev = dst->dev;\n\tunsigned int hh_len = LL_RESERVED_SPACE(dev);\n\tstruct neighbour *neigh;\n\tbool is_v6gw = false;\n\n\tif (rt->rt_type == RTN_MULTICAST) {\n\t\tIP_UPD_PO_STATS(net, IPSTATS_MIB_OUTMCAST, skb->len);\n\t} else if (rt->rt_type == RTN_BROADCAST)\n\t\tIP_UPD_PO_STATS(net, IPSTATS_MIB_OUTBCAST, skb->len);\n\n\t \n\tIP_UPD_PO_STATS(net, IPSTATS_MIB_OUT, skb->len);\n\n\tif (unlikely(skb_headroom(skb) < hh_len && dev->header_ops)) {\n\t\tskb = skb_expand_head(skb, hh_len);\n\t\tif (!skb)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tif (lwtunnel_xmit_redirect(dst->lwtstate)) {\n\t\tint res = lwtunnel_xmit(skb);\n\n\t\tif (res != LWTUNNEL_XMIT_CONTINUE)\n\t\t\treturn res;\n\t}\n\n\trcu_read_lock();\n\tneigh = ip_neigh_for_gw(rt, skb, &is_v6gw);\n\tif (!IS_ERR(neigh)) {\n\t\tint res;\n\n\t\tsock_confirm_neigh(skb, neigh);\n\t\t \n\t\tres = neigh_output(neigh, skb, is_v6gw);\n\t\trcu_read_unlock();\n\t\treturn res;\n\t}\n\trcu_read_unlock();\n\n\tnet_dbg_ratelimited(\"%s: No header cache and no neighbour!\\n\",\n\t\t\t    __func__);\n\tkfree_skb_reason(skb, SKB_DROP_REASON_NEIGH_CREATEFAIL);\n\treturn PTR_ERR(neigh);\n}\n\nstatic int ip_finish_output_gso(struct net *net, struct sock *sk,\n\t\t\t\tstruct sk_buff *skb, unsigned int mtu)\n{\n\tstruct sk_buff *segs, *nskb;\n\tnetdev_features_t features;\n\tint ret = 0;\n\n\t \n\tif (skb_gso_validate_network_len(skb, mtu))\n\t\treturn ip_finish_output2(net, sk, skb);\n\n\t \n\tfeatures = netif_skb_features(skb);\n\tBUILD_BUG_ON(sizeof(*IPCB(skb)) > SKB_GSO_CB_OFFSET);\n\tsegs = skb_gso_segment(skb, features & ~NETIF_F_GSO_MASK);\n\tif (IS_ERR_OR_NULL(segs)) {\n\t\tkfree_skb(skb);\n\t\treturn -ENOMEM;\n\t}\n\n\tconsume_skb(skb);\n\n\tskb_list_walk_safe(segs, segs, nskb) {\n\t\tint err;\n\n\t\tskb_mark_not_on_list(segs);\n\t\terr = ip_fragment(net, sk, segs, mtu, ip_finish_output2);\n\n\t\tif (err && ret == 0)\n\t\t\tret = err;\n\t}\n\n\treturn ret;\n}\n\nstatic int __ip_finish_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tunsigned int mtu;\n\n#if defined(CONFIG_NETFILTER) && defined(CONFIG_XFRM)\n\t \n\tif (skb_dst(skb)->xfrm) {\n\t\tIPCB(skb)->flags |= IPSKB_REROUTED;\n\t\treturn dst_output(net, sk, skb);\n\t}\n#endif\n\tmtu = ip_skb_dst_mtu(sk, skb);\n\tif (skb_is_gso(skb))\n\t\treturn ip_finish_output_gso(net, sk, skb, mtu);\n\n\tif (skb->len > mtu || IPCB(skb)->frag_max_size)\n\t\treturn ip_fragment(net, sk, skb, mtu, ip_finish_output2);\n\n\treturn ip_finish_output2(net, sk, skb);\n}\n\nstatic int ip_finish_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tint ret;\n\n\tret = BPF_CGROUP_RUN_PROG_INET_EGRESS(sk, skb);\n\tswitch (ret) {\n\tcase NET_XMIT_SUCCESS:\n\t\treturn __ip_finish_output(net, sk, skb);\n\tcase NET_XMIT_CN:\n\t\treturn __ip_finish_output(net, sk, skb) ? : ret;\n\tdefault:\n\t\tkfree_skb_reason(skb, SKB_DROP_REASON_BPF_CGROUP_EGRESS);\n\t\treturn ret;\n\t}\n}\n\nstatic int ip_mc_finish_output(struct net *net, struct sock *sk,\n\t\t\t       struct sk_buff *skb)\n{\n\tstruct rtable *new_rt;\n\tbool do_cn = false;\n\tint ret, err;\n\n\tret = BPF_CGROUP_RUN_PROG_INET_EGRESS(sk, skb);\n\tswitch (ret) {\n\tcase NET_XMIT_CN:\n\t\tdo_cn = true;\n\t\tfallthrough;\n\tcase NET_XMIT_SUCCESS:\n\t\tbreak;\n\tdefault:\n\t\tkfree_skb_reason(skb, SKB_DROP_REASON_BPF_CGROUP_EGRESS);\n\t\treturn ret;\n\t}\n\n\t \n\tnew_rt = rt_dst_clone(net->loopback_dev, skb_rtable(skb));\n\tif (new_rt) {\n\t\tnew_rt->rt_iif = 0;\n\t\tskb_dst_drop(skb);\n\t\tskb_dst_set(skb, &new_rt->dst);\n\t}\n\n\terr = dev_loopback_xmit(net, sk, skb);\n\treturn (do_cn && err) ? ret : err;\n}\n\nint ip_mc_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct net_device *dev = rt->dst.dev;\n\n\t \n\tskb->dev = dev;\n\tskb->protocol = htons(ETH_P_IP);\n\n\t \n\n\tif (rt->rt_flags&RTCF_MULTICAST) {\n\t\tif (sk_mc_loop(sk)\n#ifdef CONFIG_IP_MROUTE\n\t\t \n\t\t    &&\n\t\t    ((rt->rt_flags & RTCF_LOCAL) ||\n\t\t     !(IPCB(skb)->flags & IPSKB_FORWARDED))\n#endif\n\t\t   ) {\n\t\t\tstruct sk_buff *newskb = skb_clone(skb, GFP_ATOMIC);\n\t\t\tif (newskb)\n\t\t\t\tNF_HOOK(NFPROTO_IPV4, NF_INET_POST_ROUTING,\n\t\t\t\t\tnet, sk, newskb, NULL, newskb->dev,\n\t\t\t\t\tip_mc_finish_output);\n\t\t}\n\n\t\t \n\n\t\tif (ip_hdr(skb)->ttl == 0) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (rt->rt_flags&RTCF_BROADCAST) {\n\t\tstruct sk_buff *newskb = skb_clone(skb, GFP_ATOMIC);\n\t\tif (newskb)\n\t\t\tNF_HOOK(NFPROTO_IPV4, NF_INET_POST_ROUTING,\n\t\t\t\tnet, sk, newskb, NULL, newskb->dev,\n\t\t\t\tip_mc_finish_output);\n\t}\n\n\treturn NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING,\n\t\t\t    net, sk, skb, NULL, skb->dev,\n\t\t\t    ip_finish_output,\n\t\t\t    !(IPCB(skb)->flags & IPSKB_REROUTED));\n}\n\nint ip_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tstruct net_device *dev = skb_dst(skb)->dev, *indev = skb->dev;\n\n\tskb->dev = dev;\n\tskb->protocol = htons(ETH_P_IP);\n\n\treturn NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING,\n\t\t\t    net, sk, skb, indev, dev,\n\t\t\t    ip_finish_output,\n\t\t\t    !(IPCB(skb)->flags & IPSKB_REROUTED));\n}\nEXPORT_SYMBOL(ip_output);\n\n \nstatic void ip_copy_addrs(struct iphdr *iph, const struct flowi4 *fl4)\n{\n\tBUILD_BUG_ON(offsetof(typeof(*fl4), daddr) !=\n\t\t     offsetof(typeof(*fl4), saddr) + sizeof(fl4->saddr));\n\n\tiph->saddr = fl4->saddr;\n\tiph->daddr = fl4->daddr;\n}\n\n \nint __ip_queue_xmit(struct sock *sk, struct sk_buff *skb, struct flowi *fl,\n\t\t    __u8 tos)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tstruct ip_options_rcu *inet_opt;\n\tstruct flowi4 *fl4;\n\tstruct rtable *rt;\n\tstruct iphdr *iph;\n\tint res;\n\n\t \n\trcu_read_lock();\n\tinet_opt = rcu_dereference(inet->inet_opt);\n\tfl4 = &fl->u.ip4;\n\trt = skb_rtable(skb);\n\tif (rt)\n\t\tgoto packet_routed;\n\n\t \n\trt = (struct rtable *)__sk_dst_check(sk, 0);\n\tif (!rt) {\n\t\t__be32 daddr;\n\n\t\t \n\t\tdaddr = inet->inet_daddr;\n\t\tif (inet_opt && inet_opt->opt.srr)\n\t\t\tdaddr = inet_opt->opt.faddr;\n\n\t\t \n\t\trt = ip_route_output_ports(net, fl4, sk,\n\t\t\t\t\t   daddr, inet->inet_saddr,\n\t\t\t\t\t   inet->inet_dport,\n\t\t\t\t\t   inet->inet_sport,\n\t\t\t\t\t   sk->sk_protocol,\n\t\t\t\t\t   RT_CONN_FLAGS_TOS(sk, tos),\n\t\t\t\t\t   sk->sk_bound_dev_if);\n\t\tif (IS_ERR(rt))\n\t\t\tgoto no_route;\n\t\tsk_setup_caps(sk, &rt->dst);\n\t}\n\tskb_dst_set_noref(skb, &rt->dst);\n\npacket_routed:\n\tif (inet_opt && inet_opt->opt.is_strictroute && rt->rt_uses_gateway)\n\t\tgoto no_route;\n\n\t \n\tskb_push(skb, sizeof(struct iphdr) + (inet_opt ? inet_opt->opt.optlen : 0));\n\tskb_reset_network_header(skb);\n\tiph = ip_hdr(skb);\n\t*((__be16 *)iph) = htons((4 << 12) | (5 << 8) | (tos & 0xff));\n\tif (ip_dont_fragment(sk, &rt->dst) && !skb->ignore_df)\n\t\tiph->frag_off = htons(IP_DF);\n\telse\n\t\tiph->frag_off = 0;\n\tiph->ttl      = ip_select_ttl(inet, &rt->dst);\n\tiph->protocol = sk->sk_protocol;\n\tip_copy_addrs(iph, fl4);\n\n\t \n\n\tif (inet_opt && inet_opt->opt.optlen) {\n\t\tiph->ihl += inet_opt->opt.optlen >> 2;\n\t\tip_options_build(skb, &inet_opt->opt, inet->inet_daddr, rt);\n\t}\n\n\tip_select_ident_segs(net, skb, sk,\n\t\t\t     skb_shinfo(skb)->gso_segs ?: 1);\n\n\t \n\tskb->priority = READ_ONCE(sk->sk_priority);\n\tskb->mark = READ_ONCE(sk->sk_mark);\n\n\tres = ip_local_out(net, sk, skb);\n\trcu_read_unlock();\n\treturn res;\n\nno_route:\n\trcu_read_unlock();\n\tIP_INC_STATS(net, IPSTATS_MIB_OUTNOROUTES);\n\tkfree_skb_reason(skb, SKB_DROP_REASON_IP_OUTNOROUTES);\n\treturn -EHOSTUNREACH;\n}\nEXPORT_SYMBOL(__ip_queue_xmit);\n\nint ip_queue_xmit(struct sock *sk, struct sk_buff *skb, struct flowi *fl)\n{\n\treturn __ip_queue_xmit(sk, skb, fl, inet_sk(sk)->tos);\n}\nEXPORT_SYMBOL(ip_queue_xmit);\n\nstatic void ip_copy_metadata(struct sk_buff *to, struct sk_buff *from)\n{\n\tto->pkt_type = from->pkt_type;\n\tto->priority = from->priority;\n\tto->protocol = from->protocol;\n\tto->skb_iif = from->skb_iif;\n\tskb_dst_drop(to);\n\tskb_dst_copy(to, from);\n\tto->dev = from->dev;\n\tto->mark = from->mark;\n\n\tskb_copy_hash(to, from);\n\n#ifdef CONFIG_NET_SCHED\n\tto->tc_index = from->tc_index;\n#endif\n\tnf_copy(to, from);\n\tskb_ext_copy(to, from);\n#if IS_ENABLED(CONFIG_IP_VS)\n\tto->ipvs_property = from->ipvs_property;\n#endif\n\tskb_copy_secmark(to, from);\n}\n\nstatic int ip_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,\n\t\t       unsigned int mtu,\n\t\t       int (*output)(struct net *, struct sock *, struct sk_buff *))\n{\n\tstruct iphdr *iph = ip_hdr(skb);\n\n\tif ((iph->frag_off & htons(IP_DF)) == 0)\n\t\treturn ip_do_fragment(net, sk, skb, output);\n\n\tif (unlikely(!skb->ignore_df ||\n\t\t     (IPCB(skb)->frag_max_size &&\n\t\t      IPCB(skb)->frag_max_size > mtu))) {\n\t\tIP_INC_STATS(net, IPSTATS_MIB_FRAGFAILS);\n\t\ticmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED,\n\t\t\t  htonl(mtu));\n\t\tkfree_skb(skb);\n\t\treturn -EMSGSIZE;\n\t}\n\n\treturn ip_do_fragment(net, sk, skb, output);\n}\n\nvoid ip_fraglist_init(struct sk_buff *skb, struct iphdr *iph,\n\t\t      unsigned int hlen, struct ip_fraglist_iter *iter)\n{\n\tunsigned int first_len = skb_pagelen(skb);\n\n\titer->frag = skb_shinfo(skb)->frag_list;\n\tskb_frag_list_init(skb);\n\n\titer->offset = 0;\n\titer->iph = iph;\n\titer->hlen = hlen;\n\n\tskb->data_len = first_len - skb_headlen(skb);\n\tskb->len = first_len;\n\tiph->tot_len = htons(first_len);\n\tiph->frag_off = htons(IP_MF);\n\tip_send_check(iph);\n}\nEXPORT_SYMBOL(ip_fraglist_init);\n\nvoid ip_fraglist_prepare(struct sk_buff *skb, struct ip_fraglist_iter *iter)\n{\n\tunsigned int hlen = iter->hlen;\n\tstruct iphdr *iph = iter->iph;\n\tstruct sk_buff *frag;\n\n\tfrag = iter->frag;\n\tfrag->ip_summed = CHECKSUM_NONE;\n\tskb_reset_transport_header(frag);\n\t__skb_push(frag, hlen);\n\tskb_reset_network_header(frag);\n\tmemcpy(skb_network_header(frag), iph, hlen);\n\titer->iph = ip_hdr(frag);\n\tiph = iter->iph;\n\tiph->tot_len = htons(frag->len);\n\tip_copy_metadata(frag, skb);\n\titer->offset += skb->len - hlen;\n\tiph->frag_off = htons(iter->offset >> 3);\n\tif (frag->next)\n\t\tiph->frag_off |= htons(IP_MF);\n\t \n\tip_send_check(iph);\n}\nEXPORT_SYMBOL(ip_fraglist_prepare);\n\nvoid ip_frag_init(struct sk_buff *skb, unsigned int hlen,\n\t\t  unsigned int ll_rs, unsigned int mtu, bool DF,\n\t\t  struct ip_frag_state *state)\n{\n\tstruct iphdr *iph = ip_hdr(skb);\n\n\tstate->DF = DF;\n\tstate->hlen = hlen;\n\tstate->ll_rs = ll_rs;\n\tstate->mtu = mtu;\n\n\tstate->left = skb->len - hlen;\t \n\tstate->ptr = hlen;\t\t \n\n\tstate->offset = (ntohs(iph->frag_off) & IP_OFFSET) << 3;\n\tstate->not_last_frag = iph->frag_off & htons(IP_MF);\n}\nEXPORT_SYMBOL(ip_frag_init);\n\nstatic void ip_frag_ipcb(struct sk_buff *from, struct sk_buff *to,\n\t\t\t bool first_frag)\n{\n\t \n\tIPCB(to)->flags = IPCB(from)->flags;\n\n\t \n\tif (first_frag)\n\t\tip_options_fragment(from);\n}\n\nstruct sk_buff *ip_frag_next(struct sk_buff *skb, struct ip_frag_state *state)\n{\n\tunsigned int len = state->left;\n\tstruct sk_buff *skb2;\n\tstruct iphdr *iph;\n\n\t \n\tif (len > state->mtu)\n\t\tlen = state->mtu;\n\t \n\tif (len < state->left)\t{\n\t\tlen &= ~7;\n\t}\n\n\t \n\tskb2 = alloc_skb(len + state->hlen + state->ll_rs, GFP_ATOMIC);\n\tif (!skb2)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t \n\n\tip_copy_metadata(skb2, skb);\n\tskb_reserve(skb2, state->ll_rs);\n\tskb_put(skb2, len + state->hlen);\n\tskb_reset_network_header(skb2);\n\tskb2->transport_header = skb2->network_header + state->hlen;\n\n\t \n\n\tif (skb->sk)\n\t\tskb_set_owner_w(skb2, skb->sk);\n\n\t \n\n\tskb_copy_from_linear_data(skb, skb_network_header(skb2), state->hlen);\n\n\t \n\tif (skb_copy_bits(skb, state->ptr, skb_transport_header(skb2), len))\n\t\tBUG();\n\tstate->left -= len;\n\n\t \n\tiph = ip_hdr(skb2);\n\tiph->frag_off = htons((state->offset >> 3));\n\tif (state->DF)\n\t\tiph->frag_off |= htons(IP_DF);\n\n\t \n\tif (state->left > 0 || state->not_last_frag)\n\t\tiph->frag_off |= htons(IP_MF);\n\tstate->ptr += len;\n\tstate->offset += len;\n\n\tiph->tot_len = htons(len + state->hlen);\n\n\tip_send_check(iph);\n\n\treturn skb2;\n}\nEXPORT_SYMBOL(ip_frag_next);\n\n \n\nint ip_do_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,\n\t\t   int (*output)(struct net *, struct sock *, struct sk_buff *))\n{\n\tstruct iphdr *iph;\n\tstruct sk_buff *skb2;\n\tbool mono_delivery_time = skb->mono_delivery_time;\n\tstruct rtable *rt = skb_rtable(skb);\n\tunsigned int mtu, hlen, ll_rs;\n\tstruct ip_fraglist_iter iter;\n\tktime_t tstamp = skb->tstamp;\n\tstruct ip_frag_state state;\n\tint err = 0;\n\n\t \n\tif (skb->ip_summed == CHECKSUM_PARTIAL &&\n\t    (err = skb_checksum_help(skb)))\n\t\tgoto fail;\n\n\t \n\n\tiph = ip_hdr(skb);\n\n\tmtu = ip_skb_dst_mtu(sk, skb);\n\tif (IPCB(skb)->frag_max_size && IPCB(skb)->frag_max_size < mtu)\n\t\tmtu = IPCB(skb)->frag_max_size;\n\n\t \n\n\thlen = iph->ihl * 4;\n\tmtu = mtu - hlen;\t \n\tIPCB(skb)->flags |= IPSKB_FRAG_COMPLETE;\n\tll_rs = LL_RESERVED_SPACE(rt->dst.dev);\n\n\t \n\tif (skb_has_frag_list(skb)) {\n\t\tstruct sk_buff *frag, *frag2;\n\t\tunsigned int first_len = skb_pagelen(skb);\n\n\t\tif (first_len - hlen > mtu ||\n\t\t    ((first_len - hlen) & 7) ||\n\t\t    ip_is_fragment(iph) ||\n\t\t    skb_cloned(skb) ||\n\t\t    skb_headroom(skb) < ll_rs)\n\t\t\tgoto slow_path;\n\n\t\tskb_walk_frags(skb, frag) {\n\t\t\t \n\t\t\tif (frag->len > mtu ||\n\t\t\t    ((frag->len & 7) && frag->next) ||\n\t\t\t    skb_headroom(frag) < hlen + ll_rs)\n\t\t\t\tgoto slow_path_clean;\n\n\t\t\t \n\t\t\tif (skb_shared(frag))\n\t\t\t\tgoto slow_path_clean;\n\n\t\t\tBUG_ON(frag->sk);\n\t\t\tif (skb->sk) {\n\t\t\t\tfrag->sk = skb->sk;\n\t\t\t\tfrag->destructor = sock_wfree;\n\t\t\t}\n\t\t\tskb->truesize -= frag->truesize;\n\t\t}\n\n\t\t \n\t\tip_fraglist_init(skb, iph, hlen, &iter);\n\n\t\tfor (;;) {\n\t\t\t \n\t\t\tif (iter.frag) {\n\t\t\t\tbool first_frag = (iter.offset == 0);\n\n\t\t\t\tIPCB(iter.frag)->flags = IPCB(skb)->flags;\n\t\t\t\tip_fraglist_prepare(skb, &iter);\n\t\t\t\tif (first_frag && IPCB(skb)->opt.optlen) {\n\t\t\t\t\t \n\t\t\t\t\tIPCB(iter.frag)->opt.optlen =\n\t\t\t\t\t\tIPCB(skb)->opt.optlen;\n\t\t\t\t\tip_options_fragment(iter.frag);\n\t\t\t\t\tip_send_check(iter.iph);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tskb_set_delivery_time(skb, tstamp, mono_delivery_time);\n\t\t\terr = output(net, sk, skb);\n\n\t\t\tif (!err)\n\t\t\t\tIP_INC_STATS(net, IPSTATS_MIB_FRAGCREATES);\n\t\t\tif (err || !iter.frag)\n\t\t\t\tbreak;\n\n\t\t\tskb = ip_fraglist_next(&iter);\n\t\t}\n\n\t\tif (err == 0) {\n\t\t\tIP_INC_STATS(net, IPSTATS_MIB_FRAGOKS);\n\t\t\treturn 0;\n\t\t}\n\n\t\tkfree_skb_list(iter.frag);\n\n\t\tIP_INC_STATS(net, IPSTATS_MIB_FRAGFAILS);\n\t\treturn err;\n\nslow_path_clean:\n\t\tskb_walk_frags(skb, frag2) {\n\t\t\tif (frag2 == frag)\n\t\t\t\tbreak;\n\t\t\tfrag2->sk = NULL;\n\t\t\tfrag2->destructor = NULL;\n\t\t\tskb->truesize += frag2->truesize;\n\t\t}\n\t}\n\nslow_path:\n\t \n\n\tip_frag_init(skb, hlen, ll_rs, mtu, IPCB(skb)->flags & IPSKB_FRAG_PMTU,\n\t\t     &state);\n\n\t \n\n\twhile (state.left > 0) {\n\t\tbool first_frag = (state.offset == 0);\n\n\t\tskb2 = ip_frag_next(skb, &state);\n\t\tif (IS_ERR(skb2)) {\n\t\t\terr = PTR_ERR(skb2);\n\t\t\tgoto fail;\n\t\t}\n\t\tip_frag_ipcb(skb, skb2, first_frag);\n\n\t\t \n\t\tskb_set_delivery_time(skb2, tstamp, mono_delivery_time);\n\t\terr = output(net, sk, skb2);\n\t\tif (err)\n\t\t\tgoto fail;\n\n\t\tIP_INC_STATS(net, IPSTATS_MIB_FRAGCREATES);\n\t}\n\tconsume_skb(skb);\n\tIP_INC_STATS(net, IPSTATS_MIB_FRAGOKS);\n\treturn err;\n\nfail:\n\tkfree_skb(skb);\n\tIP_INC_STATS(net, IPSTATS_MIB_FRAGFAILS);\n\treturn err;\n}\nEXPORT_SYMBOL(ip_do_fragment);\n\nint\nip_generic_getfrag(void *from, char *to, int offset, int len, int odd, struct sk_buff *skb)\n{\n\tstruct msghdr *msg = from;\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tif (!copy_from_iter_full(to, len, &msg->msg_iter))\n\t\t\treturn -EFAULT;\n\t} else {\n\t\t__wsum csum = 0;\n\t\tif (!csum_and_copy_from_iter_full(to, len, &csum, &msg->msg_iter))\n\t\t\treturn -EFAULT;\n\t\tskb->csum = csum_block_add(skb->csum, csum, odd);\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(ip_generic_getfrag);\n\nstatic int __ip_append_data(struct sock *sk,\n\t\t\t    struct flowi4 *fl4,\n\t\t\t    struct sk_buff_head *queue,\n\t\t\t    struct inet_cork *cork,\n\t\t\t    struct page_frag *pfrag,\n\t\t\t    int getfrag(void *from, char *to, int offset,\n\t\t\t\t\tint len, int odd, struct sk_buff *skb),\n\t\t\t    void *from, int length, int transhdrlen,\n\t\t\t    unsigned int flags)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ubuf_info *uarg = NULL;\n\tstruct sk_buff *skb;\n\tstruct ip_options *opt = cork->opt;\n\tint hh_len;\n\tint exthdrlen;\n\tint mtu;\n\tint copy;\n\tint err;\n\tint offset = 0;\n\tbool zc = false;\n\tunsigned int maxfraglen, fragheaderlen, maxnonfragsize;\n\tint csummode = CHECKSUM_NONE;\n\tstruct rtable *rt = (struct rtable *)cork->dst;\n\tunsigned int wmem_alloc_delta = 0;\n\tbool paged, extra_uref = false;\n\tu32 tskey = 0;\n\n\tskb = skb_peek_tail(queue);\n\n\texthdrlen = !skb ? rt->dst.header_len : 0;\n\tmtu = cork->gso_size ? IP_MAX_MTU : cork->fragsize;\n\tpaged = !!cork->gso_size;\n\n\tif (cork->tx_flags & SKBTX_ANY_TSTAMP &&\n\t    READ_ONCE(sk->sk_tsflags) & SOF_TIMESTAMPING_OPT_ID)\n\t\ttskey = atomic_inc_return(&sk->sk_tskey) - 1;\n\n\thh_len = LL_RESERVED_SPACE(rt->dst.dev);\n\n\tfragheaderlen = sizeof(struct iphdr) + (opt ? opt->optlen : 0);\n\tmaxfraglen = ((mtu - fragheaderlen) & ~7) + fragheaderlen;\n\tmaxnonfragsize = ip_sk_ignore_df(sk) ? IP_MAX_MTU : mtu;\n\n\tif (cork->length + length > maxnonfragsize - fragheaderlen) {\n\t\tip_local_error(sk, EMSGSIZE, fl4->daddr, inet->inet_dport,\n\t\t\t       mtu - (opt ? opt->optlen : 0));\n\t\treturn -EMSGSIZE;\n\t}\n\n\t \n\tif (transhdrlen &&\n\t    length + fragheaderlen <= mtu &&\n\t    rt->dst.dev->features & (NETIF_F_HW_CSUM | NETIF_F_IP_CSUM) &&\n\t    (!(flags & MSG_MORE) || cork->gso_size) &&\n\t    (!exthdrlen || (rt->dst.dev->features & NETIF_F_HW_ESP_TX_CSUM)))\n\t\tcsummode = CHECKSUM_PARTIAL;\n\n\tif ((flags & MSG_ZEROCOPY) && length) {\n\t\tstruct msghdr *msg = from;\n\n\t\tif (getfrag == ip_generic_getfrag && msg->msg_ubuf) {\n\t\t\tif (skb_zcopy(skb) && msg->msg_ubuf != skb_zcopy(skb))\n\t\t\t\treturn -EINVAL;\n\n\t\t\t \n\t\t\tif ((rt->dst.dev->features & NETIF_F_SG) &&\n\t\t\t    csummode == CHECKSUM_PARTIAL) {\n\t\t\t\tpaged = true;\n\t\t\t\tzc = true;\n\t\t\t\tuarg = msg->msg_ubuf;\n\t\t\t}\n\t\t} else if (sock_flag(sk, SOCK_ZEROCOPY)) {\n\t\t\tuarg = msg_zerocopy_realloc(sk, length, skb_zcopy(skb));\n\t\t\tif (!uarg)\n\t\t\t\treturn -ENOBUFS;\n\t\t\textra_uref = !skb_zcopy(skb);\t \n\t\t\tif (rt->dst.dev->features & NETIF_F_SG &&\n\t\t\t    csummode == CHECKSUM_PARTIAL) {\n\t\t\t\tpaged = true;\n\t\t\t\tzc = true;\n\t\t\t} else {\n\t\t\t\tuarg_to_msgzc(uarg)->zerocopy = 0;\n\t\t\t\tskb_zcopy_set(skb, uarg, &extra_uref);\n\t\t\t}\n\t\t}\n\t} else if ((flags & MSG_SPLICE_PAGES) && length) {\n\t\tif (inet_test_bit(HDRINCL, sk))\n\t\t\treturn -EPERM;\n\t\tif (rt->dst.dev->features & NETIF_F_SG &&\n\t\t    getfrag == ip_generic_getfrag)\n\t\t\t \n\t\t\tpaged = true;\n\t\telse\n\t\t\tflags &= ~MSG_SPLICE_PAGES;\n\t}\n\n\tcork->length += length;\n\n\t \n\n\tif (!skb)\n\t\tgoto alloc_new_skb;\n\n\twhile (length > 0) {\n\t\t \n\t\tcopy = mtu - skb->len;\n\t\tif (copy < length)\n\t\t\tcopy = maxfraglen - skb->len;\n\t\tif (copy <= 0) {\n\t\t\tchar *data;\n\t\t\tunsigned int datalen;\n\t\t\tunsigned int fraglen;\n\t\t\tunsigned int fraggap;\n\t\t\tunsigned int alloclen, alloc_extra;\n\t\t\tunsigned int pagedlen;\n\t\t\tstruct sk_buff *skb_prev;\nalloc_new_skb:\n\t\t\tskb_prev = skb;\n\t\t\tif (skb_prev)\n\t\t\t\tfraggap = skb_prev->len - maxfraglen;\n\t\t\telse\n\t\t\t\tfraggap = 0;\n\n\t\t\t \n\t\t\tdatalen = length + fraggap;\n\t\t\tif (datalen > mtu - fragheaderlen)\n\t\t\t\tdatalen = maxfraglen - fragheaderlen;\n\t\t\tfraglen = datalen + fragheaderlen;\n\t\t\tpagedlen = 0;\n\n\t\t\talloc_extra = hh_len + 15;\n\t\t\talloc_extra += exthdrlen;\n\n\t\t\t \n\t\t\tif (datalen == length + fraggap)\n\t\t\t\talloc_extra += rt->dst.trailer_len;\n\n\t\t\tif ((flags & MSG_MORE) &&\n\t\t\t    !(rt->dst.dev->features&NETIF_F_SG))\n\t\t\t\talloclen = mtu;\n\t\t\telse if (!paged &&\n\t\t\t\t (fraglen + alloc_extra < SKB_MAX_ALLOC ||\n\t\t\t\t  !(rt->dst.dev->features & NETIF_F_SG)))\n\t\t\t\talloclen = fraglen;\n\t\t\telse {\n\t\t\t\talloclen = fragheaderlen + transhdrlen;\n\t\t\t\tpagedlen = datalen - transhdrlen;\n\t\t\t}\n\n\t\t\talloclen += alloc_extra;\n\n\t\t\tif (transhdrlen) {\n\t\t\t\tskb = sock_alloc_send_skb(sk, alloclen,\n\t\t\t\t\t\t(flags & MSG_DONTWAIT), &err);\n\t\t\t} else {\n\t\t\t\tskb = NULL;\n\t\t\t\tif (refcount_read(&sk->sk_wmem_alloc) + wmem_alloc_delta <=\n\t\t\t\t    2 * sk->sk_sndbuf)\n\t\t\t\t\tskb = alloc_skb(alloclen,\n\t\t\t\t\t\t\tsk->sk_allocation);\n\t\t\t\tif (unlikely(!skb))\n\t\t\t\t\terr = -ENOBUFS;\n\t\t\t}\n\t\t\tif (!skb)\n\t\t\t\tgoto error;\n\n\t\t\t \n\t\t\tskb->ip_summed = csummode;\n\t\t\tskb->csum = 0;\n\t\t\tskb_reserve(skb, hh_len);\n\n\t\t\t \n\t\t\tdata = skb_put(skb, fraglen + exthdrlen - pagedlen);\n\t\t\tskb_set_network_header(skb, exthdrlen);\n\t\t\tskb->transport_header = (skb->network_header +\n\t\t\t\t\t\t fragheaderlen);\n\t\t\tdata += fragheaderlen + exthdrlen;\n\n\t\t\tif (fraggap) {\n\t\t\t\tskb->csum = skb_copy_and_csum_bits(\n\t\t\t\t\tskb_prev, maxfraglen,\n\t\t\t\t\tdata + transhdrlen, fraggap);\n\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,\n\t\t\t\t\t\t\t  skb->csum);\n\t\t\t\tdata += fraggap;\n\t\t\t\tpskb_trim_unique(skb_prev, maxfraglen);\n\t\t\t}\n\n\t\t\tcopy = datalen - transhdrlen - fraggap - pagedlen;\n\t\t\t \n\t\t\tif (copy > 0 && getfrag(from, data + transhdrlen, offset, copy, fraggap, skb) < 0) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t} else if (flags & MSG_SPLICE_PAGES) {\n\t\t\t\tcopy = 0;\n\t\t\t}\n\n\t\t\toffset += copy;\n\t\t\tlength -= copy + transhdrlen;\n\t\t\ttranshdrlen = 0;\n\t\t\texthdrlen = 0;\n\t\t\tcsummode = CHECKSUM_NONE;\n\n\t\t\t \n\t\t\tskb_shinfo(skb)->tx_flags = cork->tx_flags;\n\t\t\tcork->tx_flags = 0;\n\t\t\tskb_shinfo(skb)->tskey = tskey;\n\t\t\ttskey = 0;\n\t\t\tskb_zcopy_set(skb, uarg, &extra_uref);\n\n\t\t\tif ((flags & MSG_CONFIRM) && !skb_prev)\n\t\t\t\tskb_set_dst_pending_confirm(skb, 1);\n\n\t\t\t \n\t\t\tif (!skb->destructor) {\n\t\t\t\tskb->destructor = sock_wfree;\n\t\t\t\tskb->sk = sk;\n\t\t\t\twmem_alloc_delta += skb->truesize;\n\t\t\t}\n\t\t\t__skb_queue_tail(queue, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (copy > length)\n\t\t\tcopy = length;\n\n\t\tif (!(rt->dst.dev->features&NETIF_F_SG) &&\n\t\t    skb_tailroom(skb) >= copy) {\n\t\t\tunsigned int off;\n\n\t\t\toff = skb->len;\n\t\t\tif (getfrag(from, skb_put(skb, copy),\n\t\t\t\t\toffset, copy, off, skb) < 0) {\n\t\t\t\t__skb_trim(skb, off);\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t} else if (flags & MSG_SPLICE_PAGES) {\n\t\t\tstruct msghdr *msg = from;\n\n\t\t\terr = -EIO;\n\t\t\tif (WARN_ON_ONCE(copy > msg->msg_iter.count))\n\t\t\t\tgoto error;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0)\n\t\t\t\tgoto error;\n\t\t\tcopy = err;\n\t\t\twmem_alloc_delta += copy;\n\t\t} else if (!zc) {\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\n\t\t\terr = -ENOMEM;\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto error;\n\n\t\t\tskb_zcopy_downgrade_managed(skb);\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\terr = -EMSGSIZE;\n\t\t\t\tif (i == MAX_SKB_FRAGS)\n\t\t\t\t\tgoto error;\n\n\t\t\t\t__skb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t     pfrag->offset, 0);\n\t\t\t\tskb_shinfo(skb)->nr_frags = ++i;\n\t\t\t\tget_page(pfrag->page);\n\t\t\t}\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\t\t\tif (getfrag(from,\n\t\t\t\t    page_address(pfrag->page) + pfrag->offset,\n\t\t\t\t    offset, copy, skb->len, skb) < 0)\n\t\t\t\tgoto error_efault;\n\n\t\t\tpfrag->offset += copy;\n\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\tskb_len_add(skb, copy);\n\t\t\twmem_alloc_delta += copy;\n\t\t} else {\n\t\t\terr = skb_zerocopy_iter_dgram(skb, from, copy);\n\t\t\tif (err < 0)\n\t\t\t\tgoto error;\n\t\t}\n\t\toffset += copy;\n\t\tlength -= copy;\n\t}\n\n\tif (wmem_alloc_delta)\n\t\trefcount_add(wmem_alloc_delta, &sk->sk_wmem_alloc);\n\treturn 0;\n\nerror_efault:\n\terr = -EFAULT;\nerror:\n\tnet_zcopy_put_abort(uarg, extra_uref);\n\tcork->length -= length;\n\tIP_INC_STATS(sock_net(sk), IPSTATS_MIB_OUTDISCARDS);\n\trefcount_add(wmem_alloc_delta, &sk->sk_wmem_alloc);\n\treturn err;\n}\n\nstatic int ip_setup_cork(struct sock *sk, struct inet_cork *cork,\n\t\t\t struct ipcm_cookie *ipc, struct rtable **rtp)\n{\n\tstruct ip_options_rcu *opt;\n\tstruct rtable *rt;\n\n\trt = *rtp;\n\tif (unlikely(!rt))\n\t\treturn -EFAULT;\n\n\t \n\topt = ipc->opt;\n\tif (opt) {\n\t\tif (!cork->opt) {\n\t\t\tcork->opt = kmalloc(sizeof(struct ip_options) + 40,\n\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (unlikely(!cork->opt))\n\t\t\t\treturn -ENOBUFS;\n\t\t}\n\t\tmemcpy(cork->opt, &opt->opt, sizeof(struct ip_options) + opt->opt.optlen);\n\t\tcork->flags |= IPCORK_OPT;\n\t\tcork->addr = ipc->addr;\n\t}\n\n\tcork->fragsize = ip_sk_use_pmtu(sk) ?\n\t\t\t dst_mtu(&rt->dst) : READ_ONCE(rt->dst.dev->mtu);\n\n\tif (!inetdev_valid_mtu(cork->fragsize))\n\t\treturn -ENETUNREACH;\n\n\tcork->gso_size = ipc->gso_size;\n\n\tcork->dst = &rt->dst;\n\t \n\t*rtp = NULL;\n\n\tcork->length = 0;\n\tcork->ttl = ipc->ttl;\n\tcork->tos = ipc->tos;\n\tcork->mark = ipc->sockc.mark;\n\tcork->priority = ipc->priority;\n\tcork->transmit_time = ipc->sockc.transmit_time;\n\tcork->tx_flags = 0;\n\tsock_tx_timestamp(sk, ipc->sockc.tsflags, &cork->tx_flags);\n\n\treturn 0;\n}\n\n \nint ip_append_data(struct sock *sk, struct flowi4 *fl4,\n\t\t   int getfrag(void *from, char *to, int offset, int len,\n\t\t\t       int odd, struct sk_buff *skb),\n\t\t   void *from, int length, int transhdrlen,\n\t\t   struct ipcm_cookie *ipc, struct rtable **rtp,\n\t\t   unsigned int flags)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tint err;\n\n\tif (flags&MSG_PROBE)\n\t\treturn 0;\n\n\tif (skb_queue_empty(&sk->sk_write_queue)) {\n\t\terr = ip_setup_cork(sk, &inet->cork.base, ipc, rtp);\n\t\tif (err)\n\t\t\treturn err;\n\t} else {\n\t\ttranshdrlen = 0;\n\t}\n\n\treturn __ip_append_data(sk, fl4, &sk->sk_write_queue, &inet->cork.base,\n\t\t\t\tsk_page_frag(sk), getfrag,\n\t\t\t\tfrom, length, transhdrlen, flags);\n}\n\nstatic void ip_cork_release(struct inet_cork *cork)\n{\n\tcork->flags &= ~IPCORK_OPT;\n\tkfree(cork->opt);\n\tcork->opt = NULL;\n\tdst_release(cork->dst);\n\tcork->dst = NULL;\n}\n\n \nstruct sk_buff *__ip_make_skb(struct sock *sk,\n\t\t\t      struct flowi4 *fl4,\n\t\t\t      struct sk_buff_head *queue,\n\t\t\t      struct inet_cork *cork)\n{\n\tstruct sk_buff *skb, *tmp_skb;\n\tstruct sk_buff **tail_skb;\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tstruct ip_options *opt = NULL;\n\tstruct rtable *rt = (struct rtable *)cork->dst;\n\tstruct iphdr *iph;\n\t__be16 df = 0;\n\t__u8 ttl;\n\n\tskb = __skb_dequeue(queue);\n\tif (!skb)\n\t\tgoto out;\n\ttail_skb = &(skb_shinfo(skb)->frag_list);\n\n\t \n\tif (skb->data < skb_network_header(skb))\n\t\t__skb_pull(skb, skb_network_offset(skb));\n\twhile ((tmp_skb = __skb_dequeue(queue)) != NULL) {\n\t\t__skb_pull(tmp_skb, skb_network_header_len(skb));\n\t\t*tail_skb = tmp_skb;\n\t\ttail_skb = &(tmp_skb->next);\n\t\tskb->len += tmp_skb->len;\n\t\tskb->data_len += tmp_skb->len;\n\t\tskb->truesize += tmp_skb->truesize;\n\t\ttmp_skb->destructor = NULL;\n\t\ttmp_skb->sk = NULL;\n\t}\n\n\t \n\tskb->ignore_df = ip_sk_ignore_df(sk);\n\n\t \n\tif (inet->pmtudisc == IP_PMTUDISC_DO ||\n\t    inet->pmtudisc == IP_PMTUDISC_PROBE ||\n\t    (skb->len <= dst_mtu(&rt->dst) &&\n\t     ip_dont_fragment(sk, &rt->dst)))\n\t\tdf = htons(IP_DF);\n\n\tif (cork->flags & IPCORK_OPT)\n\t\topt = cork->opt;\n\n\tif (cork->ttl != 0)\n\t\tttl = cork->ttl;\n\telse if (rt->rt_type == RTN_MULTICAST)\n\t\tttl = inet->mc_ttl;\n\telse\n\t\tttl = ip_select_ttl(inet, &rt->dst);\n\n\tiph = ip_hdr(skb);\n\tiph->version = 4;\n\tiph->ihl = 5;\n\tiph->tos = (cork->tos != -1) ? cork->tos : inet->tos;\n\tiph->frag_off = df;\n\tiph->ttl = ttl;\n\tiph->protocol = sk->sk_protocol;\n\tip_copy_addrs(iph, fl4);\n\tip_select_ident(net, skb, sk);\n\n\tif (opt) {\n\t\tiph->ihl += opt->optlen >> 2;\n\t\tip_options_build(skb, opt, cork->addr, rt);\n\t}\n\n\tskb->priority = (cork->tos != -1) ? cork->priority: sk->sk_priority;\n\tskb->mark = cork->mark;\n\tskb->tstamp = cork->transmit_time;\n\t \n\tcork->dst = NULL;\n\tskb_dst_set(skb, &rt->dst);\n\n\tif (iph->protocol == IPPROTO_ICMP) {\n\t\tu8 icmp_type;\n\n\t\t \n\t\tif (sk->sk_type == SOCK_RAW &&\n\t\t    !inet_test_bit(HDRINCL, sk))\n\t\t\ticmp_type = fl4->fl4_icmp_type;\n\t\telse\n\t\t\ticmp_type = icmp_hdr(skb)->type;\n\t\ticmp_out_count(net, icmp_type);\n\t}\n\n\tip_cork_release(cork);\nout:\n\treturn skb;\n}\n\nint ip_send_skb(struct net *net, struct sk_buff *skb)\n{\n\tint err;\n\n\terr = ip_local_out(net, skb->sk, skb);\n\tif (err) {\n\t\tif (err > 0)\n\t\t\terr = net_xmit_errno(err);\n\t\tif (err)\n\t\t\tIP_INC_STATS(net, IPSTATS_MIB_OUTDISCARDS);\n\t}\n\n\treturn err;\n}\n\nint ip_push_pending_frames(struct sock *sk, struct flowi4 *fl4)\n{\n\tstruct sk_buff *skb;\n\n\tskb = ip_finish_skb(sk, fl4);\n\tif (!skb)\n\t\treturn 0;\n\n\t \n\treturn ip_send_skb(sock_net(sk), skb);\n}\n\n \nstatic void __ip_flush_pending_frames(struct sock *sk,\n\t\t\t\t      struct sk_buff_head *queue,\n\t\t\t\t      struct inet_cork *cork)\n{\n\tstruct sk_buff *skb;\n\n\twhile ((skb = __skb_dequeue_tail(queue)) != NULL)\n\t\tkfree_skb(skb);\n\n\tip_cork_release(cork);\n}\n\nvoid ip_flush_pending_frames(struct sock *sk)\n{\n\t__ip_flush_pending_frames(sk, &sk->sk_write_queue, &inet_sk(sk)->cork.base);\n}\n\nstruct sk_buff *ip_make_skb(struct sock *sk,\n\t\t\t    struct flowi4 *fl4,\n\t\t\t    int getfrag(void *from, char *to, int offset,\n\t\t\t\t\tint len, int odd, struct sk_buff *skb),\n\t\t\t    void *from, int length, int transhdrlen,\n\t\t\t    struct ipcm_cookie *ipc, struct rtable **rtp,\n\t\t\t    struct inet_cork *cork, unsigned int flags)\n{\n\tstruct sk_buff_head queue;\n\tint err;\n\n\tif (flags & MSG_PROBE)\n\t\treturn NULL;\n\n\t__skb_queue_head_init(&queue);\n\n\tcork->flags = 0;\n\tcork->addr = 0;\n\tcork->opt = NULL;\n\terr = ip_setup_cork(sk, cork, ipc, rtp);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\terr = __ip_append_data(sk, fl4, &queue, cork,\n\t\t\t       &current->task_frag, getfrag,\n\t\t\t       from, length, transhdrlen, flags);\n\tif (err) {\n\t\t__ip_flush_pending_frames(sk, &queue, cork);\n\t\treturn ERR_PTR(err);\n\t}\n\n\treturn __ip_make_skb(sk, fl4, &queue, cork);\n}\n\n \nstatic int ip_reply_glue_bits(void *dptr, char *to, int offset,\n\t\t\t      int len, int odd, struct sk_buff *skb)\n{\n\t__wsum csum;\n\n\tcsum = csum_partial_copy_nocheck(dptr+offset, to, len);\n\tskb->csum = csum_block_add(skb->csum, csum, odd);\n\treturn 0;\n}\n\n \nvoid ip_send_unicast_reply(struct sock *sk, struct sk_buff *skb,\n\t\t\t   const struct ip_options *sopt,\n\t\t\t   __be32 daddr, __be32 saddr,\n\t\t\t   const struct ip_reply_arg *arg,\n\t\t\t   unsigned int len, u64 transmit_time, u32 txhash)\n{\n\tstruct ip_options_data replyopts;\n\tstruct ipcm_cookie ipc;\n\tstruct flowi4 fl4;\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct net *net = sock_net(sk);\n\tstruct sk_buff *nskb;\n\tint err;\n\tint oif;\n\n\tif (__ip_options_echo(net, &replyopts.opt.opt, skb, sopt))\n\t\treturn;\n\n\tipcm_init(&ipc);\n\tipc.addr = daddr;\n\tipc.sockc.transmit_time = transmit_time;\n\n\tif (replyopts.opt.opt.optlen) {\n\t\tipc.opt = &replyopts.opt;\n\n\t\tif (replyopts.opt.opt.srr)\n\t\t\tdaddr = replyopts.opt.opt.faddr;\n\t}\n\n\toif = arg->bound_dev_if;\n\tif (!oif && netif_index_is_l3_master(net, skb->skb_iif))\n\t\toif = skb->skb_iif;\n\n\tflowi4_init_output(&fl4, oif,\n\t\t\t   IP4_REPLY_MARK(net, skb->mark) ?: sk->sk_mark,\n\t\t\t   RT_TOS(arg->tos),\n\t\t\t   RT_SCOPE_UNIVERSE, ip_hdr(skb)->protocol,\n\t\t\t   ip_reply_arg_flowi_flags(arg),\n\t\t\t   daddr, saddr,\n\t\t\t   tcp_hdr(skb)->source, tcp_hdr(skb)->dest,\n\t\t\t   arg->uid);\n\tsecurity_skb_classify_flow(skb, flowi4_to_flowi_common(&fl4));\n\trt = ip_route_output_flow(net, &fl4, sk);\n\tif (IS_ERR(rt))\n\t\treturn;\n\n\tinet_sk(sk)->tos = arg->tos & ~INET_ECN_MASK;\n\n\tsk->sk_protocol = ip_hdr(skb)->protocol;\n\tsk->sk_bound_dev_if = arg->bound_dev_if;\n\tsk->sk_sndbuf = READ_ONCE(sysctl_wmem_default);\n\tipc.sockc.mark = fl4.flowi4_mark;\n\terr = ip_append_data(sk, &fl4, ip_reply_glue_bits, arg->iov->iov_base,\n\t\t\t     len, 0, &ipc, &rt, MSG_DONTWAIT);\n\tif (unlikely(err)) {\n\t\tip_flush_pending_frames(sk);\n\t\tgoto out;\n\t}\n\n\tnskb = skb_peek(&sk->sk_write_queue);\n\tif (nskb) {\n\t\tif (arg->csumoffset >= 0)\n\t\t\t*((__sum16 *)skb_transport_header(nskb) +\n\t\t\t  arg->csumoffset) = csum_fold(csum_add(nskb->csum,\n\t\t\t\t\t\t\t\targ->csum));\n\t\tnskb->ip_summed = CHECKSUM_NONE;\n\t\tnskb->mono_delivery_time = !!transmit_time;\n\t\tif (txhash)\n\t\t\tskb_set_hash(nskb, txhash, PKT_HASH_TYPE_L4);\n\t\tip_push_pending_frames(sk, &fl4);\n\t}\nout:\n\tip_rt_put(rt);\n}\n\nvoid __init ip_init(void)\n{\n\tip_rt_init();\n\tinet_initpeers();\n\n#if defined(CONFIG_IP_MULTICAST)\n\tigmp_mc_init();\n#endif\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}