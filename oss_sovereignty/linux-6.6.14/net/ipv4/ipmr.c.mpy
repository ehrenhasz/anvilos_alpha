{
  "module_name": "ipmr.c",
  "hash_id": "4bf8dfa9e721651973548ff240a54c21dc2763a6ccab1010efa2414922191dc2",
  "original_prompt": "Ingested from linux-6.6.14/net/ipv4/ipmr.c",
  "human_readable_source": "\n \n\n#include <linux/uaccess.h>\n#include <linux/types.h>\n#include <linux/cache.h>\n#include <linux/capability.h>\n#include <linux/errno.h>\n#include <linux/mm.h>\n#include <linux/kernel.h>\n#include <linux/fcntl.h>\n#include <linux/stat.h>\n#include <linux/socket.h>\n#include <linux/in.h>\n#include <linux/inet.h>\n#include <linux/netdevice.h>\n#include <linux/inetdevice.h>\n#include <linux/igmp.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/mroute.h>\n#include <linux/init.h>\n#include <linux/if_ether.h>\n#include <linux/slab.h>\n#include <net/net_namespace.h>\n#include <net/ip.h>\n#include <net/protocol.h>\n#include <linux/skbuff.h>\n#include <net/route.h>\n#include <net/icmp.h>\n#include <net/udp.h>\n#include <net/raw.h>\n#include <linux/notifier.h>\n#include <linux/if_arp.h>\n#include <linux/netfilter_ipv4.h>\n#include <linux/compat.h>\n#include <linux/export.h>\n#include <linux/rhashtable.h>\n#include <net/ip_tunnels.h>\n#include <net/checksum.h>\n#include <net/netlink.h>\n#include <net/fib_rules.h>\n#include <linux/netconf.h>\n#include <net/rtnh.h>\n\n#include <linux/nospec.h>\n\nstruct ipmr_rule {\n\tstruct fib_rule\t\tcommon;\n};\n\nstruct ipmr_result {\n\tstruct mr_table\t\t*mrt;\n};\n\n \n\nstatic DEFINE_SPINLOCK(mrt_lock);\n\nstatic struct net_device *vif_dev_read(const struct vif_device *vif)\n{\n\treturn rcu_dereference(vif->dev);\n}\n\n \n\n \nstatic DEFINE_SPINLOCK(mfc_unres_lock);\n\n \n\nstatic struct kmem_cache *mrt_cachep __ro_after_init;\n\nstatic struct mr_table *ipmr_new_table(struct net *net, u32 id);\nstatic void ipmr_free_table(struct mr_table *mrt);\n\nstatic void ip_mr_forward(struct net *net, struct mr_table *mrt,\n\t\t\t  struct net_device *dev, struct sk_buff *skb,\n\t\t\t  struct mfc_cache *cache, int local);\nstatic int ipmr_cache_report(const struct mr_table *mrt,\n\t\t\t     struct sk_buff *pkt, vifi_t vifi, int assert);\nstatic void mroute_netlink_event(struct mr_table *mrt, struct mfc_cache *mfc,\n\t\t\t\t int cmd);\nstatic void igmpmsg_netlink_event(const struct mr_table *mrt, struct sk_buff *pkt);\nstatic void mroute_clean_tables(struct mr_table *mrt, int flags);\nstatic void ipmr_expire_process(struct timer_list *t);\n\n#ifdef CONFIG_IP_MROUTE_MULTIPLE_TABLES\n#define ipmr_for_each_table(mrt, net)\t\t\t\t\t\\\n\tlist_for_each_entry_rcu(mrt, &net->ipv4.mr_tables, list,\t\\\n\t\t\t\tlockdep_rtnl_is_held() ||\t\t\\\n\t\t\t\tlist_empty(&net->ipv4.mr_tables))\n\nstatic struct mr_table *ipmr_mr_table_iter(struct net *net,\n\t\t\t\t\t   struct mr_table *mrt)\n{\n\tstruct mr_table *ret;\n\n\tif (!mrt)\n\t\tret = list_entry_rcu(net->ipv4.mr_tables.next,\n\t\t\t\t     struct mr_table, list);\n\telse\n\t\tret = list_entry_rcu(mrt->list.next,\n\t\t\t\t     struct mr_table, list);\n\n\tif (&ret->list == &net->ipv4.mr_tables)\n\t\treturn NULL;\n\treturn ret;\n}\n\nstatic struct mr_table *ipmr_get_table(struct net *net, u32 id)\n{\n\tstruct mr_table *mrt;\n\n\tipmr_for_each_table(mrt, net) {\n\t\tif (mrt->id == id)\n\t\t\treturn mrt;\n\t}\n\treturn NULL;\n}\n\nstatic int ipmr_fib_lookup(struct net *net, struct flowi4 *flp4,\n\t\t\t   struct mr_table **mrt)\n{\n\tint err;\n\tstruct ipmr_result res;\n\tstruct fib_lookup_arg arg = {\n\t\t.result = &res,\n\t\t.flags = FIB_LOOKUP_NOREF,\n\t};\n\n\t \n\tl3mdev_update_flow(net, flowi4_to_flowi(flp4));\n\n\terr = fib_rules_lookup(net->ipv4.mr_rules_ops,\n\t\t\t       flowi4_to_flowi(flp4), 0, &arg);\n\tif (err < 0)\n\t\treturn err;\n\t*mrt = res.mrt;\n\treturn 0;\n}\n\nstatic int ipmr_rule_action(struct fib_rule *rule, struct flowi *flp,\n\t\t\t    int flags, struct fib_lookup_arg *arg)\n{\n\tstruct ipmr_result *res = arg->result;\n\tstruct mr_table *mrt;\n\n\tswitch (rule->action) {\n\tcase FR_ACT_TO_TBL:\n\t\tbreak;\n\tcase FR_ACT_UNREACHABLE:\n\t\treturn -ENETUNREACH;\n\tcase FR_ACT_PROHIBIT:\n\t\treturn -EACCES;\n\tcase FR_ACT_BLACKHOLE:\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\targ->table = fib_rule_get_table(rule, arg);\n\n\tmrt = ipmr_get_table(rule->fr_net, arg->table);\n\tif (!mrt)\n\t\treturn -EAGAIN;\n\tres->mrt = mrt;\n\treturn 0;\n}\n\nstatic int ipmr_rule_match(struct fib_rule *rule, struct flowi *fl, int flags)\n{\n\treturn 1;\n}\n\nstatic int ipmr_rule_configure(struct fib_rule *rule, struct sk_buff *skb,\n\t\t\t       struct fib_rule_hdr *frh, struct nlattr **tb,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\treturn 0;\n}\n\nstatic int ipmr_rule_compare(struct fib_rule *rule, struct fib_rule_hdr *frh,\n\t\t\t     struct nlattr **tb)\n{\n\treturn 1;\n}\n\nstatic int ipmr_rule_fill(struct fib_rule *rule, struct sk_buff *skb,\n\t\t\t  struct fib_rule_hdr *frh)\n{\n\tfrh->dst_len = 0;\n\tfrh->src_len = 0;\n\tfrh->tos     = 0;\n\treturn 0;\n}\n\nstatic const struct fib_rules_ops __net_initconst ipmr_rules_ops_template = {\n\t.family\t\t= RTNL_FAMILY_IPMR,\n\t.rule_size\t= sizeof(struct ipmr_rule),\n\t.addr_size\t= sizeof(u32),\n\t.action\t\t= ipmr_rule_action,\n\t.match\t\t= ipmr_rule_match,\n\t.configure\t= ipmr_rule_configure,\n\t.compare\t= ipmr_rule_compare,\n\t.fill\t\t= ipmr_rule_fill,\n\t.nlgroup\t= RTNLGRP_IPV4_RULE,\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic int __net_init ipmr_rules_init(struct net *net)\n{\n\tstruct fib_rules_ops *ops;\n\tstruct mr_table *mrt;\n\tint err;\n\n\tops = fib_rules_register(&ipmr_rules_ops_template, net);\n\tif (IS_ERR(ops))\n\t\treturn PTR_ERR(ops);\n\n\tINIT_LIST_HEAD(&net->ipv4.mr_tables);\n\n\tmrt = ipmr_new_table(net, RT_TABLE_DEFAULT);\n\tif (IS_ERR(mrt)) {\n\t\terr = PTR_ERR(mrt);\n\t\tgoto err1;\n\t}\n\n\terr = fib_default_rule_add(ops, 0x7fff, RT_TABLE_DEFAULT, 0);\n\tif (err < 0)\n\t\tgoto err2;\n\n\tnet->ipv4.mr_rules_ops = ops;\n\treturn 0;\n\nerr2:\n\trtnl_lock();\n\tipmr_free_table(mrt);\n\trtnl_unlock();\nerr1:\n\tfib_rules_unregister(ops);\n\treturn err;\n}\n\nstatic void __net_exit ipmr_rules_exit(struct net *net)\n{\n\tstruct mr_table *mrt, *next;\n\n\tASSERT_RTNL();\n\tlist_for_each_entry_safe(mrt, next, &net->ipv4.mr_tables, list) {\n\t\tlist_del(&mrt->list);\n\t\tipmr_free_table(mrt);\n\t}\n\tfib_rules_unregister(net->ipv4.mr_rules_ops);\n}\n\nstatic int ipmr_rules_dump(struct net *net, struct notifier_block *nb,\n\t\t\t   struct netlink_ext_ack *extack)\n{\n\treturn fib_rules_dump(net, nb, RTNL_FAMILY_IPMR, extack);\n}\n\nstatic unsigned int ipmr_rules_seq_read(struct net *net)\n{\n\treturn fib_rules_seq_read(net, RTNL_FAMILY_IPMR);\n}\n\nbool ipmr_rule_default(const struct fib_rule *rule)\n{\n\treturn fib_rule_matchall(rule) && rule->table == RT_TABLE_DEFAULT;\n}\nEXPORT_SYMBOL(ipmr_rule_default);\n#else\n#define ipmr_for_each_table(mrt, net) \\\n\tfor (mrt = net->ipv4.mrt; mrt; mrt = NULL)\n\nstatic struct mr_table *ipmr_mr_table_iter(struct net *net,\n\t\t\t\t\t   struct mr_table *mrt)\n{\n\tif (!mrt)\n\t\treturn net->ipv4.mrt;\n\treturn NULL;\n}\n\nstatic struct mr_table *ipmr_get_table(struct net *net, u32 id)\n{\n\treturn net->ipv4.mrt;\n}\n\nstatic int ipmr_fib_lookup(struct net *net, struct flowi4 *flp4,\n\t\t\t   struct mr_table **mrt)\n{\n\t*mrt = net->ipv4.mrt;\n\treturn 0;\n}\n\nstatic int __net_init ipmr_rules_init(struct net *net)\n{\n\tstruct mr_table *mrt;\n\n\tmrt = ipmr_new_table(net, RT_TABLE_DEFAULT);\n\tif (IS_ERR(mrt))\n\t\treturn PTR_ERR(mrt);\n\tnet->ipv4.mrt = mrt;\n\treturn 0;\n}\n\nstatic void __net_exit ipmr_rules_exit(struct net *net)\n{\n\tASSERT_RTNL();\n\tipmr_free_table(net->ipv4.mrt);\n\tnet->ipv4.mrt = NULL;\n}\n\nstatic int ipmr_rules_dump(struct net *net, struct notifier_block *nb,\n\t\t\t   struct netlink_ext_ack *extack)\n{\n\treturn 0;\n}\n\nstatic unsigned int ipmr_rules_seq_read(struct net *net)\n{\n\treturn 0;\n}\n\nbool ipmr_rule_default(const struct fib_rule *rule)\n{\n\treturn true;\n}\nEXPORT_SYMBOL(ipmr_rule_default);\n#endif\n\nstatic inline int ipmr_hash_cmp(struct rhashtable_compare_arg *arg,\n\t\t\t\tconst void *ptr)\n{\n\tconst struct mfc_cache_cmp_arg *cmparg = arg->key;\n\tconst struct mfc_cache *c = ptr;\n\n\treturn cmparg->mfc_mcastgrp != c->mfc_mcastgrp ||\n\t       cmparg->mfc_origin != c->mfc_origin;\n}\n\nstatic const struct rhashtable_params ipmr_rht_params = {\n\t.head_offset = offsetof(struct mr_mfc, mnode),\n\t.key_offset = offsetof(struct mfc_cache, cmparg),\n\t.key_len = sizeof(struct mfc_cache_cmp_arg),\n\t.nelem_hint = 3,\n\t.obj_cmpfn = ipmr_hash_cmp,\n\t.automatic_shrinking = true,\n};\n\nstatic void ipmr_new_table_set(struct mr_table *mrt,\n\t\t\t       struct net *net)\n{\n#ifdef CONFIG_IP_MROUTE_MULTIPLE_TABLES\n\tlist_add_tail_rcu(&mrt->list, &net->ipv4.mr_tables);\n#endif\n}\n\nstatic struct mfc_cache_cmp_arg ipmr_mr_table_ops_cmparg_any = {\n\t.mfc_mcastgrp = htonl(INADDR_ANY),\n\t.mfc_origin = htonl(INADDR_ANY),\n};\n\nstatic struct mr_table_ops ipmr_mr_table_ops = {\n\t.rht_params = &ipmr_rht_params,\n\t.cmparg_any = &ipmr_mr_table_ops_cmparg_any,\n};\n\nstatic struct mr_table *ipmr_new_table(struct net *net, u32 id)\n{\n\tstruct mr_table *mrt;\n\n\t \n\tif (id != RT_TABLE_DEFAULT && id >= 1000000000)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tmrt = ipmr_get_table(net, id);\n\tif (mrt)\n\t\treturn mrt;\n\n\treturn mr_table_alloc(net, id, &ipmr_mr_table_ops,\n\t\t\t      ipmr_expire_process, ipmr_new_table_set);\n}\n\nstatic void ipmr_free_table(struct mr_table *mrt)\n{\n\ttimer_shutdown_sync(&mrt->ipmr_expire_timer);\n\tmroute_clean_tables(mrt, MRT_FLUSH_VIFS | MRT_FLUSH_VIFS_STATIC |\n\t\t\t\t MRT_FLUSH_MFC | MRT_FLUSH_MFC_STATIC);\n\trhltable_destroy(&mrt->mfc_hash);\n\tkfree(mrt);\n}\n\n \n\n \nstatic bool ipmr_init_vif_indev(const struct net_device *dev)\n{\n\tstruct in_device *in_dev;\n\n\tASSERT_RTNL();\n\n\tin_dev = __in_dev_get_rtnl(dev);\n\tif (!in_dev)\n\t\treturn false;\n\tipv4_devconf_setall(in_dev);\n\tneigh_parms_data_state_setall(in_dev->arp_parms);\n\tIPV4_DEVCONF(in_dev->cnf, RP_FILTER) = 0;\n\n\treturn true;\n}\n\nstatic struct net_device *ipmr_new_tunnel(struct net *net, struct vifctl *v)\n{\n\tstruct net_device *tunnel_dev, *new_dev;\n\tstruct ip_tunnel_parm p = { };\n\tint err;\n\n\ttunnel_dev = __dev_get_by_name(net, \"tunl0\");\n\tif (!tunnel_dev)\n\t\tgoto out;\n\n\tp.iph.daddr = v->vifc_rmt_addr.s_addr;\n\tp.iph.saddr = v->vifc_lcl_addr.s_addr;\n\tp.iph.version = 4;\n\tp.iph.ihl = 5;\n\tp.iph.protocol = IPPROTO_IPIP;\n\tsprintf(p.name, \"dvmrp%d\", v->vifc_vifi);\n\n\tif (!tunnel_dev->netdev_ops->ndo_tunnel_ctl)\n\t\tgoto out;\n\terr = tunnel_dev->netdev_ops->ndo_tunnel_ctl(tunnel_dev, &p,\n\t\t\tSIOCADDTUNNEL);\n\tif (err)\n\t\tgoto out;\n\n\tnew_dev = __dev_get_by_name(net, p.name);\n\tif (!new_dev)\n\t\tgoto out;\n\n\tnew_dev->flags |= IFF_MULTICAST;\n\tif (!ipmr_init_vif_indev(new_dev))\n\t\tgoto out_unregister;\n\tif (dev_open(new_dev, NULL))\n\t\tgoto out_unregister;\n\tdev_hold(new_dev);\n\terr = dev_set_allmulti(new_dev, 1);\n\tif (err) {\n\t\tdev_close(new_dev);\n\t\ttunnel_dev->netdev_ops->ndo_tunnel_ctl(tunnel_dev, &p,\n\t\t\t\tSIOCDELTUNNEL);\n\t\tdev_put(new_dev);\n\t\tnew_dev = ERR_PTR(err);\n\t}\n\treturn new_dev;\n\nout_unregister:\n\tunregister_netdevice(new_dev);\nout:\n\treturn ERR_PTR(-ENOBUFS);\n}\n\n#if defined(CONFIG_IP_PIMSM_V1) || defined(CONFIG_IP_PIMSM_V2)\nstatic netdev_tx_t reg_vif_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct net *net = dev_net(dev);\n\tstruct mr_table *mrt;\n\tstruct flowi4 fl4 = {\n\t\t.flowi4_oif\t= dev->ifindex,\n\t\t.flowi4_iif\t= skb->skb_iif ? : LOOPBACK_IFINDEX,\n\t\t.flowi4_mark\t= skb->mark,\n\t};\n\tint err;\n\n\terr = ipmr_fib_lookup(net, &fl4, &mrt);\n\tif (err < 0) {\n\t\tkfree_skb(skb);\n\t\treturn err;\n\t}\n\n\tDEV_STATS_ADD(dev, tx_bytes, skb->len);\n\tDEV_STATS_INC(dev, tx_packets);\n\trcu_read_lock();\n\n\t \n\tipmr_cache_report(mrt, skb, READ_ONCE(mrt->mroute_reg_vif_num),\n\t\t\t  IGMPMSG_WHOLEPKT);\n\n\trcu_read_unlock();\n\tkfree_skb(skb);\n\treturn NETDEV_TX_OK;\n}\n\nstatic int reg_vif_get_iflink(const struct net_device *dev)\n{\n\treturn 0;\n}\n\nstatic const struct net_device_ops reg_vif_netdev_ops = {\n\t.ndo_start_xmit\t= reg_vif_xmit,\n\t.ndo_get_iflink = reg_vif_get_iflink,\n};\n\nstatic void reg_vif_setup(struct net_device *dev)\n{\n\tdev->type\t\t= ARPHRD_PIMREG;\n\tdev->mtu\t\t= ETH_DATA_LEN - sizeof(struct iphdr) - 8;\n\tdev->flags\t\t= IFF_NOARP;\n\tdev->netdev_ops\t\t= &reg_vif_netdev_ops;\n\tdev->needs_free_netdev\t= true;\n\tdev->features\t\t|= NETIF_F_NETNS_LOCAL;\n}\n\nstatic struct net_device *ipmr_reg_vif(struct net *net, struct mr_table *mrt)\n{\n\tstruct net_device *dev;\n\tchar name[IFNAMSIZ];\n\n\tif (mrt->id == RT_TABLE_DEFAULT)\n\t\tsprintf(name, \"pimreg\");\n\telse\n\t\tsprintf(name, \"pimreg%u\", mrt->id);\n\n\tdev = alloc_netdev(0, name, NET_NAME_UNKNOWN, reg_vif_setup);\n\n\tif (!dev)\n\t\treturn NULL;\n\n\tdev_net_set(dev, net);\n\n\tif (register_netdevice(dev)) {\n\t\tfree_netdev(dev);\n\t\treturn NULL;\n\t}\n\n\tif (!ipmr_init_vif_indev(dev))\n\t\tgoto failure;\n\tif (dev_open(dev, NULL))\n\t\tgoto failure;\n\n\tdev_hold(dev);\n\n\treturn dev;\n\nfailure:\n\tunregister_netdevice(dev);\n\treturn NULL;\n}\n\n \nstatic int __pim_rcv(struct mr_table *mrt, struct sk_buff *skb,\n\t\t     unsigned int pimlen)\n{\n\tstruct net_device *reg_dev = NULL;\n\tstruct iphdr *encap;\n\tint vif_num;\n\n\tencap = (struct iphdr *)(skb_transport_header(skb) + pimlen);\n\t \n\tif (!ipv4_is_multicast(encap->daddr) ||\n\t    encap->tot_len == 0 ||\n\t    ntohs(encap->tot_len) + pimlen > skb->len)\n\t\treturn 1;\n\n\t \n\tvif_num = READ_ONCE(mrt->mroute_reg_vif_num);\n\tif (vif_num >= 0)\n\t\treg_dev = vif_dev_read(&mrt->vif_table[vif_num]);\n\tif (!reg_dev)\n\t\treturn 1;\n\n\tskb->mac_header = skb->network_header;\n\tskb_pull(skb, (u8 *)encap - skb->data);\n\tskb_reset_network_header(skb);\n\tskb->protocol = htons(ETH_P_IP);\n\tskb->ip_summed = CHECKSUM_NONE;\n\n\tskb_tunnel_rx(skb, reg_dev, dev_net(reg_dev));\n\n\tnetif_rx(skb);\n\n\treturn NET_RX_SUCCESS;\n}\n#else\nstatic struct net_device *ipmr_reg_vif(struct net *net, struct mr_table *mrt)\n{\n\treturn NULL;\n}\n#endif\n\nstatic int call_ipmr_vif_entry_notifiers(struct net *net,\n\t\t\t\t\t enum fib_event_type event_type,\n\t\t\t\t\t struct vif_device *vif,\n\t\t\t\t\t struct net_device *vif_dev,\n\t\t\t\t\t vifi_t vif_index, u32 tb_id)\n{\n\treturn mr_call_vif_notifiers(net, RTNL_FAMILY_IPMR, event_type,\n\t\t\t\t     vif, vif_dev, vif_index, tb_id,\n\t\t\t\t     &net->ipv4.ipmr_seq);\n}\n\nstatic int call_ipmr_mfc_entry_notifiers(struct net *net,\n\t\t\t\t\t enum fib_event_type event_type,\n\t\t\t\t\t struct mfc_cache *mfc, u32 tb_id)\n{\n\treturn mr_call_mfc_notifiers(net, RTNL_FAMILY_IPMR, event_type,\n\t\t\t\t     &mfc->_c, tb_id, &net->ipv4.ipmr_seq);\n}\n\n \nstatic int vif_delete(struct mr_table *mrt, int vifi, int notify,\n\t\t      struct list_head *head)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct vif_device *v;\n\tstruct net_device *dev;\n\tstruct in_device *in_dev;\n\n\tif (vifi < 0 || vifi >= mrt->maxvif)\n\t\treturn -EADDRNOTAVAIL;\n\n\tv = &mrt->vif_table[vifi];\n\n\tdev = rtnl_dereference(v->dev);\n\tif (!dev)\n\t\treturn -EADDRNOTAVAIL;\n\n\tspin_lock(&mrt_lock);\n\tcall_ipmr_vif_entry_notifiers(net, FIB_EVENT_VIF_DEL, v, dev,\n\t\t\t\t      vifi, mrt->id);\n\tRCU_INIT_POINTER(v->dev, NULL);\n\n\tif (vifi == mrt->mroute_reg_vif_num) {\n\t\t \n\t\tWRITE_ONCE(mrt->mroute_reg_vif_num, -1);\n\t}\n\tif (vifi + 1 == mrt->maxvif) {\n\t\tint tmp;\n\n\t\tfor (tmp = vifi - 1; tmp >= 0; tmp--) {\n\t\t\tif (VIF_EXISTS(mrt, tmp))\n\t\t\t\tbreak;\n\t\t}\n\t\tWRITE_ONCE(mrt->maxvif, tmp + 1);\n\t}\n\n\tspin_unlock(&mrt_lock);\n\n\tdev_set_allmulti(dev, -1);\n\n\tin_dev = __in_dev_get_rtnl(dev);\n\tif (in_dev) {\n\t\tIPV4_DEVCONF(in_dev->cnf, MC_FORWARDING)--;\n\t\tinet_netconf_notify_devconf(dev_net(dev), RTM_NEWNETCONF,\n\t\t\t\t\t    NETCONFA_MC_FORWARDING,\n\t\t\t\t\t    dev->ifindex, &in_dev->cnf);\n\t\tip_rt_multicast_event(in_dev);\n\t}\n\n\tif (v->flags & (VIFF_TUNNEL | VIFF_REGISTER) && !notify)\n\t\tunregister_netdevice_queue(dev, head);\n\n\tnetdev_put(dev, &v->dev_tracker);\n\treturn 0;\n}\n\nstatic void ipmr_cache_free_rcu(struct rcu_head *head)\n{\n\tstruct mr_mfc *c = container_of(head, struct mr_mfc, rcu);\n\n\tkmem_cache_free(mrt_cachep, (struct mfc_cache *)c);\n}\n\nstatic void ipmr_cache_free(struct mfc_cache *c)\n{\n\tcall_rcu(&c->_c.rcu, ipmr_cache_free_rcu);\n}\n\n \nstatic void ipmr_destroy_unres(struct mr_table *mrt, struct mfc_cache *c)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct sk_buff *skb;\n\tstruct nlmsgerr *e;\n\n\tatomic_dec(&mrt->cache_resolve_queue_len);\n\n\twhile ((skb = skb_dequeue(&c->_c.mfc_un.unres.unresolved))) {\n\t\tif (ip_hdr(skb)->version == 0) {\n\t\t\tstruct nlmsghdr *nlh = skb_pull(skb,\n\t\t\t\t\t\t\tsizeof(struct iphdr));\n\t\t\tnlh->nlmsg_type = NLMSG_ERROR;\n\t\t\tnlh->nlmsg_len = nlmsg_msg_size(sizeof(struct nlmsgerr));\n\t\t\tskb_trim(skb, nlh->nlmsg_len);\n\t\t\te = nlmsg_data(nlh);\n\t\t\te->error = -ETIMEDOUT;\n\t\t\tmemset(&e->msg, 0, sizeof(e->msg));\n\n\t\t\trtnl_unicast(skb, net, NETLINK_CB(skb).portid);\n\t\t} else {\n\t\t\tkfree_skb(skb);\n\t\t}\n\t}\n\n\tipmr_cache_free(c);\n}\n\n \nstatic void ipmr_expire_process(struct timer_list *t)\n{\n\tstruct mr_table *mrt = from_timer(mrt, t, ipmr_expire_timer);\n\tstruct mr_mfc *c, *next;\n\tunsigned long expires;\n\tunsigned long now;\n\n\tif (!spin_trylock(&mfc_unres_lock)) {\n\t\tmod_timer(&mrt->ipmr_expire_timer, jiffies+HZ/10);\n\t\treturn;\n\t}\n\n\tif (list_empty(&mrt->mfc_unres_queue))\n\t\tgoto out;\n\n\tnow = jiffies;\n\texpires = 10*HZ;\n\n\tlist_for_each_entry_safe(c, next, &mrt->mfc_unres_queue, list) {\n\t\tif (time_after(c->mfc_un.unres.expires, now)) {\n\t\t\tunsigned long interval = c->mfc_un.unres.expires - now;\n\t\t\tif (interval < expires)\n\t\t\t\texpires = interval;\n\t\t\tcontinue;\n\t\t}\n\n\t\tlist_del(&c->list);\n\t\tmroute_netlink_event(mrt, (struct mfc_cache *)c, RTM_DELROUTE);\n\t\tipmr_destroy_unres(mrt, (struct mfc_cache *)c);\n\t}\n\n\tif (!list_empty(&mrt->mfc_unres_queue))\n\t\tmod_timer(&mrt->ipmr_expire_timer, jiffies + expires);\n\nout:\n\tspin_unlock(&mfc_unres_lock);\n}\n\n \nstatic void ipmr_update_thresholds(struct mr_table *mrt, struct mr_mfc *cache,\n\t\t\t\t   unsigned char *ttls)\n{\n\tint vifi;\n\n\tcache->mfc_un.res.minvif = MAXVIFS;\n\tcache->mfc_un.res.maxvif = 0;\n\tmemset(cache->mfc_un.res.ttls, 255, MAXVIFS);\n\n\tfor (vifi = 0; vifi < mrt->maxvif; vifi++) {\n\t\tif (VIF_EXISTS(mrt, vifi) &&\n\t\t    ttls[vifi] && ttls[vifi] < 255) {\n\t\t\tcache->mfc_un.res.ttls[vifi] = ttls[vifi];\n\t\t\tif (cache->mfc_un.res.minvif > vifi)\n\t\t\t\tcache->mfc_un.res.minvif = vifi;\n\t\t\tif (cache->mfc_un.res.maxvif <= vifi)\n\t\t\t\tcache->mfc_un.res.maxvif = vifi + 1;\n\t\t}\n\t}\n\tcache->mfc_un.res.lastuse = jiffies;\n}\n\nstatic int vif_add(struct net *net, struct mr_table *mrt,\n\t\t   struct vifctl *vifc, int mrtsock)\n{\n\tstruct netdev_phys_item_id ppid = { };\n\tint vifi = vifc->vifc_vifi;\n\tstruct vif_device *v = &mrt->vif_table[vifi];\n\tstruct net_device *dev;\n\tstruct in_device *in_dev;\n\tint err;\n\n\t \n\tif (VIF_EXISTS(mrt, vifi))\n\t\treturn -EADDRINUSE;\n\n\tswitch (vifc->vifc_flags) {\n\tcase VIFF_REGISTER:\n\t\tif (!ipmr_pimsm_enabled())\n\t\t\treturn -EINVAL;\n\t\t \n\t\tif (mrt->mroute_reg_vif_num >= 0)\n\t\t\treturn -EADDRINUSE;\n\t\tdev = ipmr_reg_vif(net, mrt);\n\t\tif (!dev)\n\t\t\treturn -ENOBUFS;\n\t\terr = dev_set_allmulti(dev, 1);\n\t\tif (err) {\n\t\t\tunregister_netdevice(dev);\n\t\t\tdev_put(dev);\n\t\t\treturn err;\n\t\t}\n\t\tbreak;\n\tcase VIFF_TUNNEL:\n\t\tdev = ipmr_new_tunnel(net, vifc);\n\t\tif (IS_ERR(dev))\n\t\t\treturn PTR_ERR(dev);\n\t\tbreak;\n\tcase VIFF_USE_IFINDEX:\n\tcase 0:\n\t\tif (vifc->vifc_flags == VIFF_USE_IFINDEX) {\n\t\t\tdev = dev_get_by_index(net, vifc->vifc_lcl_ifindex);\n\t\t\tif (dev && !__in_dev_get_rtnl(dev)) {\n\t\t\t\tdev_put(dev);\n\t\t\t\treturn -EADDRNOTAVAIL;\n\t\t\t}\n\t\t} else {\n\t\t\tdev = ip_dev_find(net, vifc->vifc_lcl_addr.s_addr);\n\t\t}\n\t\tif (!dev)\n\t\t\treturn -EADDRNOTAVAIL;\n\t\terr = dev_set_allmulti(dev, 1);\n\t\tif (err) {\n\t\t\tdev_put(dev);\n\t\t\treturn err;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tin_dev = __in_dev_get_rtnl(dev);\n\tif (!in_dev) {\n\t\tdev_put(dev);\n\t\treturn -EADDRNOTAVAIL;\n\t}\n\tIPV4_DEVCONF(in_dev->cnf, MC_FORWARDING)++;\n\tinet_netconf_notify_devconf(net, RTM_NEWNETCONF, NETCONFA_MC_FORWARDING,\n\t\t\t\t    dev->ifindex, &in_dev->cnf);\n\tip_rt_multicast_event(in_dev);\n\n\t \n\tvif_device_init(v, dev, vifc->vifc_rate_limit,\n\t\t\tvifc->vifc_threshold,\n\t\t\tvifc->vifc_flags | (!mrtsock ? VIFF_STATIC : 0),\n\t\t\t(VIFF_TUNNEL | VIFF_REGISTER));\n\n\terr = dev_get_port_parent_id(dev, &ppid, true);\n\tif (err == 0) {\n\t\tmemcpy(v->dev_parent_id.id, ppid.id, ppid.id_len);\n\t\tv->dev_parent_id.id_len = ppid.id_len;\n\t} else {\n\t\tv->dev_parent_id.id_len = 0;\n\t}\n\n\tv->local = vifc->vifc_lcl_addr.s_addr;\n\tv->remote = vifc->vifc_rmt_addr.s_addr;\n\n\t \n\tspin_lock(&mrt_lock);\n\trcu_assign_pointer(v->dev, dev);\n\tnetdev_tracker_alloc(dev, &v->dev_tracker, GFP_ATOMIC);\n\tif (v->flags & VIFF_REGISTER) {\n\t\t \n\t\tWRITE_ONCE(mrt->mroute_reg_vif_num, vifi);\n\t}\n\tif (vifi+1 > mrt->maxvif)\n\t\tWRITE_ONCE(mrt->maxvif, vifi + 1);\n\tspin_unlock(&mrt_lock);\n\tcall_ipmr_vif_entry_notifiers(net, FIB_EVENT_VIF_ADD, v, dev,\n\t\t\t\t      vifi, mrt->id);\n\treturn 0;\n}\n\n \nstatic struct mfc_cache *ipmr_cache_find(struct mr_table *mrt,\n\t\t\t\t\t __be32 origin,\n\t\t\t\t\t __be32 mcastgrp)\n{\n\tstruct mfc_cache_cmp_arg arg = {\n\t\t\t.mfc_mcastgrp = mcastgrp,\n\t\t\t.mfc_origin = origin\n\t};\n\n\treturn mr_mfc_find(mrt, &arg);\n}\n\n \nstatic struct mfc_cache *ipmr_cache_find_any(struct mr_table *mrt,\n\t\t\t\t\t     __be32 mcastgrp, int vifi)\n{\n\tstruct mfc_cache_cmp_arg arg = {\n\t\t\t.mfc_mcastgrp = mcastgrp,\n\t\t\t.mfc_origin = htonl(INADDR_ANY)\n\t};\n\n\tif (mcastgrp == htonl(INADDR_ANY))\n\t\treturn mr_mfc_find_any_parent(mrt, vifi);\n\treturn mr_mfc_find_any(mrt, vifi, &arg);\n}\n\n \nstatic struct mfc_cache *ipmr_cache_find_parent(struct mr_table *mrt,\n\t\t\t\t\t\t__be32 origin, __be32 mcastgrp,\n\t\t\t\t\t\tint parent)\n{\n\tstruct mfc_cache_cmp_arg arg = {\n\t\t\t.mfc_mcastgrp = mcastgrp,\n\t\t\t.mfc_origin = origin,\n\t};\n\n\treturn mr_mfc_find_parent(mrt, &arg, parent);\n}\n\n \nstatic struct mfc_cache *ipmr_cache_alloc(void)\n{\n\tstruct mfc_cache *c = kmem_cache_zalloc(mrt_cachep, GFP_KERNEL);\n\n\tif (c) {\n\t\tc->_c.mfc_un.res.last_assert = jiffies - MFC_ASSERT_THRESH - 1;\n\t\tc->_c.mfc_un.res.minvif = MAXVIFS;\n\t\tc->_c.free = ipmr_cache_free_rcu;\n\t\trefcount_set(&c->_c.mfc_un.res.refcount, 1);\n\t}\n\treturn c;\n}\n\nstatic struct mfc_cache *ipmr_cache_alloc_unres(void)\n{\n\tstruct mfc_cache *c = kmem_cache_zalloc(mrt_cachep, GFP_ATOMIC);\n\n\tif (c) {\n\t\tskb_queue_head_init(&c->_c.mfc_un.unres.unresolved);\n\t\tc->_c.mfc_un.unres.expires = jiffies + 10 * HZ;\n\t}\n\treturn c;\n}\n\n \nstatic void ipmr_cache_resolve(struct net *net, struct mr_table *mrt,\n\t\t\t       struct mfc_cache *uc, struct mfc_cache *c)\n{\n\tstruct sk_buff *skb;\n\tstruct nlmsgerr *e;\n\n\t \n\twhile ((skb = __skb_dequeue(&uc->_c.mfc_un.unres.unresolved))) {\n\t\tif (ip_hdr(skb)->version == 0) {\n\t\t\tstruct nlmsghdr *nlh = skb_pull(skb,\n\t\t\t\t\t\t\tsizeof(struct iphdr));\n\n\t\t\tif (mr_fill_mroute(mrt, skb, &c->_c,\n\t\t\t\t\t   nlmsg_data(nlh)) > 0) {\n\t\t\t\tnlh->nlmsg_len = skb_tail_pointer(skb) -\n\t\t\t\t\t\t (u8 *)nlh;\n\t\t\t} else {\n\t\t\t\tnlh->nlmsg_type = NLMSG_ERROR;\n\t\t\t\tnlh->nlmsg_len = nlmsg_msg_size(sizeof(struct nlmsgerr));\n\t\t\t\tskb_trim(skb, nlh->nlmsg_len);\n\t\t\t\te = nlmsg_data(nlh);\n\t\t\t\te->error = -EMSGSIZE;\n\t\t\t\tmemset(&e->msg, 0, sizeof(e->msg));\n\t\t\t}\n\n\t\t\trtnl_unicast(skb, net, NETLINK_CB(skb).portid);\n\t\t} else {\n\t\t\trcu_read_lock();\n\t\t\tip_mr_forward(net, mrt, skb->dev, skb, c, 0);\n\t\t\trcu_read_unlock();\n\t\t}\n\t}\n}\n\n \nstatic int ipmr_cache_report(const struct mr_table *mrt,\n\t\t\t     struct sk_buff *pkt, vifi_t vifi, int assert)\n{\n\tconst int ihl = ip_hdrlen(pkt);\n\tstruct sock *mroute_sk;\n\tstruct igmphdr *igmp;\n\tstruct igmpmsg *msg;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tmroute_sk = rcu_dereference(mrt->mroute_sk);\n\tif (!mroute_sk)\n\t\treturn -EINVAL;\n\n\tif (assert == IGMPMSG_WHOLEPKT || assert == IGMPMSG_WRVIFWHOLE)\n\t\tskb = skb_realloc_headroom(pkt, sizeof(struct iphdr));\n\telse\n\t\tskb = alloc_skb(128, GFP_ATOMIC);\n\n\tif (!skb)\n\t\treturn -ENOBUFS;\n\n\tif (assert == IGMPMSG_WHOLEPKT || assert == IGMPMSG_WRVIFWHOLE) {\n\t\t \n\t\tskb_push(skb, sizeof(struct iphdr));\n\t\tskb_reset_network_header(skb);\n\t\tskb_reset_transport_header(skb);\n\t\tmsg = (struct igmpmsg *)skb_network_header(skb);\n\t\tmemcpy(msg, skb_network_header(pkt), sizeof(struct iphdr));\n\t\tmsg->im_msgtype = assert;\n\t\tmsg->im_mbz = 0;\n\t\tif (assert == IGMPMSG_WRVIFWHOLE) {\n\t\t\tmsg->im_vif = vifi;\n\t\t\tmsg->im_vif_hi = vifi >> 8;\n\t\t} else {\n\t\t\t \n\t\t\tint vif_num = READ_ONCE(mrt->mroute_reg_vif_num);\n\n\t\t\tmsg->im_vif = vif_num;\n\t\t\tmsg->im_vif_hi = vif_num >> 8;\n\t\t}\n\t\tip_hdr(skb)->ihl = sizeof(struct iphdr) >> 2;\n\t\tip_hdr(skb)->tot_len = htons(ntohs(ip_hdr(pkt)->tot_len) +\n\t\t\t\t\t     sizeof(struct iphdr));\n\t} else {\n\t\t \n\t\tskb_set_network_header(skb, skb->len);\n\t\tskb_put(skb, ihl);\n\t\tskb_copy_to_linear_data(skb, pkt->data, ihl);\n\t\t \n\t\tip_hdr(skb)->protocol = 0;\n\t\tmsg = (struct igmpmsg *)skb_network_header(skb);\n\t\tmsg->im_vif = vifi;\n\t\tmsg->im_vif_hi = vifi >> 8;\n\t\tipv4_pktinfo_prepare(mroute_sk, pkt);\n\t\tmemcpy(skb->cb, pkt->cb, sizeof(skb->cb));\n\t\t \n\t\tigmp = skb_put(skb, sizeof(struct igmphdr));\n\t\tigmp->type = assert;\n\t\tmsg->im_msgtype = assert;\n\t\tigmp->code = 0;\n\t\tip_hdr(skb)->tot_len = htons(skb->len);\t \n\t\tskb->transport_header = skb->network_header;\n\t}\n\n\tigmpmsg_netlink_event(mrt, skb);\n\n\t \n\tret = sock_queue_rcv_skb(mroute_sk, skb);\n\n\tif (ret < 0) {\n\t\tnet_warn_ratelimited(\"mroute: pending queue full, dropping entries\\n\");\n\t\tkfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\n \n \nstatic int ipmr_cache_unresolved(struct mr_table *mrt, vifi_t vifi,\n\t\t\t\t struct sk_buff *skb, struct net_device *dev)\n{\n\tconst struct iphdr *iph = ip_hdr(skb);\n\tstruct mfc_cache *c;\n\tbool found = false;\n\tint err;\n\n\tspin_lock_bh(&mfc_unres_lock);\n\tlist_for_each_entry(c, &mrt->mfc_unres_queue, _c.list) {\n\t\tif (c->mfc_mcastgrp == iph->daddr &&\n\t\t    c->mfc_origin == iph->saddr) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\t \n\t\tc = ipmr_cache_alloc_unres();\n\t\tif (!c) {\n\t\t\tspin_unlock_bh(&mfc_unres_lock);\n\n\t\t\tkfree_skb(skb);\n\t\t\treturn -ENOBUFS;\n\t\t}\n\n\t\t \n\t\tc->_c.mfc_parent = -1;\n\t\tc->mfc_origin\t= iph->saddr;\n\t\tc->mfc_mcastgrp\t= iph->daddr;\n\n\t\t \n\t\terr = ipmr_cache_report(mrt, skb, vifi, IGMPMSG_NOCACHE);\n\n\t\tif (err < 0) {\n\t\t\t \n\t\t\tspin_unlock_bh(&mfc_unres_lock);\n\n\t\t\tipmr_cache_free(c);\n\t\t\tkfree_skb(skb);\n\t\t\treturn err;\n\t\t}\n\n\t\tatomic_inc(&mrt->cache_resolve_queue_len);\n\t\tlist_add(&c->_c.list, &mrt->mfc_unres_queue);\n\t\tmroute_netlink_event(mrt, c, RTM_NEWROUTE);\n\n\t\tif (atomic_read(&mrt->cache_resolve_queue_len) == 1)\n\t\t\tmod_timer(&mrt->ipmr_expire_timer,\n\t\t\t\t  c->_c.mfc_un.unres.expires);\n\t}\n\n\t \n\tif (c->_c.mfc_un.unres.unresolved.qlen > 3) {\n\t\tkfree_skb(skb);\n\t\terr = -ENOBUFS;\n\t} else {\n\t\tif (dev) {\n\t\t\tskb->dev = dev;\n\t\t\tskb->skb_iif = dev->ifindex;\n\t\t}\n\t\tskb_queue_tail(&c->_c.mfc_un.unres.unresolved, skb);\n\t\terr = 0;\n\t}\n\n\tspin_unlock_bh(&mfc_unres_lock);\n\treturn err;\n}\n\n \n\nstatic int ipmr_mfc_delete(struct mr_table *mrt, struct mfcctl *mfc, int parent)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct mfc_cache *c;\n\n\t \n\trcu_read_lock();\n\tc = ipmr_cache_find_parent(mrt, mfc->mfcc_origin.s_addr,\n\t\t\t\t   mfc->mfcc_mcastgrp.s_addr, parent);\n\trcu_read_unlock();\n\tif (!c)\n\t\treturn -ENOENT;\n\trhltable_remove(&mrt->mfc_hash, &c->_c.mnode, ipmr_rht_params);\n\tlist_del_rcu(&c->_c.list);\n\tcall_ipmr_mfc_entry_notifiers(net, FIB_EVENT_ENTRY_DEL, c, mrt->id);\n\tmroute_netlink_event(mrt, c, RTM_DELROUTE);\n\tmr_cache_put(&c->_c);\n\n\treturn 0;\n}\n\nstatic int ipmr_mfc_add(struct net *net, struct mr_table *mrt,\n\t\t\tstruct mfcctl *mfc, int mrtsock, int parent)\n{\n\tstruct mfc_cache *uc, *c;\n\tstruct mr_mfc *_uc;\n\tbool found;\n\tint ret;\n\n\tif (mfc->mfcc_parent >= MAXVIFS)\n\t\treturn -ENFILE;\n\n\t \n\trcu_read_lock();\n\tc = ipmr_cache_find_parent(mrt, mfc->mfcc_origin.s_addr,\n\t\t\t\t   mfc->mfcc_mcastgrp.s_addr, parent);\n\trcu_read_unlock();\n\tif (c) {\n\t\tspin_lock(&mrt_lock);\n\t\tc->_c.mfc_parent = mfc->mfcc_parent;\n\t\tipmr_update_thresholds(mrt, &c->_c, mfc->mfcc_ttls);\n\t\tif (!mrtsock)\n\t\t\tc->_c.mfc_flags |= MFC_STATIC;\n\t\tspin_unlock(&mrt_lock);\n\t\tcall_ipmr_mfc_entry_notifiers(net, FIB_EVENT_ENTRY_REPLACE, c,\n\t\t\t\t\t      mrt->id);\n\t\tmroute_netlink_event(mrt, c, RTM_NEWROUTE);\n\t\treturn 0;\n\t}\n\n\tif (mfc->mfcc_mcastgrp.s_addr != htonl(INADDR_ANY) &&\n\t    !ipv4_is_multicast(mfc->mfcc_mcastgrp.s_addr))\n\t\treturn -EINVAL;\n\n\tc = ipmr_cache_alloc();\n\tif (!c)\n\t\treturn -ENOMEM;\n\n\tc->mfc_origin = mfc->mfcc_origin.s_addr;\n\tc->mfc_mcastgrp = mfc->mfcc_mcastgrp.s_addr;\n\tc->_c.mfc_parent = mfc->mfcc_parent;\n\tipmr_update_thresholds(mrt, &c->_c, mfc->mfcc_ttls);\n\tif (!mrtsock)\n\t\tc->_c.mfc_flags |= MFC_STATIC;\n\n\tret = rhltable_insert_key(&mrt->mfc_hash, &c->cmparg, &c->_c.mnode,\n\t\t\t\t  ipmr_rht_params);\n\tif (ret) {\n\t\tpr_err(\"ipmr: rhtable insert error %d\\n\", ret);\n\t\tipmr_cache_free(c);\n\t\treturn ret;\n\t}\n\tlist_add_tail_rcu(&c->_c.list, &mrt->mfc_cache_list);\n\t \n\tfound = false;\n\tspin_lock_bh(&mfc_unres_lock);\n\tlist_for_each_entry(_uc, &mrt->mfc_unres_queue, list) {\n\t\tuc = (struct mfc_cache *)_uc;\n\t\tif (uc->mfc_origin == c->mfc_origin &&\n\t\t    uc->mfc_mcastgrp == c->mfc_mcastgrp) {\n\t\t\tlist_del(&_uc->list);\n\t\t\tatomic_dec(&mrt->cache_resolve_queue_len);\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (list_empty(&mrt->mfc_unres_queue))\n\t\tdel_timer(&mrt->ipmr_expire_timer);\n\tspin_unlock_bh(&mfc_unres_lock);\n\n\tif (found) {\n\t\tipmr_cache_resolve(net, mrt, uc, c);\n\t\tipmr_cache_free(uc);\n\t}\n\tcall_ipmr_mfc_entry_notifiers(net, FIB_EVENT_ENTRY_ADD, c, mrt->id);\n\tmroute_netlink_event(mrt, c, RTM_NEWROUTE);\n\treturn 0;\n}\n\n \nstatic void mroute_clean_tables(struct mr_table *mrt, int flags)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct mr_mfc *c, *tmp;\n\tstruct mfc_cache *cache;\n\tLIST_HEAD(list);\n\tint i;\n\n\t \n\tif (flags & (MRT_FLUSH_VIFS | MRT_FLUSH_VIFS_STATIC)) {\n\t\tfor (i = 0; i < mrt->maxvif; i++) {\n\t\t\tif (((mrt->vif_table[i].flags & VIFF_STATIC) &&\n\t\t\t     !(flags & MRT_FLUSH_VIFS_STATIC)) ||\n\t\t\t    (!(mrt->vif_table[i].flags & VIFF_STATIC) && !(flags & MRT_FLUSH_VIFS)))\n\t\t\t\tcontinue;\n\t\t\tvif_delete(mrt, i, 0, &list);\n\t\t}\n\t\tunregister_netdevice_many(&list);\n\t}\n\n\t \n\tif (flags & (MRT_FLUSH_MFC | MRT_FLUSH_MFC_STATIC)) {\n\t\tlist_for_each_entry_safe(c, tmp, &mrt->mfc_cache_list, list) {\n\t\t\tif (((c->mfc_flags & MFC_STATIC) && !(flags & MRT_FLUSH_MFC_STATIC)) ||\n\t\t\t    (!(c->mfc_flags & MFC_STATIC) && !(flags & MRT_FLUSH_MFC)))\n\t\t\t\tcontinue;\n\t\t\trhltable_remove(&mrt->mfc_hash, &c->mnode, ipmr_rht_params);\n\t\t\tlist_del_rcu(&c->list);\n\t\t\tcache = (struct mfc_cache *)c;\n\t\t\tcall_ipmr_mfc_entry_notifiers(net, FIB_EVENT_ENTRY_DEL, cache,\n\t\t\t\t\t\t      mrt->id);\n\t\t\tmroute_netlink_event(mrt, cache, RTM_DELROUTE);\n\t\t\tmr_cache_put(c);\n\t\t}\n\t}\n\n\tif (flags & MRT_FLUSH_MFC) {\n\t\tif (atomic_read(&mrt->cache_resolve_queue_len) != 0) {\n\t\t\tspin_lock_bh(&mfc_unres_lock);\n\t\t\tlist_for_each_entry_safe(c, tmp, &mrt->mfc_unres_queue, list) {\n\t\t\t\tlist_del(&c->list);\n\t\t\t\tcache = (struct mfc_cache *)c;\n\t\t\t\tmroute_netlink_event(mrt, cache, RTM_DELROUTE);\n\t\t\t\tipmr_destroy_unres(mrt, cache);\n\t\t\t}\n\t\t\tspin_unlock_bh(&mfc_unres_lock);\n\t\t}\n\t}\n}\n\n \nstatic void mrtsock_destruct(struct sock *sk)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct mr_table *mrt;\n\n\trtnl_lock();\n\tipmr_for_each_table(mrt, net) {\n\t\tif (sk == rtnl_dereference(mrt->mroute_sk)) {\n\t\t\tIPV4_DEVCONF_ALL(net, MC_FORWARDING)--;\n\t\t\tinet_netconf_notify_devconf(net, RTM_NEWNETCONF,\n\t\t\t\t\t\t    NETCONFA_MC_FORWARDING,\n\t\t\t\t\t\t    NETCONFA_IFINDEX_ALL,\n\t\t\t\t\t\t    net->ipv4.devconf_all);\n\t\t\tRCU_INIT_POINTER(mrt->mroute_sk, NULL);\n\t\t\tmroute_clean_tables(mrt, MRT_FLUSH_VIFS | MRT_FLUSH_MFC);\n\t\t}\n\t}\n\trtnl_unlock();\n}\n\n \n\nint ip_mroute_setsockopt(struct sock *sk, int optname, sockptr_t optval,\n\t\t\t unsigned int optlen)\n{\n\tstruct net *net = sock_net(sk);\n\tint val, ret = 0, parent = 0;\n\tstruct mr_table *mrt;\n\tstruct vifctl vif;\n\tstruct mfcctl mfc;\n\tbool do_wrvifwhole;\n\tu32 uval;\n\n\t \n\trtnl_lock();\n\tif (sk->sk_type != SOCK_RAW ||\n\t    inet_sk(sk)->inet_num != IPPROTO_IGMP) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out_unlock;\n\t}\n\n\tmrt = ipmr_get_table(net, raw_sk(sk)->ipmr_table ? : RT_TABLE_DEFAULT);\n\tif (!mrt) {\n\t\tret = -ENOENT;\n\t\tgoto out_unlock;\n\t}\n\tif (optname != MRT_INIT) {\n\t\tif (sk != rcu_access_pointer(mrt->mroute_sk) &&\n\t\t    !ns_capable(net->user_ns, CAP_NET_ADMIN)) {\n\t\t\tret = -EACCES;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tswitch (optname) {\n\tcase MRT_INIT:\n\t\tif (optlen != sizeof(int)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (rtnl_dereference(mrt->mroute_sk)) {\n\t\t\tret = -EADDRINUSE;\n\t\t\tbreak;\n\t\t}\n\n\t\tret = ip_ra_control(sk, 1, mrtsock_destruct);\n\t\tif (ret == 0) {\n\t\t\trcu_assign_pointer(mrt->mroute_sk, sk);\n\t\t\tIPV4_DEVCONF_ALL(net, MC_FORWARDING)++;\n\t\t\tinet_netconf_notify_devconf(net, RTM_NEWNETCONF,\n\t\t\t\t\t\t    NETCONFA_MC_FORWARDING,\n\t\t\t\t\t\t    NETCONFA_IFINDEX_ALL,\n\t\t\t\t\t\t    net->ipv4.devconf_all);\n\t\t}\n\t\tbreak;\n\tcase MRT_DONE:\n\t\tif (sk != rcu_access_pointer(mrt->mroute_sk)) {\n\t\t\tret = -EACCES;\n\t\t} else {\n\t\t\t \n\t\t\trtnl_unlock();\n\t\t\tret = ip_ra_control(sk, 0, NULL);\n\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MRT_ADD_VIF:\n\tcase MRT_DEL_VIF:\n\t\tif (optlen != sizeof(vif)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_sockptr(&vif, optval, sizeof(vif))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (vif.vifc_vifi >= MAXVIFS) {\n\t\t\tret = -ENFILE;\n\t\t\tbreak;\n\t\t}\n\t\tif (optname == MRT_ADD_VIF) {\n\t\t\tret = vif_add(net, mrt, &vif,\n\t\t\t\t      sk == rtnl_dereference(mrt->mroute_sk));\n\t\t} else {\n\t\t\tret = vif_delete(mrt, vif.vifc_vifi, 0, NULL);\n\t\t}\n\t\tbreak;\n\t \n\tcase MRT_ADD_MFC:\n\tcase MRT_DEL_MFC:\n\t\tparent = -1;\n\t\tfallthrough;\n\tcase MRT_ADD_MFC_PROXY:\n\tcase MRT_DEL_MFC_PROXY:\n\t\tif (optlen != sizeof(mfc)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_sockptr(&mfc, optval, sizeof(mfc))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (parent == 0)\n\t\t\tparent = mfc.mfcc_parent;\n\t\tif (optname == MRT_DEL_MFC || optname == MRT_DEL_MFC_PROXY)\n\t\t\tret = ipmr_mfc_delete(mrt, &mfc, parent);\n\t\telse\n\t\t\tret = ipmr_mfc_add(net, mrt, &mfc,\n\t\t\t\t\t   sk == rtnl_dereference(mrt->mroute_sk),\n\t\t\t\t\t   parent);\n\t\tbreak;\n\tcase MRT_FLUSH:\n\t\tif (optlen != sizeof(val)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_sockptr(&val, optval, sizeof(val))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tmroute_clean_tables(mrt, val);\n\t\tbreak;\n\t \n\tcase MRT_ASSERT:\n\t\tif (optlen != sizeof(val)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_sockptr(&val, optval, sizeof(val))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tmrt->mroute_do_assert = val;\n\t\tbreak;\n\tcase MRT_PIM:\n\t\tif (!ipmr_pimsm_enabled()) {\n\t\t\tret = -ENOPROTOOPT;\n\t\t\tbreak;\n\t\t}\n\t\tif (optlen != sizeof(val)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_sockptr(&val, optval, sizeof(val))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tdo_wrvifwhole = (val == IGMPMSG_WRVIFWHOLE);\n\t\tval = !!val;\n\t\tif (val != mrt->mroute_do_pim) {\n\t\t\tmrt->mroute_do_pim = val;\n\t\t\tmrt->mroute_do_assert = val;\n\t\t\tmrt->mroute_do_wrvifwhole = do_wrvifwhole;\n\t\t}\n\t\tbreak;\n\tcase MRT_TABLE:\n\t\tif (!IS_BUILTIN(CONFIG_IP_MROUTE_MULTIPLE_TABLES)) {\n\t\t\tret = -ENOPROTOOPT;\n\t\t\tbreak;\n\t\t}\n\t\tif (optlen != sizeof(uval)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_sockptr(&uval, optval, sizeof(uval))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (sk == rtnl_dereference(mrt->mroute_sk)) {\n\t\t\tret = -EBUSY;\n\t\t} else {\n\t\t\tmrt = ipmr_new_table(net, uval);\n\t\t\tif (IS_ERR(mrt))\n\t\t\t\tret = PTR_ERR(mrt);\n\t\t\telse\n\t\t\t\traw_sk(sk)->ipmr_table = uval;\n\t\t}\n\t\tbreak;\n\t \n\tdefault:\n\t\tret = -ENOPROTOOPT;\n\t}\nout_unlock:\n\trtnl_unlock();\nout:\n\treturn ret;\n}\n\n \nint ipmr_sk_ioctl(struct sock *sk, unsigned int cmd, void __user *arg)\n{\n\tswitch (cmd) {\n\t \n\tcase SIOCGETVIFCNT: {\n\t\tstruct sioc_vif_req buffer;\n\n\t\treturn sock_ioctl_inout(sk, cmd, arg, &buffer,\n\t\t\t\t      sizeof(buffer));\n\t\t}\n\tcase SIOCGETSGCNT: {\n\t\tstruct sioc_sg_req buffer;\n\n\t\treturn sock_ioctl_inout(sk, cmd, arg, &buffer,\n\t\t\t\t      sizeof(buffer));\n\t\t}\n\t}\n\t \n\treturn 1;\n}\n\n \nint ip_mroute_getsockopt(struct sock *sk, int optname, sockptr_t optval,\n\t\t\t sockptr_t optlen)\n{\n\tint olr;\n\tint val;\n\tstruct net *net = sock_net(sk);\n\tstruct mr_table *mrt;\n\n\tif (sk->sk_type != SOCK_RAW ||\n\t    inet_sk(sk)->inet_num != IPPROTO_IGMP)\n\t\treturn -EOPNOTSUPP;\n\n\tmrt = ipmr_get_table(net, raw_sk(sk)->ipmr_table ? : RT_TABLE_DEFAULT);\n\tif (!mrt)\n\t\treturn -ENOENT;\n\n\tswitch (optname) {\n\tcase MRT_VERSION:\n\t\tval = 0x0305;\n\t\tbreak;\n\tcase MRT_PIM:\n\t\tif (!ipmr_pimsm_enabled())\n\t\t\treturn -ENOPROTOOPT;\n\t\tval = mrt->mroute_do_pim;\n\t\tbreak;\n\tcase MRT_ASSERT:\n\t\tval = mrt->mroute_do_assert;\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOPROTOOPT;\n\t}\n\n\tif (copy_from_sockptr(&olr, optlen, sizeof(int)))\n\t\treturn -EFAULT;\n\tolr = min_t(unsigned int, olr, sizeof(int));\n\tif (olr < 0)\n\t\treturn -EINVAL;\n\tif (copy_to_sockptr(optlen, &olr, sizeof(int)))\n\t\treturn -EFAULT;\n\tif (copy_to_sockptr(optval, &val, olr))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\n \nint ipmr_ioctl(struct sock *sk, int cmd, void *arg)\n{\n\tstruct vif_device *vif;\n\tstruct mfc_cache *c;\n\tstruct net *net = sock_net(sk);\n\tstruct sioc_vif_req *vr;\n\tstruct sioc_sg_req *sr;\n\tstruct mr_table *mrt;\n\n\tmrt = ipmr_get_table(net, raw_sk(sk)->ipmr_table ? : RT_TABLE_DEFAULT);\n\tif (!mrt)\n\t\treturn -ENOENT;\n\n\tswitch (cmd) {\n\tcase SIOCGETVIFCNT:\n\t\tvr = (struct sioc_vif_req *)arg;\n\t\tif (vr->vifi >= mrt->maxvif)\n\t\t\treturn -EINVAL;\n\t\tvr->vifi = array_index_nospec(vr->vifi, mrt->maxvif);\n\t\trcu_read_lock();\n\t\tvif = &mrt->vif_table[vr->vifi];\n\t\tif (VIF_EXISTS(mrt, vr->vifi)) {\n\t\t\tvr->icount = READ_ONCE(vif->pkt_in);\n\t\t\tvr->ocount = READ_ONCE(vif->pkt_out);\n\t\t\tvr->ibytes = READ_ONCE(vif->bytes_in);\n\t\t\tvr->obytes = READ_ONCE(vif->bytes_out);\n\t\t\trcu_read_unlock();\n\n\t\t\treturn 0;\n\t\t}\n\t\trcu_read_unlock();\n\t\treturn -EADDRNOTAVAIL;\n\tcase SIOCGETSGCNT:\n\t\tsr = (struct sioc_sg_req *)arg;\n\n\t\trcu_read_lock();\n\t\tc = ipmr_cache_find(mrt, sr->src.s_addr, sr->grp.s_addr);\n\t\tif (c) {\n\t\t\tsr->pktcnt = c->_c.mfc_un.res.pkt;\n\t\t\tsr->bytecnt = c->_c.mfc_un.res.bytes;\n\t\t\tsr->wrong_if = c->_c.mfc_un.res.wrong_if;\n\t\t\trcu_read_unlock();\n\t\t\treturn 0;\n\t\t}\n\t\trcu_read_unlock();\n\t\treturn -EADDRNOTAVAIL;\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n}\n\n#ifdef CONFIG_COMPAT\nstruct compat_sioc_sg_req {\n\tstruct in_addr src;\n\tstruct in_addr grp;\n\tcompat_ulong_t pktcnt;\n\tcompat_ulong_t bytecnt;\n\tcompat_ulong_t wrong_if;\n};\n\nstruct compat_sioc_vif_req {\n\tvifi_t\tvifi;\t\t \n\tcompat_ulong_t icount;\n\tcompat_ulong_t ocount;\n\tcompat_ulong_t ibytes;\n\tcompat_ulong_t obytes;\n};\n\nint ipmr_compat_ioctl(struct sock *sk, unsigned int cmd, void __user *arg)\n{\n\tstruct compat_sioc_sg_req sr;\n\tstruct compat_sioc_vif_req vr;\n\tstruct vif_device *vif;\n\tstruct mfc_cache *c;\n\tstruct net *net = sock_net(sk);\n\tstruct mr_table *mrt;\n\n\tmrt = ipmr_get_table(net, raw_sk(sk)->ipmr_table ? : RT_TABLE_DEFAULT);\n\tif (!mrt)\n\t\treturn -ENOENT;\n\n\tswitch (cmd) {\n\tcase SIOCGETVIFCNT:\n\t\tif (copy_from_user(&vr, arg, sizeof(vr)))\n\t\t\treturn -EFAULT;\n\t\tif (vr.vifi >= mrt->maxvif)\n\t\t\treturn -EINVAL;\n\t\tvr.vifi = array_index_nospec(vr.vifi, mrt->maxvif);\n\t\trcu_read_lock();\n\t\tvif = &mrt->vif_table[vr.vifi];\n\t\tif (VIF_EXISTS(mrt, vr.vifi)) {\n\t\t\tvr.icount = READ_ONCE(vif->pkt_in);\n\t\t\tvr.ocount = READ_ONCE(vif->pkt_out);\n\t\t\tvr.ibytes = READ_ONCE(vif->bytes_in);\n\t\t\tvr.obytes = READ_ONCE(vif->bytes_out);\n\t\t\trcu_read_unlock();\n\n\t\t\tif (copy_to_user(arg, &vr, sizeof(vr)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn 0;\n\t\t}\n\t\trcu_read_unlock();\n\t\treturn -EADDRNOTAVAIL;\n\tcase SIOCGETSGCNT:\n\t\tif (copy_from_user(&sr, arg, sizeof(sr)))\n\t\t\treturn -EFAULT;\n\n\t\trcu_read_lock();\n\t\tc = ipmr_cache_find(mrt, sr.src.s_addr, sr.grp.s_addr);\n\t\tif (c) {\n\t\t\tsr.pktcnt = c->_c.mfc_un.res.pkt;\n\t\t\tsr.bytecnt = c->_c.mfc_un.res.bytes;\n\t\t\tsr.wrong_if = c->_c.mfc_un.res.wrong_if;\n\t\t\trcu_read_unlock();\n\n\t\t\tif (copy_to_user(arg, &sr, sizeof(sr)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn 0;\n\t\t}\n\t\trcu_read_unlock();\n\t\treturn -EADDRNOTAVAIL;\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n}\n#endif\n\nstatic int ipmr_device_event(struct notifier_block *this, unsigned long event, void *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\tstruct net *net = dev_net(dev);\n\tstruct mr_table *mrt;\n\tstruct vif_device *v;\n\tint ct;\n\n\tif (event != NETDEV_UNREGISTER)\n\t\treturn NOTIFY_DONE;\n\n\tipmr_for_each_table(mrt, net) {\n\t\tv = &mrt->vif_table[0];\n\t\tfor (ct = 0; ct < mrt->maxvif; ct++, v++) {\n\t\t\tif (rcu_access_pointer(v->dev) == dev)\n\t\t\t\tvif_delete(mrt, ct, 1, NULL);\n\t\t}\n\t}\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block ip_mr_notifier = {\n\t.notifier_call = ipmr_device_event,\n};\n\n \nstatic void ip_encap(struct net *net, struct sk_buff *skb,\n\t\t     __be32 saddr, __be32 daddr)\n{\n\tstruct iphdr *iph;\n\tconst struct iphdr *old_iph = ip_hdr(skb);\n\n\tskb_push(skb, sizeof(struct iphdr));\n\tskb->transport_header = skb->network_header;\n\tskb_reset_network_header(skb);\n\tiph = ip_hdr(skb);\n\n\tiph->version\t=\t4;\n\tiph->tos\t=\told_iph->tos;\n\tiph->ttl\t=\told_iph->ttl;\n\tiph->frag_off\t=\t0;\n\tiph->daddr\t=\tdaddr;\n\tiph->saddr\t=\tsaddr;\n\tiph->protocol\t=\tIPPROTO_IPIP;\n\tiph->ihl\t=\t5;\n\tiph->tot_len\t=\thtons(skb->len);\n\tip_select_ident(net, skb, NULL);\n\tip_send_check(iph);\n\n\tmemset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));\n\tnf_reset_ct(skb);\n}\n\nstatic inline int ipmr_forward_finish(struct net *net, struct sock *sk,\n\t\t\t\t      struct sk_buff *skb)\n{\n\tstruct ip_options *opt = &(IPCB(skb)->opt);\n\n\tIP_INC_STATS(net, IPSTATS_MIB_OUTFORWDATAGRAMS);\n\n\tif (unlikely(opt->optlen))\n\t\tip_forward_options(skb);\n\n\treturn dst_output(net, sk, skb);\n}\n\n#ifdef CONFIG_NET_SWITCHDEV\nstatic bool ipmr_forward_offloaded(struct sk_buff *skb, struct mr_table *mrt,\n\t\t\t\t   int in_vifi, int out_vifi)\n{\n\tstruct vif_device *out_vif = &mrt->vif_table[out_vifi];\n\tstruct vif_device *in_vif = &mrt->vif_table[in_vifi];\n\n\tif (!skb->offload_l3_fwd_mark)\n\t\treturn false;\n\tif (!out_vif->dev_parent_id.id_len || !in_vif->dev_parent_id.id_len)\n\t\treturn false;\n\treturn netdev_phys_item_id_same(&out_vif->dev_parent_id,\n\t\t\t\t\t&in_vif->dev_parent_id);\n}\n#else\nstatic bool ipmr_forward_offloaded(struct sk_buff *skb, struct mr_table *mrt,\n\t\t\t\t   int in_vifi, int out_vifi)\n{\n\treturn false;\n}\n#endif\n\n \n\nstatic void ipmr_queue_xmit(struct net *net, struct mr_table *mrt,\n\t\t\t    int in_vifi, struct sk_buff *skb, int vifi)\n{\n\tconst struct iphdr *iph = ip_hdr(skb);\n\tstruct vif_device *vif = &mrt->vif_table[vifi];\n\tstruct net_device *vif_dev;\n\tstruct net_device *dev;\n\tstruct rtable *rt;\n\tstruct flowi4 fl4;\n\tint    encap = 0;\n\n\tvif_dev = vif_dev_read(vif);\n\tif (!vif_dev)\n\t\tgoto out_free;\n\n\tif (vif->flags & VIFF_REGISTER) {\n\t\tWRITE_ONCE(vif->pkt_out, vif->pkt_out + 1);\n\t\tWRITE_ONCE(vif->bytes_out, vif->bytes_out + skb->len);\n\t\tDEV_STATS_ADD(vif_dev, tx_bytes, skb->len);\n\t\tDEV_STATS_INC(vif_dev, tx_packets);\n\t\tipmr_cache_report(mrt, skb, vifi, IGMPMSG_WHOLEPKT);\n\t\tgoto out_free;\n\t}\n\n\tif (ipmr_forward_offloaded(skb, mrt, in_vifi, vifi))\n\t\tgoto out_free;\n\n\tif (vif->flags & VIFF_TUNNEL) {\n\t\trt = ip_route_output_ports(net, &fl4, NULL,\n\t\t\t\t\t   vif->remote, vif->local,\n\t\t\t\t\t   0, 0,\n\t\t\t\t\t   IPPROTO_IPIP,\n\t\t\t\t\t   RT_TOS(iph->tos), vif->link);\n\t\tif (IS_ERR(rt))\n\t\t\tgoto out_free;\n\t\tencap = sizeof(struct iphdr);\n\t} else {\n\t\trt = ip_route_output_ports(net, &fl4, NULL, iph->daddr, 0,\n\t\t\t\t\t   0, 0,\n\t\t\t\t\t   IPPROTO_IPIP,\n\t\t\t\t\t   RT_TOS(iph->tos), vif->link);\n\t\tif (IS_ERR(rt))\n\t\t\tgoto out_free;\n\t}\n\n\tdev = rt->dst.dev;\n\n\tif (skb->len+encap > dst_mtu(&rt->dst) && (ntohs(iph->frag_off) & IP_DF)) {\n\t\t \n\t\tIP_INC_STATS(net, IPSTATS_MIB_FRAGFAILS);\n\t\tip_rt_put(rt);\n\t\tgoto out_free;\n\t}\n\n\tencap += LL_RESERVED_SPACE(dev) + rt->dst.header_len;\n\n\tif (skb_cow(skb, encap)) {\n\t\tip_rt_put(rt);\n\t\tgoto out_free;\n\t}\n\n\tWRITE_ONCE(vif->pkt_out, vif->pkt_out + 1);\n\tWRITE_ONCE(vif->bytes_out, vif->bytes_out + skb->len);\n\n\tskb_dst_drop(skb);\n\tskb_dst_set(skb, &rt->dst);\n\tip_decrease_ttl(ip_hdr(skb));\n\n\t \n\tif (vif->flags & VIFF_TUNNEL) {\n\t\tip_encap(net, skb, vif->local, vif->remote);\n\t\t \n\t\tDEV_STATS_INC(vif_dev, tx_packets);\n\t\tDEV_STATS_ADD(vif_dev, tx_bytes, skb->len);\n\t}\n\n\tIPCB(skb)->flags |= IPSKB_FORWARDED;\n\n\t \n\tNF_HOOK(NFPROTO_IPV4, NF_INET_FORWARD,\n\t\tnet, NULL, skb, skb->dev, dev,\n\t\tipmr_forward_finish);\n\treturn;\n\nout_free:\n\tkfree_skb(skb);\n}\n\n \nstatic int ipmr_find_vif(const struct mr_table *mrt, struct net_device *dev)\n{\n\tint ct;\n\t \n\tfor (ct = READ_ONCE(mrt->maxvif) - 1; ct >= 0; ct--) {\n\t\tif (rcu_access_pointer(mrt->vif_table[ct].dev) == dev)\n\t\t\tbreak;\n\t}\n\treturn ct;\n}\n\n \n \nstatic void ip_mr_forward(struct net *net, struct mr_table *mrt,\n\t\t\t  struct net_device *dev, struct sk_buff *skb,\n\t\t\t  struct mfc_cache *c, int local)\n{\n\tint true_vifi = ipmr_find_vif(mrt, dev);\n\tint psend = -1;\n\tint vif, ct;\n\n\tvif = c->_c.mfc_parent;\n\tc->_c.mfc_un.res.pkt++;\n\tc->_c.mfc_un.res.bytes += skb->len;\n\tc->_c.mfc_un.res.lastuse = jiffies;\n\n\tif (c->mfc_origin == htonl(INADDR_ANY) && true_vifi >= 0) {\n\t\tstruct mfc_cache *cache_proxy;\n\n\t\t \n\t\tcache_proxy = mr_mfc_find_any_parent(mrt, vif);\n\t\tif (cache_proxy &&\n\t\t    cache_proxy->_c.mfc_un.res.ttls[true_vifi] < 255)\n\t\t\tgoto forward;\n\t}\n\n\t \n\tif (rcu_access_pointer(mrt->vif_table[vif].dev) != dev) {\n\t\tif (rt_is_output_route(skb_rtable(skb))) {\n\t\t\t \n\t\t\tgoto dont_forward;\n\t\t}\n\n\t\tc->_c.mfc_un.res.wrong_if++;\n\n\t\tif (true_vifi >= 0 && mrt->mroute_do_assert &&\n\t\t     \n\t\t    (mrt->mroute_do_pim ||\n\t\t     c->_c.mfc_un.res.ttls[true_vifi] < 255) &&\n\t\t    time_after(jiffies,\n\t\t\t       c->_c.mfc_un.res.last_assert +\n\t\t\t       MFC_ASSERT_THRESH)) {\n\t\t\tc->_c.mfc_un.res.last_assert = jiffies;\n\t\t\tipmr_cache_report(mrt, skb, true_vifi, IGMPMSG_WRONGVIF);\n\t\t\tif (mrt->mroute_do_wrvifwhole)\n\t\t\t\tipmr_cache_report(mrt, skb, true_vifi,\n\t\t\t\t\t\t  IGMPMSG_WRVIFWHOLE);\n\t\t}\n\t\tgoto dont_forward;\n\t}\n\nforward:\n\tWRITE_ONCE(mrt->vif_table[vif].pkt_in,\n\t\t   mrt->vif_table[vif].pkt_in + 1);\n\tWRITE_ONCE(mrt->vif_table[vif].bytes_in,\n\t\t   mrt->vif_table[vif].bytes_in + skb->len);\n\n\t \n\tif (c->mfc_origin == htonl(INADDR_ANY) &&\n\t    c->mfc_mcastgrp == htonl(INADDR_ANY)) {\n\t\tif (true_vifi >= 0 &&\n\t\t    true_vifi != c->_c.mfc_parent &&\n\t\t    ip_hdr(skb)->ttl >\n\t\t\t\tc->_c.mfc_un.res.ttls[c->_c.mfc_parent]) {\n\t\t\t \n\t\t\tpsend = c->_c.mfc_parent;\n\t\t\tgoto last_forward;\n\t\t}\n\t\tgoto dont_forward;\n\t}\n\tfor (ct = c->_c.mfc_un.res.maxvif - 1;\n\t     ct >= c->_c.mfc_un.res.minvif; ct--) {\n\t\t \n\t\tif ((c->mfc_origin != htonl(INADDR_ANY) ||\n\t\t     ct != true_vifi) &&\n\t\t    ip_hdr(skb)->ttl > c->_c.mfc_un.res.ttls[ct]) {\n\t\t\tif (psend != -1) {\n\t\t\t\tstruct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);\n\n\t\t\t\tif (skb2)\n\t\t\t\t\tipmr_queue_xmit(net, mrt, true_vifi,\n\t\t\t\t\t\t\tskb2, psend);\n\t\t\t}\n\t\t\tpsend = ct;\n\t\t}\n\t}\nlast_forward:\n\tif (psend != -1) {\n\t\tif (local) {\n\t\t\tstruct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);\n\n\t\t\tif (skb2)\n\t\t\t\tipmr_queue_xmit(net, mrt, true_vifi, skb2,\n\t\t\t\t\t\tpsend);\n\t\t} else {\n\t\t\tipmr_queue_xmit(net, mrt, true_vifi, skb, psend);\n\t\t\treturn;\n\t\t}\n\t}\n\ndont_forward:\n\tif (!local)\n\t\tkfree_skb(skb);\n}\n\nstatic struct mr_table *ipmr_rt_fib_lookup(struct net *net, struct sk_buff *skb)\n{\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct iphdr *iph = ip_hdr(skb);\n\tstruct flowi4 fl4 = {\n\t\t.daddr = iph->daddr,\n\t\t.saddr = iph->saddr,\n\t\t.flowi4_tos = RT_TOS(iph->tos),\n\t\t.flowi4_oif = (rt_is_output_route(rt) ?\n\t\t\t       skb->dev->ifindex : 0),\n\t\t.flowi4_iif = (rt_is_output_route(rt) ?\n\t\t\t       LOOPBACK_IFINDEX :\n\t\t\t       skb->dev->ifindex),\n\t\t.flowi4_mark = skb->mark,\n\t};\n\tstruct mr_table *mrt;\n\tint err;\n\n\terr = ipmr_fib_lookup(net, &fl4, &mrt);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\treturn mrt;\n}\n\n \nint ip_mr_input(struct sk_buff *skb)\n{\n\tstruct mfc_cache *cache;\n\tstruct net *net = dev_net(skb->dev);\n\tint local = skb_rtable(skb)->rt_flags & RTCF_LOCAL;\n\tstruct mr_table *mrt;\n\tstruct net_device *dev;\n\n\t \n\tdev = skb->dev;\n\tif (netif_is_l3_master(skb->dev)) {\n\t\tdev = dev_get_by_index_rcu(net, IPCB(skb)->iif);\n\t\tif (!dev) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\n\t \n\tif (IPCB(skb)->flags & IPSKB_FORWARDED)\n\t\tgoto dont_forward;\n\n\tmrt = ipmr_rt_fib_lookup(net, skb);\n\tif (IS_ERR(mrt)) {\n\t\tkfree_skb(skb);\n\t\treturn PTR_ERR(mrt);\n\t}\n\tif (!local) {\n\t\tif (IPCB(skb)->opt.router_alert) {\n\t\t\tif (ip_call_ra_chain(skb))\n\t\t\t\treturn 0;\n\t\t} else if (ip_hdr(skb)->protocol == IPPROTO_IGMP) {\n\t\t\t \n\t\t\tstruct sock *mroute_sk;\n\n\t\t\tmroute_sk = rcu_dereference(mrt->mroute_sk);\n\t\t\tif (mroute_sk) {\n\t\t\t\tnf_reset_ct(skb);\n\t\t\t\traw_rcv(mroute_sk, skb);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tcache = ipmr_cache_find(mrt, ip_hdr(skb)->saddr, ip_hdr(skb)->daddr);\n\tif (!cache) {\n\t\tint vif = ipmr_find_vif(mrt, dev);\n\n\t\tif (vif >= 0)\n\t\t\tcache = ipmr_cache_find_any(mrt, ip_hdr(skb)->daddr,\n\t\t\t\t\t\t    vif);\n\t}\n\n\t \n\tif (!cache) {\n\t\tint vif;\n\n\t\tif (local) {\n\t\t\tstruct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);\n\t\t\tip_local_deliver(skb);\n\t\t\tif (!skb2)\n\t\t\t\treturn -ENOBUFS;\n\t\t\tskb = skb2;\n\t\t}\n\n\t\tvif = ipmr_find_vif(mrt, dev);\n\t\tif (vif >= 0)\n\t\t\treturn ipmr_cache_unresolved(mrt, vif, skb, dev);\n\t\tkfree_skb(skb);\n\t\treturn -ENODEV;\n\t}\n\n\tip_mr_forward(net, mrt, dev, skb, cache, local);\n\n\tif (local)\n\t\treturn ip_local_deliver(skb);\n\n\treturn 0;\n\ndont_forward:\n\tif (local)\n\t\treturn ip_local_deliver(skb);\n\tkfree_skb(skb);\n\treturn 0;\n}\n\n#ifdef CONFIG_IP_PIMSM_V1\n \nint pim_rcv_v1(struct sk_buff *skb)\n{\n\tstruct igmphdr *pim;\n\tstruct net *net = dev_net(skb->dev);\n\tstruct mr_table *mrt;\n\n\tif (!pskb_may_pull(skb, sizeof(*pim) + sizeof(struct iphdr)))\n\t\tgoto drop;\n\n\tpim = igmp_hdr(skb);\n\n\tmrt = ipmr_rt_fib_lookup(net, skb);\n\tif (IS_ERR(mrt))\n\t\tgoto drop;\n\tif (!mrt->mroute_do_pim ||\n\t    pim->group != PIM_V1_VERSION || pim->code != PIM_V1_REGISTER)\n\t\tgoto drop;\n\n\tif (__pim_rcv(mrt, skb, sizeof(*pim))) {\ndrop:\n\t\tkfree_skb(skb);\n\t}\n\treturn 0;\n}\n#endif\n\n#ifdef CONFIG_IP_PIMSM_V2\nstatic int pim_rcv(struct sk_buff *skb)\n{\n\tstruct pimreghdr *pim;\n\tstruct net *net = dev_net(skb->dev);\n\tstruct mr_table *mrt;\n\n\tif (!pskb_may_pull(skb, sizeof(*pim) + sizeof(struct iphdr)))\n\t\tgoto drop;\n\n\tpim = (struct pimreghdr *)skb_transport_header(skb);\n\tif (pim->type != ((PIM_VERSION << 4) | (PIM_TYPE_REGISTER)) ||\n\t    (pim->flags & PIM_NULL_REGISTER) ||\n\t    (ip_compute_csum((void *)pim, sizeof(*pim)) != 0 &&\n\t     csum_fold(skb_checksum(skb, 0, skb->len, 0))))\n\t\tgoto drop;\n\n\tmrt = ipmr_rt_fib_lookup(net, skb);\n\tif (IS_ERR(mrt))\n\t\tgoto drop;\n\tif (__pim_rcv(mrt, skb, sizeof(*pim))) {\ndrop:\n\t\tkfree_skb(skb);\n\t}\n\treturn 0;\n}\n#endif\n\nint ipmr_get_route(struct net *net, struct sk_buff *skb,\n\t\t   __be32 saddr, __be32 daddr,\n\t\t   struct rtmsg *rtm, u32 portid)\n{\n\tstruct mfc_cache *cache;\n\tstruct mr_table *mrt;\n\tint err;\n\n\tmrt = ipmr_get_table(net, RT_TABLE_DEFAULT);\n\tif (!mrt)\n\t\treturn -ENOENT;\n\n\trcu_read_lock();\n\tcache = ipmr_cache_find(mrt, saddr, daddr);\n\tif (!cache && skb->dev) {\n\t\tint vif = ipmr_find_vif(mrt, skb->dev);\n\n\t\tif (vif >= 0)\n\t\t\tcache = ipmr_cache_find_any(mrt, daddr, vif);\n\t}\n\tif (!cache) {\n\t\tstruct sk_buff *skb2;\n\t\tstruct iphdr *iph;\n\t\tstruct net_device *dev;\n\t\tint vif = -1;\n\n\t\tdev = skb->dev;\n\t\tif (dev)\n\t\t\tvif = ipmr_find_vif(mrt, dev);\n\t\tif (vif < 0) {\n\t\t\trcu_read_unlock();\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tskb2 = skb_realloc_headroom(skb, sizeof(struct iphdr));\n\t\tif (!skb2) {\n\t\t\trcu_read_unlock();\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tNETLINK_CB(skb2).portid = portid;\n\t\tskb_push(skb2, sizeof(struct iphdr));\n\t\tskb_reset_network_header(skb2);\n\t\tiph = ip_hdr(skb2);\n\t\tiph->ihl = sizeof(struct iphdr) >> 2;\n\t\tiph->saddr = saddr;\n\t\tiph->daddr = daddr;\n\t\tiph->version = 0;\n\t\terr = ipmr_cache_unresolved(mrt, vif, skb2, dev);\n\t\trcu_read_unlock();\n\t\treturn err;\n\t}\n\n\terr = mr_fill_mroute(mrt, skb, &cache->_c, rtm);\n\trcu_read_unlock();\n\treturn err;\n}\n\nstatic int ipmr_fill_mroute(struct mr_table *mrt, struct sk_buff *skb,\n\t\t\t    u32 portid, u32 seq, struct mfc_cache *c, int cmd,\n\t\t\t    int flags)\n{\n\tstruct nlmsghdr *nlh;\n\tstruct rtmsg *rtm;\n\tint err;\n\n\tnlh = nlmsg_put(skb, portid, seq, cmd, sizeof(*rtm), flags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\trtm = nlmsg_data(nlh);\n\trtm->rtm_family   = RTNL_FAMILY_IPMR;\n\trtm->rtm_dst_len  = 32;\n\trtm->rtm_src_len  = 32;\n\trtm->rtm_tos      = 0;\n\trtm->rtm_table    = mrt->id;\n\tif (nla_put_u32(skb, RTA_TABLE, mrt->id))\n\t\tgoto nla_put_failure;\n\trtm->rtm_type     = RTN_MULTICAST;\n\trtm->rtm_scope    = RT_SCOPE_UNIVERSE;\n\tif (c->_c.mfc_flags & MFC_STATIC)\n\t\trtm->rtm_protocol = RTPROT_STATIC;\n\telse\n\t\trtm->rtm_protocol = RTPROT_MROUTED;\n\trtm->rtm_flags    = 0;\n\n\tif (nla_put_in_addr(skb, RTA_SRC, c->mfc_origin) ||\n\t    nla_put_in_addr(skb, RTA_DST, c->mfc_mcastgrp))\n\t\tgoto nla_put_failure;\n\terr = mr_fill_mroute(mrt, skb, &c->_c, rtm);\n\t \n\tif (err < 0 && err != -ENOENT)\n\t\tgoto nla_put_failure;\n\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}\n\nstatic int _ipmr_fill_mroute(struct mr_table *mrt, struct sk_buff *skb,\n\t\t\t     u32 portid, u32 seq, struct mr_mfc *c, int cmd,\n\t\t\t     int flags)\n{\n\treturn ipmr_fill_mroute(mrt, skb, portid, seq, (struct mfc_cache *)c,\n\t\t\t\tcmd, flags);\n}\n\nstatic size_t mroute_msgsize(bool unresolved, int maxvif)\n{\n\tsize_t len =\n\t\tNLMSG_ALIGN(sizeof(struct rtmsg))\n\t\t+ nla_total_size(4)\t \n\t\t+ nla_total_size(4)\t \n\t\t+ nla_total_size(4)\t \n\t\t;\n\n\tif (!unresolved)\n\t\tlen = len\n\t\t      + nla_total_size(4)\t \n\t\t      + nla_total_size(0)\t \n\t\t      + maxvif * NLA_ALIGN(sizeof(struct rtnexthop))\n\t\t\t\t\t\t \n\t\t      + nla_total_size_64bit(sizeof(struct rta_mfc_stats))\n\t\t;\n\n\treturn len;\n}\n\nstatic void mroute_netlink_event(struct mr_table *mrt, struct mfc_cache *mfc,\n\t\t\t\t int cmd)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct sk_buff *skb;\n\tint err = -ENOBUFS;\n\n\tskb = nlmsg_new(mroute_msgsize(mfc->_c.mfc_parent >= MAXVIFS,\n\t\t\t\t       mrt->maxvif),\n\t\t\tGFP_ATOMIC);\n\tif (!skb)\n\t\tgoto errout;\n\n\terr = ipmr_fill_mroute(mrt, skb, 0, 0, mfc, cmd, 0);\n\tif (err < 0)\n\t\tgoto errout;\n\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV4_MROUTE, NULL, GFP_ATOMIC);\n\treturn;\n\nerrout:\n\tkfree_skb(skb);\n\tif (err < 0)\n\t\trtnl_set_sk_err(net, RTNLGRP_IPV4_MROUTE, err);\n}\n\nstatic size_t igmpmsg_netlink_msgsize(size_t payloadlen)\n{\n\tsize_t len =\n\t\tNLMSG_ALIGN(sizeof(struct rtgenmsg))\n\t\t+ nla_total_size(1)\t \n\t\t+ nla_total_size(4)\t \n\t\t+ nla_total_size(4)\t \n\t\t+ nla_total_size(4)\t \n\t\t+ nla_total_size(4)\t \n\t\t\t\t\t \n\t\t+ nla_total_size(payloadlen)\n\t\t;\n\n\treturn len;\n}\n\nstatic void igmpmsg_netlink_event(const struct mr_table *mrt, struct sk_buff *pkt)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct nlmsghdr *nlh;\n\tstruct rtgenmsg *rtgenm;\n\tstruct igmpmsg *msg;\n\tstruct sk_buff *skb;\n\tstruct nlattr *nla;\n\tint payloadlen;\n\n\tpayloadlen = pkt->len - sizeof(struct igmpmsg);\n\tmsg = (struct igmpmsg *)skb_network_header(pkt);\n\n\tskb = nlmsg_new(igmpmsg_netlink_msgsize(payloadlen), GFP_ATOMIC);\n\tif (!skb)\n\t\tgoto errout;\n\n\tnlh = nlmsg_put(skb, 0, 0, RTM_NEWCACHEREPORT,\n\t\t\tsizeof(struct rtgenmsg), 0);\n\tif (!nlh)\n\t\tgoto errout;\n\trtgenm = nlmsg_data(nlh);\n\trtgenm->rtgen_family = RTNL_FAMILY_IPMR;\n\tif (nla_put_u8(skb, IPMRA_CREPORT_MSGTYPE, msg->im_msgtype) ||\n\t    nla_put_u32(skb, IPMRA_CREPORT_VIF_ID, msg->im_vif | (msg->im_vif_hi << 8)) ||\n\t    nla_put_in_addr(skb, IPMRA_CREPORT_SRC_ADDR,\n\t\t\t    msg->im_src.s_addr) ||\n\t    nla_put_in_addr(skb, IPMRA_CREPORT_DST_ADDR,\n\t\t\t    msg->im_dst.s_addr) ||\n\t    nla_put_u32(skb, IPMRA_CREPORT_TABLE, mrt->id))\n\t\tgoto nla_put_failure;\n\n\tnla = nla_reserve(skb, IPMRA_CREPORT_PKT, payloadlen);\n\tif (!nla || skb_copy_bits(pkt, sizeof(struct igmpmsg),\n\t\t\t\t  nla_data(nla), payloadlen))\n\t\tgoto nla_put_failure;\n\n\tnlmsg_end(skb, nlh);\n\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV4_MROUTE_R, NULL, GFP_ATOMIC);\n\treturn;\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\nerrout:\n\tkfree_skb(skb);\n\trtnl_set_sk_err(net, RTNLGRP_IPV4_MROUTE_R, -ENOBUFS);\n}\n\nstatic int ipmr_rtm_valid_getroute_req(struct sk_buff *skb,\n\t\t\t\t       const struct nlmsghdr *nlh,\n\t\t\t\t       struct nlattr **tb,\n\t\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct rtmsg *rtm;\n\tint i, err;\n\n\tif (nlh->nlmsg_len < nlmsg_msg_size(sizeof(*rtm))) {\n\t\tNL_SET_ERR_MSG(extack, \"ipv4: Invalid header for multicast route get request\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!netlink_strict_get_check(skb))\n\t\treturn nlmsg_parse_deprecated(nlh, sizeof(*rtm), tb, RTA_MAX,\n\t\t\t\t\t      rtm_ipv4_policy, extack);\n\n\trtm = nlmsg_data(nlh);\n\tif ((rtm->rtm_src_len && rtm->rtm_src_len != 32) ||\n\t    (rtm->rtm_dst_len && rtm->rtm_dst_len != 32) ||\n\t    rtm->rtm_tos || rtm->rtm_table || rtm->rtm_protocol ||\n\t    rtm->rtm_scope || rtm->rtm_type || rtm->rtm_flags) {\n\t\tNL_SET_ERR_MSG(extack, \"ipv4: Invalid values in header for multicast route get request\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = nlmsg_parse_deprecated_strict(nlh, sizeof(*rtm), tb, RTA_MAX,\n\t\t\t\t\t    rtm_ipv4_policy, extack);\n\tif (err)\n\t\treturn err;\n\n\tif ((tb[RTA_SRC] && !rtm->rtm_src_len) ||\n\t    (tb[RTA_DST] && !rtm->rtm_dst_len)) {\n\t\tNL_SET_ERR_MSG(extack, \"ipv4: rtm_src_len and rtm_dst_len must be 32 for IPv4\");\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i <= RTA_MAX; i++) {\n\t\tif (!tb[i])\n\t\t\tcontinue;\n\n\t\tswitch (i) {\n\t\tcase RTA_SRC:\n\t\tcase RTA_DST:\n\t\tcase RTA_TABLE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tNL_SET_ERR_MSG(extack, \"ipv4: Unsupported attribute in multicast route get request\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int ipmr_rtm_getroute(struct sk_buff *in_skb, struct nlmsghdr *nlh,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(in_skb->sk);\n\tstruct nlattr *tb[RTA_MAX + 1];\n\tstruct sk_buff *skb = NULL;\n\tstruct mfc_cache *cache;\n\tstruct mr_table *mrt;\n\t__be32 src, grp;\n\tu32 tableid;\n\tint err;\n\n\terr = ipmr_rtm_valid_getroute_req(in_skb, nlh, tb, extack);\n\tif (err < 0)\n\t\tgoto errout;\n\n\tsrc = tb[RTA_SRC] ? nla_get_in_addr(tb[RTA_SRC]) : 0;\n\tgrp = tb[RTA_DST] ? nla_get_in_addr(tb[RTA_DST]) : 0;\n\ttableid = tb[RTA_TABLE] ? nla_get_u32(tb[RTA_TABLE]) : 0;\n\n\tmrt = ipmr_get_table(net, tableid ? tableid : RT_TABLE_DEFAULT);\n\tif (!mrt) {\n\t\terr = -ENOENT;\n\t\tgoto errout_free;\n\t}\n\n\t \n\trcu_read_lock();\n\tcache = ipmr_cache_find(mrt, src, grp);\n\trcu_read_unlock();\n\tif (!cache) {\n\t\terr = -ENOENT;\n\t\tgoto errout_free;\n\t}\n\n\tskb = nlmsg_new(mroute_msgsize(false, mrt->maxvif), GFP_KERNEL);\n\tif (!skb) {\n\t\terr = -ENOBUFS;\n\t\tgoto errout_free;\n\t}\n\n\terr = ipmr_fill_mroute(mrt, skb, NETLINK_CB(in_skb).portid,\n\t\t\t       nlh->nlmsg_seq, cache,\n\t\t\t       RTM_NEWROUTE, 0);\n\tif (err < 0)\n\t\tgoto errout_free;\n\n\terr = rtnl_unicast(skb, net, NETLINK_CB(in_skb).portid);\n\nerrout:\n\treturn err;\n\nerrout_free:\n\tkfree_skb(skb);\n\tgoto errout;\n}\n\nstatic int ipmr_rtm_dumproute(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct fib_dump_filter filter = {};\n\tint err;\n\n\tif (cb->strict_check) {\n\t\terr = ip_valid_fib_dump_req(sock_net(skb->sk), cb->nlh,\n\t\t\t\t\t    &filter, cb);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\tif (filter.table_id) {\n\t\tstruct mr_table *mrt;\n\n\t\tmrt = ipmr_get_table(sock_net(skb->sk), filter.table_id);\n\t\tif (!mrt) {\n\t\t\tif (rtnl_msg_family(cb->nlh) != RTNL_FAMILY_IPMR)\n\t\t\t\treturn skb->len;\n\n\t\t\tNL_SET_ERR_MSG(cb->extack, \"ipv4: MR table does not exist\");\n\t\t\treturn -ENOENT;\n\t\t}\n\t\terr = mr_table_dump(mrt, skb, cb, _ipmr_fill_mroute,\n\t\t\t\t    &mfc_unres_lock, &filter);\n\t\treturn skb->len ? : err;\n\t}\n\n\treturn mr_rtm_dumproute(skb, cb, ipmr_mr_table_iter,\n\t\t\t\t_ipmr_fill_mroute, &mfc_unres_lock, &filter);\n}\n\nstatic const struct nla_policy rtm_ipmr_policy[RTA_MAX + 1] = {\n\t[RTA_SRC]\t= { .type = NLA_U32 },\n\t[RTA_DST]\t= { .type = NLA_U32 },\n\t[RTA_IIF]\t= { .type = NLA_U32 },\n\t[RTA_TABLE]\t= { .type = NLA_U32 },\n\t[RTA_MULTIPATH]\t= { .len = sizeof(struct rtnexthop) },\n};\n\nstatic bool ipmr_rtm_validate_proto(unsigned char rtm_protocol)\n{\n\tswitch (rtm_protocol) {\n\tcase RTPROT_STATIC:\n\tcase RTPROT_MROUTED:\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic int ipmr_nla_get_ttls(const struct nlattr *nla, struct mfcctl *mfcc)\n{\n\tstruct rtnexthop *rtnh = nla_data(nla);\n\tint remaining = nla_len(nla), vifi = 0;\n\n\twhile (rtnh_ok(rtnh, remaining)) {\n\t\tmfcc->mfcc_ttls[vifi] = rtnh->rtnh_hops;\n\t\tif (++vifi == MAXVIFS)\n\t\t\tbreak;\n\t\trtnh = rtnh_next(rtnh, &remaining);\n\t}\n\n\treturn remaining > 0 ? -EINVAL : vifi;\n}\n\n \nstatic int rtm_to_ipmr_mfcc(struct net *net, struct nlmsghdr *nlh,\n\t\t\t    struct mfcctl *mfcc, int *mrtsock,\n\t\t\t    struct mr_table **mrtret,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct net_device *dev = NULL;\n\tu32 tblid = RT_TABLE_DEFAULT;\n\tstruct mr_table *mrt;\n\tstruct nlattr *attr;\n\tstruct rtmsg *rtm;\n\tint ret, rem;\n\n\tret = nlmsg_validate_deprecated(nlh, sizeof(*rtm), RTA_MAX,\n\t\t\t\t\trtm_ipmr_policy, extack);\n\tif (ret < 0)\n\t\tgoto out;\n\trtm = nlmsg_data(nlh);\n\n\tret = -EINVAL;\n\tif (rtm->rtm_family != RTNL_FAMILY_IPMR || rtm->rtm_dst_len != 32 ||\n\t    rtm->rtm_type != RTN_MULTICAST ||\n\t    rtm->rtm_scope != RT_SCOPE_UNIVERSE ||\n\t    !ipmr_rtm_validate_proto(rtm->rtm_protocol))\n\t\tgoto out;\n\n\tmemset(mfcc, 0, sizeof(*mfcc));\n\tmfcc->mfcc_parent = -1;\n\tret = 0;\n\tnlmsg_for_each_attr(attr, nlh, sizeof(struct rtmsg), rem) {\n\t\tswitch (nla_type(attr)) {\n\t\tcase RTA_SRC:\n\t\t\tmfcc->mfcc_origin.s_addr = nla_get_be32(attr);\n\t\t\tbreak;\n\t\tcase RTA_DST:\n\t\t\tmfcc->mfcc_mcastgrp.s_addr = nla_get_be32(attr);\n\t\t\tbreak;\n\t\tcase RTA_IIF:\n\t\t\tdev = __dev_get_by_index(net, nla_get_u32(attr));\n\t\t\tif (!dev) {\n\t\t\t\tret = -ENODEV;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase RTA_MULTIPATH:\n\t\t\tif (ipmr_nla_get_ttls(attr, mfcc) < 0) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase RTA_PREFSRC:\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\tcase RTA_TABLE:\n\t\t\ttblid = nla_get_u32(attr);\n\t\t\tbreak;\n\t\t}\n\t}\n\tmrt = ipmr_get_table(net, tblid);\n\tif (!mrt) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\t*mrtret = mrt;\n\t*mrtsock = rtm->rtm_protocol == RTPROT_MROUTED ? 1 : 0;\n\tif (dev)\n\t\tmfcc->mfcc_parent = ipmr_find_vif(mrt, dev);\n\nout:\n\treturn ret;\n}\n\n \nstatic int ipmr_rtm_route(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tint ret, mrtsock, parent;\n\tstruct mr_table *tbl;\n\tstruct mfcctl mfcc;\n\n\tmrtsock = 0;\n\ttbl = NULL;\n\tret = rtm_to_ipmr_mfcc(net, nlh, &mfcc, &mrtsock, &tbl, extack);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tparent = ret ? mfcc.mfcc_parent : -1;\n\tif (nlh->nlmsg_type == RTM_NEWROUTE)\n\t\treturn ipmr_mfc_add(net, tbl, &mfcc, mrtsock, parent);\n\telse\n\t\treturn ipmr_mfc_delete(tbl, &mfcc, parent);\n}\n\nstatic bool ipmr_fill_table(struct mr_table *mrt, struct sk_buff *skb)\n{\n\tu32 queue_len = atomic_read(&mrt->cache_resolve_queue_len);\n\n\tif (nla_put_u32(skb, IPMRA_TABLE_ID, mrt->id) ||\n\t    nla_put_u32(skb, IPMRA_TABLE_CACHE_RES_QUEUE_LEN, queue_len) ||\n\t    nla_put_s32(skb, IPMRA_TABLE_MROUTE_REG_VIF_NUM,\n\t\t\tmrt->mroute_reg_vif_num) ||\n\t    nla_put_u8(skb, IPMRA_TABLE_MROUTE_DO_ASSERT,\n\t\t       mrt->mroute_do_assert) ||\n\t    nla_put_u8(skb, IPMRA_TABLE_MROUTE_DO_PIM, mrt->mroute_do_pim) ||\n\t    nla_put_u8(skb, IPMRA_TABLE_MROUTE_DO_WRVIFWHOLE,\n\t\t       mrt->mroute_do_wrvifwhole))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic bool ipmr_fill_vif(struct mr_table *mrt, u32 vifid, struct sk_buff *skb)\n{\n\tstruct net_device *vif_dev;\n\tstruct nlattr *vif_nest;\n\tstruct vif_device *vif;\n\n\tvif = &mrt->vif_table[vifid];\n\tvif_dev = rtnl_dereference(vif->dev);\n\t \n\tif (!vif_dev)\n\t\treturn true;\n\n\tvif_nest = nla_nest_start_noflag(skb, IPMRA_VIF);\n\tif (!vif_nest)\n\t\treturn false;\n\n\tif (nla_put_u32(skb, IPMRA_VIFA_IFINDEX, vif_dev->ifindex) ||\n\t    nla_put_u32(skb, IPMRA_VIFA_VIF_ID, vifid) ||\n\t    nla_put_u16(skb, IPMRA_VIFA_FLAGS, vif->flags) ||\n\t    nla_put_u64_64bit(skb, IPMRA_VIFA_BYTES_IN, vif->bytes_in,\n\t\t\t      IPMRA_VIFA_PAD) ||\n\t    nla_put_u64_64bit(skb, IPMRA_VIFA_BYTES_OUT, vif->bytes_out,\n\t\t\t      IPMRA_VIFA_PAD) ||\n\t    nla_put_u64_64bit(skb, IPMRA_VIFA_PACKETS_IN, vif->pkt_in,\n\t\t\t      IPMRA_VIFA_PAD) ||\n\t    nla_put_u64_64bit(skb, IPMRA_VIFA_PACKETS_OUT, vif->pkt_out,\n\t\t\t      IPMRA_VIFA_PAD) ||\n\t    nla_put_be32(skb, IPMRA_VIFA_LOCAL_ADDR, vif->local) ||\n\t    nla_put_be32(skb, IPMRA_VIFA_REMOTE_ADDR, vif->remote)) {\n\t\tnla_nest_cancel(skb, vif_nest);\n\t\treturn false;\n\t}\n\tnla_nest_end(skb, vif_nest);\n\n\treturn true;\n}\n\nstatic int ipmr_valid_dumplink(const struct nlmsghdr *nlh,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct ifinfomsg *ifm;\n\n\tif (nlh->nlmsg_len < nlmsg_msg_size(sizeof(*ifm))) {\n\t\tNL_SET_ERR_MSG(extack, \"ipv4: Invalid header for ipmr link dump\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (nlmsg_attrlen(nlh, sizeof(*ifm))) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid data after header in ipmr link dump\");\n\t\treturn -EINVAL;\n\t}\n\n\tifm = nlmsg_data(nlh);\n\tif (ifm->__ifi_pad || ifm->ifi_type || ifm->ifi_flags ||\n\t    ifm->ifi_change || ifm->ifi_index) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid values in header for ipmr link dump request\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int ipmr_rtm_dumplink(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlmsghdr *nlh = NULL;\n\tunsigned int t = 0, s_t;\n\tunsigned int e = 0, s_e;\n\tstruct mr_table *mrt;\n\n\tif (cb->strict_check) {\n\t\tint err = ipmr_valid_dumplink(cb->nlh, cb->extack);\n\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\ts_t = cb->args[0];\n\ts_e = cb->args[1];\n\n\tipmr_for_each_table(mrt, net) {\n\t\tstruct nlattr *vifs, *af;\n\t\tstruct ifinfomsg *hdr;\n\t\tu32 i;\n\n\t\tif (t < s_t)\n\t\t\tgoto skip_table;\n\t\tnlh = nlmsg_put(skb, NETLINK_CB(cb->skb).portid,\n\t\t\t\tcb->nlh->nlmsg_seq, RTM_NEWLINK,\n\t\t\t\tsizeof(*hdr), NLM_F_MULTI);\n\t\tif (!nlh)\n\t\t\tbreak;\n\n\t\thdr = nlmsg_data(nlh);\n\t\tmemset(hdr, 0, sizeof(*hdr));\n\t\thdr->ifi_family = RTNL_FAMILY_IPMR;\n\n\t\taf = nla_nest_start_noflag(skb, IFLA_AF_SPEC);\n\t\tif (!af) {\n\t\t\tnlmsg_cancel(skb, nlh);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!ipmr_fill_table(mrt, skb)) {\n\t\t\tnlmsg_cancel(skb, nlh);\n\t\t\tgoto out;\n\t\t}\n\n\t\tvifs = nla_nest_start_noflag(skb, IPMRA_TABLE_VIFS);\n\t\tif (!vifs) {\n\t\t\tnla_nest_end(skb, af);\n\t\t\tnlmsg_end(skb, nlh);\n\t\t\tgoto out;\n\t\t}\n\t\tfor (i = 0; i < mrt->maxvif; i++) {\n\t\t\tif (e < s_e)\n\t\t\t\tgoto skip_entry;\n\t\t\tif (!ipmr_fill_vif(mrt, i, skb)) {\n\t\t\t\tnla_nest_end(skb, vifs);\n\t\t\t\tnla_nest_end(skb, af);\n\t\t\t\tnlmsg_end(skb, nlh);\n\t\t\t\tgoto out;\n\t\t\t}\nskip_entry:\n\t\t\te++;\n\t\t}\n\t\ts_e = 0;\n\t\te = 0;\n\t\tnla_nest_end(skb, vifs);\n\t\tnla_nest_end(skb, af);\n\t\tnlmsg_end(skb, nlh);\nskip_table:\n\t\tt++;\n\t}\n\nout:\n\tcb->args[1] = e;\n\tcb->args[0] = t;\n\n\treturn skb->len;\n}\n\n#ifdef CONFIG_PROC_FS\n \n\nstatic void *ipmr_vif_seq_start(struct seq_file *seq, loff_t *pos)\n\t__acquires(RCU)\n{\n\tstruct mr_vif_iter *iter = seq->private;\n\tstruct net *net = seq_file_net(seq);\n\tstruct mr_table *mrt;\n\n\tmrt = ipmr_get_table(net, RT_TABLE_DEFAULT);\n\tif (!mrt)\n\t\treturn ERR_PTR(-ENOENT);\n\n\titer->mrt = mrt;\n\n\trcu_read_lock();\n\treturn mr_vif_seq_start(seq, pos);\n}\n\nstatic void ipmr_vif_seq_stop(struct seq_file *seq, void *v)\n\t__releases(RCU)\n{\n\trcu_read_unlock();\n}\n\nstatic int ipmr_vif_seq_show(struct seq_file *seq, void *v)\n{\n\tstruct mr_vif_iter *iter = seq->private;\n\tstruct mr_table *mrt = iter->mrt;\n\n\tif (v == SEQ_START_TOKEN) {\n\t\tseq_puts(seq,\n\t\t\t \"Interface      BytesIn  PktsIn  BytesOut PktsOut Flags Local    Remote\\n\");\n\t} else {\n\t\tconst struct vif_device *vif = v;\n\t\tconst struct net_device *vif_dev;\n\t\tconst char *name;\n\n\t\tvif_dev = vif_dev_read(vif);\n\t\tname = vif_dev ? vif_dev->name : \"none\";\n\t\tseq_printf(seq,\n\t\t\t   \"%2td %-10s %8ld %7ld  %8ld %7ld %05X %08X %08X\\n\",\n\t\t\t   vif - mrt->vif_table,\n\t\t\t   name, vif->bytes_in, vif->pkt_in,\n\t\t\t   vif->bytes_out, vif->pkt_out,\n\t\t\t   vif->flags, vif->local, vif->remote);\n\t}\n\treturn 0;\n}\n\nstatic const struct seq_operations ipmr_vif_seq_ops = {\n\t.start = ipmr_vif_seq_start,\n\t.next  = mr_vif_seq_next,\n\t.stop  = ipmr_vif_seq_stop,\n\t.show  = ipmr_vif_seq_show,\n};\n\nstatic void *ipmr_mfc_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tstruct net *net = seq_file_net(seq);\n\tstruct mr_table *mrt;\n\n\tmrt = ipmr_get_table(net, RT_TABLE_DEFAULT);\n\tif (!mrt)\n\t\treturn ERR_PTR(-ENOENT);\n\n\treturn mr_mfc_seq_start(seq, pos, mrt, &mfc_unres_lock);\n}\n\nstatic int ipmr_mfc_seq_show(struct seq_file *seq, void *v)\n{\n\tint n;\n\n\tif (v == SEQ_START_TOKEN) {\n\t\tseq_puts(seq,\n\t\t \"Group    Origin   Iif     Pkts    Bytes    Wrong Oifs\\n\");\n\t} else {\n\t\tconst struct mfc_cache *mfc = v;\n\t\tconst struct mr_mfc_iter *it = seq->private;\n\t\tconst struct mr_table *mrt = it->mrt;\n\n\t\tseq_printf(seq, \"%08X %08X %-3hd\",\n\t\t\t   (__force u32) mfc->mfc_mcastgrp,\n\t\t\t   (__force u32) mfc->mfc_origin,\n\t\t\t   mfc->_c.mfc_parent);\n\n\t\tif (it->cache != &mrt->mfc_unres_queue) {\n\t\t\tseq_printf(seq, \" %8lu %8lu %8lu\",\n\t\t\t\t   mfc->_c.mfc_un.res.pkt,\n\t\t\t\t   mfc->_c.mfc_un.res.bytes,\n\t\t\t\t   mfc->_c.mfc_un.res.wrong_if);\n\t\t\tfor (n = mfc->_c.mfc_un.res.minvif;\n\t\t\t     n < mfc->_c.mfc_un.res.maxvif; n++) {\n\t\t\t\tif (VIF_EXISTS(mrt, n) &&\n\t\t\t\t    mfc->_c.mfc_un.res.ttls[n] < 255)\n\t\t\t\t\tseq_printf(seq,\n\t\t\t\t\t   \" %2d:%-3d\",\n\t\t\t\t\t   n, mfc->_c.mfc_un.res.ttls[n]);\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tseq_printf(seq, \" %8lu %8lu %8lu\", 0ul, 0ul, 0ul);\n\t\t}\n\t\tseq_putc(seq, '\\n');\n\t}\n\treturn 0;\n}\n\nstatic const struct seq_operations ipmr_mfc_seq_ops = {\n\t.start = ipmr_mfc_seq_start,\n\t.next  = mr_mfc_seq_next,\n\t.stop  = mr_mfc_seq_stop,\n\t.show  = ipmr_mfc_seq_show,\n};\n#endif\n\n#ifdef CONFIG_IP_PIMSM_V2\nstatic const struct net_protocol pim_protocol = {\n\t.handler\t=\tpim_rcv,\n};\n#endif\n\nstatic unsigned int ipmr_seq_read(struct net *net)\n{\n\tASSERT_RTNL();\n\n\treturn net->ipv4.ipmr_seq + ipmr_rules_seq_read(net);\n}\n\nstatic int ipmr_dump(struct net *net, struct notifier_block *nb,\n\t\t     struct netlink_ext_ack *extack)\n{\n\treturn mr_dump(net, nb, RTNL_FAMILY_IPMR, ipmr_rules_dump,\n\t\t       ipmr_mr_table_iter, extack);\n}\n\nstatic const struct fib_notifier_ops ipmr_notifier_ops_template = {\n\t.family\t\t= RTNL_FAMILY_IPMR,\n\t.fib_seq_read\t= ipmr_seq_read,\n\t.fib_dump\t= ipmr_dump,\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic int __net_init ipmr_notifier_init(struct net *net)\n{\n\tstruct fib_notifier_ops *ops;\n\n\tnet->ipv4.ipmr_seq = 0;\n\n\tops = fib_notifier_ops_register(&ipmr_notifier_ops_template, net);\n\tif (IS_ERR(ops))\n\t\treturn PTR_ERR(ops);\n\tnet->ipv4.ipmr_notifier_ops = ops;\n\n\treturn 0;\n}\n\nstatic void __net_exit ipmr_notifier_exit(struct net *net)\n{\n\tfib_notifier_ops_unregister(net->ipv4.ipmr_notifier_ops);\n\tnet->ipv4.ipmr_notifier_ops = NULL;\n}\n\n \nstatic int __net_init ipmr_net_init(struct net *net)\n{\n\tint err;\n\n\terr = ipmr_notifier_init(net);\n\tif (err)\n\t\tgoto ipmr_notifier_fail;\n\n\terr = ipmr_rules_init(net);\n\tif (err < 0)\n\t\tgoto ipmr_rules_fail;\n\n#ifdef CONFIG_PROC_FS\n\terr = -ENOMEM;\n\tif (!proc_create_net(\"ip_mr_vif\", 0, net->proc_net, &ipmr_vif_seq_ops,\n\t\t\tsizeof(struct mr_vif_iter)))\n\t\tgoto proc_vif_fail;\n\tif (!proc_create_net(\"ip_mr_cache\", 0, net->proc_net, &ipmr_mfc_seq_ops,\n\t\t\tsizeof(struct mr_mfc_iter)))\n\t\tgoto proc_cache_fail;\n#endif\n\treturn 0;\n\n#ifdef CONFIG_PROC_FS\nproc_cache_fail:\n\tremove_proc_entry(\"ip_mr_vif\", net->proc_net);\nproc_vif_fail:\n\trtnl_lock();\n\tipmr_rules_exit(net);\n\trtnl_unlock();\n#endif\nipmr_rules_fail:\n\tipmr_notifier_exit(net);\nipmr_notifier_fail:\n\treturn err;\n}\n\nstatic void __net_exit ipmr_net_exit(struct net *net)\n{\n#ifdef CONFIG_PROC_FS\n\tremove_proc_entry(\"ip_mr_cache\", net->proc_net);\n\tremove_proc_entry(\"ip_mr_vif\", net->proc_net);\n#endif\n\tipmr_notifier_exit(net);\n}\n\nstatic void __net_exit ipmr_net_exit_batch(struct list_head *net_list)\n{\n\tstruct net *net;\n\n\trtnl_lock();\n\tlist_for_each_entry(net, net_list, exit_list)\n\t\tipmr_rules_exit(net);\n\trtnl_unlock();\n}\n\nstatic struct pernet_operations ipmr_net_ops = {\n\t.init = ipmr_net_init,\n\t.exit = ipmr_net_exit,\n\t.exit_batch = ipmr_net_exit_batch,\n};\n\nint __init ip_mr_init(void)\n{\n\tint err;\n\n\tmrt_cachep = kmem_cache_create(\"ip_mrt_cache\",\n\t\t\t\t       sizeof(struct mfc_cache),\n\t\t\t\t       0, SLAB_HWCACHE_ALIGN | SLAB_PANIC,\n\t\t\t\t       NULL);\n\n\terr = register_pernet_subsys(&ipmr_net_ops);\n\tif (err)\n\t\tgoto reg_pernet_fail;\n\n\terr = register_netdevice_notifier(&ip_mr_notifier);\n\tif (err)\n\t\tgoto reg_notif_fail;\n#ifdef CONFIG_IP_PIMSM_V2\n\tif (inet_add_protocol(&pim_protocol, IPPROTO_PIM) < 0) {\n\t\tpr_err(\"%s: can't add PIM protocol\\n\", __func__);\n\t\terr = -EAGAIN;\n\t\tgoto add_proto_fail;\n\t}\n#endif\n\trtnl_register(RTNL_FAMILY_IPMR, RTM_GETROUTE,\n\t\t      ipmr_rtm_getroute, ipmr_rtm_dumproute, 0);\n\trtnl_register(RTNL_FAMILY_IPMR, RTM_NEWROUTE,\n\t\t      ipmr_rtm_route, NULL, 0);\n\trtnl_register(RTNL_FAMILY_IPMR, RTM_DELROUTE,\n\t\t      ipmr_rtm_route, NULL, 0);\n\n\trtnl_register(RTNL_FAMILY_IPMR, RTM_GETLINK,\n\t\t      NULL, ipmr_rtm_dumplink, 0);\n\treturn 0;\n\n#ifdef CONFIG_IP_PIMSM_V2\nadd_proto_fail:\n\tunregister_netdevice_notifier(&ip_mr_notifier);\n#endif\nreg_notif_fail:\n\tunregister_pernet_subsys(&ipmr_net_ops);\nreg_pernet_fail:\n\tkmem_cache_destroy(mrt_cachep);\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}