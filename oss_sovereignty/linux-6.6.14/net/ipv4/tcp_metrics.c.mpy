{
  "module_name": "tcp_metrics.c",
  "hash_id": "e3fd3a82ac71422ff92ad12c2fc1eec0ecb693cf56d155e37177a437fd54c91d",
  "original_prompt": "Ingested from linux-6.6.14/net/ipv4/tcp_metrics.c",
  "human_readable_source": "\n#include <linux/rcupdate.h>\n#include <linux/spinlock.h>\n#include <linux/jiffies.h>\n#include <linux/module.h>\n#include <linux/cache.h>\n#include <linux/slab.h>\n#include <linux/init.h>\n#include <linux/tcp.h>\n#include <linux/hash.h>\n#include <linux/tcp_metrics.h>\n#include <linux/vmalloc.h>\n\n#include <net/inet_connection_sock.h>\n#include <net/net_namespace.h>\n#include <net/request_sock.h>\n#include <net/inetpeer.h>\n#include <net/sock.h>\n#include <net/ipv6.h>\n#include <net/dst.h>\n#include <net/tcp.h>\n#include <net/genetlink.h>\n\nstatic struct tcp_metrics_block *__tcp_get_metrics(const struct inetpeer_addr *saddr,\n\t\t\t\t\t\t   const struct inetpeer_addr *daddr,\n\t\t\t\t\t\t   struct net *net, unsigned int hash);\n\nstruct tcp_fastopen_metrics {\n\tu16\tmss;\n\tu16\tsyn_loss:10,\t\t \n\t\ttry_exp:2;\t\t \n\tunsigned long\tlast_syn_loss;\t \n\tstruct\ttcp_fastopen_cookie\tcookie;\n};\n\n \n#define TCP_METRIC_MAX_KERNEL (TCP_METRIC_MAX - 2)\n\nstruct tcp_metrics_block {\n\tstruct tcp_metrics_block __rcu\t*tcpm_next;\n\tstruct net\t\t\t*tcpm_net;\n\tstruct inetpeer_addr\t\ttcpm_saddr;\n\tstruct inetpeer_addr\t\ttcpm_daddr;\n\tunsigned long\t\t\ttcpm_stamp;\n\tu32\t\t\t\ttcpm_lock;\n\tu32\t\t\t\ttcpm_vals[TCP_METRIC_MAX_KERNEL + 1];\n\tstruct tcp_fastopen_metrics\ttcpm_fastopen;\n\n\tstruct rcu_head\t\t\trcu_head;\n};\n\nstatic inline struct net *tm_net(const struct tcp_metrics_block *tm)\n{\n\t \n\treturn READ_ONCE(tm->tcpm_net);\n}\n\nstatic bool tcp_metric_locked(struct tcp_metrics_block *tm,\n\t\t\t      enum tcp_metric_index idx)\n{\n\t \n\treturn READ_ONCE(tm->tcpm_lock) & (1 << idx);\n}\n\nstatic u32 tcp_metric_get(const struct tcp_metrics_block *tm,\n\t\t\t  enum tcp_metric_index idx)\n{\n\t \n\treturn READ_ONCE(tm->tcpm_vals[idx]);\n}\n\nstatic void tcp_metric_set(struct tcp_metrics_block *tm,\n\t\t\t   enum tcp_metric_index idx,\n\t\t\t   u32 val)\n{\n\t \n\tWRITE_ONCE(tm->tcpm_vals[idx], val);\n}\n\nstatic bool addr_same(const struct inetpeer_addr *a,\n\t\t      const struct inetpeer_addr *b)\n{\n\treturn (a->family == b->family) && !inetpeer_addr_cmp(a, b);\n}\n\nstruct tcpm_hash_bucket {\n\tstruct tcp_metrics_block __rcu\t*chain;\n};\n\nstatic struct tcpm_hash_bucket\t*tcp_metrics_hash __read_mostly;\nstatic unsigned int\t\ttcp_metrics_hash_log __read_mostly;\n\nstatic DEFINE_SPINLOCK(tcp_metrics_lock);\nstatic DEFINE_SEQLOCK(fastopen_seqlock);\n\nstatic void tcpm_suck_dst(struct tcp_metrics_block *tm,\n\t\t\t  const struct dst_entry *dst,\n\t\t\t  bool fastopen_clear)\n{\n\tu32 msval;\n\tu32 val;\n\n\tWRITE_ONCE(tm->tcpm_stamp, jiffies);\n\n\tval = 0;\n\tif (dst_metric_locked(dst, RTAX_RTT))\n\t\tval |= 1 << TCP_METRIC_RTT;\n\tif (dst_metric_locked(dst, RTAX_RTTVAR))\n\t\tval |= 1 << TCP_METRIC_RTTVAR;\n\tif (dst_metric_locked(dst, RTAX_SSTHRESH))\n\t\tval |= 1 << TCP_METRIC_SSTHRESH;\n\tif (dst_metric_locked(dst, RTAX_CWND))\n\t\tval |= 1 << TCP_METRIC_CWND;\n\tif (dst_metric_locked(dst, RTAX_REORDERING))\n\t\tval |= 1 << TCP_METRIC_REORDERING;\n\t \n\tWRITE_ONCE(tm->tcpm_lock, val);\n\n\tmsval = dst_metric_raw(dst, RTAX_RTT);\n\ttcp_metric_set(tm, TCP_METRIC_RTT, msval * USEC_PER_MSEC);\n\n\tmsval = dst_metric_raw(dst, RTAX_RTTVAR);\n\ttcp_metric_set(tm, TCP_METRIC_RTTVAR, msval * USEC_PER_MSEC);\n\ttcp_metric_set(tm, TCP_METRIC_SSTHRESH,\n\t\t       dst_metric_raw(dst, RTAX_SSTHRESH));\n\ttcp_metric_set(tm, TCP_METRIC_CWND,\n\t\t       dst_metric_raw(dst, RTAX_CWND));\n\ttcp_metric_set(tm, TCP_METRIC_REORDERING,\n\t\t       dst_metric_raw(dst, RTAX_REORDERING));\n\tif (fastopen_clear) {\n\t\twrite_seqlock(&fastopen_seqlock);\n\t\ttm->tcpm_fastopen.mss = 0;\n\t\ttm->tcpm_fastopen.syn_loss = 0;\n\t\ttm->tcpm_fastopen.try_exp = 0;\n\t\ttm->tcpm_fastopen.cookie.exp = false;\n\t\ttm->tcpm_fastopen.cookie.len = 0;\n\t\twrite_sequnlock(&fastopen_seqlock);\n\t}\n}\n\n#define TCP_METRICS_TIMEOUT\t\t(60 * 60 * HZ)\n\nstatic void tcpm_check_stamp(struct tcp_metrics_block *tm,\n\t\t\t     const struct dst_entry *dst)\n{\n\tunsigned long limit;\n\n\tif (!tm)\n\t\treturn;\n\tlimit = READ_ONCE(tm->tcpm_stamp) + TCP_METRICS_TIMEOUT;\n\tif (unlikely(time_after(jiffies, limit)))\n\t\ttcpm_suck_dst(tm, dst, false);\n}\n\n#define TCP_METRICS_RECLAIM_DEPTH\t5\n#define TCP_METRICS_RECLAIM_PTR\t\t(struct tcp_metrics_block *) 0x1UL\n\n#define deref_locked(p)\t\\\n\trcu_dereference_protected(p, lockdep_is_held(&tcp_metrics_lock))\n\nstatic struct tcp_metrics_block *tcpm_new(struct dst_entry *dst,\n\t\t\t\t\t  struct inetpeer_addr *saddr,\n\t\t\t\t\t  struct inetpeer_addr *daddr,\n\t\t\t\t\t  unsigned int hash)\n{\n\tstruct tcp_metrics_block *tm;\n\tstruct net *net;\n\tbool reclaim = false;\n\n\tspin_lock_bh(&tcp_metrics_lock);\n\tnet = dev_net(dst->dev);\n\n\t \n\ttm = __tcp_get_metrics(saddr, daddr, net, hash);\n\tif (tm == TCP_METRICS_RECLAIM_PTR) {\n\t\treclaim = true;\n\t\ttm = NULL;\n\t}\n\tif (tm) {\n\t\ttcpm_check_stamp(tm, dst);\n\t\tgoto out_unlock;\n\t}\n\n\tif (unlikely(reclaim)) {\n\t\tstruct tcp_metrics_block *oldest;\n\n\t\toldest = deref_locked(tcp_metrics_hash[hash].chain);\n\t\tfor (tm = deref_locked(oldest->tcpm_next); tm;\n\t\t     tm = deref_locked(tm->tcpm_next)) {\n\t\t\tif (time_before(READ_ONCE(tm->tcpm_stamp),\n\t\t\t\t\tREAD_ONCE(oldest->tcpm_stamp)))\n\t\t\t\toldest = tm;\n\t\t}\n\t\ttm = oldest;\n\t} else {\n\t\ttm = kzalloc(sizeof(*tm), GFP_ATOMIC);\n\t\tif (!tm)\n\t\t\tgoto out_unlock;\n\t}\n\t \n\tWRITE_ONCE(tm->tcpm_net, net);\n\n\ttm->tcpm_saddr = *saddr;\n\ttm->tcpm_daddr = *daddr;\n\n\ttcpm_suck_dst(tm, dst, reclaim);\n\n\tif (likely(!reclaim)) {\n\t\ttm->tcpm_next = tcp_metrics_hash[hash].chain;\n\t\trcu_assign_pointer(tcp_metrics_hash[hash].chain, tm);\n\t}\n\nout_unlock:\n\tspin_unlock_bh(&tcp_metrics_lock);\n\treturn tm;\n}\n\nstatic struct tcp_metrics_block *tcp_get_encode(struct tcp_metrics_block *tm, int depth)\n{\n\tif (tm)\n\t\treturn tm;\n\tif (depth > TCP_METRICS_RECLAIM_DEPTH)\n\t\treturn TCP_METRICS_RECLAIM_PTR;\n\treturn NULL;\n}\n\nstatic struct tcp_metrics_block *__tcp_get_metrics(const struct inetpeer_addr *saddr,\n\t\t\t\t\t\t   const struct inetpeer_addr *daddr,\n\t\t\t\t\t\t   struct net *net, unsigned int hash)\n{\n\tstruct tcp_metrics_block *tm;\n\tint depth = 0;\n\n\tfor (tm = rcu_dereference(tcp_metrics_hash[hash].chain); tm;\n\t     tm = rcu_dereference(tm->tcpm_next)) {\n\t\tif (addr_same(&tm->tcpm_saddr, saddr) &&\n\t\t    addr_same(&tm->tcpm_daddr, daddr) &&\n\t\t    net_eq(tm_net(tm), net))\n\t\t\tbreak;\n\t\tdepth++;\n\t}\n\treturn tcp_get_encode(tm, depth);\n}\n\nstatic struct tcp_metrics_block *__tcp_get_metrics_req(struct request_sock *req,\n\t\t\t\t\t\t       struct dst_entry *dst)\n{\n\tstruct tcp_metrics_block *tm;\n\tstruct inetpeer_addr saddr, daddr;\n\tunsigned int hash;\n\tstruct net *net;\n\n\tsaddr.family = req->rsk_ops->family;\n\tdaddr.family = req->rsk_ops->family;\n\tswitch (daddr.family) {\n\tcase AF_INET:\n\t\tinetpeer_set_addr_v4(&saddr, inet_rsk(req)->ir_loc_addr);\n\t\tinetpeer_set_addr_v4(&daddr, inet_rsk(req)->ir_rmt_addr);\n\t\thash = ipv4_addr_hash(inet_rsk(req)->ir_rmt_addr);\n\t\tbreak;\n#if IS_ENABLED(CONFIG_IPV6)\n\tcase AF_INET6:\n\t\tinetpeer_set_addr_v6(&saddr, &inet_rsk(req)->ir_v6_loc_addr);\n\t\tinetpeer_set_addr_v6(&daddr, &inet_rsk(req)->ir_v6_rmt_addr);\n\t\thash = ipv6_addr_hash(&inet_rsk(req)->ir_v6_rmt_addr);\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn NULL;\n\t}\n\n\tnet = dev_net(dst->dev);\n\thash ^= net_hash_mix(net);\n\thash = hash_32(hash, tcp_metrics_hash_log);\n\n\tfor (tm = rcu_dereference(tcp_metrics_hash[hash].chain); tm;\n\t     tm = rcu_dereference(tm->tcpm_next)) {\n\t\tif (addr_same(&tm->tcpm_saddr, &saddr) &&\n\t\t    addr_same(&tm->tcpm_daddr, &daddr) &&\n\t\t    net_eq(tm_net(tm), net))\n\t\t\tbreak;\n\t}\n\ttcpm_check_stamp(tm, dst);\n\treturn tm;\n}\n\nstatic struct tcp_metrics_block *tcp_get_metrics(struct sock *sk,\n\t\t\t\t\t\t struct dst_entry *dst,\n\t\t\t\t\t\t bool create)\n{\n\tstruct tcp_metrics_block *tm;\n\tstruct inetpeer_addr saddr, daddr;\n\tunsigned int hash;\n\tstruct net *net;\n\n\tif (sk->sk_family == AF_INET) {\n\t\tinetpeer_set_addr_v4(&saddr, inet_sk(sk)->inet_saddr);\n\t\tinetpeer_set_addr_v4(&daddr, inet_sk(sk)->inet_daddr);\n\t\thash = ipv4_addr_hash(inet_sk(sk)->inet_daddr);\n\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\telse if (sk->sk_family == AF_INET6) {\n\t\tif (ipv6_addr_v4mapped(&sk->sk_v6_daddr)) {\n\t\t\tinetpeer_set_addr_v4(&saddr, inet_sk(sk)->inet_saddr);\n\t\t\tinetpeer_set_addr_v4(&daddr, inet_sk(sk)->inet_daddr);\n\t\t\thash = ipv4_addr_hash(inet_sk(sk)->inet_daddr);\n\t\t} else {\n\t\t\tinetpeer_set_addr_v6(&saddr, &sk->sk_v6_rcv_saddr);\n\t\t\tinetpeer_set_addr_v6(&daddr, &sk->sk_v6_daddr);\n\t\t\thash = ipv6_addr_hash(&sk->sk_v6_daddr);\n\t\t}\n\t}\n#endif\n\telse\n\t\treturn NULL;\n\n\tnet = dev_net(dst->dev);\n\thash ^= net_hash_mix(net);\n\thash = hash_32(hash, tcp_metrics_hash_log);\n\n\ttm = __tcp_get_metrics(&saddr, &daddr, net, hash);\n\tif (tm == TCP_METRICS_RECLAIM_PTR)\n\t\ttm = NULL;\n\tif (!tm && create)\n\t\ttm = tcpm_new(dst, &saddr, &daddr, hash);\n\telse\n\t\ttcpm_check_stamp(tm, dst);\n\n\treturn tm;\n}\n\n \nvoid tcp_update_metrics(struct sock *sk)\n{\n\tconst struct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct dst_entry *dst = __sk_dst_get(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tstruct tcp_metrics_block *tm;\n\tunsigned long rtt;\n\tu32 val;\n\tint m;\n\n\tsk_dst_confirm(sk);\n\tif (READ_ONCE(net->ipv4.sysctl_tcp_nometrics_save) || !dst)\n\t\treturn;\n\n\trcu_read_lock();\n\tif (icsk->icsk_backoff || !tp->srtt_us) {\n\t\t \n\t\ttm = tcp_get_metrics(sk, dst, false);\n\t\tif (tm && !tcp_metric_locked(tm, TCP_METRIC_RTT))\n\t\t\ttcp_metric_set(tm, TCP_METRIC_RTT, 0);\n\t\tgoto out_unlock;\n\t} else\n\t\ttm = tcp_get_metrics(sk, dst, true);\n\n\tif (!tm)\n\t\tgoto out_unlock;\n\n\trtt = tcp_metric_get(tm, TCP_METRIC_RTT);\n\tm = rtt - tp->srtt_us;\n\n\t \n\tif (!tcp_metric_locked(tm, TCP_METRIC_RTT)) {\n\t\tif (m <= 0)\n\t\t\trtt = tp->srtt_us;\n\t\telse\n\t\t\trtt -= (m >> 3);\n\t\ttcp_metric_set(tm, TCP_METRIC_RTT, rtt);\n\t}\n\n\tif (!tcp_metric_locked(tm, TCP_METRIC_RTTVAR)) {\n\t\tunsigned long var;\n\n\t\tif (m < 0)\n\t\t\tm = -m;\n\n\t\t \n\t\tm >>= 1;\n\t\tif (m < tp->mdev_us)\n\t\t\tm = tp->mdev_us;\n\n\t\tvar = tcp_metric_get(tm, TCP_METRIC_RTTVAR);\n\t\tif (m >= var)\n\t\t\tvar = m;\n\t\telse\n\t\t\tvar -= (var - m) >> 2;\n\n\t\ttcp_metric_set(tm, TCP_METRIC_RTTVAR, var);\n\t}\n\n\tif (tcp_in_initial_slowstart(tp)) {\n\t\t \n\t\tif (!READ_ONCE(net->ipv4.sysctl_tcp_no_ssthresh_metrics_save) &&\n\t\t    !tcp_metric_locked(tm, TCP_METRIC_SSTHRESH)) {\n\t\t\tval = tcp_metric_get(tm, TCP_METRIC_SSTHRESH);\n\t\t\tif (val && (tcp_snd_cwnd(tp) >> 1) > val)\n\t\t\t\ttcp_metric_set(tm, TCP_METRIC_SSTHRESH,\n\t\t\t\t\t       tcp_snd_cwnd(tp) >> 1);\n\t\t}\n\t\tif (!tcp_metric_locked(tm, TCP_METRIC_CWND)) {\n\t\t\tval = tcp_metric_get(tm, TCP_METRIC_CWND);\n\t\t\tif (tcp_snd_cwnd(tp) > val)\n\t\t\t\ttcp_metric_set(tm, TCP_METRIC_CWND,\n\t\t\t\t\t       tcp_snd_cwnd(tp));\n\t\t}\n\t} else if (!tcp_in_slow_start(tp) &&\n\t\t   icsk->icsk_ca_state == TCP_CA_Open) {\n\t\t \n\t\tif (!READ_ONCE(net->ipv4.sysctl_tcp_no_ssthresh_metrics_save) &&\n\t\t    !tcp_metric_locked(tm, TCP_METRIC_SSTHRESH))\n\t\t\ttcp_metric_set(tm, TCP_METRIC_SSTHRESH,\n\t\t\t\t       max(tcp_snd_cwnd(tp) >> 1, tp->snd_ssthresh));\n\t\tif (!tcp_metric_locked(tm, TCP_METRIC_CWND)) {\n\t\t\tval = tcp_metric_get(tm, TCP_METRIC_CWND);\n\t\t\ttcp_metric_set(tm, TCP_METRIC_CWND, (val + tcp_snd_cwnd(tp)) >> 1);\n\t\t}\n\t} else {\n\t\t \n\t\tif (!tcp_metric_locked(tm, TCP_METRIC_CWND)) {\n\t\t\tval = tcp_metric_get(tm, TCP_METRIC_CWND);\n\t\t\ttcp_metric_set(tm, TCP_METRIC_CWND,\n\t\t\t\t       (val + tp->snd_ssthresh) >> 1);\n\t\t}\n\t\tif (!READ_ONCE(net->ipv4.sysctl_tcp_no_ssthresh_metrics_save) &&\n\t\t    !tcp_metric_locked(tm, TCP_METRIC_SSTHRESH)) {\n\t\t\tval = tcp_metric_get(tm, TCP_METRIC_SSTHRESH);\n\t\t\tif (val && tp->snd_ssthresh > val)\n\t\t\t\ttcp_metric_set(tm, TCP_METRIC_SSTHRESH,\n\t\t\t\t\t       tp->snd_ssthresh);\n\t\t}\n\t\tif (!tcp_metric_locked(tm, TCP_METRIC_REORDERING)) {\n\t\t\tval = tcp_metric_get(tm, TCP_METRIC_REORDERING);\n\t\t\tif (val < tp->reordering &&\n\t\t\t    tp->reordering !=\n\t\t\t    READ_ONCE(net->ipv4.sysctl_tcp_reordering))\n\t\t\t\ttcp_metric_set(tm, TCP_METRIC_REORDERING,\n\t\t\t\t\t       tp->reordering);\n\t\t}\n\t}\n\tWRITE_ONCE(tm->tcpm_stamp, jiffies);\nout_unlock:\n\trcu_read_unlock();\n}\n\n \n\nvoid tcp_init_metrics(struct sock *sk)\n{\n\tstruct dst_entry *dst = __sk_dst_get(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tstruct tcp_metrics_block *tm;\n\tu32 val, crtt = 0;  \n\n\tsk_dst_confirm(sk);\n\t \n\ttp->snd_ssthresh = TCP_INFINITE_SSTHRESH;\n\tif (!dst)\n\t\tgoto reset;\n\n\trcu_read_lock();\n\ttm = tcp_get_metrics(sk, dst, false);\n\tif (!tm) {\n\t\trcu_read_unlock();\n\t\tgoto reset;\n\t}\n\n\tif (tcp_metric_locked(tm, TCP_METRIC_CWND))\n\t\ttp->snd_cwnd_clamp = tcp_metric_get(tm, TCP_METRIC_CWND);\n\n\tval = READ_ONCE(net->ipv4.sysctl_tcp_no_ssthresh_metrics_save) ?\n\t      0 : tcp_metric_get(tm, TCP_METRIC_SSTHRESH);\n\tif (val) {\n\t\ttp->snd_ssthresh = val;\n\t\tif (tp->snd_ssthresh > tp->snd_cwnd_clamp)\n\t\t\ttp->snd_ssthresh = tp->snd_cwnd_clamp;\n\t}\n\tval = tcp_metric_get(tm, TCP_METRIC_REORDERING);\n\tif (val && tp->reordering != val)\n\t\ttp->reordering = val;\n\n\tcrtt = tcp_metric_get(tm, TCP_METRIC_RTT);\n\trcu_read_unlock();\nreset:\n\t \n\tif (crtt > tp->srtt_us) {\n\t\t \n\t\tcrtt /= 8 * USEC_PER_SEC / HZ;\n\t\tinet_csk(sk)->icsk_rto = crtt + max(2 * crtt, tcp_rto_min(sk));\n\t} else if (tp->srtt_us == 0) {\n\t\t \n\t\ttp->rttvar_us = jiffies_to_usecs(TCP_TIMEOUT_FALLBACK);\n\t\ttp->mdev_us = tp->mdev_max_us = tp->rttvar_us;\n\n\t\tinet_csk(sk)->icsk_rto = TCP_TIMEOUT_FALLBACK;\n\t}\n}\n\nbool tcp_peer_is_proven(struct request_sock *req, struct dst_entry *dst)\n{\n\tstruct tcp_metrics_block *tm;\n\tbool ret;\n\n\tif (!dst)\n\t\treturn false;\n\n\trcu_read_lock();\n\ttm = __tcp_get_metrics_req(req, dst);\n\tif (tm && tcp_metric_get(tm, TCP_METRIC_RTT))\n\t\tret = true;\n\telse\n\t\tret = false;\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\nvoid tcp_fastopen_cache_get(struct sock *sk, u16 *mss,\n\t\t\t    struct tcp_fastopen_cookie *cookie)\n{\n\tstruct tcp_metrics_block *tm;\n\n\trcu_read_lock();\n\ttm = tcp_get_metrics(sk, __sk_dst_get(sk), false);\n\tif (tm) {\n\t\tstruct tcp_fastopen_metrics *tfom = &tm->tcpm_fastopen;\n\t\tunsigned int seq;\n\n\t\tdo {\n\t\t\tseq = read_seqbegin(&fastopen_seqlock);\n\t\t\tif (tfom->mss)\n\t\t\t\t*mss = tfom->mss;\n\t\t\t*cookie = tfom->cookie;\n\t\t\tif (cookie->len <= 0 && tfom->try_exp == 1)\n\t\t\t\tcookie->exp = true;\n\t\t} while (read_seqretry(&fastopen_seqlock, seq));\n\t}\n\trcu_read_unlock();\n}\n\nvoid tcp_fastopen_cache_set(struct sock *sk, u16 mss,\n\t\t\t    struct tcp_fastopen_cookie *cookie, bool syn_lost,\n\t\t\t    u16 try_exp)\n{\n\tstruct dst_entry *dst = __sk_dst_get(sk);\n\tstruct tcp_metrics_block *tm;\n\n\tif (!dst)\n\t\treturn;\n\trcu_read_lock();\n\ttm = tcp_get_metrics(sk, dst, true);\n\tif (tm) {\n\t\tstruct tcp_fastopen_metrics *tfom = &tm->tcpm_fastopen;\n\n\t\twrite_seqlock_bh(&fastopen_seqlock);\n\t\tif (mss)\n\t\t\ttfom->mss = mss;\n\t\tif (cookie && cookie->len > 0)\n\t\t\ttfom->cookie = *cookie;\n\t\telse if (try_exp > tfom->try_exp &&\n\t\t\t tfom->cookie.len <= 0 && !tfom->cookie.exp)\n\t\t\ttfom->try_exp = try_exp;\n\t\tif (syn_lost) {\n\t\t\t++tfom->syn_loss;\n\t\t\ttfom->last_syn_loss = jiffies;\n\t\t} else\n\t\t\ttfom->syn_loss = 0;\n\t\twrite_sequnlock_bh(&fastopen_seqlock);\n\t}\n\trcu_read_unlock();\n}\n\nstatic struct genl_family tcp_metrics_nl_family;\n\nstatic const struct nla_policy tcp_metrics_nl_policy[TCP_METRICS_ATTR_MAX + 1] = {\n\t[TCP_METRICS_ATTR_ADDR_IPV4]\t= { .type = NLA_U32, },\n\t[TCP_METRICS_ATTR_ADDR_IPV6]\t= { .type = NLA_BINARY,\n\t\t\t\t\t    .len = sizeof(struct in6_addr), },\n\t \n#if 0\n\t[TCP_METRICS_ATTR_AGE]\t\t= { .type = NLA_MSECS, },\n\t[TCP_METRICS_ATTR_TW_TSVAL]\t= { .type = NLA_U32, },\n\t[TCP_METRICS_ATTR_TW_TS_STAMP]\t= { .type = NLA_S32, },\n\t[TCP_METRICS_ATTR_VALS]\t\t= { .type = NLA_NESTED, },\n\t[TCP_METRICS_ATTR_FOPEN_MSS]\t= { .type = NLA_U16, },\n\t[TCP_METRICS_ATTR_FOPEN_SYN_DROPS]\t= { .type = NLA_U16, },\n\t[TCP_METRICS_ATTR_FOPEN_SYN_DROP_TS]\t= { .type = NLA_MSECS, },\n\t[TCP_METRICS_ATTR_FOPEN_COOKIE]\t= { .type = NLA_BINARY,\n\t\t\t\t\t    .len = TCP_FASTOPEN_COOKIE_MAX, },\n#endif\n};\n\n \nstatic int tcp_metrics_fill_info(struct sk_buff *msg,\n\t\t\t\t struct tcp_metrics_block *tm)\n{\n\tstruct nlattr *nest;\n\tint i;\n\n\tswitch (tm->tcpm_daddr.family) {\n\tcase AF_INET:\n\t\tif (nla_put_in_addr(msg, TCP_METRICS_ATTR_ADDR_IPV4,\n\t\t\t\t    inetpeer_get_addr_v4(&tm->tcpm_daddr)) < 0)\n\t\t\tgoto nla_put_failure;\n\t\tif (nla_put_in_addr(msg, TCP_METRICS_ATTR_SADDR_IPV4,\n\t\t\t\t    inetpeer_get_addr_v4(&tm->tcpm_saddr)) < 0)\n\t\t\tgoto nla_put_failure;\n\t\tbreak;\n\tcase AF_INET6:\n\t\tif (nla_put_in6_addr(msg, TCP_METRICS_ATTR_ADDR_IPV6,\n\t\t\t\t     inetpeer_get_addr_v6(&tm->tcpm_daddr)) < 0)\n\t\t\tgoto nla_put_failure;\n\t\tif (nla_put_in6_addr(msg, TCP_METRICS_ATTR_SADDR_IPV6,\n\t\t\t\t     inetpeer_get_addr_v6(&tm->tcpm_saddr)) < 0)\n\t\t\tgoto nla_put_failure;\n\t\tbreak;\n\tdefault:\n\t\treturn -EAFNOSUPPORT;\n\t}\n\n\tif (nla_put_msecs(msg, TCP_METRICS_ATTR_AGE,\n\t\t\t  jiffies - READ_ONCE(tm->tcpm_stamp),\n\t\t\t  TCP_METRICS_ATTR_PAD) < 0)\n\t\tgoto nla_put_failure;\n\n\t{\n\t\tint n = 0;\n\n\t\tnest = nla_nest_start_noflag(msg, TCP_METRICS_ATTR_VALS);\n\t\tif (!nest)\n\t\t\tgoto nla_put_failure;\n\t\tfor (i = 0; i < TCP_METRIC_MAX_KERNEL + 1; i++) {\n\t\t\tu32 val = tcp_metric_get(tm, i);\n\n\t\t\tif (!val)\n\t\t\t\tcontinue;\n\t\t\tif (i == TCP_METRIC_RTT) {\n\t\t\t\tif (nla_put_u32(msg, TCP_METRIC_RTT_US + 1,\n\t\t\t\t\t\tval) < 0)\n\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\tn++;\n\t\t\t\tval = max(val / 1000, 1U);\n\t\t\t}\n\t\t\tif (i == TCP_METRIC_RTTVAR) {\n\t\t\t\tif (nla_put_u32(msg, TCP_METRIC_RTTVAR_US + 1,\n\t\t\t\t\t\tval) < 0)\n\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\tn++;\n\t\t\t\tval = max(val / 1000, 1U);\n\t\t\t}\n\t\t\tif (nla_put_u32(msg, i + 1, val) < 0)\n\t\t\t\tgoto nla_put_failure;\n\t\t\tn++;\n\t\t}\n\t\tif (n)\n\t\t\tnla_nest_end(msg, nest);\n\t\telse\n\t\t\tnla_nest_cancel(msg, nest);\n\t}\n\n\t{\n\t\tstruct tcp_fastopen_metrics tfom_copy[1], *tfom;\n\t\tunsigned int seq;\n\n\t\tdo {\n\t\t\tseq = read_seqbegin(&fastopen_seqlock);\n\t\t\ttfom_copy[0] = tm->tcpm_fastopen;\n\t\t} while (read_seqretry(&fastopen_seqlock, seq));\n\n\t\ttfom = tfom_copy;\n\t\tif (tfom->mss &&\n\t\t    nla_put_u16(msg, TCP_METRICS_ATTR_FOPEN_MSS,\n\t\t\t\ttfom->mss) < 0)\n\t\t\tgoto nla_put_failure;\n\t\tif (tfom->syn_loss &&\n\t\t    (nla_put_u16(msg, TCP_METRICS_ATTR_FOPEN_SYN_DROPS,\n\t\t\t\ttfom->syn_loss) < 0 ||\n\t\t     nla_put_msecs(msg, TCP_METRICS_ATTR_FOPEN_SYN_DROP_TS,\n\t\t\t\tjiffies - tfom->last_syn_loss,\n\t\t\t\tTCP_METRICS_ATTR_PAD) < 0))\n\t\t\tgoto nla_put_failure;\n\t\tif (tfom->cookie.len > 0 &&\n\t\t    nla_put(msg, TCP_METRICS_ATTR_FOPEN_COOKIE,\n\t\t\t    tfom->cookie.len, tfom->cookie.val) < 0)\n\t\t\tgoto nla_put_failure;\n\t}\n\n\treturn 0;\n\nnla_put_failure:\n\treturn -EMSGSIZE;\n}\n\nstatic int tcp_metrics_dump_info(struct sk_buff *skb,\n\t\t\t\t struct netlink_callback *cb,\n\t\t\t\t struct tcp_metrics_block *tm)\n{\n\tvoid *hdr;\n\n\thdr = genlmsg_put(skb, NETLINK_CB(cb->skb).portid, cb->nlh->nlmsg_seq,\n\t\t\t  &tcp_metrics_nl_family, NLM_F_MULTI,\n\t\t\t  TCP_METRICS_CMD_GET);\n\tif (!hdr)\n\t\treturn -EMSGSIZE;\n\n\tif (tcp_metrics_fill_info(skb, tm) < 0)\n\t\tgoto nla_put_failure;\n\n\tgenlmsg_end(skb, hdr);\n\treturn 0;\n\nnla_put_failure:\n\tgenlmsg_cancel(skb, hdr);\n\treturn -EMSGSIZE;\n}\n\nstatic int tcp_metrics_nl_dump(struct sk_buff *skb,\n\t\t\t       struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tunsigned int max_rows = 1U << tcp_metrics_hash_log;\n\tunsigned int row, s_row = cb->args[0];\n\tint s_col = cb->args[1], col = s_col;\n\n\tfor (row = s_row; row < max_rows; row++, s_col = 0) {\n\t\tstruct tcp_metrics_block *tm;\n\t\tstruct tcpm_hash_bucket *hb = tcp_metrics_hash + row;\n\n\t\trcu_read_lock();\n\t\tfor (col = 0, tm = rcu_dereference(hb->chain); tm;\n\t\t     tm = rcu_dereference(tm->tcpm_next), col++) {\n\t\t\tif (!net_eq(tm_net(tm), net))\n\t\t\t\tcontinue;\n\t\t\tif (col < s_col)\n\t\t\t\tcontinue;\n\t\t\tif (tcp_metrics_dump_info(skb, cb, tm) < 0) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\ndone:\n\tcb->args[0] = row;\n\tcb->args[1] = col;\n\treturn skb->len;\n}\n\nstatic int __parse_nl_addr(struct genl_info *info, struct inetpeer_addr *addr,\n\t\t\t   unsigned int *hash, int optional, int v4, int v6)\n{\n\tstruct nlattr *a;\n\n\ta = info->attrs[v4];\n\tif (a) {\n\t\tinetpeer_set_addr_v4(addr, nla_get_in_addr(a));\n\t\tif (hash)\n\t\t\t*hash = ipv4_addr_hash(inetpeer_get_addr_v4(addr));\n\t\treturn 0;\n\t}\n\ta = info->attrs[v6];\n\tif (a) {\n\t\tstruct in6_addr in6;\n\n\t\tif (nla_len(a) != sizeof(struct in6_addr))\n\t\t\treturn -EINVAL;\n\t\tin6 = nla_get_in6_addr(a);\n\t\tinetpeer_set_addr_v6(addr, &in6);\n\t\tif (hash)\n\t\t\t*hash = ipv6_addr_hash(inetpeer_get_addr_v6(addr));\n\t\treturn 0;\n\t}\n\treturn optional ? 1 : -EAFNOSUPPORT;\n}\n\nstatic int parse_nl_addr(struct genl_info *info, struct inetpeer_addr *addr,\n\t\t\t unsigned int *hash, int optional)\n{\n\treturn __parse_nl_addr(info, addr, hash, optional,\n\t\t\t       TCP_METRICS_ATTR_ADDR_IPV4,\n\t\t\t       TCP_METRICS_ATTR_ADDR_IPV6);\n}\n\nstatic int parse_nl_saddr(struct genl_info *info, struct inetpeer_addr *addr)\n{\n\treturn __parse_nl_addr(info, addr, NULL, 0,\n\t\t\t       TCP_METRICS_ATTR_SADDR_IPV4,\n\t\t\t       TCP_METRICS_ATTR_SADDR_IPV6);\n}\n\nstatic int tcp_metrics_nl_cmd_get(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct tcp_metrics_block *tm;\n\tstruct inetpeer_addr saddr, daddr;\n\tunsigned int hash;\n\tstruct sk_buff *msg;\n\tstruct net *net = genl_info_net(info);\n\tvoid *reply;\n\tint ret;\n\tbool src = true;\n\n\tret = parse_nl_addr(info, &daddr, &hash, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = parse_nl_saddr(info, &saddr);\n\tif (ret < 0)\n\t\tsrc = false;\n\n\tmsg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\n\tif (!msg)\n\t\treturn -ENOMEM;\n\n\treply = genlmsg_put_reply(msg, info, &tcp_metrics_nl_family, 0,\n\t\t\t\t  info->genlhdr->cmd);\n\tif (!reply)\n\t\tgoto nla_put_failure;\n\n\thash ^= net_hash_mix(net);\n\thash = hash_32(hash, tcp_metrics_hash_log);\n\tret = -ESRCH;\n\trcu_read_lock();\n\tfor (tm = rcu_dereference(tcp_metrics_hash[hash].chain); tm;\n\t     tm = rcu_dereference(tm->tcpm_next)) {\n\t\tif (addr_same(&tm->tcpm_daddr, &daddr) &&\n\t\t    (!src || addr_same(&tm->tcpm_saddr, &saddr)) &&\n\t\t    net_eq(tm_net(tm), net)) {\n\t\t\tret = tcp_metrics_fill_info(msg, tm);\n\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\tif (ret < 0)\n\t\tgoto out_free;\n\n\tgenlmsg_end(msg, reply);\n\treturn genlmsg_reply(msg, info);\n\nnla_put_failure:\n\tret = -EMSGSIZE;\n\nout_free:\n\tnlmsg_free(msg);\n\treturn ret;\n}\n\nstatic void tcp_metrics_flush_all(struct net *net)\n{\n\tunsigned int max_rows = 1U << tcp_metrics_hash_log;\n\tstruct tcpm_hash_bucket *hb = tcp_metrics_hash;\n\tstruct tcp_metrics_block *tm;\n\tunsigned int row;\n\n\tfor (row = 0; row < max_rows; row++, hb++) {\n\t\tstruct tcp_metrics_block __rcu **pp;\n\t\tbool match;\n\n\t\tspin_lock_bh(&tcp_metrics_lock);\n\t\tpp = &hb->chain;\n\t\tfor (tm = deref_locked(*pp); tm; tm = deref_locked(*pp)) {\n\t\t\tmatch = net ? net_eq(tm_net(tm), net) :\n\t\t\t\t!refcount_read(&tm_net(tm)->ns.count);\n\t\t\tif (match) {\n\t\t\t\trcu_assign_pointer(*pp, tm->tcpm_next);\n\t\t\t\tkfree_rcu(tm, rcu_head);\n\t\t\t} else {\n\t\t\t\tpp = &tm->tcpm_next;\n\t\t\t}\n\t\t}\n\t\tspin_unlock_bh(&tcp_metrics_lock);\n\t}\n}\n\nstatic int tcp_metrics_nl_cmd_del(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct tcpm_hash_bucket *hb;\n\tstruct tcp_metrics_block *tm;\n\tstruct tcp_metrics_block __rcu **pp;\n\tstruct inetpeer_addr saddr, daddr;\n\tunsigned int hash;\n\tstruct net *net = genl_info_net(info);\n\tint ret;\n\tbool src = true, found = false;\n\n\tret = parse_nl_addr(info, &daddr, &hash, 1);\n\tif (ret < 0)\n\t\treturn ret;\n\tif (ret > 0) {\n\t\ttcp_metrics_flush_all(net);\n\t\treturn 0;\n\t}\n\tret = parse_nl_saddr(info, &saddr);\n\tif (ret < 0)\n\t\tsrc = false;\n\n\thash ^= net_hash_mix(net);\n\thash = hash_32(hash, tcp_metrics_hash_log);\n\thb = tcp_metrics_hash + hash;\n\tpp = &hb->chain;\n\tspin_lock_bh(&tcp_metrics_lock);\n\tfor (tm = deref_locked(*pp); tm; tm = deref_locked(*pp)) {\n\t\tif (addr_same(&tm->tcpm_daddr, &daddr) &&\n\t\t    (!src || addr_same(&tm->tcpm_saddr, &saddr)) &&\n\t\t    net_eq(tm_net(tm), net)) {\n\t\t\trcu_assign_pointer(*pp, tm->tcpm_next);\n\t\t\tkfree_rcu(tm, rcu_head);\n\t\t\tfound = true;\n\t\t} else {\n\t\t\tpp = &tm->tcpm_next;\n\t\t}\n\t}\n\tspin_unlock_bh(&tcp_metrics_lock);\n\tif (!found)\n\t\treturn -ESRCH;\n\treturn 0;\n}\n\nstatic const struct genl_small_ops tcp_metrics_nl_ops[] = {\n\t{\n\t\t.cmd = TCP_METRICS_CMD_GET,\n\t\t.validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t\t.doit = tcp_metrics_nl_cmd_get,\n\t\t.dumpit = tcp_metrics_nl_dump,\n\t},\n\t{\n\t\t.cmd = TCP_METRICS_CMD_DEL,\n\t\t.validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t\t.doit = tcp_metrics_nl_cmd_del,\n\t\t.flags = GENL_ADMIN_PERM,\n\t},\n};\n\nstatic struct genl_family tcp_metrics_nl_family __ro_after_init = {\n\t.hdrsize\t= 0,\n\t.name\t\t= TCP_METRICS_GENL_NAME,\n\t.version\t= TCP_METRICS_GENL_VERSION,\n\t.maxattr\t= TCP_METRICS_ATTR_MAX,\n\t.policy = tcp_metrics_nl_policy,\n\t.netnsok\t= true,\n\t.module\t\t= THIS_MODULE,\n\t.small_ops\t= tcp_metrics_nl_ops,\n\t.n_small_ops\t= ARRAY_SIZE(tcp_metrics_nl_ops),\n\t.resv_start_op\t= TCP_METRICS_CMD_DEL + 1,\n};\n\nstatic unsigned int tcpmhash_entries __initdata;\nstatic int __init set_tcpmhash_entries(char *str)\n{\n\tssize_t ret;\n\n\tif (!str)\n\t\treturn 0;\n\n\tret = kstrtouint(str, 0, &tcpmhash_entries);\n\tif (ret)\n\t\treturn 0;\n\n\treturn 1;\n}\n__setup(\"tcpmhash_entries=\", set_tcpmhash_entries);\n\nstatic void __init tcp_metrics_hash_alloc(void)\n{\n\tunsigned int slots = tcpmhash_entries;\n\tsize_t size;\n\n\tif (!slots) {\n\t\tif (totalram_pages() >= 128 * 1024)\n\t\t\tslots = 16 * 1024;\n\t\telse\n\t\t\tslots = 8 * 1024;\n\t}\n\n\ttcp_metrics_hash_log = order_base_2(slots);\n\tsize = sizeof(struct tcpm_hash_bucket) << tcp_metrics_hash_log;\n\n\ttcp_metrics_hash = kvzalloc(size, GFP_KERNEL);\n\tif (!tcp_metrics_hash)\n\t\tpanic(\"Could not allocate the tcp_metrics hash table\\n\");\n}\n\nstatic void __net_exit tcp_net_metrics_exit_batch(struct list_head *net_exit_list)\n{\n\ttcp_metrics_flush_all(NULL);\n}\n\nstatic __net_initdata struct pernet_operations tcp_net_metrics_ops = {\n\t.exit_batch\t=\ttcp_net_metrics_exit_batch,\n};\n\nvoid __init tcp_metrics_init(void)\n{\n\tint ret;\n\n\ttcp_metrics_hash_alloc();\n\n\tret = register_pernet_subsys(&tcp_net_metrics_ops);\n\tif (ret < 0)\n\t\tpanic(\"Could not register tcp_net_metrics_ops\\n\");\n\n\tret = genl_register_family(&tcp_metrics_nl_family);\n\tif (ret < 0)\n\t\tpanic(\"Could not register tcp_metrics generic netlink\\n\");\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}