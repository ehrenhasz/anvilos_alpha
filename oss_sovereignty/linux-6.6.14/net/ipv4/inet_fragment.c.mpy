{
  "module_name": "inet_fragment.c",
  "hash_id": "a03c096afd4b267d879c560d5fb9a5ccc2b04761addeeba5fa85d310cfc76c78",
  "original_prompt": "Ingested from linux-6.6.14/net/ipv4/inet_fragment.c",
  "human_readable_source": "\n \n\n#include <linux/list.h>\n#include <linux/spinlock.h>\n#include <linux/module.h>\n#include <linux/timer.h>\n#include <linux/mm.h>\n#include <linux/random.h>\n#include <linux/skbuff.h>\n#include <linux/rtnetlink.h>\n#include <linux/slab.h>\n#include <linux/rhashtable.h>\n\n#include <net/sock.h>\n#include <net/inet_frag.h>\n#include <net/inet_ecn.h>\n#include <net/ip.h>\n#include <net/ipv6.h>\n\n \nstruct ipfrag_skb_cb {\n\tunion {\n\t\tstruct inet_skb_parm\th4;\n\t\tstruct inet6_skb_parm\th6;\n\t};\n\tstruct sk_buff\t\t*next_frag;\n\tint\t\t\tfrag_run_len;\n};\n\n#define FRAG_CB(skb)\t\t((struct ipfrag_skb_cb *)((skb)->cb))\n\nstatic void fragcb_clear(struct sk_buff *skb)\n{\n\tRB_CLEAR_NODE(&skb->rbnode);\n\tFRAG_CB(skb)->next_frag = NULL;\n\tFRAG_CB(skb)->frag_run_len = skb->len;\n}\n\n \nstatic void fragrun_append_to_last(struct inet_frag_queue *q,\n\t\t\t\t   struct sk_buff *skb)\n{\n\tfragcb_clear(skb);\n\n\tFRAG_CB(q->last_run_head)->frag_run_len += skb->len;\n\tFRAG_CB(q->fragments_tail)->next_frag = skb;\n\tq->fragments_tail = skb;\n}\n\n \nstatic void fragrun_create(struct inet_frag_queue *q, struct sk_buff *skb)\n{\n\tBUILD_BUG_ON(sizeof(struct ipfrag_skb_cb) > sizeof(skb->cb));\n\tfragcb_clear(skb);\n\n\tif (q->last_run_head)\n\t\trb_link_node(&skb->rbnode, &q->last_run_head->rbnode,\n\t\t\t     &q->last_run_head->rbnode.rb_right);\n\telse\n\t\trb_link_node(&skb->rbnode, NULL, &q->rb_fragments.rb_node);\n\trb_insert_color(&skb->rbnode, &q->rb_fragments);\n\n\tq->fragments_tail = skb;\n\tq->last_run_head = skb;\n}\n\n \nconst u8 ip_frag_ecn_table[16] = {\n\t \n\t[IPFRAG_ECN_CE | IPFRAG_ECN_ECT_0]\t\t\t= INET_ECN_CE,\n\t[IPFRAG_ECN_CE | IPFRAG_ECN_ECT_1]\t\t\t= INET_ECN_CE,\n\t[IPFRAG_ECN_CE | IPFRAG_ECN_ECT_0 | IPFRAG_ECN_ECT_1]\t= INET_ECN_CE,\n\n\t \n\t[IPFRAG_ECN_NOT_ECT | IPFRAG_ECN_CE] = 0xff,\n\t[IPFRAG_ECN_NOT_ECT | IPFRAG_ECN_ECT_0] = 0xff,\n\t[IPFRAG_ECN_NOT_ECT | IPFRAG_ECN_ECT_1] = 0xff,\n\t[IPFRAG_ECN_NOT_ECT | IPFRAG_ECN_ECT_0 | IPFRAG_ECN_ECT_1] = 0xff,\n\t[IPFRAG_ECN_NOT_ECT | IPFRAG_ECN_CE | IPFRAG_ECN_ECT_0] = 0xff,\n\t[IPFRAG_ECN_NOT_ECT | IPFRAG_ECN_CE | IPFRAG_ECN_ECT_1] = 0xff,\n\t[IPFRAG_ECN_NOT_ECT | IPFRAG_ECN_CE | IPFRAG_ECN_ECT_0 | IPFRAG_ECN_ECT_1] = 0xff,\n};\nEXPORT_SYMBOL(ip_frag_ecn_table);\n\nint inet_frags_init(struct inet_frags *f)\n{\n\tf->frags_cachep = kmem_cache_create(f->frags_cache_name, f->qsize, 0, 0,\n\t\t\t\t\t    NULL);\n\tif (!f->frags_cachep)\n\t\treturn -ENOMEM;\n\n\trefcount_set(&f->refcnt, 1);\n\tinit_completion(&f->completion);\n\treturn 0;\n}\nEXPORT_SYMBOL(inet_frags_init);\n\nvoid inet_frags_fini(struct inet_frags *f)\n{\n\tif (refcount_dec_and_test(&f->refcnt))\n\t\tcomplete(&f->completion);\n\n\twait_for_completion(&f->completion);\n\n\tkmem_cache_destroy(f->frags_cachep);\n\tf->frags_cachep = NULL;\n}\nEXPORT_SYMBOL(inet_frags_fini);\n\n \nstatic void inet_frags_free_cb(void *ptr, void *arg)\n{\n\tstruct inet_frag_queue *fq = ptr;\n\tint count;\n\n\tcount = del_timer_sync(&fq->timer) ? 1 : 0;\n\n\tspin_lock_bh(&fq->lock);\n\tfq->flags |= INET_FRAG_DROP;\n\tif (!(fq->flags & INET_FRAG_COMPLETE)) {\n\t\tfq->flags |= INET_FRAG_COMPLETE;\n\t\tcount++;\n\t} else if (fq->flags & INET_FRAG_HASH_DEAD) {\n\t\tcount++;\n\t}\n\tspin_unlock_bh(&fq->lock);\n\n\tif (refcount_sub_and_test(count, &fq->refcnt))\n\t\tinet_frag_destroy(fq);\n}\n\nstatic LLIST_HEAD(fqdir_free_list);\n\nstatic void fqdir_free_fn(struct work_struct *work)\n{\n\tstruct llist_node *kill_list;\n\tstruct fqdir *fqdir, *tmp;\n\tstruct inet_frags *f;\n\n\t \n\tkill_list = llist_del_all(&fqdir_free_list);\n\n\t \n\trcu_barrier();\n\n\tllist_for_each_entry_safe(fqdir, tmp, kill_list, free_list) {\n\t\tf = fqdir->f;\n\t\tif (refcount_dec_and_test(&f->refcnt))\n\t\t\tcomplete(&f->completion);\n\n\t\tkfree(fqdir);\n\t}\n}\n\nstatic DECLARE_WORK(fqdir_free_work, fqdir_free_fn);\n\nstatic void fqdir_work_fn(struct work_struct *work)\n{\n\tstruct fqdir *fqdir = container_of(work, struct fqdir, destroy_work);\n\n\trhashtable_free_and_destroy(&fqdir->rhashtable, inet_frags_free_cb, NULL);\n\n\tif (llist_add(&fqdir->free_list, &fqdir_free_list))\n\t\tqueue_work(system_wq, &fqdir_free_work);\n}\n\nint fqdir_init(struct fqdir **fqdirp, struct inet_frags *f, struct net *net)\n{\n\tstruct fqdir *fqdir = kzalloc(sizeof(*fqdir), GFP_KERNEL);\n\tint res;\n\n\tif (!fqdir)\n\t\treturn -ENOMEM;\n\tfqdir->f = f;\n\tfqdir->net = net;\n\tres = rhashtable_init(&fqdir->rhashtable, &fqdir->f->rhash_params);\n\tif (res < 0) {\n\t\tkfree(fqdir);\n\t\treturn res;\n\t}\n\trefcount_inc(&f->refcnt);\n\t*fqdirp = fqdir;\n\treturn 0;\n}\nEXPORT_SYMBOL(fqdir_init);\n\nstatic struct workqueue_struct *inet_frag_wq;\n\nstatic int __init inet_frag_wq_init(void)\n{\n\tinet_frag_wq = create_workqueue(\"inet_frag_wq\");\n\tif (!inet_frag_wq)\n\t\tpanic(\"Could not create inet frag workq\");\n\treturn 0;\n}\n\npure_initcall(inet_frag_wq_init);\n\nvoid fqdir_exit(struct fqdir *fqdir)\n{\n\tINIT_WORK(&fqdir->destroy_work, fqdir_work_fn);\n\tqueue_work(inet_frag_wq, &fqdir->destroy_work);\n}\nEXPORT_SYMBOL(fqdir_exit);\n\nvoid inet_frag_kill(struct inet_frag_queue *fq)\n{\n\tif (del_timer(&fq->timer))\n\t\trefcount_dec(&fq->refcnt);\n\n\tif (!(fq->flags & INET_FRAG_COMPLETE)) {\n\t\tstruct fqdir *fqdir = fq->fqdir;\n\n\t\tfq->flags |= INET_FRAG_COMPLETE;\n\t\trcu_read_lock();\n\t\t \n\t\tif (!READ_ONCE(fqdir->dead)) {\n\t\t\trhashtable_remove_fast(&fqdir->rhashtable, &fq->node,\n\t\t\t\t\t       fqdir->f->rhash_params);\n\t\t\trefcount_dec(&fq->refcnt);\n\t\t} else {\n\t\t\tfq->flags |= INET_FRAG_HASH_DEAD;\n\t\t}\n\t\trcu_read_unlock();\n\t}\n}\nEXPORT_SYMBOL(inet_frag_kill);\n\nstatic void inet_frag_destroy_rcu(struct rcu_head *head)\n{\n\tstruct inet_frag_queue *q = container_of(head, struct inet_frag_queue,\n\t\t\t\t\t\t rcu);\n\tstruct inet_frags *f = q->fqdir->f;\n\n\tif (f->destructor)\n\t\tf->destructor(q);\n\tkmem_cache_free(f->frags_cachep, q);\n}\n\nunsigned int inet_frag_rbtree_purge(struct rb_root *root,\n\t\t\t\t    enum skb_drop_reason reason)\n{\n\tstruct rb_node *p = rb_first(root);\n\tunsigned int sum = 0;\n\n\twhile (p) {\n\t\tstruct sk_buff *skb = rb_entry(p, struct sk_buff, rbnode);\n\n\t\tp = rb_next(p);\n\t\trb_erase(&skb->rbnode, root);\n\t\twhile (skb) {\n\t\t\tstruct sk_buff *next = FRAG_CB(skb)->next_frag;\n\n\t\t\tsum += skb->truesize;\n\t\t\tkfree_skb_reason(skb, reason);\n\t\t\tskb = next;\n\t\t}\n\t}\n\treturn sum;\n}\nEXPORT_SYMBOL(inet_frag_rbtree_purge);\n\nvoid inet_frag_destroy(struct inet_frag_queue *q)\n{\n\tunsigned int sum, sum_truesize = 0;\n\tenum skb_drop_reason reason;\n\tstruct inet_frags *f;\n\tstruct fqdir *fqdir;\n\n\tWARN_ON(!(q->flags & INET_FRAG_COMPLETE));\n\treason = (q->flags & INET_FRAG_DROP) ?\n\t\t\tSKB_DROP_REASON_FRAG_REASM_TIMEOUT :\n\t\t\tSKB_CONSUMED;\n\tWARN_ON(del_timer(&q->timer) != 0);\n\n\t \n\tfqdir = q->fqdir;\n\tf = fqdir->f;\n\tsum_truesize = inet_frag_rbtree_purge(&q->rb_fragments, reason);\n\tsum = sum_truesize + f->qsize;\n\n\tcall_rcu(&q->rcu, inet_frag_destroy_rcu);\n\n\tsub_frag_mem_limit(fqdir, sum);\n}\nEXPORT_SYMBOL(inet_frag_destroy);\n\nstatic struct inet_frag_queue *inet_frag_alloc(struct fqdir *fqdir,\n\t\t\t\t\t       struct inet_frags *f,\n\t\t\t\t\t       void *arg)\n{\n\tstruct inet_frag_queue *q;\n\n\tq = kmem_cache_zalloc(f->frags_cachep, GFP_ATOMIC);\n\tif (!q)\n\t\treturn NULL;\n\n\tq->fqdir = fqdir;\n\tf->constructor(q, arg);\n\tadd_frag_mem_limit(fqdir, f->qsize);\n\n\ttimer_setup(&q->timer, f->frag_expire, 0);\n\tspin_lock_init(&q->lock);\n\trefcount_set(&q->refcnt, 3);\n\n\treturn q;\n}\n\nstatic struct inet_frag_queue *inet_frag_create(struct fqdir *fqdir,\n\t\t\t\t\t\tvoid *arg,\n\t\t\t\t\t\tstruct inet_frag_queue **prev)\n{\n\tstruct inet_frags *f = fqdir->f;\n\tstruct inet_frag_queue *q;\n\n\tq = inet_frag_alloc(fqdir, f, arg);\n\tif (!q) {\n\t\t*prev = ERR_PTR(-ENOMEM);\n\t\treturn NULL;\n\t}\n\tmod_timer(&q->timer, jiffies + fqdir->timeout);\n\n\t*prev = rhashtable_lookup_get_insert_key(&fqdir->rhashtable, &q->key,\n\t\t\t\t\t\t &q->node, f->rhash_params);\n\tif (*prev) {\n\t\tq->flags |= INET_FRAG_COMPLETE;\n\t\tinet_frag_kill(q);\n\t\tinet_frag_destroy(q);\n\t\treturn NULL;\n\t}\n\treturn q;\n}\n\n \nstruct inet_frag_queue *inet_frag_find(struct fqdir *fqdir, void *key)\n{\n\t \n\tlong high_thresh = READ_ONCE(fqdir->high_thresh);\n\tstruct inet_frag_queue *fq = NULL, *prev;\n\n\tif (!high_thresh || frag_mem_limit(fqdir) > high_thresh)\n\t\treturn NULL;\n\n\trcu_read_lock();\n\n\tprev = rhashtable_lookup(&fqdir->rhashtable, key, fqdir->f->rhash_params);\n\tif (!prev)\n\t\tfq = inet_frag_create(fqdir, key, &prev);\n\tif (!IS_ERR_OR_NULL(prev)) {\n\t\tfq = prev;\n\t\tif (!refcount_inc_not_zero(&fq->refcnt))\n\t\t\tfq = NULL;\n\t}\n\trcu_read_unlock();\n\treturn fq;\n}\nEXPORT_SYMBOL(inet_frag_find);\n\nint inet_frag_queue_insert(struct inet_frag_queue *q, struct sk_buff *skb,\n\t\t\t   int offset, int end)\n{\n\tstruct sk_buff *last = q->fragments_tail;\n\n\t \n\tif (!last)\n\t\tfragrun_create(q, skb);   \n\telse if (last->ip_defrag_offset + last->len < end) {\n\t\t \n\t\t \n\t\tif (offset < last->ip_defrag_offset + last->len)\n\t\t\treturn IPFRAG_OVERLAP;\n\t\tif (offset == last->ip_defrag_offset + last->len)\n\t\t\tfragrun_append_to_last(q, skb);\n\t\telse\n\t\t\tfragrun_create(q, skb);\n\t} else {\n\t\t \n\t\tstruct rb_node **rbn, *parent;\n\n\t\trbn = &q->rb_fragments.rb_node;\n\t\tdo {\n\t\t\tstruct sk_buff *curr;\n\t\t\tint curr_run_end;\n\n\t\t\tparent = *rbn;\n\t\t\tcurr = rb_to_skb(parent);\n\t\t\tcurr_run_end = curr->ip_defrag_offset +\n\t\t\t\t\tFRAG_CB(curr)->frag_run_len;\n\t\t\tif (end <= curr->ip_defrag_offset)\n\t\t\t\trbn = &parent->rb_left;\n\t\t\telse if (offset >= curr_run_end)\n\t\t\t\trbn = &parent->rb_right;\n\t\t\telse if (offset >= curr->ip_defrag_offset &&\n\t\t\t\t end <= curr_run_end)\n\t\t\t\treturn IPFRAG_DUP;\n\t\t\telse\n\t\t\t\treturn IPFRAG_OVERLAP;\n\t\t} while (*rbn);\n\t\t \n\t\tfragcb_clear(skb);\n\t\trb_link_node(&skb->rbnode, parent, rbn);\n\t\trb_insert_color(&skb->rbnode, &q->rb_fragments);\n\t}\n\n\tskb->ip_defrag_offset = offset;\n\n\treturn IPFRAG_OK;\n}\nEXPORT_SYMBOL(inet_frag_queue_insert);\n\nvoid *inet_frag_reasm_prepare(struct inet_frag_queue *q, struct sk_buff *skb,\n\t\t\t      struct sk_buff *parent)\n{\n\tstruct sk_buff *fp, *head = skb_rb_first(&q->rb_fragments);\n\tstruct sk_buff **nextp;\n\tint delta;\n\n\tif (head != skb) {\n\t\tfp = skb_clone(skb, GFP_ATOMIC);\n\t\tif (!fp)\n\t\t\treturn NULL;\n\t\tFRAG_CB(fp)->next_frag = FRAG_CB(skb)->next_frag;\n\t\tif (RB_EMPTY_NODE(&skb->rbnode))\n\t\t\tFRAG_CB(parent)->next_frag = fp;\n\t\telse\n\t\t\trb_replace_node(&skb->rbnode, &fp->rbnode,\n\t\t\t\t\t&q->rb_fragments);\n\t\tif (q->fragments_tail == skb)\n\t\t\tq->fragments_tail = fp;\n\t\tskb_morph(skb, head);\n\t\tFRAG_CB(skb)->next_frag = FRAG_CB(head)->next_frag;\n\t\trb_replace_node(&head->rbnode, &skb->rbnode,\n\t\t\t\t&q->rb_fragments);\n\t\tconsume_skb(head);\n\t\thead = skb;\n\t}\n\tWARN_ON(head->ip_defrag_offset != 0);\n\n\tdelta = -head->truesize;\n\n\t \n\tif (skb_unclone(head, GFP_ATOMIC))\n\t\treturn NULL;\n\n\tdelta += head->truesize;\n\tif (delta)\n\t\tadd_frag_mem_limit(q->fqdir, delta);\n\n\t \n\tif (skb_has_frag_list(head)) {\n\t\tstruct sk_buff *clone;\n\t\tint i, plen = 0;\n\n\t\tclone = alloc_skb(0, GFP_ATOMIC);\n\t\tif (!clone)\n\t\t\treturn NULL;\n\t\tskb_shinfo(clone)->frag_list = skb_shinfo(head)->frag_list;\n\t\tskb_frag_list_init(head);\n\t\tfor (i = 0; i < skb_shinfo(head)->nr_frags; i++)\n\t\t\tplen += skb_frag_size(&skb_shinfo(head)->frags[i]);\n\t\tclone->data_len = head->data_len - plen;\n\t\tclone->len = clone->data_len;\n\t\thead->truesize += clone->truesize;\n\t\tclone->csum = 0;\n\t\tclone->ip_summed = head->ip_summed;\n\t\tadd_frag_mem_limit(q->fqdir, clone->truesize);\n\t\tskb_shinfo(head)->frag_list = clone;\n\t\tnextp = &clone->next;\n\t} else {\n\t\tnextp = &skb_shinfo(head)->frag_list;\n\t}\n\n\treturn nextp;\n}\nEXPORT_SYMBOL(inet_frag_reasm_prepare);\n\nvoid inet_frag_reasm_finish(struct inet_frag_queue *q, struct sk_buff *head,\n\t\t\t    void *reasm_data, bool try_coalesce)\n{\n\tstruct sk_buff **nextp = reasm_data;\n\tstruct rb_node *rbn;\n\tstruct sk_buff *fp;\n\tint sum_truesize;\n\n\tskb_push(head, head->data - skb_network_header(head));\n\n\t \n\tfp = FRAG_CB(head)->next_frag;\n\trbn = rb_next(&head->rbnode);\n\trb_erase(&head->rbnode, &q->rb_fragments);\n\n\tsum_truesize = head->truesize;\n\twhile (rbn || fp) {\n\t\t \n\t\t \n\t\twhile (fp) {\n\t\t\tstruct sk_buff *next_frag = FRAG_CB(fp)->next_frag;\n\t\t\tbool stolen;\n\t\t\tint delta;\n\n\t\t\tsum_truesize += fp->truesize;\n\t\t\tif (head->ip_summed != fp->ip_summed)\n\t\t\t\thead->ip_summed = CHECKSUM_NONE;\n\t\t\telse if (head->ip_summed == CHECKSUM_COMPLETE)\n\t\t\t\thead->csum = csum_add(head->csum, fp->csum);\n\n\t\t\tif (try_coalesce && skb_try_coalesce(head, fp, &stolen,\n\t\t\t\t\t\t\t     &delta)) {\n\t\t\t\tkfree_skb_partial(fp, stolen);\n\t\t\t} else {\n\t\t\t\tfp->prev = NULL;\n\t\t\t\tmemset(&fp->rbnode, 0, sizeof(fp->rbnode));\n\t\t\t\tfp->sk = NULL;\n\n\t\t\t\thead->data_len += fp->len;\n\t\t\t\thead->len += fp->len;\n\t\t\t\thead->truesize += fp->truesize;\n\n\t\t\t\t*nextp = fp;\n\t\t\t\tnextp = &fp->next;\n\t\t\t}\n\n\t\t\tfp = next_frag;\n\t\t}\n\t\t \n\t\tif (rbn) {\n\t\t\tstruct rb_node *rbnext = rb_next(rbn);\n\n\t\t\tfp = rb_to_skb(rbn);\n\t\t\trb_erase(rbn, &q->rb_fragments);\n\t\t\trbn = rbnext;\n\t\t}\n\t}\n\tsub_frag_mem_limit(q->fqdir, sum_truesize);\n\n\t*nextp = NULL;\n\tskb_mark_not_on_list(head);\n\thead->prev = NULL;\n\thead->tstamp = q->stamp;\n\thead->mono_delivery_time = q->mono_delivery_time;\n}\nEXPORT_SYMBOL(inet_frag_reasm_finish);\n\nstruct sk_buff *inet_frag_pull_head(struct inet_frag_queue *q)\n{\n\tstruct sk_buff *head, *skb;\n\n\thead = skb_rb_first(&q->rb_fragments);\n\tif (!head)\n\t\treturn NULL;\n\tskb = FRAG_CB(head)->next_frag;\n\tif (skb)\n\t\trb_replace_node(&head->rbnode, &skb->rbnode,\n\t\t\t\t&q->rb_fragments);\n\telse\n\t\trb_erase(&head->rbnode, &q->rb_fragments);\n\tmemset(&head->rbnode, 0, sizeof(head->rbnode));\n\tbarrier();\n\n\tif (head == q->fragments_tail)\n\t\tq->fragments_tail = NULL;\n\n\tsub_frag_mem_limit(q->fqdir, head->truesize);\n\n\treturn head;\n}\nEXPORT_SYMBOL(inet_frag_pull_head);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}