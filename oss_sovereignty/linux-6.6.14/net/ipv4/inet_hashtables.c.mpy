{
  "module_name": "inet_hashtables.c",
  "hash_id": "3952cfe541209fd6002b583e8c237881048a1a63166ff28e223f9c346150934f",
  "original_prompt": "Ingested from linux-6.6.14/net/ipv4/inet_hashtables.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/random.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/wait.h>\n#include <linux/vmalloc.h>\n#include <linux/memblock.h>\n\n#include <net/addrconf.h>\n#include <net/inet_connection_sock.h>\n#include <net/inet_hashtables.h>\n#if IS_ENABLED(CONFIG_IPV6)\n#include <net/inet6_hashtables.h>\n#endif\n#include <net/secure_seq.h>\n#include <net/ip.h>\n#include <net/tcp.h>\n#include <net/sock_reuseport.h>\n\nu32 inet_ehashfn(const struct net *net, const __be32 laddr,\n\t\t const __u16 lport, const __be32 faddr,\n\t\t const __be16 fport)\n{\n\tstatic u32 inet_ehash_secret __read_mostly;\n\n\tnet_get_random_once(&inet_ehash_secret, sizeof(inet_ehash_secret));\n\n\treturn __inet_ehashfn(laddr, lport, faddr, fport,\n\t\t\t      inet_ehash_secret + net_hash_mix(net));\n}\nEXPORT_SYMBOL_GPL(inet_ehashfn);\n\n \nstatic u32 sk_ehashfn(const struct sock *sk)\n{\n#if IS_ENABLED(CONFIG_IPV6)\n\tif (sk->sk_family == AF_INET6 &&\n\t    !ipv6_addr_v4mapped(&sk->sk_v6_daddr))\n\t\treturn inet6_ehashfn(sock_net(sk),\n\t\t\t\t     &sk->sk_v6_rcv_saddr, sk->sk_num,\n\t\t\t\t     &sk->sk_v6_daddr, sk->sk_dport);\n#endif\n\treturn inet_ehashfn(sock_net(sk),\n\t\t\t    sk->sk_rcv_saddr, sk->sk_num,\n\t\t\t    sk->sk_daddr, sk->sk_dport);\n}\n\n \nstruct inet_bind_bucket *inet_bind_bucket_create(struct kmem_cache *cachep,\n\t\t\t\t\t\t struct net *net,\n\t\t\t\t\t\t struct inet_bind_hashbucket *head,\n\t\t\t\t\t\t const unsigned short snum,\n\t\t\t\t\t\t int l3mdev)\n{\n\tstruct inet_bind_bucket *tb = kmem_cache_alloc(cachep, GFP_ATOMIC);\n\n\tif (tb) {\n\t\twrite_pnet(&tb->ib_net, net);\n\t\ttb->l3mdev    = l3mdev;\n\t\ttb->port      = snum;\n\t\ttb->fastreuse = 0;\n\t\ttb->fastreuseport = 0;\n\t\tINIT_HLIST_HEAD(&tb->owners);\n\t\thlist_add_head(&tb->node, &head->chain);\n\t}\n\treturn tb;\n}\n\n \nvoid inet_bind_bucket_destroy(struct kmem_cache *cachep, struct inet_bind_bucket *tb)\n{\n\tif (hlist_empty(&tb->owners)) {\n\t\t__hlist_del(&tb->node);\n\t\tkmem_cache_free(cachep, tb);\n\t}\n}\n\nbool inet_bind_bucket_match(const struct inet_bind_bucket *tb, const struct net *net,\n\t\t\t    unsigned short port, int l3mdev)\n{\n\treturn net_eq(ib_net(tb), net) && tb->port == port &&\n\t\ttb->l3mdev == l3mdev;\n}\n\nstatic void inet_bind2_bucket_init(struct inet_bind2_bucket *tb,\n\t\t\t\t   struct net *net,\n\t\t\t\t   struct inet_bind_hashbucket *head,\n\t\t\t\t   unsigned short port, int l3mdev,\n\t\t\t\t   const struct sock *sk)\n{\n\twrite_pnet(&tb->ib_net, net);\n\ttb->l3mdev    = l3mdev;\n\ttb->port      = port;\n#if IS_ENABLED(CONFIG_IPV6)\n\ttb->family    = sk->sk_family;\n\tif (sk->sk_family == AF_INET6)\n\t\ttb->v6_rcv_saddr = sk->sk_v6_rcv_saddr;\n\telse\n#endif\n\t\ttb->rcv_saddr = sk->sk_rcv_saddr;\n\tINIT_HLIST_HEAD(&tb->owners);\n\tINIT_HLIST_HEAD(&tb->deathrow);\n\thlist_add_head(&tb->node, &head->chain);\n}\n\nstruct inet_bind2_bucket *inet_bind2_bucket_create(struct kmem_cache *cachep,\n\t\t\t\t\t\t   struct net *net,\n\t\t\t\t\t\t   struct inet_bind_hashbucket *head,\n\t\t\t\t\t\t   unsigned short port,\n\t\t\t\t\t\t   int l3mdev,\n\t\t\t\t\t\t   const struct sock *sk)\n{\n\tstruct inet_bind2_bucket *tb = kmem_cache_alloc(cachep, GFP_ATOMIC);\n\n\tif (tb)\n\t\tinet_bind2_bucket_init(tb, net, head, port, l3mdev, sk);\n\n\treturn tb;\n}\n\n \nvoid inet_bind2_bucket_destroy(struct kmem_cache *cachep, struct inet_bind2_bucket *tb)\n{\n\tif (hlist_empty(&tb->owners) && hlist_empty(&tb->deathrow)) {\n\t\t__hlist_del(&tb->node);\n\t\tkmem_cache_free(cachep, tb);\n\t}\n}\n\nstatic bool inet_bind2_bucket_addr_match(const struct inet_bind2_bucket *tb2,\n\t\t\t\t\t const struct sock *sk)\n{\n#if IS_ENABLED(CONFIG_IPV6)\n\tif (sk->sk_family != tb2->family) {\n\t\tif (sk->sk_family == AF_INET)\n\t\t\treturn ipv6_addr_v4mapped(&tb2->v6_rcv_saddr) &&\n\t\t\t\ttb2->v6_rcv_saddr.s6_addr32[3] == sk->sk_rcv_saddr;\n\n\t\treturn ipv6_addr_v4mapped(&sk->sk_v6_rcv_saddr) &&\n\t\t\tsk->sk_v6_rcv_saddr.s6_addr32[3] == tb2->rcv_saddr;\n\t}\n\n\tif (sk->sk_family == AF_INET6)\n\t\treturn ipv6_addr_equal(&tb2->v6_rcv_saddr,\n\t\t\t\t       &sk->sk_v6_rcv_saddr);\n#endif\n\treturn tb2->rcv_saddr == sk->sk_rcv_saddr;\n}\n\nvoid inet_bind_hash(struct sock *sk, struct inet_bind_bucket *tb,\n\t\t    struct inet_bind2_bucket *tb2, unsigned short port)\n{\n\tinet_sk(sk)->inet_num = port;\n\tsk_add_bind_node(sk, &tb->owners);\n\tinet_csk(sk)->icsk_bind_hash = tb;\n\tsk_add_bind2_node(sk, &tb2->owners);\n\tinet_csk(sk)->icsk_bind2_hash = tb2;\n}\n\n \nstatic void __inet_put_port(struct sock *sk)\n{\n\tstruct inet_hashinfo *hashinfo = tcp_or_dccp_get_hashinfo(sk);\n\tstruct inet_bind_hashbucket *head, *head2;\n\tstruct net *net = sock_net(sk);\n\tstruct inet_bind_bucket *tb;\n\tint bhash;\n\n\tbhash = inet_bhashfn(net, inet_sk(sk)->inet_num, hashinfo->bhash_size);\n\thead = &hashinfo->bhash[bhash];\n\thead2 = inet_bhashfn_portaddr(hashinfo, sk, net, inet_sk(sk)->inet_num);\n\n\tspin_lock(&head->lock);\n\ttb = inet_csk(sk)->icsk_bind_hash;\n\t__sk_del_bind_node(sk);\n\tinet_csk(sk)->icsk_bind_hash = NULL;\n\tinet_sk(sk)->inet_num = 0;\n\tinet_bind_bucket_destroy(hashinfo->bind_bucket_cachep, tb);\n\n\tspin_lock(&head2->lock);\n\tif (inet_csk(sk)->icsk_bind2_hash) {\n\t\tstruct inet_bind2_bucket *tb2 = inet_csk(sk)->icsk_bind2_hash;\n\n\t\t__sk_del_bind2_node(sk);\n\t\tinet_csk(sk)->icsk_bind2_hash = NULL;\n\t\tinet_bind2_bucket_destroy(hashinfo->bind2_bucket_cachep, tb2);\n\t}\n\tspin_unlock(&head2->lock);\n\n\tspin_unlock(&head->lock);\n}\n\nvoid inet_put_port(struct sock *sk)\n{\n\tlocal_bh_disable();\n\t__inet_put_port(sk);\n\tlocal_bh_enable();\n}\nEXPORT_SYMBOL(inet_put_port);\n\nint __inet_inherit_port(const struct sock *sk, struct sock *child)\n{\n\tstruct inet_hashinfo *table = tcp_or_dccp_get_hashinfo(sk);\n\tunsigned short port = inet_sk(child)->inet_num;\n\tstruct inet_bind_hashbucket *head, *head2;\n\tbool created_inet_bind_bucket = false;\n\tstruct net *net = sock_net(sk);\n\tbool update_fastreuse = false;\n\tstruct inet_bind2_bucket *tb2;\n\tstruct inet_bind_bucket *tb;\n\tint bhash, l3mdev;\n\n\tbhash = inet_bhashfn(net, port, table->bhash_size);\n\thead = &table->bhash[bhash];\n\thead2 = inet_bhashfn_portaddr(table, child, net, port);\n\n\tspin_lock(&head->lock);\n\tspin_lock(&head2->lock);\n\ttb = inet_csk(sk)->icsk_bind_hash;\n\ttb2 = inet_csk(sk)->icsk_bind2_hash;\n\tif (unlikely(!tb || !tb2)) {\n\t\tspin_unlock(&head2->lock);\n\t\tspin_unlock(&head->lock);\n\t\treturn -ENOENT;\n\t}\n\tif (tb->port != port) {\n\t\tl3mdev = inet_sk_bound_l3mdev(sk);\n\n\t\t \n\t\tinet_bind_bucket_for_each(tb, &head->chain) {\n\t\t\tif (inet_bind_bucket_match(tb, net, port, l3mdev))\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!tb) {\n\t\t\ttb = inet_bind_bucket_create(table->bind_bucket_cachep,\n\t\t\t\t\t\t     net, head, port, l3mdev);\n\t\t\tif (!tb) {\n\t\t\t\tspin_unlock(&head2->lock);\n\t\t\t\tspin_unlock(&head->lock);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tcreated_inet_bind_bucket = true;\n\t\t}\n\t\tupdate_fastreuse = true;\n\n\t\tgoto bhash2_find;\n\t} else if (!inet_bind2_bucket_addr_match(tb2, child)) {\n\t\tl3mdev = inet_sk_bound_l3mdev(sk);\n\nbhash2_find:\n\t\ttb2 = inet_bind2_bucket_find(head2, net, port, l3mdev, child);\n\t\tif (!tb2) {\n\t\t\ttb2 = inet_bind2_bucket_create(table->bind2_bucket_cachep,\n\t\t\t\t\t\t       net, head2, port,\n\t\t\t\t\t\t       l3mdev, child);\n\t\t\tif (!tb2)\n\t\t\t\tgoto error;\n\t\t}\n\t}\n\tif (update_fastreuse)\n\t\tinet_csk_update_fastreuse(tb, child);\n\tinet_bind_hash(child, tb, tb2, port);\n\tspin_unlock(&head2->lock);\n\tspin_unlock(&head->lock);\n\n\treturn 0;\n\nerror:\n\tif (created_inet_bind_bucket)\n\t\tinet_bind_bucket_destroy(table->bind_bucket_cachep, tb);\n\tspin_unlock(&head2->lock);\n\tspin_unlock(&head->lock);\n\treturn -ENOMEM;\n}\nEXPORT_SYMBOL_GPL(__inet_inherit_port);\n\nstatic struct inet_listen_hashbucket *\ninet_lhash2_bucket_sk(struct inet_hashinfo *h, struct sock *sk)\n{\n\tu32 hash;\n\n#if IS_ENABLED(CONFIG_IPV6)\n\tif (sk->sk_family == AF_INET6)\n\t\thash = ipv6_portaddr_hash(sock_net(sk),\n\t\t\t\t\t  &sk->sk_v6_rcv_saddr,\n\t\t\t\t\t  inet_sk(sk)->inet_num);\n\telse\n#endif\n\t\thash = ipv4_portaddr_hash(sock_net(sk),\n\t\t\t\t\t  inet_sk(sk)->inet_rcv_saddr,\n\t\t\t\t\t  inet_sk(sk)->inet_num);\n\treturn inet_lhash2_bucket(h, hash);\n}\n\nstatic inline int compute_score(struct sock *sk, struct net *net,\n\t\t\t\tconst unsigned short hnum, const __be32 daddr,\n\t\t\t\tconst int dif, const int sdif)\n{\n\tint score = -1;\n\n\tif (net_eq(sock_net(sk), net) && sk->sk_num == hnum &&\n\t\t\t!ipv6_only_sock(sk)) {\n\t\tif (sk->sk_rcv_saddr != daddr)\n\t\t\treturn -1;\n\n\t\tif (!inet_sk_bound_dev_eq(net, sk->sk_bound_dev_if, dif, sdif))\n\t\t\treturn -1;\n\t\tscore =  sk->sk_bound_dev_if ? 2 : 1;\n\n\t\tif (sk->sk_family == PF_INET)\n\t\t\tscore++;\n\t\tif (READ_ONCE(sk->sk_incoming_cpu) == raw_smp_processor_id())\n\t\t\tscore++;\n\t}\n\treturn score;\n}\n\n \nstruct sock *inet_lookup_reuseport(struct net *net, struct sock *sk,\n\t\t\t\t   struct sk_buff *skb, int doff,\n\t\t\t\t   __be32 saddr, __be16 sport,\n\t\t\t\t   __be32 daddr, unsigned short hnum,\n\t\t\t\t   inet_ehashfn_t *ehashfn)\n{\n\tstruct sock *reuse_sk = NULL;\n\tu32 phash;\n\n\tif (sk->sk_reuseport) {\n\t\tphash = INDIRECT_CALL_2(ehashfn, udp_ehashfn, inet_ehashfn,\n\t\t\t\t\tnet, daddr, hnum, saddr, sport);\n\t\treuse_sk = reuseport_select_sock(sk, phash, skb, doff);\n\t}\n\treturn reuse_sk;\n}\nEXPORT_SYMBOL_GPL(inet_lookup_reuseport);\n\n \n\n \nstatic struct sock *inet_lhash2_lookup(struct net *net,\n\t\t\t\tstruct inet_listen_hashbucket *ilb2,\n\t\t\t\tstruct sk_buff *skb, int doff,\n\t\t\t\tconst __be32 saddr, __be16 sport,\n\t\t\t\tconst __be32 daddr, const unsigned short hnum,\n\t\t\t\tconst int dif, const int sdif)\n{\n\tstruct sock *sk, *result = NULL;\n\tstruct hlist_nulls_node *node;\n\tint score, hiscore = 0;\n\n\tsk_nulls_for_each_rcu(sk, node, &ilb2->nulls_head) {\n\t\tscore = compute_score(sk, net, hnum, daddr, dif, sdif);\n\t\tif (score > hiscore) {\n\t\t\tresult = inet_lookup_reuseport(net, sk, skb, doff,\n\t\t\t\t\t\t       saddr, sport, daddr, hnum, inet_ehashfn);\n\t\t\tif (result)\n\t\t\t\treturn result;\n\n\t\t\tresult = sk;\n\t\t\thiscore = score;\n\t\t}\n\t}\n\n\treturn result;\n}\n\nstruct sock *inet_lookup_run_sk_lookup(struct net *net,\n\t\t\t\t       int protocol,\n\t\t\t\t       struct sk_buff *skb, int doff,\n\t\t\t\t       __be32 saddr, __be16 sport,\n\t\t\t\t       __be32 daddr, u16 hnum, const int dif,\n\t\t\t\t       inet_ehashfn_t *ehashfn)\n{\n\tstruct sock *sk, *reuse_sk;\n\tbool no_reuseport;\n\n\tno_reuseport = bpf_sk_lookup_run_v4(net, protocol, saddr, sport,\n\t\t\t\t\t    daddr, hnum, dif, &sk);\n\tif (no_reuseport || IS_ERR_OR_NULL(sk))\n\t\treturn sk;\n\n\treuse_sk = inet_lookup_reuseport(net, sk, skb, doff, saddr, sport, daddr, hnum,\n\t\t\t\t\t ehashfn);\n\tif (reuse_sk)\n\t\tsk = reuse_sk;\n\treturn sk;\n}\n\nstruct sock *__inet_lookup_listener(struct net *net,\n\t\t\t\t    struct inet_hashinfo *hashinfo,\n\t\t\t\t    struct sk_buff *skb, int doff,\n\t\t\t\t    const __be32 saddr, __be16 sport,\n\t\t\t\t    const __be32 daddr, const unsigned short hnum,\n\t\t\t\t    const int dif, const int sdif)\n{\n\tstruct inet_listen_hashbucket *ilb2;\n\tstruct sock *result = NULL;\n\tunsigned int hash2;\n\n\t \n\tif (static_branch_unlikely(&bpf_sk_lookup_enabled) &&\n\t    hashinfo == net->ipv4.tcp_death_row.hashinfo) {\n\t\tresult = inet_lookup_run_sk_lookup(net, IPPROTO_TCP, skb, doff,\n\t\t\t\t\t\t   saddr, sport, daddr, hnum, dif,\n\t\t\t\t\t\t   inet_ehashfn);\n\t\tif (result)\n\t\t\tgoto done;\n\t}\n\n\thash2 = ipv4_portaddr_hash(net, daddr, hnum);\n\tilb2 = inet_lhash2_bucket(hashinfo, hash2);\n\n\tresult = inet_lhash2_lookup(net, ilb2, skb, doff,\n\t\t\t\t    saddr, sport, daddr, hnum,\n\t\t\t\t    dif, sdif);\n\tif (result)\n\t\tgoto done;\n\n\t \n\thash2 = ipv4_portaddr_hash(net, htonl(INADDR_ANY), hnum);\n\tilb2 = inet_lhash2_bucket(hashinfo, hash2);\n\n\tresult = inet_lhash2_lookup(net, ilb2, skb, doff,\n\t\t\t\t    saddr, sport, htonl(INADDR_ANY), hnum,\n\t\t\t\t    dif, sdif);\ndone:\n\tif (IS_ERR(result))\n\t\treturn NULL;\n\treturn result;\n}\nEXPORT_SYMBOL_GPL(__inet_lookup_listener);\n\n \nvoid sock_gen_put(struct sock *sk)\n{\n\tif (!refcount_dec_and_test(&sk->sk_refcnt))\n\t\treturn;\n\n\tif (sk->sk_state == TCP_TIME_WAIT)\n\t\tinet_twsk_free(inet_twsk(sk));\n\telse if (sk->sk_state == TCP_NEW_SYN_RECV)\n\t\treqsk_free(inet_reqsk(sk));\n\telse\n\t\tsk_free(sk);\n}\nEXPORT_SYMBOL_GPL(sock_gen_put);\n\nvoid sock_edemux(struct sk_buff *skb)\n{\n\tsock_gen_put(skb->sk);\n}\nEXPORT_SYMBOL(sock_edemux);\n\nstruct sock *__inet_lookup_established(struct net *net,\n\t\t\t\t  struct inet_hashinfo *hashinfo,\n\t\t\t\t  const __be32 saddr, const __be16 sport,\n\t\t\t\t  const __be32 daddr, const u16 hnum,\n\t\t\t\t  const int dif, const int sdif)\n{\n\tINET_ADDR_COOKIE(acookie, saddr, daddr);\n\tconst __portpair ports = INET_COMBINED_PORTS(sport, hnum);\n\tstruct sock *sk;\n\tconst struct hlist_nulls_node *node;\n\t \n\tunsigned int hash = inet_ehashfn(net, daddr, hnum, saddr, sport);\n\tunsigned int slot = hash & hashinfo->ehash_mask;\n\tstruct inet_ehash_bucket *head = &hashinfo->ehash[slot];\n\nbegin:\n\tsk_nulls_for_each_rcu(sk, node, &head->chain) {\n\t\tif (sk->sk_hash != hash)\n\t\t\tcontinue;\n\t\tif (likely(inet_match(net, sk, acookie, ports, dif, sdif))) {\n\t\t\tif (unlikely(!refcount_inc_not_zero(&sk->sk_refcnt)))\n\t\t\t\tgoto out;\n\t\t\tif (unlikely(!inet_match(net, sk, acookie,\n\t\t\t\t\t\t ports, dif, sdif))) {\n\t\t\t\tsock_gen_put(sk);\n\t\t\t\tgoto begin;\n\t\t\t}\n\t\t\tgoto found;\n\t\t}\n\t}\n\t \n\tif (get_nulls_value(node) != slot)\n\t\tgoto begin;\nout:\n\tsk = NULL;\nfound:\n\treturn sk;\n}\nEXPORT_SYMBOL_GPL(__inet_lookup_established);\n\n \nstatic int __inet_check_established(struct inet_timewait_death_row *death_row,\n\t\t\t\t    struct sock *sk, __u16 lport,\n\t\t\t\t    struct inet_timewait_sock **twp)\n{\n\tstruct inet_hashinfo *hinfo = death_row->hashinfo;\n\tstruct inet_sock *inet = inet_sk(sk);\n\t__be32 daddr = inet->inet_rcv_saddr;\n\t__be32 saddr = inet->inet_daddr;\n\tint dif = sk->sk_bound_dev_if;\n\tstruct net *net = sock_net(sk);\n\tint sdif = l3mdev_master_ifindex_by_index(net, dif);\n\tINET_ADDR_COOKIE(acookie, saddr, daddr);\n\tconst __portpair ports = INET_COMBINED_PORTS(inet->inet_dport, lport);\n\tunsigned int hash = inet_ehashfn(net, daddr, lport,\n\t\t\t\t\t saddr, inet->inet_dport);\n\tstruct inet_ehash_bucket *head = inet_ehash_bucket(hinfo, hash);\n\tspinlock_t *lock = inet_ehash_lockp(hinfo, hash);\n\tstruct sock *sk2;\n\tconst struct hlist_nulls_node *node;\n\tstruct inet_timewait_sock *tw = NULL;\n\n\tspin_lock(lock);\n\n\tsk_nulls_for_each(sk2, node, &head->chain) {\n\t\tif (sk2->sk_hash != hash)\n\t\t\tcontinue;\n\n\t\tif (likely(inet_match(net, sk2, acookie, ports, dif, sdif))) {\n\t\t\tif (sk2->sk_state == TCP_TIME_WAIT) {\n\t\t\t\ttw = inet_twsk(sk2);\n\t\t\t\tif (twsk_unique(sk, sk2, twp))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tgoto not_unique;\n\t\t}\n\t}\n\n\t \n\tinet->inet_num = lport;\n\tinet->inet_sport = htons(lport);\n\tsk->sk_hash = hash;\n\tWARN_ON(!sk_unhashed(sk));\n\t__sk_nulls_add_node_rcu(sk, &head->chain);\n\tif (tw) {\n\t\tsk_nulls_del_node_init_rcu((struct sock *)tw);\n\t\t__NET_INC_STATS(net, LINUX_MIB_TIMEWAITRECYCLED);\n\t}\n\tspin_unlock(lock);\n\tsock_prot_inuse_add(sock_net(sk), sk->sk_prot, 1);\n\n\tif (twp) {\n\t\t*twp = tw;\n\t} else if (tw) {\n\t\t \n\t\tinet_twsk_deschedule_put(tw);\n\t}\n\treturn 0;\n\nnot_unique:\n\tspin_unlock(lock);\n\treturn -EADDRNOTAVAIL;\n}\n\nstatic u64 inet_sk_port_offset(const struct sock *sk)\n{\n\tconst struct inet_sock *inet = inet_sk(sk);\n\n\treturn secure_ipv4_port_ephemeral(inet->inet_rcv_saddr,\n\t\t\t\t\t  inet->inet_daddr,\n\t\t\t\t\t  inet->inet_dport);\n}\n\n \nstatic bool inet_ehash_lookup_by_sk(struct sock *sk,\n\t\t\t\t    struct hlist_nulls_head *list)\n{\n\tconst __portpair ports = INET_COMBINED_PORTS(sk->sk_dport, sk->sk_num);\n\tconst int sdif = sk->sk_bound_dev_if;\n\tconst int dif = sk->sk_bound_dev_if;\n\tconst struct hlist_nulls_node *node;\n\tstruct net *net = sock_net(sk);\n\tstruct sock *esk;\n\n\tINET_ADDR_COOKIE(acookie, sk->sk_daddr, sk->sk_rcv_saddr);\n\n\tsk_nulls_for_each_rcu(esk, node, list) {\n\t\tif (esk->sk_hash != sk->sk_hash)\n\t\t\tcontinue;\n\t\tif (sk->sk_family == AF_INET) {\n\t\t\tif (unlikely(inet_match(net, esk, acookie,\n\t\t\t\t\t\tports, dif, sdif))) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\t\telse if (sk->sk_family == AF_INET6) {\n\t\t\tif (unlikely(inet6_match(net, esk,\n\t\t\t\t\t\t &sk->sk_v6_daddr,\n\t\t\t\t\t\t &sk->sk_v6_rcv_saddr,\n\t\t\t\t\t\t ports, dif, sdif))) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n#endif\n\t}\n\treturn false;\n}\n\n \nbool inet_ehash_insert(struct sock *sk, struct sock *osk, bool *found_dup_sk)\n{\n\tstruct inet_hashinfo *hashinfo = tcp_or_dccp_get_hashinfo(sk);\n\tstruct inet_ehash_bucket *head;\n\tstruct hlist_nulls_head *list;\n\tspinlock_t *lock;\n\tbool ret = true;\n\n\tWARN_ON_ONCE(!sk_unhashed(sk));\n\n\tsk->sk_hash = sk_ehashfn(sk);\n\thead = inet_ehash_bucket(hashinfo, sk->sk_hash);\n\tlist = &head->chain;\n\tlock = inet_ehash_lockp(hashinfo, sk->sk_hash);\n\n\tspin_lock(lock);\n\tif (osk) {\n\t\tWARN_ON_ONCE(sk->sk_hash != osk->sk_hash);\n\t\tret = sk_nulls_del_node_init_rcu(osk);\n\t} else if (found_dup_sk) {\n\t\t*found_dup_sk = inet_ehash_lookup_by_sk(sk, list);\n\t\tif (*found_dup_sk)\n\t\t\tret = false;\n\t}\n\n\tif (ret)\n\t\t__sk_nulls_add_node_rcu(sk, list);\n\n\tspin_unlock(lock);\n\n\treturn ret;\n}\n\nbool inet_ehash_nolisten(struct sock *sk, struct sock *osk, bool *found_dup_sk)\n{\n\tbool ok = inet_ehash_insert(sk, osk, found_dup_sk);\n\n\tif (ok) {\n\t\tsock_prot_inuse_add(sock_net(sk), sk->sk_prot, 1);\n\t} else {\n\t\tthis_cpu_inc(*sk->sk_prot->orphan_count);\n\t\tinet_sk_set_state(sk, TCP_CLOSE);\n\t\tsock_set_flag(sk, SOCK_DEAD);\n\t\tinet_csk_destroy_sock(sk);\n\t}\n\treturn ok;\n}\nEXPORT_SYMBOL_GPL(inet_ehash_nolisten);\n\nstatic int inet_reuseport_add_sock(struct sock *sk,\n\t\t\t\t   struct inet_listen_hashbucket *ilb)\n{\n\tstruct inet_bind_bucket *tb = inet_csk(sk)->icsk_bind_hash;\n\tconst struct hlist_nulls_node *node;\n\tstruct sock *sk2;\n\tkuid_t uid = sock_i_uid(sk);\n\n\tsk_nulls_for_each_rcu(sk2, node, &ilb->nulls_head) {\n\t\tif (sk2 != sk &&\n\t\t    sk2->sk_family == sk->sk_family &&\n\t\t    ipv6_only_sock(sk2) == ipv6_only_sock(sk) &&\n\t\t    sk2->sk_bound_dev_if == sk->sk_bound_dev_if &&\n\t\t    inet_csk(sk2)->icsk_bind_hash == tb &&\n\t\t    sk2->sk_reuseport && uid_eq(uid, sock_i_uid(sk2)) &&\n\t\t    inet_rcv_saddr_equal(sk, sk2, false))\n\t\t\treturn reuseport_add_sock(sk, sk2,\n\t\t\t\t\t\t  inet_rcv_saddr_any(sk));\n\t}\n\n\treturn reuseport_alloc(sk, inet_rcv_saddr_any(sk));\n}\n\nint __inet_hash(struct sock *sk, struct sock *osk)\n{\n\tstruct inet_hashinfo *hashinfo = tcp_or_dccp_get_hashinfo(sk);\n\tstruct inet_listen_hashbucket *ilb2;\n\tint err = 0;\n\n\tif (sk->sk_state != TCP_LISTEN) {\n\t\tlocal_bh_disable();\n\t\tinet_ehash_nolisten(sk, osk, NULL);\n\t\tlocal_bh_enable();\n\t\treturn 0;\n\t}\n\tWARN_ON(!sk_unhashed(sk));\n\tilb2 = inet_lhash2_bucket_sk(hashinfo, sk);\n\n\tspin_lock(&ilb2->lock);\n\tif (sk->sk_reuseport) {\n\t\terr = inet_reuseport_add_sock(sk, ilb2);\n\t\tif (err)\n\t\t\tgoto unlock;\n\t}\n\tsock_set_flag(sk, SOCK_RCU_FREE);\n\tif (IS_ENABLED(CONFIG_IPV6) && sk->sk_reuseport &&\n\t\tsk->sk_family == AF_INET6)\n\t\t__sk_nulls_add_node_tail_rcu(sk, &ilb2->nulls_head);\n\telse\n\t\t__sk_nulls_add_node_rcu(sk, &ilb2->nulls_head);\n\tsock_prot_inuse_add(sock_net(sk), sk->sk_prot, 1);\nunlock:\n\tspin_unlock(&ilb2->lock);\n\n\treturn err;\n}\nEXPORT_SYMBOL(__inet_hash);\n\nint inet_hash(struct sock *sk)\n{\n\tint err = 0;\n\n\tif (sk->sk_state != TCP_CLOSE)\n\t\terr = __inet_hash(sk, NULL);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(inet_hash);\n\nvoid inet_unhash(struct sock *sk)\n{\n\tstruct inet_hashinfo *hashinfo = tcp_or_dccp_get_hashinfo(sk);\n\n\tif (sk_unhashed(sk))\n\t\treturn;\n\n\tif (sk->sk_state == TCP_LISTEN) {\n\t\tstruct inet_listen_hashbucket *ilb2;\n\n\t\tilb2 = inet_lhash2_bucket_sk(hashinfo, sk);\n\t\t \n\t\tspin_lock(&ilb2->lock);\n\t\tif (sk_unhashed(sk)) {\n\t\t\tspin_unlock(&ilb2->lock);\n\t\t\treturn;\n\t\t}\n\n\t\tif (rcu_access_pointer(sk->sk_reuseport_cb))\n\t\t\treuseport_stop_listen_sock(sk);\n\n\t\t__sk_nulls_del_node_init_rcu(sk);\n\t\tsock_prot_inuse_add(sock_net(sk), sk->sk_prot, -1);\n\t\tspin_unlock(&ilb2->lock);\n\t} else {\n\t\tspinlock_t *lock = inet_ehash_lockp(hashinfo, sk->sk_hash);\n\n\t\tspin_lock_bh(lock);\n\t\tif (sk_unhashed(sk)) {\n\t\t\tspin_unlock_bh(lock);\n\t\t\treturn;\n\t\t}\n\t\t__sk_nulls_del_node_init_rcu(sk);\n\t\tsock_prot_inuse_add(sock_net(sk), sk->sk_prot, -1);\n\t\tspin_unlock_bh(lock);\n\t}\n}\nEXPORT_SYMBOL_GPL(inet_unhash);\n\nstatic bool inet_bind2_bucket_match(const struct inet_bind2_bucket *tb,\n\t\t\t\t    const struct net *net, unsigned short port,\n\t\t\t\t    int l3mdev, const struct sock *sk)\n{\n\tif (!net_eq(ib2_net(tb), net) || tb->port != port ||\n\t    tb->l3mdev != l3mdev)\n\t\treturn false;\n\n\treturn inet_bind2_bucket_addr_match(tb, sk);\n}\n\nbool inet_bind2_bucket_match_addr_any(const struct inet_bind2_bucket *tb, const struct net *net,\n\t\t\t\t      unsigned short port, int l3mdev, const struct sock *sk)\n{\n\tif (!net_eq(ib2_net(tb), net) || tb->port != port ||\n\t    tb->l3mdev != l3mdev)\n\t\treturn false;\n\n#if IS_ENABLED(CONFIG_IPV6)\n\tif (sk->sk_family != tb->family) {\n\t\tif (sk->sk_family == AF_INET)\n\t\t\treturn ipv6_addr_any(&tb->v6_rcv_saddr) ||\n\t\t\t\tipv6_addr_v4mapped_any(&tb->v6_rcv_saddr);\n\n\t\treturn false;\n\t}\n\n\tif (sk->sk_family == AF_INET6)\n\t\treturn ipv6_addr_any(&tb->v6_rcv_saddr);\n#endif\n\treturn tb->rcv_saddr == 0;\n}\n\n \nstruct inet_bind2_bucket *\ninet_bind2_bucket_find(const struct inet_bind_hashbucket *head, const struct net *net,\n\t\t       unsigned short port, int l3mdev, const struct sock *sk)\n{\n\tstruct inet_bind2_bucket *bhash2 = NULL;\n\n\tinet_bind_bucket_for_each(bhash2, &head->chain)\n\t\tif (inet_bind2_bucket_match(bhash2, net, port, l3mdev, sk))\n\t\t\tbreak;\n\n\treturn bhash2;\n}\n\nstruct inet_bind_hashbucket *\ninet_bhash2_addr_any_hashbucket(const struct sock *sk, const struct net *net, int port)\n{\n\tstruct inet_hashinfo *hinfo = tcp_or_dccp_get_hashinfo(sk);\n\tu32 hash;\n\n#if IS_ENABLED(CONFIG_IPV6)\n\tif (sk->sk_family == AF_INET6)\n\t\thash = ipv6_portaddr_hash(net, &in6addr_any, port);\n\telse\n#endif\n\t\thash = ipv4_portaddr_hash(net, 0, port);\n\n\treturn &hinfo->bhash2[hash & (hinfo->bhash_size - 1)];\n}\n\nstatic void inet_update_saddr(struct sock *sk, void *saddr, int family)\n{\n\tif (family == AF_INET) {\n\t\tinet_sk(sk)->inet_saddr = *(__be32 *)saddr;\n\t\tsk_rcv_saddr_set(sk, inet_sk(sk)->inet_saddr);\n\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\telse {\n\t\tsk->sk_v6_rcv_saddr = *(struct in6_addr *)saddr;\n\t}\n#endif\n}\n\nstatic int __inet_bhash2_update_saddr(struct sock *sk, void *saddr, int family, bool reset)\n{\n\tstruct inet_hashinfo *hinfo = tcp_or_dccp_get_hashinfo(sk);\n\tstruct inet_bind_hashbucket *head, *head2;\n\tstruct inet_bind2_bucket *tb2, *new_tb2;\n\tint l3mdev = inet_sk_bound_l3mdev(sk);\n\tint port = inet_sk(sk)->inet_num;\n\tstruct net *net = sock_net(sk);\n\tint bhash;\n\n\tif (!inet_csk(sk)->icsk_bind2_hash) {\n\t\t \n\t\tif (reset)\n\t\t\tinet_reset_saddr(sk);\n\t\telse\n\t\t\tinet_update_saddr(sk, saddr, family);\n\n\t\treturn 0;\n\t}\n\n\t \n\tnew_tb2 = kmem_cache_alloc(hinfo->bind2_bucket_cachep, GFP_ATOMIC);\n\tif (!new_tb2) {\n\t\tif (reset) {\n\t\t\t \n\t\t\tinet_put_port(sk);\n\t\t\tinet_reset_saddr(sk);\n\t\t}\n\n\t\treturn -ENOMEM;\n\t}\n\n\tbhash = inet_bhashfn(net, port, hinfo->bhash_size);\n\thead = &hinfo->bhash[bhash];\n\thead2 = inet_bhashfn_portaddr(hinfo, sk, net, port);\n\n\t \n\tspin_lock_bh(&head->lock);\n\n\tspin_lock(&head2->lock);\n\t__sk_del_bind2_node(sk);\n\tinet_bind2_bucket_destroy(hinfo->bind2_bucket_cachep, inet_csk(sk)->icsk_bind2_hash);\n\tspin_unlock(&head2->lock);\n\n\tif (reset)\n\t\tinet_reset_saddr(sk);\n\telse\n\t\tinet_update_saddr(sk, saddr, family);\n\n\thead2 = inet_bhashfn_portaddr(hinfo, sk, net, port);\n\n\tspin_lock(&head2->lock);\n\ttb2 = inet_bind2_bucket_find(head2, net, port, l3mdev, sk);\n\tif (!tb2) {\n\t\ttb2 = new_tb2;\n\t\tinet_bind2_bucket_init(tb2, net, head2, port, l3mdev, sk);\n\t}\n\tsk_add_bind2_node(sk, &tb2->owners);\n\tinet_csk(sk)->icsk_bind2_hash = tb2;\n\tspin_unlock(&head2->lock);\n\n\tspin_unlock_bh(&head->lock);\n\n\tif (tb2 != new_tb2)\n\t\tkmem_cache_free(hinfo->bind2_bucket_cachep, new_tb2);\n\n\treturn 0;\n}\n\nint inet_bhash2_update_saddr(struct sock *sk, void *saddr, int family)\n{\n\treturn __inet_bhash2_update_saddr(sk, saddr, family, false);\n}\nEXPORT_SYMBOL_GPL(inet_bhash2_update_saddr);\n\nvoid inet_bhash2_reset_saddr(struct sock *sk)\n{\n\tif (!(sk->sk_userlocks & SOCK_BINDADDR_LOCK))\n\t\t__inet_bhash2_update_saddr(sk, NULL, 0, true);\n}\nEXPORT_SYMBOL_GPL(inet_bhash2_reset_saddr);\n\n \n#define INET_TABLE_PERTURB_SIZE (1 << CONFIG_INET_TABLE_PERTURB_ORDER)\nstatic u32 *table_perturb;\n\nint __inet_hash_connect(struct inet_timewait_death_row *death_row,\n\t\tstruct sock *sk, u64 port_offset,\n\t\tint (*check_established)(struct inet_timewait_death_row *,\n\t\t\tstruct sock *, __u16, struct inet_timewait_sock **))\n{\n\tstruct inet_hashinfo *hinfo = death_row->hashinfo;\n\tstruct inet_bind_hashbucket *head, *head2;\n\tstruct inet_timewait_sock *tw = NULL;\n\tint port = inet_sk(sk)->inet_num;\n\tstruct net *net = sock_net(sk);\n\tstruct inet_bind2_bucket *tb2;\n\tstruct inet_bind_bucket *tb;\n\tbool tb_created = false;\n\tu32 remaining, offset;\n\tint ret, i, low, high;\n\tint l3mdev;\n\tu32 index;\n\n\tif (port) {\n\t\tlocal_bh_disable();\n\t\tret = check_established(death_row, sk, port, NULL);\n\t\tlocal_bh_enable();\n\t\treturn ret;\n\t}\n\n\tl3mdev = inet_sk_bound_l3mdev(sk);\n\n\tinet_sk_get_local_port_range(sk, &low, &high);\n\thigh++;  \n\tremaining = high - low;\n\tif (likely(remaining > 1))\n\t\tremaining &= ~1U;\n\n\tget_random_sleepable_once(table_perturb,\n\t\t\t\t  INET_TABLE_PERTURB_SIZE * sizeof(*table_perturb));\n\tindex = port_offset & (INET_TABLE_PERTURB_SIZE - 1);\n\n\toffset = READ_ONCE(table_perturb[index]) + (port_offset >> 32);\n\toffset %= remaining;\n\n\t \n\toffset &= ~1U;\nother_parity_scan:\n\tport = low + offset;\n\tfor (i = 0; i < remaining; i += 2, port += 2) {\n\t\tif (unlikely(port >= high))\n\t\t\tport -= remaining;\n\t\tif (inet_is_local_reserved_port(net, port))\n\t\t\tcontinue;\n\t\thead = &hinfo->bhash[inet_bhashfn(net, port,\n\t\t\t\t\t\t  hinfo->bhash_size)];\n\t\tspin_lock_bh(&head->lock);\n\n\t\t \n\t\tinet_bind_bucket_for_each(tb, &head->chain) {\n\t\t\tif (inet_bind_bucket_match(tb, net, port, l3mdev)) {\n\t\t\t\tif (tb->fastreuse >= 0 ||\n\t\t\t\t    tb->fastreuseport >= 0)\n\t\t\t\t\tgoto next_port;\n\t\t\t\tWARN_ON(hlist_empty(&tb->owners));\n\t\t\t\tif (!check_established(death_row, sk,\n\t\t\t\t\t\t       port, &tw))\n\t\t\t\t\tgoto ok;\n\t\t\t\tgoto next_port;\n\t\t\t}\n\t\t}\n\n\t\ttb = inet_bind_bucket_create(hinfo->bind_bucket_cachep,\n\t\t\t\t\t     net, head, port, l3mdev);\n\t\tif (!tb) {\n\t\t\tspin_unlock_bh(&head->lock);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\ttb_created = true;\n\t\ttb->fastreuse = -1;\n\t\ttb->fastreuseport = -1;\n\t\tgoto ok;\nnext_port:\n\t\tspin_unlock_bh(&head->lock);\n\t\tcond_resched();\n\t}\n\n\toffset++;\n\tif ((offset & 1) && remaining > 1)\n\t\tgoto other_parity_scan;\n\n\treturn -EADDRNOTAVAIL;\n\nok:\n\t \n\thead2 = inet_bhashfn_portaddr(hinfo, sk, net, port);\n\tspin_lock(&head2->lock);\n\n\ttb2 = inet_bind2_bucket_find(head2, net, port, l3mdev, sk);\n\tif (!tb2) {\n\t\ttb2 = inet_bind2_bucket_create(hinfo->bind2_bucket_cachep, net,\n\t\t\t\t\t       head2, port, l3mdev, sk);\n\t\tif (!tb2)\n\t\t\tgoto error;\n\t}\n\n\t \n\ti = max_t(int, i, get_random_u32_below(8) * 2);\n\tWRITE_ONCE(table_perturb[index], READ_ONCE(table_perturb[index]) + i + 2);\n\n\t \n\tinet_bind_hash(sk, tb, tb2, port);\n\n\tif (sk_unhashed(sk)) {\n\t\tinet_sk(sk)->inet_sport = htons(port);\n\t\tinet_ehash_nolisten(sk, (struct sock *)tw, NULL);\n\t}\n\tif (tw)\n\t\tinet_twsk_bind_unhash(tw, hinfo);\n\n\tspin_unlock(&head2->lock);\n\tspin_unlock(&head->lock);\n\n\tif (tw)\n\t\tinet_twsk_deschedule_put(tw);\n\tlocal_bh_enable();\n\treturn 0;\n\nerror:\n\tspin_unlock(&head2->lock);\n\tif (tb_created)\n\t\tinet_bind_bucket_destroy(hinfo->bind_bucket_cachep, tb);\n\tspin_unlock_bh(&head->lock);\n\treturn -ENOMEM;\n}\n\n \nint inet_hash_connect(struct inet_timewait_death_row *death_row,\n\t\t      struct sock *sk)\n{\n\tu64 port_offset = 0;\n\n\tif (!inet_sk(sk)->inet_num)\n\t\tport_offset = inet_sk_port_offset(sk);\n\treturn __inet_hash_connect(death_row, sk, port_offset,\n\t\t\t\t   __inet_check_established);\n}\nEXPORT_SYMBOL_GPL(inet_hash_connect);\n\nstatic void init_hashinfo_lhash2(struct inet_hashinfo *h)\n{\n\tint i;\n\n\tfor (i = 0; i <= h->lhash2_mask; i++) {\n\t\tspin_lock_init(&h->lhash2[i].lock);\n\t\tINIT_HLIST_NULLS_HEAD(&h->lhash2[i].nulls_head,\n\t\t\t\t      i + LISTENING_NULLS_BASE);\n\t}\n}\n\nvoid __init inet_hashinfo2_init(struct inet_hashinfo *h, const char *name,\n\t\t\t\tunsigned long numentries, int scale,\n\t\t\t\tunsigned long low_limit,\n\t\t\t\tunsigned long high_limit)\n{\n\th->lhash2 = alloc_large_system_hash(name,\n\t\t\t\t\t    sizeof(*h->lhash2),\n\t\t\t\t\t    numentries,\n\t\t\t\t\t    scale,\n\t\t\t\t\t    0,\n\t\t\t\t\t    NULL,\n\t\t\t\t\t    &h->lhash2_mask,\n\t\t\t\t\t    low_limit,\n\t\t\t\t\t    high_limit);\n\tinit_hashinfo_lhash2(h);\n\n\t \n\ttable_perturb = alloc_large_system_hash(\"Table-perturb\",\n\t\t\t\t\t\tsizeof(*table_perturb),\n\t\t\t\t\t\tINET_TABLE_PERTURB_SIZE,\n\t\t\t\t\t\t0, 0, NULL, NULL,\n\t\t\t\t\t\tINET_TABLE_PERTURB_SIZE,\n\t\t\t\t\t\tINET_TABLE_PERTURB_SIZE);\n}\n\nint inet_hashinfo2_init_mod(struct inet_hashinfo *h)\n{\n\th->lhash2 = kmalloc_array(INET_LHTABLE_SIZE, sizeof(*h->lhash2), GFP_KERNEL);\n\tif (!h->lhash2)\n\t\treturn -ENOMEM;\n\n\th->lhash2_mask = INET_LHTABLE_SIZE - 1;\n\t \n\tBUG_ON(INET_LHTABLE_SIZE & h->lhash2_mask);\n\n\tinit_hashinfo_lhash2(h);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(inet_hashinfo2_init_mod);\n\nint inet_ehash_locks_alloc(struct inet_hashinfo *hashinfo)\n{\n\tunsigned int locksz = sizeof(spinlock_t);\n\tunsigned int i, nblocks = 1;\n\n\tif (locksz != 0) {\n\t\t \n\t\tnblocks = max(2U * L1_CACHE_BYTES / locksz, 1U);\n\t\tnblocks = roundup_pow_of_two(nblocks * num_possible_cpus());\n\n\t\t \n\t\tnblocks = min(nblocks, hashinfo->ehash_mask + 1);\n\n\t\thashinfo->ehash_locks = kvmalloc_array(nblocks, locksz, GFP_KERNEL);\n\t\tif (!hashinfo->ehash_locks)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < nblocks; i++)\n\t\t\tspin_lock_init(&hashinfo->ehash_locks[i]);\n\t}\n\thashinfo->ehash_locks_mask = nblocks - 1;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(inet_ehash_locks_alloc);\n\nstruct inet_hashinfo *inet_pernet_hashinfo_alloc(struct inet_hashinfo *hashinfo,\n\t\t\t\t\t\t unsigned int ehash_entries)\n{\n\tstruct inet_hashinfo *new_hashinfo;\n\tint i;\n\n\tnew_hashinfo = kmemdup(hashinfo, sizeof(*hashinfo), GFP_KERNEL);\n\tif (!new_hashinfo)\n\t\tgoto err;\n\n\tnew_hashinfo->ehash = vmalloc_huge(ehash_entries * sizeof(struct inet_ehash_bucket),\n\t\t\t\t\t   GFP_KERNEL_ACCOUNT);\n\tif (!new_hashinfo->ehash)\n\t\tgoto free_hashinfo;\n\n\tnew_hashinfo->ehash_mask = ehash_entries - 1;\n\n\tif (inet_ehash_locks_alloc(new_hashinfo))\n\t\tgoto free_ehash;\n\n\tfor (i = 0; i < ehash_entries; i++)\n\t\tINIT_HLIST_NULLS_HEAD(&new_hashinfo->ehash[i].chain, i);\n\n\tnew_hashinfo->pernet = true;\n\n\treturn new_hashinfo;\n\nfree_ehash:\n\tvfree(new_hashinfo->ehash);\nfree_hashinfo:\n\tkfree(new_hashinfo);\nerr:\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(inet_pernet_hashinfo_alloc);\n\nvoid inet_pernet_hashinfo_free(struct inet_hashinfo *hashinfo)\n{\n\tif (!hashinfo->pernet)\n\t\treturn;\n\n\tinet_ehash_locks_free(hashinfo);\n\tvfree(hashinfo->ehash);\n\tkfree(hashinfo);\n}\nEXPORT_SYMBOL_GPL(inet_pernet_hashinfo_free);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}