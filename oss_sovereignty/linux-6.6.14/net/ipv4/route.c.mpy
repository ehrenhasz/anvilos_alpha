{
  "module_name": "route.c",
  "hash_id": "64445edacfc94e1e3f846c6343739c71f8a5c96de43a1b1445637830e68b909e",
  "original_prompt": "Ingested from linux-6.6.14/net/ipv4/route.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"IPv4: \" fmt\n\n#include <linux/module.h>\n#include <linux/bitops.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\n#include <linux/memblock.h>\n#include <linux/socket.h>\n#include <linux/errno.h>\n#include <linux/in.h>\n#include <linux/inet.h>\n#include <linux/netdevice.h>\n#include <linux/proc_fs.h>\n#include <linux/init.h>\n#include <linux/skbuff.h>\n#include <linux/inetdevice.h>\n#include <linux/igmp.h>\n#include <linux/pkt_sched.h>\n#include <linux/mroute.h>\n#include <linux/netfilter_ipv4.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/slab.h>\n#include <linux/jhash.h>\n#include <net/dst.h>\n#include <net/dst_metadata.h>\n#include <net/inet_dscp.h>\n#include <net/net_namespace.h>\n#include <net/ip.h>\n#include <net/route.h>\n#include <net/inetpeer.h>\n#include <net/sock.h>\n#include <net/ip_fib.h>\n#include <net/nexthop.h>\n#include <net/tcp.h>\n#include <net/icmp.h>\n#include <net/xfrm.h>\n#include <net/lwtunnel.h>\n#include <net/netevent.h>\n#include <net/rtnetlink.h>\n#ifdef CONFIG_SYSCTL\n#include <linux/sysctl.h>\n#endif\n#include <net/secure_seq.h>\n#include <net/ip_tunnels.h>\n\n#include \"fib_lookup.h\"\n\n#define RT_FL_TOS(oldflp4) \\\n\t((oldflp4)->flowi4_tos & (IPTOS_RT_MASK | RTO_ONLINK))\n\n#define RT_GC_TIMEOUT (300*HZ)\n\n#define DEFAULT_MIN_PMTU (512 + 20 + 20)\n#define DEFAULT_MTU_EXPIRES (10 * 60 * HZ)\n#define DEFAULT_MIN_ADVMSS 256\nstatic int ip_rt_max_size;\nstatic int ip_rt_redirect_number __read_mostly\t= 9;\nstatic int ip_rt_redirect_load __read_mostly\t= HZ / 50;\nstatic int ip_rt_redirect_silence __read_mostly\t= ((HZ / 50) << (9 + 1));\nstatic int ip_rt_error_cost __read_mostly\t= HZ;\nstatic int ip_rt_error_burst __read_mostly\t= 5 * HZ;\n\nstatic int ip_rt_gc_timeout __read_mostly\t= RT_GC_TIMEOUT;\n\n \n\nINDIRECT_CALLABLE_SCOPE\nstruct dst_entry\t*ipv4_dst_check(struct dst_entry *dst, u32 cookie);\nstatic unsigned int\t ipv4_default_advmss(const struct dst_entry *dst);\nINDIRECT_CALLABLE_SCOPE\nunsigned int\t\tipv4_mtu(const struct dst_entry *dst);\nstatic struct dst_entry *ipv4_negative_advice(struct dst_entry *dst);\nstatic void\t\t ipv4_link_failure(struct sk_buff *skb);\nstatic void\t\t ip_rt_update_pmtu(struct dst_entry *dst, struct sock *sk,\n\t\t\t\t\t   struct sk_buff *skb, u32 mtu,\n\t\t\t\t\t   bool confirm_neigh);\nstatic void\t\t ip_do_redirect(struct dst_entry *dst, struct sock *sk,\n\t\t\t\t\tstruct sk_buff *skb);\nstatic void\t\tipv4_dst_destroy(struct dst_entry *dst);\n\nstatic u32 *ipv4_cow_metrics(struct dst_entry *dst, unsigned long old)\n{\n\tWARN_ON(1);\n\treturn NULL;\n}\n\nstatic struct neighbour *ipv4_neigh_lookup(const struct dst_entry *dst,\n\t\t\t\t\t   struct sk_buff *skb,\n\t\t\t\t\t   const void *daddr);\nstatic void ipv4_confirm_neigh(const struct dst_entry *dst, const void *daddr);\n\nstatic struct dst_ops ipv4_dst_ops = {\n\t.family =\t\tAF_INET,\n\t.check =\t\tipv4_dst_check,\n\t.default_advmss =\tipv4_default_advmss,\n\t.mtu =\t\t\tipv4_mtu,\n\t.cow_metrics =\t\tipv4_cow_metrics,\n\t.destroy =\t\tipv4_dst_destroy,\n\t.negative_advice =\tipv4_negative_advice,\n\t.link_failure =\t\tipv4_link_failure,\n\t.update_pmtu =\t\tip_rt_update_pmtu,\n\t.redirect =\t\tip_do_redirect,\n\t.local_out =\t\t__ip_local_out,\n\t.neigh_lookup =\t\tipv4_neigh_lookup,\n\t.confirm_neigh =\tipv4_confirm_neigh,\n};\n\n#define ECN_OR_COST(class)\tTC_PRIO_##class\n\nconst __u8 ip_tos2prio[16] = {\n\tTC_PRIO_BESTEFFORT,\n\tECN_OR_COST(BESTEFFORT),\n\tTC_PRIO_BESTEFFORT,\n\tECN_OR_COST(BESTEFFORT),\n\tTC_PRIO_BULK,\n\tECN_OR_COST(BULK),\n\tTC_PRIO_BULK,\n\tECN_OR_COST(BULK),\n\tTC_PRIO_INTERACTIVE,\n\tECN_OR_COST(INTERACTIVE),\n\tTC_PRIO_INTERACTIVE,\n\tECN_OR_COST(INTERACTIVE),\n\tTC_PRIO_INTERACTIVE_BULK,\n\tECN_OR_COST(INTERACTIVE_BULK),\n\tTC_PRIO_INTERACTIVE_BULK,\n\tECN_OR_COST(INTERACTIVE_BULK)\n};\nEXPORT_SYMBOL(ip_tos2prio);\n\nstatic DEFINE_PER_CPU(struct rt_cache_stat, rt_cache_stat);\n#define RT_CACHE_STAT_INC(field) raw_cpu_inc(rt_cache_stat.field)\n\n#ifdef CONFIG_PROC_FS\nstatic void *rt_cache_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tif (*pos)\n\t\treturn NULL;\n\treturn SEQ_START_TOKEN;\n}\n\nstatic void *rt_cache_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\t++*pos;\n\treturn NULL;\n}\n\nstatic void rt_cache_seq_stop(struct seq_file *seq, void *v)\n{\n}\n\nstatic int rt_cache_seq_show(struct seq_file *seq, void *v)\n{\n\tif (v == SEQ_START_TOKEN)\n\t\tseq_printf(seq, \"%-127s\\n\",\n\t\t\t   \"Iface\\tDestination\\tGateway \\tFlags\\t\\tRefCnt\\tUse\\t\"\n\t\t\t   \"Metric\\tSource\\t\\tMTU\\tWindow\\tIRTT\\tTOS\\tHHRef\\t\"\n\t\t\t   \"HHUptod\\tSpecDst\");\n\treturn 0;\n}\n\nstatic const struct seq_operations rt_cache_seq_ops = {\n\t.start  = rt_cache_seq_start,\n\t.next   = rt_cache_seq_next,\n\t.stop   = rt_cache_seq_stop,\n\t.show   = rt_cache_seq_show,\n};\n\nstatic void *rt_cpu_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tint cpu;\n\n\tif (*pos == 0)\n\t\treturn SEQ_START_TOKEN;\n\n\tfor (cpu = *pos-1; cpu < nr_cpu_ids; ++cpu) {\n\t\tif (!cpu_possible(cpu))\n\t\t\tcontinue;\n\t\t*pos = cpu+1;\n\t\treturn &per_cpu(rt_cache_stat, cpu);\n\t}\n\treturn NULL;\n}\n\nstatic void *rt_cpu_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\tint cpu;\n\n\tfor (cpu = *pos; cpu < nr_cpu_ids; ++cpu) {\n\t\tif (!cpu_possible(cpu))\n\t\t\tcontinue;\n\t\t*pos = cpu+1;\n\t\treturn &per_cpu(rt_cache_stat, cpu);\n\t}\n\t(*pos)++;\n\treturn NULL;\n\n}\n\nstatic void rt_cpu_seq_stop(struct seq_file *seq, void *v)\n{\n\n}\n\nstatic int rt_cpu_seq_show(struct seq_file *seq, void *v)\n{\n\tstruct rt_cache_stat *st = v;\n\n\tif (v == SEQ_START_TOKEN) {\n\t\tseq_puts(seq, \"entries  in_hit   in_slow_tot in_slow_mc in_no_route in_brd   in_martian_dst in_martian_src out_hit  out_slow_tot out_slow_mc gc_total gc_ignored gc_goal_miss gc_dst_overflow in_hlist_search out_hlist_search\\n\");\n\t\treturn 0;\n\t}\n\n\tseq_printf(seq, \"%08x %08x %08x    %08x   %08x    %08x %08x       \"\n\t\t\t\"%08x       %08x %08x     %08x    %08x %08x   \"\n\t\t\t\"%08x     %08x        %08x        %08x\\n\",\n\t\t   dst_entries_get_slow(&ipv4_dst_ops),\n\t\t   0,  \n\t\t   st->in_slow_tot,\n\t\t   st->in_slow_mc,\n\t\t   st->in_no_route,\n\t\t   st->in_brd,\n\t\t   st->in_martian_dst,\n\t\t   st->in_martian_src,\n\n\t\t   0,  \n\t\t   st->out_slow_tot,\n\t\t   st->out_slow_mc,\n\n\t\t   0,  \n\t\t   0,  \n\t\t   0,  \n\t\t   0,  \n\t\t   0,  \n\t\t   0   \n\t\t);\n\treturn 0;\n}\n\nstatic const struct seq_operations rt_cpu_seq_ops = {\n\t.start  = rt_cpu_seq_start,\n\t.next   = rt_cpu_seq_next,\n\t.stop   = rt_cpu_seq_stop,\n\t.show   = rt_cpu_seq_show,\n};\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\nstatic int rt_acct_proc_show(struct seq_file *m, void *v)\n{\n\tstruct ip_rt_acct *dst, *src;\n\tunsigned int i, j;\n\n\tdst = kcalloc(256, sizeof(struct ip_rt_acct), GFP_KERNEL);\n\tif (!dst)\n\t\treturn -ENOMEM;\n\n\tfor_each_possible_cpu(i) {\n\t\tsrc = (struct ip_rt_acct *)per_cpu_ptr(ip_rt_acct, i);\n\t\tfor (j = 0; j < 256; j++) {\n\t\t\tdst[j].o_bytes   += src[j].o_bytes;\n\t\t\tdst[j].o_packets += src[j].o_packets;\n\t\t\tdst[j].i_bytes   += src[j].i_bytes;\n\t\t\tdst[j].i_packets += src[j].i_packets;\n\t\t}\n\t}\n\n\tseq_write(m, dst, 256 * sizeof(struct ip_rt_acct));\n\tkfree(dst);\n\treturn 0;\n}\n#endif\n\nstatic int __net_init ip_rt_do_proc_init(struct net *net)\n{\n\tstruct proc_dir_entry *pde;\n\n\tpde = proc_create_seq(\"rt_cache\", 0444, net->proc_net,\n\t\t\t      &rt_cache_seq_ops);\n\tif (!pde)\n\t\tgoto err1;\n\n\tpde = proc_create_seq(\"rt_cache\", 0444, net->proc_net_stat,\n\t\t\t      &rt_cpu_seq_ops);\n\tif (!pde)\n\t\tgoto err2;\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\tpde = proc_create_single(\"rt_acct\", 0, net->proc_net,\n\t\t\trt_acct_proc_show);\n\tif (!pde)\n\t\tgoto err3;\n#endif\n\treturn 0;\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\nerr3:\n\tremove_proc_entry(\"rt_cache\", net->proc_net_stat);\n#endif\nerr2:\n\tremove_proc_entry(\"rt_cache\", net->proc_net);\nerr1:\n\treturn -ENOMEM;\n}\n\nstatic void __net_exit ip_rt_do_proc_exit(struct net *net)\n{\n\tremove_proc_entry(\"rt_cache\", net->proc_net_stat);\n\tremove_proc_entry(\"rt_cache\", net->proc_net);\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\tremove_proc_entry(\"rt_acct\", net->proc_net);\n#endif\n}\n\nstatic struct pernet_operations ip_rt_proc_ops __net_initdata =  {\n\t.init = ip_rt_do_proc_init,\n\t.exit = ip_rt_do_proc_exit,\n};\n\nstatic int __init ip_rt_proc_init(void)\n{\n\treturn register_pernet_subsys(&ip_rt_proc_ops);\n}\n\n#else\nstatic inline int ip_rt_proc_init(void)\n{\n\treturn 0;\n}\n#endif  \n\nstatic inline bool rt_is_expired(const struct rtable *rth)\n{\n\treturn rth->rt_genid != rt_genid_ipv4(dev_net(rth->dst.dev));\n}\n\nvoid rt_cache_flush(struct net *net)\n{\n\trt_genid_bump_ipv4(net);\n}\n\nstatic struct neighbour *ipv4_neigh_lookup(const struct dst_entry *dst,\n\t\t\t\t\t   struct sk_buff *skb,\n\t\t\t\t\t   const void *daddr)\n{\n\tconst struct rtable *rt = container_of(dst, struct rtable, dst);\n\tstruct net_device *dev = dst->dev;\n\tstruct neighbour *n;\n\n\trcu_read_lock();\n\n\tif (likely(rt->rt_gw_family == AF_INET)) {\n\t\tn = ip_neigh_gw4(dev, rt->rt_gw4);\n\t} else if (rt->rt_gw_family == AF_INET6) {\n\t\tn = ip_neigh_gw6(dev, &rt->rt_gw6);\n        } else {\n\t\t__be32 pkey;\n\n\t\tpkey = skb ? ip_hdr(skb)->daddr : *((__be32 *) daddr);\n\t\tn = ip_neigh_gw4(dev, pkey);\n\t}\n\n\tif (!IS_ERR(n) && !refcount_inc_not_zero(&n->refcnt))\n\t\tn = NULL;\n\n\trcu_read_unlock();\n\n\treturn n;\n}\n\nstatic void ipv4_confirm_neigh(const struct dst_entry *dst, const void *daddr)\n{\n\tconst struct rtable *rt = container_of(dst, struct rtable, dst);\n\tstruct net_device *dev = dst->dev;\n\tconst __be32 *pkey = daddr;\n\n\tif (rt->rt_gw_family == AF_INET) {\n\t\tpkey = (const __be32 *)&rt->rt_gw4;\n\t} else if (rt->rt_gw_family == AF_INET6) {\n\t\treturn __ipv6_confirm_neigh_stub(dev, &rt->rt_gw6);\n\t} else if (!daddr ||\n\t\t (rt->rt_flags &\n\t\t  (RTCF_MULTICAST | RTCF_BROADCAST | RTCF_LOCAL))) {\n\t\treturn;\n\t}\n\t__ipv4_confirm_neigh(dev, *(__force u32 *)pkey);\n}\n\n \nstatic u32 ip_idents_mask __read_mostly;\nstatic atomic_t *ip_idents __read_mostly;\nstatic u32 *ip_tstamps __read_mostly;\n\n \nstatic u32 ip_idents_reserve(u32 hash, int segs)\n{\n\tu32 bucket, old, now = (u32)jiffies;\n\tatomic_t *p_id;\n\tu32 *p_tstamp;\n\tu32 delta = 0;\n\n\tbucket = hash & ip_idents_mask;\n\tp_tstamp = ip_tstamps + bucket;\n\tp_id = ip_idents + bucket;\n\told = READ_ONCE(*p_tstamp);\n\n\tif (old != now && cmpxchg(p_tstamp, old, now) == old)\n\t\tdelta = get_random_u32_below(now - old);\n\n\t \n\treturn atomic_add_return(segs + delta, p_id) - segs;\n}\n\nvoid __ip_select_ident(struct net *net, struct iphdr *iph, int segs)\n{\n\tu32 hash, id;\n\n\t \n\tif (unlikely(siphash_key_is_zero(&net->ipv4.ip_id_key)))\n\t\tget_random_bytes(&net->ipv4.ip_id_key,\n\t\t\t\t sizeof(net->ipv4.ip_id_key));\n\n\thash = siphash_3u32((__force u32)iph->daddr,\n\t\t\t    (__force u32)iph->saddr,\n\t\t\t    iph->protocol,\n\t\t\t    &net->ipv4.ip_id_key);\n\tid = ip_idents_reserve(hash, segs);\n\tiph->id = htons(id);\n}\nEXPORT_SYMBOL(__ip_select_ident);\n\nstatic void ip_rt_fix_tos(struct flowi4 *fl4)\n{\n\t__u8 tos = RT_FL_TOS(fl4);\n\n\tfl4->flowi4_tos = tos & IPTOS_RT_MASK;\n\tif (tos & RTO_ONLINK)\n\t\tfl4->flowi4_scope = RT_SCOPE_LINK;\n}\n\nstatic void __build_flow_key(const struct net *net, struct flowi4 *fl4,\n\t\t\t     const struct sock *sk, const struct iphdr *iph,\n\t\t\t     int oif, __u8 tos, u8 prot, u32 mark,\n\t\t\t     int flow_flags)\n{\n\t__u8 scope = RT_SCOPE_UNIVERSE;\n\n\tif (sk) {\n\t\toif = sk->sk_bound_dev_if;\n\t\tmark = READ_ONCE(sk->sk_mark);\n\t\ttos = ip_sock_rt_tos(sk);\n\t\tscope = ip_sock_rt_scope(sk);\n\t\tprot = inet_test_bit(HDRINCL, sk) ? IPPROTO_RAW :\n\t\t\t\t\t\t    sk->sk_protocol;\n\t}\n\n\tflowi4_init_output(fl4, oif, mark, tos & IPTOS_RT_MASK, scope,\n\t\t\t   prot, flow_flags, iph->daddr, iph->saddr, 0, 0,\n\t\t\t   sock_net_uid(net, sk));\n}\n\nstatic void build_skb_flow_key(struct flowi4 *fl4, const struct sk_buff *skb,\n\t\t\t       const struct sock *sk)\n{\n\tconst struct net *net = dev_net(skb->dev);\n\tconst struct iphdr *iph = ip_hdr(skb);\n\tint oif = skb->dev->ifindex;\n\tu8 prot = iph->protocol;\n\tu32 mark = skb->mark;\n\t__u8 tos = iph->tos;\n\n\t__build_flow_key(net, fl4, sk, iph, oif, tos, prot, mark, 0);\n}\n\nstatic void build_sk_flow_key(struct flowi4 *fl4, const struct sock *sk)\n{\n\tconst struct inet_sock *inet = inet_sk(sk);\n\tconst struct ip_options_rcu *inet_opt;\n\t__be32 daddr = inet->inet_daddr;\n\n\trcu_read_lock();\n\tinet_opt = rcu_dereference(inet->inet_opt);\n\tif (inet_opt && inet_opt->opt.srr)\n\t\tdaddr = inet_opt->opt.faddr;\n\tflowi4_init_output(fl4, sk->sk_bound_dev_if, READ_ONCE(sk->sk_mark),\n\t\t\t   ip_sock_rt_tos(sk) & IPTOS_RT_MASK,\n\t\t\t   ip_sock_rt_scope(sk),\n\t\t\t   inet_test_bit(HDRINCL, sk) ?\n\t\t\t\tIPPROTO_RAW : sk->sk_protocol,\n\t\t\t   inet_sk_flowi_flags(sk),\n\t\t\t   daddr, inet->inet_saddr, 0, 0, sk->sk_uid);\n\trcu_read_unlock();\n}\n\nstatic void ip_rt_build_flow_key(struct flowi4 *fl4, const struct sock *sk,\n\t\t\t\t const struct sk_buff *skb)\n{\n\tif (skb)\n\t\tbuild_skb_flow_key(fl4, skb, sk);\n\telse\n\t\tbuild_sk_flow_key(fl4, sk);\n}\n\nstatic DEFINE_SPINLOCK(fnhe_lock);\n\nstatic void fnhe_flush_routes(struct fib_nh_exception *fnhe)\n{\n\tstruct rtable *rt;\n\n\trt = rcu_dereference(fnhe->fnhe_rth_input);\n\tif (rt) {\n\t\tRCU_INIT_POINTER(fnhe->fnhe_rth_input, NULL);\n\t\tdst_dev_put(&rt->dst);\n\t\tdst_release(&rt->dst);\n\t}\n\trt = rcu_dereference(fnhe->fnhe_rth_output);\n\tif (rt) {\n\t\tRCU_INIT_POINTER(fnhe->fnhe_rth_output, NULL);\n\t\tdst_dev_put(&rt->dst);\n\t\tdst_release(&rt->dst);\n\t}\n}\n\nstatic void fnhe_remove_oldest(struct fnhe_hash_bucket *hash)\n{\n\tstruct fib_nh_exception __rcu **fnhe_p, **oldest_p;\n\tstruct fib_nh_exception *fnhe, *oldest = NULL;\n\n\tfor (fnhe_p = &hash->chain; ; fnhe_p = &fnhe->fnhe_next) {\n\t\tfnhe = rcu_dereference_protected(*fnhe_p,\n\t\t\t\t\t\t lockdep_is_held(&fnhe_lock));\n\t\tif (!fnhe)\n\t\t\tbreak;\n\t\tif (!oldest ||\n\t\t    time_before(fnhe->fnhe_stamp, oldest->fnhe_stamp)) {\n\t\t\toldest = fnhe;\n\t\t\toldest_p = fnhe_p;\n\t\t}\n\t}\n\tfnhe_flush_routes(oldest);\n\t*oldest_p = oldest->fnhe_next;\n\tkfree_rcu(oldest, rcu);\n}\n\nstatic u32 fnhe_hashfun(__be32 daddr)\n{\n\tstatic siphash_aligned_key_t fnhe_hash_key;\n\tu64 hval;\n\n\tnet_get_random_once(&fnhe_hash_key, sizeof(fnhe_hash_key));\n\thval = siphash_1u32((__force u32)daddr, &fnhe_hash_key);\n\treturn hash_64(hval, FNHE_HASH_SHIFT);\n}\n\nstatic void fill_route_from_fnhe(struct rtable *rt, struct fib_nh_exception *fnhe)\n{\n\trt->rt_pmtu = fnhe->fnhe_pmtu;\n\trt->rt_mtu_locked = fnhe->fnhe_mtu_locked;\n\trt->dst.expires = fnhe->fnhe_expires;\n\n\tif (fnhe->fnhe_gw) {\n\t\trt->rt_flags |= RTCF_REDIRECTED;\n\t\trt->rt_uses_gateway = 1;\n\t\trt->rt_gw_family = AF_INET;\n\t\trt->rt_gw4 = fnhe->fnhe_gw;\n\t}\n}\n\nstatic void update_or_create_fnhe(struct fib_nh_common *nhc, __be32 daddr,\n\t\t\t\t  __be32 gw, u32 pmtu, bool lock,\n\t\t\t\t  unsigned long expires)\n{\n\tstruct fnhe_hash_bucket *hash;\n\tstruct fib_nh_exception *fnhe;\n\tstruct rtable *rt;\n\tu32 genid, hval;\n\tunsigned int i;\n\tint depth;\n\n\tgenid = fnhe_genid(dev_net(nhc->nhc_dev));\n\thval = fnhe_hashfun(daddr);\n\n\tspin_lock_bh(&fnhe_lock);\n\n\thash = rcu_dereference(nhc->nhc_exceptions);\n\tif (!hash) {\n\t\thash = kcalloc(FNHE_HASH_SIZE, sizeof(*hash), GFP_ATOMIC);\n\t\tif (!hash)\n\t\t\tgoto out_unlock;\n\t\trcu_assign_pointer(nhc->nhc_exceptions, hash);\n\t}\n\n\thash += hval;\n\n\tdepth = 0;\n\tfor (fnhe = rcu_dereference(hash->chain); fnhe;\n\t     fnhe = rcu_dereference(fnhe->fnhe_next)) {\n\t\tif (fnhe->fnhe_daddr == daddr)\n\t\t\tbreak;\n\t\tdepth++;\n\t}\n\n\tif (fnhe) {\n\t\tif (fnhe->fnhe_genid != genid)\n\t\t\tfnhe->fnhe_genid = genid;\n\t\tif (gw)\n\t\t\tfnhe->fnhe_gw = gw;\n\t\tif (pmtu) {\n\t\t\tfnhe->fnhe_pmtu = pmtu;\n\t\t\tfnhe->fnhe_mtu_locked = lock;\n\t\t}\n\t\tfnhe->fnhe_expires = max(1UL, expires);\n\t\t \n\t\trt = rcu_dereference(fnhe->fnhe_rth_input);\n\t\tif (rt)\n\t\t\tfill_route_from_fnhe(rt, fnhe);\n\t\trt = rcu_dereference(fnhe->fnhe_rth_output);\n\t\tif (rt)\n\t\t\tfill_route_from_fnhe(rt, fnhe);\n\t} else {\n\t\t \n\t\tint max_depth = FNHE_RECLAIM_DEPTH +\n\t\t\t\tget_random_u32_below(FNHE_RECLAIM_DEPTH);\n\n\t\twhile (depth > max_depth) {\n\t\t\tfnhe_remove_oldest(hash);\n\t\t\tdepth--;\n\t\t}\n\n\t\tfnhe = kzalloc(sizeof(*fnhe), GFP_ATOMIC);\n\t\tif (!fnhe)\n\t\t\tgoto out_unlock;\n\n\t\tfnhe->fnhe_next = hash->chain;\n\n\t\tfnhe->fnhe_genid = genid;\n\t\tfnhe->fnhe_daddr = daddr;\n\t\tfnhe->fnhe_gw = gw;\n\t\tfnhe->fnhe_pmtu = pmtu;\n\t\tfnhe->fnhe_mtu_locked = lock;\n\t\tfnhe->fnhe_expires = max(1UL, expires);\n\n\t\trcu_assign_pointer(hash->chain, fnhe);\n\n\t\t \n\t\trt = rcu_dereference(nhc->nhc_rth_input);\n\t\tif (rt)\n\t\t\trt->dst.obsolete = DST_OBSOLETE_KILL;\n\n\t\tfor_each_possible_cpu(i) {\n\t\t\tstruct rtable __rcu **prt;\n\n\t\t\tprt = per_cpu_ptr(nhc->nhc_pcpu_rth_output, i);\n\t\t\trt = rcu_dereference(*prt);\n\t\t\tif (rt)\n\t\t\t\trt->dst.obsolete = DST_OBSOLETE_KILL;\n\t\t}\n\t}\n\n\tfnhe->fnhe_stamp = jiffies;\n\nout_unlock:\n\tspin_unlock_bh(&fnhe_lock);\n}\n\nstatic void __ip_do_redirect(struct rtable *rt, struct sk_buff *skb, struct flowi4 *fl4,\n\t\t\t     bool kill_route)\n{\n\t__be32 new_gw = icmp_hdr(skb)->un.gateway;\n\t__be32 old_gw = ip_hdr(skb)->saddr;\n\tstruct net_device *dev = skb->dev;\n\tstruct in_device *in_dev;\n\tstruct fib_result res;\n\tstruct neighbour *n;\n\tstruct net *net;\n\n\tswitch (icmp_hdr(skb)->code & 7) {\n\tcase ICMP_REDIR_NET:\n\tcase ICMP_REDIR_NETTOS:\n\tcase ICMP_REDIR_HOST:\n\tcase ICMP_REDIR_HOSTTOS:\n\t\tbreak;\n\n\tdefault:\n\t\treturn;\n\t}\n\n\tif (rt->rt_gw_family != AF_INET || rt->rt_gw4 != old_gw)\n\t\treturn;\n\n\tin_dev = __in_dev_get_rcu(dev);\n\tif (!in_dev)\n\t\treturn;\n\n\tnet = dev_net(dev);\n\tif (new_gw == old_gw || !IN_DEV_RX_REDIRECTS(in_dev) ||\n\t    ipv4_is_multicast(new_gw) || ipv4_is_lbcast(new_gw) ||\n\t    ipv4_is_zeronet(new_gw))\n\t\tgoto reject_redirect;\n\n\tif (!IN_DEV_SHARED_MEDIA(in_dev)) {\n\t\tif (!inet_addr_onlink(in_dev, new_gw, old_gw))\n\t\t\tgoto reject_redirect;\n\t\tif (IN_DEV_SEC_REDIRECTS(in_dev) && ip_fib_check_default(new_gw, dev))\n\t\t\tgoto reject_redirect;\n\t} else {\n\t\tif (inet_addr_type(net, new_gw) != RTN_UNICAST)\n\t\t\tgoto reject_redirect;\n\t}\n\n\tn = __ipv4_neigh_lookup(rt->dst.dev, (__force u32)new_gw);\n\tif (!n)\n\t\tn = neigh_create(&arp_tbl, &new_gw, rt->dst.dev);\n\tif (!IS_ERR(n)) {\n\t\tif (!(READ_ONCE(n->nud_state) & NUD_VALID)) {\n\t\t\tneigh_event_send(n, NULL);\n\t\t} else {\n\t\t\tif (fib_lookup(net, fl4, &res, 0) == 0) {\n\t\t\t\tstruct fib_nh_common *nhc;\n\n\t\t\t\tfib_select_path(net, &res, fl4, skb);\n\t\t\t\tnhc = FIB_RES_NHC(res);\n\t\t\t\tupdate_or_create_fnhe(nhc, fl4->daddr, new_gw,\n\t\t\t\t\t\t0, false,\n\t\t\t\t\t\tjiffies + ip_rt_gc_timeout);\n\t\t\t}\n\t\t\tif (kill_route)\n\t\t\t\trt->dst.obsolete = DST_OBSOLETE_KILL;\n\t\t\tcall_netevent_notifiers(NETEVENT_NEIGH_UPDATE, n);\n\t\t}\n\t\tneigh_release(n);\n\t}\n\treturn;\n\nreject_redirect:\n#ifdef CONFIG_IP_ROUTE_VERBOSE\n\tif (IN_DEV_LOG_MARTIANS(in_dev)) {\n\t\tconst struct iphdr *iph = (const struct iphdr *) skb->data;\n\t\t__be32 daddr = iph->daddr;\n\t\t__be32 saddr = iph->saddr;\n\n\t\tnet_info_ratelimited(\"Redirect from %pI4 on %s about %pI4 ignored\\n\"\n\t\t\t\t     \"  Advised path = %pI4 -> %pI4\\n\",\n\t\t\t\t     &old_gw, dev->name, &new_gw,\n\t\t\t\t     &saddr, &daddr);\n\t}\n#endif\n\t;\n}\n\nstatic void ip_do_redirect(struct dst_entry *dst, struct sock *sk, struct sk_buff *skb)\n{\n\tstruct rtable *rt;\n\tstruct flowi4 fl4;\n\tconst struct iphdr *iph = (const struct iphdr *) skb->data;\n\tstruct net *net = dev_net(skb->dev);\n\tint oif = skb->dev->ifindex;\n\tu8 prot = iph->protocol;\n\tu32 mark = skb->mark;\n\t__u8 tos = iph->tos;\n\n\trt = (struct rtable *) dst;\n\n\t__build_flow_key(net, &fl4, sk, iph, oif, tos, prot, mark, 0);\n\t__ip_do_redirect(rt, skb, &fl4, true);\n}\n\nstatic struct dst_entry *ipv4_negative_advice(struct dst_entry *dst)\n{\n\tstruct rtable *rt = (struct rtable *)dst;\n\tstruct dst_entry *ret = dst;\n\n\tif (rt) {\n\t\tif (dst->obsolete > 0) {\n\t\t\tip_rt_put(rt);\n\t\t\tret = NULL;\n\t\t} else if ((rt->rt_flags & RTCF_REDIRECTED) ||\n\t\t\t   rt->dst.expires) {\n\t\t\tip_rt_put(rt);\n\t\t\tret = NULL;\n\t\t}\n\t}\n\treturn ret;\n}\n\n \n\nvoid ip_rt_send_redirect(struct sk_buff *skb)\n{\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct in_device *in_dev;\n\tstruct inet_peer *peer;\n\tstruct net *net;\n\tint log_martians;\n\tint vif;\n\n\trcu_read_lock();\n\tin_dev = __in_dev_get_rcu(rt->dst.dev);\n\tif (!in_dev || !IN_DEV_TX_REDIRECTS(in_dev)) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\tlog_martians = IN_DEV_LOG_MARTIANS(in_dev);\n\tvif = l3mdev_master_ifindex_rcu(rt->dst.dev);\n\trcu_read_unlock();\n\n\tnet = dev_net(rt->dst.dev);\n\tpeer = inet_getpeer_v4(net->ipv4.peers, ip_hdr(skb)->saddr, vif, 1);\n\tif (!peer) {\n\t\ticmp_send(skb, ICMP_REDIRECT, ICMP_REDIR_HOST,\n\t\t\t  rt_nexthop(rt, ip_hdr(skb)->daddr));\n\t\treturn;\n\t}\n\n\t \n\tif (time_after(jiffies, peer->rate_last + ip_rt_redirect_silence)) {\n\t\tpeer->rate_tokens = 0;\n\t\tpeer->n_redirects = 0;\n\t}\n\n\t \n\tif (peer->n_redirects >= ip_rt_redirect_number) {\n\t\tpeer->rate_last = jiffies;\n\t\tgoto out_put_peer;\n\t}\n\n\t \n\tif (peer->n_redirects == 0 ||\n\t    time_after(jiffies,\n\t\t       (peer->rate_last +\n\t\t\t(ip_rt_redirect_load << peer->n_redirects)))) {\n\t\t__be32 gw = rt_nexthop(rt, ip_hdr(skb)->daddr);\n\n\t\ticmp_send(skb, ICMP_REDIRECT, ICMP_REDIR_HOST, gw);\n\t\tpeer->rate_last = jiffies;\n\t\t++peer->n_redirects;\n#ifdef CONFIG_IP_ROUTE_VERBOSE\n\t\tif (log_martians &&\n\t\t    peer->n_redirects == ip_rt_redirect_number)\n\t\t\tnet_warn_ratelimited(\"host %pI4/if%d ignores redirects for %pI4 to %pI4\\n\",\n\t\t\t\t\t     &ip_hdr(skb)->saddr, inet_iif(skb),\n\t\t\t\t\t     &ip_hdr(skb)->daddr, &gw);\n#endif\n\t}\nout_put_peer:\n\tinet_putpeer(peer);\n}\n\nstatic int ip_error(struct sk_buff *skb)\n{\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct net_device *dev = skb->dev;\n\tstruct in_device *in_dev;\n\tstruct inet_peer *peer;\n\tunsigned long now;\n\tstruct net *net;\n\tSKB_DR(reason);\n\tbool send;\n\tint code;\n\n\tif (netif_is_l3_master(skb->dev)) {\n\t\tdev = __dev_get_by_index(dev_net(skb->dev), IPCB(skb)->iif);\n\t\tif (!dev)\n\t\t\tgoto out;\n\t}\n\n\tin_dev = __in_dev_get_rcu(dev);\n\n\t \n\tif (!in_dev)\n\t\tgoto out;\n\n\tnet = dev_net(rt->dst.dev);\n\tif (!IN_DEV_FORWARD(in_dev)) {\n\t\tswitch (rt->dst.error) {\n\t\tcase EHOSTUNREACH:\n\t\t\tSKB_DR_SET(reason, IP_INADDRERRORS);\n\t\t\t__IP_INC_STATS(net, IPSTATS_MIB_INADDRERRORS);\n\t\t\tbreak;\n\n\t\tcase ENETUNREACH:\n\t\t\tSKB_DR_SET(reason, IP_INNOROUTES);\n\t\t\t__IP_INC_STATS(net, IPSTATS_MIB_INNOROUTES);\n\t\t\tbreak;\n\t\t}\n\t\tgoto out;\n\t}\n\n\tswitch (rt->dst.error) {\n\tcase EINVAL:\n\tdefault:\n\t\tgoto out;\n\tcase EHOSTUNREACH:\n\t\tcode = ICMP_HOST_UNREACH;\n\t\tbreak;\n\tcase ENETUNREACH:\n\t\tcode = ICMP_NET_UNREACH;\n\t\tSKB_DR_SET(reason, IP_INNOROUTES);\n\t\t__IP_INC_STATS(net, IPSTATS_MIB_INNOROUTES);\n\t\tbreak;\n\tcase EACCES:\n\t\tcode = ICMP_PKT_FILTERED;\n\t\tbreak;\n\t}\n\n\tpeer = inet_getpeer_v4(net->ipv4.peers, ip_hdr(skb)->saddr,\n\t\t\t       l3mdev_master_ifindex(skb->dev), 1);\n\n\tsend = true;\n\tif (peer) {\n\t\tnow = jiffies;\n\t\tpeer->rate_tokens += now - peer->rate_last;\n\t\tif (peer->rate_tokens > ip_rt_error_burst)\n\t\t\tpeer->rate_tokens = ip_rt_error_burst;\n\t\tpeer->rate_last = now;\n\t\tif (peer->rate_tokens >= ip_rt_error_cost)\n\t\t\tpeer->rate_tokens -= ip_rt_error_cost;\n\t\telse\n\t\t\tsend = false;\n\t\tinet_putpeer(peer);\n\t}\n\tif (send)\n\t\ticmp_send(skb, ICMP_DEST_UNREACH, code, 0);\n\nout:\tkfree_skb_reason(skb, reason);\n\treturn 0;\n}\n\nstatic void __ip_rt_update_pmtu(struct rtable *rt, struct flowi4 *fl4, u32 mtu)\n{\n\tstruct dst_entry *dst = &rt->dst;\n\tstruct net *net = dev_net(dst->dev);\n\tstruct fib_result res;\n\tbool lock = false;\n\tu32 old_mtu;\n\n\tif (ip_mtu_locked(dst))\n\t\treturn;\n\n\told_mtu = ipv4_mtu(dst);\n\tif (old_mtu < mtu)\n\t\treturn;\n\n\tif (mtu < net->ipv4.ip_rt_min_pmtu) {\n\t\tlock = true;\n\t\tmtu = min(old_mtu, net->ipv4.ip_rt_min_pmtu);\n\t}\n\n\tif (rt->rt_pmtu == mtu && !lock &&\n\t    time_before(jiffies, dst->expires - net->ipv4.ip_rt_mtu_expires / 2))\n\t\treturn;\n\n\trcu_read_lock();\n\tif (fib_lookup(net, fl4, &res, 0) == 0) {\n\t\tstruct fib_nh_common *nhc;\n\n\t\tfib_select_path(net, &res, fl4, NULL);\n\t\tnhc = FIB_RES_NHC(res);\n\t\tupdate_or_create_fnhe(nhc, fl4->daddr, 0, mtu, lock,\n\t\t\t\t      jiffies + net->ipv4.ip_rt_mtu_expires);\n\t}\n\trcu_read_unlock();\n}\n\nstatic void ip_rt_update_pmtu(struct dst_entry *dst, struct sock *sk,\n\t\t\t      struct sk_buff *skb, u32 mtu,\n\t\t\t      bool confirm_neigh)\n{\n\tstruct rtable *rt = (struct rtable *) dst;\n\tstruct flowi4 fl4;\n\n\tip_rt_build_flow_key(&fl4, sk, skb);\n\n\t \n\tif (skb && netif_is_any_bridge_port(skb->dev))\n\t\tfl4.flowi4_oif = 0;\n\n\t__ip_rt_update_pmtu(rt, &fl4, mtu);\n}\n\nvoid ipv4_update_pmtu(struct sk_buff *skb, struct net *net, u32 mtu,\n\t\t      int oif, u8 protocol)\n{\n\tconst struct iphdr *iph = (const struct iphdr *)skb->data;\n\tstruct flowi4 fl4;\n\tstruct rtable *rt;\n\tu32 mark = IP4_REPLY_MARK(net, skb->mark);\n\n\t__build_flow_key(net, &fl4, NULL, iph, oif, iph->tos, protocol, mark,\n\t\t\t 0);\n\trt = __ip_route_output_key(net, &fl4);\n\tif (!IS_ERR(rt)) {\n\t\t__ip_rt_update_pmtu(rt, &fl4, mtu);\n\t\tip_rt_put(rt);\n\t}\n}\nEXPORT_SYMBOL_GPL(ipv4_update_pmtu);\n\nstatic void __ipv4_sk_update_pmtu(struct sk_buff *skb, struct sock *sk, u32 mtu)\n{\n\tconst struct iphdr *iph = (const struct iphdr *)skb->data;\n\tstruct flowi4 fl4;\n\tstruct rtable *rt;\n\n\t__build_flow_key(sock_net(sk), &fl4, sk, iph, 0, 0, 0, 0, 0);\n\n\tif (!fl4.flowi4_mark)\n\t\tfl4.flowi4_mark = IP4_REPLY_MARK(sock_net(sk), skb->mark);\n\n\trt = __ip_route_output_key(sock_net(sk), &fl4);\n\tif (!IS_ERR(rt)) {\n\t\t__ip_rt_update_pmtu(rt, &fl4, mtu);\n\t\tip_rt_put(rt);\n\t}\n}\n\nvoid ipv4_sk_update_pmtu(struct sk_buff *skb, struct sock *sk, u32 mtu)\n{\n\tconst struct iphdr *iph = (const struct iphdr *)skb->data;\n\tstruct flowi4 fl4;\n\tstruct rtable *rt;\n\tstruct dst_entry *odst = NULL;\n\tbool new = false;\n\tstruct net *net = sock_net(sk);\n\n\tbh_lock_sock(sk);\n\n\tif (!ip_sk_accept_pmtu(sk))\n\t\tgoto out;\n\n\todst = sk_dst_get(sk);\n\n\tif (sock_owned_by_user(sk) || !odst) {\n\t\t__ipv4_sk_update_pmtu(skb, sk, mtu);\n\t\tgoto out;\n\t}\n\n\t__build_flow_key(net, &fl4, sk, iph, 0, 0, 0, 0, 0);\n\n\trt = (struct rtable *)odst;\n\tif (odst->obsolete && !odst->ops->check(odst, 0)) {\n\t\trt = ip_route_output_flow(sock_net(sk), &fl4, sk);\n\t\tif (IS_ERR(rt))\n\t\t\tgoto out;\n\n\t\tnew = true;\n\t}\n\n\t__ip_rt_update_pmtu((struct rtable *)xfrm_dst_path(&rt->dst), &fl4, mtu);\n\n\tif (!dst_check(&rt->dst, 0)) {\n\t\tif (new)\n\t\t\tdst_release(&rt->dst);\n\n\t\trt = ip_route_output_flow(sock_net(sk), &fl4, sk);\n\t\tif (IS_ERR(rt))\n\t\t\tgoto out;\n\n\t\tnew = true;\n\t}\n\n\tif (new)\n\t\tsk_dst_set(sk, &rt->dst);\n\nout:\n\tbh_unlock_sock(sk);\n\tdst_release(odst);\n}\nEXPORT_SYMBOL_GPL(ipv4_sk_update_pmtu);\n\nvoid ipv4_redirect(struct sk_buff *skb, struct net *net,\n\t\t   int oif, u8 protocol)\n{\n\tconst struct iphdr *iph = (const struct iphdr *)skb->data;\n\tstruct flowi4 fl4;\n\tstruct rtable *rt;\n\n\t__build_flow_key(net, &fl4, NULL, iph, oif, iph->tos, protocol, 0, 0);\n\trt = __ip_route_output_key(net, &fl4);\n\tif (!IS_ERR(rt)) {\n\t\t__ip_do_redirect(rt, skb, &fl4, false);\n\t\tip_rt_put(rt);\n\t}\n}\nEXPORT_SYMBOL_GPL(ipv4_redirect);\n\nvoid ipv4_sk_redirect(struct sk_buff *skb, struct sock *sk)\n{\n\tconst struct iphdr *iph = (const struct iphdr *)skb->data;\n\tstruct flowi4 fl4;\n\tstruct rtable *rt;\n\tstruct net *net = sock_net(sk);\n\n\t__build_flow_key(net, &fl4, sk, iph, 0, 0, 0, 0, 0);\n\trt = __ip_route_output_key(net, &fl4);\n\tif (!IS_ERR(rt)) {\n\t\t__ip_do_redirect(rt, skb, &fl4, false);\n\t\tip_rt_put(rt);\n\t}\n}\nEXPORT_SYMBOL_GPL(ipv4_sk_redirect);\n\nINDIRECT_CALLABLE_SCOPE struct dst_entry *ipv4_dst_check(struct dst_entry *dst,\n\t\t\t\t\t\t\t u32 cookie)\n{\n\tstruct rtable *rt = (struct rtable *) dst;\n\n\t \n\tif (dst->obsolete != DST_OBSOLETE_FORCE_CHK || rt_is_expired(rt))\n\t\treturn NULL;\n\treturn dst;\n}\nEXPORT_INDIRECT_CALLABLE(ipv4_dst_check);\n\nstatic void ipv4_send_dest_unreach(struct sk_buff *skb)\n{\n\tstruct net_device *dev;\n\tstruct ip_options opt;\n\tint res;\n\n\t \n\tif (!pskb_network_may_pull(skb, sizeof(struct iphdr)) ||\n\t    ip_hdr(skb)->version != 4 || ip_hdr(skb)->ihl < 5)\n\t\treturn;\n\n\tmemset(&opt, 0, sizeof(opt));\n\tif (ip_hdr(skb)->ihl > 5) {\n\t\tif (!pskb_network_may_pull(skb, ip_hdr(skb)->ihl * 4))\n\t\t\treturn;\n\t\topt.optlen = ip_hdr(skb)->ihl * 4 - sizeof(struct iphdr);\n\n\t\trcu_read_lock();\n\t\tdev = skb->dev ? skb->dev : skb_rtable(skb)->dst.dev;\n\t\tres = __ip_options_compile(dev_net(dev), &opt, skb, NULL);\n\t\trcu_read_unlock();\n\n\t\tif (res)\n\t\t\treturn;\n\t}\n\t__icmp_send(skb, ICMP_DEST_UNREACH, ICMP_HOST_UNREACH, 0, &opt);\n}\n\nstatic void ipv4_link_failure(struct sk_buff *skb)\n{\n\tstruct rtable *rt;\n\n\tipv4_send_dest_unreach(skb);\n\n\trt = skb_rtable(skb);\n\tif (rt)\n\t\tdst_set_expires(&rt->dst, 0);\n}\n\nstatic int ip_rt_bug(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tpr_debug(\"%s: %pI4 -> %pI4, %s\\n\",\n\t\t __func__, &ip_hdr(skb)->saddr, &ip_hdr(skb)->daddr,\n\t\t skb->dev ? skb->dev->name : \"?\");\n\tkfree_skb(skb);\n\tWARN_ON(1);\n\treturn 0;\n}\n\n \n\nvoid ip_rt_get_source(u8 *addr, struct sk_buff *skb, struct rtable *rt)\n{\n\t__be32 src;\n\n\tif (rt_is_output_route(rt))\n\t\tsrc = ip_hdr(skb)->saddr;\n\telse {\n\t\tstruct fib_result res;\n\t\tstruct iphdr *iph = ip_hdr(skb);\n\t\tstruct flowi4 fl4 = {\n\t\t\t.daddr = iph->daddr,\n\t\t\t.saddr = iph->saddr,\n\t\t\t.flowi4_tos = RT_TOS(iph->tos),\n\t\t\t.flowi4_oif = rt->dst.dev->ifindex,\n\t\t\t.flowi4_iif = skb->dev->ifindex,\n\t\t\t.flowi4_mark = skb->mark,\n\t\t};\n\n\t\trcu_read_lock();\n\t\tif (fib_lookup(dev_net(rt->dst.dev), &fl4, &res, 0) == 0)\n\t\t\tsrc = fib_result_prefsrc(dev_net(rt->dst.dev), &res);\n\t\telse\n\t\t\tsrc = inet_select_addr(rt->dst.dev,\n\t\t\t\t\t       rt_nexthop(rt, iph->daddr),\n\t\t\t\t\t       RT_SCOPE_UNIVERSE);\n\t\trcu_read_unlock();\n\t}\n\tmemcpy(addr, &src, 4);\n}\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\nstatic void set_class_tag(struct rtable *rt, u32 tag)\n{\n\tif (!(rt->dst.tclassid & 0xFFFF))\n\t\trt->dst.tclassid |= tag & 0xFFFF;\n\tif (!(rt->dst.tclassid & 0xFFFF0000))\n\t\trt->dst.tclassid |= tag & 0xFFFF0000;\n}\n#endif\n\nstatic unsigned int ipv4_default_advmss(const struct dst_entry *dst)\n{\n\tstruct net *net = dev_net(dst->dev);\n\tunsigned int header_size = sizeof(struct tcphdr) + sizeof(struct iphdr);\n\tunsigned int advmss = max_t(unsigned int, ipv4_mtu(dst) - header_size,\n\t\t\t\t    net->ipv4.ip_rt_min_advmss);\n\n\treturn min(advmss, IPV4_MAX_PMTU - header_size);\n}\n\nINDIRECT_CALLABLE_SCOPE unsigned int ipv4_mtu(const struct dst_entry *dst)\n{\n\treturn ip_dst_mtu_maybe_forward(dst, false);\n}\nEXPORT_INDIRECT_CALLABLE(ipv4_mtu);\n\nstatic void ip_del_fnhe(struct fib_nh_common *nhc, __be32 daddr)\n{\n\tstruct fnhe_hash_bucket *hash;\n\tstruct fib_nh_exception *fnhe, __rcu **fnhe_p;\n\tu32 hval = fnhe_hashfun(daddr);\n\n\tspin_lock_bh(&fnhe_lock);\n\n\thash = rcu_dereference_protected(nhc->nhc_exceptions,\n\t\t\t\t\t lockdep_is_held(&fnhe_lock));\n\thash += hval;\n\n\tfnhe_p = &hash->chain;\n\tfnhe = rcu_dereference_protected(*fnhe_p, lockdep_is_held(&fnhe_lock));\n\twhile (fnhe) {\n\t\tif (fnhe->fnhe_daddr == daddr) {\n\t\t\trcu_assign_pointer(*fnhe_p, rcu_dereference_protected(\n\t\t\t\tfnhe->fnhe_next, lockdep_is_held(&fnhe_lock)));\n\t\t\t \n\t\t\tfnhe->fnhe_daddr = 0;\n\t\t\tfnhe_flush_routes(fnhe);\n\t\t\tkfree_rcu(fnhe, rcu);\n\t\t\tbreak;\n\t\t}\n\t\tfnhe_p = &fnhe->fnhe_next;\n\t\tfnhe = rcu_dereference_protected(fnhe->fnhe_next,\n\t\t\t\t\t\t lockdep_is_held(&fnhe_lock));\n\t}\n\n\tspin_unlock_bh(&fnhe_lock);\n}\n\nstatic struct fib_nh_exception *find_exception(struct fib_nh_common *nhc,\n\t\t\t\t\t       __be32 daddr)\n{\n\tstruct fnhe_hash_bucket *hash = rcu_dereference(nhc->nhc_exceptions);\n\tstruct fib_nh_exception *fnhe;\n\tu32 hval;\n\n\tif (!hash)\n\t\treturn NULL;\n\n\thval = fnhe_hashfun(daddr);\n\n\tfor (fnhe = rcu_dereference(hash[hval].chain); fnhe;\n\t     fnhe = rcu_dereference(fnhe->fnhe_next)) {\n\t\tif (fnhe->fnhe_daddr == daddr) {\n\t\t\tif (fnhe->fnhe_expires &&\n\t\t\t    time_after(jiffies, fnhe->fnhe_expires)) {\n\t\t\t\tip_del_fnhe(nhc, daddr);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\treturn fnhe;\n\t\t}\n\t}\n\treturn NULL;\n}\n\n \n\nu32 ip_mtu_from_fib_result(struct fib_result *res, __be32 daddr)\n{\n\tstruct fib_nh_common *nhc = res->nhc;\n\tstruct net_device *dev = nhc->nhc_dev;\n\tstruct fib_info *fi = res->fi;\n\tu32 mtu = 0;\n\n\tif (READ_ONCE(dev_net(dev)->ipv4.sysctl_ip_fwd_use_pmtu) ||\n\t    fi->fib_metrics->metrics[RTAX_LOCK - 1] & (1 << RTAX_MTU))\n\t\tmtu = fi->fib_mtu;\n\n\tif (likely(!mtu)) {\n\t\tstruct fib_nh_exception *fnhe;\n\n\t\tfnhe = find_exception(nhc, daddr);\n\t\tif (fnhe && !time_after_eq(jiffies, fnhe->fnhe_expires))\n\t\t\tmtu = fnhe->fnhe_pmtu;\n\t}\n\n\tif (likely(!mtu))\n\t\tmtu = min(READ_ONCE(dev->mtu), IP_MAX_MTU);\n\n\treturn mtu - lwtunnel_headroom(nhc->nhc_lwtstate, mtu);\n}\n\nstatic bool rt_bind_exception(struct rtable *rt, struct fib_nh_exception *fnhe,\n\t\t\t      __be32 daddr, const bool do_cache)\n{\n\tbool ret = false;\n\n\tspin_lock_bh(&fnhe_lock);\n\n\tif (daddr == fnhe->fnhe_daddr) {\n\t\tstruct rtable __rcu **porig;\n\t\tstruct rtable *orig;\n\t\tint genid = fnhe_genid(dev_net(rt->dst.dev));\n\n\t\tif (rt_is_input_route(rt))\n\t\t\tporig = &fnhe->fnhe_rth_input;\n\t\telse\n\t\t\tporig = &fnhe->fnhe_rth_output;\n\t\torig = rcu_dereference(*porig);\n\n\t\tif (fnhe->fnhe_genid != genid) {\n\t\t\tfnhe->fnhe_genid = genid;\n\t\t\tfnhe->fnhe_gw = 0;\n\t\t\tfnhe->fnhe_pmtu = 0;\n\t\t\tfnhe->fnhe_expires = 0;\n\t\t\tfnhe->fnhe_mtu_locked = false;\n\t\t\tfnhe_flush_routes(fnhe);\n\t\t\torig = NULL;\n\t\t}\n\t\tfill_route_from_fnhe(rt, fnhe);\n\t\tif (!rt->rt_gw4) {\n\t\t\trt->rt_gw4 = daddr;\n\t\t\trt->rt_gw_family = AF_INET;\n\t\t}\n\n\t\tif (do_cache) {\n\t\t\tdst_hold(&rt->dst);\n\t\t\trcu_assign_pointer(*porig, rt);\n\t\t\tif (orig) {\n\t\t\t\tdst_dev_put(&orig->dst);\n\t\t\t\tdst_release(&orig->dst);\n\t\t\t}\n\t\t\tret = true;\n\t\t}\n\n\t\tfnhe->fnhe_stamp = jiffies;\n\t}\n\tspin_unlock_bh(&fnhe_lock);\n\n\treturn ret;\n}\n\nstatic bool rt_cache_route(struct fib_nh_common *nhc, struct rtable *rt)\n{\n\tstruct rtable *orig, *prev, **p;\n\tbool ret = true;\n\n\tif (rt_is_input_route(rt)) {\n\t\tp = (struct rtable **)&nhc->nhc_rth_input;\n\t} else {\n\t\tp = (struct rtable **)raw_cpu_ptr(nhc->nhc_pcpu_rth_output);\n\t}\n\torig = *p;\n\n\t \n\tdst_hold(&rt->dst);\n\tprev = cmpxchg(p, orig, rt);\n\tif (prev == orig) {\n\t\tif (orig) {\n\t\t\trt_add_uncached_list(orig);\n\t\t\tdst_release(&orig->dst);\n\t\t}\n\t} else {\n\t\tdst_release(&rt->dst);\n\t\tret = false;\n\t}\n\n\treturn ret;\n}\n\nstruct uncached_list {\n\tspinlock_t\t\tlock;\n\tstruct list_head\thead;\n\tstruct list_head\tquarantine;\n};\n\nstatic DEFINE_PER_CPU_ALIGNED(struct uncached_list, rt_uncached_list);\n\nvoid rt_add_uncached_list(struct rtable *rt)\n{\n\tstruct uncached_list *ul = raw_cpu_ptr(&rt_uncached_list);\n\n\trt->dst.rt_uncached_list = ul;\n\n\tspin_lock_bh(&ul->lock);\n\tlist_add_tail(&rt->dst.rt_uncached, &ul->head);\n\tspin_unlock_bh(&ul->lock);\n}\n\nvoid rt_del_uncached_list(struct rtable *rt)\n{\n\tif (!list_empty(&rt->dst.rt_uncached)) {\n\t\tstruct uncached_list *ul = rt->dst.rt_uncached_list;\n\n\t\tspin_lock_bh(&ul->lock);\n\t\tlist_del_init(&rt->dst.rt_uncached);\n\t\tspin_unlock_bh(&ul->lock);\n\t}\n}\n\nstatic void ipv4_dst_destroy(struct dst_entry *dst)\n{\n\tstruct rtable *rt = (struct rtable *)dst;\n\n\tip_dst_metrics_put(dst);\n\trt_del_uncached_list(rt);\n}\n\nvoid rt_flush_dev(struct net_device *dev)\n{\n\tstruct rtable *rt, *safe;\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct uncached_list *ul = &per_cpu(rt_uncached_list, cpu);\n\n\t\tif (list_empty(&ul->head))\n\t\t\tcontinue;\n\n\t\tspin_lock_bh(&ul->lock);\n\t\tlist_for_each_entry_safe(rt, safe, &ul->head, dst.rt_uncached) {\n\t\t\tif (rt->dst.dev != dev)\n\t\t\t\tcontinue;\n\t\t\trt->dst.dev = blackhole_netdev;\n\t\t\tnetdev_ref_replace(dev, blackhole_netdev,\n\t\t\t\t\t   &rt->dst.dev_tracker, GFP_ATOMIC);\n\t\t\tlist_move(&rt->dst.rt_uncached, &ul->quarantine);\n\t\t}\n\t\tspin_unlock_bh(&ul->lock);\n\t}\n}\n\nstatic bool rt_cache_valid(const struct rtable *rt)\n{\n\treturn\trt &&\n\t\trt->dst.obsolete == DST_OBSOLETE_FORCE_CHK &&\n\t\t!rt_is_expired(rt);\n}\n\nstatic void rt_set_nexthop(struct rtable *rt, __be32 daddr,\n\t\t\t   const struct fib_result *res,\n\t\t\t   struct fib_nh_exception *fnhe,\n\t\t\t   struct fib_info *fi, u16 type, u32 itag,\n\t\t\t   const bool do_cache)\n{\n\tbool cached = false;\n\n\tif (fi) {\n\t\tstruct fib_nh_common *nhc = FIB_RES_NHC(*res);\n\n\t\tif (nhc->nhc_gw_family && nhc->nhc_scope == RT_SCOPE_LINK) {\n\t\t\trt->rt_uses_gateway = 1;\n\t\t\trt->rt_gw_family = nhc->nhc_gw_family;\n\t\t\t \n\t\t\tif (likely(nhc->nhc_gw_family == AF_INET))\n\t\t\t\trt->rt_gw4 = nhc->nhc_gw.ipv4;\n\t\t\telse\n\t\t\t\trt->rt_gw6 = nhc->nhc_gw.ipv6;\n\t\t}\n\n\t\tip_dst_init_metrics(&rt->dst, fi->fib_metrics);\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\t\tif (nhc->nhc_family == AF_INET) {\n\t\t\tstruct fib_nh *nh;\n\n\t\t\tnh = container_of(nhc, struct fib_nh, nh_common);\n\t\t\trt->dst.tclassid = nh->nh_tclassid;\n\t\t}\n#endif\n\t\trt->dst.lwtstate = lwtstate_get(nhc->nhc_lwtstate);\n\t\tif (unlikely(fnhe))\n\t\t\tcached = rt_bind_exception(rt, fnhe, daddr, do_cache);\n\t\telse if (do_cache)\n\t\t\tcached = rt_cache_route(nhc, rt);\n\t\tif (unlikely(!cached)) {\n\t\t\t \n\t\t\tif (!rt->rt_gw4) {\n\t\t\t\trt->rt_gw_family = AF_INET;\n\t\t\t\trt->rt_gw4 = daddr;\n\t\t\t}\n\t\t\trt_add_uncached_list(rt);\n\t\t}\n\t} else\n\t\trt_add_uncached_list(rt);\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\n#ifdef CONFIG_IP_MULTIPLE_TABLES\n\tset_class_tag(rt, res->tclassid);\n#endif\n\tset_class_tag(rt, itag);\n#endif\n}\n\nstruct rtable *rt_dst_alloc(struct net_device *dev,\n\t\t\t    unsigned int flags, u16 type,\n\t\t\t    bool noxfrm)\n{\n\tstruct rtable *rt;\n\n\trt = dst_alloc(&ipv4_dst_ops, dev, 1, DST_OBSOLETE_FORCE_CHK,\n\t\t       (noxfrm ? DST_NOXFRM : 0));\n\n\tif (rt) {\n\t\trt->rt_genid = rt_genid_ipv4(dev_net(dev));\n\t\trt->rt_flags = flags;\n\t\trt->rt_type = type;\n\t\trt->rt_is_input = 0;\n\t\trt->rt_iif = 0;\n\t\trt->rt_pmtu = 0;\n\t\trt->rt_mtu_locked = 0;\n\t\trt->rt_uses_gateway = 0;\n\t\trt->rt_gw_family = 0;\n\t\trt->rt_gw4 = 0;\n\n\t\trt->dst.output = ip_output;\n\t\tif (flags & RTCF_LOCAL)\n\t\t\trt->dst.input = ip_local_deliver;\n\t}\n\n\treturn rt;\n}\nEXPORT_SYMBOL(rt_dst_alloc);\n\nstruct rtable *rt_dst_clone(struct net_device *dev, struct rtable *rt)\n{\n\tstruct rtable *new_rt;\n\n\tnew_rt = dst_alloc(&ipv4_dst_ops, dev, 1, DST_OBSOLETE_FORCE_CHK,\n\t\t\t   rt->dst.flags);\n\n\tif (new_rt) {\n\t\tnew_rt->rt_genid = rt_genid_ipv4(dev_net(dev));\n\t\tnew_rt->rt_flags = rt->rt_flags;\n\t\tnew_rt->rt_type = rt->rt_type;\n\t\tnew_rt->rt_is_input = rt->rt_is_input;\n\t\tnew_rt->rt_iif = rt->rt_iif;\n\t\tnew_rt->rt_pmtu = rt->rt_pmtu;\n\t\tnew_rt->rt_mtu_locked = rt->rt_mtu_locked;\n\t\tnew_rt->rt_gw_family = rt->rt_gw_family;\n\t\tif (rt->rt_gw_family == AF_INET)\n\t\t\tnew_rt->rt_gw4 = rt->rt_gw4;\n\t\telse if (rt->rt_gw_family == AF_INET6)\n\t\t\tnew_rt->rt_gw6 = rt->rt_gw6;\n\n\t\tnew_rt->dst.input = rt->dst.input;\n\t\tnew_rt->dst.output = rt->dst.output;\n\t\tnew_rt->dst.error = rt->dst.error;\n\t\tnew_rt->dst.lastuse = jiffies;\n\t\tnew_rt->dst.lwtstate = lwtstate_get(rt->dst.lwtstate);\n\t}\n\treturn new_rt;\n}\nEXPORT_SYMBOL(rt_dst_clone);\n\n \nint ip_mc_validate_source(struct sk_buff *skb, __be32 daddr, __be32 saddr,\n\t\t\t  u8 tos, struct net_device *dev,\n\t\t\t  struct in_device *in_dev, u32 *itag)\n{\n\tint err;\n\n\t \n\tif (!in_dev)\n\t\treturn -EINVAL;\n\n\tif (ipv4_is_multicast(saddr) || ipv4_is_lbcast(saddr) ||\n\t    skb->protocol != htons(ETH_P_IP))\n\t\treturn -EINVAL;\n\n\tif (ipv4_is_loopback(saddr) && !IN_DEV_ROUTE_LOCALNET(in_dev))\n\t\treturn -EINVAL;\n\n\tif (ipv4_is_zeronet(saddr)) {\n\t\tif (!ipv4_is_local_multicast(daddr) &&\n\t\t    ip_hdr(skb)->protocol != IPPROTO_IGMP)\n\t\t\treturn -EINVAL;\n\t} else {\n\t\terr = fib_validate_source(skb, saddr, 0, tos, 0, dev,\n\t\t\t\t\t  in_dev, itag);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\treturn 0;\n}\n\n \nstatic int ip_route_input_mc(struct sk_buff *skb, __be32 daddr, __be32 saddr,\n\t\t\t     u8 tos, struct net_device *dev, int our)\n{\n\tstruct in_device *in_dev = __in_dev_get_rcu(dev);\n\tunsigned int flags = RTCF_MULTICAST;\n\tstruct rtable *rth;\n\tu32 itag = 0;\n\tint err;\n\n\terr = ip_mc_validate_source(skb, daddr, saddr, tos, dev, in_dev, &itag);\n\tif (err)\n\t\treturn err;\n\n\tif (our)\n\t\tflags |= RTCF_LOCAL;\n\n\tif (IN_DEV_ORCONF(in_dev, NOPOLICY))\n\t\tIPCB(skb)->flags |= IPSKB_NOPOLICY;\n\n\trth = rt_dst_alloc(dev_net(dev)->loopback_dev, flags, RTN_MULTICAST,\n\t\t\t   false);\n\tif (!rth)\n\t\treturn -ENOBUFS;\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\trth->dst.tclassid = itag;\n#endif\n\trth->dst.output = ip_rt_bug;\n\trth->rt_is_input= 1;\n\n#ifdef CONFIG_IP_MROUTE\n\tif (!ipv4_is_local_multicast(daddr) && IN_DEV_MFORWARD(in_dev))\n\t\trth->dst.input = ip_mr_input;\n#endif\n\tRT_CACHE_STAT_INC(in_slow_mc);\n\n\tskb_dst_drop(skb);\n\tskb_dst_set(skb, &rth->dst);\n\treturn 0;\n}\n\n\nstatic void ip_handle_martian_source(struct net_device *dev,\n\t\t\t\t     struct in_device *in_dev,\n\t\t\t\t     struct sk_buff *skb,\n\t\t\t\t     __be32 daddr,\n\t\t\t\t     __be32 saddr)\n{\n\tRT_CACHE_STAT_INC(in_martian_src);\n#ifdef CONFIG_IP_ROUTE_VERBOSE\n\tif (IN_DEV_LOG_MARTIANS(in_dev) && net_ratelimit()) {\n\t\t \n\t\tpr_warn(\"martian source %pI4 from %pI4, on dev %s\\n\",\n\t\t\t&daddr, &saddr, dev->name);\n\t\tif (dev->hard_header_len && skb_mac_header_was_set(skb)) {\n\t\t\tprint_hex_dump(KERN_WARNING, \"ll header: \",\n\t\t\t\t       DUMP_PREFIX_OFFSET, 16, 1,\n\t\t\t\t       skb_mac_header(skb),\n\t\t\t\t       dev->hard_header_len, false);\n\t\t}\n\t}\n#endif\n}\n\n \nstatic int __mkroute_input(struct sk_buff *skb,\n\t\t\t   const struct fib_result *res,\n\t\t\t   struct in_device *in_dev,\n\t\t\t   __be32 daddr, __be32 saddr, u32 tos)\n{\n\tstruct fib_nh_common *nhc = FIB_RES_NHC(*res);\n\tstruct net_device *dev = nhc->nhc_dev;\n\tstruct fib_nh_exception *fnhe;\n\tstruct rtable *rth;\n\tint err;\n\tstruct in_device *out_dev;\n\tbool do_cache;\n\tu32 itag = 0;\n\n\t \n\tout_dev = __in_dev_get_rcu(dev);\n\tif (!out_dev) {\n\t\tnet_crit_ratelimited(\"Bug in ip_route_input_slow(). Please report.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = fib_validate_source(skb, saddr, daddr, tos, FIB_RES_OIF(*res),\n\t\t\t\t  in_dev->dev, in_dev, &itag);\n\tif (err < 0) {\n\t\tip_handle_martian_source(in_dev->dev, in_dev, skb, daddr,\n\t\t\t\t\t saddr);\n\n\t\tgoto cleanup;\n\t}\n\n\tdo_cache = res->fi && !itag;\n\tif (out_dev == in_dev && err && IN_DEV_TX_REDIRECTS(out_dev) &&\n\t    skb->protocol == htons(ETH_P_IP)) {\n\t\t__be32 gw;\n\n\t\tgw = nhc->nhc_gw_family == AF_INET ? nhc->nhc_gw.ipv4 : 0;\n\t\tif (IN_DEV_SHARED_MEDIA(out_dev) ||\n\t\t    inet_addr_onlink(out_dev, saddr, gw))\n\t\t\tIPCB(skb)->flags |= IPSKB_DOREDIRECT;\n\t}\n\n\tif (skb->protocol != htons(ETH_P_IP)) {\n\t\t \n\t\tif (out_dev == in_dev &&\n\t\t    IN_DEV_PROXY_ARP_PVLAN(in_dev) == 0) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto cleanup;\n\t\t}\n\t}\n\n\tif (IN_DEV_ORCONF(in_dev, NOPOLICY))\n\t\tIPCB(skb)->flags |= IPSKB_NOPOLICY;\n\n\tfnhe = find_exception(nhc, daddr);\n\tif (do_cache) {\n\t\tif (fnhe)\n\t\t\trth = rcu_dereference(fnhe->fnhe_rth_input);\n\t\telse\n\t\t\trth = rcu_dereference(nhc->nhc_rth_input);\n\t\tif (rt_cache_valid(rth)) {\n\t\t\tskb_dst_set_noref(skb, &rth->dst);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\trth = rt_dst_alloc(out_dev->dev, 0, res->type,\n\t\t\t   IN_DEV_ORCONF(out_dev, NOXFRM));\n\tif (!rth) {\n\t\terr = -ENOBUFS;\n\t\tgoto cleanup;\n\t}\n\n\trth->rt_is_input = 1;\n\tRT_CACHE_STAT_INC(in_slow_tot);\n\n\trth->dst.input = ip_forward;\n\n\trt_set_nexthop(rth, daddr, res, fnhe, res->fi, res->type, itag,\n\t\t       do_cache);\n\tlwtunnel_set_redirect(&rth->dst);\n\tskb_dst_set(skb, &rth->dst);\nout:\n\terr = 0;\n cleanup:\n\treturn err;\n}\n\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\n \nstatic void ip_multipath_l3_keys(const struct sk_buff *skb,\n\t\t\t\t struct flow_keys *hash_keys)\n{\n\tconst struct iphdr *outer_iph = ip_hdr(skb);\n\tconst struct iphdr *key_iph = outer_iph;\n\tconst struct iphdr *inner_iph;\n\tconst struct icmphdr *icmph;\n\tstruct iphdr _inner_iph;\n\tstruct icmphdr _icmph;\n\n\tif (likely(outer_iph->protocol != IPPROTO_ICMP))\n\t\tgoto out;\n\n\tif (unlikely((outer_iph->frag_off & htons(IP_OFFSET)) != 0))\n\t\tgoto out;\n\n\ticmph = skb_header_pointer(skb, outer_iph->ihl * 4, sizeof(_icmph),\n\t\t\t\t   &_icmph);\n\tif (!icmph)\n\t\tgoto out;\n\n\tif (!icmp_is_err(icmph->type))\n\t\tgoto out;\n\n\tinner_iph = skb_header_pointer(skb,\n\t\t\t\t       outer_iph->ihl * 4 + sizeof(_icmph),\n\t\t\t\t       sizeof(_inner_iph), &_inner_iph);\n\tif (!inner_iph)\n\t\tgoto out;\n\n\tkey_iph = inner_iph;\nout:\n\thash_keys->addrs.v4addrs.src = key_iph->saddr;\n\thash_keys->addrs.v4addrs.dst = key_iph->daddr;\n}\n\nstatic u32 fib_multipath_custom_hash_outer(const struct net *net,\n\t\t\t\t\t   const struct sk_buff *skb,\n\t\t\t\t\t   bool *p_has_inner)\n{\n\tu32 hash_fields = READ_ONCE(net->ipv4.sysctl_fib_multipath_hash_fields);\n\tstruct flow_keys keys, hash_keys;\n\n\tif (!(hash_fields & FIB_MULTIPATH_HASH_FIELD_OUTER_MASK))\n\t\treturn 0;\n\n\tmemset(&hash_keys, 0, sizeof(hash_keys));\n\tskb_flow_dissect_flow_keys(skb, &keys, FLOW_DISSECTOR_F_STOP_AT_ENCAP);\n\n\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_SRC_IP)\n\t\thash_keys.addrs.v4addrs.src = keys.addrs.v4addrs.src;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_DST_IP)\n\t\thash_keys.addrs.v4addrs.dst = keys.addrs.v4addrs.dst;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_IP_PROTO)\n\t\thash_keys.basic.ip_proto = keys.basic.ip_proto;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_SRC_PORT)\n\t\thash_keys.ports.src = keys.ports.src;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_DST_PORT)\n\t\thash_keys.ports.dst = keys.ports.dst;\n\n\t*p_has_inner = !!(keys.control.flags & FLOW_DIS_ENCAPSULATION);\n\treturn flow_hash_from_keys(&hash_keys);\n}\n\nstatic u32 fib_multipath_custom_hash_inner(const struct net *net,\n\t\t\t\t\t   const struct sk_buff *skb,\n\t\t\t\t\t   bool has_inner)\n{\n\tu32 hash_fields = READ_ONCE(net->ipv4.sysctl_fib_multipath_hash_fields);\n\tstruct flow_keys keys, hash_keys;\n\n\t \n\tif (!has_inner)\n\t\treturn 0;\n\n\tif (!(hash_fields & FIB_MULTIPATH_HASH_FIELD_INNER_MASK))\n\t\treturn 0;\n\n\tmemset(&hash_keys, 0, sizeof(hash_keys));\n\tskb_flow_dissect_flow_keys(skb, &keys, 0);\n\n\tif (!(keys.control.flags & FLOW_DIS_ENCAPSULATION))\n\t\treturn 0;\n\n\tif (keys.control.addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {\n\t\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_INNER_SRC_IP)\n\t\t\thash_keys.addrs.v4addrs.src = keys.addrs.v4addrs.src;\n\t\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_INNER_DST_IP)\n\t\t\thash_keys.addrs.v4addrs.dst = keys.addrs.v4addrs.dst;\n\t} else if (keys.control.addr_type == FLOW_DISSECTOR_KEY_IPV6_ADDRS) {\n\t\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV6_ADDRS;\n\t\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_INNER_SRC_IP)\n\t\t\thash_keys.addrs.v6addrs.src = keys.addrs.v6addrs.src;\n\t\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_INNER_DST_IP)\n\t\t\thash_keys.addrs.v6addrs.dst = keys.addrs.v6addrs.dst;\n\t\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_INNER_FLOWLABEL)\n\t\t\thash_keys.tags.flow_label = keys.tags.flow_label;\n\t}\n\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_INNER_IP_PROTO)\n\t\thash_keys.basic.ip_proto = keys.basic.ip_proto;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_INNER_SRC_PORT)\n\t\thash_keys.ports.src = keys.ports.src;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_INNER_DST_PORT)\n\t\thash_keys.ports.dst = keys.ports.dst;\n\n\treturn flow_hash_from_keys(&hash_keys);\n}\n\nstatic u32 fib_multipath_custom_hash_skb(const struct net *net,\n\t\t\t\t\t const struct sk_buff *skb)\n{\n\tu32 mhash, mhash_inner;\n\tbool has_inner = true;\n\n\tmhash = fib_multipath_custom_hash_outer(net, skb, &has_inner);\n\tmhash_inner = fib_multipath_custom_hash_inner(net, skb, has_inner);\n\n\treturn jhash_2words(mhash, mhash_inner, 0);\n}\n\nstatic u32 fib_multipath_custom_hash_fl4(const struct net *net,\n\t\t\t\t\t const struct flowi4 *fl4)\n{\n\tu32 hash_fields = READ_ONCE(net->ipv4.sysctl_fib_multipath_hash_fields);\n\tstruct flow_keys hash_keys;\n\n\tif (!(hash_fields & FIB_MULTIPATH_HASH_FIELD_OUTER_MASK))\n\t\treturn 0;\n\n\tmemset(&hash_keys, 0, sizeof(hash_keys));\n\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_SRC_IP)\n\t\thash_keys.addrs.v4addrs.src = fl4->saddr;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_DST_IP)\n\t\thash_keys.addrs.v4addrs.dst = fl4->daddr;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_IP_PROTO)\n\t\thash_keys.basic.ip_proto = fl4->flowi4_proto;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_SRC_PORT)\n\t\thash_keys.ports.src = fl4->fl4_sport;\n\tif (hash_fields & FIB_MULTIPATH_HASH_FIELD_DST_PORT)\n\t\thash_keys.ports.dst = fl4->fl4_dport;\n\n\treturn flow_hash_from_keys(&hash_keys);\n}\n\n \nint fib_multipath_hash(const struct net *net, const struct flowi4 *fl4,\n\t\t       const struct sk_buff *skb, struct flow_keys *flkeys)\n{\n\tu32 multipath_hash = fl4 ? fl4->flowi4_multipath_hash : 0;\n\tstruct flow_keys hash_keys;\n\tu32 mhash = 0;\n\n\tswitch (READ_ONCE(net->ipv4.sysctl_fib_multipath_hash_policy)) {\n\tcase 0:\n\t\tmemset(&hash_keys, 0, sizeof(hash_keys));\n\t\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\tif (skb) {\n\t\t\tip_multipath_l3_keys(skb, &hash_keys);\n\t\t} else {\n\t\t\thash_keys.addrs.v4addrs.src = fl4->saddr;\n\t\t\thash_keys.addrs.v4addrs.dst = fl4->daddr;\n\t\t}\n\t\tmhash = flow_hash_from_keys(&hash_keys);\n\t\tbreak;\n\tcase 1:\n\t\t \n\t\tif (skb) {\n\t\t\tunsigned int flag = FLOW_DISSECTOR_F_STOP_AT_ENCAP;\n\t\t\tstruct flow_keys keys;\n\n\t\t\t \n\t\t\tif (skb->l4_hash)\n\t\t\t\treturn skb_get_hash_raw(skb) >> 1;\n\n\t\t\tmemset(&hash_keys, 0, sizeof(hash_keys));\n\n\t\t\tif (!flkeys) {\n\t\t\t\tskb_flow_dissect_flow_keys(skb, &keys, flag);\n\t\t\t\tflkeys = &keys;\n\t\t\t}\n\n\t\t\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\t\thash_keys.addrs.v4addrs.src = flkeys->addrs.v4addrs.src;\n\t\t\thash_keys.addrs.v4addrs.dst = flkeys->addrs.v4addrs.dst;\n\t\t\thash_keys.ports.src = flkeys->ports.src;\n\t\t\thash_keys.ports.dst = flkeys->ports.dst;\n\t\t\thash_keys.basic.ip_proto = flkeys->basic.ip_proto;\n\t\t} else {\n\t\t\tmemset(&hash_keys, 0, sizeof(hash_keys));\n\t\t\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\t\thash_keys.addrs.v4addrs.src = fl4->saddr;\n\t\t\thash_keys.addrs.v4addrs.dst = fl4->daddr;\n\t\t\thash_keys.ports.src = fl4->fl4_sport;\n\t\t\thash_keys.ports.dst = fl4->fl4_dport;\n\t\t\thash_keys.basic.ip_proto = fl4->flowi4_proto;\n\t\t}\n\t\tmhash = flow_hash_from_keys(&hash_keys);\n\t\tbreak;\n\tcase 2:\n\t\tmemset(&hash_keys, 0, sizeof(hash_keys));\n\t\t \n\t\tif (skb) {\n\t\t\tstruct flow_keys keys;\n\n\t\t\tskb_flow_dissect_flow_keys(skb, &keys, 0);\n\t\t\t \n\t\t\tif (keys.control.addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {\n\t\t\t\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\t\t\thash_keys.addrs.v4addrs.src = keys.addrs.v4addrs.src;\n\t\t\t\thash_keys.addrs.v4addrs.dst = keys.addrs.v4addrs.dst;\n\t\t\t} else if (keys.control.addr_type == FLOW_DISSECTOR_KEY_IPV6_ADDRS) {\n\t\t\t\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV6_ADDRS;\n\t\t\t\thash_keys.addrs.v6addrs.src = keys.addrs.v6addrs.src;\n\t\t\t\thash_keys.addrs.v6addrs.dst = keys.addrs.v6addrs.dst;\n\t\t\t\thash_keys.tags.flow_label = keys.tags.flow_label;\n\t\t\t\thash_keys.basic.ip_proto = keys.basic.ip_proto;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\t\t\tip_multipath_l3_keys(skb, &hash_keys);\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\thash_keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\t\thash_keys.addrs.v4addrs.src = fl4->saddr;\n\t\t\thash_keys.addrs.v4addrs.dst = fl4->daddr;\n\t\t}\n\t\tmhash = flow_hash_from_keys(&hash_keys);\n\t\tbreak;\n\tcase 3:\n\t\tif (skb)\n\t\t\tmhash = fib_multipath_custom_hash_skb(net, skb);\n\t\telse\n\t\t\tmhash = fib_multipath_custom_hash_fl4(net, fl4);\n\t\tbreak;\n\t}\n\n\tif (multipath_hash)\n\t\tmhash = jhash_2words(mhash, multipath_hash, 0);\n\n\treturn mhash >> 1;\n}\n#endif  \n\nstatic int ip_mkroute_input(struct sk_buff *skb,\n\t\t\t    struct fib_result *res,\n\t\t\t    struct in_device *in_dev,\n\t\t\t    __be32 daddr, __be32 saddr, u32 tos,\n\t\t\t    struct flow_keys *hkeys)\n{\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\n\tif (res->fi && fib_info_num_path(res->fi) > 1) {\n\t\tint h = fib_multipath_hash(res->fi->fib_net, NULL, skb, hkeys);\n\n\t\tfib_select_multipath(res, h);\n\t\tIPCB(skb)->flags |= IPSKB_MULTIPATH;\n\t}\n#endif\n\n\t \n\treturn __mkroute_input(skb, res, in_dev, daddr, saddr, tos);\n}\n\n \nint ip_route_use_hint(struct sk_buff *skb, __be32 daddr, __be32 saddr,\n\t\t      u8 tos, struct net_device *dev,\n\t\t      const struct sk_buff *hint)\n{\n\tstruct in_device *in_dev = __in_dev_get_rcu(dev);\n\tstruct rtable *rt = skb_rtable(hint);\n\tstruct net *net = dev_net(dev);\n\tint err = -EINVAL;\n\tu32 tag = 0;\n\n\tif (ipv4_is_multicast(saddr) || ipv4_is_lbcast(saddr))\n\t\tgoto martian_source;\n\n\tif (ipv4_is_zeronet(saddr))\n\t\tgoto martian_source;\n\n\tif (ipv4_is_loopback(saddr) && !IN_DEV_NET_ROUTE_LOCALNET(in_dev, net))\n\t\tgoto martian_source;\n\n\tif (rt->rt_type != RTN_LOCAL)\n\t\tgoto skip_validate_source;\n\n\ttos &= IPTOS_RT_MASK;\n\terr = fib_validate_source(skb, saddr, daddr, tos, 0, dev, in_dev, &tag);\n\tif (err < 0)\n\t\tgoto martian_source;\n\nskip_validate_source:\n\tskb_dst_copy(skb, hint);\n\treturn 0;\n\nmartian_source:\n\tip_handle_martian_source(dev, in_dev, skb, daddr, saddr);\n\treturn err;\n}\n\n \nstatic struct net_device *ip_rt_get_dev(struct net *net,\n\t\t\t\t\tconst struct fib_result *res)\n{\n\tstruct fib_nh_common *nhc = res->fi ? res->nhc : NULL;\n\tstruct net_device *dev = NULL;\n\n\tif (nhc)\n\t\tdev = l3mdev_master_dev_rcu(nhc->nhc_dev);\n\n\treturn dev ? : net->loopback_dev;\n}\n\n \n\nstatic int ip_route_input_slow(struct sk_buff *skb, __be32 daddr, __be32 saddr,\n\t\t\t       u8 tos, struct net_device *dev,\n\t\t\t       struct fib_result *res)\n{\n\tstruct in_device *in_dev = __in_dev_get_rcu(dev);\n\tstruct flow_keys *flkeys = NULL, _flkeys;\n\tstruct net    *net = dev_net(dev);\n\tstruct ip_tunnel_info *tun_info;\n\tint\t\terr = -EINVAL;\n\tunsigned int\tflags = 0;\n\tu32\t\titag = 0;\n\tstruct rtable\t*rth;\n\tstruct flowi4\tfl4;\n\tbool do_cache = true;\n\n\t \n\n\tif (!in_dev)\n\t\tgoto out;\n\n\t \n\n\ttun_info = skb_tunnel_info(skb);\n\tif (tun_info && !(tun_info->mode & IP_TUNNEL_INFO_TX))\n\t\tfl4.flowi4_tun_key.tun_id = tun_info->key.tun_id;\n\telse\n\t\tfl4.flowi4_tun_key.tun_id = 0;\n\tskb_dst_drop(skb);\n\n\tif (ipv4_is_multicast(saddr) || ipv4_is_lbcast(saddr))\n\t\tgoto martian_source;\n\n\tres->fi = NULL;\n\tres->table = NULL;\n\tif (ipv4_is_lbcast(daddr) || (saddr == 0 && daddr == 0))\n\t\tgoto brd_input;\n\n\t \n\tif (ipv4_is_zeronet(saddr))\n\t\tgoto martian_source;\n\n\tif (ipv4_is_zeronet(daddr))\n\t\tgoto martian_destination;\n\n\t \n\tif (ipv4_is_loopback(daddr)) {\n\t\tif (!IN_DEV_NET_ROUTE_LOCALNET(in_dev, net))\n\t\t\tgoto martian_destination;\n\t} else if (ipv4_is_loopback(saddr)) {\n\t\tif (!IN_DEV_NET_ROUTE_LOCALNET(in_dev, net))\n\t\t\tgoto martian_source;\n\t}\n\n\t \n\tfl4.flowi4_l3mdev = 0;\n\tfl4.flowi4_oif = 0;\n\tfl4.flowi4_iif = dev->ifindex;\n\tfl4.flowi4_mark = skb->mark;\n\tfl4.flowi4_tos = tos;\n\tfl4.flowi4_scope = RT_SCOPE_UNIVERSE;\n\tfl4.flowi4_flags = 0;\n\tfl4.daddr = daddr;\n\tfl4.saddr = saddr;\n\tfl4.flowi4_uid = sock_net_uid(net, NULL);\n\tfl4.flowi4_multipath_hash = 0;\n\n\tif (fib4_rules_early_flow_dissect(net, skb, &fl4, &_flkeys)) {\n\t\tflkeys = &_flkeys;\n\t} else {\n\t\tfl4.flowi4_proto = 0;\n\t\tfl4.fl4_sport = 0;\n\t\tfl4.fl4_dport = 0;\n\t}\n\n\terr = fib_lookup(net, &fl4, res, 0);\n\tif (err != 0) {\n\t\tif (!IN_DEV_FORWARD(in_dev))\n\t\t\terr = -EHOSTUNREACH;\n\t\tgoto no_route;\n\t}\n\n\tif (res->type == RTN_BROADCAST) {\n\t\tif (IN_DEV_BFORWARD(in_dev))\n\t\t\tgoto make_route;\n\t\t \n\t\tif (IPV4_DEVCONF_ALL(net, BC_FORWARDING))\n\t\t\tdo_cache = false;\n\t\tgoto brd_input;\n\t}\n\n\tif (res->type == RTN_LOCAL) {\n\t\terr = fib_validate_source(skb, saddr, daddr, tos,\n\t\t\t\t\t  0, dev, in_dev, &itag);\n\t\tif (err < 0)\n\t\t\tgoto martian_source;\n\t\tgoto local_input;\n\t}\n\n\tif (!IN_DEV_FORWARD(in_dev)) {\n\t\terr = -EHOSTUNREACH;\n\t\tgoto no_route;\n\t}\n\tif (res->type != RTN_UNICAST)\n\t\tgoto martian_destination;\n\nmake_route:\n\terr = ip_mkroute_input(skb, res, in_dev, daddr, saddr, tos, flkeys);\nout:\treturn err;\n\nbrd_input:\n\tif (skb->protocol != htons(ETH_P_IP))\n\t\tgoto e_inval;\n\n\tif (!ipv4_is_zeronet(saddr)) {\n\t\terr = fib_validate_source(skb, saddr, 0, tos, 0, dev,\n\t\t\t\t\t  in_dev, &itag);\n\t\tif (err < 0)\n\t\t\tgoto martian_source;\n\t}\n\tflags |= RTCF_BROADCAST;\n\tres->type = RTN_BROADCAST;\n\tRT_CACHE_STAT_INC(in_brd);\n\nlocal_input:\n\tif (IN_DEV_ORCONF(in_dev, NOPOLICY))\n\t\tIPCB(skb)->flags |= IPSKB_NOPOLICY;\n\n\tdo_cache &= res->fi && !itag;\n\tif (do_cache) {\n\t\tstruct fib_nh_common *nhc = FIB_RES_NHC(*res);\n\n\t\trth = rcu_dereference(nhc->nhc_rth_input);\n\t\tif (rt_cache_valid(rth)) {\n\t\t\tskb_dst_set_noref(skb, &rth->dst);\n\t\t\terr = 0;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\trth = rt_dst_alloc(ip_rt_get_dev(net, res),\n\t\t\t   flags | RTCF_LOCAL, res->type, false);\n\tif (!rth)\n\t\tgoto e_nobufs;\n\n\trth->dst.output= ip_rt_bug;\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\trth->dst.tclassid = itag;\n#endif\n\trth->rt_is_input = 1;\n\n\tRT_CACHE_STAT_INC(in_slow_tot);\n\tif (res->type == RTN_UNREACHABLE) {\n\t\trth->dst.input= ip_error;\n\t\trth->dst.error= -err;\n\t\trth->rt_flags\t&= ~RTCF_LOCAL;\n\t}\n\n\tif (do_cache) {\n\t\tstruct fib_nh_common *nhc = FIB_RES_NHC(*res);\n\n\t\trth->dst.lwtstate = lwtstate_get(nhc->nhc_lwtstate);\n\t\tif (lwtunnel_input_redirect(rth->dst.lwtstate)) {\n\t\t\tWARN_ON(rth->dst.input == lwtunnel_input);\n\t\t\trth->dst.lwtstate->orig_input = rth->dst.input;\n\t\t\trth->dst.input = lwtunnel_input;\n\t\t}\n\n\t\tif (unlikely(!rt_cache_route(nhc, rth)))\n\t\t\trt_add_uncached_list(rth);\n\t}\n\tskb_dst_set(skb, &rth->dst);\n\terr = 0;\n\tgoto out;\n\nno_route:\n\tRT_CACHE_STAT_INC(in_no_route);\n\tres->type = RTN_UNREACHABLE;\n\tres->fi = NULL;\n\tres->table = NULL;\n\tgoto local_input;\n\n\t \nmartian_destination:\n\tRT_CACHE_STAT_INC(in_martian_dst);\n#ifdef CONFIG_IP_ROUTE_VERBOSE\n\tif (IN_DEV_LOG_MARTIANS(in_dev))\n\t\tnet_warn_ratelimited(\"martian destination %pI4 from %pI4, dev %s\\n\",\n\t\t\t\t     &daddr, &saddr, dev->name);\n#endif\n\ne_inval:\n\terr = -EINVAL;\n\tgoto out;\n\ne_nobufs:\n\terr = -ENOBUFS;\n\tgoto out;\n\nmartian_source:\n\tip_handle_martian_source(dev, in_dev, skb, daddr, saddr);\n\tgoto out;\n}\n\n \nstatic int ip_route_input_rcu(struct sk_buff *skb, __be32 daddr, __be32 saddr,\n\t\t\t      u8 tos, struct net_device *dev, struct fib_result *res)\n{\n\t \n\tif (ipv4_is_multicast(daddr)) {\n\t\tstruct in_device *in_dev = __in_dev_get_rcu(dev);\n\t\tint our = 0;\n\t\tint err = -EINVAL;\n\n\t\tif (!in_dev)\n\t\t\treturn err;\n\t\tour = ip_check_mc_rcu(in_dev, daddr, saddr,\n\t\t\t\t      ip_hdr(skb)->protocol);\n\n\t\t \n\t\tif (!our && netif_is_l3_slave(dev)) {\n\t\t\tstruct in_device *l3_in_dev;\n\n\t\t\tl3_in_dev = __in_dev_get_rcu(skb->dev);\n\t\t\tif (l3_in_dev)\n\t\t\t\tour = ip_check_mc_rcu(l3_in_dev, daddr, saddr,\n\t\t\t\t\t\t      ip_hdr(skb)->protocol);\n\t\t}\n\n\t\tif (our\n#ifdef CONFIG_IP_MROUTE\n\t\t\t||\n\t\t    (!ipv4_is_local_multicast(daddr) &&\n\t\t     IN_DEV_MFORWARD(in_dev))\n#endif\n\t\t   ) {\n\t\t\terr = ip_route_input_mc(skb, daddr, saddr,\n\t\t\t\t\t\ttos, dev, our);\n\t\t}\n\t\treturn err;\n\t}\n\n\treturn ip_route_input_slow(skb, daddr, saddr, tos, dev, res);\n}\n\nint ip_route_input_noref(struct sk_buff *skb, __be32 daddr, __be32 saddr,\n\t\t\t u8 tos, struct net_device *dev)\n{\n\tstruct fib_result res;\n\tint err;\n\n\ttos &= IPTOS_RT_MASK;\n\trcu_read_lock();\n\terr = ip_route_input_rcu(skb, daddr, saddr, tos, dev, &res);\n\trcu_read_unlock();\n\n\treturn err;\n}\nEXPORT_SYMBOL(ip_route_input_noref);\n\n \nstatic struct rtable *__mkroute_output(const struct fib_result *res,\n\t\t\t\t       const struct flowi4 *fl4, int orig_oif,\n\t\t\t\t       struct net_device *dev_out,\n\t\t\t\t       unsigned int flags)\n{\n\tstruct fib_info *fi = res->fi;\n\tstruct fib_nh_exception *fnhe;\n\tstruct in_device *in_dev;\n\tu16 type = res->type;\n\tstruct rtable *rth;\n\tbool do_cache;\n\n\tin_dev = __in_dev_get_rcu(dev_out);\n\tif (!in_dev)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (likely(!IN_DEV_ROUTE_LOCALNET(in_dev)))\n\t\tif (ipv4_is_loopback(fl4->saddr) &&\n\t\t    !(dev_out->flags & IFF_LOOPBACK) &&\n\t\t    !netif_is_l3_master(dev_out))\n\t\t\treturn ERR_PTR(-EINVAL);\n\n\tif (ipv4_is_lbcast(fl4->daddr))\n\t\ttype = RTN_BROADCAST;\n\telse if (ipv4_is_multicast(fl4->daddr))\n\t\ttype = RTN_MULTICAST;\n\telse if (ipv4_is_zeronet(fl4->daddr))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (dev_out->flags & IFF_LOOPBACK)\n\t\tflags |= RTCF_LOCAL;\n\n\tdo_cache = true;\n\tif (type == RTN_BROADCAST) {\n\t\tflags |= RTCF_BROADCAST | RTCF_LOCAL;\n\t\tfi = NULL;\n\t} else if (type == RTN_MULTICAST) {\n\t\tflags |= RTCF_MULTICAST | RTCF_LOCAL;\n\t\tif (!ip_check_mc_rcu(in_dev, fl4->daddr, fl4->saddr,\n\t\t\t\t     fl4->flowi4_proto))\n\t\t\tflags &= ~RTCF_LOCAL;\n\t\telse\n\t\t\tdo_cache = false;\n\t\t \n\t\tif (fi && res->prefixlen < 4)\n\t\t\tfi = NULL;\n\t} else if ((type == RTN_LOCAL) && (orig_oif != 0) &&\n\t\t   (orig_oif != dev_out->ifindex)) {\n\t\t \n\t\tdo_cache = false;\n\t}\n\n\tfnhe = NULL;\n\tdo_cache &= fi != NULL;\n\tif (fi) {\n\t\tstruct fib_nh_common *nhc = FIB_RES_NHC(*res);\n\t\tstruct rtable __rcu **prth;\n\n\t\tfnhe = find_exception(nhc, fl4->daddr);\n\t\tif (!do_cache)\n\t\t\tgoto add;\n\t\tif (fnhe) {\n\t\t\tprth = &fnhe->fnhe_rth_output;\n\t\t} else {\n\t\t\tif (unlikely(fl4->flowi4_flags &\n\t\t\t\t     FLOWI_FLAG_KNOWN_NH &&\n\t\t\t\t     !(nhc->nhc_gw_family &&\n\t\t\t\t       nhc->nhc_scope == RT_SCOPE_LINK))) {\n\t\t\t\tdo_cache = false;\n\t\t\t\tgoto add;\n\t\t\t}\n\t\t\tprth = raw_cpu_ptr(nhc->nhc_pcpu_rth_output);\n\t\t}\n\t\trth = rcu_dereference(*prth);\n\t\tif (rt_cache_valid(rth) && dst_hold_safe(&rth->dst))\n\t\t\treturn rth;\n\t}\n\nadd:\n\trth = rt_dst_alloc(dev_out, flags, type,\n\t\t\t   IN_DEV_ORCONF(in_dev, NOXFRM));\n\tif (!rth)\n\t\treturn ERR_PTR(-ENOBUFS);\n\n\trth->rt_iif = orig_oif;\n\n\tRT_CACHE_STAT_INC(out_slow_tot);\n\n\tif (flags & (RTCF_BROADCAST | RTCF_MULTICAST)) {\n\t\tif (flags & RTCF_LOCAL &&\n\t\t    !(dev_out->flags & IFF_LOOPBACK)) {\n\t\t\trth->dst.output = ip_mc_output;\n\t\t\tRT_CACHE_STAT_INC(out_slow_mc);\n\t\t}\n#ifdef CONFIG_IP_MROUTE\n\t\tif (type == RTN_MULTICAST) {\n\t\t\tif (IN_DEV_MFORWARD(in_dev) &&\n\t\t\t    !ipv4_is_local_multicast(fl4->daddr)) {\n\t\t\t\trth->dst.input = ip_mr_input;\n\t\t\t\trth->dst.output = ip_mc_output;\n\t\t\t}\n\t\t}\n#endif\n\t}\n\n\trt_set_nexthop(rth, fl4->daddr, res, fnhe, fi, type, 0, do_cache);\n\tlwtunnel_set_redirect(&rth->dst);\n\n\treturn rth;\n}\n\n \n\nstruct rtable *ip_route_output_key_hash(struct net *net, struct flowi4 *fl4,\n\t\t\t\t\tconst struct sk_buff *skb)\n{\n\tstruct fib_result res = {\n\t\t.type\t\t= RTN_UNSPEC,\n\t\t.fi\t\t= NULL,\n\t\t.table\t\t= NULL,\n\t\t.tclassid\t= 0,\n\t};\n\tstruct rtable *rth;\n\n\tfl4->flowi4_iif = LOOPBACK_IFINDEX;\n\tip_rt_fix_tos(fl4);\n\n\trcu_read_lock();\n\trth = ip_route_output_key_hash_rcu(net, fl4, &res, skb);\n\trcu_read_unlock();\n\n\treturn rth;\n}\nEXPORT_SYMBOL_GPL(ip_route_output_key_hash);\n\nstruct rtable *ip_route_output_key_hash_rcu(struct net *net, struct flowi4 *fl4,\n\t\t\t\t\t    struct fib_result *res,\n\t\t\t\t\t    const struct sk_buff *skb)\n{\n\tstruct net_device *dev_out = NULL;\n\tint orig_oif = fl4->flowi4_oif;\n\tunsigned int flags = 0;\n\tstruct rtable *rth;\n\tint err;\n\n\tif (fl4->saddr) {\n\t\tif (ipv4_is_multicast(fl4->saddr) ||\n\t\t    ipv4_is_lbcast(fl4->saddr) ||\n\t\t    ipv4_is_zeronet(fl4->saddr)) {\n\t\t\trth = ERR_PTR(-EINVAL);\n\t\t\tgoto out;\n\t\t}\n\n\t\trth = ERR_PTR(-ENETUNREACH);\n\n\t\t \n\n\t\tif (fl4->flowi4_oif == 0 &&\n\t\t    (ipv4_is_multicast(fl4->daddr) ||\n\t\t     ipv4_is_lbcast(fl4->daddr))) {\n\t\t\t \n\t\t\tdev_out = __ip_dev_find(net, fl4->saddr, false);\n\t\t\tif (!dev_out)\n\t\t\t\tgoto out;\n\n\t\t\t \n\n\t\t\tfl4->flowi4_oif = dev_out->ifindex;\n\t\t\tgoto make_route;\n\t\t}\n\n\t\tif (!(fl4->flowi4_flags & FLOWI_FLAG_ANYSRC)) {\n\t\t\t \n\t\t\tif (!__ip_dev_find(net, fl4->saddr, false))\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\n\n\tif (fl4->flowi4_oif) {\n\t\tdev_out = dev_get_by_index_rcu(net, fl4->flowi4_oif);\n\t\trth = ERR_PTR(-ENODEV);\n\t\tif (!dev_out)\n\t\t\tgoto out;\n\n\t\t \n\t\tif (!(dev_out->flags & IFF_UP) || !__in_dev_get_rcu(dev_out)) {\n\t\t\trth = ERR_PTR(-ENETUNREACH);\n\t\t\tgoto out;\n\t\t}\n\t\tif (ipv4_is_local_multicast(fl4->daddr) ||\n\t\t    ipv4_is_lbcast(fl4->daddr) ||\n\t\t    fl4->flowi4_proto == IPPROTO_IGMP) {\n\t\t\tif (!fl4->saddr)\n\t\t\t\tfl4->saddr = inet_select_addr(dev_out, 0,\n\t\t\t\t\t\t\t      RT_SCOPE_LINK);\n\t\t\tgoto make_route;\n\t\t}\n\t\tif (!fl4->saddr) {\n\t\t\tif (ipv4_is_multicast(fl4->daddr))\n\t\t\t\tfl4->saddr = inet_select_addr(dev_out, 0,\n\t\t\t\t\t\t\t      fl4->flowi4_scope);\n\t\t\telse if (!fl4->daddr)\n\t\t\t\tfl4->saddr = inet_select_addr(dev_out, 0,\n\t\t\t\t\t\t\t      RT_SCOPE_HOST);\n\t\t}\n\t}\n\n\tif (!fl4->daddr) {\n\t\tfl4->daddr = fl4->saddr;\n\t\tif (!fl4->daddr)\n\t\t\tfl4->daddr = fl4->saddr = htonl(INADDR_LOOPBACK);\n\t\tdev_out = net->loopback_dev;\n\t\tfl4->flowi4_oif = LOOPBACK_IFINDEX;\n\t\tres->type = RTN_LOCAL;\n\t\tflags |= RTCF_LOCAL;\n\t\tgoto make_route;\n\t}\n\n\terr = fib_lookup(net, fl4, res, 0);\n\tif (err) {\n\t\tres->fi = NULL;\n\t\tres->table = NULL;\n\t\tif (fl4->flowi4_oif &&\n\t\t    (ipv4_is_multicast(fl4->daddr) || !fl4->flowi4_l3mdev)) {\n\t\t\t \n\n\t\t\tif (fl4->saddr == 0)\n\t\t\t\tfl4->saddr = inet_select_addr(dev_out, 0,\n\t\t\t\t\t\t\t      RT_SCOPE_LINK);\n\t\t\tres->type = RTN_UNICAST;\n\t\t\tgoto make_route;\n\t\t}\n\t\trth = ERR_PTR(err);\n\t\tgoto out;\n\t}\n\n\tif (res->type == RTN_LOCAL) {\n\t\tif (!fl4->saddr) {\n\t\t\tif (res->fi->fib_prefsrc)\n\t\t\t\tfl4->saddr = res->fi->fib_prefsrc;\n\t\t\telse\n\t\t\t\tfl4->saddr = fl4->daddr;\n\t\t}\n\n\t\t \n\t\tdev_out = l3mdev_master_dev_rcu(FIB_RES_DEV(*res)) ? :\n\t\t\tnet->loopback_dev;\n\n\t\t \n\t\torig_oif = FIB_RES_OIF(*res);\n\n\t\tfl4->flowi4_oif = dev_out->ifindex;\n\t\tflags |= RTCF_LOCAL;\n\t\tgoto make_route;\n\t}\n\n\tfib_select_path(net, res, fl4, skb);\n\n\tdev_out = FIB_RES_DEV(*res);\n\nmake_route:\n\trth = __mkroute_output(res, fl4, orig_oif, dev_out, flags);\n\nout:\n\treturn rth;\n}\n\nstatic struct dst_ops ipv4_dst_blackhole_ops = {\n\t.family\t\t\t= AF_INET,\n\t.default_advmss\t\t= ipv4_default_advmss,\n\t.neigh_lookup\t\t= ipv4_neigh_lookup,\n\t.check\t\t\t= dst_blackhole_check,\n\t.cow_metrics\t\t= dst_blackhole_cow_metrics,\n\t.update_pmtu\t\t= dst_blackhole_update_pmtu,\n\t.redirect\t\t= dst_blackhole_redirect,\n\t.mtu\t\t\t= dst_blackhole_mtu,\n};\n\nstruct dst_entry *ipv4_blackhole_route(struct net *net, struct dst_entry *dst_orig)\n{\n\tstruct rtable *ort = (struct rtable *) dst_orig;\n\tstruct rtable *rt;\n\n\trt = dst_alloc(&ipv4_dst_blackhole_ops, NULL, 1, DST_OBSOLETE_DEAD, 0);\n\tif (rt) {\n\t\tstruct dst_entry *new = &rt->dst;\n\n\t\tnew->__use = 1;\n\t\tnew->input = dst_discard;\n\t\tnew->output = dst_discard_out;\n\n\t\tnew->dev = net->loopback_dev;\n\t\tnetdev_hold(new->dev, &new->dev_tracker, GFP_ATOMIC);\n\n\t\trt->rt_is_input = ort->rt_is_input;\n\t\trt->rt_iif = ort->rt_iif;\n\t\trt->rt_pmtu = ort->rt_pmtu;\n\t\trt->rt_mtu_locked = ort->rt_mtu_locked;\n\n\t\trt->rt_genid = rt_genid_ipv4(net);\n\t\trt->rt_flags = ort->rt_flags;\n\t\trt->rt_type = ort->rt_type;\n\t\trt->rt_uses_gateway = ort->rt_uses_gateway;\n\t\trt->rt_gw_family = ort->rt_gw_family;\n\t\tif (rt->rt_gw_family == AF_INET)\n\t\t\trt->rt_gw4 = ort->rt_gw4;\n\t\telse if (rt->rt_gw_family == AF_INET6)\n\t\t\trt->rt_gw6 = ort->rt_gw6;\n\t}\n\n\tdst_release(dst_orig);\n\n\treturn rt ? &rt->dst : ERR_PTR(-ENOMEM);\n}\n\nstruct rtable *ip_route_output_flow(struct net *net, struct flowi4 *flp4,\n\t\t\t\t    const struct sock *sk)\n{\n\tstruct rtable *rt = __ip_route_output_key(net, flp4);\n\n\tif (IS_ERR(rt))\n\t\treturn rt;\n\n\tif (flp4->flowi4_proto) {\n\t\tflp4->flowi4_oif = rt->dst.dev->ifindex;\n\t\trt = (struct rtable *)xfrm_lookup_route(net, &rt->dst,\n\t\t\t\t\t\t\tflowi4_to_flowi(flp4),\n\t\t\t\t\t\t\tsk, 0);\n\t}\n\n\treturn rt;\n}\nEXPORT_SYMBOL_GPL(ip_route_output_flow);\n\nstruct rtable *ip_route_output_tunnel(struct sk_buff *skb,\n\t\t\t\t      struct net_device *dev,\n\t\t\t\t      struct net *net, __be32 *saddr,\n\t\t\t\t      const struct ip_tunnel_info *info,\n\t\t\t\t      u8 protocol, bool use_cache)\n{\n#ifdef CONFIG_DST_CACHE\n\tstruct dst_cache *dst_cache;\n#endif\n\tstruct rtable *rt = NULL;\n\tstruct flowi4 fl4;\n\t__u8 tos;\n\n#ifdef CONFIG_DST_CACHE\n\tdst_cache = (struct dst_cache *)&info->dst_cache;\n\tif (use_cache) {\n\t\trt = dst_cache_get_ip4(dst_cache, saddr);\n\t\tif (rt)\n\t\t\treturn rt;\n\t}\n#endif\n\tmemset(&fl4, 0, sizeof(fl4));\n\tfl4.flowi4_mark = skb->mark;\n\tfl4.flowi4_proto = protocol;\n\tfl4.daddr = info->key.u.ipv4.dst;\n\tfl4.saddr = info->key.u.ipv4.src;\n\ttos = info->key.tos;\n\tfl4.flowi4_tos = RT_TOS(tos);\n\n\trt = ip_route_output_key(net, &fl4);\n\tif (IS_ERR(rt)) {\n\t\tnetdev_dbg(dev, \"no route to %pI4\\n\", &fl4.daddr);\n\t\treturn ERR_PTR(-ENETUNREACH);\n\t}\n\tif (rt->dst.dev == dev) {  \n\t\tnetdev_dbg(dev, \"circular route to %pI4\\n\", &fl4.daddr);\n\t\tip_rt_put(rt);\n\t\treturn ERR_PTR(-ELOOP);\n\t}\n#ifdef CONFIG_DST_CACHE\n\tif (use_cache)\n\t\tdst_cache_set_ip4(dst_cache, &rt->dst, fl4.saddr);\n#endif\n\t*saddr = fl4.saddr;\n\treturn rt;\n}\nEXPORT_SYMBOL_GPL(ip_route_output_tunnel);\n\n \nstatic int rt_fill_info(struct net *net, __be32 dst, __be32 src,\n\t\t\tstruct rtable *rt, u32 table_id, struct flowi4 *fl4,\n\t\t\tstruct sk_buff *skb, u32 portid, u32 seq,\n\t\t\tunsigned int flags)\n{\n\tstruct rtmsg *r;\n\tstruct nlmsghdr *nlh;\n\tunsigned long expires = 0;\n\tu32 error;\n\tu32 metrics[RTAX_MAX];\n\n\tnlh = nlmsg_put(skb, portid, seq, RTM_NEWROUTE, sizeof(*r), flags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tr = nlmsg_data(nlh);\n\tr->rtm_family\t = AF_INET;\n\tr->rtm_dst_len\t= 32;\n\tr->rtm_src_len\t= 0;\n\tr->rtm_tos\t= fl4 ? fl4->flowi4_tos : 0;\n\tr->rtm_table\t= table_id < 256 ? table_id : RT_TABLE_COMPAT;\n\tif (nla_put_u32(skb, RTA_TABLE, table_id))\n\t\tgoto nla_put_failure;\n\tr->rtm_type\t= rt->rt_type;\n\tr->rtm_scope\t= RT_SCOPE_UNIVERSE;\n\tr->rtm_protocol = RTPROT_UNSPEC;\n\tr->rtm_flags\t= (rt->rt_flags & ~0xFFFF) | RTM_F_CLONED;\n\tif (rt->rt_flags & RTCF_NOTIFY)\n\t\tr->rtm_flags |= RTM_F_NOTIFY;\n\tif (IPCB(skb)->flags & IPSKB_DOREDIRECT)\n\t\tr->rtm_flags |= RTCF_DOREDIRECT;\n\n\tif (nla_put_in_addr(skb, RTA_DST, dst))\n\t\tgoto nla_put_failure;\n\tif (src) {\n\t\tr->rtm_src_len = 32;\n\t\tif (nla_put_in_addr(skb, RTA_SRC, src))\n\t\t\tgoto nla_put_failure;\n\t}\n\tif (rt->dst.dev &&\n\t    nla_put_u32(skb, RTA_OIF, rt->dst.dev->ifindex))\n\t\tgoto nla_put_failure;\n\tif (rt->dst.lwtstate &&\n\t    lwtunnel_fill_encap(skb, rt->dst.lwtstate, RTA_ENCAP, RTA_ENCAP_TYPE) < 0)\n\t\tgoto nla_put_failure;\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\tif (rt->dst.tclassid &&\n\t    nla_put_u32(skb, RTA_FLOW, rt->dst.tclassid))\n\t\tgoto nla_put_failure;\n#endif\n\tif (fl4 && !rt_is_input_route(rt) &&\n\t    fl4->saddr != src) {\n\t\tif (nla_put_in_addr(skb, RTA_PREFSRC, fl4->saddr))\n\t\t\tgoto nla_put_failure;\n\t}\n\tif (rt->rt_uses_gateway) {\n\t\tif (rt->rt_gw_family == AF_INET &&\n\t\t    nla_put_in_addr(skb, RTA_GATEWAY, rt->rt_gw4)) {\n\t\t\tgoto nla_put_failure;\n\t\t} else if (rt->rt_gw_family == AF_INET6) {\n\t\t\tint alen = sizeof(struct in6_addr);\n\t\t\tstruct nlattr *nla;\n\t\t\tstruct rtvia *via;\n\n\t\t\tnla = nla_reserve(skb, RTA_VIA, alen + 2);\n\t\t\tif (!nla)\n\t\t\t\tgoto nla_put_failure;\n\n\t\t\tvia = nla_data(nla);\n\t\t\tvia->rtvia_family = AF_INET6;\n\t\t\tmemcpy(via->rtvia_addr, &rt->rt_gw6, alen);\n\t\t}\n\t}\n\n\texpires = rt->dst.expires;\n\tif (expires) {\n\t\tunsigned long now = jiffies;\n\n\t\tif (time_before(now, expires))\n\t\t\texpires -= now;\n\t\telse\n\t\t\texpires = 0;\n\t}\n\n\tmemcpy(metrics, dst_metrics_ptr(&rt->dst), sizeof(metrics));\n\tif (rt->rt_pmtu && expires)\n\t\tmetrics[RTAX_MTU - 1] = rt->rt_pmtu;\n\tif (rt->rt_mtu_locked && expires)\n\t\tmetrics[RTAX_LOCK - 1] |= BIT(RTAX_MTU);\n\tif (rtnetlink_put_metrics(skb, metrics) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (fl4) {\n\t\tif (fl4->flowi4_mark &&\n\t\t    nla_put_u32(skb, RTA_MARK, fl4->flowi4_mark))\n\t\t\tgoto nla_put_failure;\n\n\t\tif (!uid_eq(fl4->flowi4_uid, INVALID_UID) &&\n\t\t    nla_put_u32(skb, RTA_UID,\n\t\t\t\tfrom_kuid_munged(current_user_ns(),\n\t\t\t\t\t\t fl4->flowi4_uid)))\n\t\t\tgoto nla_put_failure;\n\n\t\tif (rt_is_input_route(rt)) {\n#ifdef CONFIG_IP_MROUTE\n\t\t\tif (ipv4_is_multicast(dst) &&\n\t\t\t    !ipv4_is_local_multicast(dst) &&\n\t\t\t    IPV4_DEVCONF_ALL(net, MC_FORWARDING)) {\n\t\t\t\tint err = ipmr_get_route(net, skb,\n\t\t\t\t\t\t\t fl4->saddr, fl4->daddr,\n\t\t\t\t\t\t\t r, portid);\n\n\t\t\t\tif (err <= 0) {\n\t\t\t\t\tif (err == 0)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\t}\n\t\t\t} else\n#endif\n\t\t\t\tif (nla_put_u32(skb, RTA_IIF, fl4->flowi4_iif))\n\t\t\t\t\tgoto nla_put_failure;\n\t\t}\n\t}\n\n\terror = rt->dst.error;\n\n\tif (rtnl_put_cacheinfo(skb, &rt->dst, 0, expires, error) < 0)\n\t\tgoto nla_put_failure;\n\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}\n\nstatic int fnhe_dump_bucket(struct net *net, struct sk_buff *skb,\n\t\t\t    struct netlink_callback *cb, u32 table_id,\n\t\t\t    struct fnhe_hash_bucket *bucket, int genid,\n\t\t\t    int *fa_index, int fa_start, unsigned int flags)\n{\n\tint i;\n\n\tfor (i = 0; i < FNHE_HASH_SIZE; i++) {\n\t\tstruct fib_nh_exception *fnhe;\n\n\t\tfor (fnhe = rcu_dereference(bucket[i].chain); fnhe;\n\t\t     fnhe = rcu_dereference(fnhe->fnhe_next)) {\n\t\t\tstruct rtable *rt;\n\t\t\tint err;\n\n\t\t\tif (*fa_index < fa_start)\n\t\t\t\tgoto next;\n\n\t\t\tif (fnhe->fnhe_genid != genid)\n\t\t\t\tgoto next;\n\n\t\t\tif (fnhe->fnhe_expires &&\n\t\t\t    time_after(jiffies, fnhe->fnhe_expires))\n\t\t\t\tgoto next;\n\n\t\t\trt = rcu_dereference(fnhe->fnhe_rth_input);\n\t\t\tif (!rt)\n\t\t\t\trt = rcu_dereference(fnhe->fnhe_rth_output);\n\t\t\tif (!rt)\n\t\t\t\tgoto next;\n\n\t\t\terr = rt_fill_info(net, fnhe->fnhe_daddr, 0, rt,\n\t\t\t\t\t   table_id, NULL, skb,\n\t\t\t\t\t   NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t   cb->nlh->nlmsg_seq, flags);\n\t\t\tif (err)\n\t\t\t\treturn err;\nnext:\n\t\t\t(*fa_index)++;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint fib_dump_info_fnhe(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t       u32 table_id, struct fib_info *fi,\n\t\t       int *fa_index, int fa_start, unsigned int flags)\n{\n\tstruct net *net = sock_net(cb->skb->sk);\n\tint nhsel, genid = fnhe_genid(net);\n\n\tfor (nhsel = 0; nhsel < fib_info_num_path(fi); nhsel++) {\n\t\tstruct fib_nh_common *nhc = fib_info_nhc(fi, nhsel);\n\t\tstruct fnhe_hash_bucket *bucket;\n\t\tint err;\n\n\t\tif (nhc->nhc_flags & RTNH_F_DEAD)\n\t\t\tcontinue;\n\n\t\trcu_read_lock();\n\t\tbucket = rcu_dereference(nhc->nhc_exceptions);\n\t\terr = 0;\n\t\tif (bucket)\n\t\t\terr = fnhe_dump_bucket(net, skb, cb, table_id, bucket,\n\t\t\t\t\t       genid, fa_index, fa_start,\n\t\t\t\t\t       flags);\n\t\trcu_read_unlock();\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic struct sk_buff *inet_rtm_getroute_build_skb(__be32 src, __be32 dst,\n\t\t\t\t\t\t   u8 ip_proto, __be16 sport,\n\t\t\t\t\t\t   __be16 dport)\n{\n\tstruct sk_buff *skb;\n\tstruct iphdr *iph;\n\n\tskb = alloc_skb(NLMSG_GOODSIZE, GFP_KERNEL);\n\tif (!skb)\n\t\treturn NULL;\n\n\t \n\tskb_reset_mac_header(skb);\n\tskb_reset_network_header(skb);\n\tskb->protocol = htons(ETH_P_IP);\n\tiph = skb_put(skb, sizeof(struct iphdr));\n\tiph->protocol = ip_proto;\n\tiph->saddr = src;\n\tiph->daddr = dst;\n\tiph->version = 0x4;\n\tiph->frag_off = 0;\n\tiph->ihl = 0x5;\n\tskb_set_transport_header(skb, skb->len);\n\n\tswitch (iph->protocol) {\n\tcase IPPROTO_UDP: {\n\t\tstruct udphdr *udph;\n\n\t\tudph = skb_put_zero(skb, sizeof(struct udphdr));\n\t\tudph->source = sport;\n\t\tudph->dest = dport;\n\t\tudph->len = htons(sizeof(struct udphdr));\n\t\tudph->check = 0;\n\t\tbreak;\n\t}\n\tcase IPPROTO_TCP: {\n\t\tstruct tcphdr *tcph;\n\n\t\ttcph = skb_put_zero(skb, sizeof(struct tcphdr));\n\t\ttcph->source\t= sport;\n\t\ttcph->dest\t= dport;\n\t\ttcph->doff\t= sizeof(struct tcphdr) / 4;\n\t\ttcph->rst = 1;\n\t\ttcph->check = ~tcp_v4_check(sizeof(struct tcphdr),\n\t\t\t\t\t    src, dst, 0);\n\t\tbreak;\n\t}\n\tcase IPPROTO_ICMP: {\n\t\tstruct icmphdr *icmph;\n\n\t\ticmph = skb_put_zero(skb, sizeof(struct icmphdr));\n\t\ticmph->type = ICMP_ECHO;\n\t\ticmph->code = 0;\n\t}\n\t}\n\n\treturn skb;\n}\n\nstatic int inet_rtm_valid_getroute_req(struct sk_buff *skb,\n\t\t\t\t       const struct nlmsghdr *nlh,\n\t\t\t\t       struct nlattr **tb,\n\t\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct rtmsg *rtm;\n\tint i, err;\n\n\tif (nlh->nlmsg_len < nlmsg_msg_size(sizeof(*rtm))) {\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"ipv4: Invalid header for route get request\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!netlink_strict_get_check(skb))\n\t\treturn nlmsg_parse_deprecated(nlh, sizeof(*rtm), tb, RTA_MAX,\n\t\t\t\t\t      rtm_ipv4_policy, extack);\n\n\trtm = nlmsg_data(nlh);\n\tif ((rtm->rtm_src_len && rtm->rtm_src_len != 32) ||\n\t    (rtm->rtm_dst_len && rtm->rtm_dst_len != 32) ||\n\t    rtm->rtm_table || rtm->rtm_protocol ||\n\t    rtm->rtm_scope || rtm->rtm_type) {\n\t\tNL_SET_ERR_MSG(extack, \"ipv4: Invalid values in header for route get request\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (rtm->rtm_flags & ~(RTM_F_NOTIFY |\n\t\t\t       RTM_F_LOOKUP_TABLE |\n\t\t\t       RTM_F_FIB_MATCH)) {\n\t\tNL_SET_ERR_MSG(extack, \"ipv4: Unsupported rtm_flags for route get request\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = nlmsg_parse_deprecated_strict(nlh, sizeof(*rtm), tb, RTA_MAX,\n\t\t\t\t\t    rtm_ipv4_policy, extack);\n\tif (err)\n\t\treturn err;\n\n\tif ((tb[RTA_SRC] && !rtm->rtm_src_len) ||\n\t    (tb[RTA_DST] && !rtm->rtm_dst_len)) {\n\t\tNL_SET_ERR_MSG(extack, \"ipv4: rtm_src_len and rtm_dst_len must be 32 for IPv4\");\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i <= RTA_MAX; i++) {\n\t\tif (!tb[i])\n\t\t\tcontinue;\n\n\t\tswitch (i) {\n\t\tcase RTA_IIF:\n\t\tcase RTA_OIF:\n\t\tcase RTA_SRC:\n\t\tcase RTA_DST:\n\t\tcase RTA_IP_PROTO:\n\t\tcase RTA_SPORT:\n\t\tcase RTA_DPORT:\n\t\tcase RTA_MARK:\n\t\tcase RTA_UID:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tNL_SET_ERR_MSG(extack, \"ipv4: Unsupported attribute in route get request\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int inet_rtm_getroute(struct sk_buff *in_skb, struct nlmsghdr *nlh,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(in_skb->sk);\n\tstruct nlattr *tb[RTA_MAX+1];\n\tu32 table_id = RT_TABLE_MAIN;\n\t__be16 sport = 0, dport = 0;\n\tstruct fib_result res = {};\n\tu8 ip_proto = IPPROTO_UDP;\n\tstruct rtable *rt = NULL;\n\tstruct sk_buff *skb;\n\tstruct rtmsg *rtm;\n\tstruct flowi4 fl4 = {};\n\t__be32 dst = 0;\n\t__be32 src = 0;\n\tkuid_t uid;\n\tu32 iif;\n\tint err;\n\tint mark;\n\n\terr = inet_rtm_valid_getroute_req(in_skb, nlh, tb, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\trtm = nlmsg_data(nlh);\n\tsrc = tb[RTA_SRC] ? nla_get_in_addr(tb[RTA_SRC]) : 0;\n\tdst = tb[RTA_DST] ? nla_get_in_addr(tb[RTA_DST]) : 0;\n\tiif = tb[RTA_IIF] ? nla_get_u32(tb[RTA_IIF]) : 0;\n\tmark = tb[RTA_MARK] ? nla_get_u32(tb[RTA_MARK]) : 0;\n\tif (tb[RTA_UID])\n\t\tuid = make_kuid(current_user_ns(), nla_get_u32(tb[RTA_UID]));\n\telse\n\t\tuid = (iif ? INVALID_UID : current_uid());\n\n\tif (tb[RTA_IP_PROTO]) {\n\t\terr = rtm_getroute_parse_ip_proto(tb[RTA_IP_PROTO],\n\t\t\t\t\t\t  &ip_proto, AF_INET, extack);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (tb[RTA_SPORT])\n\t\tsport = nla_get_be16(tb[RTA_SPORT]);\n\n\tif (tb[RTA_DPORT])\n\t\tdport = nla_get_be16(tb[RTA_DPORT]);\n\n\tskb = inet_rtm_getroute_build_skb(src, dst, ip_proto, sport, dport);\n\tif (!skb)\n\t\treturn -ENOBUFS;\n\n\tfl4.daddr = dst;\n\tfl4.saddr = src;\n\tfl4.flowi4_tos = rtm->rtm_tos & IPTOS_RT_MASK;\n\tfl4.flowi4_oif = tb[RTA_OIF] ? nla_get_u32(tb[RTA_OIF]) : 0;\n\tfl4.flowi4_mark = mark;\n\tfl4.flowi4_uid = uid;\n\tif (sport)\n\t\tfl4.fl4_sport = sport;\n\tif (dport)\n\t\tfl4.fl4_dport = dport;\n\tfl4.flowi4_proto = ip_proto;\n\n\trcu_read_lock();\n\n\tif (iif) {\n\t\tstruct net_device *dev;\n\n\t\tdev = dev_get_by_index_rcu(net, iif);\n\t\tif (!dev) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto errout_rcu;\n\t\t}\n\n\t\tfl4.flowi4_iif = iif;  \n\t\tskb->dev\t= dev;\n\t\tskb->mark\t= mark;\n\t\terr = ip_route_input_rcu(skb, dst, src,\n\t\t\t\t\t rtm->rtm_tos & IPTOS_RT_MASK, dev,\n\t\t\t\t\t &res);\n\n\t\trt = skb_rtable(skb);\n\t\tif (err == 0 && rt->dst.error)\n\t\t\terr = -rt->dst.error;\n\t} else {\n\t\tfl4.flowi4_iif = LOOPBACK_IFINDEX;\n\t\tskb->dev = net->loopback_dev;\n\t\trt = ip_route_output_key_hash_rcu(net, &fl4, &res, skb);\n\t\terr = 0;\n\t\tif (IS_ERR(rt))\n\t\t\terr = PTR_ERR(rt);\n\t\telse\n\t\t\tskb_dst_set(skb, &rt->dst);\n\t}\n\n\tif (err)\n\t\tgoto errout_rcu;\n\n\tif (rtm->rtm_flags & RTM_F_NOTIFY)\n\t\trt->rt_flags |= RTCF_NOTIFY;\n\n\tif (rtm->rtm_flags & RTM_F_LOOKUP_TABLE)\n\t\ttable_id = res.table ? res.table->tb_id : 0;\n\n\t \n\tskb_trim(skb, 0);\n\tskb_reset_network_header(skb);\n\tskb_reset_transport_header(skb);\n\tskb_reset_mac_header(skb);\n\n\tif (rtm->rtm_flags & RTM_F_FIB_MATCH) {\n\t\tstruct fib_rt_info fri;\n\n\t\tif (!res.fi) {\n\t\t\terr = fib_props[res.type].error;\n\t\t\tif (!err)\n\t\t\t\terr = -EHOSTUNREACH;\n\t\t\tgoto errout_rcu;\n\t\t}\n\t\tfri.fi = res.fi;\n\t\tfri.tb_id = table_id;\n\t\tfri.dst = res.prefix;\n\t\tfri.dst_len = res.prefixlen;\n\t\tfri.dscp = inet_dsfield_to_dscp(fl4.flowi4_tos);\n\t\tfri.type = rt->rt_type;\n\t\tfri.offload = 0;\n\t\tfri.trap = 0;\n\t\tfri.offload_failed = 0;\n\t\tif (res.fa_head) {\n\t\t\tstruct fib_alias *fa;\n\n\t\t\thlist_for_each_entry_rcu(fa, res.fa_head, fa_list) {\n\t\t\t\tu8 slen = 32 - fri.dst_len;\n\n\t\t\t\tif (fa->fa_slen == slen &&\n\t\t\t\t    fa->tb_id == fri.tb_id &&\n\t\t\t\t    fa->fa_dscp == fri.dscp &&\n\t\t\t\t    fa->fa_info == res.fi &&\n\t\t\t\t    fa->fa_type == fri.type) {\n\t\t\t\t\tfri.offload = READ_ONCE(fa->offload);\n\t\t\t\t\tfri.trap = READ_ONCE(fa->trap);\n\t\t\t\t\tfri.offload_failed =\n\t\t\t\t\t\tREAD_ONCE(fa->offload_failed);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\terr = fib_dump_info(skb, NETLINK_CB(in_skb).portid,\n\t\t\t\t    nlh->nlmsg_seq, RTM_NEWROUTE, &fri, 0);\n\t} else {\n\t\terr = rt_fill_info(net, dst, src, rt, table_id, &fl4, skb,\n\t\t\t\t   NETLINK_CB(in_skb).portid,\n\t\t\t\t   nlh->nlmsg_seq, 0);\n\t}\n\tif (err < 0)\n\t\tgoto errout_rcu;\n\n\trcu_read_unlock();\n\n\terr = rtnl_unicast(skb, net, NETLINK_CB(in_skb).portid);\n\nerrout_free:\n\treturn err;\nerrout_rcu:\n\trcu_read_unlock();\n\tkfree_skb(skb);\n\tgoto errout_free;\n}\n\nvoid ip_rt_multicast_event(struct in_device *in_dev)\n{\n\trt_cache_flush(dev_net(in_dev->dev));\n}\n\n#ifdef CONFIG_SYSCTL\nstatic int ip_rt_gc_interval __read_mostly  = 60 * HZ;\nstatic int ip_rt_gc_min_interval __read_mostly\t= HZ / 2;\nstatic int ip_rt_gc_elasticity __read_mostly\t= 8;\nstatic int ip_min_valid_pmtu __read_mostly\t= IPV4_MIN_MTU;\n\nstatic int ipv4_sysctl_rtcache_flush(struct ctl_table *__ctl, int write,\n\t\tvoid *buffer, size_t *lenp, loff_t *ppos)\n{\n\tstruct net *net = (struct net *)__ctl->extra1;\n\n\tif (write) {\n\t\trt_cache_flush(net);\n\t\tfnhe_genid_bump(net);\n\t\treturn 0;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic struct ctl_table ipv4_route_table[] = {\n\t{\n\t\t.procname\t= \"gc_thresh\",\n\t\t.data\t\t= &ipv4_dst_ops.gc_thresh,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"max_size\",\n\t\t.data\t\t= &ip_rt_max_size,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t \n\n\t\t.procname\t= \"gc_min_interval\",\n\t\t.data\t\t= &ip_rt_gc_min_interval,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"gc_min_interval_ms\",\n\t\t.data\t\t= &ip_rt_gc_min_interval,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_ms_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"gc_timeout\",\n\t\t.data\t\t= &ip_rt_gc_timeout,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"gc_interval\",\n\t\t.data\t\t= &ip_rt_gc_interval,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"redirect_load\",\n\t\t.data\t\t= &ip_rt_redirect_load,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"redirect_number\",\n\t\t.data\t\t= &ip_rt_redirect_number,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"redirect_silence\",\n\t\t.data\t\t= &ip_rt_redirect_silence,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"error_cost\",\n\t\t.data\t\t= &ip_rt_error_cost,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"error_burst\",\n\t\t.data\t\t= &ip_rt_error_burst,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{\n\t\t.procname\t= \"gc_elasticity\",\n\t\t.data\t\t= &ip_rt_gc_elasticity,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n\t{ }\n};\n\nstatic const char ipv4_route_flush_procname[] = \"flush\";\n\nstatic struct ctl_table ipv4_route_netns_table[] = {\n\t{\n\t\t.procname\t= ipv4_route_flush_procname,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0200,\n\t\t.proc_handler\t= ipv4_sysctl_rtcache_flush,\n\t},\n\t{\n\t\t.procname       = \"min_pmtu\",\n\t\t.data           = &init_net.ipv4.ip_rt_min_pmtu,\n\t\t.maxlen         = sizeof(int),\n\t\t.mode           = 0644,\n\t\t.proc_handler   = proc_dointvec_minmax,\n\t\t.extra1         = &ip_min_valid_pmtu,\n\t},\n\t{\n\t\t.procname       = \"mtu_expires\",\n\t\t.data           = &init_net.ipv4.ip_rt_mtu_expires,\n\t\t.maxlen         = sizeof(int),\n\t\t.mode           = 0644,\n\t\t.proc_handler   = proc_dointvec_jiffies,\n\t},\n\t{\n\t\t.procname   = \"min_adv_mss\",\n\t\t.data       = &init_net.ipv4.ip_rt_min_advmss,\n\t\t.maxlen     = sizeof(int),\n\t\t.mode       = 0644,\n\t\t.proc_handler   = proc_dointvec,\n\t},\n\t{ },\n};\n\nstatic __net_init int sysctl_route_net_init(struct net *net)\n{\n\tstruct ctl_table *tbl;\n\tsize_t table_size = ARRAY_SIZE(ipv4_route_netns_table);\n\n\ttbl = ipv4_route_netns_table;\n\tif (!net_eq(net, &init_net)) {\n\t\tint i;\n\n\t\ttbl = kmemdup(tbl, sizeof(ipv4_route_netns_table), GFP_KERNEL);\n\t\tif (!tbl)\n\t\t\tgoto err_dup;\n\n\t\t \n\t\tif (net->user_ns != &init_user_ns) {\n\t\t\tif (tbl[0].procname != ipv4_route_flush_procname) {\n\t\t\t\ttbl[0].procname = NULL;\n\t\t\t\ttable_size = 0;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tfor (i = 1; i < ARRAY_SIZE(ipv4_route_netns_table) - 1; i++)\n\t\t\ttbl[i].data += (void *)net - (void *)&init_net;\n\t}\n\ttbl[0].extra1 = net;\n\n\tnet->ipv4.route_hdr = register_net_sysctl_sz(net, \"net/ipv4/route\",\n\t\t\t\t\t\t     tbl, table_size);\n\tif (!net->ipv4.route_hdr)\n\t\tgoto err_reg;\n\treturn 0;\n\nerr_reg:\n\tif (tbl != ipv4_route_netns_table)\n\t\tkfree(tbl);\nerr_dup:\n\treturn -ENOMEM;\n}\n\nstatic __net_exit void sysctl_route_net_exit(struct net *net)\n{\n\tstruct ctl_table *tbl;\n\n\ttbl = net->ipv4.route_hdr->ctl_table_arg;\n\tunregister_net_sysctl_table(net->ipv4.route_hdr);\n\tBUG_ON(tbl == ipv4_route_netns_table);\n\tkfree(tbl);\n}\n\nstatic __net_initdata struct pernet_operations sysctl_route_ops = {\n\t.init = sysctl_route_net_init,\n\t.exit = sysctl_route_net_exit,\n};\n#endif\n\nstatic __net_init int netns_ip_rt_init(struct net *net)\n{\n\t \n\tnet->ipv4.ip_rt_min_pmtu = DEFAULT_MIN_PMTU;\n\tnet->ipv4.ip_rt_mtu_expires = DEFAULT_MTU_EXPIRES;\n\tnet->ipv4.ip_rt_min_advmss = DEFAULT_MIN_ADVMSS;\n\treturn 0;\n}\n\nstatic struct pernet_operations __net_initdata ip_rt_ops = {\n\t.init = netns_ip_rt_init,\n};\n\nstatic __net_init int rt_genid_init(struct net *net)\n{\n\tatomic_set(&net->ipv4.rt_genid, 0);\n\tatomic_set(&net->fnhe_genid, 0);\n\tatomic_set(&net->ipv4.dev_addr_genid, get_random_u32());\n\treturn 0;\n}\n\nstatic __net_initdata struct pernet_operations rt_genid_ops = {\n\t.init = rt_genid_init,\n};\n\nstatic int __net_init ipv4_inetpeer_init(struct net *net)\n{\n\tstruct inet_peer_base *bp = kmalloc(sizeof(*bp), GFP_KERNEL);\n\n\tif (!bp)\n\t\treturn -ENOMEM;\n\tinet_peer_base_init(bp);\n\tnet->ipv4.peers = bp;\n\treturn 0;\n}\n\nstatic void __net_exit ipv4_inetpeer_exit(struct net *net)\n{\n\tstruct inet_peer_base *bp = net->ipv4.peers;\n\n\tnet->ipv4.peers = NULL;\n\tinetpeer_invalidate_tree(bp);\n\tkfree(bp);\n}\n\nstatic __net_initdata struct pernet_operations ipv4_inetpeer_ops = {\n\t.init\t=\tipv4_inetpeer_init,\n\t.exit\t=\tipv4_inetpeer_exit,\n};\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\nstruct ip_rt_acct __percpu *ip_rt_acct __read_mostly;\n#endif  \n\nint __init ip_rt_init(void)\n{\n\tvoid *idents_hash;\n\tint cpu;\n\n\t \n\tidents_hash = alloc_large_system_hash(\"IP idents\",\n\t\t\t\t\t      sizeof(*ip_idents) + sizeof(*ip_tstamps),\n\t\t\t\t\t      0,\n\t\t\t\t\t      16,  \n\t\t\t\t\t      HASH_ZERO,\n\t\t\t\t\t      NULL,\n\t\t\t\t\t      &ip_idents_mask,\n\t\t\t\t\t      2048,\n\t\t\t\t\t      256*1024);\n\n\tip_idents = idents_hash;\n\n\tget_random_bytes(ip_idents, (ip_idents_mask + 1) * sizeof(*ip_idents));\n\n\tip_tstamps = idents_hash + (ip_idents_mask + 1) * sizeof(*ip_idents);\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct uncached_list *ul = &per_cpu(rt_uncached_list, cpu);\n\n\t\tINIT_LIST_HEAD(&ul->head);\n\t\tINIT_LIST_HEAD(&ul->quarantine);\n\t\tspin_lock_init(&ul->lock);\n\t}\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\tip_rt_acct = __alloc_percpu(256 * sizeof(struct ip_rt_acct), __alignof__(struct ip_rt_acct));\n\tif (!ip_rt_acct)\n\t\tpanic(\"IP: failed to allocate ip_rt_acct\\n\");\n#endif\n\n\tipv4_dst_ops.kmem_cachep =\n\t\tkmem_cache_create(\"ip_dst_cache\", sizeof(struct rtable), 0,\n\t\t\t\t  SLAB_HWCACHE_ALIGN|SLAB_PANIC, NULL);\n\n\tipv4_dst_blackhole_ops.kmem_cachep = ipv4_dst_ops.kmem_cachep;\n\n\tif (dst_entries_init(&ipv4_dst_ops) < 0)\n\t\tpanic(\"IP: failed to allocate ipv4_dst_ops counter\\n\");\n\n\tif (dst_entries_init(&ipv4_dst_blackhole_ops) < 0)\n\t\tpanic(\"IP: failed to allocate ipv4_dst_blackhole_ops counter\\n\");\n\n\tipv4_dst_ops.gc_thresh = ~0;\n\tip_rt_max_size = INT_MAX;\n\n\tdevinet_init();\n\tip_fib_init();\n\n\tif (ip_rt_proc_init())\n\t\tpr_err(\"Unable to create route proc files\\n\");\n#ifdef CONFIG_XFRM\n\txfrm_init();\n\txfrm4_init();\n#endif\n\trtnl_register(PF_INET, RTM_GETROUTE, inet_rtm_getroute, NULL,\n\t\t      RTNL_FLAG_DOIT_UNLOCKED);\n\n#ifdef CONFIG_SYSCTL\n\tregister_pernet_subsys(&sysctl_route_ops);\n#endif\n\tregister_pernet_subsys(&ip_rt_ops);\n\tregister_pernet_subsys(&rt_genid_ops);\n\tregister_pernet_subsys(&ipv4_inetpeer_ops);\n\treturn 0;\n}\n\n#ifdef CONFIG_SYSCTL\n \nvoid __init ip_static_sysctl_init(void)\n{\n\tregister_net_sysctl(&init_net, \"net/ipv4/route\", ipv4_route_table);\n}\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}