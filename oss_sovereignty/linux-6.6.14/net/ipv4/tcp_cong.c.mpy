{
  "module_name": "tcp_cong.c",
  "hash_id": "551d98a40ac5cb1c773ad765e80371efd9ddfcdc445cb7d711911ec4bb71765e",
  "original_prompt": "Ingested from linux-6.6.14/net/ipv4/tcp_cong.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"TCP: \" fmt\n\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/types.h>\n#include <linux/list.h>\n#include <linux/gfp.h>\n#include <linux/jhash.h>\n#include <net/tcp.h>\n#include <trace/events/tcp.h>\n\nstatic DEFINE_SPINLOCK(tcp_cong_list_lock);\nstatic LIST_HEAD(tcp_cong_list);\n\n \nstruct tcp_congestion_ops *tcp_ca_find(const char *name)\n{\n\tstruct tcp_congestion_ops *e;\n\n\tlist_for_each_entry_rcu(e, &tcp_cong_list, list) {\n\t\tif (strcmp(e->name, name) == 0)\n\t\t\treturn e;\n\t}\n\n\treturn NULL;\n}\n\nvoid tcp_set_ca_state(struct sock *sk, const u8 ca_state)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\n\ttrace_tcp_cong_state_set(sk, ca_state);\n\n\tif (icsk->icsk_ca_ops->set_state)\n\t\ticsk->icsk_ca_ops->set_state(sk, ca_state);\n\ticsk->icsk_ca_state = ca_state;\n}\n\n \nstatic struct tcp_congestion_ops *tcp_ca_find_autoload(struct net *net,\n\t\t\t\t\t\t       const char *name)\n{\n\tstruct tcp_congestion_ops *ca = tcp_ca_find(name);\n\n#ifdef CONFIG_MODULES\n\tif (!ca && capable(CAP_NET_ADMIN)) {\n\t\trcu_read_unlock();\n\t\trequest_module(\"tcp_%s\", name);\n\t\trcu_read_lock();\n\t\tca = tcp_ca_find(name);\n\t}\n#endif\n\treturn ca;\n}\n\n \nstruct tcp_congestion_ops *tcp_ca_find_key(u32 key)\n{\n\tstruct tcp_congestion_ops *e;\n\n\tlist_for_each_entry_rcu(e, &tcp_cong_list, list) {\n\t\tif (e->key == key)\n\t\t\treturn e;\n\t}\n\n\treturn NULL;\n}\n\nint tcp_validate_congestion_control(struct tcp_congestion_ops *ca)\n{\n\t \n\tif (!ca->ssthresh || !ca->undo_cwnd ||\n\t    !(ca->cong_avoid || ca->cong_control)) {\n\t\tpr_err(\"%s does not implement required ops\\n\", ca->name);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nint tcp_register_congestion_control(struct tcp_congestion_ops *ca)\n{\n\tint ret;\n\n\tret = tcp_validate_congestion_control(ca);\n\tif (ret)\n\t\treturn ret;\n\n\tca->key = jhash(ca->name, sizeof(ca->name), strlen(ca->name));\n\n\tspin_lock(&tcp_cong_list_lock);\n\tif (ca->key == TCP_CA_UNSPEC || tcp_ca_find_key(ca->key)) {\n\t\tpr_notice(\"%s already registered or non-unique key\\n\",\n\t\t\t  ca->name);\n\t\tret = -EEXIST;\n\t} else {\n\t\tlist_add_tail_rcu(&ca->list, &tcp_cong_list);\n\t\tpr_debug(\"%s registered\\n\", ca->name);\n\t}\n\tspin_unlock(&tcp_cong_list_lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(tcp_register_congestion_control);\n\n \nvoid tcp_unregister_congestion_control(struct tcp_congestion_ops *ca)\n{\n\tspin_lock(&tcp_cong_list_lock);\n\tlist_del_rcu(&ca->list);\n\tspin_unlock(&tcp_cong_list_lock);\n\n\t \n\tsynchronize_rcu();\n}\nEXPORT_SYMBOL_GPL(tcp_unregister_congestion_control);\n\n \nint tcp_update_congestion_control(struct tcp_congestion_ops *ca, struct tcp_congestion_ops *old_ca)\n{\n\tstruct tcp_congestion_ops *existing;\n\tint ret;\n\n\tret = tcp_validate_congestion_control(ca);\n\tif (ret)\n\t\treturn ret;\n\n\tca->key = jhash(ca->name, sizeof(ca->name), strlen(ca->name));\n\n\tspin_lock(&tcp_cong_list_lock);\n\texisting = tcp_ca_find_key(old_ca->key);\n\tif (ca->key == TCP_CA_UNSPEC || !existing || strcmp(existing->name, ca->name)) {\n\t\tpr_notice(\"%s not registered or non-unique key\\n\",\n\t\t\t  ca->name);\n\t\tret = -EINVAL;\n\t} else if (existing != old_ca) {\n\t\tpr_notice(\"invalid old congestion control algorithm to replace\\n\");\n\t\tret = -EINVAL;\n\t} else {\n\t\t \n\t\tlist_add_tail_rcu(&ca->list, &tcp_cong_list);\n\t\tlist_del_rcu(&existing->list);\n\t\tpr_debug(\"%s updated\\n\", ca->name);\n\t}\n\tspin_unlock(&tcp_cong_list_lock);\n\n\t \n\tif (!ret)\n\t\tsynchronize_rcu();\n\n\treturn ret;\n}\n\nu32 tcp_ca_get_key_by_name(struct net *net, const char *name, bool *ecn_ca)\n{\n\tconst struct tcp_congestion_ops *ca;\n\tu32 key = TCP_CA_UNSPEC;\n\n\tmight_sleep();\n\n\trcu_read_lock();\n\tca = tcp_ca_find_autoload(net, name);\n\tif (ca) {\n\t\tkey = ca->key;\n\t\t*ecn_ca = ca->flags & TCP_CONG_NEEDS_ECN;\n\t}\n\trcu_read_unlock();\n\n\treturn key;\n}\n\nchar *tcp_ca_get_name_by_key(u32 key, char *buffer)\n{\n\tconst struct tcp_congestion_ops *ca;\n\tchar *ret = NULL;\n\n\trcu_read_lock();\n\tca = tcp_ca_find_key(key);\n\tif (ca)\n\t\tret = strncpy(buffer, ca->name,\n\t\t\t      TCP_CA_NAME_MAX);\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\n \nvoid tcp_assign_congestion_control(struct sock *sk)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tconst struct tcp_congestion_ops *ca;\n\n\trcu_read_lock();\n\tca = rcu_dereference(net->ipv4.tcp_congestion_control);\n\tif (unlikely(!bpf_try_module_get(ca, ca->owner)))\n\t\tca = &tcp_reno;\n\ticsk->icsk_ca_ops = ca;\n\trcu_read_unlock();\n\n\tmemset(icsk->icsk_ca_priv, 0, sizeof(icsk->icsk_ca_priv));\n\tif (ca->flags & TCP_CONG_NEEDS_ECN)\n\t\tINET_ECN_xmit(sk);\n\telse\n\t\tINET_ECN_dontxmit(sk);\n}\n\nvoid tcp_init_congestion_control(struct sock *sk)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\n\ttcp_sk(sk)->prior_ssthresh = 0;\n\tif (icsk->icsk_ca_ops->init)\n\t\ticsk->icsk_ca_ops->init(sk);\n\tif (tcp_ca_needs_ecn(sk))\n\t\tINET_ECN_xmit(sk);\n\telse\n\t\tINET_ECN_dontxmit(sk);\n\ticsk->icsk_ca_initialized = 1;\n}\n\nstatic void tcp_reinit_congestion_control(struct sock *sk,\n\t\t\t\t\t  const struct tcp_congestion_ops *ca)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\n\ttcp_cleanup_congestion_control(sk);\n\ticsk->icsk_ca_ops = ca;\n\ticsk->icsk_ca_setsockopt = 1;\n\tmemset(icsk->icsk_ca_priv, 0, sizeof(icsk->icsk_ca_priv));\n\n\tif (ca->flags & TCP_CONG_NEEDS_ECN)\n\t\tINET_ECN_xmit(sk);\n\telse\n\t\tINET_ECN_dontxmit(sk);\n\n\tif (!((1 << sk->sk_state) & (TCPF_CLOSE | TCPF_LISTEN)))\n\t\ttcp_init_congestion_control(sk);\n}\n\n \nvoid tcp_cleanup_congestion_control(struct sock *sk)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\n\tif (icsk->icsk_ca_ops->release)\n\t\ticsk->icsk_ca_ops->release(sk);\n\tbpf_module_put(icsk->icsk_ca_ops, icsk->icsk_ca_ops->owner);\n}\n\n \nint tcp_set_default_congestion_control(struct net *net, const char *name)\n{\n\tstruct tcp_congestion_ops *ca;\n\tconst struct tcp_congestion_ops *prev;\n\tint ret;\n\n\trcu_read_lock();\n\tca = tcp_ca_find_autoload(net, name);\n\tif (!ca) {\n\t\tret = -ENOENT;\n\t} else if (!bpf_try_module_get(ca, ca->owner)) {\n\t\tret = -EBUSY;\n\t} else if (!net_eq(net, &init_net) &&\n\t\t\t!(ca->flags & TCP_CONG_NON_RESTRICTED)) {\n\t\t \n\t\tret = -EPERM;\n\t} else {\n\t\tprev = xchg(&net->ipv4.tcp_congestion_control, ca);\n\t\tif (prev)\n\t\t\tbpf_module_put(prev, prev->owner);\n\n\t\tca->flags |= TCP_CONG_NON_RESTRICTED;\n\t\tret = 0;\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\n \nstatic int __init tcp_congestion_default(void)\n{\n\treturn tcp_set_default_congestion_control(&init_net,\n\t\t\t\t\t\t  CONFIG_DEFAULT_TCP_CONG);\n}\nlate_initcall(tcp_congestion_default);\n\n \nvoid tcp_get_available_congestion_control(char *buf, size_t maxlen)\n{\n\tstruct tcp_congestion_ops *ca;\n\tsize_t offs = 0;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(ca, &tcp_cong_list, list) {\n\t\toffs += snprintf(buf + offs, maxlen - offs,\n\t\t\t\t \"%s%s\",\n\t\t\t\t offs == 0 ? \"\" : \" \", ca->name);\n\n\t\tif (WARN_ON_ONCE(offs >= maxlen))\n\t\t\tbreak;\n\t}\n\trcu_read_unlock();\n}\n\n \nvoid tcp_get_default_congestion_control(struct net *net, char *name)\n{\n\tconst struct tcp_congestion_ops *ca;\n\n\trcu_read_lock();\n\tca = rcu_dereference(net->ipv4.tcp_congestion_control);\n\tstrncpy(name, ca->name, TCP_CA_NAME_MAX);\n\trcu_read_unlock();\n}\n\n \nvoid tcp_get_allowed_congestion_control(char *buf, size_t maxlen)\n{\n\tstruct tcp_congestion_ops *ca;\n\tsize_t offs = 0;\n\n\t*buf = '\\0';\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(ca, &tcp_cong_list, list) {\n\t\tif (!(ca->flags & TCP_CONG_NON_RESTRICTED))\n\t\t\tcontinue;\n\t\toffs += snprintf(buf + offs, maxlen - offs,\n\t\t\t\t \"%s%s\",\n\t\t\t\t offs == 0 ? \"\" : \" \", ca->name);\n\n\t\tif (WARN_ON_ONCE(offs >= maxlen))\n\t\t\tbreak;\n\t}\n\trcu_read_unlock();\n}\n\n \nint tcp_set_allowed_congestion_control(char *val)\n{\n\tstruct tcp_congestion_ops *ca;\n\tchar *saved_clone, *clone, *name;\n\tint ret = 0;\n\n\tsaved_clone = clone = kstrdup(val, GFP_USER);\n\tif (!clone)\n\t\treturn -ENOMEM;\n\n\tspin_lock(&tcp_cong_list_lock);\n\t \n\twhile ((name = strsep(&clone, \" \")) && *name) {\n\t\tca = tcp_ca_find(name);\n\t\tif (!ca) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tlist_for_each_entry_rcu(ca, &tcp_cong_list, list)\n\t\tca->flags &= ~TCP_CONG_NON_RESTRICTED;\n\n\t \n\twhile ((name = strsep(&val, \" \")) && *name) {\n\t\tca = tcp_ca_find(name);\n\t\tWARN_ON(!ca);\n\t\tif (ca)\n\t\t\tca->flags |= TCP_CONG_NON_RESTRICTED;\n\t}\nout:\n\tspin_unlock(&tcp_cong_list_lock);\n\tkfree(saved_clone);\n\n\treturn ret;\n}\n\n \nint tcp_set_congestion_control(struct sock *sk, const char *name, bool load,\n\t\t\t       bool cap_net_admin)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tconst struct tcp_congestion_ops *ca;\n\tint err = 0;\n\n\tif (icsk->icsk_ca_dst_locked)\n\t\treturn -EPERM;\n\n\trcu_read_lock();\n\tif (!load)\n\t\tca = tcp_ca_find(name);\n\telse\n\t\tca = tcp_ca_find_autoload(sock_net(sk), name);\n\n\t \n\tif (ca == icsk->icsk_ca_ops) {\n\t\ticsk->icsk_ca_setsockopt = 1;\n\t\tgoto out;\n\t}\n\n\tif (!ca)\n\t\terr = -ENOENT;\n\telse if (!((ca->flags & TCP_CONG_NON_RESTRICTED) || cap_net_admin))\n\t\terr = -EPERM;\n\telse if (!bpf_try_module_get(ca, ca->owner))\n\t\terr = -EBUSY;\n\telse\n\t\ttcp_reinit_congestion_control(sk, ca);\n out:\n\trcu_read_unlock();\n\treturn err;\n}\n\n \n__bpf_kfunc u32 tcp_slow_start(struct tcp_sock *tp, u32 acked)\n{\n\tu32 cwnd = min(tcp_snd_cwnd(tp) + acked, tp->snd_ssthresh);\n\n\tacked -= cwnd - tcp_snd_cwnd(tp);\n\ttcp_snd_cwnd_set(tp, min(cwnd, tp->snd_cwnd_clamp));\n\n\treturn acked;\n}\nEXPORT_SYMBOL_GPL(tcp_slow_start);\n\n \n__bpf_kfunc void tcp_cong_avoid_ai(struct tcp_sock *tp, u32 w, u32 acked)\n{\n\t \n\tif (tp->snd_cwnd_cnt >= w) {\n\t\ttp->snd_cwnd_cnt = 0;\n\t\ttcp_snd_cwnd_set(tp, tcp_snd_cwnd(tp) + 1);\n\t}\n\n\ttp->snd_cwnd_cnt += acked;\n\tif (tp->snd_cwnd_cnt >= w) {\n\t\tu32 delta = tp->snd_cwnd_cnt / w;\n\n\t\ttp->snd_cwnd_cnt -= delta * w;\n\t\ttcp_snd_cwnd_set(tp, tcp_snd_cwnd(tp) + delta);\n\t}\n\ttcp_snd_cwnd_set(tp, min(tcp_snd_cwnd(tp), tp->snd_cwnd_clamp));\n}\nEXPORT_SYMBOL_GPL(tcp_cong_avoid_ai);\n\n \n \n__bpf_kfunc void tcp_reno_cong_avoid(struct sock *sk, u32 ack, u32 acked)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\n\tif (!tcp_is_cwnd_limited(sk))\n\t\treturn;\n\n\t \n\tif (tcp_in_slow_start(tp)) {\n\t\tacked = tcp_slow_start(tp, acked);\n\t\tif (!acked)\n\t\t\treturn;\n\t}\n\t \n\ttcp_cong_avoid_ai(tp, tcp_snd_cwnd(tp), acked);\n}\nEXPORT_SYMBOL_GPL(tcp_reno_cong_avoid);\n\n \n__bpf_kfunc u32 tcp_reno_ssthresh(struct sock *sk)\n{\n\tconst struct tcp_sock *tp = tcp_sk(sk);\n\n\treturn max(tcp_snd_cwnd(tp) >> 1U, 2U);\n}\nEXPORT_SYMBOL_GPL(tcp_reno_ssthresh);\n\n__bpf_kfunc u32 tcp_reno_undo_cwnd(struct sock *sk)\n{\n\tconst struct tcp_sock *tp = tcp_sk(sk);\n\n\treturn max(tcp_snd_cwnd(tp), tp->prior_cwnd);\n}\nEXPORT_SYMBOL_GPL(tcp_reno_undo_cwnd);\n\nstruct tcp_congestion_ops tcp_reno = {\n\t.flags\t\t= TCP_CONG_NON_RESTRICTED,\n\t.name\t\t= \"reno\",\n\t.owner\t\t= THIS_MODULE,\n\t.ssthresh\t= tcp_reno_ssthresh,\n\t.cong_avoid\t= tcp_reno_cong_avoid,\n\t.undo_cwnd\t= tcp_reno_undo_cwnd,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}