{
  "module_name": "nexthop.c",
  "hash_id": "d6753cfb2da033a4a09121e2aebe86bd5abea6f88c1d2154f25bcdc0eb82b01d",
  "original_prompt": "Ingested from linux-6.6.14/net/ipv4/nexthop.c",
  "human_readable_source": "\n \n\n#include <linux/nexthop.h>\n#include <linux/rtnetlink.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <net/arp.h>\n#include <net/ipv6_stubs.h>\n#include <net/lwtunnel.h>\n#include <net/ndisc.h>\n#include <net/nexthop.h>\n#include <net/route.h>\n#include <net/sock.h>\n\n#define NH_RES_DEFAULT_IDLE_TIMER\t(120 * HZ)\n#define NH_RES_DEFAULT_UNBALANCED_TIMER\t0\t \n\nstatic void remove_nexthop(struct net *net, struct nexthop *nh,\n\t\t\t   struct nl_info *nlinfo);\n\n#define NH_DEV_HASHBITS  8\n#define NH_DEV_HASHSIZE (1U << NH_DEV_HASHBITS)\n\nstatic const struct nla_policy rtm_nh_policy_new[] = {\n\t[NHA_ID]\t\t= { .type = NLA_U32 },\n\t[NHA_GROUP]\t\t= { .type = NLA_BINARY },\n\t[NHA_GROUP_TYPE]\t= { .type = NLA_U16 },\n\t[NHA_BLACKHOLE]\t\t= { .type = NLA_FLAG },\n\t[NHA_OIF]\t\t= { .type = NLA_U32 },\n\t[NHA_GATEWAY]\t\t= { .type = NLA_BINARY },\n\t[NHA_ENCAP_TYPE]\t= { .type = NLA_U16 },\n\t[NHA_ENCAP]\t\t= { .type = NLA_NESTED },\n\t[NHA_FDB]\t\t= { .type = NLA_FLAG },\n\t[NHA_RES_GROUP]\t\t= { .type = NLA_NESTED },\n};\n\nstatic const struct nla_policy rtm_nh_policy_get[] = {\n\t[NHA_ID]\t\t= { .type = NLA_U32 },\n};\n\nstatic const struct nla_policy rtm_nh_policy_dump[] = {\n\t[NHA_OIF]\t\t= { .type = NLA_U32 },\n\t[NHA_GROUPS]\t\t= { .type = NLA_FLAG },\n\t[NHA_MASTER]\t\t= { .type = NLA_U32 },\n\t[NHA_FDB]\t\t= { .type = NLA_FLAG },\n};\n\nstatic const struct nla_policy rtm_nh_res_policy_new[] = {\n\t[NHA_RES_GROUP_BUCKETS]\t\t\t= { .type = NLA_U16 },\n\t[NHA_RES_GROUP_IDLE_TIMER]\t\t= { .type = NLA_U32 },\n\t[NHA_RES_GROUP_UNBALANCED_TIMER]\t= { .type = NLA_U32 },\n};\n\nstatic const struct nla_policy rtm_nh_policy_dump_bucket[] = {\n\t[NHA_ID]\t\t= { .type = NLA_U32 },\n\t[NHA_OIF]\t\t= { .type = NLA_U32 },\n\t[NHA_MASTER]\t\t= { .type = NLA_U32 },\n\t[NHA_RES_BUCKET]\t= { .type = NLA_NESTED },\n};\n\nstatic const struct nla_policy rtm_nh_res_bucket_policy_dump[] = {\n\t[NHA_RES_BUCKET_NH_ID]\t= { .type = NLA_U32 },\n};\n\nstatic const struct nla_policy rtm_nh_policy_get_bucket[] = {\n\t[NHA_ID]\t\t= { .type = NLA_U32 },\n\t[NHA_RES_BUCKET]\t= { .type = NLA_NESTED },\n};\n\nstatic const struct nla_policy rtm_nh_res_bucket_policy_get[] = {\n\t[NHA_RES_BUCKET_INDEX]\t= { .type = NLA_U16 },\n};\n\nstatic bool nexthop_notifiers_is_empty(struct net *net)\n{\n\treturn !net->nexthop.notifier_chain.head;\n}\n\nstatic void\n__nh_notifier_single_info_init(struct nh_notifier_single_info *nh_info,\n\t\t\t       const struct nh_info *nhi)\n{\n\tnh_info->dev = nhi->fib_nhc.nhc_dev;\n\tnh_info->gw_family = nhi->fib_nhc.nhc_gw_family;\n\tif (nh_info->gw_family == AF_INET)\n\t\tnh_info->ipv4 = nhi->fib_nhc.nhc_gw.ipv4;\n\telse if (nh_info->gw_family == AF_INET6)\n\t\tnh_info->ipv6 = nhi->fib_nhc.nhc_gw.ipv6;\n\n\tnh_info->is_reject = nhi->reject_nh;\n\tnh_info->is_fdb = nhi->fdb_nh;\n\tnh_info->has_encap = !!nhi->fib_nhc.nhc_lwtstate;\n}\n\nstatic int nh_notifier_single_info_init(struct nh_notifier_info *info,\n\t\t\t\t\tconst struct nexthop *nh)\n{\n\tstruct nh_info *nhi = rtnl_dereference(nh->nh_info);\n\n\tinfo->type = NH_NOTIFIER_INFO_TYPE_SINGLE;\n\tinfo->nh = kzalloc(sizeof(*info->nh), GFP_KERNEL);\n\tif (!info->nh)\n\t\treturn -ENOMEM;\n\n\t__nh_notifier_single_info_init(info->nh, nhi);\n\n\treturn 0;\n}\n\nstatic void nh_notifier_single_info_fini(struct nh_notifier_info *info)\n{\n\tkfree(info->nh);\n}\n\nstatic int nh_notifier_mpath_info_init(struct nh_notifier_info *info,\n\t\t\t\t       struct nh_group *nhg)\n{\n\tu16 num_nh = nhg->num_nh;\n\tint i;\n\n\tinfo->type = NH_NOTIFIER_INFO_TYPE_GRP;\n\tinfo->nh_grp = kzalloc(struct_size(info->nh_grp, nh_entries, num_nh),\n\t\t\t       GFP_KERNEL);\n\tif (!info->nh_grp)\n\t\treturn -ENOMEM;\n\n\tinfo->nh_grp->num_nh = num_nh;\n\tinfo->nh_grp->is_fdb = nhg->fdb_nh;\n\n\tfor (i = 0; i < num_nh; i++) {\n\t\tstruct nh_grp_entry *nhge = &nhg->nh_entries[i];\n\t\tstruct nh_info *nhi;\n\n\t\tnhi = rtnl_dereference(nhge->nh->nh_info);\n\t\tinfo->nh_grp->nh_entries[i].id = nhge->nh->id;\n\t\tinfo->nh_grp->nh_entries[i].weight = nhge->weight;\n\t\t__nh_notifier_single_info_init(&info->nh_grp->nh_entries[i].nh,\n\t\t\t\t\t       nhi);\n\t}\n\n\treturn 0;\n}\n\nstatic int nh_notifier_res_table_info_init(struct nh_notifier_info *info,\n\t\t\t\t\t   struct nh_group *nhg)\n{\n\tstruct nh_res_table *res_table = rtnl_dereference(nhg->res_table);\n\tu16 num_nh_buckets = res_table->num_nh_buckets;\n\tunsigned long size;\n\tu16 i;\n\n\tinfo->type = NH_NOTIFIER_INFO_TYPE_RES_TABLE;\n\tsize = struct_size(info->nh_res_table, nhs, num_nh_buckets);\n\tinfo->nh_res_table = __vmalloc(size, GFP_KERNEL | __GFP_ZERO |\n\t\t\t\t       __GFP_NOWARN);\n\tif (!info->nh_res_table)\n\t\treturn -ENOMEM;\n\n\tinfo->nh_res_table->num_nh_buckets = num_nh_buckets;\n\n\tfor (i = 0; i < num_nh_buckets; i++) {\n\t\tstruct nh_res_bucket *bucket = &res_table->nh_buckets[i];\n\t\tstruct nh_grp_entry *nhge;\n\t\tstruct nh_info *nhi;\n\n\t\tnhge = rtnl_dereference(bucket->nh_entry);\n\t\tnhi = rtnl_dereference(nhge->nh->nh_info);\n\t\t__nh_notifier_single_info_init(&info->nh_res_table->nhs[i],\n\t\t\t\t\t       nhi);\n\t}\n\n\treturn 0;\n}\n\nstatic int nh_notifier_grp_info_init(struct nh_notifier_info *info,\n\t\t\t\t     const struct nexthop *nh)\n{\n\tstruct nh_group *nhg = rtnl_dereference(nh->nh_grp);\n\n\tif (nhg->hash_threshold)\n\t\treturn nh_notifier_mpath_info_init(info, nhg);\n\telse if (nhg->resilient)\n\t\treturn nh_notifier_res_table_info_init(info, nhg);\n\treturn -EINVAL;\n}\n\nstatic void nh_notifier_grp_info_fini(struct nh_notifier_info *info,\n\t\t\t\t      const struct nexthop *nh)\n{\n\tstruct nh_group *nhg = rtnl_dereference(nh->nh_grp);\n\n\tif (nhg->hash_threshold)\n\t\tkfree(info->nh_grp);\n\telse if (nhg->resilient)\n\t\tvfree(info->nh_res_table);\n}\n\nstatic int nh_notifier_info_init(struct nh_notifier_info *info,\n\t\t\t\t const struct nexthop *nh)\n{\n\tinfo->id = nh->id;\n\n\tif (nh->is_group)\n\t\treturn nh_notifier_grp_info_init(info, nh);\n\telse\n\t\treturn nh_notifier_single_info_init(info, nh);\n}\n\nstatic void nh_notifier_info_fini(struct nh_notifier_info *info,\n\t\t\t\t  const struct nexthop *nh)\n{\n\tif (nh->is_group)\n\t\tnh_notifier_grp_info_fini(info, nh);\n\telse\n\t\tnh_notifier_single_info_fini(info);\n}\n\nstatic int call_nexthop_notifiers(struct net *net,\n\t\t\t\t  enum nexthop_event_type event_type,\n\t\t\t\t  struct nexthop *nh,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct nh_notifier_info info = {\n\t\t.net = net,\n\t\t.extack = extack,\n\t};\n\tint err;\n\n\tASSERT_RTNL();\n\n\tif (nexthop_notifiers_is_empty(net))\n\t\treturn 0;\n\n\terr = nh_notifier_info_init(&info, nh);\n\tif (err) {\n\t\tNL_SET_ERR_MSG(extack, \"Failed to initialize nexthop notifier info\");\n\t\treturn err;\n\t}\n\n\terr = blocking_notifier_call_chain(&net->nexthop.notifier_chain,\n\t\t\t\t\t   event_type, &info);\n\tnh_notifier_info_fini(&info, nh);\n\n\treturn notifier_to_errno(err);\n}\n\nstatic int\nnh_notifier_res_bucket_idle_timer_get(const struct nh_notifier_info *info,\n\t\t\t\t      bool force, unsigned int *p_idle_timer_ms)\n{\n\tstruct nh_res_table *res_table;\n\tstruct nh_group *nhg;\n\tstruct nexthop *nh;\n\tint err = 0;\n\n\t \n\tif (force) {\n\t\t*p_idle_timer_ms = 0;\n\t\treturn 0;\n\t}\n\n\trcu_read_lock();\n\n\tnh = nexthop_find_by_id(info->net, info->id);\n\tif (!nh) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tnhg = rcu_dereference(nh->nh_grp);\n\tres_table = rcu_dereference(nhg->res_table);\n\t*p_idle_timer_ms = jiffies_to_msecs(res_table->idle_timer);\n\nout:\n\trcu_read_unlock();\n\n\treturn err;\n}\n\nstatic int nh_notifier_res_bucket_info_init(struct nh_notifier_info *info,\n\t\t\t\t\t    u16 bucket_index, bool force,\n\t\t\t\t\t    struct nh_info *oldi,\n\t\t\t\t\t    struct nh_info *newi)\n{\n\tunsigned int idle_timer_ms;\n\tint err;\n\n\terr = nh_notifier_res_bucket_idle_timer_get(info, force,\n\t\t\t\t\t\t    &idle_timer_ms);\n\tif (err)\n\t\treturn err;\n\n\tinfo->type = NH_NOTIFIER_INFO_TYPE_RES_BUCKET;\n\tinfo->nh_res_bucket = kzalloc(sizeof(*info->nh_res_bucket),\n\t\t\t\t      GFP_KERNEL);\n\tif (!info->nh_res_bucket)\n\t\treturn -ENOMEM;\n\n\tinfo->nh_res_bucket->bucket_index = bucket_index;\n\tinfo->nh_res_bucket->idle_timer_ms = idle_timer_ms;\n\tinfo->nh_res_bucket->force = force;\n\t__nh_notifier_single_info_init(&info->nh_res_bucket->old_nh, oldi);\n\t__nh_notifier_single_info_init(&info->nh_res_bucket->new_nh, newi);\n\treturn 0;\n}\n\nstatic void nh_notifier_res_bucket_info_fini(struct nh_notifier_info *info)\n{\n\tkfree(info->nh_res_bucket);\n}\n\nstatic int __call_nexthop_res_bucket_notifiers(struct net *net, u32 nhg_id,\n\t\t\t\t\t       u16 bucket_index, bool force,\n\t\t\t\t\t       struct nh_info *oldi,\n\t\t\t\t\t       struct nh_info *newi,\n\t\t\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct nh_notifier_info info = {\n\t\t.net = net,\n\t\t.extack = extack,\n\t\t.id = nhg_id,\n\t};\n\tint err;\n\n\tif (nexthop_notifiers_is_empty(net))\n\t\treturn 0;\n\n\terr = nh_notifier_res_bucket_info_init(&info, bucket_index, force,\n\t\t\t\t\t       oldi, newi);\n\tif (err)\n\t\treturn err;\n\n\terr = blocking_notifier_call_chain(&net->nexthop.notifier_chain,\n\t\t\t\t\t   NEXTHOP_EVENT_BUCKET_REPLACE, &info);\n\tnh_notifier_res_bucket_info_fini(&info);\n\n\treturn notifier_to_errno(err);\n}\n\n \n#define nh_res_dereference(p) (rcu_dereference_raw(p))\n\nstatic int call_nexthop_res_bucket_notifiers(struct net *net, u32 nhg_id,\n\t\t\t\t\t     u16 bucket_index, bool force,\n\t\t\t\t\t     struct nexthop *old_nh,\n\t\t\t\t\t     struct nexthop *new_nh,\n\t\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct nh_info *oldi = nh_res_dereference(old_nh->nh_info);\n\tstruct nh_info *newi = nh_res_dereference(new_nh->nh_info);\n\n\treturn __call_nexthop_res_bucket_notifiers(net, nhg_id, bucket_index,\n\t\t\t\t\t\t   force, oldi, newi, extack);\n}\n\nstatic int call_nexthop_res_table_notifiers(struct net *net, struct nexthop *nh,\n\t\t\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct nh_notifier_info info = {\n\t\t.net = net,\n\t\t.extack = extack,\n\t};\n\tstruct nh_group *nhg;\n\tint err;\n\n\tASSERT_RTNL();\n\n\tif (nexthop_notifiers_is_empty(net))\n\t\treturn 0;\n\n\t \n\tnhg = rtnl_dereference(nh->nh_grp);\n\terr = nh_notifier_mpath_info_init(&info, nhg);\n\tif (err) {\n\t\tNL_SET_ERR_MSG(extack, \"Failed to initialize nexthop notifier info\");\n\t\treturn err;\n\t}\n\n\terr = blocking_notifier_call_chain(&net->nexthop.notifier_chain,\n\t\t\t\t\t   NEXTHOP_EVENT_RES_TABLE_PRE_REPLACE,\n\t\t\t\t\t   &info);\n\tkfree(info.nh_grp);\n\n\treturn notifier_to_errno(err);\n}\n\nstatic int call_nexthop_notifier(struct notifier_block *nb, struct net *net,\n\t\t\t\t enum nexthop_event_type event_type,\n\t\t\t\t struct nexthop *nh,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct nh_notifier_info info = {\n\t\t.net = net,\n\t\t.extack = extack,\n\t};\n\tint err;\n\n\terr = nh_notifier_info_init(&info, nh);\n\tif (err)\n\t\treturn err;\n\n\terr = nb->notifier_call(nb, event_type, &info);\n\tnh_notifier_info_fini(&info, nh);\n\n\treturn notifier_to_errno(err);\n}\n\nstatic unsigned int nh_dev_hashfn(unsigned int val)\n{\n\tunsigned int mask = NH_DEV_HASHSIZE - 1;\n\n\treturn (val ^\n\t\t(val >> NH_DEV_HASHBITS) ^\n\t\t(val >> (NH_DEV_HASHBITS * 2))) & mask;\n}\n\nstatic void nexthop_devhash_add(struct net *net, struct nh_info *nhi)\n{\n\tstruct net_device *dev = nhi->fib_nhc.nhc_dev;\n\tstruct hlist_head *head;\n\tunsigned int hash;\n\n\tWARN_ON(!dev);\n\n\thash = nh_dev_hashfn(dev->ifindex);\n\thead = &net->nexthop.devhash[hash];\n\thlist_add_head(&nhi->dev_hash, head);\n}\n\nstatic void nexthop_free_group(struct nexthop *nh)\n{\n\tstruct nh_group *nhg;\n\tint i;\n\n\tnhg = rcu_dereference_raw(nh->nh_grp);\n\tfor (i = 0; i < nhg->num_nh; ++i) {\n\t\tstruct nh_grp_entry *nhge = &nhg->nh_entries[i];\n\n\t\tWARN_ON(!list_empty(&nhge->nh_list));\n\t\tnexthop_put(nhge->nh);\n\t}\n\n\tWARN_ON(nhg->spare == nhg);\n\n\tif (nhg->resilient)\n\t\tvfree(rcu_dereference_raw(nhg->res_table));\n\n\tkfree(nhg->spare);\n\tkfree(nhg);\n}\n\nstatic void nexthop_free_single(struct nexthop *nh)\n{\n\tstruct nh_info *nhi;\n\n\tnhi = rcu_dereference_raw(nh->nh_info);\n\tswitch (nhi->family) {\n\tcase AF_INET:\n\t\tfib_nh_release(nh->net, &nhi->fib_nh);\n\t\tbreak;\n\tcase AF_INET6:\n\t\tipv6_stub->fib6_nh_release(&nhi->fib6_nh);\n\t\tbreak;\n\t}\n\tkfree(nhi);\n}\n\nvoid nexthop_free_rcu(struct rcu_head *head)\n{\n\tstruct nexthop *nh = container_of(head, struct nexthop, rcu);\n\n\tif (nh->is_group)\n\t\tnexthop_free_group(nh);\n\telse\n\t\tnexthop_free_single(nh);\n\n\tkfree(nh);\n}\nEXPORT_SYMBOL_GPL(nexthop_free_rcu);\n\nstatic struct nexthop *nexthop_alloc(void)\n{\n\tstruct nexthop *nh;\n\n\tnh = kzalloc(sizeof(struct nexthop), GFP_KERNEL);\n\tif (nh) {\n\t\tINIT_LIST_HEAD(&nh->fi_list);\n\t\tINIT_LIST_HEAD(&nh->f6i_list);\n\t\tINIT_LIST_HEAD(&nh->grp_list);\n\t\tINIT_LIST_HEAD(&nh->fdb_list);\n\t}\n\treturn nh;\n}\n\nstatic struct nh_group *nexthop_grp_alloc(u16 num_nh)\n{\n\tstruct nh_group *nhg;\n\n\tnhg = kzalloc(struct_size(nhg, nh_entries, num_nh), GFP_KERNEL);\n\tif (nhg)\n\t\tnhg->num_nh = num_nh;\n\n\treturn nhg;\n}\n\nstatic void nh_res_table_upkeep_dw(struct work_struct *work);\n\nstatic struct nh_res_table *\nnexthop_res_table_alloc(struct net *net, u32 nhg_id, struct nh_config *cfg)\n{\n\tconst u16 num_nh_buckets = cfg->nh_grp_res_num_buckets;\n\tstruct nh_res_table *res_table;\n\tunsigned long size;\n\n\tsize = struct_size(res_table, nh_buckets, num_nh_buckets);\n\tres_table = __vmalloc(size, GFP_KERNEL | __GFP_ZERO | __GFP_NOWARN);\n\tif (!res_table)\n\t\treturn NULL;\n\n\tres_table->net = net;\n\tres_table->nhg_id = nhg_id;\n\tINIT_DELAYED_WORK(&res_table->upkeep_dw, &nh_res_table_upkeep_dw);\n\tINIT_LIST_HEAD(&res_table->uw_nh_entries);\n\tres_table->idle_timer = cfg->nh_grp_res_idle_timer;\n\tres_table->unbalanced_timer = cfg->nh_grp_res_unbalanced_timer;\n\tres_table->num_nh_buckets = num_nh_buckets;\n\treturn res_table;\n}\n\nstatic void nh_base_seq_inc(struct net *net)\n{\n\twhile (++net->nexthop.seq == 0)\n\t\t;\n}\n\n \nstruct nexthop *nexthop_find_by_id(struct net *net, u32 id)\n{\n\tstruct rb_node **pp, *parent = NULL, *next;\n\n\tpp = &net->nexthop.rb_root.rb_node;\n\twhile (1) {\n\t\tstruct nexthop *nh;\n\n\t\tnext = rcu_dereference_raw(*pp);\n\t\tif (!next)\n\t\t\tbreak;\n\t\tparent = next;\n\n\t\tnh = rb_entry(parent, struct nexthop, rb_node);\n\t\tif (id < nh->id)\n\t\t\tpp = &next->rb_left;\n\t\telse if (id > nh->id)\n\t\t\tpp = &next->rb_right;\n\t\telse\n\t\t\treturn nh;\n\t}\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(nexthop_find_by_id);\n\n \nstatic u32 nh_find_unused_id(struct net *net)\n{\n\tu32 id_start = net->nexthop.last_id_allocated;\n\n\twhile (1) {\n\t\tnet->nexthop.last_id_allocated++;\n\t\tif (net->nexthop.last_id_allocated == id_start)\n\t\t\tbreak;\n\n\t\tif (!nexthop_find_by_id(net, net->nexthop.last_id_allocated))\n\t\t\treturn net->nexthop.last_id_allocated;\n\t}\n\treturn 0;\n}\n\nstatic void nh_res_time_set_deadline(unsigned long next_time,\n\t\t\t\t     unsigned long *deadline)\n{\n\tif (time_before(next_time, *deadline))\n\t\t*deadline = next_time;\n}\n\nstatic clock_t nh_res_table_unbalanced_time(struct nh_res_table *res_table)\n{\n\tif (list_empty(&res_table->uw_nh_entries))\n\t\treturn 0;\n\treturn jiffies_delta_to_clock_t(jiffies - res_table->unbalanced_since);\n}\n\nstatic int nla_put_nh_group_res(struct sk_buff *skb, struct nh_group *nhg)\n{\n\tstruct nh_res_table *res_table = rtnl_dereference(nhg->res_table);\n\tstruct nlattr *nest;\n\n\tnest = nla_nest_start(skb, NHA_RES_GROUP);\n\tif (!nest)\n\t\treturn -EMSGSIZE;\n\n\tif (nla_put_u16(skb, NHA_RES_GROUP_BUCKETS,\n\t\t\tres_table->num_nh_buckets) ||\n\t    nla_put_u32(skb, NHA_RES_GROUP_IDLE_TIMER,\n\t\t\tjiffies_to_clock_t(res_table->idle_timer)) ||\n\t    nla_put_u32(skb, NHA_RES_GROUP_UNBALANCED_TIMER,\n\t\t\tjiffies_to_clock_t(res_table->unbalanced_timer)) ||\n\t    nla_put_u64_64bit(skb, NHA_RES_GROUP_UNBALANCED_TIME,\n\t\t\t      nh_res_table_unbalanced_time(res_table),\n\t\t\t      NHA_RES_GROUP_PAD))\n\t\tgoto nla_put_failure;\n\n\tnla_nest_end(skb, nest);\n\treturn 0;\n\nnla_put_failure:\n\tnla_nest_cancel(skb, nest);\n\treturn -EMSGSIZE;\n}\n\nstatic int nla_put_nh_group(struct sk_buff *skb, struct nh_group *nhg)\n{\n\tstruct nexthop_grp *p;\n\tsize_t len = nhg->num_nh * sizeof(*p);\n\tstruct nlattr *nla;\n\tu16 group_type = 0;\n\tint i;\n\n\tif (nhg->hash_threshold)\n\t\tgroup_type = NEXTHOP_GRP_TYPE_MPATH;\n\telse if (nhg->resilient)\n\t\tgroup_type = NEXTHOP_GRP_TYPE_RES;\n\n\tif (nla_put_u16(skb, NHA_GROUP_TYPE, group_type))\n\t\tgoto nla_put_failure;\n\n\tnla = nla_reserve(skb, NHA_GROUP, len);\n\tif (!nla)\n\t\tgoto nla_put_failure;\n\n\tp = nla_data(nla);\n\tfor (i = 0; i < nhg->num_nh; ++i) {\n\t\tp->id = nhg->nh_entries[i].nh->id;\n\t\tp->weight = nhg->nh_entries[i].weight - 1;\n\t\tp += 1;\n\t}\n\n\tif (nhg->resilient && nla_put_nh_group_res(skb, nhg))\n\t\tgoto nla_put_failure;\n\n\treturn 0;\n\nnla_put_failure:\n\treturn -EMSGSIZE;\n}\n\nstatic int nh_fill_node(struct sk_buff *skb, struct nexthop *nh,\n\t\t\tint event, u32 portid, u32 seq, unsigned int nlflags)\n{\n\tstruct fib6_nh *fib6_nh;\n\tstruct fib_nh *fib_nh;\n\tstruct nlmsghdr *nlh;\n\tstruct nh_info *nhi;\n\tstruct nhmsg *nhm;\n\n\tnlh = nlmsg_put(skb, portid, seq, event, sizeof(*nhm), nlflags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tnhm = nlmsg_data(nlh);\n\tnhm->nh_family = AF_UNSPEC;\n\tnhm->nh_flags = nh->nh_flags;\n\tnhm->nh_protocol = nh->protocol;\n\tnhm->nh_scope = 0;\n\tnhm->resvd = 0;\n\n\tif (nla_put_u32(skb, NHA_ID, nh->id))\n\t\tgoto nla_put_failure;\n\n\tif (nh->is_group) {\n\t\tstruct nh_group *nhg = rtnl_dereference(nh->nh_grp);\n\n\t\tif (nhg->fdb_nh && nla_put_flag(skb, NHA_FDB))\n\t\t\tgoto nla_put_failure;\n\t\tif (nla_put_nh_group(skb, nhg))\n\t\t\tgoto nla_put_failure;\n\t\tgoto out;\n\t}\n\n\tnhi = rtnl_dereference(nh->nh_info);\n\tnhm->nh_family = nhi->family;\n\tif (nhi->reject_nh) {\n\t\tif (nla_put_flag(skb, NHA_BLACKHOLE))\n\t\t\tgoto nla_put_failure;\n\t\tgoto out;\n\t} else if (nhi->fdb_nh) {\n\t\tif (nla_put_flag(skb, NHA_FDB))\n\t\t\tgoto nla_put_failure;\n\t} else {\n\t\tconst struct net_device *dev;\n\n\t\tdev = nhi->fib_nhc.nhc_dev;\n\t\tif (dev && nla_put_u32(skb, NHA_OIF, dev->ifindex))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tnhm->nh_scope = nhi->fib_nhc.nhc_scope;\n\tswitch (nhi->family) {\n\tcase AF_INET:\n\t\tfib_nh = &nhi->fib_nh;\n\t\tif (fib_nh->fib_nh_gw_family &&\n\t\t    nla_put_be32(skb, NHA_GATEWAY, fib_nh->fib_nh_gw4))\n\t\t\tgoto nla_put_failure;\n\t\tbreak;\n\n\tcase AF_INET6:\n\t\tfib6_nh = &nhi->fib6_nh;\n\t\tif (fib6_nh->fib_nh_gw_family &&\n\t\t    nla_put_in6_addr(skb, NHA_GATEWAY, &fib6_nh->fib_nh_gw6))\n\t\t\tgoto nla_put_failure;\n\t\tbreak;\n\t}\n\n\tif (nhi->fib_nhc.nhc_lwtstate &&\n\t    lwtunnel_fill_encap(skb, nhi->fib_nhc.nhc_lwtstate,\n\t\t\t\tNHA_ENCAP, NHA_ENCAP_TYPE) < 0)\n\t\tgoto nla_put_failure;\n\nout:\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}\n\nstatic size_t nh_nlmsg_size_grp_res(struct nh_group *nhg)\n{\n\treturn nla_total_size(0) +\t \n\t\tnla_total_size(2) +\t \n\t\tnla_total_size(4) +\t \n\t\tnla_total_size(4) +\t \n\t\tnla_total_size_64bit(8); \n}\n\nstatic size_t nh_nlmsg_size_grp(struct nexthop *nh)\n{\n\tstruct nh_group *nhg = rtnl_dereference(nh->nh_grp);\n\tsize_t sz = sizeof(struct nexthop_grp) * nhg->num_nh;\n\tsize_t tot = nla_total_size(sz) +\n\t\tnla_total_size(2);  \n\n\tif (nhg->resilient)\n\t\ttot += nh_nlmsg_size_grp_res(nhg);\n\n\treturn tot;\n}\n\nstatic size_t nh_nlmsg_size_single(struct nexthop *nh)\n{\n\tstruct nh_info *nhi = rtnl_dereference(nh->nh_info);\n\tsize_t sz;\n\n\t \n\tsz = nla_total_size(4);   \n\n\tswitch (nhi->family) {\n\tcase AF_INET:\n\t\tif (nhi->fib_nh.fib_nh_gw_family)\n\t\t\tsz += nla_total_size(4);   \n\t\tbreak;\n\n\tcase AF_INET6:\n\t\t \n\t\tif (nhi->fib6_nh.fib_nh_gw_family)\n\t\t\tsz += nla_total_size(sizeof(const struct in6_addr));\n\t\tbreak;\n\t}\n\n\tif (nhi->fib_nhc.nhc_lwtstate) {\n\t\tsz += lwtunnel_get_encap_size(nhi->fib_nhc.nhc_lwtstate);\n\t\tsz += nla_total_size(2);   \n\t}\n\n\treturn sz;\n}\n\nstatic size_t nh_nlmsg_size(struct nexthop *nh)\n{\n\tsize_t sz = NLMSG_ALIGN(sizeof(struct nhmsg));\n\n\tsz += nla_total_size(4);  \n\n\tif (nh->is_group)\n\t\tsz += nh_nlmsg_size_grp(nh);\n\telse\n\t\tsz += nh_nlmsg_size_single(nh);\n\n\treturn sz;\n}\n\nstatic void nexthop_notify(int event, struct nexthop *nh, struct nl_info *info)\n{\n\tunsigned int nlflags = info->nlh ? info->nlh->nlmsg_flags : 0;\n\tu32 seq = info->nlh ? info->nlh->nlmsg_seq : 0;\n\tstruct sk_buff *skb;\n\tint err = -ENOBUFS;\n\n\tskb = nlmsg_new(nh_nlmsg_size(nh), gfp_any());\n\tif (!skb)\n\t\tgoto errout;\n\n\terr = nh_fill_node(skb, nh, event, info->portid, seq, nlflags);\n\tif (err < 0) {\n\t\t \n\t\tWARN_ON(err == -EMSGSIZE);\n\t\tkfree_skb(skb);\n\t\tgoto errout;\n\t}\n\n\trtnl_notify(skb, info->nl_net, info->portid, RTNLGRP_NEXTHOP,\n\t\t    info->nlh, gfp_any());\n\treturn;\nerrout:\n\tif (err < 0)\n\t\trtnl_set_sk_err(info->nl_net, RTNLGRP_NEXTHOP, err);\n}\n\nstatic unsigned long nh_res_bucket_used_time(const struct nh_res_bucket *bucket)\n{\n\treturn (unsigned long)atomic_long_read(&bucket->used_time);\n}\n\nstatic unsigned long\nnh_res_bucket_idle_point(const struct nh_res_table *res_table,\n\t\t\t const struct nh_res_bucket *bucket,\n\t\t\t unsigned long now)\n{\n\tunsigned long time = nh_res_bucket_used_time(bucket);\n\n\t \n\tif (time == bucket->migrated_time)\n\t\treturn now;\n\n\treturn time + res_table->idle_timer;\n}\n\nstatic unsigned long\nnh_res_table_unb_point(const struct nh_res_table *res_table)\n{\n\treturn res_table->unbalanced_since + res_table->unbalanced_timer;\n}\n\nstatic void nh_res_bucket_set_idle(const struct nh_res_table *res_table,\n\t\t\t\t   struct nh_res_bucket *bucket)\n{\n\tunsigned long now = jiffies;\n\n\tatomic_long_set(&bucket->used_time, (long)now);\n\tbucket->migrated_time = now;\n}\n\nstatic void nh_res_bucket_set_busy(struct nh_res_bucket *bucket)\n{\n\tatomic_long_set(&bucket->used_time, (long)jiffies);\n}\n\nstatic clock_t nh_res_bucket_idle_time(const struct nh_res_bucket *bucket)\n{\n\tunsigned long used_time = nh_res_bucket_used_time(bucket);\n\n\treturn jiffies_delta_to_clock_t(jiffies - used_time);\n}\n\nstatic int nh_fill_res_bucket(struct sk_buff *skb, struct nexthop *nh,\n\t\t\t      struct nh_res_bucket *bucket, u16 bucket_index,\n\t\t\t      int event, u32 portid, u32 seq,\n\t\t\t      unsigned int nlflags,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct nh_grp_entry *nhge = nh_res_dereference(bucket->nh_entry);\n\tstruct nlmsghdr *nlh;\n\tstruct nlattr *nest;\n\tstruct nhmsg *nhm;\n\n\tnlh = nlmsg_put(skb, portid, seq, event, sizeof(*nhm), nlflags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tnhm = nlmsg_data(nlh);\n\tnhm->nh_family = AF_UNSPEC;\n\tnhm->nh_flags = bucket->nh_flags;\n\tnhm->nh_protocol = nh->protocol;\n\tnhm->nh_scope = 0;\n\tnhm->resvd = 0;\n\n\tif (nla_put_u32(skb, NHA_ID, nh->id))\n\t\tgoto nla_put_failure;\n\n\tnest = nla_nest_start(skb, NHA_RES_BUCKET);\n\tif (!nest)\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u16(skb, NHA_RES_BUCKET_INDEX, bucket_index) ||\n\t    nla_put_u32(skb, NHA_RES_BUCKET_NH_ID, nhge->nh->id) ||\n\t    nla_put_u64_64bit(skb, NHA_RES_BUCKET_IDLE_TIME,\n\t\t\t      nh_res_bucket_idle_time(bucket),\n\t\t\t      NHA_RES_BUCKET_PAD))\n\t\tgoto nla_put_failure_nest;\n\n\tnla_nest_end(skb, nest);\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n\nnla_put_failure_nest:\n\tnla_nest_cancel(skb, nest);\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}\n\nstatic void nexthop_bucket_notify(struct nh_res_table *res_table,\n\t\t\t\t  u16 bucket_index)\n{\n\tstruct nh_res_bucket *bucket = &res_table->nh_buckets[bucket_index];\n\tstruct nh_grp_entry *nhge = nh_res_dereference(bucket->nh_entry);\n\tstruct nexthop *nh = nhge->nh_parent;\n\tstruct sk_buff *skb;\n\tint err = -ENOBUFS;\n\n\tskb = alloc_skb(NLMSG_GOODSIZE, GFP_KERNEL);\n\tif (!skb)\n\t\tgoto errout;\n\n\terr = nh_fill_res_bucket(skb, nh, bucket, bucket_index,\n\t\t\t\t RTM_NEWNEXTHOPBUCKET, 0, 0, NLM_F_REPLACE,\n\t\t\t\t NULL);\n\tif (err < 0) {\n\t\tkfree_skb(skb);\n\t\tgoto errout;\n\t}\n\n\trtnl_notify(skb, nh->net, 0, RTNLGRP_NEXTHOP, NULL, GFP_KERNEL);\n\treturn;\nerrout:\n\tif (err < 0)\n\t\trtnl_set_sk_err(nh->net, RTNLGRP_NEXTHOP, err);\n}\n\nstatic bool valid_group_nh(struct nexthop *nh, unsigned int npaths,\n\t\t\t   bool *is_fdb, struct netlink_ext_ack *extack)\n{\n\tif (nh->is_group) {\n\t\tstruct nh_group *nhg = rtnl_dereference(nh->nh_grp);\n\n\t\t \n\t\tif (nhg->hash_threshold) {\n\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t       \"Hash-threshold group can not be a nexthop within a group\");\n\t\t\treturn false;\n\t\t}\n\t\tif (nhg->resilient) {\n\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t       \"Resilient group can not be a nexthop within a group\");\n\t\t\treturn false;\n\t\t}\n\t\t*is_fdb = nhg->fdb_nh;\n\t} else {\n\t\tstruct nh_info *nhi = rtnl_dereference(nh->nh_info);\n\n\t\tif (nhi->reject_nh && npaths > 1) {\n\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t       \"Blackhole nexthop can not be used in a group with more than 1 path\");\n\t\t\treturn false;\n\t\t}\n\t\t*is_fdb = nhi->fdb_nh;\n\t}\n\n\treturn true;\n}\n\nstatic int nh_check_attr_fdb_group(struct nexthop *nh, u8 *nh_family,\n\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct nh_info *nhi;\n\n\tnhi = rtnl_dereference(nh->nh_info);\n\n\tif (!nhi->fdb_nh) {\n\t\tNL_SET_ERR_MSG(extack, \"FDB nexthop group can only have fdb nexthops\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (*nh_family == AF_UNSPEC) {\n\t\t*nh_family = nhi->family;\n\t} else if (*nh_family != nhi->family) {\n\t\tNL_SET_ERR_MSG(extack, \"FDB nexthop group cannot have mixed family nexthops\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int nh_check_attr_group(struct net *net,\n\t\t\t       struct nlattr *tb[], size_t tb_size,\n\t\t\t       u16 nh_grp_type, struct netlink_ext_ack *extack)\n{\n\tunsigned int len = nla_len(tb[NHA_GROUP]);\n\tu8 nh_family = AF_UNSPEC;\n\tstruct nexthop_grp *nhg;\n\tunsigned int i, j;\n\tu8 nhg_fdb = 0;\n\n\tif (!len || len & (sizeof(struct nexthop_grp) - 1)) {\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"Invalid length for nexthop group attribute\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tlen /= sizeof(*nhg);\n\n\tnhg = nla_data(tb[NHA_GROUP]);\n\tfor (i = 0; i < len; ++i) {\n\t\tif (nhg[i].resvd1 || nhg[i].resvd2) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Reserved fields in nexthop_grp must be 0\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (nhg[i].weight > 254) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid value for weight\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tfor (j = i + 1; j < len; ++j) {\n\t\t\tif (nhg[i].id == nhg[j].id) {\n\t\t\t\tNL_SET_ERR_MSG(extack, \"Nexthop id can not be used twice in a group\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (tb[NHA_FDB])\n\t\tnhg_fdb = 1;\n\tnhg = nla_data(tb[NHA_GROUP]);\n\tfor (i = 0; i < len; ++i) {\n\t\tstruct nexthop *nh;\n\t\tbool is_fdb_nh;\n\n\t\tnh = nexthop_find_by_id(net, nhg[i].id);\n\t\tif (!nh) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid nexthop id\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!valid_group_nh(nh, len, &is_fdb_nh, extack))\n\t\t\treturn -EINVAL;\n\n\t\tif (nhg_fdb && nh_check_attr_fdb_group(nh, &nh_family, extack))\n\t\t\treturn -EINVAL;\n\n\t\tif (!nhg_fdb && is_fdb_nh) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Non FDB nexthop group cannot have fdb nexthops\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tfor (i = NHA_GROUP_TYPE + 1; i < tb_size; ++i) {\n\t\tif (!tb[i])\n\t\t\tcontinue;\n\t\tswitch (i) {\n\t\tcase NHA_FDB:\n\t\t\tcontinue;\n\t\tcase NHA_RES_GROUP:\n\t\t\tif (nh_grp_type == NEXTHOP_GRP_TYPE_RES)\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\t}\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"No other attributes can be set in nexthop groups\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic bool ipv6_good_nh(const struct fib6_nh *nh)\n{\n\tint state = NUD_REACHABLE;\n\tstruct neighbour *n;\n\n\trcu_read_lock();\n\n\tn = __ipv6_neigh_lookup_noref_stub(nh->fib_nh_dev, &nh->fib_nh_gw6);\n\tif (n)\n\t\tstate = READ_ONCE(n->nud_state);\n\n\trcu_read_unlock();\n\n\treturn !!(state & NUD_VALID);\n}\n\nstatic bool ipv4_good_nh(const struct fib_nh *nh)\n{\n\tint state = NUD_REACHABLE;\n\tstruct neighbour *n;\n\n\trcu_read_lock();\n\n\tn = __ipv4_neigh_lookup_noref(nh->fib_nh_dev,\n\t\t\t\t      (__force u32)nh->fib_nh_gw4);\n\tif (n)\n\t\tstate = READ_ONCE(n->nud_state);\n\n\trcu_read_unlock();\n\n\treturn !!(state & NUD_VALID);\n}\n\nstatic bool nexthop_is_good_nh(const struct nexthop *nh)\n{\n\tstruct nh_info *nhi = rcu_dereference(nh->nh_info);\n\n\tswitch (nhi->family) {\n\tcase AF_INET:\n\t\treturn ipv4_good_nh(&nhi->fib_nh);\n\tcase AF_INET6:\n\t\treturn ipv6_good_nh(&nhi->fib6_nh);\n\t}\n\n\treturn false;\n}\n\nstatic struct nexthop *nexthop_select_path_fdb(struct nh_group *nhg, int hash)\n{\n\tint i;\n\n\tfor (i = 0; i < nhg->num_nh; i++) {\n\t\tstruct nh_grp_entry *nhge = &nhg->nh_entries[i];\n\n\t\tif (hash > atomic_read(&nhge->hthr.upper_bound))\n\t\t\tcontinue;\n\n\t\treturn nhge->nh;\n\t}\n\n\tWARN_ON_ONCE(1);\n\treturn NULL;\n}\n\nstatic struct nexthop *nexthop_select_path_hthr(struct nh_group *nhg, int hash)\n{\n\tstruct nexthop *rc = NULL;\n\tint i;\n\n\tif (nhg->fdb_nh)\n\t\treturn nexthop_select_path_fdb(nhg, hash);\n\n\tfor (i = 0; i < nhg->num_nh; ++i) {\n\t\tstruct nh_grp_entry *nhge = &nhg->nh_entries[i];\n\n\t\t \n\t\tif (!nexthop_is_good_nh(nhge->nh))\n\t\t\tcontinue;\n\n\t\tif (!rc)\n\t\t\trc = nhge->nh;\n\n\t\tif (hash > atomic_read(&nhge->hthr.upper_bound))\n\t\t\tcontinue;\n\n\t\treturn nhge->nh;\n\t}\n\n\treturn rc ? : nhg->nh_entries[0].nh;\n}\n\nstatic struct nexthop *nexthop_select_path_res(struct nh_group *nhg, int hash)\n{\n\tstruct nh_res_table *res_table = rcu_dereference(nhg->res_table);\n\tu16 bucket_index = hash % res_table->num_nh_buckets;\n\tstruct nh_res_bucket *bucket;\n\tstruct nh_grp_entry *nhge;\n\n\t \n\tbucket = &res_table->nh_buckets[bucket_index];\n\tnh_res_bucket_set_busy(bucket);\n\tnhge = rcu_dereference(bucket->nh_entry);\n\treturn nhge->nh;\n}\n\nstruct nexthop *nexthop_select_path(struct nexthop *nh, int hash)\n{\n\tstruct nh_group *nhg;\n\n\tif (!nh->is_group)\n\t\treturn nh;\n\n\tnhg = rcu_dereference(nh->nh_grp);\n\tif (nhg->hash_threshold)\n\t\treturn nexthop_select_path_hthr(nhg, hash);\n\telse if (nhg->resilient)\n\t\treturn nexthop_select_path_res(nhg, hash);\n\n\t \n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(nexthop_select_path);\n\nint nexthop_for_each_fib6_nh(struct nexthop *nh,\n\t\t\t     int (*cb)(struct fib6_nh *nh, void *arg),\n\t\t\t     void *arg)\n{\n\tstruct nh_info *nhi;\n\tint err;\n\n\tif (nh->is_group) {\n\t\tstruct nh_group *nhg;\n\t\tint i;\n\n\t\tnhg = rcu_dereference_rtnl(nh->nh_grp);\n\t\tfor (i = 0; i < nhg->num_nh; i++) {\n\t\t\tstruct nh_grp_entry *nhge = &nhg->nh_entries[i];\n\n\t\t\tnhi = rcu_dereference_rtnl(nhge->nh->nh_info);\n\t\t\terr = cb(&nhi->fib6_nh, arg);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t} else {\n\t\tnhi = rcu_dereference_rtnl(nh->nh_info);\n\t\terr = cb(&nhi->fib6_nh, arg);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nexthop_for_each_fib6_nh);\n\nstatic int check_src_addr(const struct in6_addr *saddr,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tif (!ipv6_addr_any(saddr)) {\n\t\tNL_SET_ERR_MSG(extack, \"IPv6 routes using source address can not use nexthop objects\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nint fib6_check_nexthop(struct nexthop *nh, struct fib6_config *cfg,\n\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct nh_info *nhi;\n\tbool is_fdb_nh;\n\n\t \n\tif (cfg && check_src_addr(&cfg->fc_src, extack) < 0)\n\t\treturn -EINVAL;\n\n\tif (nh->is_group) {\n\t\tstruct nh_group *nhg;\n\n\t\tnhg = rtnl_dereference(nh->nh_grp);\n\t\tif (nhg->has_v4)\n\t\t\tgoto no_v4_nh;\n\t\tis_fdb_nh = nhg->fdb_nh;\n\t} else {\n\t\tnhi = rtnl_dereference(nh->nh_info);\n\t\tif (nhi->family == AF_INET)\n\t\t\tgoto no_v4_nh;\n\t\tis_fdb_nh = nhi->fdb_nh;\n\t}\n\n\tif (is_fdb_nh) {\n\t\tNL_SET_ERR_MSG(extack, \"Route cannot point to a fdb nexthop\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\nno_v4_nh:\n\tNL_SET_ERR_MSG(extack, \"IPv6 routes can not use an IPv4 nexthop\");\n\treturn -EINVAL;\n}\nEXPORT_SYMBOL_GPL(fib6_check_nexthop);\n\n \nstatic int fib6_check_nh_list(struct nexthop *old, struct nexthop *new,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct fib6_info *f6i;\n\n\tif (list_empty(&old->f6i_list))\n\t\treturn 0;\n\n\tlist_for_each_entry(f6i, &old->f6i_list, nh_list) {\n\t\tif (check_src_addr(&f6i->fib6_src.addr, extack) < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn fib6_check_nexthop(new, NULL, extack);\n}\n\nstatic int nexthop_check_scope(struct nh_info *nhi, u8 scope,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tif (scope == RT_SCOPE_HOST && nhi->fib_nhc.nhc_gw_family) {\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"Route with host scope can not have a gateway\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (nhi->fib_nhc.nhc_flags & RTNH_F_ONLINK && scope >= RT_SCOPE_LINK) {\n\t\tNL_SET_ERR_MSG(extack, \"Scope mismatch with nexthop\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nint fib_check_nexthop(struct nexthop *nh, u8 scope,\n\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct nh_info *nhi;\n\tint err = 0;\n\n\tif (nh->is_group) {\n\t\tstruct nh_group *nhg;\n\n\t\tnhg = rtnl_dereference(nh->nh_grp);\n\t\tif (nhg->fdb_nh) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Route cannot point to a fdb nexthop\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (scope == RT_SCOPE_HOST) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Route with host scope can not have multiple nexthops\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tnhi = rtnl_dereference(nhg->nh_entries[0].nh->nh_info);\n\t\terr = nexthop_check_scope(nhi, scope, extack);\n\t} else {\n\t\tnhi = rtnl_dereference(nh->nh_info);\n\t\tif (nhi->fdb_nh) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Route cannot point to a fdb nexthop\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\terr = nexthop_check_scope(nhi, scope, extack);\n\t}\n\nout:\n\treturn err;\n}\n\nstatic int fib_check_nh_list(struct nexthop *old, struct nexthop *new,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct fib_info *fi;\n\n\tlist_for_each_entry(fi, &old->fi_list, nh_list) {\n\t\tint err;\n\n\t\terr = fib_check_nexthop(new, fi->fib_scope, extack);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\treturn 0;\n}\n\nstatic bool nh_res_nhge_is_balanced(const struct nh_grp_entry *nhge)\n{\n\treturn nhge->res.count_buckets == nhge->res.wants_buckets;\n}\n\nstatic bool nh_res_nhge_is_ow(const struct nh_grp_entry *nhge)\n{\n\treturn nhge->res.count_buckets > nhge->res.wants_buckets;\n}\n\nstatic bool nh_res_nhge_is_uw(const struct nh_grp_entry *nhge)\n{\n\treturn nhge->res.count_buckets < nhge->res.wants_buckets;\n}\n\nstatic bool nh_res_table_is_balanced(const struct nh_res_table *res_table)\n{\n\treturn list_empty(&res_table->uw_nh_entries);\n}\n\nstatic void nh_res_bucket_unset_nh(struct nh_res_bucket *bucket)\n{\n\tstruct nh_grp_entry *nhge;\n\n\tif (bucket->occupied) {\n\t\tnhge = nh_res_dereference(bucket->nh_entry);\n\t\tnhge->res.count_buckets--;\n\t\tbucket->occupied = false;\n\t}\n}\n\nstatic void nh_res_bucket_set_nh(struct nh_res_bucket *bucket,\n\t\t\t\t struct nh_grp_entry *nhge)\n{\n\tnh_res_bucket_unset_nh(bucket);\n\n\tbucket->occupied = true;\n\trcu_assign_pointer(bucket->nh_entry, nhge);\n\tnhge->res.count_buckets++;\n}\n\nstatic bool nh_res_bucket_should_migrate(struct nh_res_table *res_table,\n\t\t\t\t\t struct nh_res_bucket *bucket,\n\t\t\t\t\t unsigned long *deadline, bool *force)\n{\n\tunsigned long now = jiffies;\n\tstruct nh_grp_entry *nhge;\n\tunsigned long idle_point;\n\n\tif (!bucket->occupied) {\n\t\t \n\t\t*force = true;\n\t\treturn true;\n\t}\n\n\tnhge = nh_res_dereference(bucket->nh_entry);\n\n\t \n\tif (!nh_res_nhge_is_ow(nhge))\n\t\treturn false;\n\n\t \n\n\tidle_point = nh_res_bucket_idle_point(res_table, bucket, now);\n\tif (time_after_eq(now, idle_point)) {\n\t\t \n\t\t*force = false;\n\t\treturn true;\n\t}\n\n\t \n\tif (res_table->unbalanced_timer) {\n\t\tunsigned long unb_point;\n\n\t\tunb_point = nh_res_table_unb_point(res_table);\n\t\tif (time_after(now, unb_point)) {\n\t\t\t \n\t\t\t*force = true;\n\t\t\treturn true;\n\t\t}\n\n\t\tnh_res_time_set_deadline(unb_point, deadline);\n\t}\n\n\tnh_res_time_set_deadline(idle_point, deadline);\n\treturn false;\n}\n\nstatic bool nh_res_bucket_migrate(struct nh_res_table *res_table,\n\t\t\t\t  u16 bucket_index, bool notify,\n\t\t\t\t  bool notify_nl, bool force)\n{\n\tstruct nh_res_bucket *bucket = &res_table->nh_buckets[bucket_index];\n\tstruct nh_grp_entry *new_nhge;\n\tstruct netlink_ext_ack extack;\n\tint err;\n\n\tnew_nhge = list_first_entry_or_null(&res_table->uw_nh_entries,\n\t\t\t\t\t    struct nh_grp_entry,\n\t\t\t\t\t    res.uw_nh_entry);\n\tif (WARN_ON_ONCE(!new_nhge))\n\t\t \n\t\treturn false;\n\n\tif (notify) {\n\t\tstruct nh_grp_entry *old_nhge;\n\n\t\told_nhge = nh_res_dereference(bucket->nh_entry);\n\t\terr = call_nexthop_res_bucket_notifiers(res_table->net,\n\t\t\t\t\t\t\tres_table->nhg_id,\n\t\t\t\t\t\t\tbucket_index, force,\n\t\t\t\t\t\t\told_nhge->nh,\n\t\t\t\t\t\t\tnew_nhge->nh, &extack);\n\t\tif (err) {\n\t\t\tpr_err_ratelimited(\"%s\\n\", extack._msg);\n\t\t\tif (!force)\n\t\t\t\treturn false;\n\t\t\t \n\t\t\tbucket->nh_flags &= ~(RTNH_F_OFFLOAD | RTNH_F_TRAP);\n\t\t}\n\t}\n\n\tnh_res_bucket_set_nh(bucket, new_nhge);\n\tnh_res_bucket_set_idle(res_table, bucket);\n\n\tif (notify_nl)\n\t\tnexthop_bucket_notify(res_table, bucket_index);\n\n\tif (nh_res_nhge_is_balanced(new_nhge))\n\t\tlist_del(&new_nhge->res.uw_nh_entry);\n\treturn true;\n}\n\n#define NH_RES_UPKEEP_DW_MINIMUM_INTERVAL (HZ / 2)\n\nstatic void nh_res_table_upkeep(struct nh_res_table *res_table,\n\t\t\t\tbool notify, bool notify_nl)\n{\n\tunsigned long now = jiffies;\n\tunsigned long deadline;\n\tu16 i;\n\n\t \n\tif (res_table->unbalanced_timer)\n\t\tdeadline = now + res_table->unbalanced_timer;\n\telse\n\t\tdeadline = now + res_table->idle_timer;\n\n\tfor (i = 0; i < res_table->num_nh_buckets; i++) {\n\t\tstruct nh_res_bucket *bucket = &res_table->nh_buckets[i];\n\t\tbool force;\n\n\t\tif (nh_res_bucket_should_migrate(res_table, bucket,\n\t\t\t\t\t\t &deadline, &force)) {\n\t\t\tif (!nh_res_bucket_migrate(res_table, i, notify,\n\t\t\t\t\t\t   notify_nl, force)) {\n\t\t\t\tunsigned long idle_point;\n\n\t\t\t\t \n\t\t\t\tnh_res_bucket_set_busy(bucket);\n\t\t\t\tidle_point = nh_res_bucket_idle_point(res_table,\n\t\t\t\t\t\t\t\t      bucket,\n\t\t\t\t\t\t\t\t      now);\n\t\t\t\tnh_res_time_set_deadline(idle_point, &deadline);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (!nh_res_table_is_balanced(res_table)) {\n\t\tunsigned long now = jiffies;\n\t\tunsigned long min_deadline;\n\n\t\tmin_deadline = now + NH_RES_UPKEEP_DW_MINIMUM_INTERVAL;\n\t\tif (time_before(deadline, min_deadline))\n\t\t\tdeadline = min_deadline;\n\n\t\tqueue_delayed_work(system_power_efficient_wq,\n\t\t\t\t   &res_table->upkeep_dw, deadline - now);\n\t}\n}\n\nstatic void nh_res_table_upkeep_dw(struct work_struct *work)\n{\n\tstruct delayed_work *dw = to_delayed_work(work);\n\tstruct nh_res_table *res_table;\n\n\tres_table = container_of(dw, struct nh_res_table, upkeep_dw);\n\tnh_res_table_upkeep(res_table, true, true);\n}\n\nstatic void nh_res_table_cancel_upkeep(struct nh_res_table *res_table)\n{\n\tcancel_delayed_work_sync(&res_table->upkeep_dw);\n}\n\nstatic void nh_res_group_rebalance(struct nh_group *nhg,\n\t\t\t\t   struct nh_res_table *res_table)\n{\n\tint prev_upper_bound = 0;\n\tint total = 0;\n\tint w = 0;\n\tint i;\n\n\tINIT_LIST_HEAD(&res_table->uw_nh_entries);\n\n\tfor (i = 0; i < nhg->num_nh; ++i)\n\t\ttotal += nhg->nh_entries[i].weight;\n\n\tfor (i = 0; i < nhg->num_nh; ++i) {\n\t\tstruct nh_grp_entry *nhge = &nhg->nh_entries[i];\n\t\tint upper_bound;\n\n\t\tw += nhge->weight;\n\t\tupper_bound = DIV_ROUND_CLOSEST(res_table->num_nh_buckets * w,\n\t\t\t\t\t\ttotal);\n\t\tnhge->res.wants_buckets = upper_bound - prev_upper_bound;\n\t\tprev_upper_bound = upper_bound;\n\n\t\tif (nh_res_nhge_is_uw(nhge)) {\n\t\t\tif (list_empty(&res_table->uw_nh_entries))\n\t\t\t\tres_table->unbalanced_since = jiffies;\n\t\t\tlist_add(&nhge->res.uw_nh_entry,\n\t\t\t\t &res_table->uw_nh_entries);\n\t\t}\n\t}\n}\n\n \nstatic void nh_res_table_migrate_buckets(struct nh_res_table *res_table,\n\t\t\t\t\t struct nh_group *nhg)\n{\n\tu16 i;\n\n\tfor (i = 0; i < res_table->num_nh_buckets; i++) {\n\t\tstruct nh_res_bucket *bucket = &res_table->nh_buckets[i];\n\t\tu32 id = rtnl_dereference(bucket->nh_entry)->nh->id;\n\t\tbool found = false;\n\t\tint j;\n\n\t\tfor (j = 0; j < nhg->num_nh; j++) {\n\t\t\tstruct nh_grp_entry *nhge = &nhg->nh_entries[j];\n\n\t\t\tif (nhge->nh->id == id) {\n\t\t\t\tnh_res_bucket_set_nh(bucket, nhge);\n\t\t\t\tfound = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!found)\n\t\t\tnh_res_bucket_unset_nh(bucket);\n\t}\n}\n\nstatic void replace_nexthop_grp_res(struct nh_group *oldg,\n\t\t\t\t    struct nh_group *newg)\n{\n\t \n\tstruct nh_res_table *old_res_table = rtnl_dereference(oldg->res_table);\n\tunsigned long prev_unbalanced_since = old_res_table->unbalanced_since;\n\tbool prev_has_uw = !list_empty(&old_res_table->uw_nh_entries);\n\n\tnh_res_table_cancel_upkeep(old_res_table);\n\tnh_res_table_migrate_buckets(old_res_table, newg);\n\tnh_res_group_rebalance(newg, old_res_table);\n\tif (prev_has_uw && !list_empty(&old_res_table->uw_nh_entries))\n\t\told_res_table->unbalanced_since = prev_unbalanced_since;\n\tnh_res_table_upkeep(old_res_table, true, false);\n}\n\nstatic void nh_hthr_group_rebalance(struct nh_group *nhg)\n{\n\tint total = 0;\n\tint w = 0;\n\tint i;\n\n\tfor (i = 0; i < nhg->num_nh; ++i)\n\t\ttotal += nhg->nh_entries[i].weight;\n\n\tfor (i = 0; i < nhg->num_nh; ++i) {\n\t\tstruct nh_grp_entry *nhge = &nhg->nh_entries[i];\n\t\tint upper_bound;\n\n\t\tw += nhge->weight;\n\t\tupper_bound = DIV_ROUND_CLOSEST_ULL((u64)w << 31, total) - 1;\n\t\tatomic_set(&nhge->hthr.upper_bound, upper_bound);\n\t}\n}\n\nstatic void remove_nh_grp_entry(struct net *net, struct nh_grp_entry *nhge,\n\t\t\t\tstruct nl_info *nlinfo)\n{\n\tstruct nh_grp_entry *nhges, *new_nhges;\n\tstruct nexthop *nhp = nhge->nh_parent;\n\tstruct netlink_ext_ack extack;\n\tstruct nexthop *nh = nhge->nh;\n\tstruct nh_group *nhg, *newg;\n\tint i, j, err;\n\n\tWARN_ON(!nh);\n\n\tnhg = rtnl_dereference(nhp->nh_grp);\n\tnewg = nhg->spare;\n\n\t \n\tif (nhg->num_nh == 1) {\n\t\tremove_nexthop(net, nhp, nlinfo);\n\t\treturn;\n\t}\n\n\tnewg->has_v4 = false;\n\tnewg->is_multipath = nhg->is_multipath;\n\tnewg->hash_threshold = nhg->hash_threshold;\n\tnewg->resilient = nhg->resilient;\n\tnewg->fdb_nh = nhg->fdb_nh;\n\tnewg->num_nh = nhg->num_nh;\n\n\t \n\tnhges = nhg->nh_entries;\n\tnew_nhges = newg->nh_entries;\n\tfor (i = 0, j = 0; i < nhg->num_nh; ++i) {\n\t\tstruct nh_info *nhi;\n\n\t\t \n\t\tif (nhg->nh_entries[i].nh == nh) {\n\t\t\tnewg->num_nh--;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnhi = rtnl_dereference(nhges[i].nh->nh_info);\n\t\tif (nhi->family == AF_INET)\n\t\t\tnewg->has_v4 = true;\n\n\t\tlist_del(&nhges[i].nh_list);\n\t\tnew_nhges[j].nh_parent = nhges[i].nh_parent;\n\t\tnew_nhges[j].nh = nhges[i].nh;\n\t\tnew_nhges[j].weight = nhges[i].weight;\n\t\tlist_add(&new_nhges[j].nh_list, &new_nhges[j].nh->grp_list);\n\t\tj++;\n\t}\n\n\tif (newg->hash_threshold)\n\t\tnh_hthr_group_rebalance(newg);\n\telse if (newg->resilient)\n\t\treplace_nexthop_grp_res(nhg, newg);\n\n\trcu_assign_pointer(nhp->nh_grp, newg);\n\n\tlist_del(&nhge->nh_list);\n\tnexthop_put(nhge->nh);\n\n\t \n\tif (newg->hash_threshold) {\n\t\terr = call_nexthop_notifiers(net, NEXTHOP_EVENT_REPLACE, nhp,\n\t\t\t\t\t     &extack);\n\t\tif (err)\n\t\t\tpr_err(\"%s\\n\", extack._msg);\n\t}\n\n\tif (nlinfo)\n\t\tnexthop_notify(RTM_NEWNEXTHOP, nhp, nlinfo);\n}\n\nstatic void remove_nexthop_from_groups(struct net *net, struct nexthop *nh,\n\t\t\t\t       struct nl_info *nlinfo)\n{\n\tstruct nh_grp_entry *nhge, *tmp;\n\n\tlist_for_each_entry_safe(nhge, tmp, &nh->grp_list, nh_list)\n\t\tremove_nh_grp_entry(net, nhge, nlinfo);\n\n\t \n\tsynchronize_net();\n}\n\nstatic void remove_nexthop_group(struct nexthop *nh, struct nl_info *nlinfo)\n{\n\tstruct nh_group *nhg = rcu_dereference_rtnl(nh->nh_grp);\n\tstruct nh_res_table *res_table;\n\tint i, num_nh = nhg->num_nh;\n\n\tfor (i = 0; i < num_nh; ++i) {\n\t\tstruct nh_grp_entry *nhge = &nhg->nh_entries[i];\n\n\t\tif (WARN_ON(!nhge->nh))\n\t\t\tcontinue;\n\n\t\tlist_del_init(&nhge->nh_list);\n\t}\n\n\tif (nhg->resilient) {\n\t\tres_table = rtnl_dereference(nhg->res_table);\n\t\tnh_res_table_cancel_upkeep(res_table);\n\t}\n}\n\n \nstatic void __remove_nexthop_fib(struct net *net, struct nexthop *nh)\n{\n\tstruct fib6_info *f6i, *tmp;\n\tbool do_flush = false;\n\tstruct fib_info *fi;\n\n\tlist_for_each_entry(fi, &nh->fi_list, nh_list) {\n\t\tfi->fib_flags |= RTNH_F_DEAD;\n\t\tdo_flush = true;\n\t}\n\tif (do_flush)\n\t\tfib_flush(net);\n\n\t \n\tlist_for_each_entry_safe(f6i, tmp, &nh->f6i_list, nh_list) {\n\t\t \n\t\tfib6_info_hold(f6i);\n\t\tipv6_stub->ip6_del_rt(net, f6i,\n\t\t\t\t      !READ_ONCE(net->ipv4.sysctl_nexthop_compat_mode));\n\t}\n}\n\nstatic void __remove_nexthop(struct net *net, struct nexthop *nh,\n\t\t\t     struct nl_info *nlinfo)\n{\n\t__remove_nexthop_fib(net, nh);\n\n\tif (nh->is_group) {\n\t\tremove_nexthop_group(nh, nlinfo);\n\t} else {\n\t\tstruct nh_info *nhi;\n\n\t\tnhi = rtnl_dereference(nh->nh_info);\n\t\tif (nhi->fib_nhc.nhc_dev)\n\t\t\thlist_del(&nhi->dev_hash);\n\n\t\tremove_nexthop_from_groups(net, nh, nlinfo);\n\t}\n}\n\nstatic void remove_nexthop(struct net *net, struct nexthop *nh,\n\t\t\t   struct nl_info *nlinfo)\n{\n\tcall_nexthop_notifiers(net, NEXTHOP_EVENT_DEL, nh, NULL);\n\n\t \n\trb_erase(&nh->rb_node, &net->nexthop.rb_root);\n\n\tif (nlinfo)\n\t\tnexthop_notify(RTM_DELNEXTHOP, nh, nlinfo);\n\n\t__remove_nexthop(net, nh, nlinfo);\n\tnh_base_seq_inc(net);\n\n\tnexthop_put(nh);\n}\n\n \nstatic void nh_rt_cache_flush(struct net *net, struct nexthop *nh,\n\t\t\t      struct nexthop *replaced_nh)\n{\n\tstruct fib6_info *f6i;\n\tstruct nh_group *nhg;\n\tint i;\n\n\tif (!list_empty(&nh->fi_list))\n\t\trt_cache_flush(net);\n\n\tlist_for_each_entry(f6i, &nh->f6i_list, nh_list)\n\t\tipv6_stub->fib6_update_sernum(net, f6i);\n\n\t \n\tif (!replaced_nh->is_group)\n\t\treturn;\n\n\tnhg = rtnl_dereference(replaced_nh->nh_grp);\n\tfor (i = 0; i < nhg->num_nh; i++) {\n\t\tstruct nh_grp_entry *nhge = &nhg->nh_entries[i];\n\t\tstruct nh_info *nhi = rtnl_dereference(nhge->nh->nh_info);\n\n\t\tif (nhi->family == AF_INET6)\n\t\t\tipv6_stub->fib6_nh_release_dsts(&nhi->fib6_nh);\n\t}\n}\n\nstatic int replace_nexthop_grp(struct net *net, struct nexthop *old,\n\t\t\t       struct nexthop *new, const struct nh_config *cfg,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct nh_res_table *tmp_table = NULL;\n\tstruct nh_res_table *new_res_table;\n\tstruct nh_res_table *old_res_table;\n\tstruct nh_group *oldg, *newg;\n\tint i, err;\n\n\tif (!new->is_group) {\n\t\tNL_SET_ERR_MSG(extack, \"Can not replace a nexthop group with a nexthop.\");\n\t\treturn -EINVAL;\n\t}\n\n\toldg = rtnl_dereference(old->nh_grp);\n\tnewg = rtnl_dereference(new->nh_grp);\n\n\tif (newg->hash_threshold != oldg->hash_threshold) {\n\t\tNL_SET_ERR_MSG(extack, \"Can not replace a nexthop group with one of a different type.\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (newg->hash_threshold) {\n\t\terr = call_nexthop_notifiers(net, NEXTHOP_EVENT_REPLACE, new,\n\t\t\t\t\t     extack);\n\t\tif (err)\n\t\t\treturn err;\n\t} else if (newg->resilient) {\n\t\tnew_res_table = rtnl_dereference(newg->res_table);\n\t\told_res_table = rtnl_dereference(oldg->res_table);\n\n\t\t \n\t\tif (cfg->nh_grp_res_has_num_buckets &&\n\t\t    cfg->nh_grp_res_num_buckets !=\n\t\t    old_res_table->num_nh_buckets) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Can not change number of buckets of a resilient nexthop group.\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\terr = call_nexthop_res_table_notifiers(net, new, extack);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (cfg->nh_grp_res_has_idle_timer)\n\t\t\told_res_table->idle_timer = cfg->nh_grp_res_idle_timer;\n\t\tif (cfg->nh_grp_res_has_unbalanced_timer)\n\t\t\told_res_table->unbalanced_timer =\n\t\t\t\tcfg->nh_grp_res_unbalanced_timer;\n\n\t\treplace_nexthop_grp_res(oldg, newg);\n\n\t\ttmp_table = new_res_table;\n\t\trcu_assign_pointer(newg->res_table, old_res_table);\n\t\trcu_assign_pointer(newg->spare->res_table, old_res_table);\n\t}\n\n\t \n\tfor (i = 0; i < newg->num_nh; i++)\n\t\tnewg->nh_entries[i].nh_parent = old;\n\n\trcu_assign_pointer(old->nh_grp, newg);\n\n\t \n\tsynchronize_net();\n\n\tif (newg->resilient) {\n\t\trcu_assign_pointer(oldg->res_table, tmp_table);\n\t\trcu_assign_pointer(oldg->spare->res_table, tmp_table);\n\t}\n\n\tfor (i = 0; i < oldg->num_nh; i++)\n\t\toldg->nh_entries[i].nh_parent = new;\n\n\trcu_assign_pointer(new->nh_grp, oldg);\n\n\treturn 0;\n}\n\nstatic void nh_group_v4_update(struct nh_group *nhg)\n{\n\tstruct nh_grp_entry *nhges;\n\tbool has_v4 = false;\n\tint i;\n\n\tnhges = nhg->nh_entries;\n\tfor (i = 0; i < nhg->num_nh; i++) {\n\t\tstruct nh_info *nhi;\n\n\t\tnhi = rtnl_dereference(nhges[i].nh->nh_info);\n\t\tif (nhi->family == AF_INET)\n\t\t\thas_v4 = true;\n\t}\n\tnhg->has_v4 = has_v4;\n}\n\nstatic int replace_nexthop_single_notify_res(struct net *net,\n\t\t\t\t\t     struct nh_res_table *res_table,\n\t\t\t\t\t     struct nexthop *old,\n\t\t\t\t\t     struct nh_info *oldi,\n\t\t\t\t\t     struct nh_info *newi,\n\t\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\tu32 nhg_id = res_table->nhg_id;\n\tint err;\n\tu16 i;\n\n\tfor (i = 0; i < res_table->num_nh_buckets; i++) {\n\t\tstruct nh_res_bucket *bucket = &res_table->nh_buckets[i];\n\t\tstruct nh_grp_entry *nhge;\n\n\t\tnhge = rtnl_dereference(bucket->nh_entry);\n\t\tif (nhge->nh == old) {\n\t\t\terr = __call_nexthop_res_bucket_notifiers(net, nhg_id,\n\t\t\t\t\t\t\t\t  i, true,\n\t\t\t\t\t\t\t\t  oldi, newi,\n\t\t\t\t\t\t\t\t  extack);\n\t\t\tif (err)\n\t\t\t\tgoto err_notify;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_notify:\n\twhile (i-- > 0) {\n\t\tstruct nh_res_bucket *bucket = &res_table->nh_buckets[i];\n\t\tstruct nh_grp_entry *nhge;\n\n\t\tnhge = rtnl_dereference(bucket->nh_entry);\n\t\tif (nhge->nh == old)\n\t\t\t__call_nexthop_res_bucket_notifiers(net, nhg_id, i,\n\t\t\t\t\t\t\t    true, newi, oldi,\n\t\t\t\t\t\t\t    extack);\n\t}\n\treturn err;\n}\n\nstatic int replace_nexthop_single_notify(struct net *net,\n\t\t\t\t\t struct nexthop *group_nh,\n\t\t\t\t\t struct nexthop *old,\n\t\t\t\t\t struct nh_info *oldi,\n\t\t\t\t\t struct nh_info *newi,\n\t\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct nh_group *nhg = rtnl_dereference(group_nh->nh_grp);\n\tstruct nh_res_table *res_table;\n\n\tif (nhg->hash_threshold) {\n\t\treturn call_nexthop_notifiers(net, NEXTHOP_EVENT_REPLACE,\n\t\t\t\t\t      group_nh, extack);\n\t} else if (nhg->resilient) {\n\t\tres_table = rtnl_dereference(nhg->res_table);\n\t\treturn replace_nexthop_single_notify_res(net, res_table,\n\t\t\t\t\t\t\t old, oldi, newi,\n\t\t\t\t\t\t\t extack);\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int replace_nexthop_single(struct net *net, struct nexthop *old,\n\t\t\t\t  struct nexthop *new,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tu8 old_protocol, old_nh_flags;\n\tstruct nh_info *oldi, *newi;\n\tstruct nh_grp_entry *nhge;\n\tint err;\n\n\tif (new->is_group) {\n\t\tNL_SET_ERR_MSG(extack, \"Can not replace a nexthop with a nexthop group.\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = call_nexthop_notifiers(net, NEXTHOP_EVENT_REPLACE, new, extack);\n\tif (err)\n\t\treturn err;\n\n\t \n\tnew->nh_flags |= old->nh_flags & (RTNH_F_OFFLOAD | RTNH_F_TRAP);\n\n\toldi = rtnl_dereference(old->nh_info);\n\tnewi = rtnl_dereference(new->nh_info);\n\n\tnewi->nh_parent = old;\n\toldi->nh_parent = new;\n\n\told_protocol = old->protocol;\n\told_nh_flags = old->nh_flags;\n\n\told->protocol = new->protocol;\n\told->nh_flags = new->nh_flags;\n\n\trcu_assign_pointer(old->nh_info, newi);\n\trcu_assign_pointer(new->nh_info, oldi);\n\n\t \n\tlist_for_each_entry(nhge, &old->grp_list, nh_list) {\n\t\tstruct nexthop *nhp = nhge->nh_parent;\n\n\t\terr = replace_nexthop_single_notify(net, nhp, old, oldi, newi,\n\t\t\t\t\t\t    extack);\n\t\tif (err)\n\t\t\tgoto err_notify;\n\t}\n\n\t \n\tif (oldi->family == AF_INET && newi->family == AF_INET6) {\n\t\tlist_for_each_entry(nhge, &old->grp_list, nh_list) {\n\t\t\tstruct nexthop *nhp = nhge->nh_parent;\n\t\t\tstruct nh_group *nhg;\n\n\t\t\tnhg = rtnl_dereference(nhp->nh_grp);\n\t\t\tnh_group_v4_update(nhg);\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_notify:\n\trcu_assign_pointer(new->nh_info, newi);\n\trcu_assign_pointer(old->nh_info, oldi);\n\told->nh_flags = old_nh_flags;\n\told->protocol = old_protocol;\n\toldi->nh_parent = old;\n\tnewi->nh_parent = new;\n\tlist_for_each_entry_continue_reverse(nhge, &old->grp_list, nh_list) {\n\t\tstruct nexthop *nhp = nhge->nh_parent;\n\n\t\treplace_nexthop_single_notify(net, nhp, old, newi, oldi, NULL);\n\t}\n\tcall_nexthop_notifiers(net, NEXTHOP_EVENT_REPLACE, old, extack);\n\treturn err;\n}\n\nstatic void __nexthop_replace_notify(struct net *net, struct nexthop *nh,\n\t\t\t\t     struct nl_info *info)\n{\n\tstruct fib6_info *f6i;\n\n\tif (!list_empty(&nh->fi_list)) {\n\t\tstruct fib_info *fi;\n\n\t\t \n\t\tlist_for_each_entry(fi, &nh->fi_list, nh_list)\n\t\t\tfi->nh_updated = true;\n\n\t\tfib_info_notify_update(net, info);\n\n\t\tlist_for_each_entry(fi, &nh->fi_list, nh_list)\n\t\t\tfi->nh_updated = false;\n\t}\n\n\tlist_for_each_entry(f6i, &nh->f6i_list, nh_list)\n\t\tipv6_stub->fib6_rt_update(net, f6i, info);\n}\n\n \nstatic void nexthop_replace_notify(struct net *net, struct nexthop *nh,\n\t\t\t\t   struct nl_info *info)\n{\n\tstruct nh_grp_entry *nhge;\n\n\t__nexthop_replace_notify(net, nh, info);\n\n\tlist_for_each_entry(nhge, &nh->grp_list, nh_list)\n\t\t__nexthop_replace_notify(net, nhge->nh_parent, info);\n}\n\nstatic int replace_nexthop(struct net *net, struct nexthop *old,\n\t\t\t   struct nexthop *new, const struct nh_config *cfg,\n\t\t\t   struct netlink_ext_ack *extack)\n{\n\tbool new_is_reject = false;\n\tstruct nh_grp_entry *nhge;\n\tint err;\n\n\t \n\terr = fib_check_nh_list(old, new, extack);\n\tif (err)\n\t\treturn err;\n\n\terr = fib6_check_nh_list(old, new, extack);\n\tif (err)\n\t\treturn err;\n\n\tif (!new->is_group) {\n\t\tstruct nh_info *nhi = rtnl_dereference(new->nh_info);\n\n\t\tnew_is_reject = nhi->reject_nh;\n\t}\n\n\tlist_for_each_entry(nhge, &old->grp_list, nh_list) {\n\t\t \n\t\tif (new_is_reject &&\n\t\t    nexthop_num_path(nhge->nh_parent) > 1) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Blackhole nexthop can not be a member of a group with more than one path\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\terr = fib_check_nh_list(nhge->nh_parent, new, extack);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = fib6_check_nh_list(nhge->nh_parent, new, extack);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (old->is_group)\n\t\terr = replace_nexthop_grp(net, old, new, cfg, extack);\n\telse\n\t\terr = replace_nexthop_single(net, old, new, extack);\n\n\tif (!err) {\n\t\tnh_rt_cache_flush(net, old, new);\n\n\t\t__remove_nexthop(net, new, NULL);\n\t\tnexthop_put(new);\n\t}\n\n\treturn err;\n}\n\n \nstatic int insert_nexthop(struct net *net, struct nexthop *new_nh,\n\t\t\t  struct nh_config *cfg, struct netlink_ext_ack *extack)\n{\n\tstruct rb_node **pp, *parent = NULL, *next;\n\tstruct rb_root *root = &net->nexthop.rb_root;\n\tbool replace = !!(cfg->nlflags & NLM_F_REPLACE);\n\tbool create = !!(cfg->nlflags & NLM_F_CREATE);\n\tu32 new_id = new_nh->id;\n\tint replace_notify = 0;\n\tint rc = -EEXIST;\n\n\tpp = &root->rb_node;\n\twhile (1) {\n\t\tstruct nexthop *nh;\n\n\t\tnext = *pp;\n\t\tif (!next)\n\t\t\tbreak;\n\n\t\tparent = next;\n\n\t\tnh = rb_entry(parent, struct nexthop, rb_node);\n\t\tif (new_id < nh->id) {\n\t\t\tpp = &next->rb_left;\n\t\t} else if (new_id > nh->id) {\n\t\t\tpp = &next->rb_right;\n\t\t} else if (replace) {\n\t\t\trc = replace_nexthop(net, nh, new_nh, cfg, extack);\n\t\t\tif (!rc) {\n\t\t\t\tnew_nh = nh;  \n\t\t\t\treplace_notify = 1;\n\t\t\t}\n\t\t\tgoto out;\n\t\t} else {\n\t\t\t \n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (replace && !create) {\n\t\tNL_SET_ERR_MSG(extack, \"Replace specified without create and no entry exists\");\n\t\trc = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (new_nh->is_group) {\n\t\tstruct nh_group *nhg = rtnl_dereference(new_nh->nh_grp);\n\t\tstruct nh_res_table *res_table;\n\n\t\tif (nhg->resilient) {\n\t\t\tres_table = rtnl_dereference(nhg->res_table);\n\n\t\t\t \n\t\t\tif (!cfg->nh_grp_res_has_num_buckets) {\n\t\t\t\tNL_SET_ERR_MSG(extack, \"Number of buckets not specified for nexthop group insertion\");\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tnh_res_group_rebalance(nhg, res_table);\n\n\t\t\t \n\t\t\tnh_res_table_upkeep(res_table, false, false);\n\t\t}\n\t}\n\n\trb_link_node_rcu(&new_nh->rb_node, parent, pp);\n\trb_insert_color(&new_nh->rb_node, root);\n\n\t \n\trc = call_nexthop_notifiers(net, NEXTHOP_EVENT_REPLACE, new_nh, extack);\n\tif (rc)\n\t\trb_erase(&new_nh->rb_node, &net->nexthop.rb_root);\n\nout:\n\tif (!rc) {\n\t\tnh_base_seq_inc(net);\n\t\tnexthop_notify(RTM_NEWNEXTHOP, new_nh, &cfg->nlinfo);\n\t\tif (replace_notify &&\n\t\t    READ_ONCE(net->ipv4.sysctl_nexthop_compat_mode))\n\t\t\tnexthop_replace_notify(net, new_nh, &cfg->nlinfo);\n\t}\n\n\treturn rc;\n}\n\n \n \nstatic void nexthop_flush_dev(struct net_device *dev, unsigned long event)\n{\n\tunsigned int hash = nh_dev_hashfn(dev->ifindex);\n\tstruct net *net = dev_net(dev);\n\tstruct hlist_head *head = &net->nexthop.devhash[hash];\n\tstruct hlist_node *n;\n\tstruct nh_info *nhi;\n\n\thlist_for_each_entry_safe(nhi, n, head, dev_hash) {\n\t\tif (nhi->fib_nhc.nhc_dev != dev)\n\t\t\tcontinue;\n\n\t\tif (nhi->reject_nh &&\n\t\t    (event == NETDEV_DOWN || event == NETDEV_CHANGE))\n\t\t\tcontinue;\n\n\t\tremove_nexthop(net, nhi->nh_parent, NULL);\n\t}\n}\n\n \nstatic void flush_all_nexthops(struct net *net)\n{\n\tstruct rb_root *root = &net->nexthop.rb_root;\n\tstruct rb_node *node;\n\tstruct nexthop *nh;\n\n\twhile ((node = rb_first(root))) {\n\t\tnh = rb_entry(node, struct nexthop, rb_node);\n\t\tremove_nexthop(net, nh, NULL);\n\t\tcond_resched();\n\t}\n}\n\nstatic struct nexthop *nexthop_create_group(struct net *net,\n\t\t\t\t\t    struct nh_config *cfg)\n{\n\tstruct nlattr *grps_attr = cfg->nh_grp;\n\tstruct nexthop_grp *entry = nla_data(grps_attr);\n\tu16 num_nh = nla_len(grps_attr) / sizeof(*entry);\n\tstruct nh_group *nhg;\n\tstruct nexthop *nh;\n\tint err;\n\tint i;\n\n\tif (WARN_ON(!num_nh))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tnh = nexthop_alloc();\n\tif (!nh)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tnh->is_group = 1;\n\n\tnhg = nexthop_grp_alloc(num_nh);\n\tif (!nhg) {\n\t\tkfree(nh);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\t \n\tnhg->spare = nexthop_grp_alloc(num_nh);\n\tif (!nhg->spare) {\n\t\tkfree(nhg);\n\t\tkfree(nh);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tnhg->spare->spare = nhg;\n\n\tfor (i = 0; i < nhg->num_nh; ++i) {\n\t\tstruct nexthop *nhe;\n\t\tstruct nh_info *nhi;\n\n\t\tnhe = nexthop_find_by_id(net, entry[i].id);\n\t\tif (!nexthop_get(nhe)) {\n\t\t\terr = -ENOENT;\n\t\t\tgoto out_no_nh;\n\t\t}\n\n\t\tnhi = rtnl_dereference(nhe->nh_info);\n\t\tif (nhi->family == AF_INET)\n\t\t\tnhg->has_v4 = true;\n\n\t\tnhg->nh_entries[i].nh = nhe;\n\t\tnhg->nh_entries[i].weight = entry[i].weight + 1;\n\t\tlist_add(&nhg->nh_entries[i].nh_list, &nhe->grp_list);\n\t\tnhg->nh_entries[i].nh_parent = nh;\n\t}\n\n\tif (cfg->nh_grp_type == NEXTHOP_GRP_TYPE_MPATH) {\n\t\tnhg->hash_threshold = 1;\n\t\tnhg->is_multipath = true;\n\t} else if (cfg->nh_grp_type == NEXTHOP_GRP_TYPE_RES) {\n\t\tstruct nh_res_table *res_table;\n\n\t\tres_table = nexthop_res_table_alloc(net, cfg->nh_id, cfg);\n\t\tif (!res_table) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_no_nh;\n\t\t}\n\n\t\trcu_assign_pointer(nhg->spare->res_table, res_table);\n\t\trcu_assign_pointer(nhg->res_table, res_table);\n\t\tnhg->resilient = true;\n\t\tnhg->is_multipath = true;\n\t}\n\n\tWARN_ON_ONCE(nhg->hash_threshold + nhg->resilient != 1);\n\n\tif (nhg->hash_threshold)\n\t\tnh_hthr_group_rebalance(nhg);\n\n\tif (cfg->nh_fdb)\n\t\tnhg->fdb_nh = 1;\n\n\trcu_assign_pointer(nh->nh_grp, nhg);\n\n\treturn nh;\n\nout_no_nh:\n\tfor (i--; i >= 0; --i) {\n\t\tlist_del(&nhg->nh_entries[i].nh_list);\n\t\tnexthop_put(nhg->nh_entries[i].nh);\n\t}\n\n\tkfree(nhg->spare);\n\tkfree(nhg);\n\tkfree(nh);\n\n\treturn ERR_PTR(err);\n}\n\nstatic int nh_create_ipv4(struct net *net, struct nexthop *nh,\n\t\t\t  struct nh_info *nhi, struct nh_config *cfg,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct fib_nh *fib_nh = &nhi->fib_nh;\n\tstruct fib_config fib_cfg = {\n\t\t.fc_oif   = cfg->nh_ifindex,\n\t\t.fc_gw4   = cfg->gw.ipv4,\n\t\t.fc_gw_family = cfg->gw.ipv4 ? AF_INET : 0,\n\t\t.fc_flags = cfg->nh_flags,\n\t\t.fc_nlinfo = cfg->nlinfo,\n\t\t.fc_encap = cfg->nh_encap,\n\t\t.fc_encap_type = cfg->nh_encap_type,\n\t};\n\tu32 tb_id = (cfg->dev ? l3mdev_fib_table(cfg->dev) : RT_TABLE_MAIN);\n\tint err;\n\n\terr = fib_nh_init(net, fib_nh, &fib_cfg, 1, extack);\n\tif (err) {\n\t\tfib_nh_release(net, fib_nh);\n\t\tgoto out;\n\t}\n\n\tif (nhi->fdb_nh)\n\t\tgoto out;\n\n\t \n\terr = fib_check_nh(net, fib_nh, tb_id, 0, extack);\n\tif (!err) {\n\t\tnh->nh_flags = fib_nh->fib_nh_flags;\n\t\tfib_info_update_nhc_saddr(net, &fib_nh->nh_common,\n\t\t\t\t\t  !fib_nh->fib_nh_scope ? 0 : fib_nh->fib_nh_scope - 1);\n\t} else {\n\t\tfib_nh_release(net, fib_nh);\n\t}\nout:\n\treturn err;\n}\n\nstatic int nh_create_ipv6(struct net *net,  struct nexthop *nh,\n\t\t\t  struct nh_info *nhi, struct nh_config *cfg,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct fib6_nh *fib6_nh = &nhi->fib6_nh;\n\tstruct fib6_config fib6_cfg = {\n\t\t.fc_table = l3mdev_fib_table(cfg->dev),\n\t\t.fc_ifindex = cfg->nh_ifindex,\n\t\t.fc_gateway = cfg->gw.ipv6,\n\t\t.fc_flags = cfg->nh_flags,\n\t\t.fc_nlinfo = cfg->nlinfo,\n\t\t.fc_encap = cfg->nh_encap,\n\t\t.fc_encap_type = cfg->nh_encap_type,\n\t\t.fc_is_fdb = cfg->nh_fdb,\n\t};\n\tint err;\n\n\tif (!ipv6_addr_any(&cfg->gw.ipv6))\n\t\tfib6_cfg.fc_flags |= RTF_GATEWAY;\n\n\t \n\terr = ipv6_stub->fib6_nh_init(net, fib6_nh, &fib6_cfg, GFP_KERNEL,\n\t\t\t\t      extack);\n\tif (err) {\n\t\t \n\t\tif (err == -EAFNOSUPPORT)\n\t\t\tgoto out;\n\t\tipv6_stub->fib6_nh_release(fib6_nh);\n\t} else {\n\t\tnh->nh_flags = fib6_nh->fib_nh_flags;\n\t}\nout:\n\treturn err;\n}\n\nstatic struct nexthop *nexthop_create(struct net *net, struct nh_config *cfg,\n\t\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct nh_info *nhi;\n\tstruct nexthop *nh;\n\tint err = 0;\n\n\tnh = nexthop_alloc();\n\tif (!nh)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tnhi = kzalloc(sizeof(*nhi), GFP_KERNEL);\n\tif (!nhi) {\n\t\tkfree(nh);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tnh->nh_flags = cfg->nh_flags;\n\tnh->net = net;\n\n\tnhi->nh_parent = nh;\n\tnhi->family = cfg->nh_family;\n\tnhi->fib_nhc.nhc_scope = RT_SCOPE_LINK;\n\n\tif (cfg->nh_fdb)\n\t\tnhi->fdb_nh = 1;\n\n\tif (cfg->nh_blackhole) {\n\t\tnhi->reject_nh = 1;\n\t\tcfg->nh_ifindex = net->loopback_dev->ifindex;\n\t}\n\n\tswitch (cfg->nh_family) {\n\tcase AF_INET:\n\t\terr = nh_create_ipv4(net, nh, nhi, cfg, extack);\n\t\tbreak;\n\tcase AF_INET6:\n\t\terr = nh_create_ipv6(net, nh, nhi, cfg, extack);\n\t\tbreak;\n\t}\n\n\tif (err) {\n\t\tkfree(nhi);\n\t\tkfree(nh);\n\t\treturn ERR_PTR(err);\n\t}\n\n\t \n\tif (!nhi->fdb_nh)\n\t\tnexthop_devhash_add(net, nhi);\n\n\trcu_assign_pointer(nh->nh_info, nhi);\n\n\treturn nh;\n}\n\n \nstatic struct nexthop *nexthop_add(struct net *net, struct nh_config *cfg,\n\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct nexthop *nh;\n\tint err;\n\n\tif (cfg->nlflags & NLM_F_REPLACE && !cfg->nh_id) {\n\t\tNL_SET_ERR_MSG(extack, \"Replace requires nexthop id\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!cfg->nh_id) {\n\t\tcfg->nh_id = nh_find_unused_id(net);\n\t\tif (!cfg->nh_id) {\n\t\t\tNL_SET_ERR_MSG(extack, \"No unused id\");\n\t\t\treturn ERR_PTR(-EINVAL);\n\t\t}\n\t}\n\n\tif (cfg->nh_grp)\n\t\tnh = nexthop_create_group(net, cfg);\n\telse\n\t\tnh = nexthop_create(net, cfg, extack);\n\n\tif (IS_ERR(nh))\n\t\treturn nh;\n\n\trefcount_set(&nh->refcnt, 1);\n\tnh->id = cfg->nh_id;\n\tnh->protocol = cfg->nh_protocol;\n\tnh->net = net;\n\n\terr = insert_nexthop(net, nh, cfg, extack);\n\tif (err) {\n\t\t__remove_nexthop(net, nh, NULL);\n\t\tnexthop_put(nh);\n\t\tnh = ERR_PTR(err);\n\t}\n\n\treturn nh;\n}\n\nstatic int rtm_nh_get_timer(struct nlattr *attr, unsigned long fallback,\n\t\t\t    unsigned long *timer_p, bool *has_p,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tunsigned long timer;\n\tu32 value;\n\n\tif (!attr) {\n\t\t*timer_p = fallback;\n\t\t*has_p = false;\n\t\treturn 0;\n\t}\n\n\tvalue = nla_get_u32(attr);\n\ttimer = clock_t_to_jiffies(value);\n\tif (timer == ~0UL) {\n\t\tNL_SET_ERR_MSG(extack, \"Timer value too large\");\n\t\treturn -EINVAL;\n\t}\n\n\t*timer_p = timer;\n\t*has_p = true;\n\treturn 0;\n}\n\nstatic int rtm_to_nh_config_grp_res(struct nlattr *res, struct nh_config *cfg,\n\t\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct nlattr *tb[ARRAY_SIZE(rtm_nh_res_policy_new)] = {};\n\tint err;\n\n\tif (res) {\n\t\terr = nla_parse_nested(tb,\n\t\t\t\t       ARRAY_SIZE(rtm_nh_res_policy_new) - 1,\n\t\t\t\t       res, rtm_nh_res_policy_new, extack);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\tif (tb[NHA_RES_GROUP_BUCKETS]) {\n\t\tcfg->nh_grp_res_num_buckets =\n\t\t\tnla_get_u16(tb[NHA_RES_GROUP_BUCKETS]);\n\t\tcfg->nh_grp_res_has_num_buckets = true;\n\t\tif (!cfg->nh_grp_res_num_buckets) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Number of buckets needs to be non-0\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\terr = rtm_nh_get_timer(tb[NHA_RES_GROUP_IDLE_TIMER],\n\t\t\t       NH_RES_DEFAULT_IDLE_TIMER,\n\t\t\t       &cfg->nh_grp_res_idle_timer,\n\t\t\t       &cfg->nh_grp_res_has_idle_timer,\n\t\t\t       extack);\n\tif (err)\n\t\treturn err;\n\n\treturn rtm_nh_get_timer(tb[NHA_RES_GROUP_UNBALANCED_TIMER],\n\t\t\t\tNH_RES_DEFAULT_UNBALANCED_TIMER,\n\t\t\t\t&cfg->nh_grp_res_unbalanced_timer,\n\t\t\t\t&cfg->nh_grp_res_has_unbalanced_timer,\n\t\t\t\textack);\n}\n\nstatic int rtm_to_nh_config(struct net *net, struct sk_buff *skb,\n\t\t\t    struct nlmsghdr *nlh, struct nh_config *cfg,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct nhmsg *nhm = nlmsg_data(nlh);\n\tstruct nlattr *tb[ARRAY_SIZE(rtm_nh_policy_new)];\n\tint err;\n\n\terr = nlmsg_parse(nlh, sizeof(*nhm), tb,\n\t\t\t  ARRAY_SIZE(rtm_nh_policy_new) - 1,\n\t\t\t  rtm_nh_policy_new, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = -EINVAL;\n\tif (nhm->resvd || nhm->nh_scope) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid values in ancillary header\");\n\t\tgoto out;\n\t}\n\tif (nhm->nh_flags & ~NEXTHOP_VALID_USER_FLAGS) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid nexthop flags in ancillary header\");\n\t\tgoto out;\n\t}\n\n\tswitch (nhm->nh_family) {\n\tcase AF_INET:\n\tcase AF_INET6:\n\t\tbreak;\n\tcase AF_UNSPEC:\n\t\tif (tb[NHA_GROUP])\n\t\t\tbreak;\n\t\tfallthrough;\n\tdefault:\n\t\tNL_SET_ERR_MSG(extack, \"Invalid address family\");\n\t\tgoto out;\n\t}\n\n\tmemset(cfg, 0, sizeof(*cfg));\n\tcfg->nlflags = nlh->nlmsg_flags;\n\tcfg->nlinfo.portid = NETLINK_CB(skb).portid;\n\tcfg->nlinfo.nlh = nlh;\n\tcfg->nlinfo.nl_net = net;\n\n\tcfg->nh_family = nhm->nh_family;\n\tcfg->nh_protocol = nhm->nh_protocol;\n\tcfg->nh_flags = nhm->nh_flags;\n\n\tif (tb[NHA_ID])\n\t\tcfg->nh_id = nla_get_u32(tb[NHA_ID]);\n\n\tif (tb[NHA_FDB]) {\n\t\tif (tb[NHA_OIF] || tb[NHA_BLACKHOLE] ||\n\t\t    tb[NHA_ENCAP]   || tb[NHA_ENCAP_TYPE]) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Fdb attribute can not be used with encap, oif or blackhole\");\n\t\t\tgoto out;\n\t\t}\n\t\tif (nhm->nh_flags) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Unsupported nexthop flags in ancillary header\");\n\t\t\tgoto out;\n\t\t}\n\t\tcfg->nh_fdb = nla_get_flag(tb[NHA_FDB]);\n\t}\n\n\tif (tb[NHA_GROUP]) {\n\t\tif (nhm->nh_family != AF_UNSPEC) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid family for group\");\n\t\t\tgoto out;\n\t\t}\n\t\tcfg->nh_grp = tb[NHA_GROUP];\n\n\t\tcfg->nh_grp_type = NEXTHOP_GRP_TYPE_MPATH;\n\t\tif (tb[NHA_GROUP_TYPE])\n\t\t\tcfg->nh_grp_type = nla_get_u16(tb[NHA_GROUP_TYPE]);\n\n\t\tif (cfg->nh_grp_type > NEXTHOP_GRP_TYPE_MAX) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid group type\");\n\t\t\tgoto out;\n\t\t}\n\t\terr = nh_check_attr_group(net, tb, ARRAY_SIZE(tb),\n\t\t\t\t\t  cfg->nh_grp_type, extack);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tif (cfg->nh_grp_type == NEXTHOP_GRP_TYPE_RES)\n\t\t\terr = rtm_to_nh_config_grp_res(tb[NHA_RES_GROUP],\n\t\t\t\t\t\t       cfg, extack);\n\n\t\t \n\t\tgoto out;\n\t}\n\n\tif (tb[NHA_BLACKHOLE]) {\n\t\tif (tb[NHA_GATEWAY] || tb[NHA_OIF] ||\n\t\t    tb[NHA_ENCAP]   || tb[NHA_ENCAP_TYPE] || tb[NHA_FDB]) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Blackhole attribute can not be used with gateway, oif, encap or fdb\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tcfg->nh_blackhole = 1;\n\t\terr = 0;\n\t\tgoto out;\n\t}\n\n\tif (!cfg->nh_fdb && !tb[NHA_OIF]) {\n\t\tNL_SET_ERR_MSG(extack, \"Device attribute required for non-blackhole and non-fdb nexthops\");\n\t\tgoto out;\n\t}\n\n\tif (!cfg->nh_fdb && tb[NHA_OIF]) {\n\t\tcfg->nh_ifindex = nla_get_u32(tb[NHA_OIF]);\n\t\tif (cfg->nh_ifindex)\n\t\t\tcfg->dev = __dev_get_by_index(net, cfg->nh_ifindex);\n\n\t\tif (!cfg->dev) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid device index\");\n\t\t\tgoto out;\n\t\t} else if (!(cfg->dev->flags & IFF_UP)) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Nexthop device is not up\");\n\t\t\terr = -ENETDOWN;\n\t\t\tgoto out;\n\t\t} else if (!netif_carrier_ok(cfg->dev)) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Carrier for nexthop device is down\");\n\t\t\terr = -ENETDOWN;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\terr = -EINVAL;\n\tif (tb[NHA_GATEWAY]) {\n\t\tstruct nlattr *gwa = tb[NHA_GATEWAY];\n\n\t\tswitch (cfg->nh_family) {\n\t\tcase AF_INET:\n\t\t\tif (nla_len(gwa) != sizeof(u32)) {\n\t\t\t\tNL_SET_ERR_MSG(extack, \"Invalid gateway\");\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tcfg->gw.ipv4 = nla_get_be32(gwa);\n\t\t\tbreak;\n\t\tcase AF_INET6:\n\t\t\tif (nla_len(gwa) != sizeof(struct in6_addr)) {\n\t\t\t\tNL_SET_ERR_MSG(extack, \"Invalid gateway\");\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tcfg->gw.ipv6 = nla_get_in6_addr(gwa);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t       \"Unknown address family for gateway\");\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\t \n\t\tif (cfg->nh_flags & RTNH_F_ONLINK) {\n\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t       \"ONLINK flag can not be set for nexthop without a gateway\");\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (tb[NHA_ENCAP]) {\n\t\tcfg->nh_encap = tb[NHA_ENCAP];\n\n\t\tif (!tb[NHA_ENCAP_TYPE]) {\n\t\t\tNL_SET_ERR_MSG(extack, \"LWT encapsulation type is missing\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tcfg->nh_encap_type = nla_get_u16(tb[NHA_ENCAP_TYPE]);\n\t\terr = lwtunnel_valid_encap_type(cfg->nh_encap_type, extack);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\n\t} else if (tb[NHA_ENCAP_TYPE]) {\n\t\tNL_SET_ERR_MSG(extack, \"LWT encapsulation attribute is missing\");\n\t\tgoto out;\n\t}\n\n\n\terr = 0;\nout:\n\treturn err;\n}\n\n \nstatic int rtm_new_nexthop(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nh_config cfg;\n\tstruct nexthop *nh;\n\tint err;\n\n\terr = rtm_to_nh_config(net, skb, nlh, &cfg, extack);\n\tif (!err) {\n\t\tnh = nexthop_add(net, &cfg, extack);\n\t\tif (IS_ERR(nh))\n\t\t\terr = PTR_ERR(nh);\n\t}\n\n\treturn err;\n}\n\nstatic int __nh_valid_get_del_req(const struct nlmsghdr *nlh,\n\t\t\t\t  struct nlattr **tb, u32 *id,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct nhmsg *nhm = nlmsg_data(nlh);\n\n\tif (nhm->nh_protocol || nhm->resvd || nhm->nh_scope || nhm->nh_flags) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid values in header\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!tb[NHA_ID]) {\n\t\tNL_SET_ERR_MSG(extack, \"Nexthop id is missing\");\n\t\treturn -EINVAL;\n\t}\n\n\t*id = nla_get_u32(tb[NHA_ID]);\n\tif (!(*id)) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid nexthop id\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int nh_valid_get_del_req(const struct nlmsghdr *nlh, u32 *id,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct nlattr *tb[ARRAY_SIZE(rtm_nh_policy_get)];\n\tint err;\n\n\terr = nlmsg_parse(nlh, sizeof(struct nhmsg), tb,\n\t\t\t  ARRAY_SIZE(rtm_nh_policy_get) - 1,\n\t\t\t  rtm_nh_policy_get, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\treturn __nh_valid_get_del_req(nlh, tb, id, extack);\n}\n\n \nstatic int rtm_del_nexthop(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nl_info nlinfo = {\n\t\t.nlh = nlh,\n\t\t.nl_net = net,\n\t\t.portid = NETLINK_CB(skb).portid,\n\t};\n\tstruct nexthop *nh;\n\tint err;\n\tu32 id;\n\n\terr = nh_valid_get_del_req(nlh, &id, extack);\n\tif (err)\n\t\treturn err;\n\n\tnh = nexthop_find_by_id(net, id);\n\tif (!nh)\n\t\treturn -ENOENT;\n\n\tremove_nexthop(net, nh, &nlinfo);\n\n\treturn 0;\n}\n\n \nstatic int rtm_get_nexthop(struct sk_buff *in_skb, struct nlmsghdr *nlh,\n\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(in_skb->sk);\n\tstruct sk_buff *skb = NULL;\n\tstruct nexthop *nh;\n\tint err;\n\tu32 id;\n\n\terr = nh_valid_get_del_req(nlh, &id, extack);\n\tif (err)\n\t\treturn err;\n\n\terr = -ENOBUFS;\n\tskb = alloc_skb(NLMSG_GOODSIZE, GFP_KERNEL);\n\tif (!skb)\n\t\tgoto out;\n\n\terr = -ENOENT;\n\tnh = nexthop_find_by_id(net, id);\n\tif (!nh)\n\t\tgoto errout_free;\n\n\terr = nh_fill_node(skb, nh, RTM_NEWNEXTHOP, NETLINK_CB(in_skb).portid,\n\t\t\t   nlh->nlmsg_seq, 0);\n\tif (err < 0) {\n\t\tWARN_ON(err == -EMSGSIZE);\n\t\tgoto errout_free;\n\t}\n\n\terr = rtnl_unicast(skb, net, NETLINK_CB(in_skb).portid);\nout:\n\treturn err;\nerrout_free:\n\tkfree_skb(skb);\n\tgoto out;\n}\n\nstruct nh_dump_filter {\n\tu32 nh_id;\n\tint dev_idx;\n\tint master_idx;\n\tbool group_filter;\n\tbool fdb_filter;\n\tu32 res_bucket_nh_id;\n};\n\nstatic bool nh_dump_filtered(struct nexthop *nh,\n\t\t\t     struct nh_dump_filter *filter, u8 family)\n{\n\tconst struct net_device *dev;\n\tconst struct nh_info *nhi;\n\n\tif (filter->group_filter && !nh->is_group)\n\t\treturn true;\n\n\tif (!filter->dev_idx && !filter->master_idx && !family)\n\t\treturn false;\n\n\tif (nh->is_group)\n\t\treturn true;\n\n\tnhi = rtnl_dereference(nh->nh_info);\n\tif (family && nhi->family != family)\n\t\treturn true;\n\n\tdev = nhi->fib_nhc.nhc_dev;\n\tif (filter->dev_idx && (!dev || dev->ifindex != filter->dev_idx))\n\t\treturn true;\n\n\tif (filter->master_idx) {\n\t\tstruct net_device *master;\n\n\t\tif (!dev)\n\t\t\treturn true;\n\n\t\tmaster = netdev_master_upper_dev_get((struct net_device *)dev);\n\t\tif (!master || master->ifindex != filter->master_idx)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int __nh_valid_dump_req(const struct nlmsghdr *nlh, struct nlattr **tb,\n\t\t\t       struct nh_dump_filter *filter,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct nhmsg *nhm;\n\tu32 idx;\n\n\tif (tb[NHA_OIF]) {\n\t\tidx = nla_get_u32(tb[NHA_OIF]);\n\t\tif (idx > INT_MAX) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid device index\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tfilter->dev_idx = idx;\n\t}\n\tif (tb[NHA_MASTER]) {\n\t\tidx = nla_get_u32(tb[NHA_MASTER]);\n\t\tif (idx > INT_MAX) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid master device index\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tfilter->master_idx = idx;\n\t}\n\tfilter->group_filter = nla_get_flag(tb[NHA_GROUPS]);\n\tfilter->fdb_filter = nla_get_flag(tb[NHA_FDB]);\n\n\tnhm = nlmsg_data(nlh);\n\tif (nhm->nh_protocol || nhm->resvd || nhm->nh_scope || nhm->nh_flags) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid values in header for nexthop dump request\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int nh_valid_dump_req(const struct nlmsghdr *nlh,\n\t\t\t     struct nh_dump_filter *filter,\n\t\t\t     struct netlink_callback *cb)\n{\n\tstruct nlattr *tb[ARRAY_SIZE(rtm_nh_policy_dump)];\n\tint err;\n\n\terr = nlmsg_parse(nlh, sizeof(struct nhmsg), tb,\n\t\t\t  ARRAY_SIZE(rtm_nh_policy_dump) - 1,\n\t\t\t  rtm_nh_policy_dump, cb->extack);\n\tif (err < 0)\n\t\treturn err;\n\n\treturn __nh_valid_dump_req(nlh, tb, filter, cb->extack);\n}\n\nstruct rtm_dump_nh_ctx {\n\tu32 idx;\n};\n\nstatic struct rtm_dump_nh_ctx *\nrtm_dump_nh_ctx(struct netlink_callback *cb)\n{\n\tstruct rtm_dump_nh_ctx *ctx = (void *)cb->ctx;\n\n\tBUILD_BUG_ON(sizeof(*ctx) > sizeof(cb->ctx));\n\treturn ctx;\n}\n\nstatic int rtm_dump_walk_nexthops(struct sk_buff *skb,\n\t\t\t\t  struct netlink_callback *cb,\n\t\t\t\t  struct rb_root *root,\n\t\t\t\t  struct rtm_dump_nh_ctx *ctx,\n\t\t\t\t  int (*nh_cb)(struct sk_buff *skb,\n\t\t\t\t\t       struct netlink_callback *cb,\n\t\t\t\t\t       struct nexthop *nh, void *data),\n\t\t\t\t  void *data)\n{\n\tstruct rb_node *node;\n\tint s_idx;\n\tint err;\n\n\ts_idx = ctx->idx;\n\tfor (node = rb_first(root); node; node = rb_next(node)) {\n\t\tstruct nexthop *nh;\n\n\t\tnh = rb_entry(node, struct nexthop, rb_node);\n\t\tif (nh->id < s_idx)\n\t\t\tcontinue;\n\n\t\tctx->idx = nh->id;\n\t\terr = nh_cb(skb, cb, nh, data);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int rtm_dump_nexthop_cb(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t\t       struct nexthop *nh, void *data)\n{\n\tstruct nhmsg *nhm = nlmsg_data(cb->nlh);\n\tstruct nh_dump_filter *filter = data;\n\n\tif (nh_dump_filtered(nh, filter, nhm->nh_family))\n\t\treturn 0;\n\n\treturn nh_fill_node(skb, nh, RTM_NEWNEXTHOP,\n\t\t\t    NETLINK_CB(cb->skb).portid,\n\t\t\t    cb->nlh->nlmsg_seq, NLM_F_MULTI);\n}\n\n \nstatic int rtm_dump_nexthop(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct rtm_dump_nh_ctx *ctx = rtm_dump_nh_ctx(cb);\n\tstruct net *net = sock_net(skb->sk);\n\tstruct rb_root *root = &net->nexthop.rb_root;\n\tstruct nh_dump_filter filter = {};\n\tint err;\n\n\terr = nh_valid_dump_req(cb->nlh, &filter, cb);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = rtm_dump_walk_nexthops(skb, cb, root, ctx,\n\t\t\t\t     &rtm_dump_nexthop_cb, &filter);\n\tif (err < 0) {\n\t\tif (likely(skb->len))\n\t\t\terr = skb->len;\n\t}\n\n\tcb->seq = net->nexthop.seq;\n\tnl_dump_check_consistent(cb, nlmsg_hdr(skb));\n\treturn err;\n}\n\nstatic struct nexthop *\nnexthop_find_group_resilient(struct net *net, u32 id,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct nh_group *nhg;\n\tstruct nexthop *nh;\n\n\tnh = nexthop_find_by_id(net, id);\n\tif (!nh)\n\t\treturn ERR_PTR(-ENOENT);\n\n\tif (!nh->is_group) {\n\t\tNL_SET_ERR_MSG(extack, \"Not a nexthop group\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tnhg = rtnl_dereference(nh->nh_grp);\n\tif (!nhg->resilient) {\n\t\tNL_SET_ERR_MSG(extack, \"Nexthop group not of type resilient\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\treturn nh;\n}\n\nstatic int nh_valid_dump_nhid(struct nlattr *attr, u32 *nh_id_p,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tu32 idx;\n\n\tif (attr) {\n\t\tidx = nla_get_u32(attr);\n\t\tif (!idx) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid nexthop id\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t*nh_id_p = idx;\n\t} else {\n\t\t*nh_id_p = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic int nh_valid_dump_bucket_req(const struct nlmsghdr *nlh,\n\t\t\t\t    struct nh_dump_filter *filter,\n\t\t\t\t    struct netlink_callback *cb)\n{\n\tstruct nlattr *res_tb[ARRAY_SIZE(rtm_nh_res_bucket_policy_dump)];\n\tstruct nlattr *tb[ARRAY_SIZE(rtm_nh_policy_dump_bucket)];\n\tint err;\n\n\terr = nlmsg_parse(nlh, sizeof(struct nhmsg), tb,\n\t\t\t  ARRAY_SIZE(rtm_nh_policy_dump_bucket) - 1,\n\t\t\t  rtm_nh_policy_dump_bucket, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = nh_valid_dump_nhid(tb[NHA_ID], &filter->nh_id, cb->extack);\n\tif (err)\n\t\treturn err;\n\n\tif (tb[NHA_RES_BUCKET]) {\n\t\tsize_t max = ARRAY_SIZE(rtm_nh_res_bucket_policy_dump) - 1;\n\n\t\terr = nla_parse_nested(res_tb, max,\n\t\t\t\t       tb[NHA_RES_BUCKET],\n\t\t\t\t       rtm_nh_res_bucket_policy_dump,\n\t\t\t\t       cb->extack);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\terr = nh_valid_dump_nhid(res_tb[NHA_RES_BUCKET_NH_ID],\n\t\t\t\t\t &filter->res_bucket_nh_id,\n\t\t\t\t\t cb->extack);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn __nh_valid_dump_req(nlh, tb, filter, cb->extack);\n}\n\nstruct rtm_dump_res_bucket_ctx {\n\tstruct rtm_dump_nh_ctx nh;\n\tu16 bucket_index;\n};\n\nstatic struct rtm_dump_res_bucket_ctx *\nrtm_dump_res_bucket_ctx(struct netlink_callback *cb)\n{\n\tstruct rtm_dump_res_bucket_ctx *ctx = (void *)cb->ctx;\n\n\tBUILD_BUG_ON(sizeof(*ctx) > sizeof(cb->ctx));\n\treturn ctx;\n}\n\nstruct rtm_dump_nexthop_bucket_data {\n\tstruct rtm_dump_res_bucket_ctx *ctx;\n\tstruct nh_dump_filter filter;\n};\n\nstatic int rtm_dump_nexthop_bucket_nh(struct sk_buff *skb,\n\t\t\t\t      struct netlink_callback *cb,\n\t\t\t\t      struct nexthop *nh,\n\t\t\t\t      struct rtm_dump_nexthop_bucket_data *dd)\n{\n\tu32 portid = NETLINK_CB(cb->skb).portid;\n\tstruct nhmsg *nhm = nlmsg_data(cb->nlh);\n\tstruct nh_res_table *res_table;\n\tstruct nh_group *nhg;\n\tu16 bucket_index;\n\tint err;\n\n\tnhg = rtnl_dereference(nh->nh_grp);\n\tres_table = rtnl_dereference(nhg->res_table);\n\tfor (bucket_index = dd->ctx->bucket_index;\n\t     bucket_index < res_table->num_nh_buckets;\n\t     bucket_index++) {\n\t\tstruct nh_res_bucket *bucket;\n\t\tstruct nh_grp_entry *nhge;\n\n\t\tbucket = &res_table->nh_buckets[bucket_index];\n\t\tnhge = rtnl_dereference(bucket->nh_entry);\n\t\tif (nh_dump_filtered(nhge->nh, &dd->filter, nhm->nh_family))\n\t\t\tcontinue;\n\n\t\tif (dd->filter.res_bucket_nh_id &&\n\t\t    dd->filter.res_bucket_nh_id != nhge->nh->id)\n\t\t\tcontinue;\n\n\t\tdd->ctx->bucket_index = bucket_index;\n\t\terr = nh_fill_res_bucket(skb, nh, bucket, bucket_index,\n\t\t\t\t\t RTM_NEWNEXTHOPBUCKET, portid,\n\t\t\t\t\t cb->nlh->nlmsg_seq, NLM_F_MULTI,\n\t\t\t\t\t cb->extack);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tdd->ctx->bucket_index = 0;\n\n\treturn 0;\n}\n\nstatic int rtm_dump_nexthop_bucket_cb(struct sk_buff *skb,\n\t\t\t\t      struct netlink_callback *cb,\n\t\t\t\t      struct nexthop *nh, void *data)\n{\n\tstruct rtm_dump_nexthop_bucket_data *dd = data;\n\tstruct nh_group *nhg;\n\n\tif (!nh->is_group)\n\t\treturn 0;\n\n\tnhg = rtnl_dereference(nh->nh_grp);\n\tif (!nhg->resilient)\n\t\treturn 0;\n\n\treturn rtm_dump_nexthop_bucket_nh(skb, cb, nh, dd);\n}\n\n \nstatic int rtm_dump_nexthop_bucket(struct sk_buff *skb,\n\t\t\t\t   struct netlink_callback *cb)\n{\n\tstruct rtm_dump_res_bucket_ctx *ctx = rtm_dump_res_bucket_ctx(cb);\n\tstruct rtm_dump_nexthop_bucket_data dd = { .ctx = ctx };\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nexthop *nh;\n\tint err;\n\n\terr = nh_valid_dump_bucket_req(cb->nlh, &dd.filter, cb);\n\tif (err)\n\t\treturn err;\n\n\tif (dd.filter.nh_id) {\n\t\tnh = nexthop_find_group_resilient(net, dd.filter.nh_id,\n\t\t\t\t\t\t  cb->extack);\n\t\tif (IS_ERR(nh))\n\t\t\treturn PTR_ERR(nh);\n\t\terr = rtm_dump_nexthop_bucket_nh(skb, cb, nh, &dd);\n\t} else {\n\t\tstruct rb_root *root = &net->nexthop.rb_root;\n\n\t\terr = rtm_dump_walk_nexthops(skb, cb, root, &ctx->nh,\n\t\t\t\t\t     &rtm_dump_nexthop_bucket_cb, &dd);\n\t}\n\n\tif (err < 0) {\n\t\tif (likely(skb->len))\n\t\t\terr = skb->len;\n\t}\n\n\tcb->seq = net->nexthop.seq;\n\tnl_dump_check_consistent(cb, nlmsg_hdr(skb));\n\treturn err;\n}\n\nstatic int nh_valid_get_bucket_req_res_bucket(struct nlattr *res,\n\t\t\t\t\t      u16 *bucket_index,\n\t\t\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct nlattr *tb[ARRAY_SIZE(rtm_nh_res_bucket_policy_get)];\n\tint err;\n\n\terr = nla_parse_nested(tb, ARRAY_SIZE(rtm_nh_res_bucket_policy_get) - 1,\n\t\t\t       res, rtm_nh_res_bucket_policy_get, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (!tb[NHA_RES_BUCKET_INDEX]) {\n\t\tNL_SET_ERR_MSG(extack, \"Bucket index is missing\");\n\t\treturn -EINVAL;\n\t}\n\n\t*bucket_index = nla_get_u16(tb[NHA_RES_BUCKET_INDEX]);\n\treturn 0;\n}\n\nstatic int nh_valid_get_bucket_req(const struct nlmsghdr *nlh,\n\t\t\t\t   u32 *id, u16 *bucket_index,\n\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct nlattr *tb[ARRAY_SIZE(rtm_nh_policy_get_bucket)];\n\tint err;\n\n\terr = nlmsg_parse(nlh, sizeof(struct nhmsg), tb,\n\t\t\t  ARRAY_SIZE(rtm_nh_policy_get_bucket) - 1,\n\t\t\t  rtm_nh_policy_get_bucket, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = __nh_valid_get_del_req(nlh, tb, id, extack);\n\tif (err)\n\t\treturn err;\n\n\tif (!tb[NHA_RES_BUCKET]) {\n\t\tNL_SET_ERR_MSG(extack, \"Bucket information is missing\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = nh_valid_get_bucket_req_res_bucket(tb[NHA_RES_BUCKET],\n\t\t\t\t\t\t bucket_index, extack);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\n \nstatic int rtm_get_nexthop_bucket(struct sk_buff *in_skb, struct nlmsghdr *nlh,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(in_skb->sk);\n\tstruct nh_res_table *res_table;\n\tstruct sk_buff *skb = NULL;\n\tstruct nh_group *nhg;\n\tstruct nexthop *nh;\n\tu16 bucket_index;\n\tint err;\n\tu32 id;\n\n\terr = nh_valid_get_bucket_req(nlh, &id, &bucket_index, extack);\n\tif (err)\n\t\treturn err;\n\n\tnh = nexthop_find_group_resilient(net, id, extack);\n\tif (IS_ERR(nh))\n\t\treturn PTR_ERR(nh);\n\n\tnhg = rtnl_dereference(nh->nh_grp);\n\tres_table = rtnl_dereference(nhg->res_table);\n\tif (bucket_index >= res_table->num_nh_buckets) {\n\t\tNL_SET_ERR_MSG(extack, \"Bucket index out of bounds\");\n\t\treturn -ENOENT;\n\t}\n\n\tskb = alloc_skb(NLMSG_GOODSIZE, GFP_KERNEL);\n\tif (!skb)\n\t\treturn -ENOBUFS;\n\n\terr = nh_fill_res_bucket(skb, nh, &res_table->nh_buckets[bucket_index],\n\t\t\t\t bucket_index, RTM_NEWNEXTHOPBUCKET,\n\t\t\t\t NETLINK_CB(in_skb).portid, nlh->nlmsg_seq,\n\t\t\t\t 0, extack);\n\tif (err < 0) {\n\t\tWARN_ON(err == -EMSGSIZE);\n\t\tgoto errout_free;\n\t}\n\n\treturn rtnl_unicast(skb, net, NETLINK_CB(in_skb).portid);\n\nerrout_free:\n\tkfree_skb(skb);\n\treturn err;\n}\n\nstatic void nexthop_sync_mtu(struct net_device *dev, u32 orig_mtu)\n{\n\tunsigned int hash = nh_dev_hashfn(dev->ifindex);\n\tstruct net *net = dev_net(dev);\n\tstruct hlist_head *head = &net->nexthop.devhash[hash];\n\tstruct hlist_node *n;\n\tstruct nh_info *nhi;\n\n\thlist_for_each_entry_safe(nhi, n, head, dev_hash) {\n\t\tif (nhi->fib_nhc.nhc_dev == dev) {\n\t\t\tif (nhi->family == AF_INET)\n\t\t\t\tfib_nhc_update_mtu(&nhi->fib_nhc, dev->mtu,\n\t\t\t\t\t\t   orig_mtu);\n\t\t}\n\t}\n}\n\n \nstatic int nh_netdev_event(struct notifier_block *this,\n\t\t\t   unsigned long event, void *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\tstruct netdev_notifier_info_ext *info_ext;\n\n\tswitch (event) {\n\tcase NETDEV_DOWN:\n\tcase NETDEV_UNREGISTER:\n\t\tnexthop_flush_dev(dev, event);\n\t\tbreak;\n\tcase NETDEV_CHANGE:\n\t\tif (!(dev_get_flags(dev) & (IFF_RUNNING | IFF_LOWER_UP)))\n\t\t\tnexthop_flush_dev(dev, event);\n\t\tbreak;\n\tcase NETDEV_CHANGEMTU:\n\t\tinfo_ext = ptr;\n\t\tnexthop_sync_mtu(dev, info_ext->ext.mtu);\n\t\trt_cache_flush(dev_net(dev));\n\t\tbreak;\n\t}\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block nh_netdev_notifier = {\n\t.notifier_call = nh_netdev_event,\n};\n\nstatic int nexthops_dump(struct net *net, struct notifier_block *nb,\n\t\t\t enum nexthop_event_type event_type,\n\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct rb_root *root = &net->nexthop.rb_root;\n\tstruct rb_node *node;\n\tint err = 0;\n\n\tfor (node = rb_first(root); node; node = rb_next(node)) {\n\t\tstruct nexthop *nh;\n\n\t\tnh = rb_entry(node, struct nexthop, rb_node);\n\t\terr = call_nexthop_notifier(nb, net, event_type, nh, extack);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\treturn err;\n}\n\nint register_nexthop_notifier(struct net *net, struct notifier_block *nb,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tint err;\n\n\trtnl_lock();\n\terr = nexthops_dump(net, nb, NEXTHOP_EVENT_REPLACE, extack);\n\tif (err)\n\t\tgoto unlock;\n\terr = blocking_notifier_chain_register(&net->nexthop.notifier_chain,\n\t\t\t\t\t       nb);\nunlock:\n\trtnl_unlock();\n\treturn err;\n}\nEXPORT_SYMBOL(register_nexthop_notifier);\n\nint unregister_nexthop_notifier(struct net *net, struct notifier_block *nb)\n{\n\tint err;\n\n\trtnl_lock();\n\terr = blocking_notifier_chain_unregister(&net->nexthop.notifier_chain,\n\t\t\t\t\t\t nb);\n\tif (err)\n\t\tgoto unlock;\n\tnexthops_dump(net, nb, NEXTHOP_EVENT_DEL, NULL);\nunlock:\n\trtnl_unlock();\n\treturn err;\n}\nEXPORT_SYMBOL(unregister_nexthop_notifier);\n\nvoid nexthop_set_hw_flags(struct net *net, u32 id, bool offload, bool trap)\n{\n\tstruct nexthop *nexthop;\n\n\trcu_read_lock();\n\n\tnexthop = nexthop_find_by_id(net, id);\n\tif (!nexthop)\n\t\tgoto out;\n\n\tnexthop->nh_flags &= ~(RTNH_F_OFFLOAD | RTNH_F_TRAP);\n\tif (offload)\n\t\tnexthop->nh_flags |= RTNH_F_OFFLOAD;\n\tif (trap)\n\t\tnexthop->nh_flags |= RTNH_F_TRAP;\n\nout:\n\trcu_read_unlock();\n}\nEXPORT_SYMBOL(nexthop_set_hw_flags);\n\nvoid nexthop_bucket_set_hw_flags(struct net *net, u32 id, u16 bucket_index,\n\t\t\t\t bool offload, bool trap)\n{\n\tstruct nh_res_table *res_table;\n\tstruct nh_res_bucket *bucket;\n\tstruct nexthop *nexthop;\n\tstruct nh_group *nhg;\n\n\trcu_read_lock();\n\n\tnexthop = nexthop_find_by_id(net, id);\n\tif (!nexthop || !nexthop->is_group)\n\t\tgoto out;\n\n\tnhg = rcu_dereference(nexthop->nh_grp);\n\tif (!nhg->resilient)\n\t\tgoto out;\n\n\tif (bucket_index >= nhg->res_table->num_nh_buckets)\n\t\tgoto out;\n\n\tres_table = rcu_dereference(nhg->res_table);\n\tbucket = &res_table->nh_buckets[bucket_index];\n\tbucket->nh_flags &= ~(RTNH_F_OFFLOAD | RTNH_F_TRAP);\n\tif (offload)\n\t\tbucket->nh_flags |= RTNH_F_OFFLOAD;\n\tif (trap)\n\t\tbucket->nh_flags |= RTNH_F_TRAP;\n\nout:\n\trcu_read_unlock();\n}\nEXPORT_SYMBOL(nexthop_bucket_set_hw_flags);\n\nvoid nexthop_res_grp_activity_update(struct net *net, u32 id, u16 num_buckets,\n\t\t\t\t     unsigned long *activity)\n{\n\tstruct nh_res_table *res_table;\n\tstruct nexthop *nexthop;\n\tstruct nh_group *nhg;\n\tu16 i;\n\n\trcu_read_lock();\n\n\tnexthop = nexthop_find_by_id(net, id);\n\tif (!nexthop || !nexthop->is_group)\n\t\tgoto out;\n\n\tnhg = rcu_dereference(nexthop->nh_grp);\n\tif (!nhg->resilient)\n\t\tgoto out;\n\n\t \n\tres_table = rcu_dereference(nhg->res_table);\n\tif (num_buckets != res_table->num_nh_buckets)\n\t\tgoto out;\n\n\tfor (i = 0; i < num_buckets; i++) {\n\t\tif (test_bit(i, activity))\n\t\t\tnh_res_bucket_set_busy(&res_table->nh_buckets[i]);\n\t}\n\nout:\n\trcu_read_unlock();\n}\nEXPORT_SYMBOL(nexthop_res_grp_activity_update);\n\nstatic void __net_exit nexthop_net_exit_batch(struct list_head *net_list)\n{\n\tstruct net *net;\n\n\trtnl_lock();\n\tlist_for_each_entry(net, net_list, exit_list) {\n\t\tflush_all_nexthops(net);\n\t\tkfree(net->nexthop.devhash);\n\t}\n\trtnl_unlock();\n}\n\nstatic int __net_init nexthop_net_init(struct net *net)\n{\n\tsize_t sz = sizeof(struct hlist_head) * NH_DEV_HASHSIZE;\n\n\tnet->nexthop.rb_root = RB_ROOT;\n\tnet->nexthop.devhash = kzalloc(sz, GFP_KERNEL);\n\tif (!net->nexthop.devhash)\n\t\treturn -ENOMEM;\n\tBLOCKING_INIT_NOTIFIER_HEAD(&net->nexthop.notifier_chain);\n\n\treturn 0;\n}\n\nstatic struct pernet_operations nexthop_net_ops = {\n\t.init = nexthop_net_init,\n\t.exit_batch = nexthop_net_exit_batch,\n};\n\nstatic int __init nexthop_init(void)\n{\n\tregister_pernet_subsys(&nexthop_net_ops);\n\n\tregister_netdevice_notifier(&nh_netdev_notifier);\n\n\trtnl_register(PF_UNSPEC, RTM_NEWNEXTHOP, rtm_new_nexthop, NULL, 0);\n\trtnl_register(PF_UNSPEC, RTM_DELNEXTHOP, rtm_del_nexthop, NULL, 0);\n\trtnl_register(PF_UNSPEC, RTM_GETNEXTHOP, rtm_get_nexthop,\n\t\t      rtm_dump_nexthop, 0);\n\n\trtnl_register(PF_INET, RTM_NEWNEXTHOP, rtm_new_nexthop, NULL, 0);\n\trtnl_register(PF_INET, RTM_GETNEXTHOP, NULL, rtm_dump_nexthop, 0);\n\n\trtnl_register(PF_INET6, RTM_NEWNEXTHOP, rtm_new_nexthop, NULL, 0);\n\trtnl_register(PF_INET6, RTM_GETNEXTHOP, NULL, rtm_dump_nexthop, 0);\n\n\trtnl_register(PF_UNSPEC, RTM_GETNEXTHOPBUCKET, rtm_get_nexthop_bucket,\n\t\t      rtm_dump_nexthop_bucket, 0);\n\n\treturn 0;\n}\nsubsys_initcall(nexthop_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}