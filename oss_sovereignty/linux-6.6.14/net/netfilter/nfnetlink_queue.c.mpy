{
  "module_name": "nfnetlink_queue.c",
  "hash_id": "0badcd7c6629c906175fbfd1bf280ce95049b66d6e4ae7f45faf556d81675f76",
  "original_prompt": "Ingested from linux-6.6.14/net/netfilter/nfnetlink_queue.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/module.h>\n#include <linux/skbuff.h>\n#include <linux/init.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/notifier.h>\n#include <linux/netdevice.h>\n#include <linux/netfilter.h>\n#include <linux/proc_fs.h>\n#include <linux/netfilter_ipv4.h>\n#include <linux/netfilter_ipv6.h>\n#include <linux/netfilter_bridge.h>\n#include <linux/netfilter/nfnetlink.h>\n#include <linux/netfilter/nfnetlink_queue.h>\n#include <linux/netfilter/nf_conntrack_common.h>\n#include <linux/list.h>\n#include <linux/cgroup-defs.h>\n#include <net/gso.h>\n#include <net/sock.h>\n#include <net/tcp_states.h>\n#include <net/netfilter/nf_queue.h>\n#include <net/netns/generic.h>\n\n#include <linux/atomic.h>\n\n#if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)\n#include \"../bridge/br_private.h\"\n#endif\n\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n#include <net/netfilter/nf_conntrack.h>\n#endif\n\n#define NFQNL_QMAX_DEFAULT 1024\n\n \n#define NFQNL_MAX_COPY_RANGE (0xffff - NLA_HDRLEN)\n\nstruct nfqnl_instance {\n\tstruct hlist_node hlist;\t\t \n\tstruct rcu_head rcu;\n\n\tu32 peer_portid;\n\tunsigned int queue_maxlen;\n\tunsigned int copy_range;\n\tunsigned int queue_dropped;\n\tunsigned int queue_user_dropped;\n\n\n\tu_int16_t queue_num;\t\t\t \n\tu_int8_t copy_mode;\n\tu_int32_t flags;\t\t\t \n \n\tspinlock_t\tlock\t____cacheline_aligned_in_smp;\n\tunsigned int\tqueue_total;\n\tunsigned int\tid_sequence;\t\t \n\tstruct list_head queue_list;\t\t \n};\n\ntypedef int (*nfqnl_cmpfn)(struct nf_queue_entry *, unsigned long);\n\nstatic unsigned int nfnl_queue_net_id __read_mostly;\n\n#define INSTANCE_BUCKETS\t16\nstruct nfnl_queue_net {\n\tspinlock_t instances_lock;\n\tstruct hlist_head instance_table[INSTANCE_BUCKETS];\n};\n\nstatic struct nfnl_queue_net *nfnl_queue_pernet(struct net *net)\n{\n\treturn net_generic(net, nfnl_queue_net_id);\n}\n\nstatic inline u_int8_t instance_hashfn(u_int16_t queue_num)\n{\n\treturn ((queue_num >> 8) ^ queue_num) % INSTANCE_BUCKETS;\n}\n\nstatic struct nfqnl_instance *\ninstance_lookup(struct nfnl_queue_net *q, u_int16_t queue_num)\n{\n\tstruct hlist_head *head;\n\tstruct nfqnl_instance *inst;\n\n\thead = &q->instance_table[instance_hashfn(queue_num)];\n\thlist_for_each_entry_rcu(inst, head, hlist) {\n\t\tif (inst->queue_num == queue_num)\n\t\t\treturn inst;\n\t}\n\treturn NULL;\n}\n\nstatic struct nfqnl_instance *\ninstance_create(struct nfnl_queue_net *q, u_int16_t queue_num, u32 portid)\n{\n\tstruct nfqnl_instance *inst;\n\tunsigned int h;\n\tint err;\n\n\tspin_lock(&q->instances_lock);\n\tif (instance_lookup(q, queue_num)) {\n\t\terr = -EEXIST;\n\t\tgoto out_unlock;\n\t}\n\n\tinst = kzalloc(sizeof(*inst), GFP_ATOMIC);\n\tif (!inst) {\n\t\terr = -ENOMEM;\n\t\tgoto out_unlock;\n\t}\n\n\tinst->queue_num = queue_num;\n\tinst->peer_portid = portid;\n\tinst->queue_maxlen = NFQNL_QMAX_DEFAULT;\n\tinst->copy_range = NFQNL_MAX_COPY_RANGE;\n\tinst->copy_mode = NFQNL_COPY_NONE;\n\tspin_lock_init(&inst->lock);\n\tINIT_LIST_HEAD(&inst->queue_list);\n\n\tif (!try_module_get(THIS_MODULE)) {\n\t\terr = -EAGAIN;\n\t\tgoto out_free;\n\t}\n\n\th = instance_hashfn(queue_num);\n\thlist_add_head_rcu(&inst->hlist, &q->instance_table[h]);\n\n\tspin_unlock(&q->instances_lock);\n\n\treturn inst;\n\nout_free:\n\tkfree(inst);\nout_unlock:\n\tspin_unlock(&q->instances_lock);\n\treturn ERR_PTR(err);\n}\n\nstatic void nfqnl_flush(struct nfqnl_instance *queue, nfqnl_cmpfn cmpfn,\n\t\t\tunsigned long data);\n\nstatic void\ninstance_destroy_rcu(struct rcu_head *head)\n{\n\tstruct nfqnl_instance *inst = container_of(head, struct nfqnl_instance,\n\t\t\t\t\t\t   rcu);\n\n\tnfqnl_flush(inst, NULL, 0);\n\tkfree(inst);\n\tmodule_put(THIS_MODULE);\n}\n\nstatic void\n__instance_destroy(struct nfqnl_instance *inst)\n{\n\thlist_del_rcu(&inst->hlist);\n\tcall_rcu(&inst->rcu, instance_destroy_rcu);\n}\n\nstatic void\ninstance_destroy(struct nfnl_queue_net *q, struct nfqnl_instance *inst)\n{\n\tspin_lock(&q->instances_lock);\n\t__instance_destroy(inst);\n\tspin_unlock(&q->instances_lock);\n}\n\nstatic inline void\n__enqueue_entry(struct nfqnl_instance *queue, struct nf_queue_entry *entry)\n{\n       list_add_tail(&entry->list, &queue->queue_list);\n       queue->queue_total++;\n}\n\nstatic void\n__dequeue_entry(struct nfqnl_instance *queue, struct nf_queue_entry *entry)\n{\n\tlist_del(&entry->list);\n\tqueue->queue_total--;\n}\n\nstatic struct nf_queue_entry *\nfind_dequeue_entry(struct nfqnl_instance *queue, unsigned int id)\n{\n\tstruct nf_queue_entry *entry = NULL, *i;\n\n\tspin_lock_bh(&queue->lock);\n\n\tlist_for_each_entry(i, &queue->queue_list, list) {\n\t\tif (i->id == id) {\n\t\t\tentry = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (entry)\n\t\t__dequeue_entry(queue, entry);\n\n\tspin_unlock_bh(&queue->lock);\n\n\treturn entry;\n}\n\nstatic void nfqnl_reinject(struct nf_queue_entry *entry, unsigned int verdict)\n{\n\tconst struct nf_ct_hook *ct_hook;\n\tint err;\n\n\tif (verdict == NF_ACCEPT ||\n\t    verdict == NF_REPEAT ||\n\t    verdict == NF_STOP) {\n\t\trcu_read_lock();\n\t\tct_hook = rcu_dereference(nf_ct_hook);\n\t\tif (ct_hook) {\n\t\t\terr = ct_hook->update(entry->state.net, entry->skb);\n\t\t\tif (err < 0)\n\t\t\t\tverdict = NF_DROP;\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\tnf_reinject(entry, verdict);\n}\n\nstatic void\nnfqnl_flush(struct nfqnl_instance *queue, nfqnl_cmpfn cmpfn, unsigned long data)\n{\n\tstruct nf_queue_entry *entry, *next;\n\n\tspin_lock_bh(&queue->lock);\n\tlist_for_each_entry_safe(entry, next, &queue->queue_list, list) {\n\t\tif (!cmpfn || cmpfn(entry, data)) {\n\t\t\tlist_del(&entry->list);\n\t\t\tqueue->queue_total--;\n\t\t\tnfqnl_reinject(entry, NF_DROP);\n\t\t}\n\t}\n\tspin_unlock_bh(&queue->lock);\n}\n\nstatic int\nnfqnl_put_packet_info(struct sk_buff *nlskb, struct sk_buff *packet,\n\t\t      bool csum_verify)\n{\n\t__u32 flags = 0;\n\n\tif (packet->ip_summed == CHECKSUM_PARTIAL)\n\t\tflags = NFQA_SKB_CSUMNOTREADY;\n\telse if (csum_verify)\n\t\tflags = NFQA_SKB_CSUM_NOTVERIFIED;\n\n\tif (skb_is_gso(packet))\n\t\tflags |= NFQA_SKB_GSO;\n\n\treturn flags ? nla_put_be32(nlskb, NFQA_SKB_INFO, htonl(flags)) : 0;\n}\n\nstatic int nfqnl_put_sk_uidgid(struct sk_buff *skb, struct sock *sk)\n{\n\tconst struct cred *cred;\n\n\tif (!sk_fullsock(sk))\n\t\treturn 0;\n\n\tread_lock_bh(&sk->sk_callback_lock);\n\tif (sk->sk_socket && sk->sk_socket->file) {\n\t\tcred = sk->sk_socket->file->f_cred;\n\t\tif (nla_put_be32(skb, NFQA_UID,\n\t\t    htonl(from_kuid_munged(&init_user_ns, cred->fsuid))))\n\t\t\tgoto nla_put_failure;\n\t\tif (nla_put_be32(skb, NFQA_GID,\n\t\t    htonl(from_kgid_munged(&init_user_ns, cred->fsgid))))\n\t\t\tgoto nla_put_failure;\n\t}\n\tread_unlock_bh(&sk->sk_callback_lock);\n\treturn 0;\n\nnla_put_failure:\n\tread_unlock_bh(&sk->sk_callback_lock);\n\treturn -1;\n}\n\nstatic int nfqnl_put_sk_classid(struct sk_buff *skb, struct sock *sk)\n{\n#if IS_ENABLED(CONFIG_CGROUP_NET_CLASSID)\n\tif (sk && sk_fullsock(sk)) {\n\t\tu32 classid = sock_cgroup_classid(&sk->sk_cgrp_data);\n\n\t\tif (classid && nla_put_be32(skb, NFQA_CGROUP_CLASSID, htonl(classid)))\n\t\t\treturn -1;\n\t}\n#endif\n\treturn 0;\n}\n\nstatic u32 nfqnl_get_sk_secctx(struct sk_buff *skb, char **secdata)\n{\n\tu32 seclen = 0;\n#if IS_ENABLED(CONFIG_NETWORK_SECMARK)\n\tif (!skb || !sk_fullsock(skb->sk))\n\t\treturn 0;\n\n\tread_lock_bh(&skb->sk->sk_callback_lock);\n\n\tif (skb->secmark)\n\t\tsecurity_secid_to_secctx(skb->secmark, secdata, &seclen);\n\n\tread_unlock_bh(&skb->sk->sk_callback_lock);\n#endif\n\treturn seclen;\n}\n\nstatic u32 nfqnl_get_bridge_size(struct nf_queue_entry *entry)\n{\n\tstruct sk_buff *entskb = entry->skb;\n\tu32 nlalen = 0;\n\n\tif (entry->state.pf != PF_BRIDGE || !skb_mac_header_was_set(entskb))\n\t\treturn 0;\n\n\tif (skb_vlan_tag_present(entskb))\n\t\tnlalen += nla_total_size(nla_total_size(sizeof(__be16)) +\n\t\t\t\t\t nla_total_size(sizeof(__be16)));\n\n\tif (entskb->network_header > entskb->mac_header)\n\t\tnlalen += nla_total_size((entskb->network_header -\n\t\t\t\t\t  entskb->mac_header));\n\n\treturn nlalen;\n}\n\nstatic int nfqnl_put_bridge(struct nf_queue_entry *entry, struct sk_buff *skb)\n{\n\tstruct sk_buff *entskb = entry->skb;\n\n\tif (entry->state.pf != PF_BRIDGE || !skb_mac_header_was_set(entskb))\n\t\treturn 0;\n\n\tif (skb_vlan_tag_present(entskb)) {\n\t\tstruct nlattr *nest;\n\n\t\tnest = nla_nest_start(skb, NFQA_VLAN);\n\t\tif (!nest)\n\t\t\tgoto nla_put_failure;\n\n\t\tif (nla_put_be16(skb, NFQA_VLAN_TCI, htons(entskb->vlan_tci)) ||\n\t\t    nla_put_be16(skb, NFQA_VLAN_PROTO, entskb->vlan_proto))\n\t\t\tgoto nla_put_failure;\n\n\t\tnla_nest_end(skb, nest);\n\t}\n\n\tif (entskb->mac_header < entskb->network_header) {\n\t\tint len = (int)(entskb->network_header - entskb->mac_header);\n\n\t\tif (nla_put(skb, NFQA_L2HDR, len, skb_mac_header(entskb)))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\treturn 0;\n\nnla_put_failure:\n\treturn -1;\n}\n\nstatic struct sk_buff *\nnfqnl_build_packet_message(struct net *net, struct nfqnl_instance *queue,\n\t\t\t   struct nf_queue_entry *entry,\n\t\t\t   __be32 **packet_id_ptr)\n{\n\tsize_t size;\n\tsize_t data_len = 0, cap_len = 0;\n\tunsigned int hlen = 0;\n\tstruct sk_buff *skb;\n\tstruct nlattr *nla;\n\tstruct nfqnl_msg_packet_hdr *pmsg;\n\tstruct nlmsghdr *nlh;\n\tstruct sk_buff *entskb = entry->skb;\n\tstruct net_device *indev;\n\tstruct net_device *outdev;\n\tstruct nf_conn *ct = NULL;\n\tenum ip_conntrack_info ctinfo = 0;\n\tconst struct nfnl_ct_hook *nfnl_ct;\n\tbool csum_verify;\n\tchar *secdata = NULL;\n\tu32 seclen = 0;\n\tktime_t tstamp;\n\n\tsize = nlmsg_total_size(sizeof(struct nfgenmsg))\n\t\t+ nla_total_size(sizeof(struct nfqnl_msg_packet_hdr))\n\t\t+ nla_total_size(sizeof(u_int32_t))\t \n\t\t+ nla_total_size(sizeof(u_int32_t))\t \n#if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)\n\t\t+ nla_total_size(sizeof(u_int32_t))\t \n\t\t+ nla_total_size(sizeof(u_int32_t))\t \n#endif\n\t\t+ nla_total_size(sizeof(u_int32_t))\t \n\t\t+ nla_total_size(sizeof(u_int32_t))\t \n\t\t+ nla_total_size(sizeof(struct nfqnl_msg_packet_hw))\n\t\t+ nla_total_size(sizeof(u_int32_t))\t \n#if IS_ENABLED(CONFIG_CGROUP_NET_CLASSID)\n\t\t+ nla_total_size(sizeof(u_int32_t))\t \n#endif\n\t\t+ nla_total_size(sizeof(u_int32_t));\t \n\n\ttstamp = skb_tstamp_cond(entskb, false);\n\tif (tstamp)\n\t\tsize += nla_total_size(sizeof(struct nfqnl_msg_packet_timestamp));\n\n\tsize += nfqnl_get_bridge_size(entry);\n\n\tif (entry->state.hook <= NF_INET_FORWARD ||\n\t   (entry->state.hook == NF_INET_POST_ROUTING && entskb->sk == NULL))\n\t\tcsum_verify = !skb_csum_unnecessary(entskb);\n\telse\n\t\tcsum_verify = false;\n\n\toutdev = entry->state.out;\n\n\tswitch ((enum nfqnl_config_mode)READ_ONCE(queue->copy_mode)) {\n\tcase NFQNL_COPY_META:\n\tcase NFQNL_COPY_NONE:\n\t\tbreak;\n\n\tcase NFQNL_COPY_PACKET:\n\t\tif (!(queue->flags & NFQA_CFG_F_GSO) &&\n\t\t    entskb->ip_summed == CHECKSUM_PARTIAL &&\n\t\t    skb_checksum_help(entskb))\n\t\t\treturn NULL;\n\n\t\tdata_len = READ_ONCE(queue->copy_range);\n\t\tif (data_len > entskb->len)\n\t\t\tdata_len = entskb->len;\n\n\t\thlen = skb_zerocopy_headlen(entskb);\n\t\thlen = min_t(unsigned int, hlen, data_len);\n\t\tsize += sizeof(struct nlattr) + hlen;\n\t\tcap_len = entskb->len;\n\t\tbreak;\n\t}\n\n\tnfnl_ct = rcu_dereference(nfnl_ct_hook);\n\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\tif (queue->flags & NFQA_CFG_F_CONNTRACK) {\n\t\tif (nfnl_ct != NULL) {\n\t\t\tct = nf_ct_get(entskb, &ctinfo);\n\t\t\tif (ct != NULL)\n\t\t\t\tsize += nfnl_ct->build_size(ct);\n\t\t}\n\t}\n#endif\n\n\tif (queue->flags & NFQA_CFG_F_UID_GID) {\n\t\tsize += (nla_total_size(sizeof(u_int32_t))\t \n\t\t\t+ nla_total_size(sizeof(u_int32_t)));\t \n\t}\n\n\tif ((queue->flags & NFQA_CFG_F_SECCTX) && entskb->sk) {\n\t\tseclen = nfqnl_get_sk_secctx(entskb, &secdata);\n\t\tif (seclen)\n\t\t\tsize += nla_total_size(seclen);\n\t}\n\n\tskb = alloc_skb(size, GFP_ATOMIC);\n\tif (!skb) {\n\t\tskb_tx_error(entskb);\n\t\tgoto nlmsg_failure;\n\t}\n\n\tnlh = nfnl_msg_put(skb, 0, 0,\n\t\t\t   nfnl_msg_type(NFNL_SUBSYS_QUEUE, NFQNL_MSG_PACKET),\n\t\t\t   0, entry->state.pf, NFNETLINK_V0,\n\t\t\t   htons(queue->queue_num));\n\tif (!nlh) {\n\t\tskb_tx_error(entskb);\n\t\tkfree_skb(skb);\n\t\tgoto nlmsg_failure;\n\t}\n\n\tnla = __nla_reserve(skb, NFQA_PACKET_HDR, sizeof(*pmsg));\n\tpmsg = nla_data(nla);\n\tpmsg->hw_protocol\t= entskb->protocol;\n\tpmsg->hook\t\t= entry->state.hook;\n\t*packet_id_ptr\t\t= &pmsg->packet_id;\n\n\tindev = entry->state.in;\n\tif (indev) {\n#if !IS_ENABLED(CONFIG_BRIDGE_NETFILTER)\n\t\tif (nla_put_be32(skb, NFQA_IFINDEX_INDEV, htonl(indev->ifindex)))\n\t\t\tgoto nla_put_failure;\n#else\n\t\tif (entry->state.pf == PF_BRIDGE) {\n\t\t\t \n\t\t\tif (nla_put_be32(skb, NFQA_IFINDEX_PHYSINDEV,\n\t\t\t\t\t htonl(indev->ifindex)) ||\n\t\t\t \n\t\t\t \n\t\t\t    nla_put_be32(skb, NFQA_IFINDEX_INDEV,\n\t\t\t\t\t htonl(br_port_get_rcu(indev)->br->dev->ifindex)))\n\t\t\t\tgoto nla_put_failure;\n\t\t} else {\n\t\t\tint physinif;\n\n\t\t\t \n\t\t\tif (nla_put_be32(skb, NFQA_IFINDEX_INDEV,\n\t\t\t\t\t htonl(indev->ifindex)))\n\t\t\t\tgoto nla_put_failure;\n\n\t\t\tphysinif = nf_bridge_get_physinif(entskb);\n\t\t\tif (physinif &&\n\t\t\t    nla_put_be32(skb, NFQA_IFINDEX_PHYSINDEV,\n\t\t\t\t\t htonl(physinif)))\n\t\t\t\tgoto nla_put_failure;\n\t\t}\n#endif\n\t}\n\n\tif (outdev) {\n#if !IS_ENABLED(CONFIG_BRIDGE_NETFILTER)\n\t\tif (nla_put_be32(skb, NFQA_IFINDEX_OUTDEV, htonl(outdev->ifindex)))\n\t\t\tgoto nla_put_failure;\n#else\n\t\tif (entry->state.pf == PF_BRIDGE) {\n\t\t\t \n\t\t\tif (nla_put_be32(skb, NFQA_IFINDEX_PHYSOUTDEV,\n\t\t\t\t\t htonl(outdev->ifindex)) ||\n\t\t\t \n\t\t\t \n\t\t\t    nla_put_be32(skb, NFQA_IFINDEX_OUTDEV,\n\t\t\t\t\t htonl(br_port_get_rcu(outdev)->br->dev->ifindex)))\n\t\t\t\tgoto nla_put_failure;\n\t\t} else {\n\t\t\tint physoutif;\n\n\t\t\t \n\t\t\tif (nla_put_be32(skb, NFQA_IFINDEX_OUTDEV,\n\t\t\t\t\t htonl(outdev->ifindex)))\n\t\t\t\tgoto nla_put_failure;\n\n\t\t\tphysoutif = nf_bridge_get_physoutif(entskb);\n\t\t\tif (physoutif &&\n\t\t\t    nla_put_be32(skb, NFQA_IFINDEX_PHYSOUTDEV,\n\t\t\t\t\t htonl(physoutif)))\n\t\t\t\tgoto nla_put_failure;\n\t\t}\n#endif\n\t}\n\n\tif (entskb->mark &&\n\t    nla_put_be32(skb, NFQA_MARK, htonl(entskb->mark)))\n\t\tgoto nla_put_failure;\n\n\tif (entskb->priority &&\n\t    nla_put_be32(skb, NFQA_PRIORITY, htonl(entskb->priority)))\n\t\tgoto nla_put_failure;\n\n\tif (indev && entskb->dev &&\n\t    skb_mac_header_was_set(entskb) &&\n\t    skb_mac_header_len(entskb) != 0) {\n\t\tstruct nfqnl_msg_packet_hw phw;\n\t\tint len;\n\n\t\tmemset(&phw, 0, sizeof(phw));\n\t\tlen = dev_parse_header(entskb, phw.hw_addr);\n\t\tif (len) {\n\t\t\tphw.hw_addrlen = htons(len);\n\t\t\tif (nla_put(skb, NFQA_HWADDR, sizeof(phw), &phw))\n\t\t\t\tgoto nla_put_failure;\n\t\t}\n\t}\n\n\tif (nfqnl_put_bridge(entry, skb) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (entry->state.hook <= NF_INET_FORWARD && tstamp) {\n\t\tstruct nfqnl_msg_packet_timestamp ts;\n\t\tstruct timespec64 kts = ktime_to_timespec64(tstamp);\n\n\t\tts.sec = cpu_to_be64(kts.tv_sec);\n\t\tts.usec = cpu_to_be64(kts.tv_nsec / NSEC_PER_USEC);\n\n\t\tif (nla_put(skb, NFQA_TIMESTAMP, sizeof(ts), &ts))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif ((queue->flags & NFQA_CFG_F_UID_GID) && entskb->sk &&\n\t    nfqnl_put_sk_uidgid(skb, entskb->sk) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (nfqnl_put_sk_classid(skb, entskb->sk) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (seclen && nla_put(skb, NFQA_SECCTX, seclen, secdata))\n\t\tgoto nla_put_failure;\n\n\tif (ct && nfnl_ct->build(skb, ct, ctinfo, NFQA_CT, NFQA_CT_INFO) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (cap_len > data_len &&\n\t    nla_put_be32(skb, NFQA_CAP_LEN, htonl(cap_len)))\n\t\tgoto nla_put_failure;\n\n\tif (nfqnl_put_packet_info(skb, entskb, csum_verify))\n\t\tgoto nla_put_failure;\n\n\tif (data_len) {\n\t\tstruct nlattr *nla;\n\n\t\tif (skb_tailroom(skb) < sizeof(*nla) + hlen)\n\t\t\tgoto nla_put_failure;\n\n\t\tnla = skb_put(skb, sizeof(*nla));\n\t\tnla->nla_type = NFQA_PAYLOAD;\n\t\tnla->nla_len = nla_attr_size(data_len);\n\n\t\tif (skb_zerocopy(skb, entskb, data_len, hlen))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tnlh->nlmsg_len = skb->len;\n\tif (seclen)\n\t\tsecurity_release_secctx(secdata, seclen);\n\treturn skb;\n\nnla_put_failure:\n\tskb_tx_error(entskb);\n\tkfree_skb(skb);\n\tnet_err_ratelimited(\"nf_queue: error creating packet message\\n\");\nnlmsg_failure:\n\tif (seclen)\n\t\tsecurity_release_secctx(secdata, seclen);\n\treturn NULL;\n}\n\nstatic bool nf_ct_drop_unconfirmed(const struct nf_queue_entry *entry)\n{\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\tstatic const unsigned long flags = IPS_CONFIRMED | IPS_DYING;\n\tconst struct nf_conn *ct = (void *)skb_nfct(entry->skb);\n\n\tif (ct && ((ct->status & flags) == IPS_DYING))\n\t\treturn true;\n#endif\n\treturn false;\n}\n\nstatic int\n__nfqnl_enqueue_packet(struct net *net, struct nfqnl_instance *queue,\n\t\t\tstruct nf_queue_entry *entry)\n{\n\tstruct sk_buff *nskb;\n\tint err = -ENOBUFS;\n\t__be32 *packet_id_ptr;\n\tint failopen = 0;\n\n\tnskb = nfqnl_build_packet_message(net, queue, entry, &packet_id_ptr);\n\tif (nskb == NULL) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\tspin_lock_bh(&queue->lock);\n\n\tif (nf_ct_drop_unconfirmed(entry))\n\t\tgoto err_out_free_nskb;\n\n\tif (queue->queue_total >= queue->queue_maxlen) {\n\t\tif (queue->flags & NFQA_CFG_F_FAIL_OPEN) {\n\t\t\tfailopen = 1;\n\t\t\terr = 0;\n\t\t} else {\n\t\t\tqueue->queue_dropped++;\n\t\t\tnet_warn_ratelimited(\"nf_queue: full at %d entries, dropping packets(s)\\n\",\n\t\t\t\t\t     queue->queue_total);\n\t\t}\n\t\tgoto err_out_free_nskb;\n\t}\n\tentry->id = ++queue->id_sequence;\n\t*packet_id_ptr = htonl(entry->id);\n\n\t \n\terr = nfnetlink_unicast(nskb, net, queue->peer_portid);\n\tif (err < 0) {\n\t\tif (queue->flags & NFQA_CFG_F_FAIL_OPEN) {\n\t\t\tfailopen = 1;\n\t\t\terr = 0;\n\t\t} else {\n\t\t\tqueue->queue_user_dropped++;\n\t\t}\n\t\tgoto err_out_unlock;\n\t}\n\n\t__enqueue_entry(queue, entry);\n\n\tspin_unlock_bh(&queue->lock);\n\treturn 0;\n\nerr_out_free_nskb:\n\tkfree_skb(nskb);\nerr_out_unlock:\n\tspin_unlock_bh(&queue->lock);\n\tif (failopen)\n\t\tnfqnl_reinject(entry, NF_ACCEPT);\nerr_out:\n\treturn err;\n}\n\nstatic struct nf_queue_entry *\nnf_queue_entry_dup(struct nf_queue_entry *e)\n{\n\tstruct nf_queue_entry *entry = kmemdup(e, e->size, GFP_ATOMIC);\n\n\tif (!entry)\n\t\treturn NULL;\n\n\tif (nf_queue_entry_get_refs(entry))\n\t\treturn entry;\n\n\tkfree(entry);\n\treturn NULL;\n}\n\n#if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)\n \nstatic void nf_bridge_adjust_skb_data(struct sk_buff *skb)\n{\n\tif (nf_bridge_info_get(skb))\n\t\t__skb_push(skb, skb->network_header - skb->mac_header);\n}\n\nstatic void nf_bridge_adjust_segmented_data(struct sk_buff *skb)\n{\n\tif (nf_bridge_info_get(skb))\n\t\t__skb_pull(skb, skb->network_header - skb->mac_header);\n}\n#else\n#define nf_bridge_adjust_skb_data(s) do {} while (0)\n#define nf_bridge_adjust_segmented_data(s) do {} while (0)\n#endif\n\nstatic int\n__nfqnl_enqueue_packet_gso(struct net *net, struct nfqnl_instance *queue,\n\t\t\t   struct sk_buff *skb, struct nf_queue_entry *entry)\n{\n\tint ret = -ENOMEM;\n\tstruct nf_queue_entry *entry_seg;\n\n\tnf_bridge_adjust_segmented_data(skb);\n\n\tif (skb->next == NULL) {  \n\t\tstruct sk_buff *gso_skb = entry->skb;\n\t\tentry->skb = skb;\n\t\tret = __nfqnl_enqueue_packet(net, queue, entry);\n\t\tif (ret)\n\t\t\tentry->skb = gso_skb;\n\t\treturn ret;\n\t}\n\n\tskb_mark_not_on_list(skb);\n\n\tentry_seg = nf_queue_entry_dup(entry);\n\tif (entry_seg) {\n\t\tentry_seg->skb = skb;\n\t\tret = __nfqnl_enqueue_packet(net, queue, entry_seg);\n\t\tif (ret)\n\t\t\tnf_queue_entry_free(entry_seg);\n\t}\n\treturn ret;\n}\n\nstatic int\nnfqnl_enqueue_packet(struct nf_queue_entry *entry, unsigned int queuenum)\n{\n\tunsigned int queued;\n\tstruct nfqnl_instance *queue;\n\tstruct sk_buff *skb, *segs, *nskb;\n\tint err = -ENOBUFS;\n\tstruct net *net = entry->state.net;\n\tstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\n\n\t \n\tqueue = instance_lookup(q, queuenum);\n\tif (!queue)\n\t\treturn -ESRCH;\n\n\tif (queue->copy_mode == NFQNL_COPY_NONE)\n\t\treturn -EINVAL;\n\n\tskb = entry->skb;\n\n\tswitch (entry->state.pf) {\n\tcase NFPROTO_IPV4:\n\t\tskb->protocol = htons(ETH_P_IP);\n\t\tbreak;\n\tcase NFPROTO_IPV6:\n\t\tskb->protocol = htons(ETH_P_IPV6);\n\t\tbreak;\n\t}\n\n\tif ((queue->flags & NFQA_CFG_F_GSO) || !skb_is_gso(skb))\n\t\treturn __nfqnl_enqueue_packet(net, queue, entry);\n\n\tnf_bridge_adjust_skb_data(skb);\n\tsegs = skb_gso_segment(skb, 0);\n\t \n\tif (IS_ERR_OR_NULL(segs))\n\t\tgoto out_err;\n\tqueued = 0;\n\terr = 0;\n\tskb_list_walk_safe(segs, segs, nskb) {\n\t\tif (err == 0)\n\t\t\terr = __nfqnl_enqueue_packet_gso(net, queue,\n\t\t\t\t\t\t\tsegs, entry);\n\t\tif (err == 0)\n\t\t\tqueued++;\n\t\telse\n\t\t\tkfree_skb(segs);\n\t}\n\n\tif (queued) {\n\t\tif (err)  \n\t\t\tnf_queue_entry_free(entry);\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n out_err:\n\tnf_bridge_adjust_segmented_data(skb);\n\treturn err;\n}\n\nstatic int\nnfqnl_mangle(void *data, unsigned int data_len, struct nf_queue_entry *e, int diff)\n{\n\tstruct sk_buff *nskb;\n\n\tif (diff < 0) {\n\t\tunsigned int min_len = skb_transport_offset(e->skb);\n\n\t\tif (data_len < min_len)\n\t\t\treturn -EINVAL;\n\n\t\tif (pskb_trim(e->skb, data_len))\n\t\t\treturn -ENOMEM;\n\t} else if (diff > 0) {\n\t\tif (data_len > 0xFFFF)\n\t\t\treturn -EINVAL;\n\t\tif (diff > skb_tailroom(e->skb)) {\n\t\t\tnskb = skb_copy_expand(e->skb, skb_headroom(e->skb),\n\t\t\t\t\t       diff, GFP_ATOMIC);\n\t\t\tif (!nskb)\n\t\t\t\treturn -ENOMEM;\n\t\t\tkfree_skb(e->skb);\n\t\t\te->skb = nskb;\n\t\t}\n\t\tskb_put(e->skb, diff);\n\t}\n\tif (skb_ensure_writable(e->skb, data_len))\n\t\treturn -ENOMEM;\n\tskb_copy_to_linear_data(e->skb, data, data_len);\n\te->skb->ip_summed = CHECKSUM_NONE;\n\treturn 0;\n}\n\nstatic int\nnfqnl_set_mode(struct nfqnl_instance *queue,\n\t       unsigned char mode, unsigned int range)\n{\n\tint status = 0;\n\n\tspin_lock_bh(&queue->lock);\n\tswitch (mode) {\n\tcase NFQNL_COPY_NONE:\n\tcase NFQNL_COPY_META:\n\t\tqueue->copy_mode = mode;\n\t\tqueue->copy_range = 0;\n\t\tbreak;\n\n\tcase NFQNL_COPY_PACKET:\n\t\tqueue->copy_mode = mode;\n\t\tif (range == 0 || range > NFQNL_MAX_COPY_RANGE)\n\t\t\tqueue->copy_range = NFQNL_MAX_COPY_RANGE;\n\t\telse\n\t\t\tqueue->copy_range = range;\n\t\tbreak;\n\n\tdefault:\n\t\tstatus = -EINVAL;\n\n\t}\n\tspin_unlock_bh(&queue->lock);\n\n\treturn status;\n}\n\nstatic int\ndev_cmp(struct nf_queue_entry *entry, unsigned long ifindex)\n{\n#if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)\n\tint physinif, physoutif;\n\n\tphysinif = nf_bridge_get_physinif(entry->skb);\n\tphysoutif = nf_bridge_get_physoutif(entry->skb);\n\n\tif (physinif == ifindex || physoutif == ifindex)\n\t\treturn 1;\n#endif\n\tif (entry->state.in)\n\t\tif (entry->state.in->ifindex == ifindex)\n\t\t\treturn 1;\n\tif (entry->state.out)\n\t\tif (entry->state.out->ifindex == ifindex)\n\t\t\treturn 1;\n\n\treturn 0;\n}\n\n \nstatic void\nnfqnl_dev_drop(struct net *net, int ifindex)\n{\n\tint i;\n\tstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\n\n\trcu_read_lock();\n\n\tfor (i = 0; i < INSTANCE_BUCKETS; i++) {\n\t\tstruct nfqnl_instance *inst;\n\t\tstruct hlist_head *head = &q->instance_table[i];\n\n\t\thlist_for_each_entry_rcu(inst, head, hlist)\n\t\t\tnfqnl_flush(inst, dev_cmp, ifindex);\n\t}\n\n\trcu_read_unlock();\n}\n\nstatic int\nnfqnl_rcv_dev_event(struct notifier_block *this,\n\t\t    unsigned long event, void *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\n\t \n\tif (event == NETDEV_DOWN)\n\t\tnfqnl_dev_drop(dev_net(dev), dev->ifindex);\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block nfqnl_dev_notifier = {\n\t.notifier_call\t= nfqnl_rcv_dev_event,\n};\n\nstatic void nfqnl_nf_hook_drop(struct net *net)\n{\n\tstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\n\tint i;\n\n\t \n\tif (!q)\n\t\treturn;\n\n\tfor (i = 0; i < INSTANCE_BUCKETS; i++) {\n\t\tstruct nfqnl_instance *inst;\n\t\tstruct hlist_head *head = &q->instance_table[i];\n\n\t\thlist_for_each_entry_rcu(inst, head, hlist)\n\t\t\tnfqnl_flush(inst, NULL, 0);\n\t}\n}\n\nstatic int\nnfqnl_rcv_nl_event(struct notifier_block *this,\n\t\t   unsigned long event, void *ptr)\n{\n\tstruct netlink_notify *n = ptr;\n\tstruct nfnl_queue_net *q = nfnl_queue_pernet(n->net);\n\n\tif (event == NETLINK_URELEASE && n->protocol == NETLINK_NETFILTER) {\n\t\tint i;\n\n\t\t \n\t\tspin_lock(&q->instances_lock);\n\t\tfor (i = 0; i < INSTANCE_BUCKETS; i++) {\n\t\t\tstruct hlist_node *t2;\n\t\t\tstruct nfqnl_instance *inst;\n\t\t\tstruct hlist_head *head = &q->instance_table[i];\n\n\t\t\thlist_for_each_entry_safe(inst, t2, head, hlist) {\n\t\t\t\tif (n->portid == inst->peer_portid)\n\t\t\t\t\t__instance_destroy(inst);\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&q->instances_lock);\n\t}\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block nfqnl_rtnl_notifier = {\n\t.notifier_call\t= nfqnl_rcv_nl_event,\n};\n\nstatic const struct nla_policy nfqa_vlan_policy[NFQA_VLAN_MAX + 1] = {\n\t[NFQA_VLAN_TCI]\t\t= { .type = NLA_U16},\n\t[NFQA_VLAN_PROTO]\t= { .type = NLA_U16},\n};\n\nstatic const struct nla_policy nfqa_verdict_policy[NFQA_MAX+1] = {\n\t[NFQA_VERDICT_HDR]\t= { .len = sizeof(struct nfqnl_msg_verdict_hdr) },\n\t[NFQA_MARK]\t\t= { .type = NLA_U32 },\n\t[NFQA_PAYLOAD]\t\t= { .type = NLA_UNSPEC },\n\t[NFQA_CT]\t\t= { .type = NLA_UNSPEC },\n\t[NFQA_EXP]\t\t= { .type = NLA_UNSPEC },\n\t[NFQA_VLAN]\t\t= { .type = NLA_NESTED },\n\t[NFQA_PRIORITY]\t\t= { .type = NLA_U32 },\n};\n\nstatic const struct nla_policy nfqa_verdict_batch_policy[NFQA_MAX+1] = {\n\t[NFQA_VERDICT_HDR]\t= { .len = sizeof(struct nfqnl_msg_verdict_hdr) },\n\t[NFQA_MARK]\t\t= { .type = NLA_U32 },\n\t[NFQA_PRIORITY]\t\t= { .type = NLA_U32 },\n};\n\nstatic struct nfqnl_instance *\nverdict_instance_lookup(struct nfnl_queue_net *q, u16 queue_num, u32 nlportid)\n{\n\tstruct nfqnl_instance *queue;\n\n\tqueue = instance_lookup(q, queue_num);\n\tif (!queue)\n\t\treturn ERR_PTR(-ENODEV);\n\n\tif (queue->peer_portid != nlportid)\n\t\treturn ERR_PTR(-EPERM);\n\n\treturn queue;\n}\n\nstatic struct nfqnl_msg_verdict_hdr*\nverdicthdr_get(const struct nlattr * const nfqa[])\n{\n\tstruct nfqnl_msg_verdict_hdr *vhdr;\n\tunsigned int verdict;\n\n\tif (!nfqa[NFQA_VERDICT_HDR])\n\t\treturn NULL;\n\n\tvhdr = nla_data(nfqa[NFQA_VERDICT_HDR]);\n\tverdict = ntohl(vhdr->verdict) & NF_VERDICT_MASK;\n\tif (verdict > NF_MAX_VERDICT || verdict == NF_STOLEN)\n\t\treturn NULL;\n\treturn vhdr;\n}\n\nstatic int nfq_id_after(unsigned int id, unsigned int max)\n{\n\treturn (int)(id - max) > 0;\n}\n\nstatic int nfqnl_recv_verdict_batch(struct sk_buff *skb,\n\t\t\t\t    const struct nfnl_info *info,\n\t\t\t\t    const struct nlattr * const nfqa[])\n{\n\tstruct nfnl_queue_net *q = nfnl_queue_pernet(info->net);\n\tu16 queue_num = ntohs(info->nfmsg->res_id);\n\tstruct nf_queue_entry *entry, *tmp;\n\tstruct nfqnl_msg_verdict_hdr *vhdr;\n\tstruct nfqnl_instance *queue;\n\tunsigned int verdict, maxid;\n\tLIST_HEAD(batch_list);\n\n\tqueue = verdict_instance_lookup(q, queue_num,\n\t\t\t\t\tNETLINK_CB(skb).portid);\n\tif (IS_ERR(queue))\n\t\treturn PTR_ERR(queue);\n\n\tvhdr = verdicthdr_get(nfqa);\n\tif (!vhdr)\n\t\treturn -EINVAL;\n\n\tverdict = ntohl(vhdr->verdict);\n\tmaxid = ntohl(vhdr->id);\n\n\tspin_lock_bh(&queue->lock);\n\n\tlist_for_each_entry_safe(entry, tmp, &queue->queue_list, list) {\n\t\tif (nfq_id_after(entry->id, maxid))\n\t\t\tbreak;\n\t\t__dequeue_entry(queue, entry);\n\t\tlist_add_tail(&entry->list, &batch_list);\n\t}\n\n\tspin_unlock_bh(&queue->lock);\n\n\tif (list_empty(&batch_list))\n\t\treturn -ENOENT;\n\n\tlist_for_each_entry_safe(entry, tmp, &batch_list, list) {\n\t\tif (nfqa[NFQA_MARK])\n\t\t\tentry->skb->mark = ntohl(nla_get_be32(nfqa[NFQA_MARK]));\n\n\t\tif (nfqa[NFQA_PRIORITY])\n\t\t\tentry->skb->priority = ntohl(nla_get_be32(nfqa[NFQA_PRIORITY]));\n\n\t\tnfqnl_reinject(entry, verdict);\n\t}\n\treturn 0;\n}\n\nstatic struct nf_conn *nfqnl_ct_parse(const struct nfnl_ct_hook *nfnl_ct,\n\t\t\t\t      const struct nlmsghdr *nlh,\n\t\t\t\t      const struct nlattr * const nfqa[],\n\t\t\t\t      struct nf_queue_entry *entry,\n\t\t\t\t      enum ip_conntrack_info *ctinfo)\n{\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\tstruct nf_conn *ct;\n\n\tct = nf_ct_get(entry->skb, ctinfo);\n\tif (ct == NULL)\n\t\treturn NULL;\n\n\tif (nfnl_ct->parse(nfqa[NFQA_CT], ct) < 0)\n\t\treturn NULL;\n\n\tif (nfqa[NFQA_EXP])\n\t\tnfnl_ct->attach_expect(nfqa[NFQA_EXP], ct,\n\t\t\t\t      NETLINK_CB(entry->skb).portid,\n\t\t\t\t      nlmsg_report(nlh));\n\treturn ct;\n#else\n\treturn NULL;\n#endif\n}\n\nstatic int nfqa_parse_bridge(struct nf_queue_entry *entry,\n\t\t\t     const struct nlattr * const nfqa[])\n{\n\tif (nfqa[NFQA_VLAN]) {\n\t\tstruct nlattr *tb[NFQA_VLAN_MAX + 1];\n\t\tint err;\n\n\t\terr = nla_parse_nested_deprecated(tb, NFQA_VLAN_MAX,\n\t\t\t\t\t\t  nfqa[NFQA_VLAN],\n\t\t\t\t\t\t  nfqa_vlan_policy, NULL);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (!tb[NFQA_VLAN_TCI] || !tb[NFQA_VLAN_PROTO])\n\t\t\treturn -EINVAL;\n\n\t\t__vlan_hwaccel_put_tag(entry->skb,\n\t\t\tnla_get_be16(tb[NFQA_VLAN_PROTO]),\n\t\t\tntohs(nla_get_be16(tb[NFQA_VLAN_TCI])));\n\t}\n\n\tif (nfqa[NFQA_L2HDR]) {\n\t\tint mac_header_len = entry->skb->network_header -\n\t\t\tentry->skb->mac_header;\n\n\t\tif (mac_header_len != nla_len(nfqa[NFQA_L2HDR]))\n\t\t\treturn -EINVAL;\n\t\telse if (mac_header_len > 0)\n\t\t\tmemcpy(skb_mac_header(entry->skb),\n\t\t\t       nla_data(nfqa[NFQA_L2HDR]),\n\t\t\t       mac_header_len);\n\t}\n\n\treturn 0;\n}\n\nstatic int nfqnl_recv_verdict(struct sk_buff *skb, const struct nfnl_info *info,\n\t\t\t      const struct nlattr * const nfqa[])\n{\n\tstruct nfnl_queue_net *q = nfnl_queue_pernet(info->net);\n\tu_int16_t queue_num = ntohs(info->nfmsg->res_id);\n\tconst struct nfnl_ct_hook *nfnl_ct;\n\tstruct nfqnl_msg_verdict_hdr *vhdr;\n\tenum ip_conntrack_info ctinfo;\n\tstruct nfqnl_instance *queue;\n\tstruct nf_queue_entry *entry;\n\tstruct nf_conn *ct = NULL;\n\tunsigned int verdict;\n\tint err;\n\n\tqueue = verdict_instance_lookup(q, queue_num,\n\t\t\t\t\tNETLINK_CB(skb).portid);\n\tif (IS_ERR(queue))\n\t\treturn PTR_ERR(queue);\n\n\tvhdr = verdicthdr_get(nfqa);\n\tif (!vhdr)\n\t\treturn -EINVAL;\n\n\tverdict = ntohl(vhdr->verdict);\n\n\tentry = find_dequeue_entry(queue, ntohl(vhdr->id));\n\tif (entry == NULL)\n\t\treturn -ENOENT;\n\n\t \n\tnfnl_ct = rcu_dereference(nfnl_ct_hook);\n\n\tif (nfqa[NFQA_CT]) {\n\t\tif (nfnl_ct != NULL)\n\t\t\tct = nfqnl_ct_parse(nfnl_ct, info->nlh, nfqa, entry,\n\t\t\t\t\t    &ctinfo);\n\t}\n\n\tif (entry->state.pf == PF_BRIDGE) {\n\t\terr = nfqa_parse_bridge(entry, nfqa);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\tif (nfqa[NFQA_PAYLOAD]) {\n\t\tu16 payload_len = nla_len(nfqa[NFQA_PAYLOAD]);\n\t\tint diff = payload_len - entry->skb->len;\n\n\t\tif (nfqnl_mangle(nla_data(nfqa[NFQA_PAYLOAD]),\n\t\t\t\t payload_len, entry, diff) < 0)\n\t\t\tverdict = NF_DROP;\n\n\t\tif (ct && diff)\n\t\t\tnfnl_ct->seq_adjust(entry->skb, ct, ctinfo, diff);\n\t}\n\n\tif (nfqa[NFQA_MARK])\n\t\tentry->skb->mark = ntohl(nla_get_be32(nfqa[NFQA_MARK]));\n\n\tif (nfqa[NFQA_PRIORITY])\n\t\tentry->skb->priority = ntohl(nla_get_be32(nfqa[NFQA_PRIORITY]));\n\n\tnfqnl_reinject(entry, verdict);\n\treturn 0;\n}\n\nstatic int nfqnl_recv_unsupp(struct sk_buff *skb, const struct nfnl_info *info,\n\t\t\t     const struct nlattr * const cda[])\n{\n\treturn -ENOTSUPP;\n}\n\nstatic const struct nla_policy nfqa_cfg_policy[NFQA_CFG_MAX+1] = {\n\t[NFQA_CFG_CMD]\t\t= { .len = sizeof(struct nfqnl_msg_config_cmd) },\n\t[NFQA_CFG_PARAMS]\t= { .len = sizeof(struct nfqnl_msg_config_params) },\n\t[NFQA_CFG_QUEUE_MAXLEN]\t= { .type = NLA_U32 },\n\t[NFQA_CFG_MASK]\t\t= { .type = NLA_U32 },\n\t[NFQA_CFG_FLAGS]\t= { .type = NLA_U32 },\n};\n\nstatic const struct nf_queue_handler nfqh = {\n\t.outfn\t\t= nfqnl_enqueue_packet,\n\t.nf_hook_drop\t= nfqnl_nf_hook_drop,\n};\n\nstatic int nfqnl_recv_config(struct sk_buff *skb, const struct nfnl_info *info,\n\t\t\t     const struct nlattr * const nfqa[])\n{\n\tstruct nfnl_queue_net *q = nfnl_queue_pernet(info->net);\n\tu_int16_t queue_num = ntohs(info->nfmsg->res_id);\n\tstruct nfqnl_msg_config_cmd *cmd = NULL;\n\tstruct nfqnl_instance *queue;\n\t__u32 flags = 0, mask = 0;\n\tint ret = 0;\n\n\tif (nfqa[NFQA_CFG_CMD]) {\n\t\tcmd = nla_data(nfqa[NFQA_CFG_CMD]);\n\n\t\t \n\t\tswitch (cmd->command) {\n\t\tcase NFQNL_CFG_CMD_PF_BIND: return 0;\n\t\tcase NFQNL_CFG_CMD_PF_UNBIND: return 0;\n\t\t}\n\t}\n\n\t \n\tif (nfqa[NFQA_CFG_FLAGS]) {\n\t\tif (!nfqa[NFQA_CFG_MASK]) {\n\t\t\t \n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tflags = ntohl(nla_get_be32(nfqa[NFQA_CFG_FLAGS]));\n\t\tmask = ntohl(nla_get_be32(nfqa[NFQA_CFG_MASK]));\n\n\t\tif (flags >= NFQA_CFG_F_MAX)\n\t\t\treturn -EOPNOTSUPP;\n\n#if !IS_ENABLED(CONFIG_NETWORK_SECMARK)\n\t\tif (flags & mask & NFQA_CFG_F_SECCTX)\n\t\t\treturn -EOPNOTSUPP;\n#endif\n\t\tif ((flags & mask & NFQA_CFG_F_CONNTRACK) &&\n\t\t    !rcu_access_pointer(nfnl_ct_hook)) {\n#ifdef CONFIG_MODULES\n\t\t\tnfnl_unlock(NFNL_SUBSYS_QUEUE);\n\t\t\trequest_module(\"ip_conntrack_netlink\");\n\t\t\tnfnl_lock(NFNL_SUBSYS_QUEUE);\n\t\t\tif (rcu_access_pointer(nfnl_ct_hook))\n\t\t\t\treturn -EAGAIN;\n#endif\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t}\n\n\trcu_read_lock();\n\tqueue = instance_lookup(q, queue_num);\n\tif (queue && queue->peer_portid != NETLINK_CB(skb).portid) {\n\t\tret = -EPERM;\n\t\tgoto err_out_unlock;\n\t}\n\n\tif (cmd != NULL) {\n\t\tswitch (cmd->command) {\n\t\tcase NFQNL_CFG_CMD_BIND:\n\t\t\tif (queue) {\n\t\t\t\tret = -EBUSY;\n\t\t\t\tgoto err_out_unlock;\n\t\t\t}\n\t\t\tqueue = instance_create(q, queue_num,\n\t\t\t\t\t\tNETLINK_CB(skb).portid);\n\t\t\tif (IS_ERR(queue)) {\n\t\t\t\tret = PTR_ERR(queue);\n\t\t\t\tgoto err_out_unlock;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase NFQNL_CFG_CMD_UNBIND:\n\t\t\tif (!queue) {\n\t\t\t\tret = -ENODEV;\n\t\t\t\tgoto err_out_unlock;\n\t\t\t}\n\t\t\tinstance_destroy(q, queue);\n\t\t\tgoto err_out_unlock;\n\t\tcase NFQNL_CFG_CMD_PF_BIND:\n\t\tcase NFQNL_CFG_CMD_PF_UNBIND:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -ENOTSUPP;\n\t\t\tgoto err_out_unlock;\n\t\t}\n\t}\n\n\tif (!queue) {\n\t\tret = -ENODEV;\n\t\tgoto err_out_unlock;\n\t}\n\n\tif (nfqa[NFQA_CFG_PARAMS]) {\n\t\tstruct nfqnl_msg_config_params *params =\n\t\t\tnla_data(nfqa[NFQA_CFG_PARAMS]);\n\n\t\tnfqnl_set_mode(queue, params->copy_mode,\n\t\t\t\tntohl(params->copy_range));\n\t}\n\n\tif (nfqa[NFQA_CFG_QUEUE_MAXLEN]) {\n\t\t__be32 *queue_maxlen = nla_data(nfqa[NFQA_CFG_QUEUE_MAXLEN]);\n\n\t\tspin_lock_bh(&queue->lock);\n\t\tqueue->queue_maxlen = ntohl(*queue_maxlen);\n\t\tspin_unlock_bh(&queue->lock);\n\t}\n\n\tif (nfqa[NFQA_CFG_FLAGS]) {\n\t\tspin_lock_bh(&queue->lock);\n\t\tqueue->flags &= ~mask;\n\t\tqueue->flags |= flags & mask;\n\t\tspin_unlock_bh(&queue->lock);\n\t}\n\nerr_out_unlock:\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic const struct nfnl_callback nfqnl_cb[NFQNL_MSG_MAX] = {\n\t[NFQNL_MSG_PACKET]\t= {\n\t\t.call\t\t= nfqnl_recv_unsupp,\n\t\t.type\t\t= NFNL_CB_RCU,\n\t\t.attr_count\t= NFQA_MAX,\n\t},\n\t[NFQNL_MSG_VERDICT]\t= {\n\t\t.call\t\t= nfqnl_recv_verdict,\n\t\t.type\t\t= NFNL_CB_RCU,\n\t\t.attr_count\t= NFQA_MAX,\n\t\t.policy\t\t= nfqa_verdict_policy\n\t},\n\t[NFQNL_MSG_CONFIG]\t= {\n\t\t.call\t\t= nfqnl_recv_config,\n\t\t.type\t\t= NFNL_CB_MUTEX,\n\t\t.attr_count\t= NFQA_CFG_MAX,\n\t\t.policy\t\t= nfqa_cfg_policy\n\t},\n\t[NFQNL_MSG_VERDICT_BATCH] = {\n\t\t.call\t\t= nfqnl_recv_verdict_batch,\n\t\t.type\t\t= NFNL_CB_RCU,\n\t\t.attr_count\t= NFQA_MAX,\n\t\t.policy\t\t= nfqa_verdict_batch_policy\n\t},\n};\n\nstatic const struct nfnetlink_subsystem nfqnl_subsys = {\n\t.name\t\t= \"nf_queue\",\n\t.subsys_id\t= NFNL_SUBSYS_QUEUE,\n\t.cb_count\t= NFQNL_MSG_MAX,\n\t.cb\t\t= nfqnl_cb,\n};\n\n#ifdef CONFIG_PROC_FS\nstruct iter_state {\n\tstruct seq_net_private p;\n\tunsigned int bucket;\n};\n\nstatic struct hlist_node *get_first(struct seq_file *seq)\n{\n\tstruct iter_state *st = seq->private;\n\tstruct net *net;\n\tstruct nfnl_queue_net *q;\n\n\tif (!st)\n\t\treturn NULL;\n\n\tnet = seq_file_net(seq);\n\tq = nfnl_queue_pernet(net);\n\tfor (st->bucket = 0; st->bucket < INSTANCE_BUCKETS; st->bucket++) {\n\t\tif (!hlist_empty(&q->instance_table[st->bucket]))\n\t\t\treturn q->instance_table[st->bucket].first;\n\t}\n\treturn NULL;\n}\n\nstatic struct hlist_node *get_next(struct seq_file *seq, struct hlist_node *h)\n{\n\tstruct iter_state *st = seq->private;\n\tstruct net *net = seq_file_net(seq);\n\n\th = h->next;\n\twhile (!h) {\n\t\tstruct nfnl_queue_net *q;\n\n\t\tif (++st->bucket >= INSTANCE_BUCKETS)\n\t\t\treturn NULL;\n\n\t\tq = nfnl_queue_pernet(net);\n\t\th = q->instance_table[st->bucket].first;\n\t}\n\treturn h;\n}\n\nstatic struct hlist_node *get_idx(struct seq_file *seq, loff_t pos)\n{\n\tstruct hlist_node *head;\n\thead = get_first(seq);\n\n\tif (head)\n\t\twhile (pos && (head = get_next(seq, head)))\n\t\t\tpos--;\n\treturn pos ? NULL : head;\n}\n\nstatic void *seq_start(struct seq_file *s, loff_t *pos)\n\t__acquires(nfnl_queue_pernet(seq_file_net(s))->instances_lock)\n{\n\tspin_lock(&nfnl_queue_pernet(seq_file_net(s))->instances_lock);\n\treturn get_idx(s, *pos);\n}\n\nstatic void *seq_next(struct seq_file *s, void *v, loff_t *pos)\n{\n\t(*pos)++;\n\treturn get_next(s, v);\n}\n\nstatic void seq_stop(struct seq_file *s, void *v)\n\t__releases(nfnl_queue_pernet(seq_file_net(s))->instances_lock)\n{\n\tspin_unlock(&nfnl_queue_pernet(seq_file_net(s))->instances_lock);\n}\n\nstatic int seq_show(struct seq_file *s, void *v)\n{\n\tconst struct nfqnl_instance *inst = v;\n\n\tseq_printf(s, \"%5u %6u %5u %1u %5u %5u %5u %8u %2d\\n\",\n\t\t   inst->queue_num,\n\t\t   inst->peer_portid, inst->queue_total,\n\t\t   inst->copy_mode, inst->copy_range,\n\t\t   inst->queue_dropped, inst->queue_user_dropped,\n\t\t   inst->id_sequence, 1);\n\treturn 0;\n}\n\nstatic const struct seq_operations nfqnl_seq_ops = {\n\t.start\t= seq_start,\n\t.next\t= seq_next,\n\t.stop\t= seq_stop,\n\t.show\t= seq_show,\n};\n#endif  \n\nstatic int __net_init nfnl_queue_net_init(struct net *net)\n{\n\tunsigned int i;\n\tstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\n\n\tfor (i = 0; i < INSTANCE_BUCKETS; i++)\n\t\tINIT_HLIST_HEAD(&q->instance_table[i]);\n\n\tspin_lock_init(&q->instances_lock);\n\n#ifdef CONFIG_PROC_FS\n\tif (!proc_create_net(\"nfnetlink_queue\", 0440, net->nf.proc_netfilter,\n\t\t\t&nfqnl_seq_ops, sizeof(struct iter_state)))\n\t\treturn -ENOMEM;\n#endif\n\treturn 0;\n}\n\nstatic void __net_exit nfnl_queue_net_exit(struct net *net)\n{\n\tstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\n\tunsigned int i;\n\n#ifdef CONFIG_PROC_FS\n\tremove_proc_entry(\"nfnetlink_queue\", net->nf.proc_netfilter);\n#endif\n\tfor (i = 0; i < INSTANCE_BUCKETS; i++)\n\t\tWARN_ON_ONCE(!hlist_empty(&q->instance_table[i]));\n}\n\nstatic struct pernet_operations nfnl_queue_net_ops = {\n\t.init\t\t= nfnl_queue_net_init,\n\t.exit\t\t= nfnl_queue_net_exit,\n\t.id\t\t= &nfnl_queue_net_id,\n\t.size\t\t= sizeof(struct nfnl_queue_net),\n};\n\nstatic int __init nfnetlink_queue_init(void)\n{\n\tint status;\n\n\tstatus = register_pernet_subsys(&nfnl_queue_net_ops);\n\tif (status < 0) {\n\t\tpr_err(\"failed to register pernet ops\\n\");\n\t\tgoto out;\n\t}\n\n\tnetlink_register_notifier(&nfqnl_rtnl_notifier);\n\tstatus = nfnetlink_subsys_register(&nfqnl_subsys);\n\tif (status < 0) {\n\t\tpr_err(\"failed to create netlink socket\\n\");\n\t\tgoto cleanup_netlink_notifier;\n\t}\n\n\tstatus = register_netdevice_notifier(&nfqnl_dev_notifier);\n\tif (status < 0) {\n\t\tpr_err(\"failed to register netdevice notifier\\n\");\n\t\tgoto cleanup_netlink_subsys;\n\t}\n\n\tnf_register_queue_handler(&nfqh);\n\n\treturn status;\n\ncleanup_netlink_subsys:\n\tnfnetlink_subsys_unregister(&nfqnl_subsys);\ncleanup_netlink_notifier:\n\tnetlink_unregister_notifier(&nfqnl_rtnl_notifier);\n\tunregister_pernet_subsys(&nfnl_queue_net_ops);\nout:\n\treturn status;\n}\n\nstatic void __exit nfnetlink_queue_fini(void)\n{\n\tnf_unregister_queue_handler();\n\tunregister_netdevice_notifier(&nfqnl_dev_notifier);\n\tnfnetlink_subsys_unregister(&nfqnl_subsys);\n\tnetlink_unregister_notifier(&nfqnl_rtnl_notifier);\n\tunregister_pernet_subsys(&nfnl_queue_net_ops);\n\n\trcu_barrier();  \n}\n\nMODULE_DESCRIPTION(\"netfilter packet queue handler\");\nMODULE_AUTHOR(\"Harald Welte <laforge@netfilter.org>\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_NFNL_SUBSYS(NFNL_SUBSYS_QUEUE);\n\nmodule_init(nfnetlink_queue_init);\nmodule_exit(nfnetlink_queue_fini);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}