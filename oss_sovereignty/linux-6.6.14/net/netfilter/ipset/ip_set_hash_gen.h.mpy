{
  "module_name": "ip_set_hash_gen.h",
  "hash_id": "505a9dc69ba63b33f800ab8492974af3b1c32d35f9f41415b2edae9d30455d8b",
  "original_prompt": "Ingested from linux-6.6.14/net/netfilter/ipset/ip_set_hash_gen.h",
  "human_readable_source": " \n \n\n#ifndef _IP_SET_HASH_GEN_H\n#define _IP_SET_HASH_GEN_H\n\n#include <linux/rcupdate.h>\n#include <linux/jhash.h>\n#include <linux/types.h>\n#include <linux/netfilter/nfnetlink.h>\n#include <linux/netfilter/ipset/ip_set.h>\n\n#define __ipset_dereference(p)\t\t\\\n\trcu_dereference_protected(p, 1)\n#define ipset_dereference_nfnl(p)\t\\\n\trcu_dereference_protected(p,\t\\\n\t\tlockdep_nfnl_is_held(NFNL_SUBSYS_IPSET))\n#define ipset_dereference_set(p, set) \t\\\n\trcu_dereference_protected(p,\t\\\n\t\tlockdep_nfnl_is_held(NFNL_SUBSYS_IPSET) || \\\n\t\tlockdep_is_held(&(set)->lock))\n#define ipset_dereference_bh_nfnl(p)\t\\\n\trcu_dereference_bh_check(p, \t\\\n\t\tlockdep_nfnl_is_held(NFNL_SUBSYS_IPSET))\n\n \n\n \n#define AHASH_INIT_SIZE\t\t\t2\n \n#define AHASH_MAX_SIZE\t\t\t(6 * AHASH_INIT_SIZE)\n \n#define AHASH_MAX_TUNED\t\t\t64\n#define AHASH_MAX(h)\t\t\t((h)->bucketsize)\n\n \nstruct hbucket {\n\tstruct rcu_head rcu;\t \n\t \n\tDECLARE_BITMAP(used, AHASH_MAX_TUNED);\n\tu8 size;\t\t \n\tu8 pos;\t\t\t \n\tunsigned char value[]\t \n\t\t__aligned(__alignof__(u64));\n};\n\n \n#define HTABLE_REGION_BITS\t10\n#define ahash_numof_locks(htable_bits)\t\t\\\n\t((htable_bits) < HTABLE_REGION_BITS ? 1\t\\\n\t\t: jhash_size((htable_bits) - HTABLE_REGION_BITS))\n#define ahash_sizeof_regions(htable_bits)\t\t\\\n\t(ahash_numof_locks(htable_bits) * sizeof(struct ip_set_region))\n#define ahash_region(n, htable_bits)\t\t\\\n\t((n) % ahash_numof_locks(htable_bits))\n#define ahash_bucket_start(h,  htable_bits)\t\\\n\t((htable_bits) < HTABLE_REGION_BITS ? 0\t\\\n\t\t: (h) * jhash_size(HTABLE_REGION_BITS))\n#define ahash_bucket_end(h,  htable_bits)\t\\\n\t((htable_bits) < HTABLE_REGION_BITS ? jhash_size(htable_bits)\t\\\n\t\t: ((h) + 1) * jhash_size(HTABLE_REGION_BITS))\n\nstruct htable_gc {\n\tstruct delayed_work dwork;\n\tstruct ip_set *set;\t \n\tu32 region;\t\t \n};\n\n \nstruct htable {\n\tatomic_t ref;\t\t \n\tatomic_t uref;\t\t \n\tu8 htable_bits;\t\t \n\tu32 maxelem;\t\t \n\tstruct ip_set_region *hregion;\t \n\tstruct hbucket __rcu *bucket[];  \n};\n\n#define hbucket(h, i)\t\t((h)->bucket[i])\n#define ext_size(n, dsize)\t\\\n\t(sizeof(struct hbucket) + (n) * (dsize))\n\n#ifndef IPSET_NET_COUNT\n#define IPSET_NET_COUNT\t\t1\n#endif\n\n \nstruct net_prefixes {\n\tu32 nets[IPSET_NET_COUNT];  \n\tu8 cidr[IPSET_NET_COUNT];   \n};\n\n \nstatic size_t\nhtable_size(u8 hbits)\n{\n\tsize_t hsize;\n\n\t \n\tif (hbits > 31)\n\t\treturn 0;\n\thsize = jhash_size(hbits);\n\tif ((INT_MAX - sizeof(struct htable)) / sizeof(struct hbucket *)\n\t    < hsize)\n\t\treturn 0;\n\n\treturn hsize * sizeof(struct hbucket *) + sizeof(struct htable);\n}\n\n#ifdef IP_SET_HASH_WITH_NETS\n#if IPSET_NET_COUNT > 1\n#define __CIDR(cidr, i)\t\t(cidr[i])\n#else\n#define __CIDR(cidr, i)\t\t(cidr)\n#endif\n\n \n#define NCIDR_PUT(cidr)\t\t((cidr) + 1)\n#define NCIDR_GET(cidr)\t\t((cidr) - 1)\n\n#ifdef IP_SET_HASH_WITH_NETS_PACKED\n \n#define DCIDR_PUT(cidr)\t\t((cidr) - 1)\n#define DCIDR_GET(cidr, i)\t(__CIDR(cidr, i) + 1)\n#else\n#define DCIDR_PUT(cidr)\t\t(cidr)\n#define DCIDR_GET(cidr, i)\t__CIDR(cidr, i)\n#endif\n\n#define INIT_CIDR(cidr, host_mask)\t\\\n\tDCIDR_PUT(((cidr) ? NCIDR_GET(cidr) : host_mask))\n\n#ifdef IP_SET_HASH_WITH_NET0\n \n#define NLEN\t\t\t(HOST_MASK + 1)\n#define CIDR_POS(c)\t\t((c) - 1)\n#else\n \n#define NLEN\t\t\tHOST_MASK\n#define CIDR_POS(c)\t\t((c) - 2)\n#endif\n\n#else\n#define NLEN\t\t\t0\n#endif  \n\n#define SET_ELEM_EXPIRED(set, d)\t\\\n\t(SET_WITH_TIMEOUT(set) &&\t\\\n\t ip_set_timeout_expired(ext_timeout(d, set)))\n\n#if defined(IP_SET_HASH_WITH_NETMASK) || defined(IP_SET_HASH_WITH_BITMASK)\nstatic const union nf_inet_addr onesmask = {\n\t.all[0] = 0xffffffff,\n\t.all[1] = 0xffffffff,\n\t.all[2] = 0xffffffff,\n\t.all[3] = 0xffffffff\n};\n\nstatic const union nf_inet_addr zeromask = {};\n#endif\n\n#endif  \n\n#ifndef MTYPE\n#error \"MTYPE is not defined!\"\n#endif\n\n#ifndef HTYPE\n#error \"HTYPE is not defined!\"\n#endif\n\n#ifndef HOST_MASK\n#error \"HOST_MASK is not defined!\"\n#endif\n\n \n\n#undef ahash_data\n#undef mtype_data_equal\n#undef mtype_do_data_match\n#undef mtype_data_set_flags\n#undef mtype_data_reset_elem\n#undef mtype_data_reset_flags\n#undef mtype_data_netmask\n#undef mtype_data_list\n#undef mtype_data_next\n#undef mtype_elem\n\n#undef mtype_ahash_destroy\n#undef mtype_ext_cleanup\n#undef mtype_add_cidr\n#undef mtype_del_cidr\n#undef mtype_ahash_memsize\n#undef mtype_flush\n#undef mtype_destroy\n#undef mtype_same_set\n#undef mtype_kadt\n#undef mtype_uadt\n\n#undef mtype_add\n#undef mtype_del\n#undef mtype_test_cidrs\n#undef mtype_test\n#undef mtype_uref\n#undef mtype_resize\n#undef mtype_ext_size\n#undef mtype_resize_ad\n#undef mtype_head\n#undef mtype_list\n#undef mtype_gc_do\n#undef mtype_gc\n#undef mtype_gc_init\n#undef mtype_variant\n#undef mtype_data_match\n\n#undef htype\n#undef HKEY\n\n#define mtype_data_equal\tIPSET_TOKEN(MTYPE, _data_equal)\n#ifdef IP_SET_HASH_WITH_NETS\n#define mtype_do_data_match\tIPSET_TOKEN(MTYPE, _do_data_match)\n#else\n#define mtype_do_data_match(d)\t1\n#endif\n#define mtype_data_set_flags\tIPSET_TOKEN(MTYPE, _data_set_flags)\n#define mtype_data_reset_elem\tIPSET_TOKEN(MTYPE, _data_reset_elem)\n#define mtype_data_reset_flags\tIPSET_TOKEN(MTYPE, _data_reset_flags)\n#define mtype_data_netmask\tIPSET_TOKEN(MTYPE, _data_netmask)\n#define mtype_data_list\t\tIPSET_TOKEN(MTYPE, _data_list)\n#define mtype_data_next\t\tIPSET_TOKEN(MTYPE, _data_next)\n#define mtype_elem\t\tIPSET_TOKEN(MTYPE, _elem)\n\n#define mtype_ahash_destroy\tIPSET_TOKEN(MTYPE, _ahash_destroy)\n#define mtype_ext_cleanup\tIPSET_TOKEN(MTYPE, _ext_cleanup)\n#define mtype_add_cidr\t\tIPSET_TOKEN(MTYPE, _add_cidr)\n#define mtype_del_cidr\t\tIPSET_TOKEN(MTYPE, _del_cidr)\n#define mtype_ahash_memsize\tIPSET_TOKEN(MTYPE, _ahash_memsize)\n#define mtype_flush\t\tIPSET_TOKEN(MTYPE, _flush)\n#define mtype_destroy\t\tIPSET_TOKEN(MTYPE, _destroy)\n#define mtype_same_set\t\tIPSET_TOKEN(MTYPE, _same_set)\n#define mtype_kadt\t\tIPSET_TOKEN(MTYPE, _kadt)\n#define mtype_uadt\t\tIPSET_TOKEN(MTYPE, _uadt)\n\n#define mtype_add\t\tIPSET_TOKEN(MTYPE, _add)\n#define mtype_del\t\tIPSET_TOKEN(MTYPE, _del)\n#define mtype_test_cidrs\tIPSET_TOKEN(MTYPE, _test_cidrs)\n#define mtype_test\t\tIPSET_TOKEN(MTYPE, _test)\n#define mtype_uref\t\tIPSET_TOKEN(MTYPE, _uref)\n#define mtype_resize\t\tIPSET_TOKEN(MTYPE, _resize)\n#define mtype_ext_size\t\tIPSET_TOKEN(MTYPE, _ext_size)\n#define mtype_resize_ad\t\tIPSET_TOKEN(MTYPE, _resize_ad)\n#define mtype_head\t\tIPSET_TOKEN(MTYPE, _head)\n#define mtype_list\t\tIPSET_TOKEN(MTYPE, _list)\n#define mtype_gc_do\t\tIPSET_TOKEN(MTYPE, _gc_do)\n#define mtype_gc\t\tIPSET_TOKEN(MTYPE, _gc)\n#define mtype_gc_init\t\tIPSET_TOKEN(MTYPE, _gc_init)\n#define mtype_variant\t\tIPSET_TOKEN(MTYPE, _variant)\n#define mtype_data_match\tIPSET_TOKEN(MTYPE, _data_match)\n\n#ifndef HKEY_DATALEN\n#define HKEY_DATALEN\t\tsizeof(struct mtype_elem)\n#endif\n\n#define htype\t\t\tMTYPE\n\n#define HKEY(data, initval, htable_bits)\t\t\t\\\n({\t\t\t\t\t\t\t\t\\\n\tconst u32 *__k = (const u32 *)data;\t\t\t\\\n\tu32 __l = HKEY_DATALEN / sizeof(u32);\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\tBUILD_BUG_ON(HKEY_DATALEN % sizeof(u32) != 0);\t\t\\\n\t\t\t\t\t\t\t\t\\\n\tjhash2(__k, __l, initval) & jhash_mask(htable_bits);\t\\\n})\n\n \nstruct htype {\n\tstruct htable __rcu *table;  \n\tstruct htable_gc gc;\t \n\tu32 maxelem;\t\t \n\tu32 initval;\t\t \n#ifdef IP_SET_HASH_WITH_MARKMASK\n\tu32 markmask;\t\t \n#endif\n\tu8 bucketsize;\t\t \n#if defined(IP_SET_HASH_WITH_NETMASK) || defined(IP_SET_HASH_WITH_BITMASK)\n\tu8 netmask;\t\t \n\tunion nf_inet_addr bitmask;\t \n#endif\n\tstruct list_head ad;\t \n\tstruct mtype_elem next;  \n#ifdef IP_SET_HASH_WITH_NETS\n\tstruct net_prefixes nets[NLEN];  \n#endif\n};\n\n \nstruct mtype_resize_ad {\n\tstruct list_head list;\n\tenum ipset_adt ad;\t \n\tstruct mtype_elem d;\t \n\tstruct ip_set_ext ext;\t \n\tstruct ip_set_ext mext;\t \n\tu32 flags;\t\t \n};\n\n#ifdef IP_SET_HASH_WITH_NETS\n \nstatic void\nmtype_add_cidr(struct ip_set *set, struct htype *h, u8 cidr, u8 n)\n{\n\tint i, j;\n\n\tspin_lock_bh(&set->lock);\n\t \n\tfor (i = 0, j = -1; i < NLEN && h->nets[i].cidr[n]; i++) {\n\t\tif (j != -1) {\n\t\t\tcontinue;\n\t\t} else if (h->nets[i].cidr[n] < cidr) {\n\t\t\tj = i;\n\t\t} else if (h->nets[i].cidr[n] == cidr) {\n\t\t\th->nets[CIDR_POS(cidr)].nets[n]++;\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\tif (j != -1) {\n\t\tfor (; i > j; i--)\n\t\t\th->nets[i].cidr[n] = h->nets[i - 1].cidr[n];\n\t}\n\th->nets[i].cidr[n] = cidr;\n\th->nets[CIDR_POS(cidr)].nets[n] = 1;\nunlock:\n\tspin_unlock_bh(&set->lock);\n}\n\nstatic void\nmtype_del_cidr(struct ip_set *set, struct htype *h, u8 cidr, u8 n)\n{\n\tu8 i, j, net_end = NLEN - 1;\n\n\tspin_lock_bh(&set->lock);\n\tfor (i = 0; i < NLEN; i++) {\n\t\tif (h->nets[i].cidr[n] != cidr)\n\t\t\tcontinue;\n\t\th->nets[CIDR_POS(cidr)].nets[n]--;\n\t\tif (h->nets[CIDR_POS(cidr)].nets[n] > 0)\n\t\t\tgoto unlock;\n\t\tfor (j = i; j < net_end && h->nets[j].cidr[n]; j++)\n\t\t\th->nets[j].cidr[n] = h->nets[j + 1].cidr[n];\n\t\th->nets[j].cidr[n] = 0;\n\t\tgoto unlock;\n\t}\nunlock:\n\tspin_unlock_bh(&set->lock);\n}\n#endif\n\n \nstatic size_t\nmtype_ahash_memsize(const struct htype *h, const struct htable *t)\n{\n\treturn sizeof(*h) + sizeof(*t) + ahash_sizeof_regions(t->htable_bits);\n}\n\n \n#define ahash_data(n, i, dsize)\t\\\n\t((struct mtype_elem *)((n)->value + ((i) * (dsize))))\n\nstatic void\nmtype_ext_cleanup(struct ip_set *set, struct hbucket *n)\n{\n\tint i;\n\n\tfor (i = 0; i < n->pos; i++)\n\t\tif (test_bit(i, n->used))\n\t\t\tip_set_ext_destroy(set, ahash_data(n, i, set->dsize));\n}\n\n \nstatic void\nmtype_flush(struct ip_set *set)\n{\n\tstruct htype *h = set->data;\n\tstruct htable *t;\n\tstruct hbucket *n;\n\tu32 r, i;\n\n\tt = ipset_dereference_nfnl(h->table);\n\tfor (r = 0; r < ahash_numof_locks(t->htable_bits); r++) {\n\t\tspin_lock_bh(&t->hregion[r].lock);\n\t\tfor (i = ahash_bucket_start(r, t->htable_bits);\n\t\t     i < ahash_bucket_end(r, t->htable_bits); i++) {\n\t\t\tn = __ipset_dereference(hbucket(t, i));\n\t\t\tif (!n)\n\t\t\t\tcontinue;\n\t\t\tif (set->extensions & IPSET_EXT_DESTROY)\n\t\t\t\tmtype_ext_cleanup(set, n);\n\t\t\t \n\t\t\trcu_assign_pointer(hbucket(t, i), NULL);\n\t\t\tkfree_rcu(n, rcu);\n\t\t}\n\t\tt->hregion[r].ext_size = 0;\n\t\tt->hregion[r].elements = 0;\n\t\tspin_unlock_bh(&t->hregion[r].lock);\n\t}\n#ifdef IP_SET_HASH_WITH_NETS\n\tmemset(h->nets, 0, sizeof(h->nets));\n#endif\n}\n\n \nstatic void\nmtype_ahash_destroy(struct ip_set *set, struct htable *t, bool ext_destroy)\n{\n\tstruct hbucket *n;\n\tu32 i;\n\n\tfor (i = 0; i < jhash_size(t->htable_bits); i++) {\n\t\tn = __ipset_dereference(hbucket(t, i));\n\t\tif (!n)\n\t\t\tcontinue;\n\t\tif (set->extensions & IPSET_EXT_DESTROY && ext_destroy)\n\t\t\tmtype_ext_cleanup(set, n);\n\t\t \n\t\tkfree(n);\n\t}\n\n\tip_set_free(t->hregion);\n\tip_set_free(t);\n}\n\n \nstatic void\nmtype_destroy(struct ip_set *set)\n{\n\tstruct htype *h = set->data;\n\tstruct list_head *l, *lt;\n\n\tif (SET_WITH_TIMEOUT(set))\n\t\tcancel_delayed_work_sync(&h->gc.dwork);\n\n\tmtype_ahash_destroy(set, ipset_dereference_nfnl(h->table), true);\n\tlist_for_each_safe(l, lt, &h->ad) {\n\t\tlist_del(l);\n\t\tkfree(l);\n\t}\n\tkfree(h);\n\n\tset->data = NULL;\n}\n\nstatic bool\nmtype_same_set(const struct ip_set *a, const struct ip_set *b)\n{\n\tconst struct htype *x = a->data;\n\tconst struct htype *y = b->data;\n\n\t \n\treturn x->maxelem == y->maxelem &&\n\t       a->timeout == b->timeout &&\n#if defined(IP_SET_HASH_WITH_NETMASK) || defined(IP_SET_HASH_WITH_BITMASK)\n\t       nf_inet_addr_cmp(&x->bitmask, &y->bitmask) &&\n#endif\n#ifdef IP_SET_HASH_WITH_MARKMASK\n\t       x->markmask == y->markmask &&\n#endif\n\t       a->extensions == b->extensions;\n}\n\nstatic void\nmtype_gc_do(struct ip_set *set, struct htype *h, struct htable *t, u32 r)\n{\n\tstruct hbucket *n, *tmp;\n\tstruct mtype_elem *data;\n\tu32 i, j, d;\n\tsize_t dsize = set->dsize;\n#ifdef IP_SET_HASH_WITH_NETS\n\tu8 k;\n#endif\n\tu8 htable_bits = t->htable_bits;\n\n\tspin_lock_bh(&t->hregion[r].lock);\n\tfor (i = ahash_bucket_start(r, htable_bits);\n\t     i < ahash_bucket_end(r, htable_bits); i++) {\n\t\tn = __ipset_dereference(hbucket(t, i));\n\t\tif (!n)\n\t\t\tcontinue;\n\t\tfor (j = 0, d = 0; j < n->pos; j++) {\n\t\t\tif (!test_bit(j, n->used)) {\n\t\t\t\td++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tdata = ahash_data(n, j, dsize);\n\t\t\tif (!ip_set_timeout_expired(ext_timeout(data, set)))\n\t\t\t\tcontinue;\n\t\t\tpr_debug(\"expired %u/%u\\n\", i, j);\n\t\t\tclear_bit(j, n->used);\n\t\t\tsmp_mb__after_atomic();\n#ifdef IP_SET_HASH_WITH_NETS\n\t\t\tfor (k = 0; k < IPSET_NET_COUNT; k++)\n\t\t\t\tmtype_del_cidr(set, h,\n\t\t\t\t\tNCIDR_PUT(DCIDR_GET(data->cidr, k)),\n\t\t\t\t\tk);\n#endif\n\t\t\tt->hregion[r].elements--;\n\t\t\tip_set_ext_destroy(set, data);\n\t\t\td++;\n\t\t}\n\t\tif (d >= AHASH_INIT_SIZE) {\n\t\t\tif (d >= n->size) {\n\t\t\t\tt->hregion[r].ext_size -=\n\t\t\t\t\text_size(n->size, dsize);\n\t\t\t\trcu_assign_pointer(hbucket(t, i), NULL);\n\t\t\t\tkfree_rcu(n, rcu);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ttmp = kzalloc(sizeof(*tmp) +\n\t\t\t\t(n->size - AHASH_INIT_SIZE) * dsize,\n\t\t\t\tGFP_ATOMIC);\n\t\t\tif (!tmp)\n\t\t\t\t \n\t\t\t\tcontinue;\n\t\t\ttmp->size = n->size - AHASH_INIT_SIZE;\n\t\t\tfor (j = 0, d = 0; j < n->pos; j++) {\n\t\t\t\tif (!test_bit(j, n->used))\n\t\t\t\t\tcontinue;\n\t\t\t\tdata = ahash_data(n, j, dsize);\n\t\t\t\tmemcpy(tmp->value + d * dsize,\n\t\t\t\t       data, dsize);\n\t\t\t\tset_bit(d, tmp->used);\n\t\t\t\td++;\n\t\t\t}\n\t\t\ttmp->pos = d;\n\t\t\tt->hregion[r].ext_size -=\n\t\t\t\text_size(AHASH_INIT_SIZE, dsize);\n\t\t\trcu_assign_pointer(hbucket(t, i), tmp);\n\t\t\tkfree_rcu(n, rcu);\n\t\t}\n\t}\n\tspin_unlock_bh(&t->hregion[r].lock);\n}\n\nstatic void\nmtype_gc(struct work_struct *work)\n{\n\tstruct htable_gc *gc;\n\tstruct ip_set *set;\n\tstruct htype *h;\n\tstruct htable *t;\n\tu32 r, numof_locks;\n\tunsigned int next_run;\n\n\tgc = container_of(work, struct htable_gc, dwork.work);\n\tset = gc->set;\n\th = set->data;\n\n\tspin_lock_bh(&set->lock);\n\tt = ipset_dereference_set(h->table, set);\n\tatomic_inc(&t->uref);\n\tnumof_locks = ahash_numof_locks(t->htable_bits);\n\tr = gc->region++;\n\tif (r >= numof_locks) {\n\t\tr = gc->region = 0;\n\t}\n\tnext_run = (IPSET_GC_PERIOD(set->timeout) * HZ) / numof_locks;\n\tif (next_run < HZ/10)\n\t\tnext_run = HZ/10;\n\tspin_unlock_bh(&set->lock);\n\n\tmtype_gc_do(set, h, t, r);\n\n\tif (atomic_dec_and_test(&t->uref) && atomic_read(&t->ref)) {\n\t\tpr_debug(\"Table destroy after resize by expire: %p\\n\", t);\n\t\tmtype_ahash_destroy(set, t, false);\n\t}\n\n\tqueue_delayed_work(system_power_efficient_wq, &gc->dwork, next_run);\n\n}\n\nstatic void\nmtype_gc_init(struct htable_gc *gc)\n{\n\tINIT_DEFERRABLE_WORK(&gc->dwork, mtype_gc);\n\tqueue_delayed_work(system_power_efficient_wq, &gc->dwork, HZ);\n}\n\nstatic int\nmtype_add(struct ip_set *set, void *value, const struct ip_set_ext *ext,\n\t  struct ip_set_ext *mext, u32 flags);\nstatic int\nmtype_del(struct ip_set *set, void *value, const struct ip_set_ext *ext,\n\t  struct ip_set_ext *mext, u32 flags);\n\n \nstatic int\nmtype_resize(struct ip_set *set, bool retried)\n{\n\tstruct htype *h = set->data;\n\tstruct htable *t, *orig;\n\tu8 htable_bits;\n\tsize_t hsize, dsize = set->dsize;\n#ifdef IP_SET_HASH_WITH_NETS\n\tu8 flags;\n\tstruct mtype_elem *tmp;\n#endif\n\tstruct mtype_elem *data;\n\tstruct mtype_elem *d;\n\tstruct hbucket *n, *m;\n\tstruct list_head *l, *lt;\n\tstruct mtype_resize_ad *x;\n\tu32 i, j, r, nr, key;\n\tint ret;\n\n#ifdef IP_SET_HASH_WITH_NETS\n\ttmp = kmalloc(dsize, GFP_KERNEL);\n\tif (!tmp)\n\t\treturn -ENOMEM;\n#endif\n\torig = ipset_dereference_bh_nfnl(h->table);\n\thtable_bits = orig->htable_bits;\n\nretry:\n\tret = 0;\n\thtable_bits++;\n\tif (!htable_bits)\n\t\tgoto hbwarn;\n\thsize = htable_size(htable_bits);\n\tif (!hsize)\n\t\tgoto hbwarn;\n\tt = ip_set_alloc(hsize);\n\tif (!t) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tt->hregion = ip_set_alloc(ahash_sizeof_regions(htable_bits));\n\tif (!t->hregion) {\n\t\tip_set_free(t);\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tt->htable_bits = htable_bits;\n\tt->maxelem = h->maxelem / ahash_numof_locks(htable_bits);\n\tfor (i = 0; i < ahash_numof_locks(htable_bits); i++)\n\t\tspin_lock_init(&t->hregion[i].lock);\n\n\t \n\torig = ipset_dereference_bh_nfnl(h->table);\n\tatomic_set(&orig->ref, 1);\n\tatomic_inc(&orig->uref);\n\tpr_debug(\"attempt to resize set %s from %u to %u, t %p\\n\",\n\t\t set->name, orig->htable_bits, htable_bits, orig);\n\tfor (r = 0; r < ahash_numof_locks(orig->htable_bits); r++) {\n\t\t \n\t\trcu_read_lock_bh();\n\t\tfor (i = ahash_bucket_start(r, orig->htable_bits);\n\t\t     i < ahash_bucket_end(r, orig->htable_bits); i++) {\n\t\t\tn = __ipset_dereference(hbucket(orig, i));\n\t\t\tif (!n)\n\t\t\t\tcontinue;\n\t\t\tfor (j = 0; j < n->pos; j++) {\n\t\t\t\tif (!test_bit(j, n->used))\n\t\t\t\t\tcontinue;\n\t\t\t\tdata = ahash_data(n, j, dsize);\n\t\t\t\tif (SET_ELEM_EXPIRED(set, data))\n\t\t\t\t\tcontinue;\n#ifdef IP_SET_HASH_WITH_NETS\n\t\t\t\t \n\t\t\t\tflags = 0;\n\t\t\t\tmemcpy(tmp, data, dsize);\n\t\t\t\tdata = tmp;\n\t\t\t\tmtype_data_reset_flags(data, &flags);\n#endif\n\t\t\t\tkey = HKEY(data, h->initval, htable_bits);\n\t\t\t\tm = __ipset_dereference(hbucket(t, key));\n\t\t\t\tnr = ahash_region(key, htable_bits);\n\t\t\t\tif (!m) {\n\t\t\t\t\tm = kzalloc(sizeof(*m) +\n\t\t\t\t\t    AHASH_INIT_SIZE * dsize,\n\t\t\t\t\t    GFP_ATOMIC);\n\t\t\t\t\tif (!m) {\n\t\t\t\t\t\tret = -ENOMEM;\n\t\t\t\t\t\tgoto cleanup;\n\t\t\t\t\t}\n\t\t\t\t\tm->size = AHASH_INIT_SIZE;\n\t\t\t\t\tt->hregion[nr].ext_size +=\n\t\t\t\t\t\text_size(AHASH_INIT_SIZE,\n\t\t\t\t\t\t\t dsize);\n\t\t\t\t\tRCU_INIT_POINTER(hbucket(t, key), m);\n\t\t\t\t} else if (m->pos >= m->size) {\n\t\t\t\t\tstruct hbucket *ht;\n\n\t\t\t\t\tif (m->size >= AHASH_MAX(h)) {\n\t\t\t\t\t\tret = -EAGAIN;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tht = kzalloc(sizeof(*ht) +\n\t\t\t\t\t\t(m->size + AHASH_INIT_SIZE)\n\t\t\t\t\t\t* dsize,\n\t\t\t\t\t\tGFP_ATOMIC);\n\t\t\t\t\t\tif (!ht)\n\t\t\t\t\t\t\tret = -ENOMEM;\n\t\t\t\t\t}\n\t\t\t\t\tif (ret < 0)\n\t\t\t\t\t\tgoto cleanup;\n\t\t\t\t\tmemcpy(ht, m, sizeof(struct hbucket) +\n\t\t\t\t\t       m->size * dsize);\n\t\t\t\t\tht->size = m->size + AHASH_INIT_SIZE;\n\t\t\t\t\tt->hregion[nr].ext_size +=\n\t\t\t\t\t\text_size(AHASH_INIT_SIZE,\n\t\t\t\t\t\t\t dsize);\n\t\t\t\t\tkfree(m);\n\t\t\t\t\tm = ht;\n\t\t\t\t\tRCU_INIT_POINTER(hbucket(t, key), ht);\n\t\t\t\t}\n\t\t\t\td = ahash_data(m, m->pos, dsize);\n\t\t\t\tmemcpy(d, data, dsize);\n\t\t\t\tset_bit(m->pos++, m->used);\n\t\t\t\tt->hregion[nr].elements++;\n#ifdef IP_SET_HASH_WITH_NETS\n\t\t\t\tmtype_data_reset_flags(d, &flags);\n#endif\n\t\t\t}\n\t\t}\n\t\trcu_read_unlock_bh();\n\t}\n\n\t \n\trcu_assign_pointer(h->table, t);\n\n\t \n\tsynchronize_rcu();\n\n\tpr_debug(\"set %s resized from %u (%p) to %u (%p)\\n\", set->name,\n\t\t orig->htable_bits, orig, t->htable_bits, t);\n\t \n\tlist_for_each_safe(l, lt, &h->ad) {\n\t\tx = list_entry(l, struct mtype_resize_ad, list);\n\t\tif (x->ad == IPSET_ADD) {\n\t\t\tmtype_add(set, &x->d, &x->ext, &x->mext, x->flags);\n\t\t} else {\n\t\t\tmtype_del(set, &x->d, NULL, NULL, 0);\n\t\t}\n\t\tlist_del(l);\n\t\tkfree(l);\n\t}\n\t \n\tif (atomic_dec_and_test(&orig->uref)) {\n\t\tpr_debug(\"Table destroy by resize %p\\n\", orig);\n\t\tmtype_ahash_destroy(set, orig, false);\n\t}\n\nout:\n#ifdef IP_SET_HASH_WITH_NETS\n\tkfree(tmp);\n#endif\n\treturn ret;\n\ncleanup:\n\trcu_read_unlock_bh();\n\tatomic_set(&orig->ref, 0);\n\tatomic_dec(&orig->uref);\n\tmtype_ahash_destroy(set, t, false);\n\tif (ret == -EAGAIN)\n\t\tgoto retry;\n\tgoto out;\n\nhbwarn:\n\t \n\tpr_warn(\"Cannot increase the hashsize of set %s further\\n\", set->name);\n\tret = -IPSET_ERR_HASH_FULL;\n\tgoto out;\n}\n\n \nstatic void\nmtype_ext_size(struct ip_set *set, u32 *elements, size_t *ext_size)\n{\n\tstruct htype *h = set->data;\n\tconst struct htable *t;\n\tu32 i, j, r;\n\tstruct hbucket *n;\n\tstruct mtype_elem *data;\n\n\tt = rcu_dereference_bh(h->table);\n\tfor (r = 0; r < ahash_numof_locks(t->htable_bits); r++) {\n\t\tfor (i = ahash_bucket_start(r, t->htable_bits);\n\t\t     i < ahash_bucket_end(r, t->htable_bits); i++) {\n\t\t\tn = rcu_dereference_bh(hbucket(t, i));\n\t\t\tif (!n)\n\t\t\t\tcontinue;\n\t\t\tfor (j = 0; j < n->pos; j++) {\n\t\t\t\tif (!test_bit(j, n->used))\n\t\t\t\t\tcontinue;\n\t\t\t\tdata = ahash_data(n, j, set->dsize);\n\t\t\t\tif (!SET_ELEM_EXPIRED(set, data))\n\t\t\t\t\t(*elements)++;\n\t\t\t}\n\t\t}\n\t\t*ext_size += t->hregion[r].ext_size;\n\t}\n}\n\n \nstatic int\nmtype_add(struct ip_set *set, void *value, const struct ip_set_ext *ext,\n\t  struct ip_set_ext *mext, u32 flags)\n{\n\tstruct htype *h = set->data;\n\tstruct htable *t;\n\tconst struct mtype_elem *d = value;\n\tstruct mtype_elem *data;\n\tstruct hbucket *n, *old = ERR_PTR(-ENOENT);\n\tint i, j = -1, ret;\n\tbool flag_exist = flags & IPSET_FLAG_EXIST;\n\tbool deleted = false, forceadd = false, reuse = false;\n\tu32 r, key, multi = 0, elements, maxelem;\n\n\trcu_read_lock_bh();\n\tt = rcu_dereference_bh(h->table);\n\tkey = HKEY(value, h->initval, t->htable_bits);\n\tr = ahash_region(key, t->htable_bits);\n\tatomic_inc(&t->uref);\n\telements = t->hregion[r].elements;\n\tmaxelem = t->maxelem;\n\tif (elements >= maxelem) {\n\t\tu32 e;\n\t\tif (SET_WITH_TIMEOUT(set)) {\n\t\t\trcu_read_unlock_bh();\n\t\t\tmtype_gc_do(set, h, t, r);\n\t\t\trcu_read_lock_bh();\n\t\t}\n\t\tmaxelem = h->maxelem;\n\t\telements = 0;\n\t\tfor (e = 0; e < ahash_numof_locks(t->htable_bits); e++)\n\t\t\telements += t->hregion[e].elements;\n\t\tif (elements >= maxelem && SET_WITH_FORCEADD(set))\n\t\t\tforceadd = true;\n\t}\n\trcu_read_unlock_bh();\n\n\tspin_lock_bh(&t->hregion[r].lock);\n\tn = rcu_dereference_bh(hbucket(t, key));\n\tif (!n) {\n\t\tif (forceadd || elements >= maxelem)\n\t\t\tgoto set_full;\n\t\told = NULL;\n\t\tn = kzalloc(sizeof(*n) + AHASH_INIT_SIZE * set->dsize,\n\t\t\t    GFP_ATOMIC);\n\t\tif (!n) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto unlock;\n\t\t}\n\t\tn->size = AHASH_INIT_SIZE;\n\t\tt->hregion[r].ext_size +=\n\t\t\text_size(AHASH_INIT_SIZE, set->dsize);\n\t\tgoto copy_elem;\n\t}\n\tfor (i = 0; i < n->pos; i++) {\n\t\tif (!test_bit(i, n->used)) {\n\t\t\t \n\t\t\tif (j == -1) {\n\t\t\t\tdeleted = reuse = true;\n\t\t\t\tj = i;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\tdata = ahash_data(n, i, set->dsize);\n\t\tif (mtype_data_equal(data, d, &multi)) {\n\t\t\tif (flag_exist || SET_ELEM_EXPIRED(set, data)) {\n\t\t\t\t \n\t\t\t\tj = i;\n\t\t\t\tgoto overwrite_extensions;\n\t\t\t}\n\t\t\tret = -IPSET_ERR_EXIST;\n\t\t\tgoto unlock;\n\t\t}\n\t\t \n\t\tif (SET_ELEM_EXPIRED(set, data) && j == -1) {\n\t\t\tj = i;\n\t\t\treuse = true;\n\t\t}\n\t}\n\tif (reuse || forceadd) {\n\t\tif (j == -1)\n\t\t\tj = 0;\n\t\tdata = ahash_data(n, j, set->dsize);\n\t\tif (!deleted) {\n#ifdef IP_SET_HASH_WITH_NETS\n\t\t\tfor (i = 0; i < IPSET_NET_COUNT; i++)\n\t\t\t\tmtype_del_cidr(set, h,\n\t\t\t\t\tNCIDR_PUT(DCIDR_GET(data->cidr, i)),\n\t\t\t\t\ti);\n#endif\n\t\t\tip_set_ext_destroy(set, data);\n\t\t\tt->hregion[r].elements--;\n\t\t}\n\t\tgoto copy_data;\n\t}\n\tif (elements >= maxelem)\n\t\tgoto set_full;\n\t \n\tif (n->pos >= n->size) {\n#ifdef IP_SET_HASH_WITH_MULTI\n\t\tif (h->bucketsize >= AHASH_MAX_TUNED)\n\t\t\tgoto set_full;\n\t\telse if (h->bucketsize <= multi)\n\t\t\th->bucketsize += AHASH_INIT_SIZE;\n#endif\n\t\tif (n->size >= AHASH_MAX(h)) {\n\t\t\t \n\t\t\tmtype_data_next(&h->next, d);\n\t\t\tret = -EAGAIN;\n\t\t\tgoto resize;\n\t\t}\n\t\told = n;\n\t\tn = kzalloc(sizeof(*n) +\n\t\t\t    (old->size + AHASH_INIT_SIZE) * set->dsize,\n\t\t\t    GFP_ATOMIC);\n\t\tif (!n) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto unlock;\n\t\t}\n\t\tmemcpy(n, old, sizeof(struct hbucket) +\n\t\t       old->size * set->dsize);\n\t\tn->size = old->size + AHASH_INIT_SIZE;\n\t\tt->hregion[r].ext_size +=\n\t\t\text_size(AHASH_INIT_SIZE, set->dsize);\n\t}\n\ncopy_elem:\n\tj = n->pos++;\n\tdata = ahash_data(n, j, set->dsize);\ncopy_data:\n\tt->hregion[r].elements++;\n#ifdef IP_SET_HASH_WITH_NETS\n\tfor (i = 0; i < IPSET_NET_COUNT; i++)\n\t\tmtype_add_cidr(set, h, NCIDR_PUT(DCIDR_GET(d->cidr, i)), i);\n#endif\n\tmemcpy(data, d, sizeof(struct mtype_elem));\noverwrite_extensions:\n#ifdef IP_SET_HASH_WITH_NETS\n\tmtype_data_set_flags(data, flags);\n#endif\n\tif (SET_WITH_COUNTER(set))\n\t\tip_set_init_counter(ext_counter(data, set), ext);\n\tif (SET_WITH_COMMENT(set))\n\t\tip_set_init_comment(set, ext_comment(data, set), ext);\n\tif (SET_WITH_SKBINFO(set))\n\t\tip_set_init_skbinfo(ext_skbinfo(data, set), ext);\n\t \n\tif (SET_WITH_TIMEOUT(set))\n\t\tip_set_timeout_set(ext_timeout(data, set), ext->timeout);\n\tsmp_mb__before_atomic();\n\tset_bit(j, n->used);\n\tif (old != ERR_PTR(-ENOENT)) {\n\t\trcu_assign_pointer(hbucket(t, key), n);\n\t\tif (old)\n\t\t\tkfree_rcu(old, rcu);\n\t}\n\tret = 0;\nresize:\n\tspin_unlock_bh(&t->hregion[r].lock);\n\tif (atomic_read(&t->ref) && ext->target) {\n\t\t \n\t\tstruct mtype_resize_ad *x;\n\n\t\tx = kzalloc(sizeof(struct mtype_resize_ad), GFP_ATOMIC);\n\t\tif (!x)\n\t\t\t \n\t\t\tgoto out;\n\t\tx->ad = IPSET_ADD;\n\t\tmemcpy(&x->d, value, sizeof(struct mtype_elem));\n\t\tmemcpy(&x->ext, ext, sizeof(struct ip_set_ext));\n\t\tmemcpy(&x->mext, mext, sizeof(struct ip_set_ext));\n\t\tx->flags = flags;\n\t\tspin_lock_bh(&set->lock);\n\t\tlist_add_tail(&x->list, &h->ad);\n\t\tspin_unlock_bh(&set->lock);\n\t}\n\tgoto out;\n\nset_full:\n\tif (net_ratelimit())\n\t\tpr_warn(\"Set %s is full, maxelem %u reached\\n\",\n\t\t\tset->name, maxelem);\n\tret = -IPSET_ERR_HASH_FULL;\nunlock:\n\tspin_unlock_bh(&t->hregion[r].lock);\nout:\n\tif (atomic_dec_and_test(&t->uref) && atomic_read(&t->ref)) {\n\t\tpr_debug(\"Table destroy after resize by add: %p\\n\", t);\n\t\tmtype_ahash_destroy(set, t, false);\n\t}\n\treturn ret;\n}\n\n \nstatic int\nmtype_del(struct ip_set *set, void *value, const struct ip_set_ext *ext,\n\t  struct ip_set_ext *mext, u32 flags)\n{\n\tstruct htype *h = set->data;\n\tstruct htable *t;\n\tconst struct mtype_elem *d = value;\n\tstruct mtype_elem *data;\n\tstruct hbucket *n;\n\tstruct mtype_resize_ad *x = NULL;\n\tint i, j, k, r, ret = -IPSET_ERR_EXIST;\n\tu32 key, multi = 0;\n\tsize_t dsize = set->dsize;\n\n\t \n\trcu_read_lock_bh();\n\tt = rcu_dereference_bh(h->table);\n\tkey = HKEY(value, h->initval, t->htable_bits);\n\tr = ahash_region(key, t->htable_bits);\n\tatomic_inc(&t->uref);\n\trcu_read_unlock_bh();\n\n\tspin_lock_bh(&t->hregion[r].lock);\n\tn = rcu_dereference_bh(hbucket(t, key));\n\tif (!n)\n\t\tgoto out;\n\tfor (i = 0, k = 0; i < n->pos; i++) {\n\t\tif (!test_bit(i, n->used)) {\n\t\t\tk++;\n\t\t\tcontinue;\n\t\t}\n\t\tdata = ahash_data(n, i, dsize);\n\t\tif (!mtype_data_equal(data, d, &multi))\n\t\t\tcontinue;\n\t\tif (SET_ELEM_EXPIRED(set, data))\n\t\t\tgoto out;\n\n\t\tret = 0;\n\t\tclear_bit(i, n->used);\n\t\tsmp_mb__after_atomic();\n\t\tif (i + 1 == n->pos)\n\t\t\tn->pos--;\n\t\tt->hregion[r].elements--;\n#ifdef IP_SET_HASH_WITH_NETS\n\t\tfor (j = 0; j < IPSET_NET_COUNT; j++)\n\t\t\tmtype_del_cidr(set, h,\n\t\t\t\t       NCIDR_PUT(DCIDR_GET(d->cidr, j)), j);\n#endif\n\t\tip_set_ext_destroy(set, data);\n\n\t\tif (atomic_read(&t->ref) && ext->target) {\n\t\t\t \n\t\t\tx = kzalloc(sizeof(struct mtype_resize_ad),\n\t\t\t\t    GFP_ATOMIC);\n\t\t\tif (x) {\n\t\t\t\tx->ad = IPSET_DEL;\n\t\t\t\tmemcpy(&x->d, value,\n\t\t\t\t       sizeof(struct mtype_elem));\n\t\t\t\tx->flags = flags;\n\t\t\t}\n\t\t}\n\t\tfor (; i < n->pos; i++) {\n\t\t\tif (!test_bit(i, n->used))\n\t\t\t\tk++;\n\t\t}\n\t\tif (n->pos == 0 && k == 0) {\n\t\t\tt->hregion[r].ext_size -= ext_size(n->size, dsize);\n\t\t\trcu_assign_pointer(hbucket(t, key), NULL);\n\t\t\tkfree_rcu(n, rcu);\n\t\t} else if (k >= AHASH_INIT_SIZE) {\n\t\t\tstruct hbucket *tmp = kzalloc(sizeof(*tmp) +\n\t\t\t\t\t(n->size - AHASH_INIT_SIZE) * dsize,\n\t\t\t\t\tGFP_ATOMIC);\n\t\t\tif (!tmp)\n\t\t\t\tgoto out;\n\t\t\ttmp->size = n->size - AHASH_INIT_SIZE;\n\t\t\tfor (j = 0, k = 0; j < n->pos; j++) {\n\t\t\t\tif (!test_bit(j, n->used))\n\t\t\t\t\tcontinue;\n\t\t\t\tdata = ahash_data(n, j, dsize);\n\t\t\t\tmemcpy(tmp->value + k * dsize, data, dsize);\n\t\t\t\tset_bit(k, tmp->used);\n\t\t\t\tk++;\n\t\t\t}\n\t\t\ttmp->pos = k;\n\t\t\tt->hregion[r].ext_size -=\n\t\t\t\text_size(AHASH_INIT_SIZE, dsize);\n\t\t\trcu_assign_pointer(hbucket(t, key), tmp);\n\t\t\tkfree_rcu(n, rcu);\n\t\t}\n\t\tgoto out;\n\t}\n\nout:\n\tspin_unlock_bh(&t->hregion[r].lock);\n\tif (x) {\n\t\tspin_lock_bh(&set->lock);\n\t\tlist_add(&x->list, &h->ad);\n\t\tspin_unlock_bh(&set->lock);\n\t}\n\tif (atomic_dec_and_test(&t->uref) && atomic_read(&t->ref)) {\n\t\tpr_debug(\"Table destroy after resize by del: %p\\n\", t);\n\t\tmtype_ahash_destroy(set, t, false);\n\t}\n\treturn ret;\n}\n\nstatic int\nmtype_data_match(struct mtype_elem *data, const struct ip_set_ext *ext,\n\t\t struct ip_set_ext *mext, struct ip_set *set, u32 flags)\n{\n\tif (!ip_set_match_extensions(set, ext, mext, flags, data))\n\t\treturn 0;\n\t \n\treturn mtype_do_data_match(data);\n}\n\n#ifdef IP_SET_HASH_WITH_NETS\n \nstatic int\nmtype_test_cidrs(struct ip_set *set, struct mtype_elem *d,\n\t\t const struct ip_set_ext *ext,\n\t\t struct ip_set_ext *mext, u32 flags)\n{\n\tstruct htype *h = set->data;\n\tstruct htable *t = rcu_dereference_bh(h->table);\n\tstruct hbucket *n;\n\tstruct mtype_elem *data;\n#if IPSET_NET_COUNT == 2\n\tstruct mtype_elem orig = *d;\n\tint ret, i, j = 0, k;\n#else\n\tint ret, i, j = 0;\n#endif\n\tu32 key, multi = 0;\n\n\tpr_debug(\"test by nets\\n\");\n\tfor (; j < NLEN && h->nets[j].cidr[0] && !multi; j++) {\n#if IPSET_NET_COUNT == 2\n\t\tmtype_data_reset_elem(d, &orig);\n\t\tmtype_data_netmask(d, NCIDR_GET(h->nets[j].cidr[0]), false);\n\t\tfor (k = 0; k < NLEN && h->nets[k].cidr[1] && !multi;\n\t\t     k++) {\n\t\t\tmtype_data_netmask(d, NCIDR_GET(h->nets[k].cidr[1]),\n\t\t\t\t\t   true);\n#else\n\t\tmtype_data_netmask(d, NCIDR_GET(h->nets[j].cidr[0]));\n#endif\n\t\tkey = HKEY(d, h->initval, t->htable_bits);\n\t\tn = rcu_dereference_bh(hbucket(t, key));\n\t\tif (!n)\n\t\t\tcontinue;\n\t\tfor (i = 0; i < n->pos; i++) {\n\t\t\tif (!test_bit(i, n->used))\n\t\t\t\tcontinue;\n\t\t\tdata = ahash_data(n, i, set->dsize);\n\t\t\tif (!mtype_data_equal(data, d, &multi))\n\t\t\t\tcontinue;\n\t\t\tret = mtype_data_match(data, ext, mext, set, flags);\n\t\t\tif (ret != 0)\n\t\t\t\treturn ret;\n#ifdef IP_SET_HASH_WITH_MULTI\n\t\t\t \n\t\t\tmulti = 0;\n#endif\n\t\t}\n#if IPSET_NET_COUNT == 2\n\t\t}\n#endif\n\t}\n\treturn 0;\n}\n#endif\n\n \nstatic int\nmtype_test(struct ip_set *set, void *value, const struct ip_set_ext *ext,\n\t   struct ip_set_ext *mext, u32 flags)\n{\n\tstruct htype *h = set->data;\n\tstruct htable *t;\n\tstruct mtype_elem *d = value;\n\tstruct hbucket *n;\n\tstruct mtype_elem *data;\n\tint i, ret = 0;\n\tu32 key, multi = 0;\n\n\trcu_read_lock_bh();\n\tt = rcu_dereference_bh(h->table);\n#ifdef IP_SET_HASH_WITH_NETS\n\t \n\tfor (i = 0; i < IPSET_NET_COUNT; i++)\n\t\tif (DCIDR_GET(d->cidr, i) != HOST_MASK)\n\t\t\tbreak;\n\tif (i == IPSET_NET_COUNT) {\n\t\tret = mtype_test_cidrs(set, d, ext, mext, flags);\n\t\tgoto out;\n\t}\n#endif\n\n\tkey = HKEY(d, h->initval, t->htable_bits);\n\tn = rcu_dereference_bh(hbucket(t, key));\n\tif (!n) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\tfor (i = 0; i < n->pos; i++) {\n\t\tif (!test_bit(i, n->used))\n\t\t\tcontinue;\n\t\tdata = ahash_data(n, i, set->dsize);\n\t\tif (!mtype_data_equal(data, d, &multi))\n\t\t\tcontinue;\n\t\tret = mtype_data_match(data, ext, mext, set, flags);\n\t\tif (ret != 0)\n\t\t\tgoto out;\n\t}\nout:\n\trcu_read_unlock_bh();\n\treturn ret;\n}\n\n \nstatic int\nmtype_head(struct ip_set *set, struct sk_buff *skb)\n{\n\tstruct htype *h = set->data;\n\tconst struct htable *t;\n\tstruct nlattr *nested;\n\tsize_t memsize;\n\tu32 elements = 0;\n\tsize_t ext_size = 0;\n\tu8 htable_bits;\n\n\trcu_read_lock_bh();\n\tt = rcu_dereference_bh(h->table);\n\tmtype_ext_size(set, &elements, &ext_size);\n\tmemsize = mtype_ahash_memsize(h, t) + ext_size + set->ext_size;\n\thtable_bits = t->htable_bits;\n\trcu_read_unlock_bh();\n\n\tnested = nla_nest_start(skb, IPSET_ATTR_DATA);\n\tif (!nested)\n\t\tgoto nla_put_failure;\n\tif (nla_put_net32(skb, IPSET_ATTR_HASHSIZE,\n\t\t\t  htonl(jhash_size(htable_bits))) ||\n\t    nla_put_net32(skb, IPSET_ATTR_MAXELEM, htonl(h->maxelem)))\n\t\tgoto nla_put_failure;\n#ifdef IP_SET_HASH_WITH_BITMASK\n\t \n\tif (h->netmask == HOST_MASK && !nf_inet_addr_cmp(&onesmask, &h->bitmask)) {\n\t\tif (set->family == NFPROTO_IPV4) {\n\t\t\tif (nla_put_ipaddr4(skb, IPSET_ATTR_BITMASK, h->bitmask.ip))\n\t\t\t\tgoto nla_put_failure;\n\t\t} else if (set->family == NFPROTO_IPV6) {\n\t\t\tif (nla_put_ipaddr6(skb, IPSET_ATTR_BITMASK, &h->bitmask.in6))\n\t\t\t\tgoto nla_put_failure;\n\t\t}\n\t}\n#endif\n#ifdef IP_SET_HASH_WITH_NETMASK\n\tif (h->netmask != HOST_MASK && nla_put_u8(skb, IPSET_ATTR_NETMASK, h->netmask))\n\t\tgoto nla_put_failure;\n#endif\n#ifdef IP_SET_HASH_WITH_MARKMASK\n\tif (nla_put_u32(skb, IPSET_ATTR_MARKMASK, h->markmask))\n\t\tgoto nla_put_failure;\n#endif\n\tif (set->flags & IPSET_CREATE_FLAG_BUCKETSIZE) {\n\t\tif (nla_put_u8(skb, IPSET_ATTR_BUCKETSIZE, h->bucketsize) ||\n\t\t    nla_put_net32(skb, IPSET_ATTR_INITVAL, htonl(h->initval)))\n\t\t\tgoto nla_put_failure;\n\t}\n\tif (nla_put_net32(skb, IPSET_ATTR_REFERENCES, htonl(set->ref)) ||\n\t    nla_put_net32(skb, IPSET_ATTR_MEMSIZE, htonl(memsize)) ||\n\t    nla_put_net32(skb, IPSET_ATTR_ELEMENTS, htonl(elements)))\n\t\tgoto nla_put_failure;\n\tif (unlikely(ip_set_put_flags(skb, set)))\n\t\tgoto nla_put_failure;\n\tnla_nest_end(skb, nested);\n\n\treturn 0;\nnla_put_failure:\n\treturn -EMSGSIZE;\n}\n\n \nstatic void\nmtype_uref(struct ip_set *set, struct netlink_callback *cb, bool start)\n{\n\tstruct htype *h = set->data;\n\tstruct htable *t;\n\n\tif (start) {\n\t\trcu_read_lock_bh();\n\t\tt = ipset_dereference_bh_nfnl(h->table);\n\t\tatomic_inc(&t->uref);\n\t\tcb->args[IPSET_CB_PRIVATE] = (unsigned long)t;\n\t\trcu_read_unlock_bh();\n\t} else if (cb->args[IPSET_CB_PRIVATE]) {\n\t\tt = (struct htable *)cb->args[IPSET_CB_PRIVATE];\n\t\tif (atomic_dec_and_test(&t->uref) && atomic_read(&t->ref)) {\n\t\t\tpr_debug(\"Table destroy after resize \"\n\t\t\t\t \" by dump: %p\\n\", t);\n\t\t\tmtype_ahash_destroy(set, t, false);\n\t\t}\n\t\tcb->args[IPSET_CB_PRIVATE] = 0;\n\t}\n}\n\n \nstatic int\nmtype_list(const struct ip_set *set,\n\t   struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tconst struct htable *t;\n\tstruct nlattr *atd, *nested;\n\tconst struct hbucket *n;\n\tconst struct mtype_elem *e;\n\tu32 first = cb->args[IPSET_CB_ARG0];\n\t \n\tvoid *incomplete;\n\tint i, ret = 0;\n\n\tatd = nla_nest_start(skb, IPSET_ATTR_ADT);\n\tif (!atd)\n\t\treturn -EMSGSIZE;\n\n\tpr_debug(\"list hash set %s\\n\", set->name);\n\tt = (const struct htable *)cb->args[IPSET_CB_PRIVATE];\n\t \n\trcu_read_lock();\n\tfor (; cb->args[IPSET_CB_ARG0] < jhash_size(t->htable_bits);\n\t     cb->args[IPSET_CB_ARG0]++) {\n\t\tcond_resched_rcu();\n\t\tincomplete = skb_tail_pointer(skb);\n\t\tn = rcu_dereference(hbucket(t, cb->args[IPSET_CB_ARG0]));\n\t\tpr_debug(\"cb->arg bucket: %lu, t %p n %p\\n\",\n\t\t\t cb->args[IPSET_CB_ARG0], t, n);\n\t\tif (!n)\n\t\t\tcontinue;\n\t\tfor (i = 0; i < n->pos; i++) {\n\t\t\tif (!test_bit(i, n->used))\n\t\t\t\tcontinue;\n\t\t\te = ahash_data(n, i, set->dsize);\n\t\t\tif (SET_ELEM_EXPIRED(set, e))\n\t\t\t\tcontinue;\n\t\t\tpr_debug(\"list hash %lu hbucket %p i %u, data %p\\n\",\n\t\t\t\t cb->args[IPSET_CB_ARG0], n, i, e);\n\t\t\tnested = nla_nest_start(skb, IPSET_ATTR_DATA);\n\t\t\tif (!nested) {\n\t\t\t\tif (cb->args[IPSET_CB_ARG0] == first) {\n\t\t\t\t\tnla_nest_cancel(skb, atd);\n\t\t\t\t\tret = -EMSGSIZE;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tgoto nla_put_failure;\n\t\t\t}\n\t\t\tif (mtype_data_list(skb, e))\n\t\t\t\tgoto nla_put_failure;\n\t\t\tif (ip_set_put_extensions(skb, set, e, true))\n\t\t\t\tgoto nla_put_failure;\n\t\t\tnla_nest_end(skb, nested);\n\t\t}\n\t}\n\tnla_nest_end(skb, atd);\n\t \n\tcb->args[IPSET_CB_ARG0] = 0;\n\n\tgoto out;\n\nnla_put_failure:\n\tnlmsg_trim(skb, incomplete);\n\tif (unlikely(first == cb->args[IPSET_CB_ARG0])) {\n\t\tpr_warn(\"Can't list set %s: one bucket does not fit into a message. Please report it!\\n\",\n\t\t\tset->name);\n\t\tcb->args[IPSET_CB_ARG0] = 0;\n\t\tret = -EMSGSIZE;\n\t} else {\n\t\tnla_nest_end(skb, atd);\n\t}\nout:\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic int\nIPSET_TOKEN(MTYPE, _kadt)(struct ip_set *set, const struct sk_buff *skb,\n\t\t\t  const struct xt_action_param *par,\n\t\t\t  enum ipset_adt adt, struct ip_set_adt_opt *opt);\n\nstatic int\nIPSET_TOKEN(MTYPE, _uadt)(struct ip_set *set, struct nlattr *tb[],\n\t\t\t  enum ipset_adt adt, u32 *lineno, u32 flags,\n\t\t\t  bool retried);\n\nstatic const struct ip_set_type_variant mtype_variant = {\n\t.kadt\t= mtype_kadt,\n\t.uadt\t= mtype_uadt,\n\t.adt\t= {\n\t\t[IPSET_ADD] = mtype_add,\n\t\t[IPSET_DEL] = mtype_del,\n\t\t[IPSET_TEST] = mtype_test,\n\t},\n\t.destroy = mtype_destroy,\n\t.flush\t= mtype_flush,\n\t.head\t= mtype_head,\n\t.list\t= mtype_list,\n\t.uref\t= mtype_uref,\n\t.resize\t= mtype_resize,\n\t.same_set = mtype_same_set,\n\t.region_lock = true,\n};\n\n#ifdef IP_SET_EMIT_CREATE\nstatic int\nIPSET_TOKEN(HTYPE, _create)(struct net *net, struct ip_set *set,\n\t\t\t    struct nlattr *tb[], u32 flags)\n{\n\tu32 hashsize = IPSET_DEFAULT_HASHSIZE, maxelem = IPSET_DEFAULT_MAXELEM;\n#ifdef IP_SET_HASH_WITH_MARKMASK\n\tu32 markmask;\n#endif\n\tu8 hbits;\n#if defined(IP_SET_HASH_WITH_NETMASK) || defined(IP_SET_HASH_WITH_BITMASK)\n\tint ret __attribute__((unused)) = 0;\n\tu8 netmask = set->family == NFPROTO_IPV4 ? 32 : 128;\n\tunion nf_inet_addr bitmask = onesmask;\n#endif\n\tsize_t hsize;\n\tstruct htype *h;\n\tstruct htable *t;\n\tu32 i;\n\n\tpr_debug(\"Create set %s with family %s\\n\",\n\t\t set->name, set->family == NFPROTO_IPV4 ? \"inet\" : \"inet6\");\n\n#ifdef IP_SET_PROTO_UNDEF\n\tif (set->family != NFPROTO_UNSPEC)\n\t\treturn -IPSET_ERR_INVALID_FAMILY;\n#else\n\tif (!(set->family == NFPROTO_IPV4 || set->family == NFPROTO_IPV6))\n\t\treturn -IPSET_ERR_INVALID_FAMILY;\n#endif\n\n\tif (unlikely(!ip_set_optattr_netorder(tb, IPSET_ATTR_HASHSIZE) ||\n\t\t     !ip_set_optattr_netorder(tb, IPSET_ATTR_MAXELEM) ||\n\t\t     !ip_set_optattr_netorder(tb, IPSET_ATTR_TIMEOUT) ||\n\t\t     !ip_set_optattr_netorder(tb, IPSET_ATTR_CADT_FLAGS)))\n\t\treturn -IPSET_ERR_PROTOCOL;\n\n#ifdef IP_SET_HASH_WITH_MARKMASK\n\t \n\tif (unlikely(!ip_set_optattr_netorder(tb, IPSET_ATTR_MARKMASK)))\n\t\treturn -IPSET_ERR_PROTOCOL;\n\n\tmarkmask = 0xffffffff;\n\tif (tb[IPSET_ATTR_MARKMASK]) {\n\t\tmarkmask = ntohl(nla_get_be32(tb[IPSET_ATTR_MARKMASK]));\n\t\tif (markmask == 0)\n\t\t\treturn -IPSET_ERR_INVALID_MARKMASK;\n\t}\n#endif\n\n#ifdef IP_SET_HASH_WITH_NETMASK\n\tif (tb[IPSET_ATTR_NETMASK]) {\n\t\tnetmask = nla_get_u8(tb[IPSET_ATTR_NETMASK]);\n\n\t\tif ((set->family == NFPROTO_IPV4 && netmask > 32) ||\n\t\t    (set->family == NFPROTO_IPV6 && netmask > 128) ||\n\t\t    netmask == 0)\n\t\t\treturn -IPSET_ERR_INVALID_NETMASK;\n\n\t\t \n\t\tif (set->family == NFPROTO_IPV4)\n\t\t\tbitmask.ip = ip_set_netmask(netmask);\n\t\telse\n\t\t\tip6_netmask(&bitmask, netmask);\n\t}\n#endif\n\n#ifdef IP_SET_HASH_WITH_BITMASK\n\tif (tb[IPSET_ATTR_BITMASK]) {\n\t\t \n\t\tif (tb[IPSET_ATTR_NETMASK])\n\t\t\treturn -IPSET_ERR_BITMASK_NETMASK_EXCL;\n\n\t\tif (set->family == NFPROTO_IPV4) {\n\t\t\tret = ip_set_get_ipaddr4(tb[IPSET_ATTR_BITMASK], &bitmask.ip);\n\t\t\tif (ret || !bitmask.ip)\n\t\t\t\treturn -IPSET_ERR_INVALID_NETMASK;\n\t\t} else if (set->family == NFPROTO_IPV6) {\n\t\t\tret = ip_set_get_ipaddr6(tb[IPSET_ATTR_BITMASK], &bitmask);\n\t\t\tif (ret || ipv6_addr_any(&bitmask.in6))\n\t\t\t\treturn -IPSET_ERR_INVALID_NETMASK;\n\t\t}\n\n\t\tif (nf_inet_addr_cmp(&bitmask, &zeromask))\n\t\t\treturn -IPSET_ERR_INVALID_NETMASK;\n\t}\n#endif\n\n\tif (tb[IPSET_ATTR_HASHSIZE]) {\n\t\thashsize = ip_set_get_h32(tb[IPSET_ATTR_HASHSIZE]);\n\t\tif (hashsize < IPSET_MIMINAL_HASHSIZE)\n\t\t\thashsize = IPSET_MIMINAL_HASHSIZE;\n\t}\n\n\tif (tb[IPSET_ATTR_MAXELEM])\n\t\tmaxelem = ip_set_get_h32(tb[IPSET_ATTR_MAXELEM]);\n\n\thsize = sizeof(*h);\n\th = kzalloc(hsize, GFP_KERNEL);\n\tif (!h)\n\t\treturn -ENOMEM;\n\n\t \n\thbits = fls(hashsize - 1);\n\thsize = htable_size(hbits);\n\tif (hsize == 0) {\n\t\tkfree(h);\n\t\treturn -ENOMEM;\n\t}\n\tt = ip_set_alloc(hsize);\n\tif (!t) {\n\t\tkfree(h);\n\t\treturn -ENOMEM;\n\t}\n\tt->hregion = ip_set_alloc(ahash_sizeof_regions(hbits));\n\tif (!t->hregion) {\n\t\tip_set_free(t);\n\t\tkfree(h);\n\t\treturn -ENOMEM;\n\t}\n\th->gc.set = set;\n\tfor (i = 0; i < ahash_numof_locks(hbits); i++)\n\t\tspin_lock_init(&t->hregion[i].lock);\n\th->maxelem = maxelem;\n#if defined(IP_SET_HASH_WITH_NETMASK) || defined(IP_SET_HASH_WITH_BITMASK)\n\th->bitmask = bitmask;\n\th->netmask = netmask;\n#endif\n#ifdef IP_SET_HASH_WITH_MARKMASK\n\th->markmask = markmask;\n#endif\n\tif (tb[IPSET_ATTR_INITVAL])\n\t\th->initval = ntohl(nla_get_be32(tb[IPSET_ATTR_INITVAL]));\n\telse\n\t\tget_random_bytes(&h->initval, sizeof(h->initval));\n\th->bucketsize = AHASH_MAX_SIZE;\n\tif (tb[IPSET_ATTR_BUCKETSIZE]) {\n\t\th->bucketsize = nla_get_u8(tb[IPSET_ATTR_BUCKETSIZE]);\n\t\tif (h->bucketsize < AHASH_INIT_SIZE)\n\t\t\th->bucketsize = AHASH_INIT_SIZE;\n\t\telse if (h->bucketsize > AHASH_MAX_SIZE)\n\t\t\th->bucketsize = AHASH_MAX_SIZE;\n\t\telse if (h->bucketsize % 2)\n\t\t\th->bucketsize += 1;\n\t}\n\tt->htable_bits = hbits;\n\tt->maxelem = h->maxelem / ahash_numof_locks(hbits);\n\tRCU_INIT_POINTER(h->table, t);\n\n\tINIT_LIST_HEAD(&h->ad);\n\tset->data = h;\n#ifndef IP_SET_PROTO_UNDEF\n\tif (set->family == NFPROTO_IPV4) {\n#endif\n\t\tset->variant = &IPSET_TOKEN(HTYPE, 4_variant);\n\t\tset->dsize = ip_set_elem_len(set, tb,\n\t\t\tsizeof(struct IPSET_TOKEN(HTYPE, 4_elem)),\n\t\t\t__alignof__(struct IPSET_TOKEN(HTYPE, 4_elem)));\n#ifndef IP_SET_PROTO_UNDEF\n\t} else {\n\t\tset->variant = &IPSET_TOKEN(HTYPE, 6_variant);\n\t\tset->dsize = ip_set_elem_len(set, tb,\n\t\t\tsizeof(struct IPSET_TOKEN(HTYPE, 6_elem)),\n\t\t\t__alignof__(struct IPSET_TOKEN(HTYPE, 6_elem)));\n\t}\n#endif\n\tset->timeout = IPSET_NO_TIMEOUT;\n\tif (tb[IPSET_ATTR_TIMEOUT]) {\n\t\tset->timeout = ip_set_timeout_uget(tb[IPSET_ATTR_TIMEOUT]);\n#ifndef IP_SET_PROTO_UNDEF\n\t\tif (set->family == NFPROTO_IPV4)\n#endif\n\t\t\tIPSET_TOKEN(HTYPE, 4_gc_init)(&h->gc);\n#ifndef IP_SET_PROTO_UNDEF\n\t\telse\n\t\t\tIPSET_TOKEN(HTYPE, 6_gc_init)(&h->gc);\n#endif\n\t}\n\tpr_debug(\"create %s hashsize %u (%u) maxelem %u: %p(%p)\\n\",\n\t\t set->name, jhash_size(t->htable_bits),\n\t\t t->htable_bits, h->maxelem, set->data, t);\n\n\treturn 0;\n}\n#endif  \n\n#undef HKEY_DATALEN\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}