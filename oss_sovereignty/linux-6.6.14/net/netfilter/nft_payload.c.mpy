{
  "module_name": "nft_payload.c",
  "hash_id": "5597e31a2e2d0493835d720798b0629a2927f92c39a9f0538306144833231615",
  "original_prompt": "Ingested from linux-6.6.14/net/netfilter/nft_payload.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/if_vlan.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/netlink.h>\n#include <linux/netfilter.h>\n#include <linux/netfilter/nf_tables.h>\n#include <net/netfilter/nf_tables_core.h>\n#include <net/netfilter/nf_tables.h>\n#include <net/netfilter/nf_tables_offload.h>\n \n#include <linux/tcp.h>\n#include <linux/udp.h>\n#include <net/gre.h>\n#include <linux/icmpv6.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <net/sctp/checksum.h>\n\nstatic bool nft_payload_rebuild_vlan_hdr(const struct sk_buff *skb, int mac_off,\n\t\t\t\t\t struct vlan_ethhdr *veth)\n{\n\tif (skb_copy_bits(skb, mac_off, veth, ETH_HLEN))\n\t\treturn false;\n\n\tveth->h_vlan_proto = skb->vlan_proto;\n\tveth->h_vlan_TCI = htons(skb_vlan_tag_get(skb));\n\tveth->h_vlan_encapsulated_proto = skb->protocol;\n\n\treturn true;\n}\n\n \nstatic bool\nnft_payload_copy_vlan(u32 *d, const struct sk_buff *skb, u8 offset, u8 len)\n{\n\tint mac_off = skb_mac_header(skb) - skb->data;\n\tu8 *vlanh, *dst_u8 = (u8 *) d;\n\tstruct vlan_ethhdr veth;\n\tu8 vlan_hlen = 0;\n\n\tif ((skb->protocol == htons(ETH_P_8021AD) ||\n\t     skb->protocol == htons(ETH_P_8021Q)) &&\n\t    offset >= VLAN_ETH_HLEN && offset < VLAN_ETH_HLEN + VLAN_HLEN)\n\t\tvlan_hlen += VLAN_HLEN;\n\n\tvlanh = (u8 *) &veth;\n\tif (offset < VLAN_ETH_HLEN + vlan_hlen) {\n\t\tu8 ethlen = len;\n\n\t\tif (vlan_hlen &&\n\t\t    skb_copy_bits(skb, mac_off, &veth, VLAN_ETH_HLEN) < 0)\n\t\t\treturn false;\n\t\telse if (!nft_payload_rebuild_vlan_hdr(skb, mac_off, &veth))\n\t\t\treturn false;\n\n\t\tif (offset + len > VLAN_ETH_HLEN + vlan_hlen)\n\t\t\tethlen -= offset + len - VLAN_ETH_HLEN - vlan_hlen;\n\n\t\tmemcpy(dst_u8, vlanh + offset - vlan_hlen, ethlen);\n\n\t\tlen -= ethlen;\n\t\tif (len == 0)\n\t\t\treturn true;\n\n\t\tdst_u8 += ethlen;\n\t\toffset = ETH_HLEN + vlan_hlen;\n\t} else {\n\t\toffset -= VLAN_HLEN + vlan_hlen;\n\t}\n\n\treturn skb_copy_bits(skb, offset + mac_off, dst_u8, len) == 0;\n}\n\nstatic int __nft_payload_inner_offset(struct nft_pktinfo *pkt)\n{\n\tunsigned int thoff = nft_thoff(pkt);\n\n\tif (!(pkt->flags & NFT_PKTINFO_L4PROTO) || pkt->fragoff)\n\t\treturn -1;\n\n\tswitch (pkt->tprot) {\n\tcase IPPROTO_UDP:\n\t\tpkt->inneroff = thoff + sizeof(struct udphdr);\n\t\tbreak;\n\tcase IPPROTO_TCP: {\n\t\tstruct tcphdr *th, _tcph;\n\n\t\tth = skb_header_pointer(pkt->skb, thoff, sizeof(_tcph), &_tcph);\n\t\tif (!th)\n\t\t\treturn -1;\n\n\t\tpkt->inneroff = thoff + __tcp_hdrlen(th);\n\t\t}\n\t\tbreak;\n\tcase IPPROTO_GRE: {\n\t\tu32 offset = sizeof(struct gre_base_hdr);\n\t\tstruct gre_base_hdr *gre, _gre;\n\t\t__be16 version;\n\n\t\tgre = skb_header_pointer(pkt->skb, thoff, sizeof(_gre), &_gre);\n\t\tif (!gre)\n\t\t\treturn -1;\n\n\t\tversion = gre->flags & GRE_VERSION;\n\t\tswitch (version) {\n\t\tcase GRE_VERSION_0:\n\t\t\tif (gre->flags & GRE_ROUTING)\n\t\t\t\treturn -1;\n\n\t\t\tif (gre->flags & GRE_CSUM) {\n\t\t\t\toffset += sizeof_field(struct gre_full_hdr, csum) +\n\t\t\t\t\t  sizeof_field(struct gre_full_hdr, reserved1);\n\t\t\t}\n\t\t\tif (gre->flags & GRE_KEY)\n\t\t\t\toffset += sizeof_field(struct gre_full_hdr, key);\n\n\t\t\tif (gre->flags & GRE_SEQ)\n\t\t\t\toffset += sizeof_field(struct gre_full_hdr, seq);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -1;\n\t\t}\n\n\t\tpkt->inneroff = thoff + offset;\n\t\t}\n\t\tbreak;\n\tcase IPPROTO_IPIP:\n\t\tpkt->inneroff = thoff;\n\t\tbreak;\n\tdefault:\n\t\treturn -1;\n\t}\n\n\tpkt->flags |= NFT_PKTINFO_INNER;\n\n\treturn 0;\n}\n\nint nft_payload_inner_offset(const struct nft_pktinfo *pkt)\n{\n\tif (!(pkt->flags & NFT_PKTINFO_INNER) &&\n\t    __nft_payload_inner_offset((struct nft_pktinfo *)pkt) < 0)\n\t\treturn -1;\n\n\treturn pkt->inneroff;\n}\n\nstatic bool nft_payload_need_vlan_copy(const struct nft_payload *priv)\n{\n\tunsigned int len = priv->offset + priv->len;\n\n\t \n\tif (len > offsetof(struct ethhdr, h_proto))\n\t\treturn true;\n\n\treturn false;\n}\n\nvoid nft_payload_eval(const struct nft_expr *expr,\n\t\t      struct nft_regs *regs,\n\t\t      const struct nft_pktinfo *pkt)\n{\n\tconst struct nft_payload *priv = nft_expr_priv(expr);\n\tconst struct sk_buff *skb = pkt->skb;\n\tu32 *dest = &regs->data[priv->dreg];\n\tint offset;\n\n\tif (priv->len % NFT_REG32_SIZE)\n\t\tdest[priv->len / NFT_REG32_SIZE] = 0;\n\n\tswitch (priv->base) {\n\tcase NFT_PAYLOAD_LL_HEADER:\n\t\tif (!skb_mac_header_was_set(skb) || skb_mac_header_len(skb) == 0)\n\t\t\tgoto err;\n\n\t\tif (skb_vlan_tag_present(skb) &&\n\t\t    nft_payload_need_vlan_copy(priv)) {\n\t\t\tif (!nft_payload_copy_vlan(dest, skb,\n\t\t\t\t\t\t   priv->offset, priv->len))\n\t\t\t\tgoto err;\n\t\t\treturn;\n\t\t}\n\t\toffset = skb_mac_header(skb) - skb->data;\n\t\tbreak;\n\tcase NFT_PAYLOAD_NETWORK_HEADER:\n\t\toffset = skb_network_offset(skb);\n\t\tbreak;\n\tcase NFT_PAYLOAD_TRANSPORT_HEADER:\n\t\tif (!(pkt->flags & NFT_PKTINFO_L4PROTO) || pkt->fragoff)\n\t\t\tgoto err;\n\t\toffset = nft_thoff(pkt);\n\t\tbreak;\n\tcase NFT_PAYLOAD_INNER_HEADER:\n\t\toffset = nft_payload_inner_offset(pkt);\n\t\tif (offset < 0)\n\t\t\tgoto err;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\tgoto err;\n\t}\n\toffset += priv->offset;\n\n\tif (skb_copy_bits(skb, offset, dest, priv->len) < 0)\n\t\tgoto err;\n\treturn;\nerr:\n\tregs->verdict.code = NFT_BREAK;\n}\n\nstatic const struct nla_policy nft_payload_policy[NFTA_PAYLOAD_MAX + 1] = {\n\t[NFTA_PAYLOAD_SREG]\t\t= { .type = NLA_U32 },\n\t[NFTA_PAYLOAD_DREG]\t\t= { .type = NLA_U32 },\n\t[NFTA_PAYLOAD_BASE]\t\t= { .type = NLA_U32 },\n\t[NFTA_PAYLOAD_OFFSET]\t\t= NLA_POLICY_MAX(NLA_BE32, 255),\n\t[NFTA_PAYLOAD_LEN]\t\t= NLA_POLICY_MAX(NLA_BE32, 255),\n\t[NFTA_PAYLOAD_CSUM_TYPE]\t= { .type = NLA_U32 },\n\t[NFTA_PAYLOAD_CSUM_OFFSET]\t= NLA_POLICY_MAX(NLA_BE32, 255),\n\t[NFTA_PAYLOAD_CSUM_FLAGS]\t= { .type = NLA_U32 },\n};\n\nstatic int nft_payload_init(const struct nft_ctx *ctx,\n\t\t\t    const struct nft_expr *expr,\n\t\t\t    const struct nlattr * const tb[])\n{\n\tstruct nft_payload *priv = nft_expr_priv(expr);\n\n\tpriv->base   = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_BASE]));\n\tpriv->offset = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_OFFSET]));\n\tpriv->len    = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_LEN]));\n\n\treturn nft_parse_register_store(ctx, tb[NFTA_PAYLOAD_DREG],\n\t\t\t\t\t&priv->dreg, NULL, NFT_DATA_VALUE,\n\t\t\t\t\tpriv->len);\n}\n\nstatic int nft_payload_dump(struct sk_buff *skb,\n\t\t\t    const struct nft_expr *expr, bool reset)\n{\n\tconst struct nft_payload *priv = nft_expr_priv(expr);\n\n\tif (nft_dump_register(skb, NFTA_PAYLOAD_DREG, priv->dreg) ||\n\t    nla_put_be32(skb, NFTA_PAYLOAD_BASE, htonl(priv->base)) ||\n\t    nla_put_be32(skb, NFTA_PAYLOAD_OFFSET, htonl(priv->offset)) ||\n\t    nla_put_be32(skb, NFTA_PAYLOAD_LEN, htonl(priv->len)))\n\t\tgoto nla_put_failure;\n\treturn 0;\n\nnla_put_failure:\n\treturn -1;\n}\n\nstatic bool nft_payload_reduce(struct nft_regs_track *track,\n\t\t\t       const struct nft_expr *expr)\n{\n\tconst struct nft_payload *priv = nft_expr_priv(expr);\n\tconst struct nft_payload *payload;\n\n\tif (!nft_reg_track_cmp(track, expr, priv->dreg)) {\n\t\tnft_reg_track_update(track, expr, priv->dreg, priv->len);\n\t\treturn false;\n\t}\n\n\tpayload = nft_expr_priv(track->regs[priv->dreg].selector);\n\tif (priv->base != payload->base ||\n\t    priv->offset != payload->offset ||\n\t    priv->len != payload->len) {\n\t\tnft_reg_track_update(track, expr, priv->dreg, priv->len);\n\t\treturn false;\n\t}\n\n\tif (!track->regs[priv->dreg].bitwise)\n\t\treturn true;\n\n\treturn nft_expr_reduce_bitwise(track, expr);\n}\n\nstatic bool nft_payload_offload_mask(struct nft_offload_reg *reg,\n\t\t\t\t     u32 priv_len, u32 field_len)\n{\n\tunsigned int remainder, delta, k;\n\tstruct nft_data mask = {};\n\t__be32 remainder_mask;\n\n\tif (priv_len == field_len) {\n\t\tmemset(&reg->mask, 0xff, priv_len);\n\t\treturn true;\n\t} else if (priv_len > field_len) {\n\t\treturn false;\n\t}\n\n\tmemset(&mask, 0xff, field_len);\n\tremainder = priv_len % sizeof(u32);\n\tif (remainder) {\n\t\tk = priv_len / sizeof(u32);\n\t\tdelta = field_len - priv_len;\n\t\tremainder_mask = htonl(~((1 << (delta * BITS_PER_BYTE)) - 1));\n\t\tmask.data[k] = (__force u32)remainder_mask;\n\t}\n\n\tmemcpy(&reg->mask, &mask, field_len);\n\n\treturn true;\n}\n\nstatic int nft_payload_offload_ll(struct nft_offload_ctx *ctx,\n\t\t\t\t  struct nft_flow_rule *flow,\n\t\t\t\t  const struct nft_payload *priv)\n{\n\tstruct nft_offload_reg *reg = &ctx->regs[priv->dreg];\n\n\tswitch (priv->offset) {\n\tcase offsetof(struct ethhdr, h_source):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, ETH_ALEN))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_ETH_ADDRS, eth_addrs,\n\t\t\t\t  src, ETH_ALEN, reg);\n\t\tbreak;\n\tcase offsetof(struct ethhdr, h_dest):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, ETH_ALEN))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_ETH_ADDRS, eth_addrs,\n\t\t\t\t  dst, ETH_ALEN, reg);\n\t\tbreak;\n\tcase offsetof(struct ethhdr, h_proto):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__be16)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_BASIC, basic,\n\t\t\t\t  n_proto, sizeof(__be16), reg);\n\t\tnft_offload_set_dependency(ctx, NFT_OFFLOAD_DEP_NETWORK);\n\t\tbreak;\n\tcase offsetof(struct vlan_ethhdr, h_vlan_TCI):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__be16)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH_FLAGS(FLOW_DISSECTOR_KEY_VLAN, vlan,\n\t\t\t\t\tvlan_tci, sizeof(__be16), reg,\n\t\t\t\t\tNFT_OFFLOAD_F_NETWORK2HOST);\n\t\tbreak;\n\tcase offsetof(struct vlan_ethhdr, h_vlan_encapsulated_proto):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__be16)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_VLAN, vlan,\n\t\t\t\t  vlan_tpid, sizeof(__be16), reg);\n\t\tnft_offload_set_dependency(ctx, NFT_OFFLOAD_DEP_NETWORK);\n\t\tbreak;\n\tcase offsetof(struct vlan_ethhdr, h_vlan_TCI) + sizeof(struct vlan_hdr):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__be16)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH_FLAGS(FLOW_DISSECTOR_KEY_CVLAN, cvlan,\n\t\t\t\t\tvlan_tci, sizeof(__be16), reg,\n\t\t\t\t\tNFT_OFFLOAD_F_NETWORK2HOST);\n\t\tbreak;\n\tcase offsetof(struct vlan_ethhdr, h_vlan_encapsulated_proto) +\n\t\t\t\t\t\t\tsizeof(struct vlan_hdr):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__be16)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_CVLAN, cvlan,\n\t\t\t\t  vlan_tpid, sizeof(__be16), reg);\n\t\tnft_offload_set_dependency(ctx, NFT_OFFLOAD_DEP_NETWORK);\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int nft_payload_offload_ip(struct nft_offload_ctx *ctx,\n\t\t\t\t  struct nft_flow_rule *flow,\n\t\t\t\t  const struct nft_payload *priv)\n{\n\tstruct nft_offload_reg *reg = &ctx->regs[priv->dreg];\n\n\tswitch (priv->offset) {\n\tcase offsetof(struct iphdr, saddr):\n\t\tif (!nft_payload_offload_mask(reg, priv->len,\n\t\t\t\t\t      sizeof(struct in_addr)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_IPV4_ADDRS, ipv4, src,\n\t\t\t\t  sizeof(struct in_addr), reg);\n\t\tnft_flow_rule_set_addr_type(flow, FLOW_DISSECTOR_KEY_IPV4_ADDRS);\n\t\tbreak;\n\tcase offsetof(struct iphdr, daddr):\n\t\tif (!nft_payload_offload_mask(reg, priv->len,\n\t\t\t\t\t      sizeof(struct in_addr)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_IPV4_ADDRS, ipv4, dst,\n\t\t\t\t  sizeof(struct in_addr), reg);\n\t\tnft_flow_rule_set_addr_type(flow, FLOW_DISSECTOR_KEY_IPV4_ADDRS);\n\t\tbreak;\n\tcase offsetof(struct iphdr, protocol):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__u8)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_BASIC, basic, ip_proto,\n\t\t\t\t  sizeof(__u8), reg);\n\t\tnft_offload_set_dependency(ctx, NFT_OFFLOAD_DEP_TRANSPORT);\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int nft_payload_offload_ip6(struct nft_offload_ctx *ctx,\n\t\t\t\t  struct nft_flow_rule *flow,\n\t\t\t\t  const struct nft_payload *priv)\n{\n\tstruct nft_offload_reg *reg = &ctx->regs[priv->dreg];\n\n\tswitch (priv->offset) {\n\tcase offsetof(struct ipv6hdr, saddr):\n\t\tif (!nft_payload_offload_mask(reg, priv->len,\n\t\t\t\t\t      sizeof(struct in6_addr)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_IPV6_ADDRS, ipv6, src,\n\t\t\t\t  sizeof(struct in6_addr), reg);\n\t\tnft_flow_rule_set_addr_type(flow, FLOW_DISSECTOR_KEY_IPV6_ADDRS);\n\t\tbreak;\n\tcase offsetof(struct ipv6hdr, daddr):\n\t\tif (!nft_payload_offload_mask(reg, priv->len,\n\t\t\t\t\t      sizeof(struct in6_addr)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_IPV6_ADDRS, ipv6, dst,\n\t\t\t\t  sizeof(struct in6_addr), reg);\n\t\tnft_flow_rule_set_addr_type(flow, FLOW_DISSECTOR_KEY_IPV6_ADDRS);\n\t\tbreak;\n\tcase offsetof(struct ipv6hdr, nexthdr):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__u8)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_BASIC, basic, ip_proto,\n\t\t\t\t  sizeof(__u8), reg);\n\t\tnft_offload_set_dependency(ctx, NFT_OFFLOAD_DEP_TRANSPORT);\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int nft_payload_offload_nh(struct nft_offload_ctx *ctx,\n\t\t\t\t  struct nft_flow_rule *flow,\n\t\t\t\t  const struct nft_payload *priv)\n{\n\tint err;\n\n\tswitch (ctx->dep.l3num) {\n\tcase htons(ETH_P_IP):\n\t\terr = nft_payload_offload_ip(ctx, flow, priv);\n\t\tbreak;\n\tcase htons(ETH_P_IPV6):\n\t\terr = nft_payload_offload_ip6(ctx, flow, priv);\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn err;\n}\n\nstatic int nft_payload_offload_tcp(struct nft_offload_ctx *ctx,\n\t\t\t\t   struct nft_flow_rule *flow,\n\t\t\t\t   const struct nft_payload *priv)\n{\n\tstruct nft_offload_reg *reg = &ctx->regs[priv->dreg];\n\n\tswitch (priv->offset) {\n\tcase offsetof(struct tcphdr, source):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__be16)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_PORTS, tp, src,\n\t\t\t\t  sizeof(__be16), reg);\n\t\tbreak;\n\tcase offsetof(struct tcphdr, dest):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__be16)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_PORTS, tp, dst,\n\t\t\t\t  sizeof(__be16), reg);\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int nft_payload_offload_udp(struct nft_offload_ctx *ctx,\n\t\t\t\t   struct nft_flow_rule *flow,\n\t\t\t\t   const struct nft_payload *priv)\n{\n\tstruct nft_offload_reg *reg = &ctx->regs[priv->dreg];\n\n\tswitch (priv->offset) {\n\tcase offsetof(struct udphdr, source):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__be16)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_PORTS, tp, src,\n\t\t\t\t  sizeof(__be16), reg);\n\t\tbreak;\n\tcase offsetof(struct udphdr, dest):\n\t\tif (!nft_payload_offload_mask(reg, priv->len, sizeof(__be16)))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tNFT_OFFLOAD_MATCH(FLOW_DISSECTOR_KEY_PORTS, tp, dst,\n\t\t\t\t  sizeof(__be16), reg);\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int nft_payload_offload_th(struct nft_offload_ctx *ctx,\n\t\t\t\t  struct nft_flow_rule *flow,\n\t\t\t\t  const struct nft_payload *priv)\n{\n\tint err;\n\n\tswitch (ctx->dep.protonum) {\n\tcase IPPROTO_TCP:\n\t\terr = nft_payload_offload_tcp(ctx, flow, priv);\n\t\tbreak;\n\tcase IPPROTO_UDP:\n\t\terr = nft_payload_offload_udp(ctx, flow, priv);\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn err;\n}\n\nstatic int nft_payload_offload(struct nft_offload_ctx *ctx,\n\t\t\t       struct nft_flow_rule *flow,\n\t\t\t       const struct nft_expr *expr)\n{\n\tconst struct nft_payload *priv = nft_expr_priv(expr);\n\tint err;\n\n\tswitch (priv->base) {\n\tcase NFT_PAYLOAD_LL_HEADER:\n\t\terr = nft_payload_offload_ll(ctx, flow, priv);\n\t\tbreak;\n\tcase NFT_PAYLOAD_NETWORK_HEADER:\n\t\terr = nft_payload_offload_nh(ctx, flow, priv);\n\t\tbreak;\n\tcase NFT_PAYLOAD_TRANSPORT_HEADER:\n\t\terr = nft_payload_offload_th(ctx, flow, priv);\n\t\tbreak;\n\tdefault:\n\t\terr = -EOPNOTSUPP;\n\t\tbreak;\n\t}\n\treturn err;\n}\n\nstatic const struct nft_expr_ops nft_payload_ops = {\n\t.type\t\t= &nft_payload_type,\n\t.size\t\t= NFT_EXPR_SIZE(sizeof(struct nft_payload)),\n\t.eval\t\t= nft_payload_eval,\n\t.init\t\t= nft_payload_init,\n\t.dump\t\t= nft_payload_dump,\n\t.reduce\t\t= nft_payload_reduce,\n\t.offload\t= nft_payload_offload,\n};\n\nconst struct nft_expr_ops nft_payload_fast_ops = {\n\t.type\t\t= &nft_payload_type,\n\t.size\t\t= NFT_EXPR_SIZE(sizeof(struct nft_payload)),\n\t.eval\t\t= nft_payload_eval,\n\t.init\t\t= nft_payload_init,\n\t.dump\t\t= nft_payload_dump,\n\t.reduce\t\t= nft_payload_reduce,\n\t.offload\t= nft_payload_offload,\n};\n\nvoid nft_payload_inner_eval(const struct nft_expr *expr, struct nft_regs *regs,\n\t\t\t    const struct nft_pktinfo *pkt,\n\t\t\t    struct nft_inner_tun_ctx *tun_ctx)\n{\n\tconst struct nft_payload *priv = nft_expr_priv(expr);\n\tconst struct sk_buff *skb = pkt->skb;\n\tu32 *dest = &regs->data[priv->dreg];\n\tint offset;\n\n\tif (priv->len % NFT_REG32_SIZE)\n\t\tdest[priv->len / NFT_REG32_SIZE] = 0;\n\n\tswitch (priv->base) {\n\tcase NFT_PAYLOAD_TUN_HEADER:\n\t\tif (!(tun_ctx->flags & NFT_PAYLOAD_CTX_INNER_TUN))\n\t\t\tgoto err;\n\n\t\toffset = tun_ctx->inner_tunoff;\n\t\tbreak;\n\tcase NFT_PAYLOAD_LL_HEADER:\n\t\tif (!(tun_ctx->flags & NFT_PAYLOAD_CTX_INNER_LL))\n\t\t\tgoto err;\n\n\t\toffset = tun_ctx->inner_lloff;\n\t\tbreak;\n\tcase NFT_PAYLOAD_NETWORK_HEADER:\n\t\tif (!(tun_ctx->flags & NFT_PAYLOAD_CTX_INNER_NH))\n\t\t\tgoto err;\n\n\t\toffset = tun_ctx->inner_nhoff;\n\t\tbreak;\n\tcase NFT_PAYLOAD_TRANSPORT_HEADER:\n\t\tif (!(tun_ctx->flags & NFT_PAYLOAD_CTX_INNER_TH))\n\t\t\tgoto err;\n\n\t\toffset = tun_ctx->inner_thoff;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\tgoto err;\n\t}\n\toffset += priv->offset;\n\n\tif (skb_copy_bits(skb, offset, dest, priv->len) < 0)\n\t\tgoto err;\n\n\treturn;\nerr:\n\tregs->verdict.code = NFT_BREAK;\n}\n\nstatic int nft_payload_inner_init(const struct nft_ctx *ctx,\n\t\t\t\t  const struct nft_expr *expr,\n\t\t\t\t  const struct nlattr * const tb[])\n{\n\tstruct nft_payload *priv = nft_expr_priv(expr);\n\tu32 base;\n\n\tbase   = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_BASE]));\n\tswitch (base) {\n\tcase NFT_PAYLOAD_TUN_HEADER:\n\tcase NFT_PAYLOAD_LL_HEADER:\n\tcase NFT_PAYLOAD_NETWORK_HEADER:\n\tcase NFT_PAYLOAD_TRANSPORT_HEADER:\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tpriv->base   = base;\n\tpriv->offset = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_OFFSET]));\n\tpriv->len    = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_LEN]));\n\n\treturn nft_parse_register_store(ctx, tb[NFTA_PAYLOAD_DREG],\n\t\t\t\t\t&priv->dreg, NULL, NFT_DATA_VALUE,\n\t\t\t\t\tpriv->len);\n}\n\nstatic const struct nft_expr_ops nft_payload_inner_ops = {\n\t.type\t\t= &nft_payload_type,\n\t.size\t\t= NFT_EXPR_SIZE(sizeof(struct nft_payload)),\n\t.init\t\t= nft_payload_inner_init,\n\t.dump\t\t= nft_payload_dump,\n\t \n};\n\nstatic inline void nft_csum_replace(__sum16 *sum, __wsum fsum, __wsum tsum)\n{\n\t*sum = csum_fold(csum_add(csum_sub(~csum_unfold(*sum), fsum), tsum));\n\tif (*sum == 0)\n\t\t*sum = CSUM_MANGLED_0;\n}\n\nstatic bool nft_payload_udp_checksum(struct sk_buff *skb, unsigned int thoff)\n{\n\tstruct udphdr *uh, _uh;\n\n\tuh = skb_header_pointer(skb, thoff, sizeof(_uh), &_uh);\n\tif (!uh)\n\t\treturn false;\n\n\treturn (__force bool)uh->check;\n}\n\nstatic int nft_payload_l4csum_offset(const struct nft_pktinfo *pkt,\n\t\t\t\t     struct sk_buff *skb,\n\t\t\t\t     unsigned int *l4csum_offset)\n{\n\tif (pkt->fragoff)\n\t\treturn -1;\n\n\tswitch (pkt->tprot) {\n\tcase IPPROTO_TCP:\n\t\t*l4csum_offset = offsetof(struct tcphdr, check);\n\t\tbreak;\n\tcase IPPROTO_UDP:\n\t\tif (!nft_payload_udp_checksum(skb, nft_thoff(pkt)))\n\t\t\treturn -1;\n\t\tfallthrough;\n\tcase IPPROTO_UDPLITE:\n\t\t*l4csum_offset = offsetof(struct udphdr, check);\n\t\tbreak;\n\tcase IPPROTO_ICMPV6:\n\t\t*l4csum_offset = offsetof(struct icmp6hdr, icmp6_cksum);\n\t\tbreak;\n\tdefault:\n\t\treturn -1;\n\t}\n\n\t*l4csum_offset += nft_thoff(pkt);\n\treturn 0;\n}\n\nstatic int nft_payload_csum_sctp(struct sk_buff *skb, int offset)\n{\n\tstruct sctphdr *sh;\n\n\tif (skb_ensure_writable(skb, offset + sizeof(*sh)))\n\t\treturn -1;\n\n\tsh = (struct sctphdr *)(skb->data + offset);\n\tsh->checksum = sctp_compute_cksum(skb, offset);\n\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\treturn 0;\n}\n\nstatic int nft_payload_l4csum_update(const struct nft_pktinfo *pkt,\n\t\t\t\t     struct sk_buff *skb,\n\t\t\t\t     __wsum fsum, __wsum tsum)\n{\n\tint l4csum_offset;\n\t__sum16 sum;\n\n\t \n\tif (nft_payload_l4csum_offset(pkt, skb, &l4csum_offset) < 0)\n\t\treturn 0;\n\n\tif (skb_copy_bits(skb, l4csum_offset, &sum, sizeof(sum)) < 0)\n\t\treturn -1;\n\n\t \n\tif (skb->ip_summed != CHECKSUM_PARTIAL) {\n\t\tnft_csum_replace(&sum, fsum, tsum);\n\t\tif (skb->ip_summed == CHECKSUM_COMPLETE) {\n\t\t\tskb->csum = ~csum_add(csum_sub(~(skb->csum), fsum),\n\t\t\t\t\t      tsum);\n\t\t}\n\t} else {\n\t\tsum = ~csum_fold(csum_add(csum_sub(csum_unfold(sum), fsum),\n\t\t\t\t\t  tsum));\n\t}\n\n\tif (skb_ensure_writable(skb, l4csum_offset + sizeof(sum)) ||\n\t    skb_store_bits(skb, l4csum_offset, &sum, sizeof(sum)) < 0)\n\t\treturn -1;\n\n\treturn 0;\n}\n\nstatic int nft_payload_csum_inet(struct sk_buff *skb, const u32 *src,\n\t\t\t\t __wsum fsum, __wsum tsum, int csum_offset)\n{\n\t__sum16 sum;\n\n\tif (skb_copy_bits(skb, csum_offset, &sum, sizeof(sum)) < 0)\n\t\treturn -1;\n\n\tnft_csum_replace(&sum, fsum, tsum);\n\tif (skb_ensure_writable(skb, csum_offset + sizeof(sum)) ||\n\t    skb_store_bits(skb, csum_offset, &sum, sizeof(sum)) < 0)\n\t\treturn -1;\n\n\treturn 0;\n}\n\nstruct nft_payload_set {\n\tenum nft_payload_bases\tbase:8;\n\tu8\t\t\toffset;\n\tu8\t\t\tlen;\n\tu8\t\t\tsreg;\n\tu8\t\t\tcsum_type;\n\tu8\t\t\tcsum_offset;\n\tu8\t\t\tcsum_flags;\n};\n\nstatic void nft_payload_set_eval(const struct nft_expr *expr,\n\t\t\t\t struct nft_regs *regs,\n\t\t\t\t const struct nft_pktinfo *pkt)\n{\n\tconst struct nft_payload_set *priv = nft_expr_priv(expr);\n\tstruct sk_buff *skb = pkt->skb;\n\tconst u32 *src = &regs->data[priv->sreg];\n\tint offset, csum_offset;\n\t__wsum fsum, tsum;\n\n\tswitch (priv->base) {\n\tcase NFT_PAYLOAD_LL_HEADER:\n\t\tif (!skb_mac_header_was_set(skb))\n\t\t\tgoto err;\n\t\toffset = skb_mac_header(skb) - skb->data;\n\t\tbreak;\n\tcase NFT_PAYLOAD_NETWORK_HEADER:\n\t\toffset = skb_network_offset(skb);\n\t\tbreak;\n\tcase NFT_PAYLOAD_TRANSPORT_HEADER:\n\t\tif (!(pkt->flags & NFT_PKTINFO_L4PROTO) || pkt->fragoff)\n\t\t\tgoto err;\n\t\toffset = nft_thoff(pkt);\n\t\tbreak;\n\tcase NFT_PAYLOAD_INNER_HEADER:\n\t\toffset = nft_payload_inner_offset(pkt);\n\t\tif (offset < 0)\n\t\t\tgoto err;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\tgoto err;\n\t}\n\n\tcsum_offset = offset + priv->csum_offset;\n\toffset += priv->offset;\n\n\tif ((priv->csum_type == NFT_PAYLOAD_CSUM_INET || priv->csum_flags) &&\n\t    ((priv->base != NFT_PAYLOAD_TRANSPORT_HEADER &&\n\t      priv->base != NFT_PAYLOAD_INNER_HEADER) ||\n\t     skb->ip_summed != CHECKSUM_PARTIAL)) {\n\t\tfsum = skb_checksum(skb, offset, priv->len, 0);\n\t\ttsum = csum_partial(src, priv->len, 0);\n\n\t\tif (priv->csum_type == NFT_PAYLOAD_CSUM_INET &&\n\t\t    nft_payload_csum_inet(skb, src, fsum, tsum, csum_offset))\n\t\t\tgoto err;\n\n\t\tif (priv->csum_flags &&\n\t\t    nft_payload_l4csum_update(pkt, skb, fsum, tsum) < 0)\n\t\t\tgoto err;\n\t}\n\n\tif (skb_ensure_writable(skb, max(offset + priv->len, 0)) ||\n\t    skb_store_bits(skb, offset, src, priv->len) < 0)\n\t\tgoto err;\n\n\tif (priv->csum_type == NFT_PAYLOAD_CSUM_SCTP &&\n\t    pkt->tprot == IPPROTO_SCTP &&\n\t    skb->ip_summed != CHECKSUM_PARTIAL) {\n\t\tif (pkt->fragoff == 0 &&\n\t\t    nft_payload_csum_sctp(skb, nft_thoff(pkt)))\n\t\t\tgoto err;\n\t}\n\n\treturn;\nerr:\n\tregs->verdict.code = NFT_BREAK;\n}\n\nstatic int nft_payload_set_init(const struct nft_ctx *ctx,\n\t\t\t\tconst struct nft_expr *expr,\n\t\t\t\tconst struct nlattr * const tb[])\n{\n\tstruct nft_payload_set *priv = nft_expr_priv(expr);\n\tu32 csum_offset, csum_type = NFT_PAYLOAD_CSUM_NONE;\n\tint err;\n\n\tpriv->base        = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_BASE]));\n\tpriv->offset      = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_OFFSET]));\n\tpriv->len         = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_LEN]));\n\n\tif (tb[NFTA_PAYLOAD_CSUM_TYPE])\n\t\tcsum_type = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_CSUM_TYPE]));\n\tif (tb[NFTA_PAYLOAD_CSUM_OFFSET]) {\n\t\terr = nft_parse_u32_check(tb[NFTA_PAYLOAD_CSUM_OFFSET], U8_MAX,\n\t\t\t\t\t  &csum_offset);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tpriv->csum_offset = csum_offset;\n\t}\n\tif (tb[NFTA_PAYLOAD_CSUM_FLAGS]) {\n\t\tu32 flags;\n\n\t\tflags = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_CSUM_FLAGS]));\n\t\tif (flags & ~NFT_PAYLOAD_L4CSUM_PSEUDOHDR)\n\t\t\treturn -EINVAL;\n\n\t\tpriv->csum_flags = flags;\n\t}\n\n\tswitch (csum_type) {\n\tcase NFT_PAYLOAD_CSUM_NONE:\n\tcase NFT_PAYLOAD_CSUM_INET:\n\t\tbreak;\n\tcase NFT_PAYLOAD_CSUM_SCTP:\n\t\tif (priv->base != NFT_PAYLOAD_TRANSPORT_HEADER)\n\t\t\treturn -EINVAL;\n\n\t\tif (priv->csum_offset != offsetof(struct sctphdr, checksum))\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\tpriv->csum_type = csum_type;\n\n\treturn nft_parse_register_load(tb[NFTA_PAYLOAD_SREG], &priv->sreg,\n\t\t\t\t       priv->len);\n}\n\nstatic int nft_payload_set_dump(struct sk_buff *skb,\n\t\t\t\tconst struct nft_expr *expr, bool reset)\n{\n\tconst struct nft_payload_set *priv = nft_expr_priv(expr);\n\n\tif (nft_dump_register(skb, NFTA_PAYLOAD_SREG, priv->sreg) ||\n\t    nla_put_be32(skb, NFTA_PAYLOAD_BASE, htonl(priv->base)) ||\n\t    nla_put_be32(skb, NFTA_PAYLOAD_OFFSET, htonl(priv->offset)) ||\n\t    nla_put_be32(skb, NFTA_PAYLOAD_LEN, htonl(priv->len)) ||\n\t    nla_put_be32(skb, NFTA_PAYLOAD_CSUM_TYPE, htonl(priv->csum_type)) ||\n\t    nla_put_be32(skb, NFTA_PAYLOAD_CSUM_OFFSET,\n\t\t\t htonl(priv->csum_offset)) ||\n\t    nla_put_be32(skb, NFTA_PAYLOAD_CSUM_FLAGS, htonl(priv->csum_flags)))\n\t\tgoto nla_put_failure;\n\treturn 0;\n\nnla_put_failure:\n\treturn -1;\n}\n\nstatic bool nft_payload_set_reduce(struct nft_regs_track *track,\n\t\t\t\t   const struct nft_expr *expr)\n{\n\tint i;\n\n\tfor (i = 0; i < NFT_REG32_NUM; i++) {\n\t\tif (!track->regs[i].selector)\n\t\t\tcontinue;\n\n\t\tif (track->regs[i].selector->ops != &nft_payload_ops &&\n\t\t    track->regs[i].selector->ops != &nft_payload_fast_ops)\n\t\t\tcontinue;\n\n\t\t__nft_reg_track_cancel(track, i);\n\t}\n\n\treturn false;\n}\n\nstatic const struct nft_expr_ops nft_payload_set_ops = {\n\t.type\t\t= &nft_payload_type,\n\t.size\t\t= NFT_EXPR_SIZE(sizeof(struct nft_payload_set)),\n\t.eval\t\t= nft_payload_set_eval,\n\t.init\t\t= nft_payload_set_init,\n\t.dump\t\t= nft_payload_set_dump,\n\t.reduce\t\t= nft_payload_set_reduce,\n};\n\nstatic const struct nft_expr_ops *\nnft_payload_select_ops(const struct nft_ctx *ctx,\n\t\t       const struct nlattr * const tb[])\n{\n\tenum nft_payload_bases base;\n\tunsigned int offset, len;\n\tint err;\n\n\tif (tb[NFTA_PAYLOAD_BASE] == NULL ||\n\t    tb[NFTA_PAYLOAD_OFFSET] == NULL ||\n\t    tb[NFTA_PAYLOAD_LEN] == NULL)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tbase = ntohl(nla_get_be32(tb[NFTA_PAYLOAD_BASE]));\n\tswitch (base) {\n\tcase NFT_PAYLOAD_LL_HEADER:\n\tcase NFT_PAYLOAD_NETWORK_HEADER:\n\tcase NFT_PAYLOAD_TRANSPORT_HEADER:\n\tcase NFT_PAYLOAD_INNER_HEADER:\n\t\tbreak;\n\tdefault:\n\t\treturn ERR_PTR(-EOPNOTSUPP);\n\t}\n\n\tif (tb[NFTA_PAYLOAD_SREG] != NULL) {\n\t\tif (tb[NFTA_PAYLOAD_DREG] != NULL)\n\t\t\treturn ERR_PTR(-EINVAL);\n\t\treturn &nft_payload_set_ops;\n\t}\n\n\tif (tb[NFTA_PAYLOAD_DREG] == NULL)\n\t\treturn ERR_PTR(-EINVAL);\n\n\terr = nft_parse_u32_check(tb[NFTA_PAYLOAD_OFFSET], U8_MAX, &offset);\n\tif (err < 0)\n\t\treturn ERR_PTR(err);\n\n\terr = nft_parse_u32_check(tb[NFTA_PAYLOAD_LEN], U8_MAX, &len);\n\tif (err < 0)\n\t\treturn ERR_PTR(err);\n\n\tif (len <= 4 && is_power_of_2(len) && IS_ALIGNED(offset, len) &&\n\t    base != NFT_PAYLOAD_LL_HEADER && base != NFT_PAYLOAD_INNER_HEADER)\n\t\treturn &nft_payload_fast_ops;\n\telse\n\t\treturn &nft_payload_ops;\n}\n\nstruct nft_expr_type nft_payload_type __read_mostly = {\n\t.name\t\t= \"payload\",\n\t.select_ops\t= nft_payload_select_ops,\n\t.inner_ops\t= &nft_payload_inner_ops,\n\t.policy\t\t= nft_payload_policy,\n\t.maxattr\t= NFTA_PAYLOAD_MAX,\n\t.owner\t\t= THIS_MODULE,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}