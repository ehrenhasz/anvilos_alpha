{
  "module_name": "nf_conntrack_expect.c",
  "hash_id": "05ae15dbbdc44ebb07bf98decfbed999dba4d33b854ad3031c99b80ad5078837",
  "original_prompt": "Ingested from linux-6.6.14/net/netfilter/nf_conntrack_expect.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/types.h>\n#include <linux/netfilter.h>\n#include <linux/skbuff.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/stddef.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/percpu.h>\n#include <linux/kernel.h>\n#include <linux/siphash.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <net/net_namespace.h>\n#include <net/netns/hash.h>\n\n#include <net/netfilter/nf_conntrack.h>\n#include <net/netfilter/nf_conntrack_core.h>\n#include <net/netfilter/nf_conntrack_ecache.h>\n#include <net/netfilter/nf_conntrack_expect.h>\n#include <net/netfilter/nf_conntrack_helper.h>\n#include <net/netfilter/nf_conntrack_l4proto.h>\n#include <net/netfilter/nf_conntrack_tuple.h>\n#include <net/netfilter/nf_conntrack_zones.h>\n\nunsigned int nf_ct_expect_hsize __read_mostly;\nEXPORT_SYMBOL_GPL(nf_ct_expect_hsize);\n\nstruct hlist_head *nf_ct_expect_hash __read_mostly;\nEXPORT_SYMBOL_GPL(nf_ct_expect_hash);\n\nunsigned int nf_ct_expect_max __read_mostly;\n\nstatic struct kmem_cache *nf_ct_expect_cachep __read_mostly;\nstatic siphash_aligned_key_t nf_ct_expect_hashrnd;\n\n \nvoid nf_ct_unlink_expect_report(struct nf_conntrack_expect *exp,\n\t\t\t\tu32 portid, int report)\n{\n\tstruct nf_conn_help *master_help = nfct_help(exp->master);\n\tstruct net *net = nf_ct_exp_net(exp);\n\tstruct nf_conntrack_net *cnet;\n\n\tWARN_ON(!master_help);\n\tWARN_ON(timer_pending(&exp->timeout));\n\n\thlist_del_rcu(&exp->hnode);\n\n\tcnet = nf_ct_pernet(net);\n\tcnet->expect_count--;\n\n\thlist_del_rcu(&exp->lnode);\n\tmaster_help->expecting[exp->class]--;\n\n\tnf_ct_expect_event_report(IPEXP_DESTROY, exp, portid, report);\n\tnf_ct_expect_put(exp);\n\n\tNF_CT_STAT_INC(net, expect_delete);\n}\nEXPORT_SYMBOL_GPL(nf_ct_unlink_expect_report);\n\nstatic void nf_ct_expectation_timed_out(struct timer_list *t)\n{\n\tstruct nf_conntrack_expect *exp = from_timer(exp, t, timeout);\n\n\tspin_lock_bh(&nf_conntrack_expect_lock);\n\tnf_ct_unlink_expect(exp);\n\tspin_unlock_bh(&nf_conntrack_expect_lock);\n\tnf_ct_expect_put(exp);\n}\n\nstatic unsigned int nf_ct_expect_dst_hash(const struct net *n, const struct nf_conntrack_tuple *tuple)\n{\n\tstruct {\n\t\tunion nf_inet_addr dst_addr;\n\t\tu32 net_mix;\n\t\tu16 dport;\n\t\tu8 l3num;\n\t\tu8 protonum;\n\t} __aligned(SIPHASH_ALIGNMENT) combined;\n\tu32 hash;\n\n\tget_random_once(&nf_ct_expect_hashrnd, sizeof(nf_ct_expect_hashrnd));\n\n\tmemset(&combined, 0, sizeof(combined));\n\n\tcombined.dst_addr = tuple->dst.u3;\n\tcombined.net_mix = net_hash_mix(n);\n\tcombined.dport = (__force __u16)tuple->dst.u.all;\n\tcombined.l3num = tuple->src.l3num;\n\tcombined.protonum = tuple->dst.protonum;\n\n\thash = siphash(&combined, sizeof(combined), &nf_ct_expect_hashrnd);\n\n\treturn reciprocal_scale(hash, nf_ct_expect_hsize);\n}\n\nstatic bool\nnf_ct_exp_equal(const struct nf_conntrack_tuple *tuple,\n\t\tconst struct nf_conntrack_expect *i,\n\t\tconst struct nf_conntrack_zone *zone,\n\t\tconst struct net *net)\n{\n\treturn nf_ct_tuple_mask_cmp(tuple, &i->tuple, &i->mask) &&\n\t       net_eq(net, nf_ct_net(i->master)) &&\n\t       nf_ct_zone_equal_any(i->master, zone);\n}\n\nbool nf_ct_remove_expect(struct nf_conntrack_expect *exp)\n{\n\tif (del_timer(&exp->timeout)) {\n\t\tnf_ct_unlink_expect(exp);\n\t\tnf_ct_expect_put(exp);\n\t\treturn true;\n\t}\n\treturn false;\n}\nEXPORT_SYMBOL_GPL(nf_ct_remove_expect);\n\nstruct nf_conntrack_expect *\n__nf_ct_expect_find(struct net *net,\n\t\t    const struct nf_conntrack_zone *zone,\n\t\t    const struct nf_conntrack_tuple *tuple)\n{\n\tstruct nf_conntrack_net *cnet = nf_ct_pernet(net);\n\tstruct nf_conntrack_expect *i;\n\tunsigned int h;\n\n\tif (!cnet->expect_count)\n\t\treturn NULL;\n\n\th = nf_ct_expect_dst_hash(net, tuple);\n\thlist_for_each_entry_rcu(i, &nf_ct_expect_hash[h], hnode) {\n\t\tif (nf_ct_exp_equal(tuple, i, zone, net))\n\t\t\treturn i;\n\t}\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(__nf_ct_expect_find);\n\n \nstruct nf_conntrack_expect *\nnf_ct_expect_find_get(struct net *net,\n\t\t      const struct nf_conntrack_zone *zone,\n\t\t      const struct nf_conntrack_tuple *tuple)\n{\n\tstruct nf_conntrack_expect *i;\n\n\trcu_read_lock();\n\ti = __nf_ct_expect_find(net, zone, tuple);\n\tif (i && !refcount_inc_not_zero(&i->use))\n\t\ti = NULL;\n\trcu_read_unlock();\n\n\treturn i;\n}\nEXPORT_SYMBOL_GPL(nf_ct_expect_find_get);\n\n \nstruct nf_conntrack_expect *\nnf_ct_find_expectation(struct net *net,\n\t\t       const struct nf_conntrack_zone *zone,\n\t\t       const struct nf_conntrack_tuple *tuple, bool unlink)\n{\n\tstruct nf_conntrack_net *cnet = nf_ct_pernet(net);\n\tstruct nf_conntrack_expect *i, *exp = NULL;\n\tunsigned int h;\n\n\tif (!cnet->expect_count)\n\t\treturn NULL;\n\n\th = nf_ct_expect_dst_hash(net, tuple);\n\thlist_for_each_entry(i, &nf_ct_expect_hash[h], hnode) {\n\t\tif (!(i->flags & NF_CT_EXPECT_INACTIVE) &&\n\t\t    nf_ct_exp_equal(tuple, i, zone, net)) {\n\t\t\texp = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!exp)\n\t\treturn NULL;\n\n\t \n\tif (!nf_ct_is_confirmed(exp->master))\n\t\treturn NULL;\n\n\t \n\tif (unlikely(nf_ct_is_dying(exp->master) ||\n\t\t     !refcount_inc_not_zero(&exp->master->ct_general.use)))\n\t\treturn NULL;\n\n\tif (exp->flags & NF_CT_EXPECT_PERMANENT || !unlink) {\n\t\trefcount_inc(&exp->use);\n\t\treturn exp;\n\t} else if (del_timer(&exp->timeout)) {\n\t\tnf_ct_unlink_expect(exp);\n\t\treturn exp;\n\t}\n\t \n\tnf_ct_put(exp->master);\n\n\treturn NULL;\n}\n\n \nvoid nf_ct_remove_expectations(struct nf_conn *ct)\n{\n\tstruct nf_conn_help *help = nfct_help(ct);\n\tstruct nf_conntrack_expect *exp;\n\tstruct hlist_node *next;\n\n\t \n\tif (!help)\n\t\treturn;\n\n\tspin_lock_bh(&nf_conntrack_expect_lock);\n\thlist_for_each_entry_safe(exp, next, &help->expectations, lnode) {\n\t\tnf_ct_remove_expect(exp);\n\t}\n\tspin_unlock_bh(&nf_conntrack_expect_lock);\n}\nEXPORT_SYMBOL_GPL(nf_ct_remove_expectations);\n\n \nstatic inline int expect_clash(const struct nf_conntrack_expect *a,\n\t\t\t       const struct nf_conntrack_expect *b)\n{\n\t \n\tstruct nf_conntrack_tuple_mask intersect_mask;\n\tint count;\n\n\tintersect_mask.src.u.all = a->mask.src.u.all & b->mask.src.u.all;\n\n\tfor (count = 0; count < NF_CT_TUPLE_L3SIZE; count++){\n\t\tintersect_mask.src.u3.all[count] =\n\t\t\ta->mask.src.u3.all[count] & b->mask.src.u3.all[count];\n\t}\n\n\treturn nf_ct_tuple_mask_cmp(&a->tuple, &b->tuple, &intersect_mask) &&\n\t       net_eq(nf_ct_net(a->master), nf_ct_net(b->master)) &&\n\t       nf_ct_zone_equal_any(a->master, nf_ct_zone(b->master));\n}\n\nstatic inline int expect_matches(const struct nf_conntrack_expect *a,\n\t\t\t\t const struct nf_conntrack_expect *b)\n{\n\treturn nf_ct_tuple_equal(&a->tuple, &b->tuple) &&\n\t       nf_ct_tuple_mask_equal(&a->mask, &b->mask) &&\n\t       net_eq(nf_ct_net(a->master), nf_ct_net(b->master)) &&\n\t       nf_ct_zone_equal_any(a->master, nf_ct_zone(b->master));\n}\n\nstatic bool master_matches(const struct nf_conntrack_expect *a,\n\t\t\t   const struct nf_conntrack_expect *b,\n\t\t\t   unsigned int flags)\n{\n\tif (flags & NF_CT_EXP_F_SKIP_MASTER)\n\t\treturn true;\n\n\treturn a->master == b->master;\n}\n\n \nvoid nf_ct_unexpect_related(struct nf_conntrack_expect *exp)\n{\n\tspin_lock_bh(&nf_conntrack_expect_lock);\n\tnf_ct_remove_expect(exp);\n\tspin_unlock_bh(&nf_conntrack_expect_lock);\n}\nEXPORT_SYMBOL_GPL(nf_ct_unexpect_related);\n\n \nstruct nf_conntrack_expect *nf_ct_expect_alloc(struct nf_conn *me)\n{\n\tstruct nf_conntrack_expect *new;\n\n\tnew = kmem_cache_alloc(nf_ct_expect_cachep, GFP_ATOMIC);\n\tif (!new)\n\t\treturn NULL;\n\n\tnew->master = me;\n\trefcount_set(&new->use, 1);\n\treturn new;\n}\nEXPORT_SYMBOL_GPL(nf_ct_expect_alloc);\n\nvoid nf_ct_expect_init(struct nf_conntrack_expect *exp, unsigned int class,\n\t\t       u_int8_t family,\n\t\t       const union nf_inet_addr *saddr,\n\t\t       const union nf_inet_addr *daddr,\n\t\t       u_int8_t proto, const __be16 *src, const __be16 *dst)\n{\n\tint len;\n\n\tif (family == AF_INET)\n\t\tlen = 4;\n\telse\n\t\tlen = 16;\n\n\texp->flags = 0;\n\texp->class = class;\n\texp->expectfn = NULL;\n\texp->helper = NULL;\n\texp->tuple.src.l3num = family;\n\texp->tuple.dst.protonum = proto;\n\n\tif (saddr) {\n\t\tmemcpy(&exp->tuple.src.u3, saddr, len);\n\t\tif (sizeof(exp->tuple.src.u3) > len)\n\t\t\t \n\t\t\tmemset((void *)&exp->tuple.src.u3 + len, 0x00,\n\t\t\t       sizeof(exp->tuple.src.u3) - len);\n\t\tmemset(&exp->mask.src.u3, 0xFF, len);\n\t\tif (sizeof(exp->mask.src.u3) > len)\n\t\t\tmemset((void *)&exp->mask.src.u3 + len, 0x00,\n\t\t\t       sizeof(exp->mask.src.u3) - len);\n\t} else {\n\t\tmemset(&exp->tuple.src.u3, 0x00, sizeof(exp->tuple.src.u3));\n\t\tmemset(&exp->mask.src.u3, 0x00, sizeof(exp->mask.src.u3));\n\t}\n\n\tif (src) {\n\t\texp->tuple.src.u.all = *src;\n\t\texp->mask.src.u.all = htons(0xFFFF);\n\t} else {\n\t\texp->tuple.src.u.all = 0;\n\t\texp->mask.src.u.all = 0;\n\t}\n\n\tmemcpy(&exp->tuple.dst.u3, daddr, len);\n\tif (sizeof(exp->tuple.dst.u3) > len)\n\t\t \n\t\tmemset((void *)&exp->tuple.dst.u3 + len, 0x00,\n\t\t       sizeof(exp->tuple.dst.u3) - len);\n\n\texp->tuple.dst.u.all = *dst;\n\n#if IS_ENABLED(CONFIG_NF_NAT)\n\tmemset(&exp->saved_addr, 0, sizeof(exp->saved_addr));\n\tmemset(&exp->saved_proto, 0, sizeof(exp->saved_proto));\n#endif\n}\nEXPORT_SYMBOL_GPL(nf_ct_expect_init);\n\nstatic void nf_ct_expect_free_rcu(struct rcu_head *head)\n{\n\tstruct nf_conntrack_expect *exp;\n\n\texp = container_of(head, struct nf_conntrack_expect, rcu);\n\tkmem_cache_free(nf_ct_expect_cachep, exp);\n}\n\nvoid nf_ct_expect_put(struct nf_conntrack_expect *exp)\n{\n\tif (refcount_dec_and_test(&exp->use))\n\t\tcall_rcu(&exp->rcu, nf_ct_expect_free_rcu);\n}\nEXPORT_SYMBOL_GPL(nf_ct_expect_put);\n\nstatic void nf_ct_expect_insert(struct nf_conntrack_expect *exp)\n{\n\tstruct nf_conntrack_net *cnet;\n\tstruct nf_conn_help *master_help = nfct_help(exp->master);\n\tstruct nf_conntrack_helper *helper;\n\tstruct net *net = nf_ct_exp_net(exp);\n\tunsigned int h = nf_ct_expect_dst_hash(net, &exp->tuple);\n\n\t \n\trefcount_add(2, &exp->use);\n\n\ttimer_setup(&exp->timeout, nf_ct_expectation_timed_out, 0);\n\thelper = rcu_dereference_protected(master_help->helper,\n\t\t\t\t\t   lockdep_is_held(&nf_conntrack_expect_lock));\n\tif (helper) {\n\t\texp->timeout.expires = jiffies +\n\t\t\thelper->expect_policy[exp->class].timeout * HZ;\n\t}\n\tadd_timer(&exp->timeout);\n\n\thlist_add_head_rcu(&exp->lnode, &master_help->expectations);\n\tmaster_help->expecting[exp->class]++;\n\n\thlist_add_head_rcu(&exp->hnode, &nf_ct_expect_hash[h]);\n\tcnet = nf_ct_pernet(net);\n\tcnet->expect_count++;\n\n\tNF_CT_STAT_INC(net, expect_create);\n}\n\n \nstatic void evict_oldest_expect(struct nf_conn *master,\n\t\t\t\tstruct nf_conntrack_expect *new)\n{\n\tstruct nf_conn_help *master_help = nfct_help(master);\n\tstruct nf_conntrack_expect *exp, *last = NULL;\n\n\thlist_for_each_entry(exp, &master_help->expectations, lnode) {\n\t\tif (exp->class == new->class)\n\t\t\tlast = exp;\n\t}\n\n\tif (last)\n\t\tnf_ct_remove_expect(last);\n}\n\nstatic inline int __nf_ct_expect_check(struct nf_conntrack_expect *expect,\n\t\t\t\t       unsigned int flags)\n{\n\tconst struct nf_conntrack_expect_policy *p;\n\tstruct nf_conntrack_expect *i;\n\tstruct nf_conntrack_net *cnet;\n\tstruct nf_conn *master = expect->master;\n\tstruct nf_conn_help *master_help = nfct_help(master);\n\tstruct nf_conntrack_helper *helper;\n\tstruct net *net = nf_ct_exp_net(expect);\n\tstruct hlist_node *next;\n\tunsigned int h;\n\tint ret = 0;\n\n\tif (!master_help) {\n\t\tret = -ESHUTDOWN;\n\t\tgoto out;\n\t}\n\th = nf_ct_expect_dst_hash(net, &expect->tuple);\n\thlist_for_each_entry_safe(i, next, &nf_ct_expect_hash[h], hnode) {\n\t\tif (master_matches(i, expect, flags) &&\n\t\t    expect_matches(i, expect)) {\n\t\t\tif (i->class != expect->class ||\n\t\t\t    i->master != expect->master)\n\t\t\t\treturn -EALREADY;\n\n\t\t\tif (nf_ct_remove_expect(i))\n\t\t\t\tbreak;\n\t\t} else if (expect_clash(i, expect)) {\n\t\t\tret = -EBUSY;\n\t\t\tgoto out;\n\t\t}\n\t}\n\t \n\thelper = rcu_dereference_protected(master_help->helper,\n\t\t\t\t\t   lockdep_is_held(&nf_conntrack_expect_lock));\n\tif (helper) {\n\t\tp = &helper->expect_policy[expect->class];\n\t\tif (p->max_expected &&\n\t\t    master_help->expecting[expect->class] >= p->max_expected) {\n\t\t\tevict_oldest_expect(master, expect);\n\t\t\tif (master_help->expecting[expect->class]\n\t\t\t\t\t\t>= p->max_expected) {\n\t\t\t\tret = -EMFILE;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tcnet = nf_ct_pernet(net);\n\tif (cnet->expect_count >= nf_ct_expect_max) {\n\t\tnet_warn_ratelimited(\"nf_conntrack: expectation table full\\n\");\n\t\tret = -EMFILE;\n\t}\nout:\n\treturn ret;\n}\n\nint nf_ct_expect_related_report(struct nf_conntrack_expect *expect,\n\t\t\t\tu32 portid, int report, unsigned int flags)\n{\n\tint ret;\n\n\tspin_lock_bh(&nf_conntrack_expect_lock);\n\tret = __nf_ct_expect_check(expect, flags);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tnf_ct_expect_insert(expect);\n\n\tspin_unlock_bh(&nf_conntrack_expect_lock);\n\tnf_ct_expect_event_report(IPEXP_NEW, expect, portid, report);\n\treturn 0;\nout:\n\tspin_unlock_bh(&nf_conntrack_expect_lock);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(nf_ct_expect_related_report);\n\nvoid nf_ct_expect_iterate_destroy(bool (*iter)(struct nf_conntrack_expect *e, void *data),\n\t\t\t\t  void *data)\n{\n\tstruct nf_conntrack_expect *exp;\n\tconst struct hlist_node *next;\n\tunsigned int i;\n\n\tspin_lock_bh(&nf_conntrack_expect_lock);\n\n\tfor (i = 0; i < nf_ct_expect_hsize; i++) {\n\t\thlist_for_each_entry_safe(exp, next,\n\t\t\t\t\t  &nf_ct_expect_hash[i],\n\t\t\t\t\t  hnode) {\n\t\t\tif (iter(exp, data) && del_timer(&exp->timeout)) {\n\t\t\t\tnf_ct_unlink_expect(exp);\n\t\t\t\tnf_ct_expect_put(exp);\n\t\t\t}\n\t\t}\n\t}\n\n\tspin_unlock_bh(&nf_conntrack_expect_lock);\n}\nEXPORT_SYMBOL_GPL(nf_ct_expect_iterate_destroy);\n\nvoid nf_ct_expect_iterate_net(struct net *net,\n\t\t\t      bool (*iter)(struct nf_conntrack_expect *e, void *data),\n\t\t\t      void *data,\n\t\t\t      u32 portid, int report)\n{\n\tstruct nf_conntrack_expect *exp;\n\tconst struct hlist_node *next;\n\tunsigned int i;\n\n\tspin_lock_bh(&nf_conntrack_expect_lock);\n\n\tfor (i = 0; i < nf_ct_expect_hsize; i++) {\n\t\thlist_for_each_entry_safe(exp, next,\n\t\t\t\t\t  &nf_ct_expect_hash[i],\n\t\t\t\t\t  hnode) {\n\n\t\t\tif (!net_eq(nf_ct_exp_net(exp), net))\n\t\t\t\tcontinue;\n\n\t\t\tif (iter(exp, data) && del_timer(&exp->timeout)) {\n\t\t\t\tnf_ct_unlink_expect_report(exp, portid, report);\n\t\t\t\tnf_ct_expect_put(exp);\n\t\t\t}\n\t\t}\n\t}\n\n\tspin_unlock_bh(&nf_conntrack_expect_lock);\n}\nEXPORT_SYMBOL_GPL(nf_ct_expect_iterate_net);\n\n#ifdef CONFIG_NF_CONNTRACK_PROCFS\nstruct ct_expect_iter_state {\n\tstruct seq_net_private p;\n\tunsigned int bucket;\n};\n\nstatic struct hlist_node *ct_expect_get_first(struct seq_file *seq)\n{\n\tstruct ct_expect_iter_state *st = seq->private;\n\tstruct hlist_node *n;\n\n\tfor (st->bucket = 0; st->bucket < nf_ct_expect_hsize; st->bucket++) {\n\t\tn = rcu_dereference(hlist_first_rcu(&nf_ct_expect_hash[st->bucket]));\n\t\tif (n)\n\t\t\treturn n;\n\t}\n\treturn NULL;\n}\n\nstatic struct hlist_node *ct_expect_get_next(struct seq_file *seq,\n\t\t\t\t\t     struct hlist_node *head)\n{\n\tstruct ct_expect_iter_state *st = seq->private;\n\n\thead = rcu_dereference(hlist_next_rcu(head));\n\twhile (head == NULL) {\n\t\tif (++st->bucket >= nf_ct_expect_hsize)\n\t\t\treturn NULL;\n\t\thead = rcu_dereference(hlist_first_rcu(&nf_ct_expect_hash[st->bucket]));\n\t}\n\treturn head;\n}\n\nstatic struct hlist_node *ct_expect_get_idx(struct seq_file *seq, loff_t pos)\n{\n\tstruct hlist_node *head = ct_expect_get_first(seq);\n\n\tif (head)\n\t\twhile (pos && (head = ct_expect_get_next(seq, head)))\n\t\t\tpos--;\n\treturn pos ? NULL : head;\n}\n\nstatic void *exp_seq_start(struct seq_file *seq, loff_t *pos)\n\t__acquires(RCU)\n{\n\trcu_read_lock();\n\treturn ct_expect_get_idx(seq, *pos);\n}\n\nstatic void *exp_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\t(*pos)++;\n\treturn ct_expect_get_next(seq, v);\n}\n\nstatic void exp_seq_stop(struct seq_file *seq, void *v)\n\t__releases(RCU)\n{\n\trcu_read_unlock();\n}\n\nstatic int exp_seq_show(struct seq_file *s, void *v)\n{\n\tstruct nf_conntrack_expect *expect;\n\tstruct nf_conntrack_helper *helper;\n\tstruct hlist_node *n = v;\n\tchar *delim = \"\";\n\n\texpect = hlist_entry(n, struct nf_conntrack_expect, hnode);\n\n\tif (expect->timeout.function)\n\t\tseq_printf(s, \"%ld \", timer_pending(&expect->timeout)\n\t\t\t   ? (long)(expect->timeout.expires - jiffies)/HZ : 0);\n\telse\n\t\tseq_puts(s, \"- \");\n\tseq_printf(s, \"l3proto = %u proto=%u \",\n\t\t   expect->tuple.src.l3num,\n\t\t   expect->tuple.dst.protonum);\n\tprint_tuple(s, &expect->tuple,\n\t\t    nf_ct_l4proto_find(expect->tuple.dst.protonum));\n\n\tif (expect->flags & NF_CT_EXPECT_PERMANENT) {\n\t\tseq_puts(s, \"PERMANENT\");\n\t\tdelim = \",\";\n\t}\n\tif (expect->flags & NF_CT_EXPECT_INACTIVE) {\n\t\tseq_printf(s, \"%sINACTIVE\", delim);\n\t\tdelim = \",\";\n\t}\n\tif (expect->flags & NF_CT_EXPECT_USERSPACE)\n\t\tseq_printf(s, \"%sUSERSPACE\", delim);\n\n\thelper = rcu_dereference(nfct_help(expect->master)->helper);\n\tif (helper) {\n\t\tseq_printf(s, \"%s%s\", expect->flags ? \" \" : \"\", helper->name);\n\t\tif (helper->expect_policy[expect->class].name[0])\n\t\t\tseq_printf(s, \"/%s\",\n\t\t\t\t   helper->expect_policy[expect->class].name);\n\t}\n\n\tseq_putc(s, '\\n');\n\n\treturn 0;\n}\n\nstatic const struct seq_operations exp_seq_ops = {\n\t.start = exp_seq_start,\n\t.next = exp_seq_next,\n\t.stop = exp_seq_stop,\n\t.show = exp_seq_show\n};\n#endif  \n\nstatic int exp_proc_init(struct net *net)\n{\n#ifdef CONFIG_NF_CONNTRACK_PROCFS\n\tstruct proc_dir_entry *proc;\n\tkuid_t root_uid;\n\tkgid_t root_gid;\n\n\tproc = proc_create_net(\"nf_conntrack_expect\", 0440, net->proc_net,\n\t\t\t&exp_seq_ops, sizeof(struct ct_expect_iter_state));\n\tif (!proc)\n\t\treturn -ENOMEM;\n\n\troot_uid = make_kuid(net->user_ns, 0);\n\troot_gid = make_kgid(net->user_ns, 0);\n\tif (uid_valid(root_uid) && gid_valid(root_gid))\n\t\tproc_set_user(proc, root_uid, root_gid);\n#endif  \n\treturn 0;\n}\n\nstatic void exp_proc_remove(struct net *net)\n{\n#ifdef CONFIG_NF_CONNTRACK_PROCFS\n\tremove_proc_entry(\"nf_conntrack_expect\", net->proc_net);\n#endif  \n}\n\nmodule_param_named(expect_hashsize, nf_ct_expect_hsize, uint, 0400);\n\nint nf_conntrack_expect_pernet_init(struct net *net)\n{\n\treturn exp_proc_init(net);\n}\n\nvoid nf_conntrack_expect_pernet_fini(struct net *net)\n{\n\texp_proc_remove(net);\n}\n\nint nf_conntrack_expect_init(void)\n{\n\tif (!nf_ct_expect_hsize) {\n\t\tnf_ct_expect_hsize = nf_conntrack_htable_size / 256;\n\t\tif (!nf_ct_expect_hsize)\n\t\t\tnf_ct_expect_hsize = 1;\n\t}\n\tnf_ct_expect_max = nf_ct_expect_hsize * 4;\n\tnf_ct_expect_cachep = kmem_cache_create(\"nf_conntrack_expect\",\n\t\t\t\tsizeof(struct nf_conntrack_expect),\n\t\t\t\t0, 0, NULL);\n\tif (!nf_ct_expect_cachep)\n\t\treturn -ENOMEM;\n\n\tnf_ct_expect_hash = nf_ct_alloc_hashtable(&nf_ct_expect_hsize, 0);\n\tif (!nf_ct_expect_hash) {\n\t\tkmem_cache_destroy(nf_ct_expect_cachep);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nvoid nf_conntrack_expect_fini(void)\n{\n\trcu_barrier();  \n\tkmem_cache_destroy(nf_ct_expect_cachep);\n\tkvfree(nf_ct_expect_hash);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}