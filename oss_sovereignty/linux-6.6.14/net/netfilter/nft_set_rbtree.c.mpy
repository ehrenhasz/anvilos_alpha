{
  "module_name": "nft_set_rbtree.c",
  "hash_id": "bc92d005371b27ca08153ed7462c06baace0e4b4b435aa1080eb61d7ae149015",
  "original_prompt": "Ingested from linux-6.6.14/net/netfilter/nft_set_rbtree.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/list.h>\n#include <linux/rbtree.h>\n#include <linux/netlink.h>\n#include <linux/netfilter.h>\n#include <linux/netfilter/nf_tables.h>\n#include <net/netfilter/nf_tables_core.h>\n\nstruct nft_rbtree {\n\tstruct rb_root\t\troot;\n\trwlock_t\t\tlock;\n\tseqcount_rwlock_t\tcount;\n\tstruct delayed_work\tgc_work;\n};\n\nstruct nft_rbtree_elem {\n\tstruct rb_node\t\tnode;\n\tstruct nft_set_ext\text;\n};\n\nstatic bool nft_rbtree_interval_end(const struct nft_rbtree_elem *rbe)\n{\n\treturn nft_set_ext_exists(&rbe->ext, NFT_SET_EXT_FLAGS) &&\n\t       (*nft_set_ext_flags(&rbe->ext) & NFT_SET_ELEM_INTERVAL_END);\n}\n\nstatic bool nft_rbtree_interval_start(const struct nft_rbtree_elem *rbe)\n{\n\treturn !nft_rbtree_interval_end(rbe);\n}\n\nstatic int nft_rbtree_cmp(const struct nft_set *set,\n\t\t\t  const struct nft_rbtree_elem *e1,\n\t\t\t  const struct nft_rbtree_elem *e2)\n{\n\treturn memcmp(nft_set_ext_key(&e1->ext), nft_set_ext_key(&e2->ext),\n\t\t      set->klen);\n}\n\nstatic bool nft_rbtree_elem_expired(const struct nft_rbtree_elem *rbe)\n{\n\treturn nft_set_elem_expired(&rbe->ext) ||\n\t       nft_set_elem_is_dead(&rbe->ext);\n}\n\nstatic bool __nft_rbtree_lookup(const struct net *net, const struct nft_set *set,\n\t\t\t\tconst u32 *key, const struct nft_set_ext **ext,\n\t\t\t\tunsigned int seq)\n{\n\tstruct nft_rbtree *priv = nft_set_priv(set);\n\tconst struct nft_rbtree_elem *rbe, *interval = NULL;\n\tu8 genmask = nft_genmask_cur(net);\n\tconst struct rb_node *parent;\n\tint d;\n\n\tparent = rcu_dereference_raw(priv->root.rb_node);\n\twhile (parent != NULL) {\n\t\tif (read_seqcount_retry(&priv->count, seq))\n\t\t\treturn false;\n\n\t\trbe = rb_entry(parent, struct nft_rbtree_elem, node);\n\n\t\td = memcmp(nft_set_ext_key(&rbe->ext), key, set->klen);\n\t\tif (d < 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_left);\n\t\t\tif (interval &&\n\t\t\t    !nft_rbtree_cmp(set, rbe, interval) &&\n\t\t\t    nft_rbtree_interval_end(rbe) &&\n\t\t\t    nft_rbtree_interval_start(interval))\n\t\t\t\tcontinue;\n\t\t\tinterval = rbe;\n\t\t} else if (d > 0)\n\t\t\tparent = rcu_dereference_raw(parent->rb_right);\n\t\telse {\n\t\t\tif (!nft_set_elem_active(&rbe->ext, genmask)) {\n\t\t\t\tparent = rcu_dereference_raw(parent->rb_left);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (nft_rbtree_elem_expired(rbe))\n\t\t\t\treturn false;\n\n\t\t\tif (nft_rbtree_interval_end(rbe)) {\n\t\t\t\tif (nft_set_is_anonymous(set))\n\t\t\t\t\treturn false;\n\t\t\t\tparent = rcu_dereference_raw(parent->rb_left);\n\t\t\t\tinterval = NULL;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t*ext = &rbe->ext;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tif (set->flags & NFT_SET_INTERVAL && interval != NULL &&\n\t    nft_set_elem_active(&interval->ext, genmask) &&\n\t    !nft_rbtree_elem_expired(interval) &&\n\t    nft_rbtree_interval_start(interval)) {\n\t\t*ext = &interval->ext;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nINDIRECT_CALLABLE_SCOPE\nbool nft_rbtree_lookup(const struct net *net, const struct nft_set *set,\n\t\t       const u32 *key, const struct nft_set_ext **ext)\n{\n\tstruct nft_rbtree *priv = nft_set_priv(set);\n\tunsigned int seq = read_seqcount_begin(&priv->count);\n\tbool ret;\n\n\tret = __nft_rbtree_lookup(net, set, key, ext, seq);\n\tif (ret || !read_seqcount_retry(&priv->count, seq))\n\t\treturn ret;\n\n\tread_lock_bh(&priv->lock);\n\tseq = read_seqcount_begin(&priv->count);\n\tret = __nft_rbtree_lookup(net, set, key, ext, seq);\n\tread_unlock_bh(&priv->lock);\n\n\treturn ret;\n}\n\nstatic bool __nft_rbtree_get(const struct net *net, const struct nft_set *set,\n\t\t\t     const u32 *key, struct nft_rbtree_elem **elem,\n\t\t\t     unsigned int seq, unsigned int flags, u8 genmask)\n{\n\tstruct nft_rbtree_elem *rbe, *interval = NULL;\n\tstruct nft_rbtree *priv = nft_set_priv(set);\n\tconst struct rb_node *parent;\n\tconst void *this;\n\tint d;\n\n\tparent = rcu_dereference_raw(priv->root.rb_node);\n\twhile (parent != NULL) {\n\t\tif (read_seqcount_retry(&priv->count, seq))\n\t\t\treturn false;\n\n\t\trbe = rb_entry(parent, struct nft_rbtree_elem, node);\n\n\t\tthis = nft_set_ext_key(&rbe->ext);\n\t\td = memcmp(this, key, set->klen);\n\t\tif (d < 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_left);\n\t\t\tif (!(flags & NFT_SET_ELEM_INTERVAL_END))\n\t\t\t\tinterval = rbe;\n\t\t} else if (d > 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_right);\n\t\t\tif (flags & NFT_SET_ELEM_INTERVAL_END)\n\t\t\t\tinterval = rbe;\n\t\t} else {\n\t\t\tif (!nft_set_elem_active(&rbe->ext, genmask)) {\n\t\t\t\tparent = rcu_dereference_raw(parent->rb_left);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (nft_set_elem_expired(&rbe->ext))\n\t\t\t\treturn false;\n\n\t\t\tif (!nft_set_ext_exists(&rbe->ext, NFT_SET_EXT_FLAGS) ||\n\t\t\t    (*nft_set_ext_flags(&rbe->ext) & NFT_SET_ELEM_INTERVAL_END) ==\n\t\t\t    (flags & NFT_SET_ELEM_INTERVAL_END)) {\n\t\t\t\t*elem = rbe;\n\t\t\t\treturn true;\n\t\t\t}\n\n\t\t\tif (nft_rbtree_interval_end(rbe))\n\t\t\t\tinterval = NULL;\n\n\t\t\tparent = rcu_dereference_raw(parent->rb_left);\n\t\t}\n\t}\n\n\tif (set->flags & NFT_SET_INTERVAL && interval != NULL &&\n\t    nft_set_elem_active(&interval->ext, genmask) &&\n\t    !nft_set_elem_expired(&interval->ext) &&\n\t    ((!nft_rbtree_interval_end(interval) &&\n\t      !(flags & NFT_SET_ELEM_INTERVAL_END)) ||\n\t     (nft_rbtree_interval_end(interval) &&\n\t      (flags & NFT_SET_ELEM_INTERVAL_END)))) {\n\t\t*elem = interval;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void *nft_rbtree_get(const struct net *net, const struct nft_set *set,\n\t\t\t    const struct nft_set_elem *elem, unsigned int flags)\n{\n\tstruct nft_rbtree *priv = nft_set_priv(set);\n\tunsigned int seq = read_seqcount_begin(&priv->count);\n\tstruct nft_rbtree_elem *rbe = ERR_PTR(-ENOENT);\n\tconst u32 *key = (const u32 *)&elem->key.val;\n\tu8 genmask = nft_genmask_cur(net);\n\tbool ret;\n\n\tret = __nft_rbtree_get(net, set, key, &rbe, seq, flags, genmask);\n\tif (ret || !read_seqcount_retry(&priv->count, seq))\n\t\treturn rbe;\n\n\tread_lock_bh(&priv->lock);\n\tseq = read_seqcount_begin(&priv->count);\n\tret = __nft_rbtree_get(net, set, key, &rbe, seq, flags, genmask);\n\tif (!ret)\n\t\trbe = ERR_PTR(-ENOENT);\n\tread_unlock_bh(&priv->lock);\n\n\treturn rbe;\n}\n\nstatic void nft_rbtree_gc_remove(struct net *net, struct nft_set *set,\n\t\t\t\t struct nft_rbtree *priv,\n\t\t\t\t struct nft_rbtree_elem *rbe)\n{\n\tstruct nft_set_elem elem = {\n\t\t.priv\t= rbe,\n\t};\n\n\tnft_setelem_data_deactivate(net, set, &elem);\n\trb_erase(&rbe->node, &priv->root);\n}\n\nstatic const struct nft_rbtree_elem *\nnft_rbtree_gc_elem(const struct nft_set *__set, struct nft_rbtree *priv,\n\t\t   struct nft_rbtree_elem *rbe, u8 genmask)\n{\n\tstruct nft_set *set = (struct nft_set *)__set;\n\tstruct rb_node *prev = rb_prev(&rbe->node);\n\tstruct net *net = read_pnet(&set->net);\n\tstruct nft_rbtree_elem *rbe_prev;\n\tstruct nft_trans_gc *gc;\n\n\tgc = nft_trans_gc_alloc(set, 0, GFP_ATOMIC);\n\tif (!gc)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t \n\twhile (prev) {\n\t\trbe_prev = rb_entry(prev, struct nft_rbtree_elem, node);\n\t\tif (nft_rbtree_interval_end(rbe_prev) &&\n\t\t    nft_set_elem_active(&rbe_prev->ext, genmask))\n\t\t\tbreak;\n\n\t\tprev = rb_prev(prev);\n\t}\n\n\trbe_prev = NULL;\n\tif (prev) {\n\t\trbe_prev = rb_entry(prev, struct nft_rbtree_elem, node);\n\t\tnft_rbtree_gc_remove(net, set, priv, rbe_prev);\n\n\t\t \n\t\tgc = nft_trans_gc_queue_sync(gc, GFP_ATOMIC);\n\t\tif (WARN_ON_ONCE(!gc))\n\t\t\treturn ERR_PTR(-ENOMEM);\n\n\t\tnft_trans_gc_elem_add(gc, rbe_prev);\n\t}\n\n\tnft_rbtree_gc_remove(net, set, priv, rbe);\n\tgc = nft_trans_gc_queue_sync(gc, GFP_ATOMIC);\n\tif (WARN_ON_ONCE(!gc))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tnft_trans_gc_elem_add(gc, rbe);\n\n\tnft_trans_gc_queue_sync_done(gc);\n\n\treturn rbe_prev;\n}\n\nstatic bool nft_rbtree_update_first(const struct nft_set *set,\n\t\t\t\t    struct nft_rbtree_elem *rbe,\n\t\t\t\t    struct rb_node *first)\n{\n\tstruct nft_rbtree_elem *first_elem;\n\n\tfirst_elem = rb_entry(first, struct nft_rbtree_elem, node);\n\t \n\tif (nft_rbtree_cmp(set, rbe, first_elem) < 0)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int __nft_rbtree_insert(const struct net *net, const struct nft_set *set,\n\t\t\t       struct nft_rbtree_elem *new,\n\t\t\t       struct nft_set_ext **ext)\n{\n\tstruct nft_rbtree_elem *rbe, *rbe_le = NULL, *rbe_ge = NULL;\n\tstruct rb_node *node, *next, *parent, **p, *first = NULL;\n\tstruct nft_rbtree *priv = nft_set_priv(set);\n\tu8 cur_genmask = nft_genmask_cur(net);\n\tu8 genmask = nft_genmask_next(net);\n\tint d;\n\n\t \n\tparent = NULL;\n\tp = &priv->root.rb_node;\n\twhile (*p != NULL) {\n\t\tparent = *p;\n\t\trbe = rb_entry(parent, struct nft_rbtree_elem, node);\n\t\td = nft_rbtree_cmp(set, rbe, new);\n\n\t\tif (d < 0) {\n\t\t\tp = &parent->rb_left;\n\t\t} else if (d > 0) {\n\t\t\tif (!first ||\n\t\t\t    nft_rbtree_update_first(set, rbe, first))\n\t\t\t\tfirst = &rbe->node;\n\n\t\t\tp = &parent->rb_right;\n\t\t} else {\n\t\t\tif (nft_rbtree_interval_end(rbe))\n\t\t\t\tp = &parent->rb_left;\n\t\t\telse\n\t\t\t\tp = &parent->rb_right;\n\t\t}\n\t}\n\n\tif (!first)\n\t\tfirst = rb_first(&priv->root);\n\n\t \n\tfor (node = first; node != NULL; node = next) {\n\t\tnext = rb_next(node);\n\n\t\trbe = rb_entry(node, struct nft_rbtree_elem, node);\n\n\t\tif (!nft_set_elem_active(&rbe->ext, genmask))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (nft_set_elem_expired(&rbe->ext) &&\n\t\t    nft_set_elem_active(&rbe->ext, cur_genmask)) {\n\t\t\tconst struct nft_rbtree_elem *removed_end;\n\n\t\t\tremoved_end = nft_rbtree_gc_elem(set, priv, rbe, genmask);\n\t\t\tif (IS_ERR(removed_end))\n\t\t\t\treturn PTR_ERR(removed_end);\n\n\t\t\tif (removed_end == rbe_le || removed_end == rbe_ge)\n\t\t\t\treturn -EAGAIN;\n\n\t\t\tcontinue;\n\t\t}\n\n\t\td = nft_rbtree_cmp(set, rbe, new);\n\t\tif (d == 0) {\n\t\t\t \n\t\t\tif (nft_rbtree_interval_end(rbe)) {\n\t\t\t\trbe_le = rbe;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (!rbe_ge) {\n\t\t\t\trbe_ge = rbe;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (nft_rbtree_cmp(set, rbe_ge, new) != 0) {\n\t\t\t\trbe_ge = rbe;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tif ((nft_rbtree_interval_start(new) &&\n\t\t\t     nft_rbtree_interval_start(rbe_ge)) ||\n\t\t\t    (nft_rbtree_interval_end(new) &&\n\t\t\t     nft_rbtree_interval_end(rbe_ge))) {\n\t\t\t\trbe_ge = rbe;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else if (d > 0) {\n\t\t\t \n\t\t\trbe_ge = rbe;\n\t\t\tcontinue;\n\t\t} else if (d < 0) {\n\t\t\t \n\t\t\trbe_le = rbe;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (rbe_ge && !nft_rbtree_cmp(set, new, rbe_ge) &&\n\t    nft_rbtree_interval_start(rbe_ge) == nft_rbtree_interval_start(new)) {\n\t\t*ext = &rbe_ge->ext;\n\t\treturn -EEXIST;\n\t}\n\n\t \n\tif (rbe_le && !nft_rbtree_cmp(set, new, rbe_le) &&\n\t    nft_rbtree_interval_end(rbe_le) == nft_rbtree_interval_end(new)) {\n\t\t*ext = &rbe_le->ext;\n\t\treturn -EEXIST;\n\t}\n\n\t \n\tif (!nft_set_is_anonymous(set) && rbe_le &&\n\t    nft_rbtree_interval_start(rbe_le) && nft_rbtree_interval_start(new))\n\t\treturn -ENOTEMPTY;\n\n\t \n\tif (rbe_le &&\n\t    nft_rbtree_interval_end(rbe_le) && nft_rbtree_interval_end(new))\n\t\treturn -ENOTEMPTY;\n\n\t \n\tif (rbe_ge &&\n\t    nft_rbtree_interval_end(rbe_ge) && nft_rbtree_interval_end(new))\n\t\treturn -ENOTEMPTY;\n\n\t \n\tparent = NULL;\n\tp = &priv->root.rb_node;\n\twhile (*p != NULL) {\n\t\tparent = *p;\n\t\trbe = rb_entry(parent, struct nft_rbtree_elem, node);\n\t\td = nft_rbtree_cmp(set, rbe, new);\n\n\t\tif (d < 0)\n\t\t\tp = &parent->rb_left;\n\t\telse if (d > 0)\n\t\t\tp = &parent->rb_right;\n\t\telse if (nft_rbtree_interval_end(rbe))\n\t\t\tp = &parent->rb_left;\n\t\telse\n\t\t\tp = &parent->rb_right;\n\t}\n\n\trb_link_node_rcu(&new->node, parent, p);\n\trb_insert_color(&new->node, &priv->root);\n\treturn 0;\n}\n\nstatic int nft_rbtree_insert(const struct net *net, const struct nft_set *set,\n\t\t\t     const struct nft_set_elem *elem,\n\t\t\t     struct nft_set_ext **ext)\n{\n\tstruct nft_rbtree *priv = nft_set_priv(set);\n\tstruct nft_rbtree_elem *rbe = elem->priv;\n\tint err;\n\n\tdo {\n\t\tif (fatal_signal_pending(current))\n\t\t\treturn -EINTR;\n\n\t\tcond_resched();\n\n\t\twrite_lock_bh(&priv->lock);\n\t\twrite_seqcount_begin(&priv->count);\n\t\terr = __nft_rbtree_insert(net, set, rbe, ext);\n\t\twrite_seqcount_end(&priv->count);\n\t\twrite_unlock_bh(&priv->lock);\n\t} while (err == -EAGAIN);\n\n\treturn err;\n}\n\nstatic void nft_rbtree_remove(const struct net *net,\n\t\t\t      const struct nft_set *set,\n\t\t\t      const struct nft_set_elem *elem)\n{\n\tstruct nft_rbtree *priv = nft_set_priv(set);\n\tstruct nft_rbtree_elem *rbe = elem->priv;\n\n\twrite_lock_bh(&priv->lock);\n\twrite_seqcount_begin(&priv->count);\n\trb_erase(&rbe->node, &priv->root);\n\twrite_seqcount_end(&priv->count);\n\twrite_unlock_bh(&priv->lock);\n}\n\nstatic void nft_rbtree_activate(const struct net *net,\n\t\t\t\tconst struct nft_set *set,\n\t\t\t\tconst struct nft_set_elem *elem)\n{\n\tstruct nft_rbtree_elem *rbe = elem->priv;\n\n\tnft_set_elem_change_active(net, set, &rbe->ext);\n}\n\nstatic bool nft_rbtree_flush(const struct net *net,\n\t\t\t     const struct nft_set *set, void *priv)\n{\n\tstruct nft_rbtree_elem *rbe = priv;\n\n\tnft_set_elem_change_active(net, set, &rbe->ext);\n\n\treturn true;\n}\n\nstatic void *nft_rbtree_deactivate(const struct net *net,\n\t\t\t\t   const struct nft_set *set,\n\t\t\t\t   const struct nft_set_elem *elem)\n{\n\tconst struct nft_rbtree *priv = nft_set_priv(set);\n\tconst struct rb_node *parent = priv->root.rb_node;\n\tstruct nft_rbtree_elem *rbe, *this = elem->priv;\n\tu8 genmask = nft_genmask_next(net);\n\tint d;\n\n\twhile (parent != NULL) {\n\t\trbe = rb_entry(parent, struct nft_rbtree_elem, node);\n\n\t\td = memcmp(nft_set_ext_key(&rbe->ext), &elem->key.val,\n\t\t\t\t\t   set->klen);\n\t\tif (d < 0)\n\t\t\tparent = parent->rb_left;\n\t\telse if (d > 0)\n\t\t\tparent = parent->rb_right;\n\t\telse {\n\t\t\tif (nft_rbtree_interval_end(rbe) &&\n\t\t\t    nft_rbtree_interval_start(this)) {\n\t\t\t\tparent = parent->rb_left;\n\t\t\t\tcontinue;\n\t\t\t} else if (nft_rbtree_interval_start(rbe) &&\n\t\t\t\t   nft_rbtree_interval_end(this)) {\n\t\t\t\tparent = parent->rb_right;\n\t\t\t\tcontinue;\n\t\t\t} else if (nft_set_elem_expired(&rbe->ext)) {\n\t\t\t\tbreak;\n\t\t\t} else if (!nft_set_elem_active(&rbe->ext, genmask)) {\n\t\t\t\tparent = parent->rb_left;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tnft_rbtree_flush(net, set, rbe);\n\t\t\treturn rbe;\n\t\t}\n\t}\n\treturn NULL;\n}\n\nstatic void nft_rbtree_walk(const struct nft_ctx *ctx,\n\t\t\t    struct nft_set *set,\n\t\t\t    struct nft_set_iter *iter)\n{\n\tstruct nft_rbtree *priv = nft_set_priv(set);\n\tstruct nft_rbtree_elem *rbe;\n\tstruct nft_set_elem elem;\n\tstruct rb_node *node;\n\n\tread_lock_bh(&priv->lock);\n\tfor (node = rb_first(&priv->root); node != NULL; node = rb_next(node)) {\n\t\trbe = rb_entry(node, struct nft_rbtree_elem, node);\n\n\t\tif (iter->count < iter->skip)\n\t\t\tgoto cont;\n\t\tif (!nft_set_elem_active(&rbe->ext, iter->genmask))\n\t\t\tgoto cont;\n\n\t\telem.priv = rbe;\n\n\t\titer->err = iter->fn(ctx, set, iter, &elem);\n\t\tif (iter->err < 0) {\n\t\t\tread_unlock_bh(&priv->lock);\n\t\t\treturn;\n\t\t}\ncont:\n\t\titer->count++;\n\t}\n\tread_unlock_bh(&priv->lock);\n}\n\nstatic void nft_rbtree_gc(struct work_struct *work)\n{\n\tstruct nft_rbtree_elem *rbe, *rbe_end = NULL;\n\tstruct nftables_pernet *nft_net;\n\tstruct nft_rbtree *priv;\n\tstruct nft_trans_gc *gc;\n\tstruct rb_node *node;\n\tstruct nft_set *set;\n\tunsigned int gc_seq;\n\tstruct net *net;\n\n\tpriv = container_of(work, struct nft_rbtree, gc_work.work);\n\tset  = nft_set_container_of(priv);\n\tnet  = read_pnet(&set->net);\n\tnft_net = nft_pernet(net);\n\tgc_seq  = READ_ONCE(nft_net->gc_seq);\n\n\tif (nft_set_gc_is_pending(set))\n\t\tgoto done;\n\n\tgc = nft_trans_gc_alloc(set, gc_seq, GFP_KERNEL);\n\tif (!gc)\n\t\tgoto done;\n\n\tread_lock_bh(&priv->lock);\n\tfor (node = rb_first(&priv->root); node != NULL; node = rb_next(node)) {\n\n\t\t \n\t\tif (READ_ONCE(nft_net->gc_seq) != gc_seq) {\n\t\t\tnft_trans_gc_destroy(gc);\n\t\t\tgc = NULL;\n\t\t\tgoto try_later;\n\t\t}\n\n\t\trbe = rb_entry(node, struct nft_rbtree_elem, node);\n\n\t\tif (nft_set_elem_is_dead(&rbe->ext))\n\t\t\tgoto dead_elem;\n\n\t\t \n\t\tif (nft_rbtree_interval_end(rbe)) {\n\t\t\trbe_end = rbe;\n\t\t\tcontinue;\n\t\t}\n\t\tif (!nft_set_elem_expired(&rbe->ext))\n\t\t\tcontinue;\n\n\t\tnft_set_elem_dead(&rbe->ext);\n\n\t\tif (!rbe_end)\n\t\t\tcontinue;\n\n\t\tnft_set_elem_dead(&rbe_end->ext);\n\n\t\tgc = nft_trans_gc_queue_async(gc, gc_seq, GFP_ATOMIC);\n\t\tif (!gc)\n\t\t\tgoto try_later;\n\n\t\tnft_trans_gc_elem_add(gc, rbe_end);\n\t\trbe_end = NULL;\ndead_elem:\n\t\tgc = nft_trans_gc_queue_async(gc, gc_seq, GFP_ATOMIC);\n\t\tif (!gc)\n\t\t\tgoto try_later;\n\n\t\tnft_trans_gc_elem_add(gc, rbe);\n\t}\n\n\tgc = nft_trans_gc_catchall_async(gc, gc_seq);\n\ntry_later:\n\tread_unlock_bh(&priv->lock);\n\n\tif (gc)\n\t\tnft_trans_gc_queue_async_done(gc);\ndone:\n\tqueue_delayed_work(system_power_efficient_wq, &priv->gc_work,\n\t\t\t   nft_set_gc_interval(set));\n}\n\nstatic u64 nft_rbtree_privsize(const struct nlattr * const nla[],\n\t\t\t       const struct nft_set_desc *desc)\n{\n\treturn sizeof(struct nft_rbtree);\n}\n\nstatic int nft_rbtree_init(const struct nft_set *set,\n\t\t\t   const struct nft_set_desc *desc,\n\t\t\t   const struct nlattr * const nla[])\n{\n\tstruct nft_rbtree *priv = nft_set_priv(set);\n\n\trwlock_init(&priv->lock);\n\tseqcount_rwlock_init(&priv->count, &priv->lock);\n\tpriv->root = RB_ROOT;\n\n\tINIT_DEFERRABLE_WORK(&priv->gc_work, nft_rbtree_gc);\n\tif (set->flags & NFT_SET_TIMEOUT)\n\t\tqueue_delayed_work(system_power_efficient_wq, &priv->gc_work,\n\t\t\t\t   nft_set_gc_interval(set));\n\n\treturn 0;\n}\n\nstatic void nft_rbtree_destroy(const struct nft_ctx *ctx,\n\t\t\t       const struct nft_set *set)\n{\n\tstruct nft_rbtree *priv = nft_set_priv(set);\n\tstruct nft_rbtree_elem *rbe;\n\tstruct rb_node *node;\n\n\tcancel_delayed_work_sync(&priv->gc_work);\n\trcu_barrier();\n\twhile ((node = priv->root.rb_node) != NULL) {\n\t\trb_erase(node, &priv->root);\n\t\trbe = rb_entry(node, struct nft_rbtree_elem, node);\n\t\tnf_tables_set_elem_destroy(ctx, set, rbe);\n\t}\n}\n\nstatic bool nft_rbtree_estimate(const struct nft_set_desc *desc, u32 features,\n\t\t\t\tstruct nft_set_estimate *est)\n{\n\tif (desc->field_count > 1)\n\t\treturn false;\n\n\tif (desc->size)\n\t\test->size = sizeof(struct nft_rbtree) +\n\t\t\t    desc->size * sizeof(struct nft_rbtree_elem);\n\telse\n\t\test->size = ~0;\n\n\test->lookup = NFT_SET_CLASS_O_LOG_N;\n\test->space  = NFT_SET_CLASS_O_N;\n\n\treturn true;\n}\n\nconst struct nft_set_type nft_set_rbtree_type = {\n\t.features\t= NFT_SET_INTERVAL | NFT_SET_MAP | NFT_SET_OBJECT | NFT_SET_TIMEOUT,\n\t.ops\t\t= {\n\t\t.privsize\t= nft_rbtree_privsize,\n\t\t.elemsize\t= offsetof(struct nft_rbtree_elem, ext),\n\t\t.estimate\t= nft_rbtree_estimate,\n\t\t.init\t\t= nft_rbtree_init,\n\t\t.destroy\t= nft_rbtree_destroy,\n\t\t.insert\t\t= nft_rbtree_insert,\n\t\t.remove\t\t= nft_rbtree_remove,\n\t\t.deactivate\t= nft_rbtree_deactivate,\n\t\t.flush\t\t= nft_rbtree_flush,\n\t\t.activate\t= nft_rbtree_activate,\n\t\t.lookup\t\t= nft_rbtree_lookup,\n\t\t.walk\t\t= nft_rbtree_walk,\n\t\t.get\t\t= nft_rbtree_get,\n\t},\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}