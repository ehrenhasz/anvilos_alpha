{
  "module_name": "x_tables.c",
  "hash_id": "e5e915aad6daaaff625286f22d93bc96777f971141c00a5548b332628953869b",
  "original_prompt": "Ingested from linux-6.6.14/net/netfilter/x_tables.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/socket.h>\n#include <linux/net.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/string.h>\n#include <linux/vmalloc.h>\n#include <linux/mutex.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/audit.h>\n#include <linux/user_namespace.h>\n#include <net/net_namespace.h>\n#include <net/netns/generic.h>\n\n#include <linux/netfilter/x_tables.h>\n#include <linux/netfilter_arp.h>\n#include <linux/netfilter_ipv4/ip_tables.h>\n#include <linux/netfilter_ipv6/ip6_tables.h>\n#include <linux/netfilter_arp/arp_tables.h>\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Harald Welte <laforge@netfilter.org>\");\nMODULE_DESCRIPTION(\"{ip,ip6,arp,eb}_tables backend module\");\n\n#define XT_PCPU_BLOCK_SIZE 4096\n#define XT_MAX_TABLE_SIZE\t(512 * 1024 * 1024)\n\nstruct xt_template {\n\tstruct list_head list;\n\n\t \n\tint (*table_init)(struct net *net);\n\n\tstruct module *me;\n\n\t \n\tchar name[XT_TABLE_MAXNAMELEN];\n};\n\nstatic struct list_head xt_templates[NFPROTO_NUMPROTO];\n\nstruct xt_pernet {\n\tstruct list_head tables[NFPROTO_NUMPROTO];\n};\n\nstruct compat_delta {\n\tunsigned int offset;  \n\tint delta;  \n};\n\nstruct xt_af {\n\tstruct mutex mutex;\n\tstruct list_head match;\n\tstruct list_head target;\n#ifdef CONFIG_NETFILTER_XTABLES_COMPAT\n\tstruct mutex compat_mutex;\n\tstruct compat_delta *compat_tab;\n\tunsigned int number;  \n\tunsigned int cur;  \n#endif\n};\n\nstatic unsigned int xt_pernet_id __read_mostly;\nstatic struct xt_af *xt __read_mostly;\n\nstatic const char *const xt_prefix[NFPROTO_NUMPROTO] = {\n\t[NFPROTO_UNSPEC] = \"x\",\n\t[NFPROTO_IPV4]   = \"ip\",\n\t[NFPROTO_ARP]    = \"arp\",\n\t[NFPROTO_BRIDGE] = \"eb\",\n\t[NFPROTO_IPV6]   = \"ip6\",\n};\n\n \nint xt_register_target(struct xt_target *target)\n{\n\tu_int8_t af = target->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_add(&target->list, &xt[af].target);\n\tmutex_unlock(&xt[af].mutex);\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_register_target);\n\nvoid\nxt_unregister_target(struct xt_target *target)\n{\n\tu_int8_t af = target->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_del(&target->list);\n\tmutex_unlock(&xt[af].mutex);\n}\nEXPORT_SYMBOL(xt_unregister_target);\n\nint\nxt_register_targets(struct xt_target *target, unsigned int n)\n{\n\tunsigned int i;\n\tint err = 0;\n\n\tfor (i = 0; i < n; i++) {\n\t\terr = xt_register_target(&target[i]);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\treturn err;\n\nerr:\n\tif (i > 0)\n\t\txt_unregister_targets(target, i);\n\treturn err;\n}\nEXPORT_SYMBOL(xt_register_targets);\n\nvoid\nxt_unregister_targets(struct xt_target *target, unsigned int n)\n{\n\twhile (n-- > 0)\n\t\txt_unregister_target(&target[n]);\n}\nEXPORT_SYMBOL(xt_unregister_targets);\n\nint xt_register_match(struct xt_match *match)\n{\n\tu_int8_t af = match->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_add(&match->list, &xt[af].match);\n\tmutex_unlock(&xt[af].mutex);\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_register_match);\n\nvoid\nxt_unregister_match(struct xt_match *match)\n{\n\tu_int8_t af = match->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_del(&match->list);\n\tmutex_unlock(&xt[af].mutex);\n}\nEXPORT_SYMBOL(xt_unregister_match);\n\nint\nxt_register_matches(struct xt_match *match, unsigned int n)\n{\n\tunsigned int i;\n\tint err = 0;\n\n\tfor (i = 0; i < n; i++) {\n\t\terr = xt_register_match(&match[i]);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\treturn err;\n\nerr:\n\tif (i > 0)\n\t\txt_unregister_matches(match, i);\n\treturn err;\n}\nEXPORT_SYMBOL(xt_register_matches);\n\nvoid\nxt_unregister_matches(struct xt_match *match, unsigned int n)\n{\n\twhile (n-- > 0)\n\t\txt_unregister_match(&match[n]);\n}\nEXPORT_SYMBOL(xt_unregister_matches);\n\n\n \n\n \nstruct xt_match *xt_find_match(u8 af, const char *name, u8 revision)\n{\n\tstruct xt_match *m;\n\tint err = -ENOENT;\n\n\tif (strnlen(name, XT_EXTENSION_MAXNAMELEN) == XT_EXTENSION_MAXNAMELEN)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(m, &xt[af].match, list) {\n\t\tif (strcmp(m->name, name) == 0) {\n\t\t\tif (m->revision == revision) {\n\t\t\t\tif (try_module_get(m->me)) {\n\t\t\t\t\tmutex_unlock(&xt[af].mutex);\n\t\t\t\t\treturn m;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\terr = -EPROTOTYPE;  \n\t\t}\n\t}\n\tmutex_unlock(&xt[af].mutex);\n\n\tif (af != NFPROTO_UNSPEC)\n\t\t \n\t\treturn xt_find_match(NFPROTO_UNSPEC, name, revision);\n\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL(xt_find_match);\n\nstruct xt_match *\nxt_request_find_match(uint8_t nfproto, const char *name, uint8_t revision)\n{\n\tstruct xt_match *match;\n\n\tif (strnlen(name, XT_EXTENSION_MAXNAMELEN) == XT_EXTENSION_MAXNAMELEN)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tmatch = xt_find_match(nfproto, name, revision);\n\tif (IS_ERR(match)) {\n\t\trequest_module(\"%st_%s\", xt_prefix[nfproto], name);\n\t\tmatch = xt_find_match(nfproto, name, revision);\n\t}\n\n\treturn match;\n}\nEXPORT_SYMBOL_GPL(xt_request_find_match);\n\n \nstatic struct xt_target *xt_find_target(u8 af, const char *name, u8 revision)\n{\n\tstruct xt_target *t;\n\tint err = -ENOENT;\n\n\tif (strnlen(name, XT_EXTENSION_MAXNAMELEN) == XT_EXTENSION_MAXNAMELEN)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(t, &xt[af].target, list) {\n\t\tif (strcmp(t->name, name) == 0) {\n\t\t\tif (t->revision == revision) {\n\t\t\t\tif (try_module_get(t->me)) {\n\t\t\t\t\tmutex_unlock(&xt[af].mutex);\n\t\t\t\t\treturn t;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\terr = -EPROTOTYPE;  \n\t\t}\n\t}\n\tmutex_unlock(&xt[af].mutex);\n\n\tif (af != NFPROTO_UNSPEC)\n\t\t \n\t\treturn xt_find_target(NFPROTO_UNSPEC, name, revision);\n\n\treturn ERR_PTR(err);\n}\n\nstruct xt_target *xt_request_find_target(u8 af, const char *name, u8 revision)\n{\n\tstruct xt_target *target;\n\n\tif (strnlen(name, XT_EXTENSION_MAXNAMELEN) == XT_EXTENSION_MAXNAMELEN)\n\t\treturn ERR_PTR(-EINVAL);\n\n\ttarget = xt_find_target(af, name, revision);\n\tif (IS_ERR(target)) {\n\t\trequest_module(\"%st_%s\", xt_prefix[af], name);\n\t\ttarget = xt_find_target(af, name, revision);\n\t}\n\n\treturn target;\n}\nEXPORT_SYMBOL_GPL(xt_request_find_target);\n\n\nstatic int xt_obj_to_user(u16 __user *psize, u16 size,\n\t\t\t  void __user *pname, const char *name,\n\t\t\t  u8 __user *prev, u8 rev)\n{\n\tif (put_user(size, psize))\n\t\treturn -EFAULT;\n\tif (copy_to_user(pname, name, strlen(name) + 1))\n\t\treturn -EFAULT;\n\tif (put_user(rev, prev))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\n#define XT_OBJ_TO_USER(U, K, TYPE, C_SIZE)\t\t\t\t\\\n\txt_obj_to_user(&U->u.TYPE##_size, C_SIZE ? : K->u.TYPE##_size,\t\\\n\t\t       U->u.user.name, K->u.kernel.TYPE->name,\t\t\\\n\t\t       &U->u.user.revision, K->u.kernel.TYPE->revision)\n\nint xt_data_to_user(void __user *dst, const void *src,\n\t\t    int usersize, int size, int aligned_size)\n{\n\tusersize = usersize ? : size;\n\tif (copy_to_user(dst, src, usersize))\n\t\treturn -EFAULT;\n\tif (usersize != aligned_size &&\n\t    clear_user(dst + usersize, aligned_size - usersize))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_data_to_user);\n\n#define XT_DATA_TO_USER(U, K, TYPE)\t\t\t\t\t\\\n\txt_data_to_user(U->data, K->data,\t\t\t\t\\\n\t\t\tK->u.kernel.TYPE->usersize,\t\t\t\\\n\t\t\tK->u.kernel.TYPE->TYPE##size,\t\t\t\\\n\t\t\tXT_ALIGN(K->u.kernel.TYPE->TYPE##size))\n\nint xt_match_to_user(const struct xt_entry_match *m,\n\t\t     struct xt_entry_match __user *u)\n{\n\treturn XT_OBJ_TO_USER(u, m, match, 0) ||\n\t       XT_DATA_TO_USER(u, m, match);\n}\nEXPORT_SYMBOL_GPL(xt_match_to_user);\n\nint xt_target_to_user(const struct xt_entry_target *t,\n\t\t      struct xt_entry_target __user *u)\n{\n\treturn XT_OBJ_TO_USER(u, t, target, 0) ||\n\t       XT_DATA_TO_USER(u, t, target);\n}\nEXPORT_SYMBOL_GPL(xt_target_to_user);\n\nstatic int match_revfn(u8 af, const char *name, u8 revision, int *bestp)\n{\n\tconst struct xt_match *m;\n\tint have_rev = 0;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(m, &xt[af].match, list) {\n\t\tif (strcmp(m->name, name) == 0) {\n\t\t\tif (m->revision > *bestp)\n\t\t\t\t*bestp = m->revision;\n\t\t\tif (m->revision == revision)\n\t\t\t\thave_rev = 1;\n\t\t}\n\t}\n\tmutex_unlock(&xt[af].mutex);\n\n\tif (af != NFPROTO_UNSPEC && !have_rev)\n\t\treturn match_revfn(NFPROTO_UNSPEC, name, revision, bestp);\n\n\treturn have_rev;\n}\n\nstatic int target_revfn(u8 af, const char *name, u8 revision, int *bestp)\n{\n\tconst struct xt_target *t;\n\tint have_rev = 0;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(t, &xt[af].target, list) {\n\t\tif (strcmp(t->name, name) == 0) {\n\t\t\tif (t->revision > *bestp)\n\t\t\t\t*bestp = t->revision;\n\t\t\tif (t->revision == revision)\n\t\t\t\thave_rev = 1;\n\t\t}\n\t}\n\tmutex_unlock(&xt[af].mutex);\n\n\tif (af != NFPROTO_UNSPEC && !have_rev)\n\t\treturn target_revfn(NFPROTO_UNSPEC, name, revision, bestp);\n\n\treturn have_rev;\n}\n\n \nint xt_find_revision(u8 af, const char *name, u8 revision, int target,\n\t\t     int *err)\n{\n\tint have_rev, best = -1;\n\n\tif (target == 1)\n\t\thave_rev = target_revfn(af, name, revision, &best);\n\telse\n\t\thave_rev = match_revfn(af, name, revision, &best);\n\n\t \n\tif (best == -1) {\n\t\t*err = -ENOENT;\n\t\treturn 0;\n\t}\n\n\t*err = best;\n\tif (!have_rev)\n\t\t*err = -EPROTONOSUPPORT;\n\treturn 1;\n}\nEXPORT_SYMBOL_GPL(xt_find_revision);\n\nstatic char *\ntextify_hooks(char *buf, size_t size, unsigned int mask, uint8_t nfproto)\n{\n\tstatic const char *const inetbr_names[] = {\n\t\t\"PREROUTING\", \"INPUT\", \"FORWARD\",\n\t\t\"OUTPUT\", \"POSTROUTING\", \"BROUTING\",\n\t};\n\tstatic const char *const arp_names[] = {\n\t\t\"INPUT\", \"FORWARD\", \"OUTPUT\",\n\t};\n\tconst char *const *names;\n\tunsigned int i, max;\n\tchar *p = buf;\n\tbool np = false;\n\tint res;\n\n\tnames = (nfproto == NFPROTO_ARP) ? arp_names : inetbr_names;\n\tmax   = (nfproto == NFPROTO_ARP) ? ARRAY_SIZE(arp_names) :\n\t                                   ARRAY_SIZE(inetbr_names);\n\t*p = '\\0';\n\tfor (i = 0; i < max; ++i) {\n\t\tif (!(mask & (1 << i)))\n\t\t\tcontinue;\n\t\tres = snprintf(p, size, \"%s%s\", np ? \"/\" : \"\", names[i]);\n\t\tif (res > 0) {\n\t\t\tsize -= res;\n\t\t\tp += res;\n\t\t}\n\t\tnp = true;\n\t}\n\n\treturn buf;\n}\n\n \nint xt_check_proc_name(const char *name, unsigned int size)\n{\n\tif (name[0] == '\\0')\n\t\treturn -EINVAL;\n\n\tif (strnlen(name, size) == size)\n\t\treturn -ENAMETOOLONG;\n\n\tif (strcmp(name, \".\") == 0 ||\n\t    strcmp(name, \"..\") == 0 ||\n\t    strchr(name, '/'))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_check_proc_name);\n\nint xt_check_match(struct xt_mtchk_param *par,\n\t\t   unsigned int size, u16 proto, bool inv_proto)\n{\n\tint ret;\n\n\tif (XT_ALIGN(par->match->matchsize) != size &&\n\t    par->match->matchsize != -1) {\n\t\t \n\t\tpr_err_ratelimited(\"%s_tables: %s.%u match: invalid size %u (kernel) != (user) %u\\n\",\n\t\t\t\t   xt_prefix[par->family], par->match->name,\n\t\t\t\t   par->match->revision,\n\t\t\t\t   XT_ALIGN(par->match->matchsize), size);\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->table != NULL &&\n\t    strcmp(par->match->table, par->table) != 0) {\n\t\tpr_info_ratelimited(\"%s_tables: %s match: only valid in %s table, not %s\\n\",\n\t\t\t\t    xt_prefix[par->family], par->match->name,\n\t\t\t\t    par->match->table, par->table);\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->hooks && (par->hook_mask & ~par->match->hooks) != 0) {\n\t\tchar used[64], allow[64];\n\n\t\tpr_info_ratelimited(\"%s_tables: %s match: used from hooks %s, but only valid from %s\\n\",\n\t\t\t\t    xt_prefix[par->family], par->match->name,\n\t\t\t\t    textify_hooks(used, sizeof(used),\n\t\t\t\t\t\t  par->hook_mask, par->family),\n\t\t\t\t    textify_hooks(allow, sizeof(allow),\n\t\t\t\t\t\t  par->match->hooks,\n\t\t\t\t\t\t  par->family));\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->proto && (par->match->proto != proto || inv_proto)) {\n\t\tpr_info_ratelimited(\"%s_tables: %s match: only valid for protocol %u\\n\",\n\t\t\t\t    xt_prefix[par->family], par->match->name,\n\t\t\t\t    par->match->proto);\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->checkentry != NULL) {\n\t\tret = par->match->checkentry(par);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\telse if (ret > 0)\n\t\t\t \n\t\t\treturn -EIO;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_check_match);\n\n \nstatic int xt_check_entry_match(const char *match, const char *target,\n\t\t\t\tconst size_t alignment)\n{\n\tconst struct xt_entry_match *pos;\n\tint length = target - match;\n\n\tif (length == 0)  \n\t\treturn 0;\n\n\tpos = (struct xt_entry_match *)match;\n\tdo {\n\t\tif ((unsigned long)pos % alignment)\n\t\t\treturn -EINVAL;\n\n\t\tif (length < (int)sizeof(struct xt_entry_match))\n\t\t\treturn -EINVAL;\n\n\t\tif (pos->u.match_size < sizeof(struct xt_entry_match))\n\t\t\treturn -EINVAL;\n\n\t\tif (pos->u.match_size > length)\n\t\t\treturn -EINVAL;\n\n\t\tlength -= pos->u.match_size;\n\t\tpos = ((void *)((char *)(pos) + (pos)->u.match_size));\n\t} while (length > 0);\n\n\treturn 0;\n}\n\n \nint xt_check_table_hooks(const struct xt_table_info *info, unsigned int valid_hooks)\n{\n\tconst char *err = \"unsorted underflow\";\n\tunsigned int i, max_uflow, max_entry;\n\tbool check_hooks = false;\n\n\tBUILD_BUG_ON(ARRAY_SIZE(info->hook_entry) != ARRAY_SIZE(info->underflow));\n\n\tmax_entry = 0;\n\tmax_uflow = 0;\n\n\tfor (i = 0; i < ARRAY_SIZE(info->hook_entry); i++) {\n\t\tif (!(valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\n\t\tif (info->hook_entry[i] == 0xFFFFFFFF)\n\t\t\treturn -EINVAL;\n\t\tif (info->underflow[i] == 0xFFFFFFFF)\n\t\t\treturn -EINVAL;\n\n\t\tif (check_hooks) {\n\t\t\tif (max_uflow > info->underflow[i])\n\t\t\t\tgoto error;\n\n\t\t\tif (max_uflow == info->underflow[i]) {\n\t\t\t\terr = \"duplicate underflow\";\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tif (max_entry > info->hook_entry[i]) {\n\t\t\t\terr = \"unsorted entry\";\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tif (max_entry == info->hook_entry[i]) {\n\t\t\t\terr = \"duplicate entry\";\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t\tmax_entry = info->hook_entry[i];\n\t\tmax_uflow = info->underflow[i];\n\t\tcheck_hooks = true;\n\t}\n\n\treturn 0;\nerror:\n\tpr_err_ratelimited(\"%s at hook %d\\n\", err, i);\n\treturn -EINVAL;\n}\nEXPORT_SYMBOL(xt_check_table_hooks);\n\nstatic bool verdict_ok(int verdict)\n{\n\tif (verdict > 0)\n\t\treturn true;\n\n\tif (verdict < 0) {\n\t\tint v = -verdict - 1;\n\n\t\tif (verdict == XT_RETURN)\n\t\t\treturn true;\n\n\t\tswitch (v) {\n\t\tcase NF_ACCEPT: return true;\n\t\tcase NF_DROP: return true;\n\t\tcase NF_QUEUE: return true;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\treturn false;\n\t}\n\n\treturn false;\n}\n\nstatic bool error_tg_ok(unsigned int usersize, unsigned int kernsize,\n\t\t\tconst char *msg, unsigned int msglen)\n{\n\treturn usersize == kernsize && strnlen(msg, msglen) < msglen;\n}\n\n#ifdef CONFIG_NETFILTER_XTABLES_COMPAT\nint xt_compat_add_offset(u_int8_t af, unsigned int offset, int delta)\n{\n\tstruct xt_af *xp = &xt[af];\n\n\tWARN_ON(!mutex_is_locked(&xt[af].compat_mutex));\n\n\tif (WARN_ON(!xp->compat_tab))\n\t\treturn -ENOMEM;\n\n\tif (xp->cur >= xp->number)\n\t\treturn -EINVAL;\n\n\tif (xp->cur)\n\t\tdelta += xp->compat_tab[xp->cur - 1].delta;\n\txp->compat_tab[xp->cur].offset = offset;\n\txp->compat_tab[xp->cur].delta = delta;\n\txp->cur++;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_add_offset);\n\nvoid xt_compat_flush_offsets(u_int8_t af)\n{\n\tWARN_ON(!mutex_is_locked(&xt[af].compat_mutex));\n\n\tif (xt[af].compat_tab) {\n\t\tvfree(xt[af].compat_tab);\n\t\txt[af].compat_tab = NULL;\n\t\txt[af].number = 0;\n\t\txt[af].cur = 0;\n\t}\n}\nEXPORT_SYMBOL_GPL(xt_compat_flush_offsets);\n\nint xt_compat_calc_jump(u_int8_t af, unsigned int offset)\n{\n\tstruct compat_delta *tmp = xt[af].compat_tab;\n\tint mid, left = 0, right = xt[af].cur - 1;\n\n\twhile (left <= right) {\n\t\tmid = (left + right) >> 1;\n\t\tif (offset > tmp[mid].offset)\n\t\t\tleft = mid + 1;\n\t\telse if (offset < tmp[mid].offset)\n\t\t\tright = mid - 1;\n\t\telse\n\t\t\treturn mid ? tmp[mid - 1].delta : 0;\n\t}\n\treturn left ? tmp[left - 1].delta : 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_calc_jump);\n\nint xt_compat_init_offsets(u8 af, unsigned int number)\n{\n\tsize_t mem;\n\n\tWARN_ON(!mutex_is_locked(&xt[af].compat_mutex));\n\n\tif (!number || number > (INT_MAX / sizeof(struct compat_delta)))\n\t\treturn -EINVAL;\n\n\tif (WARN_ON(xt[af].compat_tab))\n\t\treturn -EINVAL;\n\n\tmem = sizeof(struct compat_delta) * number;\n\tif (mem > XT_MAX_TABLE_SIZE)\n\t\treturn -ENOMEM;\n\n\txt[af].compat_tab = vmalloc(mem);\n\tif (!xt[af].compat_tab)\n\t\treturn -ENOMEM;\n\n\txt[af].number = number;\n\txt[af].cur = 0;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_compat_init_offsets);\n\nint xt_compat_match_offset(const struct xt_match *match)\n{\n\tu_int16_t csize = match->compatsize ? : match->matchsize;\n\treturn XT_ALIGN(match->matchsize) - COMPAT_XT_ALIGN(csize);\n}\nEXPORT_SYMBOL_GPL(xt_compat_match_offset);\n\nvoid xt_compat_match_from_user(struct xt_entry_match *m, void **dstptr,\n\t\t\t       unsigned int *size)\n{\n\tconst struct xt_match *match = m->u.kernel.match;\n\tstruct compat_xt_entry_match *cm = (struct compat_xt_entry_match *)m;\n\tint off = xt_compat_match_offset(match);\n\tu_int16_t msize = cm->u.user.match_size;\n\tchar name[sizeof(m->u.user.name)];\n\n\tm = *dstptr;\n\tmemcpy(m, cm, sizeof(*cm));\n\tif (match->compat_from_user)\n\t\tmatch->compat_from_user(m->data, cm->data);\n\telse\n\t\tmemcpy(m->data, cm->data, msize - sizeof(*cm));\n\n\tmsize += off;\n\tm->u.user.match_size = msize;\n\tstrscpy(name, match->name, sizeof(name));\n\tmodule_put(match->me);\n\tstrscpy_pad(m->u.user.name, name, sizeof(m->u.user.name));\n\n\t*size += off;\n\t*dstptr += msize;\n}\nEXPORT_SYMBOL_GPL(xt_compat_match_from_user);\n\n#define COMPAT_XT_DATA_TO_USER(U, K, TYPE, C_SIZE)\t\t\t\\\n\txt_data_to_user(U->data, K->data,\t\t\t\t\\\n\t\t\tK->u.kernel.TYPE->usersize,\t\t\t\\\n\t\t\tC_SIZE,\t\t\t\t\t\t\\\n\t\t\tCOMPAT_XT_ALIGN(C_SIZE))\n\nint xt_compat_match_to_user(const struct xt_entry_match *m,\n\t\t\t    void __user **dstptr, unsigned int *size)\n{\n\tconst struct xt_match *match = m->u.kernel.match;\n\tstruct compat_xt_entry_match __user *cm = *dstptr;\n\tint off = xt_compat_match_offset(match);\n\tu_int16_t msize = m->u.user.match_size - off;\n\n\tif (XT_OBJ_TO_USER(cm, m, match, msize))\n\t\treturn -EFAULT;\n\n\tif (match->compat_to_user) {\n\t\tif (match->compat_to_user((void __user *)cm->data, m->data))\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tif (COMPAT_XT_DATA_TO_USER(cm, m, match, msize - sizeof(*cm)))\n\t\t\treturn -EFAULT;\n\t}\n\n\t*size -= off;\n\t*dstptr += msize;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_match_to_user);\n\n \nstruct compat_xt_standard_target {\n\tstruct compat_xt_entry_target t;\n\tcompat_uint_t verdict;\n};\n\nstruct compat_xt_error_target {\n\tstruct compat_xt_entry_target t;\n\tchar errorname[XT_FUNCTION_MAXNAMELEN];\n};\n\nint xt_compat_check_entry_offsets(const void *base, const char *elems,\n\t\t\t\t  unsigned int target_offset,\n\t\t\t\t  unsigned int next_offset)\n{\n\tlong size_of_base_struct = elems - (const char *)base;\n\tconst struct compat_xt_entry_target *t;\n\tconst char *e = base;\n\n\tif (target_offset < size_of_base_struct)\n\t\treturn -EINVAL;\n\n\tif (target_offset + sizeof(*t) > next_offset)\n\t\treturn -EINVAL;\n\n\tt = (void *)(e + target_offset);\n\tif (t->u.target_size < sizeof(*t))\n\t\treturn -EINVAL;\n\n\tif (target_offset + t->u.target_size > next_offset)\n\t\treturn -EINVAL;\n\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) == 0) {\n\t\tconst struct compat_xt_standard_target *st = (const void *)t;\n\n\t\tif (COMPAT_XT_ALIGN(target_offset + sizeof(*st)) != next_offset)\n\t\t\treturn -EINVAL;\n\n\t\tif (!verdict_ok(st->verdict))\n\t\t\treturn -EINVAL;\n\t} else if (strcmp(t->u.user.name, XT_ERROR_TARGET) == 0) {\n\t\tconst struct compat_xt_error_target *et = (const void *)t;\n\n\t\tif (!error_tg_ok(t->u.target_size, sizeof(*et),\n\t\t\t\t et->errorname, sizeof(et->errorname)))\n\t\t\treturn -EINVAL;\n\t}\n\n\t \n\tBUILD_BUG_ON(sizeof(struct compat_xt_entry_match) != sizeof(struct xt_entry_match));\n\n\treturn xt_check_entry_match(elems, base + target_offset,\n\t\t\t\t    __alignof__(struct compat_xt_entry_match));\n}\nEXPORT_SYMBOL(xt_compat_check_entry_offsets);\n#endif  \n\n \nint xt_check_entry_offsets(const void *base,\n\t\t\t   const char *elems,\n\t\t\t   unsigned int target_offset,\n\t\t\t   unsigned int next_offset)\n{\n\tlong size_of_base_struct = elems - (const char *)base;\n\tconst struct xt_entry_target *t;\n\tconst char *e = base;\n\n\t \n\tif (target_offset < size_of_base_struct)\n\t\treturn -EINVAL;\n\n\tif (target_offset + sizeof(*t) > next_offset)\n\t\treturn -EINVAL;\n\n\tt = (void *)(e + target_offset);\n\tif (t->u.target_size < sizeof(*t))\n\t\treturn -EINVAL;\n\n\tif (target_offset + t->u.target_size > next_offset)\n\t\treturn -EINVAL;\n\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) == 0) {\n\t\tconst struct xt_standard_target *st = (const void *)t;\n\n\t\tif (XT_ALIGN(target_offset + sizeof(*st)) != next_offset)\n\t\t\treturn -EINVAL;\n\n\t\tif (!verdict_ok(st->verdict))\n\t\t\treturn -EINVAL;\n\t} else if (strcmp(t->u.user.name, XT_ERROR_TARGET) == 0) {\n\t\tconst struct xt_error_target *et = (const void *)t;\n\n\t\tif (!error_tg_ok(t->u.target_size, sizeof(*et),\n\t\t\t\t et->errorname, sizeof(et->errorname)))\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn xt_check_entry_match(elems, base + target_offset,\n\t\t\t\t    __alignof__(struct xt_entry_match));\n}\nEXPORT_SYMBOL(xt_check_entry_offsets);\n\n \nunsigned int *xt_alloc_entry_offsets(unsigned int size)\n{\n\tif (size > XT_MAX_TABLE_SIZE / sizeof(unsigned int))\n\t\treturn NULL;\n\n\treturn kvcalloc(size, sizeof(unsigned int), GFP_KERNEL);\n\n}\nEXPORT_SYMBOL(xt_alloc_entry_offsets);\n\n \nbool xt_find_jump_offset(const unsigned int *offsets,\n\t\t\t unsigned int target, unsigned int size)\n{\n\tint m, low = 0, hi = size;\n\n\twhile (hi > low) {\n\t\tm = (low + hi) / 2u;\n\n\t\tif (offsets[m] > target)\n\t\t\thi = m;\n\t\telse if (offsets[m] < target)\n\t\t\tlow = m + 1;\n\t\telse\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\nEXPORT_SYMBOL(xt_find_jump_offset);\n\nint xt_check_target(struct xt_tgchk_param *par,\n\t\t    unsigned int size, u16 proto, bool inv_proto)\n{\n\tint ret;\n\n\tif (XT_ALIGN(par->target->targetsize) != size) {\n\t\tpr_err_ratelimited(\"%s_tables: %s.%u target: invalid size %u (kernel) != (user) %u\\n\",\n\t\t\t\t   xt_prefix[par->family], par->target->name,\n\t\t\t\t   par->target->revision,\n\t\t\t\t   XT_ALIGN(par->target->targetsize), size);\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->table != NULL &&\n\t    strcmp(par->target->table, par->table) != 0) {\n\t\tpr_info_ratelimited(\"%s_tables: %s target: only valid in %s table, not %s\\n\",\n\t\t\t\t    xt_prefix[par->family], par->target->name,\n\t\t\t\t    par->target->table, par->table);\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->hooks && (par->hook_mask & ~par->target->hooks) != 0) {\n\t\tchar used[64], allow[64];\n\n\t\tpr_info_ratelimited(\"%s_tables: %s target: used from hooks %s, but only usable from %s\\n\",\n\t\t\t\t    xt_prefix[par->family], par->target->name,\n\t\t\t\t    textify_hooks(used, sizeof(used),\n\t\t\t\t\t\t  par->hook_mask, par->family),\n\t\t\t\t    textify_hooks(allow, sizeof(allow),\n\t\t\t\t\t\t  par->target->hooks,\n\t\t\t\t\t\t  par->family));\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->proto && (par->target->proto != proto || inv_proto)) {\n\t\tpr_info_ratelimited(\"%s_tables: %s target: only valid for protocol %u\\n\",\n\t\t\t\t    xt_prefix[par->family], par->target->name,\n\t\t\t\t    par->target->proto);\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->checkentry != NULL) {\n\t\tret = par->target->checkentry(par);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\telse if (ret > 0)\n\t\t\t \n\t\t\treturn -EIO;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_check_target);\n\n \nvoid *xt_copy_counters(sockptr_t arg, unsigned int len,\n\t\t       struct xt_counters_info *info)\n{\n\tsize_t offset;\n\tvoid *mem;\n\tu64 size;\n\n#ifdef CONFIG_NETFILTER_XTABLES_COMPAT\n\tif (in_compat_syscall()) {\n\t\t \n\t\tstruct compat_xt_counters_info compat_tmp;\n\n\t\tif (len <= sizeof(compat_tmp))\n\t\t\treturn ERR_PTR(-EINVAL);\n\n\t\tlen -= sizeof(compat_tmp);\n\t\tif (copy_from_sockptr(&compat_tmp, arg, sizeof(compat_tmp)) != 0)\n\t\t\treturn ERR_PTR(-EFAULT);\n\n\t\tmemcpy(info->name, compat_tmp.name, sizeof(info->name) - 1);\n\t\tinfo->num_counters = compat_tmp.num_counters;\n\t\toffset = sizeof(compat_tmp);\n\t} else\n#endif\n\t{\n\t\tif (len <= sizeof(*info))\n\t\t\treturn ERR_PTR(-EINVAL);\n\n\t\tlen -= sizeof(*info);\n\t\tif (copy_from_sockptr(info, arg, sizeof(*info)) != 0)\n\t\t\treturn ERR_PTR(-EFAULT);\n\n\t\toffset = sizeof(*info);\n\t}\n\tinfo->name[sizeof(info->name) - 1] = '\\0';\n\n\tsize = sizeof(struct xt_counters);\n\tsize *= info->num_counters;\n\n\tif (size != (u64)len)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tmem = vmalloc(len);\n\tif (!mem)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (copy_from_sockptr_offset(mem, arg, offset, len) == 0)\n\t\treturn mem;\n\n\tvfree(mem);\n\treturn ERR_PTR(-EFAULT);\n}\nEXPORT_SYMBOL_GPL(xt_copy_counters);\n\n#ifdef CONFIG_NETFILTER_XTABLES_COMPAT\nint xt_compat_target_offset(const struct xt_target *target)\n{\n\tu_int16_t csize = target->compatsize ? : target->targetsize;\n\treturn XT_ALIGN(target->targetsize) - COMPAT_XT_ALIGN(csize);\n}\nEXPORT_SYMBOL_GPL(xt_compat_target_offset);\n\nvoid xt_compat_target_from_user(struct xt_entry_target *t, void **dstptr,\n\t\t\t\tunsigned int *size)\n{\n\tconst struct xt_target *target = t->u.kernel.target;\n\tstruct compat_xt_entry_target *ct = (struct compat_xt_entry_target *)t;\n\tint off = xt_compat_target_offset(target);\n\tu_int16_t tsize = ct->u.user.target_size;\n\tchar name[sizeof(t->u.user.name)];\n\n\tt = *dstptr;\n\tmemcpy(t, ct, sizeof(*ct));\n\tif (target->compat_from_user)\n\t\ttarget->compat_from_user(t->data, ct->data);\n\telse\n\t\tmemcpy(t->data, ct->data, tsize - sizeof(*ct));\n\n\ttsize += off;\n\tt->u.user.target_size = tsize;\n\tstrscpy(name, target->name, sizeof(name));\n\tmodule_put(target->me);\n\tstrscpy_pad(t->u.user.name, name, sizeof(t->u.user.name));\n\n\t*size += off;\n\t*dstptr += tsize;\n}\nEXPORT_SYMBOL_GPL(xt_compat_target_from_user);\n\nint xt_compat_target_to_user(const struct xt_entry_target *t,\n\t\t\t     void __user **dstptr, unsigned int *size)\n{\n\tconst struct xt_target *target = t->u.kernel.target;\n\tstruct compat_xt_entry_target __user *ct = *dstptr;\n\tint off = xt_compat_target_offset(target);\n\tu_int16_t tsize = t->u.user.target_size - off;\n\n\tif (XT_OBJ_TO_USER(ct, t, target, tsize))\n\t\treturn -EFAULT;\n\n\tif (target->compat_to_user) {\n\t\tif (target->compat_to_user((void __user *)ct->data, t->data))\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tif (COMPAT_XT_DATA_TO_USER(ct, t, target, tsize - sizeof(*ct)))\n\t\t\treturn -EFAULT;\n\t}\n\n\t*size -= off;\n\t*dstptr += tsize;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_target_to_user);\n#endif\n\nstruct xt_table_info *xt_alloc_table_info(unsigned int size)\n{\n\tstruct xt_table_info *info = NULL;\n\tsize_t sz = sizeof(*info) + size;\n\n\tif (sz < sizeof(*info) || sz >= XT_MAX_TABLE_SIZE)\n\t\treturn NULL;\n\n\tinfo = kvmalloc(sz, GFP_KERNEL_ACCOUNT);\n\tif (!info)\n\t\treturn NULL;\n\n\tmemset(info, 0, sizeof(*info));\n\tinfo->size = size;\n\treturn info;\n}\nEXPORT_SYMBOL(xt_alloc_table_info);\n\nvoid xt_free_table_info(struct xt_table_info *info)\n{\n\tint cpu;\n\n\tif (info->jumpstack != NULL) {\n\t\tfor_each_possible_cpu(cpu)\n\t\t\tkvfree(info->jumpstack[cpu]);\n\t\tkvfree(info->jumpstack);\n\t}\n\n\tkvfree(info);\n}\nEXPORT_SYMBOL(xt_free_table_info);\n\nstruct xt_table *xt_find_table(struct net *net, u8 af, const char *name)\n{\n\tstruct xt_pernet *xt_net = net_generic(net, xt_pernet_id);\n\tstruct xt_table *t;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(t, &xt_net->tables[af], list) {\n\t\tif (strcmp(t->name, name) == 0) {\n\t\t\tmutex_unlock(&xt[af].mutex);\n\t\t\treturn t;\n\t\t}\n\t}\n\tmutex_unlock(&xt[af].mutex);\n\treturn NULL;\n}\nEXPORT_SYMBOL(xt_find_table);\n\n \nstruct xt_table *xt_find_table_lock(struct net *net, u_int8_t af,\n\t\t\t\t    const char *name)\n{\n\tstruct xt_pernet *xt_net = net_generic(net, xt_pernet_id);\n\tstruct module *owner = NULL;\n\tstruct xt_template *tmpl;\n\tstruct xt_table *t;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(t, &xt_net->tables[af], list)\n\t\tif (strcmp(t->name, name) == 0 && try_module_get(t->me))\n\t\t\treturn t;\n\n\t \n\tlist_for_each_entry(tmpl, &xt_templates[af], list) {\n\t\tint err;\n\n\t\tif (strcmp(tmpl->name, name))\n\t\t\tcontinue;\n\t\tif (!try_module_get(tmpl->me))\n\t\t\tgoto out;\n\n\t\towner = tmpl->me;\n\n\t\tmutex_unlock(&xt[af].mutex);\n\t\terr = tmpl->table_init(net);\n\t\tif (err < 0) {\n\t\t\tmodule_put(owner);\n\t\t\treturn ERR_PTR(err);\n\t\t}\n\n\t\tmutex_lock(&xt[af].mutex);\n\t\tbreak;\n\t}\n\n\t \n\tlist_for_each_entry(t, &xt_net->tables[af], list)\n\t\tif (strcmp(t->name, name) == 0)\n\t\t\treturn t;\n\n\tmodule_put(owner);\n out:\n\tmutex_unlock(&xt[af].mutex);\n\treturn ERR_PTR(-ENOENT);\n}\nEXPORT_SYMBOL_GPL(xt_find_table_lock);\n\nstruct xt_table *xt_request_find_table_lock(struct net *net, u_int8_t af,\n\t\t\t\t\t    const char *name)\n{\n\tstruct xt_table *t = xt_find_table_lock(net, af, name);\n\n#ifdef CONFIG_MODULES\n\tif (IS_ERR(t)) {\n\t\tint err = request_module(\"%stable_%s\", xt_prefix[af], name);\n\t\tif (err < 0)\n\t\t\treturn ERR_PTR(err);\n\t\tt = xt_find_table_lock(net, af, name);\n\t}\n#endif\n\n\treturn t;\n}\nEXPORT_SYMBOL_GPL(xt_request_find_table_lock);\n\nvoid xt_table_unlock(struct xt_table *table)\n{\n\tmutex_unlock(&xt[table->af].mutex);\n}\nEXPORT_SYMBOL_GPL(xt_table_unlock);\n\n#ifdef CONFIG_NETFILTER_XTABLES_COMPAT\nvoid xt_compat_lock(u_int8_t af)\n{\n\tmutex_lock(&xt[af].compat_mutex);\n}\nEXPORT_SYMBOL_GPL(xt_compat_lock);\n\nvoid xt_compat_unlock(u_int8_t af)\n{\n\tmutex_unlock(&xt[af].compat_mutex);\n}\nEXPORT_SYMBOL_GPL(xt_compat_unlock);\n#endif\n\nDEFINE_PER_CPU(seqcount_t, xt_recseq);\nEXPORT_PER_CPU_SYMBOL_GPL(xt_recseq);\n\nstruct static_key xt_tee_enabled __read_mostly;\nEXPORT_SYMBOL_GPL(xt_tee_enabled);\n\nstatic int xt_jumpstack_alloc(struct xt_table_info *i)\n{\n\tunsigned int size;\n\tint cpu;\n\n\tsize = sizeof(void **) * nr_cpu_ids;\n\tif (size > PAGE_SIZE)\n\t\ti->jumpstack = kvzalloc(size, GFP_KERNEL);\n\telse\n\t\ti->jumpstack = kzalloc(size, GFP_KERNEL);\n\tif (i->jumpstack == NULL)\n\t\treturn -ENOMEM;\n\n\t \n\tif (i->stacksize == 0)\n\t\treturn 0;\n\n\t \n\tsize = sizeof(void *) * i->stacksize * 2u;\n\tfor_each_possible_cpu(cpu) {\n\t\ti->jumpstack[cpu] = kvmalloc_node(size, GFP_KERNEL,\n\t\t\tcpu_to_node(cpu));\n\t\tif (i->jumpstack[cpu] == NULL)\n\t\t\t \n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstruct xt_counters *xt_counters_alloc(unsigned int counters)\n{\n\tstruct xt_counters *mem;\n\n\tif (counters == 0 || counters > INT_MAX / sizeof(*mem))\n\t\treturn NULL;\n\n\tcounters *= sizeof(*mem);\n\tif (counters > XT_MAX_TABLE_SIZE)\n\t\treturn NULL;\n\n\treturn vzalloc(counters);\n}\nEXPORT_SYMBOL(xt_counters_alloc);\n\nstruct xt_table_info *\nxt_replace_table(struct xt_table *table,\n\t      unsigned int num_counters,\n\t      struct xt_table_info *newinfo,\n\t      int *error)\n{\n\tstruct xt_table_info *private;\n\tunsigned int cpu;\n\tint ret;\n\n\tret = xt_jumpstack_alloc(newinfo);\n\tif (ret < 0) {\n\t\t*error = ret;\n\t\treturn NULL;\n\t}\n\n\t \n\tlocal_bh_disable();\n\tprivate = table->private;\n\n\t \n\tif (num_counters != private->number) {\n\t\tpr_debug(\"num_counters != table->private->number (%u/%u)\\n\",\n\t\t\t num_counters, private->number);\n\t\tlocal_bh_enable();\n\t\t*error = -EAGAIN;\n\t\treturn NULL;\n\t}\n\n\tnewinfo->initial_entries = private->initial_entries;\n\t \n\tsmp_wmb();\n\ttable->private = newinfo;\n\n\t \n\tsmp_mb();\n\n\t \n\tlocal_bh_enable();\n\n\t \n\tfor_each_possible_cpu(cpu) {\n\t\tseqcount_t *s = &per_cpu(xt_recseq, cpu);\n\t\tu32 seq = raw_read_seqcount(s);\n\n\t\tif (seq & 1) {\n\t\t\tdo {\n\t\t\t\tcond_resched();\n\t\t\t\tcpu_relax();\n\t\t\t} while (seq == raw_read_seqcount(s));\n\t\t}\n\t}\n\n\taudit_log_nfcfg(table->name, table->af, private->number,\n\t\t\t!private->number ? AUDIT_XT_OP_REGISTER :\n\t\t\t\t\t   AUDIT_XT_OP_REPLACE,\n\t\t\tGFP_KERNEL);\n\treturn private;\n}\nEXPORT_SYMBOL_GPL(xt_replace_table);\n\nstruct xt_table *xt_register_table(struct net *net,\n\t\t\t\t   const struct xt_table *input_table,\n\t\t\t\t   struct xt_table_info *bootstrap,\n\t\t\t\t   struct xt_table_info *newinfo)\n{\n\tstruct xt_pernet *xt_net = net_generic(net, xt_pernet_id);\n\tstruct xt_table_info *private;\n\tstruct xt_table *t, *table;\n\tint ret;\n\n\t \n\ttable = kmemdup(input_table, sizeof(struct xt_table), GFP_KERNEL);\n\tif (!table) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmutex_lock(&xt[table->af].mutex);\n\t \n\tlist_for_each_entry(t, &xt_net->tables[table->af], list) {\n\t\tif (strcmp(t->name, table->name) == 0) {\n\t\t\tret = -EEXIST;\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\t \n\ttable->private = bootstrap;\n\n\tif (!xt_replace_table(table, 0, newinfo, &ret))\n\t\tgoto unlock;\n\n\tprivate = table->private;\n\tpr_debug(\"table->private->number = %u\\n\", private->number);\n\n\t \n\tprivate->initial_entries = private->number;\n\n\tlist_add(&table->list, &xt_net->tables[table->af]);\n\tmutex_unlock(&xt[table->af].mutex);\n\treturn table;\n\nunlock:\n\tmutex_unlock(&xt[table->af].mutex);\n\tkfree(table);\nout:\n\treturn ERR_PTR(ret);\n}\nEXPORT_SYMBOL_GPL(xt_register_table);\n\nvoid *xt_unregister_table(struct xt_table *table)\n{\n\tstruct xt_table_info *private;\n\n\tmutex_lock(&xt[table->af].mutex);\n\tprivate = table->private;\n\tlist_del(&table->list);\n\tmutex_unlock(&xt[table->af].mutex);\n\taudit_log_nfcfg(table->name, table->af, private->number,\n\t\t\tAUDIT_XT_OP_UNREGISTER, GFP_KERNEL);\n\tkfree(table->ops);\n\tkfree(table);\n\n\treturn private;\n}\nEXPORT_SYMBOL_GPL(xt_unregister_table);\n\n#ifdef CONFIG_PROC_FS\nstatic void *xt_table_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tu8 af = (unsigned long)pde_data(file_inode(seq->file));\n\tstruct net *net = seq_file_net(seq);\n\tstruct xt_pernet *xt_net;\n\n\txt_net = net_generic(net, xt_pernet_id);\n\n\tmutex_lock(&xt[af].mutex);\n\treturn seq_list_start(&xt_net->tables[af], *pos);\n}\n\nstatic void *xt_table_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\tu8 af = (unsigned long)pde_data(file_inode(seq->file));\n\tstruct net *net = seq_file_net(seq);\n\tstruct xt_pernet *xt_net;\n\n\txt_net = net_generic(net, xt_pernet_id);\n\n\treturn seq_list_next(v, &xt_net->tables[af], pos);\n}\n\nstatic void xt_table_seq_stop(struct seq_file *seq, void *v)\n{\n\tu_int8_t af = (unsigned long)pde_data(file_inode(seq->file));\n\n\tmutex_unlock(&xt[af].mutex);\n}\n\nstatic int xt_table_seq_show(struct seq_file *seq, void *v)\n{\n\tstruct xt_table *table = list_entry(v, struct xt_table, list);\n\n\tif (*table->name)\n\t\tseq_printf(seq, \"%s\\n\", table->name);\n\treturn 0;\n}\n\nstatic const struct seq_operations xt_table_seq_ops = {\n\t.start\t= xt_table_seq_start,\n\t.next\t= xt_table_seq_next,\n\t.stop\t= xt_table_seq_stop,\n\t.show\t= xt_table_seq_show,\n};\n\n \nstruct nf_mttg_trav {\n\tstruct list_head *head, *curr;\n\tuint8_t class;\n};\n\nenum {\n\tMTTG_TRAV_INIT,\n\tMTTG_TRAV_NFP_UNSPEC,\n\tMTTG_TRAV_NFP_SPEC,\n\tMTTG_TRAV_DONE,\n};\n\nstatic void *xt_mttg_seq_next(struct seq_file *seq, void *v, loff_t *ppos,\n    bool is_target)\n{\n\tstatic const uint8_t next_class[] = {\n\t\t[MTTG_TRAV_NFP_UNSPEC] = MTTG_TRAV_NFP_SPEC,\n\t\t[MTTG_TRAV_NFP_SPEC]   = MTTG_TRAV_DONE,\n\t};\n\tuint8_t nfproto = (unsigned long)pde_data(file_inode(seq->file));\n\tstruct nf_mttg_trav *trav = seq->private;\n\n\tif (ppos != NULL)\n\t\t++(*ppos);\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_INIT:\n\t\ttrav->class = MTTG_TRAV_NFP_UNSPEC;\n\t\tmutex_lock(&xt[NFPROTO_UNSPEC].mutex);\n\t\ttrav->head = trav->curr = is_target ?\n\t\t\t&xt[NFPROTO_UNSPEC].target : &xt[NFPROTO_UNSPEC].match;\n \t\tbreak;\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\t\ttrav->curr = trav->curr->next;\n\t\tif (trav->curr != trav->head)\n\t\t\tbreak;\n\t\tmutex_unlock(&xt[NFPROTO_UNSPEC].mutex);\n\t\tmutex_lock(&xt[nfproto].mutex);\n\t\ttrav->head = trav->curr = is_target ?\n\t\t\t&xt[nfproto].target : &xt[nfproto].match;\n\t\ttrav->class = next_class[trav->class];\n\t\tbreak;\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\ttrav->curr = trav->curr->next;\n\t\tif (trav->curr != trav->head)\n\t\t\tbreak;\n\t\tfallthrough;\n\tdefault:\n\t\treturn NULL;\n\t}\n\treturn trav;\n}\n\nstatic void *xt_mttg_seq_start(struct seq_file *seq, loff_t *pos,\n    bool is_target)\n{\n\tstruct nf_mttg_trav *trav = seq->private;\n\tunsigned int j;\n\n\ttrav->class = MTTG_TRAV_INIT;\n\tfor (j = 0; j < *pos; ++j)\n\t\tif (xt_mttg_seq_next(seq, NULL, NULL, is_target) == NULL)\n\t\t\treturn NULL;\n\treturn trav;\n}\n\nstatic void xt_mttg_seq_stop(struct seq_file *seq, void *v)\n{\n\tuint8_t nfproto = (unsigned long)pde_data(file_inode(seq->file));\n\tstruct nf_mttg_trav *trav = seq->private;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\t\tmutex_unlock(&xt[NFPROTO_UNSPEC].mutex);\n\t\tbreak;\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\tmutex_unlock(&xt[nfproto].mutex);\n\t\tbreak;\n\t}\n}\n\nstatic void *xt_match_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\treturn xt_mttg_seq_start(seq, pos, false);\n}\n\nstatic void *xt_match_seq_next(struct seq_file *seq, void *v, loff_t *ppos)\n{\n\treturn xt_mttg_seq_next(seq, v, ppos, false);\n}\n\nstatic int xt_match_seq_show(struct seq_file *seq, void *v)\n{\n\tconst struct nf_mttg_trav *trav = seq->private;\n\tconst struct xt_match *match;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\tif (trav->curr == trav->head)\n\t\t\treturn 0;\n\t\tmatch = list_entry(trav->curr, struct xt_match, list);\n\t\tif (*match->name)\n\t\t\tseq_printf(seq, \"%s\\n\", match->name);\n\t}\n\treturn 0;\n}\n\nstatic const struct seq_operations xt_match_seq_ops = {\n\t.start\t= xt_match_seq_start,\n\t.next\t= xt_match_seq_next,\n\t.stop\t= xt_mttg_seq_stop,\n\t.show\t= xt_match_seq_show,\n};\n\nstatic void *xt_target_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\treturn xt_mttg_seq_start(seq, pos, true);\n}\n\nstatic void *xt_target_seq_next(struct seq_file *seq, void *v, loff_t *ppos)\n{\n\treturn xt_mttg_seq_next(seq, v, ppos, true);\n}\n\nstatic int xt_target_seq_show(struct seq_file *seq, void *v)\n{\n\tconst struct nf_mttg_trav *trav = seq->private;\n\tconst struct xt_target *target;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\tif (trav->curr == trav->head)\n\t\t\treturn 0;\n\t\ttarget = list_entry(trav->curr, struct xt_target, list);\n\t\tif (*target->name)\n\t\t\tseq_printf(seq, \"%s\\n\", target->name);\n\t}\n\treturn 0;\n}\n\nstatic const struct seq_operations xt_target_seq_ops = {\n\t.start\t= xt_target_seq_start,\n\t.next\t= xt_target_seq_next,\n\t.stop\t= xt_mttg_seq_stop,\n\t.show\t= xt_target_seq_show,\n};\n\n#define FORMAT_TABLES\t\"_tables_names\"\n#define\tFORMAT_MATCHES\t\"_tables_matches\"\n#define FORMAT_TARGETS \t\"_tables_targets\"\n\n#endif  \n\n \nstruct nf_hook_ops *\nxt_hook_ops_alloc(const struct xt_table *table, nf_hookfn *fn)\n{\n\tunsigned int hook_mask = table->valid_hooks;\n\tuint8_t i, num_hooks = hweight32(hook_mask);\n\tuint8_t hooknum;\n\tstruct nf_hook_ops *ops;\n\n\tif (!num_hooks)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tops = kcalloc(num_hooks, sizeof(*ops), GFP_KERNEL);\n\tif (ops == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfor (i = 0, hooknum = 0; i < num_hooks && hook_mask != 0;\n\t     hook_mask >>= 1, ++hooknum) {\n\t\tif (!(hook_mask & 1))\n\t\t\tcontinue;\n\t\tops[i].hook     = fn;\n\t\tops[i].pf       = table->af;\n\t\tops[i].hooknum  = hooknum;\n\t\tops[i].priority = table->priority;\n\t\t++i;\n\t}\n\n\treturn ops;\n}\nEXPORT_SYMBOL_GPL(xt_hook_ops_alloc);\n\nint xt_register_template(const struct xt_table *table,\n\t\t\t int (*table_init)(struct net *net))\n{\n\tint ret = -EEXIST, af = table->af;\n\tstruct xt_template *t;\n\n\tmutex_lock(&xt[af].mutex);\n\n\tlist_for_each_entry(t, &xt_templates[af], list) {\n\t\tif (WARN_ON_ONCE(strcmp(table->name, t->name) == 0))\n\t\t\tgoto out_unlock;\n\t}\n\n\tret = -ENOMEM;\n\tt = kzalloc(sizeof(*t), GFP_KERNEL);\n\tif (!t)\n\t\tgoto out_unlock;\n\n\tBUILD_BUG_ON(sizeof(t->name) != sizeof(table->name));\n\n\tstrscpy(t->name, table->name, sizeof(t->name));\n\tt->table_init = table_init;\n\tt->me = table->me;\n\tlist_add(&t->list, &xt_templates[af]);\n\tret = 0;\nout_unlock:\n\tmutex_unlock(&xt[af].mutex);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(xt_register_template);\n\nvoid xt_unregister_template(const struct xt_table *table)\n{\n\tstruct xt_template *t;\n\tint af = table->af;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(t, &xt_templates[af], list) {\n\t\tif (strcmp(table->name, t->name))\n\t\t\tcontinue;\n\n\t\tlist_del(&t->list);\n\t\tmutex_unlock(&xt[af].mutex);\n\t\tkfree(t);\n\t\treturn;\n\t}\n\n\tmutex_unlock(&xt[af].mutex);\n\tWARN_ON_ONCE(1);\n}\nEXPORT_SYMBOL_GPL(xt_unregister_template);\n\nint xt_proto_init(struct net *net, u_int8_t af)\n{\n#ifdef CONFIG_PROC_FS\n\tchar buf[XT_FUNCTION_MAXNAMELEN];\n\tstruct proc_dir_entry *proc;\n\tkuid_t root_uid;\n\tkgid_t root_gid;\n#endif\n\n\tif (af >= ARRAY_SIZE(xt_prefix))\n\t\treturn -EINVAL;\n\n\n#ifdef CONFIG_PROC_FS\n\troot_uid = make_kuid(net->user_ns, 0);\n\troot_gid = make_kgid(net->user_ns, 0);\n\n\tstrscpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TABLES, sizeof(buf));\n\tproc = proc_create_net_data(buf, 0440, net->proc_net, &xt_table_seq_ops,\n\t\t\tsizeof(struct seq_net_private),\n\t\t\t(void *)(unsigned long)af);\n\tif (!proc)\n\t\tgoto out;\n\tif (uid_valid(root_uid) && gid_valid(root_gid))\n\t\tproc_set_user(proc, root_uid, root_gid);\n\n\tstrscpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\n\tproc = proc_create_seq_private(buf, 0440, net->proc_net,\n\t\t\t&xt_match_seq_ops, sizeof(struct nf_mttg_trav),\n\t\t\t(void *)(unsigned long)af);\n\tif (!proc)\n\t\tgoto out_remove_tables;\n\tif (uid_valid(root_uid) && gid_valid(root_gid))\n\t\tproc_set_user(proc, root_uid, root_gid);\n\n\tstrscpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TARGETS, sizeof(buf));\n\tproc = proc_create_seq_private(buf, 0440, net->proc_net,\n\t\t\t &xt_target_seq_ops, sizeof(struct nf_mttg_trav),\n\t\t\t (void *)(unsigned long)af);\n\tif (!proc)\n\t\tgoto out_remove_matches;\n\tif (uid_valid(root_uid) && gid_valid(root_gid))\n\t\tproc_set_user(proc, root_uid, root_gid);\n#endif\n\n\treturn 0;\n\n#ifdef CONFIG_PROC_FS\nout_remove_matches:\n\tstrscpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n\nout_remove_tables:\n\tstrscpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TABLES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\nout:\n\treturn -1;\n#endif\n}\nEXPORT_SYMBOL_GPL(xt_proto_init);\n\nvoid xt_proto_fini(struct net *net, u_int8_t af)\n{\n#ifdef CONFIG_PROC_FS\n\tchar buf[XT_FUNCTION_MAXNAMELEN];\n\n\tstrscpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TABLES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n\n\tstrscpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TARGETS, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n\n\tstrscpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n#endif  \n}\nEXPORT_SYMBOL_GPL(xt_proto_fini);\n\n \nbool xt_percpu_counter_alloc(struct xt_percpu_counter_alloc_state *state,\n\t\t\t     struct xt_counters *counter)\n{\n\tBUILD_BUG_ON(XT_PCPU_BLOCK_SIZE < (sizeof(*counter) * 2));\n\n\tif (nr_cpu_ids <= 1)\n\t\treturn true;\n\n\tif (!state->mem) {\n\t\tstate->mem = __alloc_percpu(XT_PCPU_BLOCK_SIZE,\n\t\t\t\t\t    XT_PCPU_BLOCK_SIZE);\n\t\tif (!state->mem)\n\t\t\treturn false;\n\t}\n\tcounter->pcnt = (__force unsigned long)(state->mem + state->off);\n\tstate->off += sizeof(*counter);\n\tif (state->off > (XT_PCPU_BLOCK_SIZE - sizeof(*counter))) {\n\t\tstate->mem = NULL;\n\t\tstate->off = 0;\n\t}\n\treturn true;\n}\nEXPORT_SYMBOL_GPL(xt_percpu_counter_alloc);\n\nvoid xt_percpu_counter_free(struct xt_counters *counters)\n{\n\tunsigned long pcnt = counters->pcnt;\n\n\tif (nr_cpu_ids > 1 && (pcnt & (XT_PCPU_BLOCK_SIZE - 1)) == 0)\n\t\tfree_percpu((void __percpu *)pcnt);\n}\nEXPORT_SYMBOL_GPL(xt_percpu_counter_free);\n\nstatic int __net_init xt_net_init(struct net *net)\n{\n\tstruct xt_pernet *xt_net = net_generic(net, xt_pernet_id);\n\tint i;\n\n\tfor (i = 0; i < NFPROTO_NUMPROTO; i++)\n\t\tINIT_LIST_HEAD(&xt_net->tables[i]);\n\treturn 0;\n}\n\nstatic void __net_exit xt_net_exit(struct net *net)\n{\n\tstruct xt_pernet *xt_net = net_generic(net, xt_pernet_id);\n\tint i;\n\n\tfor (i = 0; i < NFPROTO_NUMPROTO; i++)\n\t\tWARN_ON_ONCE(!list_empty(&xt_net->tables[i]));\n}\n\nstatic struct pernet_operations xt_net_ops = {\n\t.init = xt_net_init,\n\t.exit = xt_net_exit,\n\t.id   = &xt_pernet_id,\n\t.size = sizeof(struct xt_pernet),\n};\n\nstatic int __init xt_init(void)\n{\n\tunsigned int i;\n\tint rv;\n\n\tfor_each_possible_cpu(i) {\n\t\tseqcount_init(&per_cpu(xt_recseq, i));\n\t}\n\n\txt = kcalloc(NFPROTO_NUMPROTO, sizeof(struct xt_af), GFP_KERNEL);\n\tif (!xt)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < NFPROTO_NUMPROTO; i++) {\n\t\tmutex_init(&xt[i].mutex);\n#ifdef CONFIG_NETFILTER_XTABLES_COMPAT\n\t\tmutex_init(&xt[i].compat_mutex);\n\t\txt[i].compat_tab = NULL;\n#endif\n\t\tINIT_LIST_HEAD(&xt[i].target);\n\t\tINIT_LIST_HEAD(&xt[i].match);\n\t\tINIT_LIST_HEAD(&xt_templates[i]);\n\t}\n\trv = register_pernet_subsys(&xt_net_ops);\n\tif (rv < 0)\n\t\tkfree(xt);\n\treturn rv;\n}\n\nstatic void __exit xt_fini(void)\n{\n\tunregister_pernet_subsys(&xt_net_ops);\n\tkfree(xt);\n}\n\nmodule_init(xt_init);\nmodule_exit(xt_fini);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}