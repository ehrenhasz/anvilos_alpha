{
  "module_name": "nf_conntrack_ecache.c",
  "hash_id": "7acbf8f7808113b628c8629dcd52acb0d25c504c98e4a9a536acf9e59602bfed",
  "original_prompt": "Ingested from linux-6.6.14/net/netfilter/nf_conntrack_ecache.c",
  "human_readable_source": "\n \n\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/types.h>\n#include <linux/netfilter.h>\n#include <linux/skbuff.h>\n#include <linux/vmalloc.h>\n#include <linux/stddef.h>\n#include <linux/err.h>\n#include <linux/kernel.h>\n#include <linux/netdevice.h>\n#include <linux/slab.h>\n#include <linux/export.h>\n\n#include <net/netfilter/nf_conntrack.h>\n#include <net/netfilter/nf_conntrack_core.h>\n#include <net/netfilter/nf_conntrack_ecache.h>\n#include <net/netfilter/nf_conntrack_extend.h>\n\nstatic DEFINE_MUTEX(nf_ct_ecache_mutex);\n\n#define DYING_NULLS_VAL\t\t\t((1 << 30) + 1)\n#define ECACHE_MAX_JIFFIES\t\tmsecs_to_jiffies(10)\n#define ECACHE_RETRY_JIFFIES\t\tmsecs_to_jiffies(10)\n\nenum retry_state {\n\tSTATE_CONGESTED,\n\tSTATE_RESTART,\n\tSTATE_DONE,\n};\n\nstruct nf_conntrack_net_ecache *nf_conn_pernet_ecache(const struct net *net)\n{\n\tstruct nf_conntrack_net *cnet = nf_ct_pernet(net);\n\n\treturn &cnet->ecache;\n}\n#if IS_MODULE(CONFIG_NF_CT_NETLINK)\nEXPORT_SYMBOL_GPL(nf_conn_pernet_ecache);\n#endif\n\nstatic enum retry_state ecache_work_evict_list(struct nf_conntrack_net *cnet)\n{\n\tunsigned long stop = jiffies + ECACHE_MAX_JIFFIES;\n\tstruct hlist_nulls_head evicted_list;\n\tenum retry_state ret = STATE_DONE;\n\tstruct nf_conntrack_tuple_hash *h;\n\tstruct hlist_nulls_node *n;\n\tunsigned int sent;\n\n\tINIT_HLIST_NULLS_HEAD(&evicted_list, DYING_NULLS_VAL);\n\nnext:\n\tsent = 0;\n\tspin_lock_bh(&cnet->ecache.dying_lock);\n\n\thlist_nulls_for_each_entry_safe(h, n, &cnet->ecache.dying_list, hnnode) {\n\t\tstruct nf_conn *ct = nf_ct_tuplehash_to_ctrack(h);\n\n\t\t \n\t\tif (nf_conntrack_event(IPCT_DESTROY, ct)) {\n\t\t\tret = STATE_CONGESTED;\n\t\t\tbreak;\n\t\t}\n\n\t\thlist_nulls_del_rcu(&ct->tuplehash[IP_CT_DIR_ORIGINAL].hnnode);\n\t\thlist_nulls_add_head(&ct->tuplehash[IP_CT_DIR_REPLY].hnnode, &evicted_list);\n\n\t\tif (time_after(stop, jiffies)) {\n\t\t\tret = STATE_RESTART;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (sent++ > 16) {\n\t\t\tspin_unlock_bh(&cnet->ecache.dying_lock);\n\t\t\tcond_resched();\n\t\t\tgoto next;\n\t\t}\n\t}\n\n\tspin_unlock_bh(&cnet->ecache.dying_lock);\n\n\thlist_nulls_for_each_entry_safe(h, n, &evicted_list, hnnode) {\n\t\tstruct nf_conn *ct = nf_ct_tuplehash_to_ctrack(h);\n\n\t\thlist_nulls_del_rcu(&ct->tuplehash[IP_CT_DIR_REPLY].hnnode);\n\t\tnf_ct_put(ct);\n\n\t\tcond_resched();\n\t}\n\n\treturn ret;\n}\n\nstatic void ecache_work(struct work_struct *work)\n{\n\tstruct nf_conntrack_net *cnet = container_of(work, struct nf_conntrack_net, ecache.dwork.work);\n\tint ret, delay = -1;\n\n\tret = ecache_work_evict_list(cnet);\n\tswitch (ret) {\n\tcase STATE_CONGESTED:\n\t\tdelay = ECACHE_RETRY_JIFFIES;\n\t\tbreak;\n\tcase STATE_RESTART:\n\t\tdelay = 0;\n\t\tbreak;\n\tcase STATE_DONE:\n\t\tbreak;\n\t}\n\n\tif (delay >= 0)\n\t\tschedule_delayed_work(&cnet->ecache.dwork, delay);\n}\n\nstatic int __nf_conntrack_eventmask_report(struct nf_conntrack_ecache *e,\n\t\t\t\t\t   const u32 events,\n\t\t\t\t\t   const u32 missed,\n\t\t\t\t\t   const struct nf_ct_event *item)\n{\n\tstruct net *net = nf_ct_net(item->ct);\n\tstruct nf_ct_event_notifier *notify;\n\tu32 old, want;\n\tint ret;\n\n\tif (!((events | missed) & e->ctmask))\n\t\treturn 0;\n\n\trcu_read_lock();\n\n\tnotify = rcu_dereference(net->ct.nf_conntrack_event_cb);\n\tif (!notify) {\n\t\trcu_read_unlock();\n\t\treturn 0;\n\t}\n\n\tret = notify->ct_event(events | missed, item);\n\trcu_read_unlock();\n\n\tif (likely(ret >= 0 && missed == 0))\n\t\treturn 0;\n\n\tdo {\n\t\told = READ_ONCE(e->missed);\n\t\tif (ret < 0)\n\t\t\twant = old | events;\n\t\telse\n\t\t\twant = old & ~missed;\n\t} while (cmpxchg(&e->missed, old, want) != old);\n\n\treturn ret;\n}\n\nint nf_conntrack_eventmask_report(unsigned int events, struct nf_conn *ct,\n\t\t\t\t  u32 portid, int report)\n{\n\tstruct nf_conntrack_ecache *e;\n\tstruct nf_ct_event item;\n\tunsigned int missed;\n\tint ret;\n\n\tif (!nf_ct_is_confirmed(ct))\n\t\treturn 0;\n\n\te = nf_ct_ecache_find(ct);\n\tif (!e)\n\t\treturn 0;\n\n\tmemset(&item, 0, sizeof(item));\n\n\titem.ct = ct;\n\titem.portid = e->portid ? e->portid : portid;\n\titem.report = report;\n\n\t \n\tmissed = e->portid ? 0 : e->missed;\n\n\tret = __nf_conntrack_eventmask_report(e, events, missed, &item);\n\tif (unlikely(ret < 0 && (events & (1 << IPCT_DESTROY)))) {\n\t\t \n\t\tif (e->portid == 0 && portid != 0)\n\t\t\te->portid = portid;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(nf_conntrack_eventmask_report);\n\n \nvoid nf_ct_deliver_cached_events(struct nf_conn *ct)\n{\n\tstruct nf_conntrack_ecache *e;\n\tstruct nf_ct_event item;\n\tunsigned int events;\n\n\tif (!nf_ct_is_confirmed(ct) || nf_ct_is_dying(ct))\n\t\treturn;\n\n\te = nf_ct_ecache_find(ct);\n\tif (e == NULL)\n\t\treturn;\n\n\tevents = xchg(&e->cache, 0);\n\n\titem.ct = ct;\n\titem.portid = 0;\n\titem.report = 0;\n\n\t \n\t__nf_conntrack_eventmask_report(e, events, e->missed, &item);\n}\nEXPORT_SYMBOL_GPL(nf_ct_deliver_cached_events);\n\nvoid nf_ct_expect_event_report(enum ip_conntrack_expect_events event,\n\t\t\t       struct nf_conntrack_expect *exp,\n\t\t\t       u32 portid, int report)\n\n{\n\tstruct net *net = nf_ct_exp_net(exp);\n\tstruct nf_ct_event_notifier *notify;\n\tstruct nf_conntrack_ecache *e;\n\n\trcu_read_lock();\n\tnotify = rcu_dereference(net->ct.nf_conntrack_event_cb);\n\tif (!notify)\n\t\tgoto out_unlock;\n\n\te = nf_ct_ecache_find(exp->master);\n\tif (!e)\n\t\tgoto out_unlock;\n\n\tif (e->expmask & (1 << event)) {\n\t\tstruct nf_exp_event item = {\n\t\t\t.exp\t= exp,\n\t\t\t.portid\t= portid,\n\t\t\t.report = report\n\t\t};\n\t\tnotify->exp_event(1 << event, &item);\n\t}\nout_unlock:\n\trcu_read_unlock();\n}\n\nvoid nf_conntrack_register_notifier(struct net *net,\n\t\t\t\t    const struct nf_ct_event_notifier *new)\n{\n\tstruct nf_ct_event_notifier *notify;\n\n\tmutex_lock(&nf_ct_ecache_mutex);\n\tnotify = rcu_dereference_protected(net->ct.nf_conntrack_event_cb,\n\t\t\t\t\t   lockdep_is_held(&nf_ct_ecache_mutex));\n\tWARN_ON_ONCE(notify);\n\trcu_assign_pointer(net->ct.nf_conntrack_event_cb, new);\n\tmutex_unlock(&nf_ct_ecache_mutex);\n}\nEXPORT_SYMBOL_GPL(nf_conntrack_register_notifier);\n\nvoid nf_conntrack_unregister_notifier(struct net *net)\n{\n\tmutex_lock(&nf_ct_ecache_mutex);\n\tRCU_INIT_POINTER(net->ct.nf_conntrack_event_cb, NULL);\n\tmutex_unlock(&nf_ct_ecache_mutex);\n\t \n}\nEXPORT_SYMBOL_GPL(nf_conntrack_unregister_notifier);\n\nvoid nf_conntrack_ecache_work(struct net *net, enum nf_ct_ecache_state state)\n{\n\tstruct nf_conntrack_net *cnet = nf_ct_pernet(net);\n\n\tif (state == NFCT_ECACHE_DESTROY_FAIL &&\n\t    !delayed_work_pending(&cnet->ecache.dwork)) {\n\t\tschedule_delayed_work(&cnet->ecache.dwork, HZ);\n\t\tnet->ct.ecache_dwork_pending = true;\n\t} else if (state == NFCT_ECACHE_DESTROY_SENT) {\n\t\tif (!hlist_nulls_empty(&cnet->ecache.dying_list))\n\t\t\tmod_delayed_work(system_wq, &cnet->ecache.dwork, 0);\n\t\telse\n\t\t\tnet->ct.ecache_dwork_pending = false;\n\t}\n}\n\nbool nf_ct_ecache_ext_add(struct nf_conn *ct, u16 ctmask, u16 expmask, gfp_t gfp)\n{\n\tstruct net *net = nf_ct_net(ct);\n\tstruct nf_conntrack_ecache *e;\n\n\tswitch (net->ct.sysctl_events) {\n\tcase 0:\n\t\t  \n\t\tif (ctmask || expmask)\n\t\t\tbreak;\n\t\treturn true;\n\tcase 2:  \n\t\tif (!READ_ONCE(nf_ctnetlink_has_listener))\n\t\t\treturn true;\n\t\tfallthrough;\n\tcase 1:\n\t\t \n\t\tif (!ctmask && !expmask) {\n\t\t\tctmask = ~0;\n\t\t\texpmask = ~0;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn true;\n\t}\n\n\te = nf_ct_ext_add(ct, NF_CT_EXT_ECACHE, gfp);\n\tif (e) {\n\t\te->ctmask  = ctmask;\n\t\te->expmask = expmask;\n\t}\n\n\treturn e != NULL;\n}\nEXPORT_SYMBOL_GPL(nf_ct_ecache_ext_add);\n\n#define NF_CT_EVENTS_DEFAULT 2\nstatic int nf_ct_events __read_mostly = NF_CT_EVENTS_DEFAULT;\n\nvoid nf_conntrack_ecache_pernet_init(struct net *net)\n{\n\tstruct nf_conntrack_net *cnet = nf_ct_pernet(net);\n\n\tnet->ct.sysctl_events = nf_ct_events;\n\n\tINIT_DELAYED_WORK(&cnet->ecache.dwork, ecache_work);\n\tINIT_HLIST_NULLS_HEAD(&cnet->ecache.dying_list, DYING_NULLS_VAL);\n\tspin_lock_init(&cnet->ecache.dying_lock);\n\n\tBUILD_BUG_ON(__IPCT_MAX >= 16);\t \n}\n\nvoid nf_conntrack_ecache_pernet_fini(struct net *net)\n{\n\tstruct nf_conntrack_net *cnet = nf_ct_pernet(net);\n\n\tcancel_delayed_work_sync(&cnet->ecache.dwork);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}