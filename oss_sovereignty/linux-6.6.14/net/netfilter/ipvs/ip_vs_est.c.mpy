{
  "module_name": "ip_vs_est.c",
  "hash_id": "d8a35d45af3d906c19ab409653eafd091443b3951bfc66679c0ec8f7f2236828",
  "original_prompt": "Ingested from linux-6.6.14/net/netfilter/ipvs/ip_vs_est.c",
  "human_readable_source": "\n \n\n#define KMSG_COMPONENT \"IPVS\"\n#define pr_fmt(fmt) KMSG_COMPONENT \": \" fmt\n\n#include <linux/kernel.h>\n#include <linux/jiffies.h>\n#include <linux/types.h>\n#include <linux/interrupt.h>\n#include <linux/sysctl.h>\n#include <linux/list.h>\n\n#include <net/ip_vs.h>\n\n \n\nstatic struct lock_class_key __ipvs_est_key;\n\nstatic void ip_vs_est_calc_phase(struct netns_ipvs *ipvs);\nstatic void ip_vs_est_drain_temp_list(struct netns_ipvs *ipvs);\n\nstatic void ip_vs_chain_estimation(struct hlist_head *chain)\n{\n\tstruct ip_vs_estimator *e;\n\tstruct ip_vs_cpu_stats *c;\n\tstruct ip_vs_stats *s;\n\tu64 rate;\n\n\thlist_for_each_entry_rcu(e, chain, list) {\n\t\tu64 conns, inpkts, outpkts, inbytes, outbytes;\n\t\tu64 kconns = 0, kinpkts = 0, koutpkts = 0;\n\t\tu64 kinbytes = 0, koutbytes = 0;\n\t\tunsigned int start;\n\t\tint i;\n\n\t\tif (kthread_should_stop())\n\t\t\tbreak;\n\n\t\ts = container_of(e, struct ip_vs_stats, est);\n\t\tfor_each_possible_cpu(i) {\n\t\t\tc = per_cpu_ptr(s->cpustats, i);\n\t\t\tdo {\n\t\t\t\tstart = u64_stats_fetch_begin(&c->syncp);\n\t\t\t\tconns = u64_stats_read(&c->cnt.conns);\n\t\t\t\tinpkts = u64_stats_read(&c->cnt.inpkts);\n\t\t\t\toutpkts = u64_stats_read(&c->cnt.outpkts);\n\t\t\t\tinbytes = u64_stats_read(&c->cnt.inbytes);\n\t\t\t\toutbytes = u64_stats_read(&c->cnt.outbytes);\n\t\t\t} while (u64_stats_fetch_retry(&c->syncp, start));\n\t\t\tkconns += conns;\n\t\t\tkinpkts += inpkts;\n\t\t\tkoutpkts += outpkts;\n\t\t\tkinbytes += inbytes;\n\t\t\tkoutbytes += outbytes;\n\t\t}\n\n\t\tspin_lock(&s->lock);\n\n\t\ts->kstats.conns = kconns;\n\t\ts->kstats.inpkts = kinpkts;\n\t\ts->kstats.outpkts = koutpkts;\n\t\ts->kstats.inbytes = kinbytes;\n\t\ts->kstats.outbytes = koutbytes;\n\n\t\t \n\t\trate = (s->kstats.conns - e->last_conns) << 9;\n\t\te->last_conns = s->kstats.conns;\n\t\te->cps += ((s64)rate - (s64)e->cps) >> 2;\n\n\t\trate = (s->kstats.inpkts - e->last_inpkts) << 9;\n\t\te->last_inpkts = s->kstats.inpkts;\n\t\te->inpps += ((s64)rate - (s64)e->inpps) >> 2;\n\n\t\trate = (s->kstats.outpkts - e->last_outpkts) << 9;\n\t\te->last_outpkts = s->kstats.outpkts;\n\t\te->outpps += ((s64)rate - (s64)e->outpps) >> 2;\n\n\t\t \n\t\trate = (s->kstats.inbytes - e->last_inbytes) << 4;\n\t\te->last_inbytes = s->kstats.inbytes;\n\t\te->inbps += ((s64)rate - (s64)e->inbps) >> 2;\n\n\t\trate = (s->kstats.outbytes - e->last_outbytes) << 4;\n\t\te->last_outbytes = s->kstats.outbytes;\n\t\te->outbps += ((s64)rate - (s64)e->outbps) >> 2;\n\t\tspin_unlock(&s->lock);\n\t}\n}\n\nstatic void ip_vs_tick_estimation(struct ip_vs_est_kt_data *kd, int row)\n{\n\tstruct ip_vs_est_tick_data *td;\n\tint cid;\n\n\trcu_read_lock();\n\ttd = rcu_dereference(kd->ticks[row]);\n\tif (!td)\n\t\tgoto out;\n\tfor_each_set_bit(cid, td->present, IPVS_EST_TICK_CHAINS) {\n\t\tif (kthread_should_stop())\n\t\t\tbreak;\n\t\tip_vs_chain_estimation(&td->chains[cid]);\n\t\tcond_resched_rcu();\n\t\ttd = rcu_dereference(kd->ticks[row]);\n\t\tif (!td)\n\t\t\tbreak;\n\t}\n\nout:\n\trcu_read_unlock();\n}\n\nstatic int ip_vs_estimation_kthread(void *data)\n{\n\tstruct ip_vs_est_kt_data *kd = data;\n\tstruct netns_ipvs *ipvs = kd->ipvs;\n\tint row = kd->est_row;\n\tunsigned long now;\n\tint id = kd->id;\n\tlong gap;\n\n\tif (id > 0) {\n\t\tif (!ipvs->est_chain_max)\n\t\t\treturn 0;\n\t} else {\n\t\tif (!ipvs->est_chain_max) {\n\t\t\tipvs->est_calc_phase = 1;\n\t\t\t \n\t\t\tsmp_mb();\n\t\t}\n\n\t\t \n\t\tif (ipvs->est_calc_phase)\n\t\t\tip_vs_est_calc_phase(ipvs);\n\t}\n\n\twhile (1) {\n\t\tif (!id && !hlist_empty(&ipvs->est_temp_list))\n\t\t\tip_vs_est_drain_temp_list(ipvs);\n\t\tset_current_state(TASK_IDLE);\n\t\tif (kthread_should_stop())\n\t\t\tbreak;\n\n\t\t \n\t\tnow = jiffies;\n\t\tgap = kd->est_timer - now;\n\t\tif (gap > 0) {\n\t\t\tif (gap > IPVS_EST_TICK) {\n\t\t\t\tkd->est_timer = now - IPVS_EST_TICK;\n\t\t\t\tgap = IPVS_EST_TICK;\n\t\t\t}\n\t\t\tschedule_timeout(gap);\n\t\t} else {\n\t\t\t__set_current_state(TASK_RUNNING);\n\t\t\tif (gap < -8 * IPVS_EST_TICK)\n\t\t\t\tkd->est_timer = now;\n\t\t}\n\n\t\tif (kd->tick_len[row])\n\t\t\tip_vs_tick_estimation(kd, row);\n\n\t\trow++;\n\t\tif (row >= IPVS_EST_NTICKS)\n\t\t\trow = 0;\n\t\tWRITE_ONCE(kd->est_row, row);\n\t\tkd->est_timer += IPVS_EST_TICK;\n\t}\n\t__set_current_state(TASK_RUNNING);\n\n\treturn 0;\n}\n\n \nvoid ip_vs_est_reload_start(struct netns_ipvs *ipvs)\n{\n\t \n\tif (!ipvs->enable)\n\t\treturn;\n\tip_vs_est_stopped_recalc(ipvs);\n\t \n\tatomic_inc(&ipvs->est_genid);\n\tqueue_delayed_work(system_long_wq, &ipvs->est_reload_work, 0);\n}\n\n \nint ip_vs_est_kthread_start(struct netns_ipvs *ipvs,\n\t\t\t    struct ip_vs_est_kt_data *kd)\n{\n\tunsigned long now;\n\tint ret = 0;\n\tlong gap;\n\n\tlockdep_assert_held(&ipvs->est_mutex);\n\n\tif (kd->task)\n\t\tgoto out;\n\tnow = jiffies;\n\tgap = kd->est_timer - now;\n\t \n\tif (abs(gap) > 4 * IPVS_EST_TICK)\n\t\tkd->est_timer = now;\n\tkd->task = kthread_create(ip_vs_estimation_kthread, kd, \"ipvs-e:%d:%d\",\n\t\t\t\t  ipvs->gen, kd->id);\n\tif (IS_ERR(kd->task)) {\n\t\tret = PTR_ERR(kd->task);\n\t\tkd->task = NULL;\n\t\tgoto out;\n\t}\n\n\tset_user_nice(kd->task, sysctl_est_nice(ipvs));\n\tset_cpus_allowed_ptr(kd->task, sysctl_est_cpulist(ipvs));\n\n\tpr_info(\"starting estimator thread %d...\\n\", kd->id);\n\twake_up_process(kd->task);\n\nout:\n\treturn ret;\n}\n\nvoid ip_vs_est_kthread_stop(struct ip_vs_est_kt_data *kd)\n{\n\tif (kd->task) {\n\t\tpr_info(\"stopping estimator thread %d...\\n\", kd->id);\n\t\tkthread_stop(kd->task);\n\t\tkd->task = NULL;\n\t}\n}\n\n \nstatic void ip_vs_est_set_params(struct netns_ipvs *ipvs,\n\t\t\t\t struct ip_vs_est_kt_data *kd)\n{\n\tkd->chain_max = ipvs->est_chain_max;\n\t \n\tif (IPVS_EST_TICK_CHAINS == 1)\n\t\tkd->chain_max *= IPVS_EST_CHAIN_FACTOR;\n\tkd->tick_max = IPVS_EST_TICK_CHAINS * kd->chain_max;\n\tkd->est_max_count = IPVS_EST_NTICKS * kd->tick_max;\n}\n\n \nstatic int ip_vs_est_add_kthread(struct netns_ipvs *ipvs)\n{\n\tstruct ip_vs_est_kt_data *kd = NULL;\n\tint id = ipvs->est_kt_count;\n\tint ret = -ENOMEM;\n\tvoid *arr = NULL;\n\tint i;\n\n\tif ((unsigned long)ipvs->est_kt_count >= ipvs->est_max_threads &&\n\t    ipvs->enable && ipvs->est_max_threads)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&ipvs->est_mutex);\n\n\tfor (i = 0; i < id; i++) {\n\t\tif (!ipvs->est_kt_arr[i])\n\t\t\tbreak;\n\t}\n\tif (i >= id) {\n\t\tarr = krealloc_array(ipvs->est_kt_arr, id + 1,\n\t\t\t\t     sizeof(struct ip_vs_est_kt_data *),\n\t\t\t\t     GFP_KERNEL);\n\t\tif (!arr)\n\t\t\tgoto out;\n\t\tipvs->est_kt_arr = arr;\n\t} else {\n\t\tid = i;\n\t}\n\n\tkd = kzalloc(sizeof(*kd), GFP_KERNEL);\n\tif (!kd)\n\t\tgoto out;\n\tkd->ipvs = ipvs;\n\tbitmap_fill(kd->avail, IPVS_EST_NTICKS);\n\tkd->est_timer = jiffies;\n\tkd->id = id;\n\tip_vs_est_set_params(ipvs, kd);\n\n\t \n\tif (!id && !kd->calc_stats) {\n\t\tkd->calc_stats = ip_vs_stats_alloc();\n\t\tif (!kd->calc_stats)\n\t\t\tgoto out;\n\t}\n\n\t \n\tif (ipvs->enable && !ip_vs_est_stopped(ipvs)) {\n\t\tret = ip_vs_est_kthread_start(ipvs, kd);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t}\n\n\tif (arr)\n\t\tipvs->est_kt_count++;\n\tipvs->est_kt_arr[id] = kd;\n\tkd = NULL;\n\t \n\tipvs->est_add_ktid = id;\n\tret = 0;\n\nout:\n\tmutex_unlock(&ipvs->est_mutex);\n\tif (kd) {\n\t\tip_vs_stats_free(kd->calc_stats);\n\t\tkfree(kd);\n\t}\n\n\treturn ret;\n}\n\n \nstatic void ip_vs_est_update_ktid(struct netns_ipvs *ipvs)\n{\n\tint ktid, best = ipvs->est_kt_count;\n\tstruct ip_vs_est_kt_data *kd;\n\n\tfor (ktid = 0; ktid < ipvs->est_kt_count; ktid++) {\n\t\tkd = ipvs->est_kt_arr[ktid];\n\t\tif (kd) {\n\t\t\tif (kd->est_count < kd->est_max_count) {\n\t\t\t\tbest = ktid;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (ktid < best) {\n\t\t\tbest = ktid;\n\t\t}\n\t}\n\tipvs->est_add_ktid = best;\n}\n\n \nstatic int ip_vs_enqueue_estimator(struct netns_ipvs *ipvs,\n\t\t\t\t   struct ip_vs_estimator *est)\n{\n\tstruct ip_vs_est_kt_data *kd = NULL;\n\tstruct ip_vs_est_tick_data *td;\n\tint ktid, row, crow, cid, ret;\n\tint delay = est->ktrow;\n\n\tBUILD_BUG_ON_MSG(IPVS_EST_TICK_CHAINS > 127,\n\t\t\t \"Too many chains for ktcid\");\n\n\tif (ipvs->est_add_ktid < ipvs->est_kt_count) {\n\t\tkd = ipvs->est_kt_arr[ipvs->est_add_ktid];\n\t\tif (kd)\n\t\t\tgoto add_est;\n\t}\n\n\tret = ip_vs_est_add_kthread(ipvs);\n\tif (ret < 0)\n\t\tgoto out;\n\tkd = ipvs->est_kt_arr[ipvs->est_add_ktid];\n\nadd_est:\n\tktid = kd->id;\n\t \n\tif (kd->est_count >= 2 * kd->tick_max || delay < IPVS_EST_NTICKS - 1)\n\t\tcrow = READ_ONCE(kd->est_row);\n\telse\n\t\tcrow = kd->add_row;\n\tcrow += delay;\n\tif (crow >= IPVS_EST_NTICKS)\n\t\tcrow -= IPVS_EST_NTICKS;\n\t \n\tif (delay >= IPVS_EST_NTICKS - 1) {\n\t\t \n\t\trow = crow;\n\t\tif (crow < IPVS_EST_NTICKS - 1) {\n\t\t\tcrow++;\n\t\t\trow = find_last_bit(kd->avail, crow);\n\t\t}\n\t\tif (row >= crow)\n\t\t\trow = find_last_bit(kd->avail, IPVS_EST_NTICKS);\n\t} else {\n\t\t \n\t\trow = IPVS_EST_NTICKS;\n\t\tif (crow > 0)\n\t\t\trow = find_next_bit(kd->avail, IPVS_EST_NTICKS, crow);\n\t\tif (row >= IPVS_EST_NTICKS)\n\t\t\trow = find_first_bit(kd->avail, IPVS_EST_NTICKS);\n\t}\n\n\ttd = rcu_dereference_protected(kd->ticks[row], 1);\n\tif (!td) {\n\t\ttd = kzalloc(sizeof(*td), GFP_KERNEL);\n\t\tif (!td) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\trcu_assign_pointer(kd->ticks[row], td);\n\t}\n\n\tcid = find_first_zero_bit(td->full, IPVS_EST_TICK_CHAINS);\n\n\tkd->est_count++;\n\tkd->tick_len[row]++;\n\tif (!td->chain_len[cid])\n\t\t__set_bit(cid, td->present);\n\ttd->chain_len[cid]++;\n\test->ktid = ktid;\n\test->ktrow = row;\n\test->ktcid = cid;\n\thlist_add_head_rcu(&est->list, &td->chains[cid]);\n\n\tif (td->chain_len[cid] >= kd->chain_max) {\n\t\t__set_bit(cid, td->full);\n\t\tif (kd->tick_len[row] >= kd->tick_max)\n\t\t\t__clear_bit(row, kd->avail);\n\t}\n\n\t \n\tif (kd->est_count == kd->est_max_count)\n\t\tip_vs_est_update_ktid(ipvs);\n\n\tret = 0;\n\nout:\n\treturn ret;\n}\n\n \nint ip_vs_start_estimator(struct netns_ipvs *ipvs, struct ip_vs_stats *stats)\n{\n\tstruct ip_vs_estimator *est = &stats->est;\n\tint ret;\n\n\tif (!ipvs->est_max_threads && ipvs->enable)\n\t\tipvs->est_max_threads = ip_vs_est_max_threads(ipvs);\n\n\test->ktid = -1;\n\test->ktrow = IPVS_EST_NTICKS - 1;\t \n\n\t \n\tret = 0;\n\tif (!ipvs->est_kt_count || !ipvs->est_kt_arr[0])\n\t\tret = ip_vs_est_add_kthread(ipvs);\n\tif (ret >= 0)\n\t\thlist_add_head(&est->list, &ipvs->est_temp_list);\n\telse\n\t\tINIT_HLIST_NODE(&est->list);\n\treturn ret;\n}\n\nstatic void ip_vs_est_kthread_destroy(struct ip_vs_est_kt_data *kd)\n{\n\tif (kd) {\n\t\tif (kd->task) {\n\t\t\tpr_info(\"stop unused estimator thread %d...\\n\", kd->id);\n\t\t\tkthread_stop(kd->task);\n\t\t}\n\t\tip_vs_stats_free(kd->calc_stats);\n\t\tkfree(kd);\n\t}\n}\n\n \nvoid ip_vs_stop_estimator(struct netns_ipvs *ipvs, struct ip_vs_stats *stats)\n{\n\tstruct ip_vs_estimator *est = &stats->est;\n\tstruct ip_vs_est_tick_data *td;\n\tstruct ip_vs_est_kt_data *kd;\n\tint ktid = est->ktid;\n\tint row = est->ktrow;\n\tint cid = est->ktcid;\n\n\t \n\tif (hlist_unhashed(&est->list))\n\t\treturn;\n\n\t \n\n\t \n\tif (ktid < 0) {\n\t\thlist_del(&est->list);\n\t\tgoto end_kt0;\n\t}\n\n\thlist_del_rcu(&est->list);\n\tkd = ipvs->est_kt_arr[ktid];\n\ttd = rcu_dereference_protected(kd->ticks[row], 1);\n\t__clear_bit(cid, td->full);\n\ttd->chain_len[cid]--;\n\tif (!td->chain_len[cid])\n\t\t__clear_bit(cid, td->present);\n\tkd->tick_len[row]--;\n\t__set_bit(row, kd->avail);\n\tif (!kd->tick_len[row]) {\n\t\tRCU_INIT_POINTER(kd->ticks[row], NULL);\n\t\tkfree_rcu(td, rcu_head);\n\t}\n\tkd->est_count--;\n\tif (kd->est_count) {\n\t\t \n\t\tif (ktid < ipvs->est_add_ktid)\n\t\t\tipvs->est_add_ktid = ktid;\n\t\treturn;\n\t}\n\n\tif (ktid > 0) {\n\t\tmutex_lock(&ipvs->est_mutex);\n\t\tip_vs_est_kthread_destroy(kd);\n\t\tipvs->est_kt_arr[ktid] = NULL;\n\t\tif (ktid == ipvs->est_kt_count - 1) {\n\t\t\tipvs->est_kt_count--;\n\t\t\twhile (ipvs->est_kt_count > 1 &&\n\t\t\t       !ipvs->est_kt_arr[ipvs->est_kt_count - 1])\n\t\t\t\tipvs->est_kt_count--;\n\t\t}\n\t\tmutex_unlock(&ipvs->est_mutex);\n\n\t\t \n\t\tif (ktid == ipvs->est_add_ktid)\n\t\t\tip_vs_est_update_ktid(ipvs);\n\t}\n\nend_kt0:\n\t \n\tif (ipvs->est_kt_count == 1 && hlist_empty(&ipvs->est_temp_list)) {\n\t\tkd = ipvs->est_kt_arr[0];\n\t\tif (!kd || !kd->est_count) {\n\t\t\tmutex_lock(&ipvs->est_mutex);\n\t\t\tif (kd) {\n\t\t\t\tip_vs_est_kthread_destroy(kd);\n\t\t\t\tipvs->est_kt_arr[0] = NULL;\n\t\t\t}\n\t\t\tipvs->est_kt_count--;\n\t\t\tmutex_unlock(&ipvs->est_mutex);\n\t\t\tipvs->est_add_ktid = 0;\n\t\t}\n\t}\n}\n\n \nstatic void ip_vs_est_drain_temp_list(struct netns_ipvs *ipvs)\n{\n\tstruct ip_vs_estimator *est;\n\n\twhile (1) {\n\t\tint max = 16;\n\n\t\tmutex_lock(&__ip_vs_mutex);\n\n\t\twhile (max-- > 0) {\n\t\t\test = hlist_entry_safe(ipvs->est_temp_list.first,\n\t\t\t\t\t       struct ip_vs_estimator, list);\n\t\t\tif (est) {\n\t\t\t\tif (kthread_should_stop())\n\t\t\t\t\tgoto unlock;\n\t\t\t\thlist_del_init(&est->list);\n\t\t\t\tif (ip_vs_enqueue_estimator(ipvs, est) >= 0)\n\t\t\t\t\tcontinue;\n\t\t\t\test->ktid = -1;\n\t\t\t\thlist_add_head(&est->list,\n\t\t\t\t\t       &ipvs->est_temp_list);\n\t\t\t\t \n\t\t\t}\n\t\t\tgoto unlock;\n\t\t}\n\t\tmutex_unlock(&__ip_vs_mutex);\n\t\tcond_resched();\n\t}\n\nunlock:\n\tmutex_unlock(&__ip_vs_mutex);\n}\n\n \nstatic int ip_vs_est_calc_limits(struct netns_ipvs *ipvs, int *chain_max)\n{\n\tDECLARE_WAIT_QUEUE_HEAD_ONSTACK(wq);\n\tstruct ip_vs_est_kt_data *kd;\n\tstruct hlist_head chain;\n\tstruct ip_vs_stats *s;\n\tint cache_factor = 4;\n\tint i, loops, ntest;\n\ts32 min_est = 0;\n\tktime_t t1, t2;\n\tint max = 8;\n\tint ret = 1;\n\ts64 diff;\n\tu64 val;\n\n\tINIT_HLIST_HEAD(&chain);\n\tmutex_lock(&__ip_vs_mutex);\n\tkd = ipvs->est_kt_arr[0];\n\tmutex_unlock(&__ip_vs_mutex);\n\ts = kd ? kd->calc_stats : NULL;\n\tif (!s)\n\t\tgoto out;\n\thlist_add_head(&s->est.list, &chain);\n\n\tloops = 1;\n\t \n\tfor (ntest = 0; ntest < 12; ntest++) {\n\t\tif (!(ntest & 3)) {\n\t\t\t \n\t\t\twait_event_idle_timeout(wq, kthread_should_stop(),\n\t\t\t\t\t\tHZ / 50);\n\t\t\tif (!ipvs->enable || kthread_should_stop())\n\t\t\t\tgoto stop;\n\t\t}\n\n\t\tlocal_bh_disable();\n\t\trcu_read_lock();\n\n\t\t \n\t\tip_vs_chain_estimation(&chain);\n\n\t\tt1 = ktime_get();\n\t\tfor (i = loops * cache_factor; i > 0; i--)\n\t\t\tip_vs_chain_estimation(&chain);\n\t\tt2 = ktime_get();\n\n\t\trcu_read_unlock();\n\t\tlocal_bh_enable();\n\n\t\tif (!ipvs->enable || kthread_should_stop())\n\t\t\tgoto stop;\n\t\tcond_resched();\n\n\t\tdiff = ktime_to_ns(ktime_sub(t2, t1));\n\t\tif (diff <= 1 * NSEC_PER_USEC) {\n\t\t\t \n\t\t\tloops *= 2;\n\t\t\tcontinue;\n\t\t}\n\t\tif (diff >= NSEC_PER_SEC)\n\t\t\tcontinue;\n\t\tval = diff;\n\t\tdo_div(val, loops);\n\t\tif (!min_est || val < min_est) {\n\t\t\tmin_est = val;\n\t\t\t \n\t\t\tval = 95 * NSEC_PER_USEC;\n\t\t\tif (val >= min_est) {\n\t\t\t\tdo_div(val, min_est);\n\t\t\t\tmax = (int)val;\n\t\t\t} else {\n\t\t\t\tmax = 1;\n\t\t\t}\n\t\t}\n\t}\n\nout:\n\tif (s)\n\t\thlist_del_init(&s->est.list);\n\t*chain_max = max;\n\treturn ret;\n\nstop:\n\tret = 0;\n\tgoto out;\n}\n\n \nstatic void ip_vs_est_calc_phase(struct netns_ipvs *ipvs)\n{\n\tint genid = atomic_read(&ipvs->est_genid);\n\tstruct ip_vs_est_tick_data *td;\n\tstruct ip_vs_est_kt_data *kd;\n\tstruct ip_vs_estimator *est;\n\tstruct ip_vs_stats *stats;\n\tint id, row, cid, delay;\n\tbool last, last_td;\n\tint chain_max;\n\tint step;\n\n\tif (!ip_vs_est_calc_limits(ipvs, &chain_max))\n\t\treturn;\n\n\tmutex_lock(&__ip_vs_mutex);\n\n\t \n\tmutex_lock(&ipvs->est_mutex);\n\tfor (id = 1; id < ipvs->est_kt_count; id++) {\n\t\t \n\t\tif (!ipvs->enable)\n\t\t\tgoto unlock2;\n\t\tkd = ipvs->est_kt_arr[id];\n\t\tif (!kd)\n\t\t\tcontinue;\n\t\tip_vs_est_kthread_stop(kd);\n\t}\n\tmutex_unlock(&ipvs->est_mutex);\n\n\t \n\tstep = 0;\n\n\t \n\tdelay = IPVS_EST_NTICKS;\n\nnext_delay:\n\tdelay--;\n\tif (delay < 0)\n\t\tgoto end_dequeue;\n\nlast_kt:\n\t \n\tid = ipvs->est_kt_count;\n\nnext_kt:\n\tif (!ipvs->enable || kthread_should_stop())\n\t\tgoto unlock;\n\tid--;\n\tif (id < 0)\n\t\tgoto next_delay;\n\tkd = ipvs->est_kt_arr[id];\n\tif (!kd)\n\t\tgoto next_kt;\n\t \n\tif (!id && kd->est_count <= 1)\n\t\tgoto next_delay;\n\n\trow = kd->est_row + delay;\n\tif (row >= IPVS_EST_NTICKS)\n\t\trow -= IPVS_EST_NTICKS;\n\ttd = rcu_dereference_protected(kd->ticks[row], 1);\n\tif (!td)\n\t\tgoto next_kt;\n\n\tcid = 0;\n\nwalk_chain:\n\tif (kthread_should_stop())\n\t\tgoto unlock;\n\tstep++;\n\tif (!(step & 63)) {\n\t\t \n\t\tmutex_unlock(&__ip_vs_mutex);\n\t\tcond_resched();\n\t\tmutex_lock(&__ip_vs_mutex);\n\n\t\t \n\t\tif (id >= ipvs->est_kt_count)\n\t\t\tgoto last_kt;\n\t\tif (kd != ipvs->est_kt_arr[id])\n\t\t\tgoto next_kt;\n\t\t \n\t\tif (td != rcu_dereference_protected(kd->ticks[row], 1))\n\t\t\tgoto next_kt;\n\t\t \n\t}\n\test = hlist_entry_safe(td->chains[cid].first, struct ip_vs_estimator,\n\t\t\t       list);\n\tif (!est) {\n\t\tcid++;\n\t\tif (cid >= IPVS_EST_TICK_CHAINS)\n\t\t\tgoto next_kt;\n\t\tgoto walk_chain;\n\t}\n\t \n\tlast = kd->est_count <= 1;\n\t \n\tif (!id && last)\n\t\tgoto next_delay;\n\tlast_td = kd->tick_len[row] <= 1;\n\tstats = container_of(est, struct ip_vs_stats, est);\n\tip_vs_stop_estimator(ipvs, stats);\n\t \n\test->ktid = -1;\n\test->ktrow = row - kd->est_row;\n\tif (est->ktrow < 0)\n\t\test->ktrow += IPVS_EST_NTICKS;\n\thlist_add_head(&est->list, &ipvs->est_temp_list);\n\t \n\tif (last)\n\t\tgoto next_kt;\n\t \n\tif (last_td)\n\t\tgoto next_kt;\n\tgoto walk_chain;\n\nend_dequeue:\n\t \n\tif (!ipvs->est_kt_count)\n\t\tgoto unlock;\n\tkd = ipvs->est_kt_arr[0];\n\tif (!kd)\n\t\tgoto unlock;\n\tkd->add_row = kd->est_row;\n\tipvs->est_chain_max = chain_max;\n\tip_vs_est_set_params(ipvs, kd);\n\n\tpr_info(\"using max %d ests per chain, %d per kthread\\n\",\n\t\tkd->chain_max, kd->est_max_count);\n\n\t \n\tif (ipvs->tot_stats && !hlist_unhashed(&ipvs->tot_stats->s.est.list) &&\n\t    ipvs->tot_stats->s.est.ktid == -1) {\n\t\thlist_del(&ipvs->tot_stats->s.est.list);\n\t\thlist_add_head(&ipvs->tot_stats->s.est.list,\n\t\t\t       &ipvs->est_temp_list);\n\t}\n\n\tmutex_lock(&ipvs->est_mutex);\n\n\t \n\tif (genid == atomic_read(&ipvs->est_genid))\n\t\tipvs->est_calc_phase = 0;\n\nunlock2:\n\tmutex_unlock(&ipvs->est_mutex);\n\nunlock:\n\tmutex_unlock(&__ip_vs_mutex);\n}\n\nvoid ip_vs_zero_estimator(struct ip_vs_stats *stats)\n{\n\tstruct ip_vs_estimator *est = &stats->est;\n\tstruct ip_vs_kstats *k = &stats->kstats;\n\n\t \n\test->last_inbytes = k->inbytes;\n\test->last_outbytes = k->outbytes;\n\test->last_conns = k->conns;\n\test->last_inpkts = k->inpkts;\n\test->last_outpkts = k->outpkts;\n\test->cps = 0;\n\test->inpps = 0;\n\test->outpps = 0;\n\test->inbps = 0;\n\test->outbps = 0;\n}\n\n \nvoid ip_vs_read_estimator(struct ip_vs_kstats *dst, struct ip_vs_stats *stats)\n{\n\tstruct ip_vs_estimator *e = &stats->est;\n\n\tdst->cps = (e->cps + 0x1FF) >> 10;\n\tdst->inpps = (e->inpps + 0x1FF) >> 10;\n\tdst->outpps = (e->outpps + 0x1FF) >> 10;\n\tdst->inbps = (e->inbps + 0xF) >> 5;\n\tdst->outbps = (e->outbps + 0xF) >> 5;\n}\n\nint __net_init ip_vs_estimator_net_init(struct netns_ipvs *ipvs)\n{\n\tINIT_HLIST_HEAD(&ipvs->est_temp_list);\n\tipvs->est_kt_arr = NULL;\n\tipvs->est_max_threads = 0;\n\tipvs->est_calc_phase = 0;\n\tipvs->est_chain_max = 0;\n\tipvs->est_kt_count = 0;\n\tipvs->est_add_ktid = 0;\n\tatomic_set(&ipvs->est_genid, 0);\n\tatomic_set(&ipvs->est_genid_done, 0);\n\t__mutex_init(&ipvs->est_mutex, \"ipvs->est_mutex\", &__ipvs_est_key);\n\treturn 0;\n}\n\nvoid __net_exit ip_vs_estimator_net_cleanup(struct netns_ipvs *ipvs)\n{\n\tint i;\n\n\tfor (i = 0; i < ipvs->est_kt_count; i++)\n\t\tip_vs_est_kthread_destroy(ipvs->est_kt_arr[i]);\n\tkfree(ipvs->est_kt_arr);\n\tmutex_destroy(&ipvs->est_mutex);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}