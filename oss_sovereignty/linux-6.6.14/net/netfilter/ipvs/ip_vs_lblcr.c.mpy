{
  "module_name": "ip_vs_lblcr.c",
  "hash_id": "62230aed32195ef7d2a4a36ad30af03bdb3822eb8c307b9be3aa10ab8c4681cb",
  "original_prompt": "Ingested from linux-6.6.14/net/netfilter/ipvs/ip_vs_lblcr.c",
  "human_readable_source": "\n \n\n \n\n#define KMSG_COMPONENT \"IPVS\"\n#define pr_fmt(fmt) KMSG_COMPONENT \": \" fmt\n\n#include <linux/ip.h>\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/skbuff.h>\n#include <linux/jiffies.h>\n#include <linux/list.h>\n#include <linux/slab.h>\n#include <linux/hash.h>\n\n \n#include <linux/fs.h>\n#include <linux/sysctl.h>\n#include <net/net_namespace.h>\n\n#include <net/ip_vs.h>\n\n\n \n#define CHECK_EXPIRE_INTERVAL   (60*HZ)\n#define ENTRY_TIMEOUT           (6*60*HZ)\n\n#define DEFAULT_EXPIRATION\t(24*60*60*HZ)\n\n \n#define COUNT_FOR_FULL_EXPIRATION   30\n\n \n#ifndef CONFIG_IP_VS_LBLCR_TAB_BITS\n#define CONFIG_IP_VS_LBLCR_TAB_BITS      10\n#endif\n#define IP_VS_LBLCR_TAB_BITS     CONFIG_IP_VS_LBLCR_TAB_BITS\n#define IP_VS_LBLCR_TAB_SIZE     (1 << IP_VS_LBLCR_TAB_BITS)\n#define IP_VS_LBLCR_TAB_MASK     (IP_VS_LBLCR_TAB_SIZE - 1)\n\n\n \nstruct ip_vs_dest_set_elem {\n\tstruct list_head\tlist;           \n\tstruct ip_vs_dest\t*dest;\t\t \n\tstruct rcu_head\t\trcu_head;\n};\n\nstruct ip_vs_dest_set {\n\tatomic_t                size;            \n\tunsigned long           lastmod;         \n\tstruct list_head\tlist;            \n};\n\n\nstatic void ip_vs_dest_set_insert(struct ip_vs_dest_set *set,\n\t\t\t\t  struct ip_vs_dest *dest, bool check)\n{\n\tstruct ip_vs_dest_set_elem *e;\n\n\tif (check) {\n\t\tlist_for_each_entry(e, &set->list, list) {\n\t\t\tif (e->dest == dest)\n\t\t\t\treturn;\n\t\t}\n\t}\n\n\te = kmalloc(sizeof(*e), GFP_ATOMIC);\n\tif (e == NULL)\n\t\treturn;\n\n\tip_vs_dest_hold(dest);\n\te->dest = dest;\n\n\tlist_add_rcu(&e->list, &set->list);\n\tatomic_inc(&set->size);\n\n\tset->lastmod = jiffies;\n}\n\nstatic void ip_vs_lblcr_elem_rcu_free(struct rcu_head *head)\n{\n\tstruct ip_vs_dest_set_elem *e;\n\n\te = container_of(head, struct ip_vs_dest_set_elem, rcu_head);\n\tip_vs_dest_put_and_free(e->dest);\n\tkfree(e);\n}\n\nstatic void\nip_vs_dest_set_erase(struct ip_vs_dest_set *set, struct ip_vs_dest *dest)\n{\n\tstruct ip_vs_dest_set_elem *e;\n\n\tlist_for_each_entry(e, &set->list, list) {\n\t\tif (e->dest == dest) {\n\t\t\t \n\t\t\tatomic_dec(&set->size);\n\t\t\tset->lastmod = jiffies;\n\t\t\tlist_del_rcu(&e->list);\n\t\t\tcall_rcu(&e->rcu_head, ip_vs_lblcr_elem_rcu_free);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void ip_vs_dest_set_eraseall(struct ip_vs_dest_set *set)\n{\n\tstruct ip_vs_dest_set_elem *e, *ep;\n\n\tlist_for_each_entry_safe(e, ep, &set->list, list) {\n\t\tlist_del_rcu(&e->list);\n\t\tcall_rcu(&e->rcu_head, ip_vs_lblcr_elem_rcu_free);\n\t}\n}\n\n \nstatic inline struct ip_vs_dest *ip_vs_dest_set_min(struct ip_vs_dest_set *set)\n{\n\tstruct ip_vs_dest_set_elem *e;\n\tstruct ip_vs_dest *dest, *least;\n\tint loh, doh;\n\n\t \n\tlist_for_each_entry_rcu(e, &set->list, list) {\n\t\tleast = e->dest;\n\t\tif (least->flags & IP_VS_DEST_F_OVERLOAD)\n\t\t\tcontinue;\n\n\t\tif ((atomic_read(&least->weight) > 0)\n\t\t    && (least->flags & IP_VS_DEST_F_AVAILABLE)) {\n\t\t\tloh = ip_vs_dest_conn_overhead(least);\n\t\t\tgoto nextstage;\n\t\t}\n\t}\n\treturn NULL;\n\n\t \n  nextstage:\n\tlist_for_each_entry_continue_rcu(e, &set->list, list) {\n\t\tdest = e->dest;\n\t\tif (dest->flags & IP_VS_DEST_F_OVERLOAD)\n\t\t\tcontinue;\n\n\t\tdoh = ip_vs_dest_conn_overhead(dest);\n\t\tif (((__s64)loh * atomic_read(&dest->weight) >\n\t\t     (__s64)doh * atomic_read(&least->weight))\n\t\t    && (dest->flags & IP_VS_DEST_F_AVAILABLE)) {\n\t\t\tleast = dest;\n\t\t\tloh = doh;\n\t\t}\n\t}\n\n\tIP_VS_DBG_BUF(6, \"%s(): server %s:%d \"\n\t\t      \"activeconns %d refcnt %d weight %d overhead %d\\n\",\n\t\t      __func__,\n\t\t      IP_VS_DBG_ADDR(least->af, &least->addr),\n\t\t      ntohs(least->port),\n\t\t      atomic_read(&least->activeconns),\n\t\t      refcount_read(&least->refcnt),\n\t\t      atomic_read(&least->weight), loh);\n\treturn least;\n}\n\n\n \nstatic inline struct ip_vs_dest *ip_vs_dest_set_max(struct ip_vs_dest_set *set)\n{\n\tstruct ip_vs_dest_set_elem *e;\n\tstruct ip_vs_dest *dest, *most;\n\tint moh, doh;\n\n\tif (set == NULL)\n\t\treturn NULL;\n\n\t \n\tlist_for_each_entry(e, &set->list, list) {\n\t\tmost = e->dest;\n\t\tif (atomic_read(&most->weight) > 0) {\n\t\t\tmoh = ip_vs_dest_conn_overhead(most);\n\t\t\tgoto nextstage;\n\t\t}\n\t}\n\treturn NULL;\n\n\t \n  nextstage:\n\tlist_for_each_entry_continue(e, &set->list, list) {\n\t\tdest = e->dest;\n\t\tdoh = ip_vs_dest_conn_overhead(dest);\n\t\t \n\t\tif (((__s64)moh * atomic_read(&dest->weight) <\n\t\t     (__s64)doh * atomic_read(&most->weight))\n\t\t    && (atomic_read(&dest->weight) > 0)) {\n\t\t\tmost = dest;\n\t\t\tmoh = doh;\n\t\t}\n\t}\n\n\tIP_VS_DBG_BUF(6, \"%s(): server %s:%d \"\n\t\t      \"activeconns %d refcnt %d weight %d overhead %d\\n\",\n\t\t      __func__,\n\t\t      IP_VS_DBG_ADDR(most->af, &most->addr), ntohs(most->port),\n\t\t      atomic_read(&most->activeconns),\n\t\t      refcount_read(&most->refcnt),\n\t\t      atomic_read(&most->weight), moh);\n\treturn most;\n}\n\n\n \nstruct ip_vs_lblcr_entry {\n\tstruct hlist_node       list;\n\tint\t\t\taf;\t\t \n\tunion nf_inet_addr      addr;            \n\tstruct ip_vs_dest_set   set;             \n\tunsigned long           lastuse;         \n\tstruct rcu_head\t\trcu_head;\n};\n\n\n \nstruct ip_vs_lblcr_table {\n\tstruct rcu_head\t\trcu_head;\n\tstruct hlist_head\tbucket[IP_VS_LBLCR_TAB_SIZE];   \n\tatomic_t                entries;         \n\tint                     max_size;        \n\tstruct timer_list       periodic_timer;  \n\tstruct ip_vs_service\t*svc;\t\t \n\tint                     rover;           \n\tint                     counter;         \n\tbool\t\t\tdead;\n};\n\n\n#ifdef CONFIG_SYSCTL\n \n\nstatic struct ctl_table vs_vars_table[] = {\n\t{\n\t\t.procname\t= \"lblcr_expiration\",\n\t\t.data\t\t= NULL,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{ }\n};\n#endif\n\nstatic inline void ip_vs_lblcr_free(struct ip_vs_lblcr_entry *en)\n{\n\thlist_del_rcu(&en->list);\n\tip_vs_dest_set_eraseall(&en->set);\n\tkfree_rcu(en, rcu_head);\n}\n\n\n \nstatic inline unsigned int\nip_vs_lblcr_hashkey(int af, const union nf_inet_addr *addr)\n{\n\t__be32 addr_fold = addr->ip;\n\n#ifdef CONFIG_IP_VS_IPV6\n\tif (af == AF_INET6)\n\t\taddr_fold = addr->ip6[0]^addr->ip6[1]^\n\t\t\t    addr->ip6[2]^addr->ip6[3];\n#endif\n\treturn hash_32(ntohl(addr_fold), IP_VS_LBLCR_TAB_BITS);\n}\n\n\n \nstatic void\nip_vs_lblcr_hash(struct ip_vs_lblcr_table *tbl, struct ip_vs_lblcr_entry *en)\n{\n\tunsigned int hash = ip_vs_lblcr_hashkey(en->af, &en->addr);\n\n\thlist_add_head_rcu(&en->list, &tbl->bucket[hash]);\n\tatomic_inc(&tbl->entries);\n}\n\n\n \nstatic inline struct ip_vs_lblcr_entry *\nip_vs_lblcr_get(int af, struct ip_vs_lblcr_table *tbl,\n\t\tconst union nf_inet_addr *addr)\n{\n\tunsigned int hash = ip_vs_lblcr_hashkey(af, addr);\n\tstruct ip_vs_lblcr_entry *en;\n\n\thlist_for_each_entry_rcu(en, &tbl->bucket[hash], list)\n\t\tif (ip_vs_addr_equal(af, &en->addr, addr))\n\t\t\treturn en;\n\n\treturn NULL;\n}\n\n\n \nstatic inline struct ip_vs_lblcr_entry *\nip_vs_lblcr_new(struct ip_vs_lblcr_table *tbl, const union nf_inet_addr *daddr,\n\t\tu16 af, struct ip_vs_dest *dest)\n{\n\tstruct ip_vs_lblcr_entry *en;\n\n\ten = ip_vs_lblcr_get(af, tbl, daddr);\n\tif (!en) {\n\t\ten = kmalloc(sizeof(*en), GFP_ATOMIC);\n\t\tif (!en)\n\t\t\treturn NULL;\n\n\t\ten->af = af;\n\t\tip_vs_addr_copy(af, &en->addr, daddr);\n\t\ten->lastuse = jiffies;\n\n\t\t \n\t\tatomic_set(&(en->set.size), 0);\n\t\tINIT_LIST_HEAD(&en->set.list);\n\n\t\tip_vs_dest_set_insert(&en->set, dest, false);\n\n\t\tip_vs_lblcr_hash(tbl, en);\n\t\treturn en;\n\t}\n\n\tip_vs_dest_set_insert(&en->set, dest, true);\n\n\treturn en;\n}\n\n\n \nstatic void ip_vs_lblcr_flush(struct ip_vs_service *svc)\n{\n\tstruct ip_vs_lblcr_table *tbl = svc->sched_data;\n\tint i;\n\tstruct ip_vs_lblcr_entry *en;\n\tstruct hlist_node *next;\n\n\tspin_lock_bh(&svc->sched_lock);\n\ttbl->dead = true;\n\tfor (i = 0; i < IP_VS_LBLCR_TAB_SIZE; i++) {\n\t\thlist_for_each_entry_safe(en, next, &tbl->bucket[i], list) {\n\t\t\tip_vs_lblcr_free(en);\n\t\t}\n\t}\n\tspin_unlock_bh(&svc->sched_lock);\n}\n\nstatic int sysctl_lblcr_expiration(struct ip_vs_service *svc)\n{\n#ifdef CONFIG_SYSCTL\n\treturn svc->ipvs->sysctl_lblcr_expiration;\n#else\n\treturn DEFAULT_EXPIRATION;\n#endif\n}\n\nstatic inline void ip_vs_lblcr_full_check(struct ip_vs_service *svc)\n{\n\tstruct ip_vs_lblcr_table *tbl = svc->sched_data;\n\tunsigned long now = jiffies;\n\tint i, j;\n\tstruct ip_vs_lblcr_entry *en;\n\tstruct hlist_node *next;\n\n\tfor (i = 0, j = tbl->rover; i < IP_VS_LBLCR_TAB_SIZE; i++) {\n\t\tj = (j + 1) & IP_VS_LBLCR_TAB_MASK;\n\n\t\tspin_lock(&svc->sched_lock);\n\t\thlist_for_each_entry_safe(en, next, &tbl->bucket[j], list) {\n\t\t\tif (time_after(en->lastuse +\n\t\t\t\t       sysctl_lblcr_expiration(svc), now))\n\t\t\t\tcontinue;\n\n\t\t\tip_vs_lblcr_free(en);\n\t\t\tatomic_dec(&tbl->entries);\n\t\t}\n\t\tspin_unlock(&svc->sched_lock);\n\t}\n\ttbl->rover = j;\n}\n\n\n \nstatic void ip_vs_lblcr_check_expire(struct timer_list *t)\n{\n\tstruct ip_vs_lblcr_table *tbl = from_timer(tbl, t, periodic_timer);\n\tstruct ip_vs_service *svc = tbl->svc;\n\tunsigned long now = jiffies;\n\tint goal;\n\tint i, j;\n\tstruct ip_vs_lblcr_entry *en;\n\tstruct hlist_node *next;\n\n\tif ((tbl->counter % COUNT_FOR_FULL_EXPIRATION) == 0) {\n\t\t \n\t\tip_vs_lblcr_full_check(svc);\n\t\ttbl->counter = 1;\n\t\tgoto out;\n\t}\n\n\tif (atomic_read(&tbl->entries) <= tbl->max_size) {\n\t\ttbl->counter++;\n\t\tgoto out;\n\t}\n\n\tgoal = (atomic_read(&tbl->entries) - tbl->max_size)*4/3;\n\tif (goal > tbl->max_size/2)\n\t\tgoal = tbl->max_size/2;\n\n\tfor (i = 0, j = tbl->rover; i < IP_VS_LBLCR_TAB_SIZE; i++) {\n\t\tj = (j + 1) & IP_VS_LBLCR_TAB_MASK;\n\n\t\tspin_lock(&svc->sched_lock);\n\t\thlist_for_each_entry_safe(en, next, &tbl->bucket[j], list) {\n\t\t\tif (time_before(now, en->lastuse+ENTRY_TIMEOUT))\n\t\t\t\tcontinue;\n\n\t\t\tip_vs_lblcr_free(en);\n\t\t\tatomic_dec(&tbl->entries);\n\t\t\tgoal--;\n\t\t}\n\t\tspin_unlock(&svc->sched_lock);\n\t\tif (goal <= 0)\n\t\t\tbreak;\n\t}\n\ttbl->rover = j;\n\n  out:\n\tmod_timer(&tbl->periodic_timer, jiffies+CHECK_EXPIRE_INTERVAL);\n}\n\nstatic int ip_vs_lblcr_init_svc(struct ip_vs_service *svc)\n{\n\tint i;\n\tstruct ip_vs_lblcr_table *tbl;\n\n\t \n\ttbl = kmalloc(sizeof(*tbl), GFP_KERNEL);\n\tif (tbl == NULL)\n\t\treturn -ENOMEM;\n\n\tsvc->sched_data = tbl;\n\tIP_VS_DBG(6, \"LBLCR hash table (memory=%zdbytes) allocated for \"\n\t\t  \"current service\\n\", sizeof(*tbl));\n\n\t \n\tfor (i = 0; i < IP_VS_LBLCR_TAB_SIZE; i++) {\n\t\tINIT_HLIST_HEAD(&tbl->bucket[i]);\n\t}\n\ttbl->max_size = IP_VS_LBLCR_TAB_SIZE*16;\n\ttbl->rover = 0;\n\ttbl->counter = 1;\n\ttbl->dead = false;\n\ttbl->svc = svc;\n\tatomic_set(&tbl->entries, 0);\n\n\t \n\ttimer_setup(&tbl->periodic_timer, ip_vs_lblcr_check_expire, 0);\n\tmod_timer(&tbl->periodic_timer, jiffies + CHECK_EXPIRE_INTERVAL);\n\n\treturn 0;\n}\n\n\nstatic void ip_vs_lblcr_done_svc(struct ip_vs_service *svc)\n{\n\tstruct ip_vs_lblcr_table *tbl = svc->sched_data;\n\n\t \n\ttimer_shutdown_sync(&tbl->periodic_timer);\n\n\t \n\tip_vs_lblcr_flush(svc);\n\n\t \n\tkfree_rcu(tbl, rcu_head);\n\tIP_VS_DBG(6, \"LBLCR hash table (memory=%zdbytes) released\\n\",\n\t\t  sizeof(*tbl));\n}\n\n\nstatic inline struct ip_vs_dest *\n__ip_vs_lblcr_schedule(struct ip_vs_service *svc)\n{\n\tstruct ip_vs_dest *dest, *least;\n\tint loh, doh;\n\n\t \n\tlist_for_each_entry_rcu(dest, &svc->destinations, n_list) {\n\t\tif (dest->flags & IP_VS_DEST_F_OVERLOAD)\n\t\t\tcontinue;\n\n\t\tif (atomic_read(&dest->weight) > 0) {\n\t\t\tleast = dest;\n\t\t\tloh = ip_vs_dest_conn_overhead(least);\n\t\t\tgoto nextstage;\n\t\t}\n\t}\n\treturn NULL;\n\n\t \n  nextstage:\n\tlist_for_each_entry_continue_rcu(dest, &svc->destinations, n_list) {\n\t\tif (dest->flags & IP_VS_DEST_F_OVERLOAD)\n\t\t\tcontinue;\n\n\t\tdoh = ip_vs_dest_conn_overhead(dest);\n\t\tif ((__s64)loh * atomic_read(&dest->weight) >\n\t\t    (__s64)doh * atomic_read(&least->weight)) {\n\t\t\tleast = dest;\n\t\t\tloh = doh;\n\t\t}\n\t}\n\n\tIP_VS_DBG_BUF(6, \"LBLCR: server %s:%d \"\n\t\t      \"activeconns %d refcnt %d weight %d overhead %d\\n\",\n\t\t      IP_VS_DBG_ADDR(least->af, &least->addr),\n\t\t      ntohs(least->port),\n\t\t      atomic_read(&least->activeconns),\n\t\t      refcount_read(&least->refcnt),\n\t\t      atomic_read(&least->weight), loh);\n\n\treturn least;\n}\n\n\n \nstatic inline int\nis_overloaded(struct ip_vs_dest *dest, struct ip_vs_service *svc)\n{\n\tif (atomic_read(&dest->activeconns) > atomic_read(&dest->weight)) {\n\t\tstruct ip_vs_dest *d;\n\n\t\tlist_for_each_entry_rcu(d, &svc->destinations, n_list) {\n\t\t\tif (atomic_read(&d->activeconns)*2\n\t\t\t    < atomic_read(&d->weight)) {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n\n \nstatic struct ip_vs_dest *\nip_vs_lblcr_schedule(struct ip_vs_service *svc, const struct sk_buff *skb,\n\t\t     struct ip_vs_iphdr *iph)\n{\n\tstruct ip_vs_lblcr_table *tbl = svc->sched_data;\n\tstruct ip_vs_dest *dest;\n\tstruct ip_vs_lblcr_entry *en;\n\n\tIP_VS_DBG(6, \"%s(): Scheduling...\\n\", __func__);\n\n\t \n\ten = ip_vs_lblcr_get(svc->af, tbl, &iph->daddr);\n\tif (en) {\n\t\ten->lastuse = jiffies;\n\n\t\t \n\t\tdest = ip_vs_dest_set_min(&en->set);\n\n\t\t \n\t\tif (atomic_read(&en->set.size) > 1 &&\n\t\t    time_after(jiffies, en->set.lastmod +\n\t\t\t\tsysctl_lblcr_expiration(svc))) {\n\t\t\tspin_lock_bh(&svc->sched_lock);\n\t\t\tif (atomic_read(&en->set.size) > 1) {\n\t\t\t\tstruct ip_vs_dest *m;\n\n\t\t\t\tm = ip_vs_dest_set_max(&en->set);\n\t\t\t\tif (m)\n\t\t\t\t\tip_vs_dest_set_erase(&en->set, m);\n\t\t\t}\n\t\t\tspin_unlock_bh(&svc->sched_lock);\n\t\t}\n\n\t\t \n\t\tif (dest && !is_overloaded(dest, svc))\n\t\t\tgoto out;\n\n\t\t \n\t\tdest = __ip_vs_lblcr_schedule(svc);\n\t\tif (!dest) {\n\t\t\tip_vs_scheduler_err(svc, \"no destination available\");\n\t\t\treturn NULL;\n\t\t}\n\n\t\t \n\t\tspin_lock_bh(&svc->sched_lock);\n\t\tif (!tbl->dead)\n\t\t\tip_vs_dest_set_insert(&en->set, dest, true);\n\t\tspin_unlock_bh(&svc->sched_lock);\n\t\tgoto out;\n\t}\n\n\t \n\tdest = __ip_vs_lblcr_schedule(svc);\n\tif (!dest) {\n\t\tIP_VS_DBG(1, \"no destination available\\n\");\n\t\treturn NULL;\n\t}\n\n\t \n\tspin_lock_bh(&svc->sched_lock);\n\tif (!tbl->dead)\n\t\tip_vs_lblcr_new(tbl, &iph->daddr, svc->af, dest);\n\tspin_unlock_bh(&svc->sched_lock);\n\nout:\n\tIP_VS_DBG_BUF(6, \"LBLCR: destination IP address %s --> server %s:%d\\n\",\n\t\t      IP_VS_DBG_ADDR(svc->af, &iph->daddr),\n\t\t      IP_VS_DBG_ADDR(dest->af, &dest->addr), ntohs(dest->port));\n\n\treturn dest;\n}\n\n\n \nstatic struct ip_vs_scheduler ip_vs_lblcr_scheduler =\n{\n\t.name =\t\t\t\"lblcr\",\n\t.refcnt =\t\tATOMIC_INIT(0),\n\t.module =\t\tTHIS_MODULE,\n\t.n_list =\t\tLIST_HEAD_INIT(ip_vs_lblcr_scheduler.n_list),\n\t.init_service =\t\tip_vs_lblcr_init_svc,\n\t.done_service =\t\tip_vs_lblcr_done_svc,\n\t.schedule =\t\tip_vs_lblcr_schedule,\n};\n\n \n#ifdef CONFIG_SYSCTL\nstatic int __net_init __ip_vs_lblcr_init(struct net *net)\n{\n\tstruct netns_ipvs *ipvs = net_ipvs(net);\n\tsize_t vars_table_size = ARRAY_SIZE(vs_vars_table);\n\n\tif (!ipvs)\n\t\treturn -ENOENT;\n\n\tif (!net_eq(net, &init_net)) {\n\t\tipvs->lblcr_ctl_table = kmemdup(vs_vars_table,\n\t\t\t\t\t\tsizeof(vs_vars_table),\n\t\t\t\t\t\tGFP_KERNEL);\n\t\tif (ipvs->lblcr_ctl_table == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\t \n\t\tif (net->user_ns != &init_user_ns) {\n\t\t\tipvs->lblcr_ctl_table[0].procname = NULL;\n\t\t\tvars_table_size = 0;\n\t\t}\n\t} else\n\t\tipvs->lblcr_ctl_table = vs_vars_table;\n\tipvs->sysctl_lblcr_expiration = DEFAULT_EXPIRATION;\n\tipvs->lblcr_ctl_table[0].data = &ipvs->sysctl_lblcr_expiration;\n\n\tipvs->lblcr_ctl_header = register_net_sysctl_sz(net, \"net/ipv4/vs\",\n\t\t\t\t\t\t\tipvs->lblcr_ctl_table,\n\t\t\t\t\t\t\tvars_table_size);\n\tif (!ipvs->lblcr_ctl_header) {\n\t\tif (!net_eq(net, &init_net))\n\t\t\tkfree(ipvs->lblcr_ctl_table);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic void __net_exit __ip_vs_lblcr_exit(struct net *net)\n{\n\tstruct netns_ipvs *ipvs = net_ipvs(net);\n\n\tunregister_net_sysctl_table(ipvs->lblcr_ctl_header);\n\n\tif (!net_eq(net, &init_net))\n\t\tkfree(ipvs->lblcr_ctl_table);\n}\n\n#else\n\nstatic int __net_init __ip_vs_lblcr_init(struct net *net) { return 0; }\nstatic void __net_exit __ip_vs_lblcr_exit(struct net *net) { }\n\n#endif\n\nstatic struct pernet_operations ip_vs_lblcr_ops = {\n\t.init = __ip_vs_lblcr_init,\n\t.exit = __ip_vs_lblcr_exit,\n};\n\nstatic int __init ip_vs_lblcr_init(void)\n{\n\tint ret;\n\n\tret = register_pernet_subsys(&ip_vs_lblcr_ops);\n\tif (ret)\n\t\treturn ret;\n\n\tret = register_ip_vs_scheduler(&ip_vs_lblcr_scheduler);\n\tif (ret)\n\t\tunregister_pernet_subsys(&ip_vs_lblcr_ops);\n\treturn ret;\n}\n\nstatic void __exit ip_vs_lblcr_cleanup(void)\n{\n\tunregister_ip_vs_scheduler(&ip_vs_lblcr_scheduler);\n\tunregister_pernet_subsys(&ip_vs_lblcr_ops);\n\trcu_barrier();\n}\n\n\nmodule_init(ip_vs_lblcr_init);\nmodule_exit(ip_vs_lblcr_cleanup);\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}