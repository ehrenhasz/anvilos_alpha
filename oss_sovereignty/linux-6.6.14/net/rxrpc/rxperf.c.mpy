{
  "module_name": "rxperf.c",
  "hash_id": "421c4cd605d7ec27672b056898857f755fa75eaf61135c3481799b69870cb87e",
  "original_prompt": "Ingested from linux-6.6.14/net/rxrpc/rxperf.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"rxperf: \" fmt\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <net/sock.h>\n#include <net/af_rxrpc.h>\n#define RXRPC_TRACE_ONLY_DEFINE_ENUMS\n#include <trace/events/rxrpc.h>\n\nMODULE_DESCRIPTION(\"rxperf test server (afs)\");\nMODULE_AUTHOR(\"Red Hat, Inc.\");\nMODULE_LICENSE(\"GPL\");\n\n#define RXPERF_PORT\t\t7009\n#define RX_PERF_SERVICE\t\t147\n#define RX_PERF_VERSION\t\t3\n#define RX_PERF_SEND\t\t0\n#define RX_PERF_RECV\t\t1\n#define RX_PERF_RPC\t\t3\n#define RX_PERF_FILE\t\t4\n#define RX_PERF_MAGIC_COOKIE\t0x4711\n\nstruct rxperf_proto_params {\n\t__be32\t\tversion;\n\t__be32\t\ttype;\n\t__be32\t\trsize;\n\t__be32\t\twsize;\n} __packed;\n\nstatic const u8 rxperf_magic_cookie[] = { 0x00, 0x00, 0x47, 0x11 };\nstatic const u8 secret[8] = { 0xa7, 0x83, 0x8a, 0xcb, 0xc7, 0x83, 0xec, 0x94 };\n\nenum rxperf_call_state {\n\tRXPERF_CALL_SV_AWAIT_PARAMS,\t \n\tRXPERF_CALL_SV_AWAIT_REQUEST,\t \n\tRXPERF_CALL_SV_REPLYING,\t \n\tRXPERF_CALL_SV_AWAIT_ACK,\t \n\tRXPERF_CALL_COMPLETE,\t\t \n};\n\nstruct rxperf_call {\n\tstruct rxrpc_call\t*rxcall;\n\tstruct iov_iter\t\titer;\n\tstruct kvec\t\tkvec[1];\n\tstruct work_struct\twork;\n\tconst char\t\t*type;\n\tsize_t\t\t\tiov_len;\n\tsize_t\t\t\treq_len;\t \n\tsize_t\t\t\treply_len;\t \n\tunsigned int\t\tdebug_id;\n\tunsigned int\t\toperation_id;\n\tstruct rxperf_proto_params params;\n\t__be32\t\t\ttmp[2];\n\ts32\t\t\tabort_code;\n\tenum rxperf_call_state\tstate;\n\tshort\t\t\terror;\n\tunsigned short\t\tunmarshal;\n\tu16\t\t\tservice_id;\n\tint (*deliver)(struct rxperf_call *call);\n\tvoid (*processor)(struct work_struct *work);\n};\n\nstatic struct socket *rxperf_socket;\nstatic struct key *rxperf_sec_keyring;\t \nstatic struct workqueue_struct *rxperf_workqueue;\n\nstatic void rxperf_deliver_to_call(struct work_struct *work);\nstatic int rxperf_deliver_param_block(struct rxperf_call *call);\nstatic int rxperf_deliver_request(struct rxperf_call *call);\nstatic int rxperf_process_call(struct rxperf_call *call);\nstatic void rxperf_charge_preallocation(struct work_struct *work);\n\nstatic DECLARE_WORK(rxperf_charge_preallocation_work,\n\t\t    rxperf_charge_preallocation);\n\nstatic inline void rxperf_set_call_state(struct rxperf_call *call,\n\t\t\t\t\t enum rxperf_call_state to)\n{\n\tcall->state = to;\n}\n\nstatic inline void rxperf_set_call_complete(struct rxperf_call *call,\n\t\t\t\t\t    int error, s32 remote_abort)\n{\n\tif (call->state != RXPERF_CALL_COMPLETE) {\n\t\tcall->abort_code = remote_abort;\n\t\tcall->error = error;\n\t\tcall->state = RXPERF_CALL_COMPLETE;\n\t}\n}\n\nstatic void rxperf_rx_discard_new_call(struct rxrpc_call *rxcall,\n\t\t\t\t       unsigned long user_call_ID)\n{\n\tkfree((struct rxperf_call *)user_call_ID);\n}\n\nstatic void rxperf_rx_new_call(struct sock *sk, struct rxrpc_call *rxcall,\n\t\t\t       unsigned long user_call_ID)\n{\n\tqueue_work(rxperf_workqueue, &rxperf_charge_preallocation_work);\n}\n\nstatic void rxperf_queue_call_work(struct rxperf_call *call)\n{\n\tqueue_work(rxperf_workqueue, &call->work);\n}\n\nstatic void rxperf_notify_rx(struct sock *sk, struct rxrpc_call *rxcall,\n\t\t\t     unsigned long call_user_ID)\n{\n\tstruct rxperf_call *call = (struct rxperf_call *)call_user_ID;\n\n\tif (call->state != RXPERF_CALL_COMPLETE)\n\t\trxperf_queue_call_work(call);\n}\n\nstatic void rxperf_rx_attach(struct rxrpc_call *rxcall, unsigned long user_call_ID)\n{\n\tstruct rxperf_call *call = (struct rxperf_call *)user_call_ID;\n\n\tcall->rxcall = rxcall;\n}\n\nstatic void rxperf_notify_end_reply_tx(struct sock *sock,\n\t\t\t\t       struct rxrpc_call *rxcall,\n\t\t\t\t       unsigned long call_user_ID)\n{\n\trxperf_set_call_state((struct rxperf_call *)call_user_ID,\n\t\t\t      RXPERF_CALL_SV_AWAIT_ACK);\n}\n\n \nstatic void rxperf_charge_preallocation(struct work_struct *work)\n{\n\tstruct rxperf_call *call;\n\n\tfor (;;) {\n\t\tcall = kzalloc(sizeof(*call), GFP_KERNEL);\n\t\tif (!call)\n\t\t\tbreak;\n\n\t\tcall->type\t\t= \"unset\";\n\t\tcall->debug_id\t\t= atomic_inc_return(&rxrpc_debug_id);\n\t\tcall->deliver\t\t= rxperf_deliver_param_block;\n\t\tcall->state\t\t= RXPERF_CALL_SV_AWAIT_PARAMS;\n\t\tcall->service_id\t= RX_PERF_SERVICE;\n\t\tcall->iov_len\t\t= sizeof(call->params);\n\t\tcall->kvec[0].iov_len\t= sizeof(call->params);\n\t\tcall->kvec[0].iov_base\t= &call->params;\n\t\tiov_iter_kvec(&call->iter, READ, call->kvec, 1, call->iov_len);\n\t\tINIT_WORK(&call->work, rxperf_deliver_to_call);\n\n\t\tif (rxrpc_kernel_charge_accept(rxperf_socket,\n\t\t\t\t\t       rxperf_notify_rx,\n\t\t\t\t\t       rxperf_rx_attach,\n\t\t\t\t\t       (unsigned long)call,\n\t\t\t\t\t       GFP_KERNEL,\n\t\t\t\t\t       call->debug_id) < 0)\n\t\t\tbreak;\n\t\tcall = NULL;\n\t}\n\n\tkfree(call);\n}\n\n \nstatic int rxperf_open_socket(void)\n{\n\tstruct sockaddr_rxrpc srx;\n\tstruct socket *socket;\n\tint ret;\n\n\tret = sock_create_kern(&init_net, AF_RXRPC, SOCK_DGRAM, PF_INET6,\n\t\t\t       &socket);\n\tif (ret < 0)\n\t\tgoto error_1;\n\n\tsocket->sk->sk_allocation = GFP_NOFS;\n\n\t \n\tmemset(&srx, 0, sizeof(srx));\n\tsrx.srx_family\t\t\t= AF_RXRPC;\n\tsrx.srx_service\t\t\t= RX_PERF_SERVICE;\n\tsrx.transport_type\t\t= SOCK_DGRAM;\n\tsrx.transport_len\t\t= sizeof(srx.transport.sin6);\n\tsrx.transport.sin6.sin6_family\t= AF_INET6;\n\tsrx.transport.sin6.sin6_port\t= htons(RXPERF_PORT);\n\n\tret = rxrpc_sock_set_min_security_level(socket->sk,\n\t\t\t\t\t\tRXRPC_SECURITY_ENCRYPT);\n\tif (ret < 0)\n\t\tgoto error_2;\n\n\tret = rxrpc_sock_set_security_keyring(socket->sk, rxperf_sec_keyring);\n\n\tret = kernel_bind(socket, (struct sockaddr *)&srx, sizeof(srx));\n\tif (ret < 0)\n\t\tgoto error_2;\n\n\trxrpc_kernel_new_call_notification(socket, rxperf_rx_new_call,\n\t\t\t\t\t   rxperf_rx_discard_new_call);\n\n\tret = kernel_listen(socket, INT_MAX);\n\tif (ret < 0)\n\t\tgoto error_2;\n\n\trxperf_socket = socket;\n\trxperf_charge_preallocation(&rxperf_charge_preallocation_work);\n\treturn 0;\n\nerror_2:\n\tsock_release(socket);\nerror_1:\n\tpr_err(\"Can't set up rxperf socket: %d\\n\", ret);\n\treturn ret;\n}\n\n \nstatic void rxperf_close_socket(void)\n{\n\tkernel_listen(rxperf_socket, 0);\n\tkernel_sock_shutdown(rxperf_socket, SHUT_RDWR);\n\tflush_workqueue(rxperf_workqueue);\n\tsock_release(rxperf_socket);\n}\n\n \nstatic void rxperf_log_error(struct rxperf_call *call, s32 remote_abort)\n{\n\tstatic int max = 0;\n\tconst char *msg;\n\tint m;\n\n\tswitch (remote_abort) {\n\tcase RX_EOF:\t\t msg = \"unexpected EOF\";\tbreak;\n\tcase RXGEN_CC_MARSHAL:\t msg = \"client marshalling\";\tbreak;\n\tcase RXGEN_CC_UNMARSHAL: msg = \"client unmarshalling\";\tbreak;\n\tcase RXGEN_SS_MARSHAL:\t msg = \"server marshalling\";\tbreak;\n\tcase RXGEN_SS_UNMARSHAL: msg = \"server unmarshalling\";\tbreak;\n\tcase RXGEN_DECODE:\t msg = \"opcode decode\";\t\tbreak;\n\tcase RXGEN_SS_XDRFREE:\t msg = \"server XDR cleanup\";\tbreak;\n\tcase RXGEN_CC_XDRFREE:\t msg = \"client XDR cleanup\";\tbreak;\n\tcase -32:\t\t msg = \"insufficient data\";\tbreak;\n\tdefault:\n\t\treturn;\n\t}\n\n\tm = max;\n\tif (m < 3) {\n\t\tmax = m + 1;\n\t\tpr_info(\"Peer reported %s failure on %s\\n\", msg, call->type);\n\t}\n}\n\n \nstatic void rxperf_deliver_to_call(struct work_struct *work)\n{\n\tstruct rxperf_call *call = container_of(work, struct rxperf_call, work);\n\tenum rxperf_call_state state;\n\tu32 abort_code, remote_abort = 0;\n\tint ret = 0;\n\n\tif (call->state == RXPERF_CALL_COMPLETE)\n\t\treturn;\n\n\twhile (state = call->state,\n\t       state == RXPERF_CALL_SV_AWAIT_PARAMS ||\n\t       state == RXPERF_CALL_SV_AWAIT_REQUEST ||\n\t       state == RXPERF_CALL_SV_AWAIT_ACK\n\t       ) {\n\t\tif (state == RXPERF_CALL_SV_AWAIT_ACK) {\n\t\t\tif (!rxrpc_kernel_check_life(rxperf_socket, call->rxcall))\n\t\t\t\tgoto call_complete;\n\t\t\treturn;\n\t\t}\n\n\t\tret = call->deliver(call);\n\t\tif (ret == 0)\n\t\t\tret = rxperf_process_call(call);\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\tcontinue;\n\t\tcase -EINPROGRESS:\n\t\tcase -EAGAIN:\n\t\t\treturn;\n\t\tcase -ECONNABORTED:\n\t\t\trxperf_log_error(call, call->abort_code);\n\t\t\tgoto call_complete;\n\t\tcase -EOPNOTSUPP:\n\t\t\tabort_code = RXGEN_OPCODE;\n\t\t\trxrpc_kernel_abort_call(rxperf_socket, call->rxcall,\n\t\t\t\t\t\tabort_code, ret,\n\t\t\t\t\t\trxperf_abort_op_not_supported);\n\t\t\tgoto call_complete;\n\t\tcase -ENOTSUPP:\n\t\t\tabort_code = RX_USER_ABORT;\n\t\t\trxrpc_kernel_abort_call(rxperf_socket, call->rxcall,\n\t\t\t\t\t\tabort_code, ret,\n\t\t\t\t\t\trxperf_abort_op_not_supported);\n\t\t\tgoto call_complete;\n\t\tcase -EIO:\n\t\t\tpr_err(\"Call %u in bad state %u\\n\",\n\t\t\t       call->debug_id, call->state);\n\t\t\tfallthrough;\n\t\tcase -ENODATA:\n\t\tcase -EBADMSG:\n\t\tcase -EMSGSIZE:\n\t\tcase -ENOMEM:\n\t\tcase -EFAULT:\n\t\t\trxrpc_kernel_abort_call(rxperf_socket, call->rxcall,\n\t\t\t\t\t\tRXGEN_SS_UNMARSHAL, ret,\n\t\t\t\t\t\trxperf_abort_unmarshal_error);\n\t\t\tgoto call_complete;\n\t\tdefault:\n\t\t\trxrpc_kernel_abort_call(rxperf_socket, call->rxcall,\n\t\t\t\t\t\tRX_CALL_DEAD, ret,\n\t\t\t\t\t\trxperf_abort_general_error);\n\t\t\tgoto call_complete;\n\t\t}\n\t}\n\ncall_complete:\n\trxperf_set_call_complete(call, ret, remote_abort);\n\t \n\trxrpc_kernel_shutdown_call(rxperf_socket, call->rxcall);\n\trxrpc_kernel_put_call(rxperf_socket, call->rxcall);\n\tcancel_work(&call->work);\n\tkfree(call);\n}\n\n \nstatic int rxperf_extract_data(struct rxperf_call *call, bool want_more)\n{\n\tu32 remote_abort = 0;\n\tint ret;\n\n\tret = rxrpc_kernel_recv_data(rxperf_socket, call->rxcall, &call->iter,\n\t\t\t\t     &call->iov_len, want_more, &remote_abort,\n\t\t\t\t     &call->service_id);\n\tpr_debug(\"Extract i=%zu l=%zu m=%u ret=%d\\n\",\n\t\t iov_iter_count(&call->iter), call->iov_len, want_more, ret);\n\tif (ret == 0 || ret == -EAGAIN)\n\t\treturn ret;\n\n\tif (ret == 1) {\n\t\tswitch (call->state) {\n\t\tcase RXPERF_CALL_SV_AWAIT_REQUEST:\n\t\t\trxperf_set_call_state(call, RXPERF_CALL_SV_REPLYING);\n\t\t\tbreak;\n\t\tcase RXPERF_CALL_COMPLETE:\n\t\t\tpr_debug(\"premature completion %d\", call->error);\n\t\t\treturn call->error;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\treturn 0;\n\t}\n\n\trxperf_set_call_complete(call, ret, remote_abort);\n\treturn ret;\n}\n\n \nstatic int rxperf_deliver_param_block(struct rxperf_call *call)\n{\n\tu32 version;\n\tint ret;\n\n\t \n\tret = rxperf_extract_data(call, true);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tversion\t\t\t= ntohl(call->params.version);\n\tcall->operation_id\t= ntohl(call->params.type);\n\tcall->deliver\t\t= rxperf_deliver_request;\n\n\tif (version != RX_PERF_VERSION) {\n\t\tpr_info(\"Version mismatch %x\\n\", version);\n\t\treturn -ENOTSUPP;\n\t}\n\n\tswitch (call->operation_id) {\n\tcase RX_PERF_SEND:\n\t\tcall->type = \"send\";\n\t\tcall->reply_len = 0;\n\t\tcall->iov_len = 4;\t \n\t\tbreak;\n\tcase RX_PERF_RECV:\n\t\tcall->type = \"recv\";\n\t\tcall->req_len = 0;\n\t\tcall->iov_len = 4;\t \n\t\tbreak;\n\tcase RX_PERF_RPC:\n\t\tcall->type = \"rpc\";\n\t\tcall->iov_len = 8;\t \n\t\tbreak;\n\tcase RX_PERF_FILE:\n\t\tcall->type = \"file\";\n\t\tfallthrough;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\trxperf_set_call_state(call, RXPERF_CALL_SV_AWAIT_REQUEST);\n\treturn call->deliver(call);\n}\n\n \nstatic int rxperf_deliver_request(struct rxperf_call *call)\n{\n\tint ret;\n\n\tswitch (call->unmarshal) {\n\tcase 0:\n\t\tcall->kvec[0].iov_len\t= call->iov_len;\n\t\tcall->kvec[0].iov_base\t= call->tmp;\n\t\tiov_iter_kvec(&call->iter, READ, call->kvec, 1, call->iov_len);\n\t\tcall->unmarshal++;\n\t\tfallthrough;\n\tcase 1:\n\t\tret = rxperf_extract_data(call, true);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tswitch (call->operation_id) {\n\t\tcase RX_PERF_SEND:\n\t\t\tcall->type = \"send\";\n\t\t\tcall->req_len\t= ntohl(call->tmp[0]);\n\t\t\tcall->reply_len\t= 0;\n\t\t\tbreak;\n\t\tcase RX_PERF_RECV:\n\t\t\tcall->type = \"recv\";\n\t\t\tcall->req_len = 0;\n\t\t\tcall->reply_len\t= ntohl(call->tmp[0]);\n\t\t\tbreak;\n\t\tcase RX_PERF_RPC:\n\t\t\tcall->type = \"rpc\";\n\t\t\tcall->req_len\t= ntohl(call->tmp[0]);\n\t\t\tcall->reply_len\t= ntohl(call->tmp[1]);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_info(\"Can't parse extra params\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tpr_debug(\"CALL op=%s rq=%zx rp=%zx\\n\",\n\t\t\t call->type, call->req_len, call->reply_len);\n\n\t\tcall->iov_len = call->req_len;\n\t\tiov_iter_discard(&call->iter, READ, call->req_len);\n\t\tcall->unmarshal++;\n\t\tfallthrough;\n\tcase 2:\n\t\tret = rxperf_extract_data(call, false);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tcall->unmarshal++;\n\t\tfallthrough;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\n \nstatic int rxperf_process_call(struct rxperf_call *call)\n{\n\tstruct msghdr msg = {};\n\tstruct bio_vec bv;\n\tstruct kvec iov[1];\n\tssize_t n;\n\tsize_t reply_len = call->reply_len, len;\n\n\trxrpc_kernel_set_tx_length(rxperf_socket, call->rxcall,\n\t\t\t\t   reply_len + sizeof(rxperf_magic_cookie));\n\n\twhile (reply_len > 0) {\n\t\tlen = min_t(size_t, reply_len, PAGE_SIZE);\n\t\tbvec_set_page(&bv, ZERO_PAGE(0), len, 0);\n\t\tiov_iter_bvec(&msg.msg_iter, WRITE, &bv, 1, len);\n\t\tmsg.msg_flags = MSG_MORE;\n\t\tn = rxrpc_kernel_send_data(rxperf_socket, call->rxcall, &msg,\n\t\t\t\t\t   len, rxperf_notify_end_reply_tx);\n\t\tif (n < 0)\n\t\t\treturn n;\n\t\tif (n == 0)\n\t\t\treturn -EIO;\n\t\treply_len -= n;\n\t}\n\n\tlen = sizeof(rxperf_magic_cookie);\n\tiov[0].iov_base\t= (void *)rxperf_magic_cookie;\n\tiov[0].iov_len\t= len;\n\tiov_iter_kvec(&msg.msg_iter, WRITE, iov, 1, len);\n\tmsg.msg_flags = 0;\n\tn = rxrpc_kernel_send_data(rxperf_socket, call->rxcall, &msg, len,\n\t\t\t\t   rxperf_notify_end_reply_tx);\n\tif (n >= 0)\n\t\treturn 0;  \n\n\tif (n == -ENOMEM)\n\t\trxrpc_kernel_abort_call(rxperf_socket, call->rxcall,\n\t\t\t\t\tRXGEN_SS_MARSHAL, -ENOMEM,\n\t\t\t\t\trxperf_abort_oom);\n\treturn n;\n}\n\n \nstatic int rxperf_add_key(struct key *keyring)\n{\n\tkey_ref_t kref;\n\tint ret;\n\n\tkref = key_create_or_update(make_key_ref(keyring, true),\n\t\t\t\t    \"rxrpc_s\",\n\t\t\t\t    __stringify(RX_PERF_SERVICE) \":2\",\n\t\t\t\t    secret,\n\t\t\t\t    sizeof(secret),\n\t\t\t\t    KEY_POS_VIEW | KEY_POS_READ | KEY_POS_SEARCH\n\t\t\t\t    | KEY_USR_VIEW,\n\t\t\t\t    KEY_ALLOC_NOT_IN_QUOTA);\n\n\tif (IS_ERR(kref)) {\n\t\tpr_err(\"Can't allocate rxperf server key: %ld\\n\", PTR_ERR(kref));\n\t\treturn PTR_ERR(kref);\n\t}\n\n\tret = key_link(keyring, key_ref_to_ptr(kref));\n\tif (ret < 0)\n\t\tpr_err(\"Can't link rxperf server key: %d\\n\", ret);\n\tkey_ref_put(kref);\n\treturn ret;\n}\n\n \nstatic int __init rxperf_init(void)\n{\n\tstruct key *keyring;\n\tint ret = -ENOMEM;\n\n\tpr_info(\"Server registering\\n\");\n\n\trxperf_workqueue = alloc_workqueue(\"rxperf\", 0, 0);\n\tif (!rxperf_workqueue)\n\t\tgoto error_workqueue;\n\n\tkeyring = keyring_alloc(\"rxperf_server\",\n\t\t\t\tGLOBAL_ROOT_UID, GLOBAL_ROOT_GID, current_cred(),\n\t\t\t\tKEY_POS_VIEW | KEY_POS_READ | KEY_POS_SEARCH |\n\t\t\t\tKEY_POS_WRITE |\n\t\t\t\tKEY_USR_VIEW | KEY_USR_READ | KEY_USR_SEARCH |\n\t\t\t\tKEY_USR_WRITE |\n\t\t\t\tKEY_OTH_VIEW | KEY_OTH_READ | KEY_OTH_SEARCH,\n\t\t\t\tKEY_ALLOC_NOT_IN_QUOTA,\n\t\t\t\tNULL, NULL);\n\tif (IS_ERR(keyring)) {\n\t\tpr_err(\"Can't allocate rxperf server keyring: %ld\\n\",\n\t\t       PTR_ERR(keyring));\n\t\tgoto error_keyring;\n\t}\n\trxperf_sec_keyring = keyring;\n\tret = rxperf_add_key(keyring);\n\tif (ret < 0)\n\t\tgoto error_key;\n\n\tret = rxperf_open_socket();\n\tif (ret < 0)\n\t\tgoto error_socket;\n\treturn 0;\n\nerror_socket:\nerror_key:\n\tkey_put(rxperf_sec_keyring);\nerror_keyring:\n\tdestroy_workqueue(rxperf_workqueue);\n\trcu_barrier();\nerror_workqueue:\n\tpr_err(\"Failed to register: %d\\n\", ret);\n\treturn ret;\n}\nlate_initcall(rxperf_init);  \n\nstatic void __exit rxperf_exit(void)\n{\n\tpr_info(\"Server unregistering.\\n\");\n\n\trxperf_close_socket();\n\tkey_put(rxperf_sec_keyring);\n\tdestroy_workqueue(rxperf_workqueue);\n\trcu_barrier();\n}\nmodule_exit(rxperf_exit);\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}