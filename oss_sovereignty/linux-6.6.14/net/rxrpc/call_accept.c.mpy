{
  "module_name": "call_accept.c",
  "hash_id": "2fcfd317a5400002a8c46651748e09eb6510816a75da03edfb0c7b9920c80272",
  "original_prompt": "Ingested from linux-6.6.14/net/rxrpc/call_accept.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/module.h>\n#include <linux/net.h>\n#include <linux/skbuff.h>\n#include <linux/errqueue.h>\n#include <linux/udp.h>\n#include <linux/in.h>\n#include <linux/in6.h>\n#include <linux/icmp.h>\n#include <linux/gfp.h>\n#include <linux/circ_buf.h>\n#include <net/sock.h>\n#include <net/af_rxrpc.h>\n#include <net/ip.h>\n#include \"ar-internal.h\"\n\nstatic void rxrpc_dummy_notify(struct sock *sk, struct rxrpc_call *call,\n\t\t\t       unsigned long user_call_ID)\n{\n}\n\n \nstatic int rxrpc_service_prealloc_one(struct rxrpc_sock *rx,\n\t\t\t\t      struct rxrpc_backlog *b,\n\t\t\t\t      rxrpc_notify_rx_t notify_rx,\n\t\t\t\t      rxrpc_user_attach_call_t user_attach_call,\n\t\t\t\t      unsigned long user_call_ID, gfp_t gfp,\n\t\t\t\t      unsigned int debug_id)\n{\n\tstruct rxrpc_call *call, *xcall;\n\tstruct rxrpc_net *rxnet = rxrpc_net(sock_net(&rx->sk));\n\tstruct rb_node *parent, **pp;\n\tint max, tmp;\n\tunsigned int size = RXRPC_BACKLOG_MAX;\n\tunsigned int head, tail, call_head, call_tail;\n\n\tmax = rx->sk.sk_max_ack_backlog;\n\ttmp = rx->sk.sk_ack_backlog;\n\tif (tmp >= max) {\n\t\t_leave(\" = -ENOBUFS [full %u]\", max);\n\t\treturn -ENOBUFS;\n\t}\n\tmax -= tmp;\n\n\t \n\tcall_head = b->call_backlog_head;\n\tcall_tail = READ_ONCE(b->call_backlog_tail);\n\ttmp = CIRC_CNT(call_head, call_tail, size);\n\tif (tmp >= max) {\n\t\t_leave(\" = -ENOBUFS [enough %u]\", tmp);\n\t\treturn -ENOBUFS;\n\t}\n\tmax = tmp + 1;\n\n\thead = b->peer_backlog_head;\n\ttail = READ_ONCE(b->peer_backlog_tail);\n\tif (CIRC_CNT(head, tail, size) < max) {\n\t\tstruct rxrpc_peer *peer;\n\n\t\tpeer = rxrpc_alloc_peer(rx->local, gfp, rxrpc_peer_new_prealloc);\n\t\tif (!peer)\n\t\t\treturn -ENOMEM;\n\t\tb->peer_backlog[head] = peer;\n\t\tsmp_store_release(&b->peer_backlog_head,\n\t\t\t\t  (head + 1) & (size - 1));\n\t}\n\n\thead = b->conn_backlog_head;\n\ttail = READ_ONCE(b->conn_backlog_tail);\n\tif (CIRC_CNT(head, tail, size) < max) {\n\t\tstruct rxrpc_connection *conn;\n\n\t\tconn = rxrpc_prealloc_service_connection(rxnet, gfp);\n\t\tif (!conn)\n\t\t\treturn -ENOMEM;\n\t\tb->conn_backlog[head] = conn;\n\t\tsmp_store_release(&b->conn_backlog_head,\n\t\t\t\t  (head + 1) & (size - 1));\n\t}\n\n\t \n\tcall = rxrpc_alloc_call(rx, gfp, debug_id);\n\tif (!call)\n\t\treturn -ENOMEM;\n\tcall->flags |= (1 << RXRPC_CALL_IS_SERVICE);\n\trxrpc_set_call_state(call, RXRPC_CALL_SERVER_PREALLOC);\n\t__set_bit(RXRPC_CALL_EV_INITIAL_PING, &call->events);\n\n\ttrace_rxrpc_call(call->debug_id, refcount_read(&call->ref),\n\t\t\t user_call_ID, rxrpc_call_new_prealloc_service);\n\n\twrite_lock(&rx->call_lock);\n\n\t \n\tpp = &rx->calls.rb_node;\n\tparent = NULL;\n\twhile (*pp) {\n\t\tparent = *pp;\n\t\txcall = rb_entry(parent, struct rxrpc_call, sock_node);\n\t\tif (user_call_ID < xcall->user_call_ID)\n\t\t\tpp = &(*pp)->rb_left;\n\t\telse if (user_call_ID > xcall->user_call_ID)\n\t\t\tpp = &(*pp)->rb_right;\n\t\telse\n\t\t\tgoto id_in_use;\n\t}\n\n\tcall->user_call_ID = user_call_ID;\n\tcall->notify_rx = notify_rx;\n\tif (user_attach_call) {\n\t\trxrpc_get_call(call, rxrpc_call_get_kernel_service);\n\t\tuser_attach_call(call, user_call_ID);\n\t}\n\n\trxrpc_get_call(call, rxrpc_call_get_userid);\n\trb_link_node(&call->sock_node, parent, pp);\n\trb_insert_color(&call->sock_node, &rx->calls);\n\tset_bit(RXRPC_CALL_HAS_USERID, &call->flags);\n\n\tlist_add(&call->sock_link, &rx->sock_calls);\n\n\twrite_unlock(&rx->call_lock);\n\n\trxnet = call->rxnet;\n\tspin_lock(&rxnet->call_lock);\n\tlist_add_tail_rcu(&call->link, &rxnet->calls);\n\tspin_unlock(&rxnet->call_lock);\n\n\tb->call_backlog[call_head] = call;\n\tsmp_store_release(&b->call_backlog_head, (call_head + 1) & (size - 1));\n\t_leave(\" = 0 [%d -> %lx]\", call->debug_id, user_call_ID);\n\treturn 0;\n\nid_in_use:\n\twrite_unlock(&rx->call_lock);\n\trxrpc_cleanup_call(call);\n\t_leave(\" = -EBADSLT\");\n\treturn -EBADSLT;\n}\n\n \nint rxrpc_service_prealloc(struct rxrpc_sock *rx, gfp_t gfp)\n{\n\tstruct rxrpc_backlog *b = rx->backlog;\n\n\tif (!b) {\n\t\tb = kzalloc(sizeof(struct rxrpc_backlog), gfp);\n\t\tif (!b)\n\t\t\treturn -ENOMEM;\n\t\trx->backlog = b;\n\t}\n\n\treturn 0;\n}\n\n \nvoid rxrpc_discard_prealloc(struct rxrpc_sock *rx)\n{\n\tstruct rxrpc_backlog *b = rx->backlog;\n\tstruct rxrpc_net *rxnet = rxrpc_net(sock_net(&rx->sk));\n\tunsigned int size = RXRPC_BACKLOG_MAX, head, tail;\n\n\tif (!b)\n\t\treturn;\n\trx->backlog = NULL;\n\n\t \n\tspin_lock(&rx->incoming_lock);\n\tspin_unlock(&rx->incoming_lock);\n\n\thead = b->peer_backlog_head;\n\ttail = b->peer_backlog_tail;\n\twhile (CIRC_CNT(head, tail, size) > 0) {\n\t\tstruct rxrpc_peer *peer = b->peer_backlog[tail];\n\t\trxrpc_put_local(peer->local, rxrpc_local_put_prealloc_peer);\n\t\tkfree(peer);\n\t\ttail = (tail + 1) & (size - 1);\n\t}\n\n\thead = b->conn_backlog_head;\n\ttail = b->conn_backlog_tail;\n\twhile (CIRC_CNT(head, tail, size) > 0) {\n\t\tstruct rxrpc_connection *conn = b->conn_backlog[tail];\n\t\twrite_lock(&rxnet->conn_lock);\n\t\tlist_del(&conn->link);\n\t\tlist_del(&conn->proc_link);\n\t\twrite_unlock(&rxnet->conn_lock);\n\t\tkfree(conn);\n\t\tif (atomic_dec_and_test(&rxnet->nr_conns))\n\t\t\twake_up_var(&rxnet->nr_conns);\n\t\ttail = (tail + 1) & (size - 1);\n\t}\n\n\thead = b->call_backlog_head;\n\ttail = b->call_backlog_tail;\n\twhile (CIRC_CNT(head, tail, size) > 0) {\n\t\tstruct rxrpc_call *call = b->call_backlog[tail];\n\t\trcu_assign_pointer(call->socket, rx);\n\t\tif (rx->discard_new_call) {\n\t\t\t_debug(\"discard %lx\", call->user_call_ID);\n\t\t\trx->discard_new_call(call, call->user_call_ID);\n\t\t\tif (call->notify_rx)\n\t\t\t\tcall->notify_rx = rxrpc_dummy_notify;\n\t\t\trxrpc_put_call(call, rxrpc_call_put_kernel);\n\t\t}\n\t\trxrpc_call_completed(call);\n\t\trxrpc_release_call(rx, call);\n\t\trxrpc_put_call(call, rxrpc_call_put_discard_prealloc);\n\t\ttail = (tail + 1) & (size - 1);\n\t}\n\n\tkfree(b);\n}\n\n \nstatic struct rxrpc_call *rxrpc_alloc_incoming_call(struct rxrpc_sock *rx,\n\t\t\t\t\t\t    struct rxrpc_local *local,\n\t\t\t\t\t\t    struct rxrpc_peer *peer,\n\t\t\t\t\t\t    struct rxrpc_connection *conn,\n\t\t\t\t\t\t    const struct rxrpc_security *sec,\n\t\t\t\t\t\t    struct sockaddr_rxrpc *peer_srx,\n\t\t\t\t\t\t    struct sk_buff *skb)\n{\n\tstruct rxrpc_backlog *b = rx->backlog;\n\tstruct rxrpc_call *call;\n\tunsigned short call_head, conn_head, peer_head;\n\tunsigned short call_tail, conn_tail, peer_tail;\n\tunsigned short call_count, conn_count;\n\n\t \n\tcall_head = smp_load_acquire(&b->call_backlog_head);\n\tcall_tail = b->call_backlog_tail;\n\tcall_count = CIRC_CNT(call_head, call_tail, RXRPC_BACKLOG_MAX);\n\tconn_head = smp_load_acquire(&b->conn_backlog_head);\n\tconn_tail = b->conn_backlog_tail;\n\tconn_count = CIRC_CNT(conn_head, conn_tail, RXRPC_BACKLOG_MAX);\n\tASSERTCMP(conn_count, >=, call_count);\n\tpeer_head = smp_load_acquire(&b->peer_backlog_head);\n\tpeer_tail = b->peer_backlog_tail;\n\tASSERTCMP(CIRC_CNT(peer_head, peer_tail, RXRPC_BACKLOG_MAX), >=,\n\t\t  conn_count);\n\n\tif (call_count == 0)\n\t\treturn NULL;\n\n\tif (!conn) {\n\t\tif (peer && !rxrpc_get_peer_maybe(peer, rxrpc_peer_get_service_conn))\n\t\t\tpeer = NULL;\n\t\tif (!peer) {\n\t\t\tpeer = b->peer_backlog[peer_tail];\n\t\t\tpeer->srx = *peer_srx;\n\t\t\tb->peer_backlog[peer_tail] = NULL;\n\t\t\tsmp_store_release(&b->peer_backlog_tail,\n\t\t\t\t\t  (peer_tail + 1) &\n\t\t\t\t\t  (RXRPC_BACKLOG_MAX - 1));\n\n\t\t\trxrpc_new_incoming_peer(local, peer);\n\t\t}\n\n\t\t \n\t\tconn = b->conn_backlog[conn_tail];\n\t\tb->conn_backlog[conn_tail] = NULL;\n\t\tsmp_store_release(&b->conn_backlog_tail,\n\t\t\t\t  (conn_tail + 1) & (RXRPC_BACKLOG_MAX - 1));\n\t\tconn->local = rxrpc_get_local(local, rxrpc_local_get_prealloc_conn);\n\t\tconn->peer = peer;\n\t\trxrpc_see_connection(conn, rxrpc_conn_see_new_service_conn);\n\t\trxrpc_new_incoming_connection(rx, conn, sec, skb);\n\t} else {\n\t\trxrpc_get_connection(conn, rxrpc_conn_get_service_conn);\n\t\tatomic_inc(&conn->active);\n\t}\n\n\t \n\tcall = b->call_backlog[call_tail];\n\tb->call_backlog[call_tail] = NULL;\n\tsmp_store_release(&b->call_backlog_tail,\n\t\t\t  (call_tail + 1) & (RXRPC_BACKLOG_MAX - 1));\n\n\trxrpc_see_call(call, rxrpc_call_see_accept);\n\tcall->local = rxrpc_get_local(conn->local, rxrpc_local_get_call);\n\tcall->conn = conn;\n\tcall->security = conn->security;\n\tcall->security_ix = conn->security_ix;\n\tcall->peer = rxrpc_get_peer(conn->peer, rxrpc_peer_get_accept);\n\tcall->dest_srx = peer->srx;\n\tcall->cong_ssthresh = call->peer->cong_ssthresh;\n\tcall->tx_last_sent = ktime_get_real();\n\treturn call;\n}\n\n \nbool rxrpc_new_incoming_call(struct rxrpc_local *local,\n\t\t\t     struct rxrpc_peer *peer,\n\t\t\t     struct rxrpc_connection *conn,\n\t\t\t     struct sockaddr_rxrpc *peer_srx,\n\t\t\t     struct sk_buff *skb)\n{\n\tconst struct rxrpc_security *sec = NULL;\n\tstruct rxrpc_skb_priv *sp = rxrpc_skb(skb);\n\tstruct rxrpc_call *call = NULL;\n\tstruct rxrpc_sock *rx;\n\n\t_enter(\"\");\n\n\t \n\tif (sp->hdr.type != RXRPC_PACKET_TYPE_DATA)\n\t\treturn rxrpc_protocol_error(skb, rxrpc_eproto_no_service_call);\n\n\tread_lock(&local->services_lock);\n\n\t \n\trx = local->service;\n\tif (!rx || (sp->hdr.serviceId != rx->srx.srx_service &&\n\t\t    sp->hdr.serviceId != rx->second_service)\n\t    ) {\n\t\tif (sp->hdr.type == RXRPC_PACKET_TYPE_DATA &&\n\t\t    sp->hdr.seq == 1)\n\t\t\tgoto unsupported_service;\n\t\tgoto discard;\n\t}\n\n\tif (!conn) {\n\t\tsec = rxrpc_get_incoming_security(rx, skb);\n\t\tif (!sec)\n\t\t\tgoto unsupported_security;\n\t}\n\n\tspin_lock(&rx->incoming_lock);\n\tif (rx->sk.sk_state == RXRPC_SERVER_LISTEN_DISABLED ||\n\t    rx->sk.sk_state == RXRPC_CLOSE) {\n\t\trxrpc_direct_abort(skb, rxrpc_abort_shut_down,\n\t\t\t\t   RX_INVALID_OPERATION, -ESHUTDOWN);\n\t\tgoto no_call;\n\t}\n\n\tcall = rxrpc_alloc_incoming_call(rx, local, peer, conn, sec, peer_srx,\n\t\t\t\t\t skb);\n\tif (!call) {\n\t\tskb->mark = RXRPC_SKB_MARK_REJECT_BUSY;\n\t\tgoto no_call;\n\t}\n\n\ttrace_rxrpc_receive(call, rxrpc_receive_incoming,\n\t\t\t    sp->hdr.serial, sp->hdr.seq);\n\n\t \n\trxrpc_incoming_call(rx, call, skb);\n\tconn = call->conn;\n\n\tif (rx->notify_new_call)\n\t\trx->notify_new_call(&rx->sk, call, call->user_call_ID);\n\n\tspin_lock(&conn->state_lock);\n\tif (conn->state == RXRPC_CONN_SERVICE_UNSECURED) {\n\t\tconn->state = RXRPC_CONN_SERVICE_CHALLENGING;\n\t\tset_bit(RXRPC_CONN_EV_CHALLENGE, &call->conn->events);\n\t\trxrpc_queue_conn(call->conn, rxrpc_conn_queue_challenge);\n\t}\n\tspin_unlock(&conn->state_lock);\n\n\tspin_unlock(&rx->incoming_lock);\n\tread_unlock(&local->services_lock);\n\n\tif (hlist_unhashed(&call->error_link)) {\n\t\tspin_lock(&call->peer->lock);\n\t\thlist_add_head(&call->error_link, &call->peer->error_targets);\n\t\tspin_unlock(&call->peer->lock);\n\t}\n\n\t_leave(\" = %p{%d}\", call, call->debug_id);\n\trxrpc_input_call_event(call, skb);\n\trxrpc_put_call(call, rxrpc_call_put_input);\n\treturn true;\n\nunsupported_service:\n\tread_unlock(&local->services_lock);\n\treturn rxrpc_direct_abort(skb, rxrpc_abort_service_not_offered,\n\t\t\t\t  RX_INVALID_OPERATION, -EOPNOTSUPP);\nunsupported_security:\n\tread_unlock(&local->services_lock);\n\treturn rxrpc_direct_abort(skb, rxrpc_abort_service_not_offered,\n\t\t\t\t  RX_INVALID_OPERATION, -EKEYREJECTED);\nno_call:\n\tspin_unlock(&rx->incoming_lock);\n\tread_unlock(&local->services_lock);\n\t_leave(\" = f [%u]\", skb->mark);\n\treturn false;\ndiscard:\n\tread_unlock(&local->services_lock);\n\treturn true;\n}\n\n \nint rxrpc_user_charge_accept(struct rxrpc_sock *rx, unsigned long user_call_ID)\n{\n\tstruct rxrpc_backlog *b = rx->backlog;\n\n\tif (rx->sk.sk_state == RXRPC_CLOSE)\n\t\treturn -ESHUTDOWN;\n\n\treturn rxrpc_service_prealloc_one(rx, b, NULL, NULL, user_call_ID,\n\t\t\t\t\t  GFP_KERNEL,\n\t\t\t\t\t  atomic_inc_return(&rxrpc_debug_id));\n}\n\n \nint rxrpc_kernel_charge_accept(struct socket *sock,\n\t\t\t       rxrpc_notify_rx_t notify_rx,\n\t\t\t       rxrpc_user_attach_call_t user_attach_call,\n\t\t\t       unsigned long user_call_ID, gfp_t gfp,\n\t\t\t       unsigned int debug_id)\n{\n\tstruct rxrpc_sock *rx = rxrpc_sk(sock->sk);\n\tstruct rxrpc_backlog *b = rx->backlog;\n\n\tif (sock->sk->sk_state == RXRPC_CLOSE)\n\t\treturn -ESHUTDOWN;\n\n\treturn rxrpc_service_prealloc_one(rx, b, notify_rx,\n\t\t\t\t\t  user_attach_call, user_call_ID,\n\t\t\t\t\t  gfp, debug_id);\n}\nEXPORT_SYMBOL(rxrpc_kernel_charge_accept);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}