{
  "module_name": "nlrx64.c",
  "hash_id": "4a2861e3e4fd912c83f806aa7422eea0448a779b067ffc6960feed6a7c384f86",
  "original_prompt": "Ingested from sys_09_Anvil/source/py/nlrx64.c",
  "human_readable_source": " \n\n#include \"py/mpstate.h\"\n\n#if MICROPY_NLR_X64\n\n#undef nlr_push\n\n\n\n\n__attribute__((used)) unsigned int nlr_push_tail(nlr_buf_t *nlr);\n\n#if !MICROPY_NLR_OS_WINDOWS\n#if defined(__clang__) || (defined(__GNUC__) && __GNUC__ >= 8)\n#define USE_NAKED 1\n#else\n\n__attribute__((optimize(\"omit-frame-pointer\")))\n#endif\n#endif\n\n#if !defined(USE_NAKED)\n#define USE_NAKED 0\n#endif\n\n#if USE_NAKED\n\n__attribute__((naked))\n#endif\nunsigned int nlr_push(nlr_buf_t *nlr) {\n    #if !USE_NAKED\n    (void)nlr;\n    #endif\n\n    #if MICROPY_NLR_OS_WINDOWS\n\n    __asm volatile (\n        \"movq   (%rsp), %rax        \\n\" \n        \"movq   %rax, 16(%rcx)      \\n\" \n        \"movq   %rbp, 24(%rcx)      \\n\" \n        \"movq   %rsp, 32(%rcx)      \\n\" \n        \"movq   %rbx, 40(%rcx)      \\n\" \n        \"movq   %r12, 48(%rcx)      \\n\" \n        \"movq   %r13, 56(%rcx)      \\n\" \n        \"movq   %r14, 64(%rcx)      \\n\" \n        \"movq   %r15, 72(%rcx)      \\n\" \n        \"movq   %rdi, 80(%rcx)      \\n\" \n        \"movq   %rsi, 88(%rcx)      \\n\" \n        \"jmp    nlr_push_tail       \\n\" \n        );\n\n    #else\n\n    __asm volatile (\n        \"movq   (%rsp), %rax        \\n\" \n        \"movq   %rax, 16(%rdi)      \\n\" \n        \"movq   %rbp, 24(%rdi)      \\n\" \n        \"movq   %rsp, 32(%rdi)      \\n\" \n        \"movq   %rbx, 40(%rdi)      \\n\" \n        \"movq   %r12, 48(%rdi)      \\n\" \n        \"movq   %r13, 56(%rdi)      \\n\" \n        \"movq   %r14, 64(%rdi)      \\n\" \n        \"movq   %r15, 72(%rdi)      \\n\" \n        #if defined(__APPLE__) && defined(__MACH__)\n        \"jmp    _nlr_push_tail      \\n\" \n        #else\n        \"jmp    nlr_push_tail       \\n\" \n        #endif\n        );\n\n    #endif\n\n    #if !USE_NAKED\n    return 0; \n    #endif\n}\n\nNORETURN void nlr_jump(void *val) {\n    MP_NLR_JUMP_HEAD(val, top)\n\n    __asm volatile (\n        \"movq   %0, %%rcx           \\n\" \n        #if MICROPY_NLR_OS_WINDOWS\n        \"movq   88(%%rcx), %%rsi    \\n\" \n        \"movq   80(%%rcx), %%rdi    \\n\" \n        #endif\n        \"movq   72(%%rcx), %%r15    \\n\" \n        \"movq   64(%%rcx), %%r14    \\n\" \n        \"movq   56(%%rcx), %%r13    \\n\" \n        \"movq   48(%%rcx), %%r12    \\n\" \n        \"movq   40(%%rcx), %%rbx    \\n\" \n        \"movq   32(%%rcx), %%rsp    \\n\" \n        \"movq   24(%%rcx), %%rbp    \\n\" \n        \"movq   16(%%rcx), %%rax    \\n\" \n        \"movq   %%rax, (%%rsp)      \\n\" \n        \"xorq   %%rax, %%rax        \\n\" \n        \"inc    %%al                \\n\" \n        \"ret                        \\n\" \n        :                           \n        : \"r\" (top)                 \n        : \"memory\"                  \n        );\n\n    MP_UNREACHABLE\n}\n\n#endif \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}