{
  "module_name": "asmthumb.h",
  "hash_id": "0eb300bc2ca3155e5b92f729253648d0e5732ee23af057ca118fb53d694d7d83",
  "original_prompt": "Ingested from sys_09_Anvil/source/py/asmthumb.h",
  "human_readable_source": " \n#ifndef MICROPY_INCLUDED_PY_ASMTHUMB_H\n#define MICROPY_INCLUDED_PY_ASMTHUMB_H\n\n#include <assert.h>\n#include \"py/misc.h\"\n#include \"py/asmbase.h\"\n#include \"py/persistentcode.h\"\n\n#define ASM_THUMB_REG_R0  (0)\n#define ASM_THUMB_REG_R1  (1)\n#define ASM_THUMB_REG_R2  (2)\n#define ASM_THUMB_REG_R3  (3)\n#define ASM_THUMB_REG_R4  (4)\n#define ASM_THUMB_REG_R5  (5)\n#define ASM_THUMB_REG_R6  (6)\n#define ASM_THUMB_REG_R7  (7)\n#define ASM_THUMB_REG_R8  (8)\n#define ASM_THUMB_REG_R9  (9)\n#define ASM_THUMB_REG_R10 (10)\n#define ASM_THUMB_REG_R11 (11)\n#define ASM_THUMB_REG_R12 (12)\n#define ASM_THUMB_REG_R13 (13)\n#define ASM_THUMB_REG_R14 (14)\n#define ASM_THUMB_REG_R15 (15)\n#define ASM_THUMB_REG_SP  (ASM_THUMB_REG_R13)\n#define ASM_THUMB_REG_LR  (REG_R14)\n\n#define ASM_THUMB_CC_EQ (0x0)\n#define ASM_THUMB_CC_NE (0x1)\n#define ASM_THUMB_CC_CS (0x2)\n#define ASM_THUMB_CC_CC (0x3)\n#define ASM_THUMB_CC_MI (0x4)\n#define ASM_THUMB_CC_PL (0x5)\n#define ASM_THUMB_CC_VS (0x6)\n#define ASM_THUMB_CC_VC (0x7)\n#define ASM_THUMB_CC_HI (0x8)\n#define ASM_THUMB_CC_LS (0x9)\n#define ASM_THUMB_CC_GE (0xa)\n#define ASM_THUMB_CC_LT (0xb)\n#define ASM_THUMB_CC_GT (0xc)\n#define ASM_THUMB_CC_LE (0xd)\n\ntypedef struct _asm_thumb_t {\n    mp_asm_base_t base;\n    uint32_t push_reglist;\n    uint32_t stack_adjust;\n} asm_thumb_t;\n\n#if MICROPY_DYNAMIC_COMPILER\n\nstatic inline bool asm_thumb_allow_armv7m(asm_thumb_t *as) {\n    return MP_NATIVE_ARCH_ARMV7M <= mp_dynamic_compiler.native_arch\n           && mp_dynamic_compiler.native_arch <= MP_NATIVE_ARCH_ARMV7EMDP;\n}\n\n#else\n\nstatic inline bool asm_thumb_allow_armv7m(asm_thumb_t *as) {\n    return MICROPY_EMIT_THUMB_ARMV7M;\n}\n\n#endif\n\nstatic inline void asm_thumb_end_pass(asm_thumb_t *as) {\n    (void)as;\n}\n\nvoid asm_thumb_entry(asm_thumb_t *as, int num_locals);\nvoid asm_thumb_exit(asm_thumb_t *as);\n\n\n\n\n#define ASM_THUMB_OP_IT (0xbf00)\n#define ASM_THUMB_OP_ITE_EQ (0xbf0c)\n#define ASM_THUMB_OP_ITE_NE (0xbf14)\n#define ASM_THUMB_OP_ITE_CS (0xbf2c)\n#define ASM_THUMB_OP_ITE_CC (0xbf34)\n#define ASM_THUMB_OP_ITE_MI (0xbf4c)\n#define ASM_THUMB_OP_ITE_PL (0xbf54)\n#define ASM_THUMB_OP_ITE_VS (0xbf6c)\n#define ASM_THUMB_OP_ITE_VC (0xbf74)\n#define ASM_THUMB_OP_ITE_HI (0xbf8c)\n#define ASM_THUMB_OP_ITE_LS (0xbf94)\n#define ASM_THUMB_OP_ITE_GE (0xbfac)\n#define ASM_THUMB_OP_ITE_LT (0xbfb4)\n#define ASM_THUMB_OP_ITE_GT (0xbfcc)\n#define ASM_THUMB_OP_ITE_LE (0xbfd4)\n\n#define ASM_THUMB_OP_NOP        (0xbf00)\n#define ASM_THUMB_OP_WFI        (0xbf30)\n#define ASM_THUMB_OP_CPSID_I    (0xb672) \n#define ASM_THUMB_OP_CPSIE_I    (0xb662) \n\nvoid asm_thumb_op16(asm_thumb_t *as, uint op);\nvoid asm_thumb_op32(asm_thumb_t *as, uint op1, uint op2);\n\nstatic inline void asm_thumb_it_cc(asm_thumb_t *as, uint cc, uint mask) {\n    asm_thumb_op16(as, ASM_THUMB_OP_IT | (cc << 4) | mask);\n}\n\n\n\n#define ASM_THUMB_FORMAT_1_LSL (0x0000)\n#define ASM_THUMB_FORMAT_1_LSR (0x0800)\n#define ASM_THUMB_FORMAT_1_ASR (0x1000)\n\n#define ASM_THUMB_FORMAT_1_ENCODE(op, rlo_dest, rlo_src, offset) \\\n    ((op) | ((offset) << 6) | ((rlo_src) << 3) | (rlo_dest))\n\nstatic inline void asm_thumb_format_1(asm_thumb_t *as, uint op, uint rlo_dest, uint rlo_src, uint offset) {\n    assert(rlo_dest < ASM_THUMB_REG_R8);\n    assert(rlo_src < ASM_THUMB_REG_R8);\n    asm_thumb_op16(as, ASM_THUMB_FORMAT_1_ENCODE(op, rlo_dest, rlo_src, offset));\n}\n\n\n\n#define ASM_THUMB_FORMAT_2_ADD (0x1800)\n#define ASM_THUMB_FORMAT_2_SUB (0x1a00)\n#define ASM_THUMB_FORMAT_2_REG_OPERAND (0x0000)\n#define ASM_THUMB_FORMAT_2_IMM_OPERAND (0x0400)\n\n#define ASM_THUMB_FORMAT_2_ENCODE(op, rlo_dest, rlo_src, src_b) \\\n    ((op) | ((src_b) << 6) | ((rlo_src) << 3) | (rlo_dest))\n\nstatic inline void asm_thumb_format_2(asm_thumb_t *as, uint op, uint rlo_dest, uint rlo_src, int src_b) {\n    assert(rlo_dest < ASM_THUMB_REG_R8);\n    assert(rlo_src < ASM_THUMB_REG_R8);\n    asm_thumb_op16(as, ASM_THUMB_FORMAT_2_ENCODE(op, rlo_dest, rlo_src, src_b));\n}\n\nstatic inline void asm_thumb_add_rlo_rlo_rlo(asm_thumb_t *as, uint rlo_dest, uint rlo_src_a, uint rlo_src_b) {\n    asm_thumb_format_2(as, ASM_THUMB_FORMAT_2_ADD | ASM_THUMB_FORMAT_2_REG_OPERAND, rlo_dest, rlo_src_a, rlo_src_b);\n}\nstatic inline void asm_thumb_add_rlo_rlo_i3(asm_thumb_t *as, uint rlo_dest, uint rlo_src_a, int i3_src) {\n    asm_thumb_format_2(as, ASM_THUMB_FORMAT_2_ADD | ASM_THUMB_FORMAT_2_IMM_OPERAND, rlo_dest, rlo_src_a, i3_src);\n}\nstatic inline void asm_thumb_sub_rlo_rlo_rlo(asm_thumb_t *as, uint rlo_dest, uint rlo_src_a, uint rlo_src_b) {\n    asm_thumb_format_2(as, ASM_THUMB_FORMAT_2_SUB | ASM_THUMB_FORMAT_2_REG_OPERAND, rlo_dest, rlo_src_a, rlo_src_b);\n}\nstatic inline void asm_thumb_sub_rlo_rlo_i3(asm_thumb_t *as, uint rlo_dest, uint rlo_src_a, int i3_src) {\n    asm_thumb_format_2(as, ASM_THUMB_FORMAT_2_SUB | ASM_THUMB_FORMAT_2_IMM_OPERAND, rlo_dest, rlo_src_a, i3_src);\n}\n\n\n\n\n#define ASM_THUMB_FORMAT_3_MOV (0x2000)\n#define ASM_THUMB_FORMAT_3_CMP (0x2800)\n#define ASM_THUMB_FORMAT_3_ADD (0x3000)\n#define ASM_THUMB_FORMAT_3_SUB (0x3800)\n#define ASM_THUMB_FORMAT_3_LDR (0x4800)\n\n#define ASM_THUMB_FORMAT_3_ENCODE(op, rlo, i8) ((op) | ((rlo) << 8) | (i8))\n\nstatic inline void asm_thumb_format_3(asm_thumb_t *as, uint op, uint rlo, int i8) {\n    assert(rlo < ASM_THUMB_REG_R8);\n    asm_thumb_op16(as, ASM_THUMB_FORMAT_3_ENCODE(op, rlo, i8));\n}\n\nstatic inline void asm_thumb_mov_rlo_i8(asm_thumb_t *as, uint rlo, int i8) {\n    asm_thumb_format_3(as, ASM_THUMB_FORMAT_3_MOV, rlo, i8);\n}\nstatic inline void asm_thumb_cmp_rlo_i8(asm_thumb_t *as, uint rlo, int i8) {\n    asm_thumb_format_3(as, ASM_THUMB_FORMAT_3_CMP, rlo, i8);\n}\nstatic inline void asm_thumb_add_rlo_i8(asm_thumb_t *as, uint rlo, int i8) {\n    asm_thumb_format_3(as, ASM_THUMB_FORMAT_3_ADD, rlo, i8);\n}\nstatic inline void asm_thumb_sub_rlo_i8(asm_thumb_t *as, uint rlo, int i8) {\n    asm_thumb_format_3(as, ASM_THUMB_FORMAT_3_SUB, rlo, i8);\n}\nstatic inline void asm_thumb_ldr_rlo_pcrel_i8(asm_thumb_t *as, uint rlo, uint i8) {\n    asm_thumb_format_3(as, ASM_THUMB_FORMAT_3_LDR, rlo, i8);\n}\n\n\n\n#define ASM_THUMB_FORMAT_4_AND (0x4000)\n#define ASM_THUMB_FORMAT_4_EOR (0x4040)\n#define ASM_THUMB_FORMAT_4_LSL (0x4080)\n#define ASM_THUMB_FORMAT_4_LSR (0x40c0)\n#define ASM_THUMB_FORMAT_4_ASR (0x4100)\n#define ASM_THUMB_FORMAT_4_ADC (0x4140)\n#define ASM_THUMB_FORMAT_4_SBC (0x4180)\n#define ASM_THUMB_FORMAT_4_ROR (0x41c0)\n#define ASM_THUMB_FORMAT_4_TST (0x4200)\n#define ASM_THUMB_FORMAT_4_NEG (0x4240)\n#define ASM_THUMB_FORMAT_4_CMP (0x4280)\n#define ASM_THUMB_FORMAT_4_CMN (0x42c0)\n#define ASM_THUMB_FORMAT_4_ORR (0x4300)\n#define ASM_THUMB_FORMAT_4_MUL (0x4340)\n#define ASM_THUMB_FORMAT_4_BIC (0x4380)\n#define ASM_THUMB_FORMAT_4_MVN (0x43c0)\n\nvoid asm_thumb_format_4(asm_thumb_t *as, uint op, uint rlo_dest, uint rlo_src);\n\nstatic inline void asm_thumb_cmp_rlo_rlo(asm_thumb_t *as, uint rlo_dest, uint rlo_src) {\n    asm_thumb_format_4(as, ASM_THUMB_FORMAT_4_CMP, rlo_dest, rlo_src);\n}\nstatic inline void asm_thumb_mvn_rlo_rlo(asm_thumb_t *as, uint rlo_dest, uint rlo_src) {\n    asm_thumb_format_4(as, ASM_THUMB_FORMAT_4_MVN, rlo_dest, rlo_src);\n}\nstatic inline void asm_thumb_neg_rlo_rlo(asm_thumb_t *as, uint rlo_dest, uint rlo_src) {\n    asm_thumb_format_4(as, ASM_THUMB_FORMAT_4_NEG, rlo_dest, rlo_src);\n}\n\n\n\n\n#define ASM_THUMB_FORMAT_5_ADD (0x4400)\n#define ASM_THUMB_FORMAT_5_BX (0x4700)\n\n#define ASM_THUMB_FORMAT_5_ENCODE(op, r_dest, r_src) \\\n    ((op) | ((r_dest) << 4 & 0x0080) | ((r_src) << 3) | ((r_dest) & 0x0007))\n\nstatic inline void asm_thumb_format_5(asm_thumb_t *as, uint op, uint r_dest, uint r_src) {\n    asm_thumb_op16(as, ASM_THUMB_FORMAT_5_ENCODE(op, r_dest, r_src));\n}\n\nstatic inline void asm_thumb_add_reg_reg(asm_thumb_t *as, uint r_dest, uint r_src) {\n    asm_thumb_format_5(as, ASM_THUMB_FORMAT_5_ADD, r_dest, r_src);\n}\nstatic inline void asm_thumb_bx_reg(asm_thumb_t *as, uint r_src) {\n    asm_thumb_format_5(as, ASM_THUMB_FORMAT_5_BX, 0, r_src);\n}\n\n\n\n\n\n\n\n\n#define ASM_THUMB_FORMAT_9_STR (0x6000)\n#define ASM_THUMB_FORMAT_9_LDR (0x6800)\n#define ASM_THUMB_FORMAT_9_WORD_TRANSFER (0x0000)\n#define ASM_THUMB_FORMAT_9_BYTE_TRANSFER (0x1000)\n\n#define ASM_THUMB_FORMAT_10_STRH (0x8000)\n#define ASM_THUMB_FORMAT_10_LDRH (0x8800)\n\n#define ASM_THUMB_FORMAT_9_10_ENCODE(op, rlo_dest, rlo_base, offset) \\\n    ((op) | (((offset) << 6) & 0x07c0) | ((rlo_base) << 3) | (rlo_dest))\n\nstatic inline void asm_thumb_format_9_10(asm_thumb_t *as, uint op, uint rlo_dest, uint rlo_base, uint offset) {\n    asm_thumb_op16(as, ASM_THUMB_FORMAT_9_10_ENCODE(op, rlo_dest, rlo_base, offset));\n}\n\nstatic inline void asm_thumb_str_rlo_rlo_i5(asm_thumb_t *as, uint rlo_src, uint rlo_base, uint word_offset) {\n    asm_thumb_format_9_10(as, ASM_THUMB_FORMAT_9_STR | ASM_THUMB_FORMAT_9_WORD_TRANSFER, rlo_src, rlo_base, word_offset);\n}\nstatic inline void asm_thumb_strb_rlo_rlo_i5(asm_thumb_t *as, uint rlo_src, uint rlo_base, uint byte_offset) {\n    asm_thumb_format_9_10(as, ASM_THUMB_FORMAT_9_STR | ASM_THUMB_FORMAT_9_BYTE_TRANSFER, rlo_src, rlo_base, byte_offset);\n}\nstatic inline void asm_thumb_strh_rlo_rlo_i5(asm_thumb_t *as, uint rlo_src, uint rlo_base, uint uint16_offset) {\n    asm_thumb_format_9_10(as, ASM_THUMB_FORMAT_10_STRH, rlo_src, rlo_base, uint16_offset);\n}\nstatic inline void asm_thumb_ldr_rlo_rlo_i5(asm_thumb_t *as, uint rlo_dest, uint rlo_base, uint word_offset) {\n    asm_thumb_format_9_10(as, ASM_THUMB_FORMAT_9_LDR | ASM_THUMB_FORMAT_9_WORD_TRANSFER, rlo_dest, rlo_base, word_offset);\n}\nstatic inline void asm_thumb_ldrb_rlo_rlo_i5(asm_thumb_t *as, uint rlo_dest, uint rlo_base, uint byte_offset) {\n    asm_thumb_format_9_10(as, ASM_THUMB_FORMAT_9_LDR | ASM_THUMB_FORMAT_9_BYTE_TRANSFER, rlo_dest, rlo_base, byte_offset);\n}\nstatic inline void asm_thumb_ldrh_rlo_rlo_i5(asm_thumb_t *as, uint rlo_dest, uint rlo_base, uint uint16_offset) {\n    asm_thumb_format_9_10(as, ASM_THUMB_FORMAT_10_LDRH, rlo_dest, rlo_base, uint16_offset);\n}\nstatic inline void asm_thumb_lsl_rlo_rlo_i5(asm_thumb_t *as, uint rlo_dest, uint rlo_src, uint shift) {\n    asm_thumb_format_1(as, ASM_THUMB_FORMAT_1_LSL, rlo_dest, rlo_src, shift);\n}\nstatic inline void asm_thumb_asr_rlo_rlo_i5(asm_thumb_t *as, uint rlo_dest, uint rlo_src, uint shift) {\n    asm_thumb_format_1(as, ASM_THUMB_FORMAT_1_ASR, rlo_dest, rlo_src, shift);\n}\n\n\n\n#define ASM_THUMB_FORMAT_11_ENCODE(op, rlo_dest, rlo_src) \\\n    ((op) | ((rlo_src) << 3) | (rlo_dest))\n\n#define ASM_THUMB_FORMAT_11_SXTH (0xb200)\n#define ASM_THUMB_FORMAT_11_SXTB (0xb240)\n#define ASM_THUMB_FORMAT_11_UXTH (0xb280)\n#define ASM_THUMB_FORMAT_11_UXTB (0xb2c0)\n\nstatic inline void asm_thumb_format_11(asm_thumb_t *as, uint op, uint rlo_dest, uint rlo_src) {\n    assert(rlo_dest < ASM_THUMB_REG_R8);\n    assert(rlo_src < ASM_THUMB_REG_R8);\n    asm_thumb_op16(as, ASM_THUMB_FORMAT_11_ENCODE(op, rlo_dest, rlo_src));\n}\n\nstatic inline void asm_thumb_sxth_rlo_rlo(asm_thumb_t *as, uint rlo_dest, uint rlo_src) {\n    asm_thumb_format_11(as, ASM_THUMB_FORMAT_11_SXTH, rlo_dest, rlo_src);\n}\n\n\n\n#define ASM_THUMB_OP_MOVW (0xf240)\n#define ASM_THUMB_OP_MOVT (0xf2c0)\n\nvoid asm_thumb_mov_reg_reg(asm_thumb_t *as, uint reg_dest, uint reg_src);\nvoid asm_thumb_mov_reg_i16(asm_thumb_t *as, uint mov_op, uint reg_dest, int i16_src);\n\n\nbool asm_thumb_b_n_label(asm_thumb_t *as, uint label);\nbool asm_thumb_bcc_nw_label(asm_thumb_t *as, int cond, uint label, bool wide);\nbool asm_thumb_bl_label(asm_thumb_t *as, uint label);\n\nsize_t asm_thumb_mov_reg_i32(asm_thumb_t *as, uint reg_dest, mp_uint_t i32_src); \nvoid asm_thumb_mov_reg_i32_optimised(asm_thumb_t *as, uint reg_dest, int i32_src); \nvoid asm_thumb_mov_local_reg(asm_thumb_t *as, int local_num_dest, uint rlo_src); \nvoid asm_thumb_mov_reg_local(asm_thumb_t *as, uint rlo_dest, int local_num); \nvoid asm_thumb_mov_reg_local_addr(asm_thumb_t *as, uint rlo_dest, int local_num); \nvoid asm_thumb_mov_reg_pcrel(asm_thumb_t *as, uint rlo_dest, uint label);\n\nvoid asm_thumb_ldr_reg_reg_i12_optimised(asm_thumb_t *as, uint reg_dest, uint reg_base, uint word_offset); \nvoid asm_thumb_ldrh_reg_reg_i12_optimised(asm_thumb_t *as, uint reg_dest, uint reg_base, uint uint16_offset); \n\nvoid asm_thumb_b_label(asm_thumb_t *as, uint label); \nvoid asm_thumb_bcc_label(asm_thumb_t *as, int cc, uint label); \nvoid asm_thumb_bl_ind(asm_thumb_t *as, uint fun_id, uint reg_temp); \nvoid asm_thumb_bcc_rel9(asm_thumb_t *as, int cc, int rel);\nvoid asm_thumb_b_rel12(asm_thumb_t *as, int rel);\n\n\n#define ASM_THUMB_REG_FUN_TABLE ASM_THUMB_REG_R7\n\n#if GENERIC_ASM_API\n\n\n\n\n#define ASM_WORD_SIZE (4)\n\n#define REG_RET ASM_THUMB_REG_R0\n#define REG_ARG_1 ASM_THUMB_REG_R0\n#define REG_ARG_2 ASM_THUMB_REG_R1\n#define REG_ARG_3 ASM_THUMB_REG_R2\n#define REG_ARG_4 ASM_THUMB_REG_R3\n\n\n#define REG_TEMP0 ASM_THUMB_REG_R0\n#define REG_TEMP1 ASM_THUMB_REG_R1\n#define REG_TEMP2 ASM_THUMB_REG_R2\n\n#define REG_LOCAL_1 ASM_THUMB_REG_R4\n#define REG_LOCAL_2 ASM_THUMB_REG_R5\n#define REG_LOCAL_3 ASM_THUMB_REG_R6\n#define REG_LOCAL_NUM (3)\n\n#define REG_FUN_TABLE ASM_THUMB_REG_FUN_TABLE\n\n#define ASM_T               asm_thumb_t\n#define ASM_END_PASS        asm_thumb_end_pass\n#define ASM_ENTRY           asm_thumb_entry\n#define ASM_EXIT            asm_thumb_exit\n\n#define ASM_JUMP            asm_thumb_b_label\n#define ASM_JUMP_IF_REG_ZERO(as, reg, label, bool_test) \\\n    do { \\\n        asm_thumb_cmp_rlo_i8(as, reg, 0); \\\n        asm_thumb_bcc_label(as, ASM_THUMB_CC_EQ, label); \\\n    } while (0)\n#define ASM_JUMP_IF_REG_NONZERO(as, reg, label, bool_test) \\\n    do { \\\n        asm_thumb_cmp_rlo_i8(as, reg, 0); \\\n        asm_thumb_bcc_label(as, ASM_THUMB_CC_NE, label); \\\n    } while (0)\n#define ASM_JUMP_IF_REG_EQ(as, reg1, reg2, label) \\\n    do { \\\n        asm_thumb_cmp_rlo_rlo(as, reg1, reg2); \\\n        asm_thumb_bcc_label(as, ASM_THUMB_CC_EQ, label); \\\n    } while (0)\n#define ASM_JUMP_REG(as, reg) asm_thumb_bx_reg((as), (reg))\n#define ASM_CALL_IND(as, idx) asm_thumb_bl_ind(as, idx, ASM_THUMB_REG_R3)\n\n#define ASM_MOV_LOCAL_REG(as, local_num, reg) asm_thumb_mov_local_reg((as), (local_num), (reg))\n#define ASM_MOV_REG_IMM(as, reg_dest, imm) asm_thumb_mov_reg_i32_optimised((as), (reg_dest), (imm))\n#define ASM_MOV_REG_LOCAL(as, reg_dest, local_num) asm_thumb_mov_reg_local((as), (reg_dest), (local_num))\n#define ASM_MOV_REG_REG(as, reg_dest, reg_src) asm_thumb_mov_reg_reg((as), (reg_dest), (reg_src))\n#define ASM_MOV_REG_LOCAL_ADDR(as, reg_dest, local_num) asm_thumb_mov_reg_local_addr((as), (reg_dest), (local_num))\n#define ASM_MOV_REG_PCREL(as, rlo_dest, label) asm_thumb_mov_reg_pcrel((as), (rlo_dest), (label))\n\n#define ASM_NOT_REG(as, reg_dest) asm_thumb_mvn_rlo_rlo((as), (reg_dest), (reg_dest))\n#define ASM_NEG_REG(as, reg_dest) asm_thumb_neg_rlo_rlo((as), (reg_dest), (reg_dest))\n#define ASM_LSL_REG_REG(as, reg_dest, reg_shift) asm_thumb_format_4((as), ASM_THUMB_FORMAT_4_LSL, (reg_dest), (reg_shift))\n#define ASM_LSR_REG_REG(as, reg_dest, reg_shift) asm_thumb_format_4((as), ASM_THUMB_FORMAT_4_LSR, (reg_dest), (reg_shift))\n#define ASM_ASR_REG_REG(as, reg_dest, reg_shift) asm_thumb_format_4((as), ASM_THUMB_FORMAT_4_ASR, (reg_dest), (reg_shift))\n#define ASM_OR_REG_REG(as, reg_dest, reg_src) asm_thumb_format_4((as), ASM_THUMB_FORMAT_4_ORR, (reg_dest), (reg_src))\n#define ASM_XOR_REG_REG(as, reg_dest, reg_src) asm_thumb_format_4((as), ASM_THUMB_FORMAT_4_EOR, (reg_dest), (reg_src))\n#define ASM_AND_REG_REG(as, reg_dest, reg_src) asm_thumb_format_4((as), ASM_THUMB_FORMAT_4_AND, (reg_dest), (reg_src))\n#define ASM_ADD_REG_REG(as, reg_dest, reg_src) asm_thumb_add_rlo_rlo_rlo((as), (reg_dest), (reg_dest), (reg_src))\n#define ASM_SUB_REG_REG(as, reg_dest, reg_src) asm_thumb_sub_rlo_rlo_rlo((as), (reg_dest), (reg_dest), (reg_src))\n#define ASM_MUL_REG_REG(as, reg_dest, reg_src) asm_thumb_format_4((as), ASM_THUMB_FORMAT_4_MUL, (reg_dest), (reg_src))\n\n#define ASM_LOAD_REG_REG(as, reg_dest, reg_base) asm_thumb_ldr_rlo_rlo_i5((as), (reg_dest), (reg_base), 0)\n#define ASM_LOAD_REG_REG_OFFSET(as, reg_dest, reg_base, word_offset) asm_thumb_ldr_reg_reg_i12_optimised((as), (reg_dest), (reg_base), (word_offset))\n#define ASM_LOAD8_REG_REG(as, reg_dest, reg_base) asm_thumb_ldrb_rlo_rlo_i5((as), (reg_dest), (reg_base), 0)\n#define ASM_LOAD16_REG_REG(as, reg_dest, reg_base) asm_thumb_ldrh_rlo_rlo_i5((as), (reg_dest), (reg_base), 0)\n#define ASM_LOAD16_REG_REG_OFFSET(as, reg_dest, reg_base, uint16_offset) asm_thumb_ldrh_reg_reg_i12_optimised((as), (reg_dest), (reg_base), (uint16_offset))\n#define ASM_LOAD32_REG_REG(as, reg_dest, reg_base) asm_thumb_ldr_rlo_rlo_i5((as), (reg_dest), (reg_base), 0)\n\n#define ASM_STORE_REG_REG(as, reg_src, reg_base) asm_thumb_str_rlo_rlo_i5((as), (reg_src), (reg_base), 0)\n#define ASM_STORE_REG_REG_OFFSET(as, reg_src, reg_base, word_offset) asm_thumb_str_rlo_rlo_i5((as), (reg_src), (reg_base), (word_offset))\n#define ASM_STORE8_REG_REG(as, reg_src, reg_base) asm_thumb_strb_rlo_rlo_i5((as), (reg_src), (reg_base), 0)\n#define ASM_STORE16_REG_REG(as, reg_src, reg_base) asm_thumb_strh_rlo_rlo_i5((as), (reg_src), (reg_base), 0)\n#define ASM_STORE32_REG_REG(as, reg_src, reg_base) asm_thumb_str_rlo_rlo_i5((as), (reg_src), (reg_base), 0)\n\n#endif \n\n#endif \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}