{
  "module_name": "asmthumb.c",
  "hash_id": "8d04f6ff62d2408bab7f818c95483454e8a9c59357af1164ded2f21fe63e3137",
  "original_prompt": "Ingested from sys_09_Anvil/source/py/asmthumb.c",
  "human_readable_source": " \n\n#include <stdio.h>\n#include <assert.h>\n#include <string.h>\n\n#include \"py/mpconfig.h\"\n\n\n#if MICROPY_EMIT_THUMB || MICROPY_EMIT_INLINE_THUMB\n\n#include \"py/mpstate.h\"\n#include \"py/asmthumb.h\"\n\n#ifdef _MSC_VER\n#include <intrin.h>\n\nstatic uint32_t mp_clz(uint32_t x) {\n    unsigned long lz = 0;\n    return _BitScanReverse(&lz, x) ? (sizeof(x) * 8 - 1) - lz : 0;\n}\n\nstatic uint32_t mp_ctz(uint32_t x) {\n    unsigned long tz = 0;\n    return _BitScanForward(&tz, x) ? tz : 0;\n}\n#else\n#define mp_clz(x) __builtin_clz(x)\n#define mp_ctz(x) __builtin_ctz(x)\n#endif\n\n#define UNSIGNED_FIT5(x) ((uint32_t)(x) < 32)\n#define UNSIGNED_FIT7(x) ((uint32_t)(x) < 128)\n#define UNSIGNED_FIT8(x) (((x) & 0xffffff00) == 0)\n#define UNSIGNED_FIT16(x) (((x) & 0xffff0000) == 0)\n#define SIGNED_FIT8(x) (((x) & 0xffffff80) == 0) || (((x) & 0xffffff80) == 0xffffff80)\n#define SIGNED_FIT9(x) (((x) & 0xffffff00) == 0) || (((x) & 0xffffff00) == 0xffffff00)\n#define SIGNED_FIT12(x) (((x) & 0xfffff800) == 0) || (((x) & 0xfffff800) == 0xfffff800)\n#define SIGNED_FIT23(x) (((x) & 0xffc00000) == 0) || (((x) & 0xffc00000) == 0xffc00000)\n\n\n#define OP_ADD_W_RRI_HI(reg_src) (0xf200 | (reg_src))\n#define OP_ADD_W_RRI_LO(reg_dest, imm11) ((imm11 << 4 & 0x7000) | reg_dest << 8 | (imm11 & 0xff))\n#define OP_SUB_W_RRI_HI(reg_src) (0xf2a0 | (reg_src))\n#define OP_SUB_W_RRI_LO(reg_dest, imm11) ((imm11 << 4 & 0x7000) | reg_dest << 8 | (imm11 & 0xff))\n\n#define OP_LDR_W_HI(reg_base) (0xf8d0 | (reg_base))\n#define OP_LDR_W_LO(reg_dest, imm12) ((reg_dest) << 12 | (imm12))\n\n#define OP_LDRH_W_HI(reg_base) (0xf8b0 | (reg_base))\n#define OP_LDRH_W_LO(reg_dest, imm12) ((reg_dest) << 12 | (imm12))\n\nstatic inline byte *asm_thumb_get_cur_to_write_bytes(asm_thumb_t *as, int n) {\n    return mp_asm_base_get_cur_to_write_bytes(&as->base, n);\n}\n\n \n\n \n\n\n#define OP_PUSH_RLIST(rlolist)      (0xb400 | (rlolist))\n#define OP_PUSH_RLIST_LR(rlolist)   (0xb400 | 0x0100 | (rlolist))\n#define OP_POP_RLIST(rlolist)       (0xbc00 | (rlolist))\n#define OP_POP_RLIST_PC(rlolist)    (0xbc00 | 0x0100 | (rlolist))\n\n\n#define OP_ADD_SP(num_words) (0xb000 | (num_words))\n#define OP_SUB_SP(num_words) (0xb080 | (num_words))\n\n\n\n\n\n\n\n\n\n\n\n\nvoid asm_thumb_entry(asm_thumb_t *as, int num_locals) {\n    assert(num_locals >= 0);\n\n    \n    \n    #if MICROPY_DYNAMIC_COMPILER || MICROPY_EMIT_ARM || (defined(__arm__) && !defined(__thumb2__) && !defined(__thumb__))\n    #if MICROPY_DYNAMIC_COMPILER\n    if (mp_dynamic_compiler.native_arch == MP_NATIVE_ARCH_ARMV6)\n    #endif\n    {\n        asm_thumb_op32(as, 0x4010, 0xe92d); \n        asm_thumb_op32(as, 0xe009, 0xe28f); \n        asm_thumb_op32(as, 0xff3e, 0xe12f); \n        asm_thumb_op32(as, 0x4010, 0xe8bd); \n        asm_thumb_op32(as, 0xff1e, 0xe12f); \n    }\n    #endif\n\n    \n    \n    \n    \n    \n    uint reglist;\n    uint stack_adjust;\n    \n    switch (num_locals) {\n        case 0:\n            reglist = 0xf2;\n            stack_adjust = 0;\n            break;\n\n        case 1:\n            reglist = 0xf2;\n            stack_adjust = 0;\n            break;\n\n        case 2:\n            reglist = 0xfe;\n            stack_adjust = 0;\n            break;\n\n        case 3:\n            reglist = 0xfe;\n            stack_adjust = 0;\n            break;\n\n        default:\n            reglist = 0xfe;\n            stack_adjust = ((num_locals - 3) + 1) & (~1);\n            break;\n    }\n    asm_thumb_op16(as, OP_PUSH_RLIST_LR(reglist));\n    if (stack_adjust > 0) {\n        if (asm_thumb_allow_armv7m(as)) {\n            if (UNSIGNED_FIT7(stack_adjust)) {\n                asm_thumb_op16(as, OP_SUB_SP(stack_adjust));\n            } else {\n                asm_thumb_op32(as, OP_SUB_W_RRI_HI(ASM_THUMB_REG_SP), OP_SUB_W_RRI_LO(ASM_THUMB_REG_SP, stack_adjust * 4));\n            }\n        } else {\n            int adj = stack_adjust;\n            \n            while (!UNSIGNED_FIT7(adj)) {\n                asm_thumb_op16(as, OP_SUB_SP(127));\n                adj -= 127;\n            }\n            asm_thumb_op16(as, OP_SUB_SP(adj));\n        }\n    }\n    as->push_reglist = reglist;\n    as->stack_adjust = stack_adjust;\n}\n\nvoid asm_thumb_exit(asm_thumb_t *as) {\n    if (as->stack_adjust > 0) {\n        if (asm_thumb_allow_armv7m(as)) {\n            if (UNSIGNED_FIT7(as->stack_adjust)) {\n                asm_thumb_op16(as, OP_ADD_SP(as->stack_adjust));\n            } else {\n                asm_thumb_op32(as, OP_ADD_W_RRI_HI(ASM_THUMB_REG_SP), OP_ADD_W_RRI_LO(ASM_THUMB_REG_SP, as->stack_adjust * 4));\n            }\n        } else {\n            int adj = as->stack_adjust;\n            \n            while (!UNSIGNED_FIT7(adj)) {\n                asm_thumb_op16(as, OP_ADD_SP(127));\n                adj -= 127;\n            }\n            asm_thumb_op16(as, OP_ADD_SP(adj));\n        }\n    }\n    asm_thumb_op16(as, OP_POP_RLIST_PC(as->push_reglist));\n}\n\nstatic mp_uint_t get_label_dest(asm_thumb_t *as, uint label) {\n    assert(label < as->base.max_num_labels);\n    return as->base.label_offsets[label];\n}\n\nvoid asm_thumb_op16(asm_thumb_t *as, uint op) {\n    byte *c = asm_thumb_get_cur_to_write_bytes(as, 2);\n    if (c != NULL) {\n        \n        c[0] = op;\n        c[1] = op >> 8;\n    }\n}\n\nvoid asm_thumb_op32(asm_thumb_t *as, uint op1, uint op2) {\n    byte *c = asm_thumb_get_cur_to_write_bytes(as, 4);\n    if (c != NULL) {\n        \n        c[0] = op1;\n        c[1] = op1 >> 8;\n        c[2] = op2;\n        c[3] = op2 >> 8;\n    }\n}\n\n#define OP_FORMAT_4(op, rlo_dest, rlo_src) ((op) | ((rlo_src) << 3) | (rlo_dest))\n\nvoid asm_thumb_format_4(asm_thumb_t *as, uint op, uint rlo_dest, uint rlo_src) {\n    assert(rlo_dest < ASM_THUMB_REG_R8);\n    assert(rlo_src < ASM_THUMB_REG_R8);\n    asm_thumb_op16(as, OP_FORMAT_4(op, rlo_dest, rlo_src));\n}\n\nvoid asm_thumb_mov_reg_reg(asm_thumb_t *as, uint reg_dest, uint reg_src) {\n    uint op_lo;\n    if (reg_src < 8) {\n        op_lo = reg_src << 3;\n    } else {\n        op_lo = 0x40 | ((reg_src - 8) << 3);\n    }\n    if (reg_dest < 8) {\n        op_lo |= reg_dest;\n    } else {\n        op_lo |= 0x80 | (reg_dest - 8);\n    }\n    \n    asm_thumb_op16(as, 0x4600 | op_lo);\n}\n\n\nvoid asm_thumb_mov_reg_i16(asm_thumb_t *as, uint mov_op, uint reg_dest, int i16_src) {\n    assert(reg_dest < ASM_THUMB_REG_R15);\n    \n    asm_thumb_op32(as, mov_op | ((i16_src >> 1) & 0x0400) | ((i16_src >> 12) & 0xf), ((i16_src << 4) & 0x7000) | (reg_dest << 8) | (i16_src & 0xff));\n}\n\nstatic void asm_thumb_mov_rlo_i16(asm_thumb_t *as, uint rlo_dest, int i16_src) {\n    asm_thumb_mov_rlo_i8(as, rlo_dest, (i16_src >> 8) & 0xff);\n    asm_thumb_lsl_rlo_rlo_i5(as, rlo_dest, rlo_dest, 8);\n    asm_thumb_add_rlo_i8(as, rlo_dest, i16_src & 0xff);\n}\n\n#define OP_B_N(byte_offset) (0xe000 | (((byte_offset) >> 1) & 0x07ff))\n\nbool asm_thumb_b_n_label(asm_thumb_t *as, uint label) {\n    mp_uint_t dest = get_label_dest(as, label);\n    mp_int_t rel = dest - as->base.code_offset;\n    rel -= 4; \n    asm_thumb_op16(as, OP_B_N(rel));\n    return as->base.pass != MP_ASM_PASS_EMIT || SIGNED_FIT12(rel);\n}\n\n#define OP_BCC_N(cond, byte_offset) (0xd000 | ((cond) << 8) | (((byte_offset) >> 1) & 0x00ff))\n\n\n#define OP_BCC_W_HI(cond, byte_offset) (0xf000 | ((cond) << 6) | (((byte_offset) >> 10) & 0x0400) | (((byte_offset) >> 14) & 0x003f))\n#define OP_BCC_W_LO(byte_offset) (0x8000 | ((byte_offset) & 0x2000) | (((byte_offset) >> 1) & 0x0fff))\n\nbool asm_thumb_bcc_nw_label(asm_thumb_t *as, int cond, uint label, bool wide) {\n    mp_uint_t dest = get_label_dest(as, label);\n    mp_int_t rel = dest - as->base.code_offset;\n    rel -= 4; \n    if (!wide) {\n        asm_thumb_op16(as, OP_BCC_N(cond, rel));\n        return as->base.pass != MP_ASM_PASS_EMIT || SIGNED_FIT9(rel);\n    } else if (asm_thumb_allow_armv7m(as)) {\n        asm_thumb_op32(as, OP_BCC_W_HI(cond, rel), OP_BCC_W_LO(rel));\n        return true;\n    } else {\n        \n        return false;\n    }\n}\n\n#define OP_BL_HI(byte_offset) (0xf000 | (((byte_offset) >> 12) & 0x07ff))\n#define OP_BL_LO(byte_offset) (0xf800 | (((byte_offset) >> 1) & 0x07ff))\n\nbool asm_thumb_bl_label(asm_thumb_t *as, uint label) {\n    mp_uint_t dest = get_label_dest(as, label);\n    mp_int_t rel = dest - as->base.code_offset;\n    rel -= 4; \n    asm_thumb_op32(as, OP_BL_HI(rel), OP_BL_LO(rel));\n    return as->base.pass != MP_ASM_PASS_EMIT || SIGNED_FIT23(rel);\n}\n\nsize_t asm_thumb_mov_reg_i32(asm_thumb_t *as, uint reg_dest, mp_uint_t i32) {\n    \n    \n\n    size_t loc = mp_asm_base_get_code_pos(&as->base);\n\n    if (asm_thumb_allow_armv7m(as)) {\n        asm_thumb_mov_reg_i16(as, ASM_THUMB_OP_MOVW, reg_dest, i32);\n        asm_thumb_mov_reg_i16(as, ASM_THUMB_OP_MOVT, reg_dest, i32 >> 16);\n    } else {\n        \n        assert(reg_dest < ASM_THUMB_REG_R8);\n\n        \n        assert(!as->base.code_base || !(3u & (uintptr_t)as->base.code_base));\n\n        \n        \n        \n        \n        \n        \n        if (as->base.code_offset & 2u) {\n            asm_thumb_op16(as, ASM_THUMB_OP_NOP);\n        }\n        asm_thumb_ldr_rlo_pcrel_i8(as, reg_dest, 0);\n        asm_thumb_op16(as, OP_B_N(2));\n        asm_thumb_op16(as, i32 & 0xffff);\n        asm_thumb_op16(as, i32 >> 16);\n    }\n\n    return loc;\n}\n\nvoid asm_thumb_mov_reg_i32_optimised(asm_thumb_t *as, uint reg_dest, int i32) {\n    if (reg_dest < 8 && UNSIGNED_FIT8(i32)) {\n        asm_thumb_mov_rlo_i8(as, reg_dest, i32);\n    } else if (asm_thumb_allow_armv7m(as)) {\n        if (UNSIGNED_FIT16(i32)) {\n            asm_thumb_mov_reg_i16(as, ASM_THUMB_OP_MOVW, reg_dest, i32);\n        } else {\n            asm_thumb_mov_reg_i32(as, reg_dest, i32);\n        }\n    } else {\n        uint rlo_dest = reg_dest;\n        assert(rlo_dest < ASM_THUMB_REG_R8); \n\n        bool negate = i32 < 0 && ((i32 + i32) & 0xffffffffu); \n        if (negate) {\n            i32 = -i32;\n        }\n\n        uint clz = mp_clz(i32);\n        uint ctz = i32 ? mp_ctz(i32) : 0;\n        assert(clz + ctz <= 32);\n        if (clz + ctz >= 24) {\n            asm_thumb_mov_rlo_i8(as, rlo_dest, (i32 >> ctz) & 0xff);\n            asm_thumb_lsl_rlo_rlo_i5(as, rlo_dest, rlo_dest, ctz);\n        } else if (UNSIGNED_FIT16(i32)) {\n            asm_thumb_mov_rlo_i16(as, rlo_dest, i32);\n        } else {\n            if (negate) {\n                \n                negate = false;\n                i32 = -i32;\n            }\n            asm_thumb_mov_reg_i32(as, rlo_dest, i32);\n        }\n        if (negate) {\n            asm_thumb_neg_rlo_rlo(as, rlo_dest, rlo_dest);\n        }\n    }\n}\n\n#define OP_STR_TO_SP_OFFSET(rlo_dest, word_offset) (0x9000 | ((rlo_dest) << 8) | ((word_offset) & 0x00ff))\n#define OP_LDR_FROM_SP_OFFSET(rlo_dest, word_offset) (0x9800 | ((rlo_dest) << 8) | ((word_offset) & 0x00ff))\n\nstatic void asm_thumb_mov_local_check(asm_thumb_t *as, int word_offset) {\n    if (as->base.pass >= MP_ASM_PASS_EMIT) {\n        assert(word_offset >= 0);\n        if (!UNSIGNED_FIT8(word_offset)) {\n            mp_raise_NotImplementedError(MP_ERROR_TEXT(\"too many locals for native method\"));\n        }\n    }\n}\n\nvoid asm_thumb_mov_local_reg(asm_thumb_t *as, int local_num, uint rlo_src) {\n    assert(rlo_src < ASM_THUMB_REG_R8);\n    int word_offset = local_num;\n    asm_thumb_mov_local_check(as, word_offset);\n    asm_thumb_op16(as, OP_STR_TO_SP_OFFSET(rlo_src, word_offset));\n}\n\nvoid asm_thumb_mov_reg_local(asm_thumb_t *as, uint rlo_dest, int local_num) {\n    assert(rlo_dest < ASM_THUMB_REG_R8);\n    int word_offset = local_num;\n    asm_thumb_mov_local_check(as, word_offset);\n    asm_thumb_op16(as, OP_LDR_FROM_SP_OFFSET(rlo_dest, word_offset));\n}\n\n#define OP_ADD_REG_SP_OFFSET(rlo_dest, word_offset) (0xa800 | ((rlo_dest) << 8) | ((word_offset) & 0x00ff))\n\nvoid asm_thumb_mov_reg_local_addr(asm_thumb_t *as, uint rlo_dest, int local_num) {\n    assert(rlo_dest < ASM_THUMB_REG_R8);\n    int word_offset = local_num;\n    assert(as->base.pass < MP_ASM_PASS_EMIT || word_offset >= 0);\n    asm_thumb_op16(as, OP_ADD_REG_SP_OFFSET(rlo_dest, word_offset));\n}\n\nvoid asm_thumb_mov_reg_pcrel(asm_thumb_t *as, uint rlo_dest, uint label) {\n    mp_uint_t dest = get_label_dest(as, label);\n    mp_int_t rel = dest - as->base.code_offset;\n    rel |= 1; \n    if (asm_thumb_allow_armv7m(as)) {\n        rel -= 6 + 4; \n        asm_thumb_mov_reg_i16(as, ASM_THUMB_OP_MOVW, rlo_dest, rel); \n        asm_thumb_sxth_rlo_rlo(as, rlo_dest, rlo_dest); \n    } else {\n        rel -= 8 + 4; \n        \n        asm_thumb_mov_rlo_i16(as, rlo_dest, rel);\n        \n        asm_thumb_sxth_rlo_rlo(as, rlo_dest, rlo_dest);\n    }\n    asm_thumb_add_reg_reg(as, rlo_dest, ASM_THUMB_REG_R15); \n}\n\n\nstatic inline void asm_thumb_ldr_reg_reg_i12(asm_thumb_t *as, uint reg_dest, uint reg_base, uint word_offset) {\n    asm_thumb_op32(as, OP_LDR_W_HI(reg_base), OP_LDR_W_LO(reg_dest, word_offset * 4));\n}\n\n\nstatic void asm_thumb_add_reg_reg_offset(asm_thumb_t *as, uint reg_dest, uint reg_base, uint offset, uint offset_shift) {\n    if (reg_dest < ASM_THUMB_REG_R8 && reg_base < ASM_THUMB_REG_R8) {\n        if (offset << offset_shift < 256) {\n            if (reg_dest != reg_base) {\n                asm_thumb_mov_reg_reg(as, reg_dest, reg_base);\n            }\n            asm_thumb_add_rlo_i8(as, reg_dest, offset << offset_shift);\n        } else if (UNSIGNED_FIT8(offset) && reg_dest != reg_base) {\n            asm_thumb_mov_rlo_i8(as, reg_dest, offset);\n            asm_thumb_lsl_rlo_rlo_i5(as, reg_dest, reg_dest, offset_shift);\n            asm_thumb_add_rlo_rlo_rlo(as, reg_dest, reg_dest, reg_base);\n        } else if (reg_dest != reg_base) {\n            asm_thumb_mov_rlo_i16(as, reg_dest, offset << offset_shift);\n            asm_thumb_add_rlo_rlo_rlo(as, reg_dest, reg_dest, reg_dest);\n        } else {\n            uint reg_other = reg_dest ^ 7;\n            asm_thumb_op16(as, OP_PUSH_RLIST((1 << reg_other)));\n            asm_thumb_mov_rlo_i16(as, reg_other, offset << offset_shift);\n            asm_thumb_add_rlo_rlo_rlo(as, reg_dest, reg_dest, reg_other);\n            asm_thumb_op16(as, OP_POP_RLIST((1 << reg_other)));\n        }\n    } else {\n        assert(0); \n    }\n}\n\nvoid asm_thumb_ldr_reg_reg_i12_optimised(asm_thumb_t *as, uint reg_dest, uint reg_base, uint word_offset) {\n    if (reg_dest < ASM_THUMB_REG_R8 && reg_base < ASM_THUMB_REG_R8 && UNSIGNED_FIT5(word_offset)) {\n        asm_thumb_ldr_rlo_rlo_i5(as, reg_dest, reg_base, word_offset);\n    } else if (asm_thumb_allow_armv7m(as)) {\n        asm_thumb_ldr_reg_reg_i12(as, reg_dest, reg_base, word_offset);\n    } else {\n        asm_thumb_add_reg_reg_offset(as, reg_dest, reg_base, word_offset - 31, 2);\n        asm_thumb_ldr_rlo_rlo_i5(as, reg_dest, reg_dest, 31);\n    }\n}\n\n\nstatic inline void asm_thumb_ldrh_reg_reg_i12(asm_thumb_t *as, uint reg_dest, uint reg_base, uint uint16_offset) {\n    asm_thumb_op32(as, OP_LDRH_W_HI(reg_base), OP_LDRH_W_LO(reg_dest, uint16_offset * 2));\n}\n\nvoid asm_thumb_ldrh_reg_reg_i12_optimised(asm_thumb_t *as, uint reg_dest, uint reg_base, uint uint16_offset) {\n    if (reg_dest < ASM_THUMB_REG_R8 && reg_base < ASM_THUMB_REG_R8 && UNSIGNED_FIT5(uint16_offset)) {\n        asm_thumb_ldrh_rlo_rlo_i5(as, reg_dest, reg_base, uint16_offset);\n    } else if (asm_thumb_allow_armv7m(as)) {\n        asm_thumb_ldrh_reg_reg_i12(as, reg_dest, reg_base, uint16_offset);\n    } else {\n        asm_thumb_add_reg_reg_offset(as, reg_dest, reg_base, uint16_offset - 31, 1);\n        asm_thumb_ldrh_rlo_rlo_i5(as, reg_dest, reg_dest, 31);\n    }\n}\n\n\n#define OP_BW_HI(byte_offset) (0xf000 | (((byte_offset) >> 12) & 0x07ff))\n#define OP_BW_LO(byte_offset) (0xb800 | (((byte_offset) >> 1) & 0x07ff))\n\nvoid asm_thumb_b_label(asm_thumb_t *as, uint label) {\n    mp_uint_t dest = get_label_dest(as, label);\n    mp_int_t rel = dest - as->base.code_offset;\n    rel -= 4; \n\n    if (dest != (mp_uint_t)-1 && rel <= -4) {\n        \n        \n        if (SIGNED_FIT12(rel)) {\n            asm_thumb_op16(as, OP_B_N(rel));\n            return;\n        }\n    }\n\n    \n\n    if (asm_thumb_allow_armv7m(as)) {\n        asm_thumb_op32(as, OP_BW_HI(rel), OP_BW_LO(rel));\n    } else {\n        if (SIGNED_FIT12(rel)) {\n            \n            asm_thumb_op16(as, OP_B_N(rel));\n        } else {\n            asm_thumb_op16(as, ASM_THUMB_OP_NOP);\n            if (dest != (mp_uint_t)-1) {\n                \n                mp_raise_NotImplementedError(MP_ERROR_TEXT(\"native method too big\"));\n            }\n        }\n    }\n}\n\nvoid asm_thumb_bcc_label(asm_thumb_t *as, int cond, uint label) {\n    mp_uint_t dest = get_label_dest(as, label);\n    mp_int_t rel = dest - as->base.code_offset;\n    rel -= 4; \n\n    if (dest != (mp_uint_t)-1 && rel <= -4) {\n        \n        \n        if (SIGNED_FIT9(rel)) {\n            asm_thumb_op16(as, OP_BCC_N(cond, rel));\n            return;\n        }\n    }\n\n    \n\n    if (asm_thumb_allow_armv7m(as)) {\n        asm_thumb_op32(as, OP_BCC_W_HI(cond, rel), OP_BCC_W_LO(rel));\n    } else {\n        \n        asm_thumb_op16(as, OP_BCC_N(cond ^ 1, 0));\n        asm_thumb_b_label(as, label);\n    }\n}\n\nvoid asm_thumb_bcc_rel9(asm_thumb_t *as, int cond, int rel) {\n    rel -= 4; \n    assert(SIGNED_FIT9(rel));\n    asm_thumb_op16(as, OP_BCC_N(cond, rel));\n}\n\nvoid asm_thumb_b_rel12(asm_thumb_t *as, int rel) {\n    rel -= 4; \n    assert(SIGNED_FIT12(rel));\n    asm_thumb_op16(as, OP_B_N(rel));\n}\n\n#define OP_BLX(reg) (0x4780 | ((reg) << 3))\n#define OP_SVC(arg) (0xdf00 | (arg))\n\nvoid asm_thumb_bl_ind(asm_thumb_t *as, uint fun_id, uint reg_temp) {\n    \n    asm_thumb_ldr_reg_reg_i12_optimised(as, reg_temp, ASM_THUMB_REG_FUN_TABLE, fun_id);\n    asm_thumb_op16(as, OP_BLX(reg_temp));\n}\n\n#endif \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}